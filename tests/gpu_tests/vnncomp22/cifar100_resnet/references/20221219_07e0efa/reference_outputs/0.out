Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  sparse_alpha: true
  save_adv_example: false
  precompile_jit: false
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2022_benchmarks/benchmarks/cifar100_tinyimagenet_resnet
model:
  name: null
  path: null
  onnx_path: null
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: default_onnx_and_vnnlib_loader
  onnx_optimization_flags: merge_bn
data:
  start: 0
  end: 1
  select_instance: null
  num_outputs: 100
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR100
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  vnnlib_path: null
  vnnlib_path_prefix: ''
solver:
  batch_size: 256
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: true
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.25
    iteration: 20
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
    full_conv_alpha: false
  beta-crown:
    lr_alpha: 0.05
    lr_beta: 0.1
    lr_decay: 0.98
    optimizer: adam
    iteration: 5
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
  multi_class:
    multi_class_method: allclass_domain
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
bab:
  initial_max_domains: 100
  max_domains: .inf
  decision_thresh: 0
  timeout: 360
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_intermediate_layers: ''
  interm_transfer: false
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 100
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
    _tmp_cuts: null
    fixed_cuts: false
    _eran_cuts: null
    add_implied_cuts: false
    add_input_cuts: false
  branching:
    method: kfsb
    candidates: 7
    reduceop: max
    sb_coeff_thresh: 0.001
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sort_domain_interval: -1
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 30.0
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  pgd_steps: 100
  pgd_restarts: 10
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  cex_path: ./test_cex.txt
  attack_mode: PGD
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 5000000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
debug:
  lp_test: null

Experiments at Thu Dec 22 00:19:18 2022 on diablo.cs.ucla.edu
customized start/end sample from instance 0 to 1 in instances.csv
Internal results will be saved to a-b-crown_[instances]_start=0_end=1_iter=5_b=256_timeout=360_branching=kfsb-max-7_lra-init=0.25_lra=0.05_lrb=0.1_PGD=skip_cplex_cuts=False_initial_max_domains=100.npz.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx onnx/CIFAR100_resnet_small.onnx
Using vnnlib vnnlib/CIFAR100_resnet_small_prop_idx_7129_sidx_1634_eps_0.0039.vnnlib
Precompiled vnnlib file found at ../../vnncomp2022_benchmarks/benchmarks/cifar100_tinyimagenet_resnet/vnnlib/CIFAR100_resnet_small_prop_idx_7129_sidx_1634_eps_0.0039.vnnlib.compiled
Loading onnx ../../vnncomp2022_benchmarks/benchmarks/cifar100_tinyimagenet_resnet/onnx/CIFAR100_resnet_small.onnx wih quirks {}
Onnx optimization with flag: merge_bn
Found existed optimized onnx model at ../../vnncomp2022_benchmarks/benchmarks/cifar100_tinyimagenet_resnet/onnx/CIFAR100_resnet_small.onnx.optimized
Model prediction is: tensor([[ -6.16110611,  -5.35189247,  -6.63838196,  -1.86059761,   0.11116584,
         -10.11872673,  -4.05360031,  -1.74366450,  -3.32689142,  -8.15904236,
          -7.46693563,  -5.78805780,  -3.15143609,  -5.00590134,  -4.14910078,
          -2.56400585,  -7.67670918,  -7.34021759,  -4.19427729,  -2.98574638,
         -11.50354290,  -2.86428237,  -6.95179081,  -8.57429600,  -5.86174917,
          -6.12972975,  -1.81921124,  -1.88009501,  -7.23338795,  -2.77960277,
          -6.66013479,  -2.95222259,  -4.44099236,  -2.23306108,  -2.14823103,
          -6.19033241,  -7.01506472,  -3.64295626,  -1.63159943,  -6.60959435,
          -6.24223185,  -5.34258413,  -2.82549000,  -4.65815115,  -1.93024802,
          -1.66022003,  -5.19752359,  -4.90962315,  -3.16080785,  -6.14222050,
          -1.68901002,  -1.35682666,  -4.53342772,  -9.38375664,  -6.84528923,
          -0.98658538,  -2.42015982,  -6.15781927,  -4.54610157,  -3.36491632,
          -7.45315218,  -9.82804394,  -6.81166935,  -2.71696711,  -0.80461359,
          -3.63948226,  -0.40597302,  -4.75543308,  -6.19850063,  -6.96731520,
          -5.63448668,  -6.89007616,  -1.89141941,  -5.16311264,   2.23245382,
          -3.20890164,  -7.58390331,  -2.06751800,  -2.76550269,  -1.95667255,
          -2.20863008,  -3.25515842,  -5.95652390,  -4.48778105,  -7.88440990,
          -3.25094366,  -6.59201813,  -7.73082256,  -5.21276379,  -2.16033602,
          -1.06771100,  -5.50464869,  -5.21620941,  -3.12952518,  -9.58456707,
          -7.41099882,  -4.63919449,  -2.05928230,  -6.47336006,  -2.76289630]],
       device='cuda:0')
layer /54 using sparse-features alpha with shape [553]; unstable size 553; total size 14400 (torch.Size([1, 64, 15, 15]))
layer /54 start_node /input.4 using sparse-spec alpha with unstable size 82 total_size 128 output_shape 128
layer /54 start_node /59 using sparse-spec alpha with unstable size 106 total_size 128 output_shape 128
layer /54 start_node /input.12 using sparse-spec alpha with unstable size 15 total_size 128 output_shape 128
layer /54 start_node /64 using sparse-spec alpha with unstable size 91 total_size 128 output_shape 128
layer /54 start_node /input.20 using sparse-spec alpha with unstable size 108 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /54 start_node /70 using sparse-spec alpha with unstable size 316 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /54 start_node /75 using sparse-spec alpha with unstable size 150 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /54 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /54 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /56 using sparse-features alpha with shape [217]; unstable size 217; total size 8192 (torch.Size([1, 128, 8, 8]))
layer /56 start_node /59 using sparse-spec alpha with unstable size 106 total_size 128 output_shape 128
layer /56 start_node /input.12 using sparse-spec alpha with unstable size 15 total_size 128 output_shape 128
layer /56 start_node /64 using sparse-spec alpha with unstable size 91 total_size 128 output_shape 128
layer /56 start_node /input.20 using sparse-spec alpha with unstable size 108 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /56 start_node /70 using sparse-spec alpha with unstable size 316 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /56 start_node /75 using sparse-spec alpha with unstable size 150 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /56 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /56 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /input.8 using sparse-features alpha with shape [408]; unstable size 408; total size 8192 (torch.Size([1, 128, 8, 8]))
layer /input.8 start_node /input.12 using sparse-spec alpha with unstable size 15 total_size 128 output_shape 128
layer /input.8 start_node /64 using sparse-spec alpha with unstable size 91 total_size 128 output_shape 128
layer /input.8 start_node /input.20 using sparse-spec alpha with unstable size 59 total_size 128 output_shape 128
layer /input.8 start_node /70 using sparse-spec alpha with unstable size 316 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /input.8 start_node /75 using sparse-spec alpha with unstable size 150 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /input.8 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /input.8 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /62 using sparse-features alpha with shape [43]; unstable size 43; total size 8192 (torch.Size([1, 128, 8, 8]))
layer /62 start_node /64 using sparse-spec alpha with unstable size 91 total_size 128 output_shape 128
layer /62 start_node /input.20 using sparse-spec alpha with unstable size 59 total_size 128 output_shape 128
layer /62 start_node /70 using sparse-spec alpha with unstable size 316 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /62 start_node /75 using sparse-spec alpha with unstable size 150 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /62 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /62 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /input.16 using sparse-features alpha with shape [337]; unstable size 337; total size 8192 (torch.Size([1, 128, 8, 8]))
layer /input.16 start_node /input.20 using sparse-spec alpha with unstable size 59 total_size 128 output_shape 128
layer /input.16 start_node /70 using sparse-spec alpha with unstable size 100 total_size 128 output_shape 128
layer /input.16 start_node /75 using sparse-spec alpha with unstable size 150 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /input.16 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /input.16 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /67 using sparse-features alpha with shape [108]; unstable size 108; total size 2048 (torch.Size([1, 128, 4, 4]))
layer /67 start_node /70 using sparse-spec alpha with unstable size 100 total_size 128 output_shape 128
layer /67 start_node /75 using sparse-spec alpha with unstable size 150 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /67 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /67 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /input.24 using sparse-features alpha with shape [316]; unstable size 316; total size 2048 (torch.Size([1, 128, 4, 4]))
layer /input.24 start_node /75 using sparse-spec alpha with unstable size 150 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /input.24 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /input.24 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /73 using sparse-features alpha with shape [0]; unstable size 0; total size 2048 (torch.Size([1, 128, 4, 4]))
layer /73 start_node /75 using sparse-spec alpha with unstable size 53 total_size 128 output_shape 128
layer /73 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /73 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /76 using sparse-features alpha with shape [150]; unstable size 150; total size 2048 (torch.Size([1, 128, 4, 4]))
layer /76 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /76 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /79 using sparse-features alpha with shape [12]; unstable size 12; total size 100 (torch.Size([1, 100]))
layer /79 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
Optimizable variables initialized.
initial CROWN bounds: tensor([[ 4.58201504,  4.65631199,  5.54419279,  1.16658831, -0.02561814,
          8.95760155,  2.92082930,  1.14079309,  1.54260302,  6.60651779,
          6.72118282,  4.72295666,  1.85433054,  3.96015310,  3.29507971,
          1.82076097,  6.14002609,  5.73220253,  3.15422821,  1.95755959,
          9.82365417,  1.88867521,  5.52393675,  7.77056217,  5.11357689,
          5.20151758,  1.33262062,  1.49766982,  6.21567726,  1.55253029,
          5.87450933,  1.85210419,  3.75290775,  0.78319836,  1.26455164,
          4.88834047,  6.21213245,  2.83589864,  1.20469046,  4.86897659,
          4.78672695,  3.89892912,  1.78502131,  3.59130025,  1.30915356,
          1.02204657,  4.03141499,  2.62421322,  1.27290249,  5.27491570,
          2.30410385,  0.47220445,  2.56466961,  7.35462761,  5.69668293,
          0.80267698,  0.71510577,  4.70079041,  3.13846779,  1.79706764,
          5.98687696,  8.38723755,  5.69914627,  2.59605598,  0.47852373,
          3.19327521, -0.67651582,  4.54048634,  4.93768740,  5.61079025,
          3.82027340,  6.05506468,  1.46648192,  4.81223869,  2.09049225,
          6.37115240,  1.13275194,  1.83720136,  0.85678625,  1.74134564,
          2.26106930,  4.88198090,  3.27520180,  6.57559776,  2.21175909,
          4.97303867,  6.46450520,  4.21740913,  0.68550968,  0.35515904,
          4.71084166,  4.08793640,  2.73747897,  7.69276810,  6.60700607,
          2.63158560,  1.51131129,  5.10305214,  2.18639612]], device='cuda:0') None
prune_after_crown optimization in use: original label size = 99 pruned label size = 2
best_l after optimization: 0.4482877552509308 with beta sum per layer: []
alpha/beta optimization time: 11.748404502868652
initial alpha-CROWN bounds: tensor([[        inf,         inf,         inf,         inf,  0.44896796,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf, -0.00068021,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf]], device='cuda:0')
Worst class: (+ rhs) -0.0006802082061767578
  prune after CROWN overhead: 0.0013973712921142578 s
Total VNNLIB file length: 99, max property batch size: 100, total number of batches: 1
lA shape: [torch.Size([1, 99, 64, 15, 15]), torch.Size([1, 99, 128, 8, 8]), torch.Size([1, 99, 128, 8, 8]), torch.Size([1, 99, 128, 8, 8]), torch.Size([1, 99, 128, 8, 8]), torch.Size([1, 99, 128, 4, 4]), torch.Size([1, 99, 128, 4, 4]), torch.Size([1, 99, 128, 4, 4]), torch.Size([1, 99, 128, 4, 4]), torch.Size([1, 99, 100])]

Properties batch 0, size 99
Remaining timeout: 221.88721323013306
##### Instance 0 first 10 spec matrices: [[[-1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]

 [[ 0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]

 [[ 0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]

 [[ 0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]]
thresholds: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ######
Initial alpha-CROWN verified for spec index [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 67 68 69 70 71 72
 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96
 97 98] with bound tensor([       inf,        inf,        inf,        inf, 0.44896796,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf], device='cuda:0').
Remaining spec index [66] with bounds tensor([[-0.00068021]], device='cuda:0') need to verify.
Model prediction is: tensor([ -6.16110611,  -5.35189247,  -6.63838196,  -1.86059761,   0.11116584,
        -10.11872673,  -4.05360031,  -1.74366450,  -3.32689142,  -8.15904236,
         -7.46693563,  -5.78805780,  -3.15143609,  -5.00590134,  -4.14910078,
         -2.56400585,  -7.67670918,  -7.34021759,  -4.19427729,  -2.98574638,
        -11.50354290,  -2.86428237,  -6.95179081,  -8.57429600,  -5.86174917,
         -6.12972975,  -1.81921124,  -1.88009501,  -7.23338795,  -2.77960277,
         -6.66013479,  -2.95222259,  -4.44099236,  -2.23306108,  -2.14823103,
         -6.19033241,  -7.01506472,  -3.64295626,  -1.63159943,  -6.60959435,
         -6.24223185,  -5.34258413,  -2.82549000,  -4.65815115,  -1.93024802,
         -1.66022003,  -5.19752359,  -4.90962315,  -3.16080785,  -6.14222050,
         -1.68901002,  -1.35682666,  -4.53342772,  -9.38375664,  -6.84528923,
         -0.98658538,  -2.42015982,  -6.15781927,  -4.54610157,  -3.36491632,
         -7.45315218,  -9.82804394,  -6.81166935,  -2.71696711,  -0.80461359,
         -3.63948226,  -0.40597302,  -4.75543308,  -6.19850063,  -6.96731520,
         -5.63448668,  -6.89007616,  -1.89141941,  -5.16311264,   2.23245382,
         -3.20890164,  -7.58390331,  -2.06751800,  -2.76550269,  -1.95667255,
         -2.20863008,  -3.25515842,  -5.95652390,  -4.48778105,  -7.88440990,
         -3.25094366,  -6.59201813,  -7.73082256,  -5.21276379,  -2.16033602,
         -1.06771100,  -5.50464869,  -5.21620941,  -3.12952518,  -9.58456707,
         -7.41099882,  -4.63919449,  -2.05928230,  -6.47336006,  -2.76289630],
       device='cuda:0')/home/zhouxingshi/onnx2pytorch/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  "Using experimental implementation that allows 'batch_size > 1'."
/home/zhouxingshi/onnx2pytorch/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/zhouxingshi/onnx2pytorch/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/branching_domains.py:970: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(arguments.Config["bab"]["decision_thresh"] + 1e-7)

build_the_model_with_refined_bounds batch [0/1]
setting alpha for layer /54 start_node /80 with alignment adjustment
setting alpha for layer /56 start_node /80 with alignment adjustment
setting alpha for layer /input.8 start_node /80 with alignment adjustment
setting alpha for layer /62 start_node /80 with alignment adjustment
setting alpha for layer /input.16 start_node /80 with alignment adjustment
setting alpha for layer /67 start_node /80 with alignment adjustment
setting alpha for layer /input.24 start_node /80 with alignment adjustment
setting alpha for layer /73 start_node /80 with alignment adjustment
setting alpha for layer /76 start_node /80 with alignment adjustment
setting alpha for layer /79 start_node /80 with alignment adjustment
all slope initialized
directly get lb and ub from refined bounds
lA shapes: [torch.Size([1, 1, 64, 15, 15]), torch.Size([1, 1, 128, 8, 8]), torch.Size([1, 1, 128, 8, 8]), torch.Size([1, 1, 128, 8, 8]), torch.Size([1, 1, 128, 8, 8]), torch.Size([1, 1, 128, 4, 4]), torch.Size([1, 1, 128, 4, 4]), torch.Size([1, 1, 128, 4, 4]), torch.Size([1, 1, 128, 4, 4]), torch.Size([1, 1, 100])]
c shape: torch.Size([1, 1, 100])
alpha-CROWN with fixed intermediate bounds: tensor([[-0.00068021]], device='cuda:0') tensor([[inf]], device='cuda:0')
Keeping slopes for these layers: ['/80']
Keeping slopes for these layers: ['/80']
layer 0 name BoundConv(name="/input") size torch.Size([14400]) unstable 553
layer 1 name BoundConv(name="/input.4") size torch.Size([8192]) unstable 212
layer 2 name BoundAdd(name="/59") size torch.Size([8192]) unstable 396
layer 3 name BoundConv(name="/input.12") size torch.Size([8192]) unstable 41
layer 4 name BoundAdd(name="/64") size torch.Size([8192]) unstable 325
layer 5 name BoundConv(name="/input.20") size torch.Size([2048]) unstable 101
layer 6 name BoundAdd(name="/70") size torch.Size([2048]) unstable 300
layer 7 name BoundConv(name="/input.28") size torch.Size([2048]) unstable 0
layer 8 name BoundAdd(name="/75") size torch.Size([2048]) unstable 143
layer 9 name BoundLinear(name="/input.32") size torch.Size([100]) unstable 9
-----------------
# of unstable neurons: 2080
-----------------

batch:  torch.Size([1, 64, 15, 15]) pre split depth:  4
batch:  torch.Size([1, 64, 15, 15]) post split depth:  4
splitting decisions: 
split level 0: [9, 71] 
split level 1: [9, 49] 
split level 2: [6, 1466] 
split level 3: [9, 43] 
(16, 3, 32, 32) torch.Size([16, 1, 100]) torch.Size([16, 1])

all verified at 0th iter
pruning_in_iteration open status: False
ratio of positive domain = 16 / 16 = 1.0
pruning-in-iteration extra time: 0.0001373291015625
Tensors transferred: lA=0.8463M alpha=0.0654M beta=0.0001M
This batch time : update_bounds func: 2.0068	 prepare: 0.0056	 bound: 1.9977	 transfer: 0.0024	 finalize: 0.0011
Accumulated time: update_bounds func: 2.0068	 prepare: 0.0056	 bound: 1.9977	 transfer: 0.0024	 finalize: 0.0011
batch bounding time:  2.0068860054016113
length of domains: 0
Total time: 2.5364	 pickout: 0.0023	 decision: 0.5217	 get_bound: 2.0107	 add_domain: 0.0017
Accumulated time:	 pickout: 0.0023	 decision: 0.5217	 get_bound: 2.0107	 add_domain: 0.0017
No domains left, verification finished!
Current (lb-rhs): 1.0000000116860974e-07
16 domains visited
Cumulative time: 2.8997812271118164

Result: safe in 21.5496 seconds
############# Summary #############
Final verified acc: 100.0% (total 1 examples)
Problem instances count: 1 , total verified (safe/unsat): 1 , total falsified (unsafe/sat): 0 , timeout: 0
mean time for ALL instances (total 1): 21.549377954859366, max time: 21.549593448638916
mean time for verified SAFE instances (total 1): 21.549593448638916, max time: 21.549593448638916
safe (total 1), index: [0]
