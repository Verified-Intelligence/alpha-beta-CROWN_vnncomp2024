Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  sparse_alpha: true
  save_adv_example: false
  precompile_jit: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
  csv_name: instances.csv
  results_file: null
  root_path: ../../vnncomp2022_benchmarks/benchmarks/cifar100_tinyimagenet_resnet
model:
  path: null
  cache_onnx_conversion: false
  onnx_quirks: null
  name: mnist_9_200
  onnx_path: null
  onnx_path_prefix: ''
  onnx_optimization_flags: merge_bn
data:
  start: 0
  end: 1
  select_instance: null
  num_outputs: 100
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR100
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: null
  vnnlib_path: null
  vnnlib_path_prefix: ''
solver:
  batch_size: 256
  no_float64_last_iter: true
  no_amp: false
  early_stop_patience: 10
  start_save_best: 2
  bound_prop_method: alpha-crown
  prune_after_crown: true
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.25
    iteration: 20
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
    full_conv_alpha: false
  beta-crown:
    min_batch_size_ratio: 0.1
    lr_alpha: 0.05
    lr_beta: 0.1
    lr_decay: 0.98
    optimizer: adam
    iteration: 5
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  multi_class:
    multi_class_method: allclass_domain
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
bab:
  initial_max_domains: 100
  max_domains: 200000
  decision_thresh: 0
  timeout: 360
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_intermediate_layers: ''
  interm_transfer: false
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 100
    batch_size_primal: 100
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    max_num: 1000000000
    fixed_cuts: false
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
    lr: 0.01
  branching:
    method: kfsb
    candidates: 7
    reduceop: max
    sb_coeff_thresh: 0.001
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      sort_domain_interval: -1
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  pgd_steps: 100
  pgd_restarts: 10
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  attack_mode: PGD
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 5000000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
  enable_mip_attack: false
  cex_path: ./test_cex.txt
debug:
  lp_test: null

Experiments at Sun Aug 21 12:01:06 2022 on diablo.cs.ucla.edu
saving results to a-b-crown_[instances]_start=0_end=1_iter=5_b=256_timeout=360_branching=kfsb-max-7_lra-init=0.25_lra=0.05_lrb=0.1_PGD=skip_cplex_cuts=False_initial_max_domains=100.npz
customized start/end sample from 0 to 1

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx onnx/CIFAR100_resnet_small.onnx
Using vnnlib vnnlib/CIFAR100_resnet_small_prop_idx_7129_sidx_1634_eps_0.0039.vnnlib
Loading onnx ../../vnncomp2022_benchmarks/benchmarks/cifar100_tinyimagenet_resnet/onnx/CIFAR100_resnet_small.onnx wih quirks {}
Onnx optimization with flag merge_bn
Found existed optimized onnx model at ../../vnncomp2022_benchmarks/benchmarks/cifar100_tinyimagenet_resnet/onnx/CIFAR100_resnet_small.onnx.optimized
ConvertModel(
  (Conv_72): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2))
  (Relu_73): ReLU(inplace=True)
  (Conv_75): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (Relu_76): ReLU(inplace=True)
  (Conv_78): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (Conv_80): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))
  (Add_81): Add()
  (Relu_82): ReLU(inplace=True)
  (Conv_84): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (Relu_85): ReLU(inplace=True)
  (Conv_87): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (Add_88): Add()
  (Relu_89): ReLU(inplace=True)
  (Conv_91): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (Relu_92): ReLU(inplace=True)
  (Conv_94): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (Conv_96): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2))
  (Add_97): Add()
  (Relu_98): ReLU(inplace=True)
  (Conv_100): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (Relu_101): ReLU(inplace=True)
  (Conv_103): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (Add_104): Add()
  (Relu_105): ReLU(inplace=True)
  (Flatten_106): Flatten()
  (Gemm_107): Linear(in_features=2048, out_features=100, bias=True)
  (Relu_108): ReLU(inplace=True)
  (Gemm_modelOutput): Linear(in_features=100, out_features=100, bias=True)
)
Precompiled vnnlib file found at ../../vnncomp2022_benchmarks/benchmarks/cifar100_tinyimagenet_resnet/vnnlib/CIFAR100_resnet_small_prop_idx_7129_sidx_1634_eps_0.0039.vnnlib.compiled
Model prediction is: tensor([[ -6.16110611,  -5.35189247,  -6.63838196,  -1.86059761,   0.11116584,
         -10.11872673,  -4.05360031,  -1.74366450,  -3.32689142,  -8.15904236,
          -7.46693563,  -5.78805780,  -3.15143609,  -5.00590134,  -4.14910078,
          -2.56400585,  -7.67670918,  -7.34021759,  -4.19427729,  -2.98574638,
         -11.50354290,  -2.86428237,  -6.95179081,  -8.57429600,  -5.86174917,
          -6.12972975,  -1.81921124,  -1.88009501,  -7.23338795,  -2.77960277,
          -6.66013479,  -2.95222259,  -4.44099236,  -2.23306108,  -2.14823103,
          -6.19033241,  -7.01506472,  -3.64295626,  -1.63159943,  -6.60959435,
          -6.24223185,  -5.34258413,  -2.82549000,  -4.65815115,  -1.93024802,
          -1.66022003,  -5.19752359,  -4.90962315,  -3.16080785,  -6.14222050,
          -1.68901002,  -1.35682666,  -4.53342772,  -9.38375664,  -6.84528923,
          -0.98658538,  -2.42015982,  -6.15781927,  -4.54610157,  -3.36491632,
          -7.45315218,  -9.82804394,  -6.81166935,  -2.71696711,  -0.80461359,
          -3.63948226,  -0.40597302,  -4.75543308,  -6.19850063,  -6.96731520,
          -5.63448668,  -6.89007616,  -1.89141941,  -5.16311264,   2.23245382,
          -3.20890164,  -7.58390331,  -2.06751800,  -2.76550269,  -1.95667255,
          -2.20863008,  -3.25515842,  -5.95652390,  -4.48778105,  -7.88440990,
          -3.25094366,  -6.59201813,  -7.73082256,  -5.21276379,  -2.16033602,
          -1.06771100,  -5.50464869,  -5.21620941,  -3.12952518,  -9.58456707,
          -7.41099882,  -4.63919449,  -2.05928230,  -6.47336006,  -2.76289630]],
       device='cuda:0')
layer /54 using sparse-features alpha with shape [553]; unstable size 553; total size 14400 (torch.Size([1, 64, 15, 15]))
layer /54 start_node /input.4 using sparse-spec alpha with unstable size 82 total_size 128 output_shape 128
layer /54 start_node /59 using sparse-spec alpha with unstable size 106 total_size 128 output_shape 128
layer /54 start_node /input.12 using sparse-spec alpha with unstable size 15 total_size 128 output_shape 128
layer /54 start_node /64 using sparse-spec alpha with unstable size 91 total_size 128 output_shape 128
layer /54 start_node /input.20 using sparse-spec alpha with unstable size 108 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /54 start_node /70 using sparse-spec alpha with unstable size 316 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /54 start_node /75 using sparse-spec alpha with unstable size 150 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /54 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /54 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /56 using sparse-features alpha with shape [217]; unstable size 217; total size 8192 (torch.Size([1, 128, 8, 8]))
layer /56 start_node /59 using sparse-spec alpha with unstable size 106 total_size 128 output_shape 128
layer /56 start_node /input.12 using sparse-spec alpha with unstable size 15 total_size 128 output_shape 128
layer /56 start_node /64 using sparse-spec alpha with unstable size 91 total_size 128 output_shape 128
layer /56 start_node /input.20 using sparse-spec alpha with unstable size 108 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /56 start_node /70 using sparse-spec alpha with unstable size 316 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /56 start_node /75 using sparse-spec alpha with unstable size 150 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /56 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /56 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /input.8 using sparse-features alpha with shape [408]; unstable size 408; total size 8192 (torch.Size([1, 128, 8, 8]))
layer /input.8 start_node /input.12 using sparse-spec alpha with unstable size 15 total_size 128 output_shape 128
layer /input.8 start_node /64 using sparse-spec alpha with unstable size 91 total_size 128 output_shape 128
layer /input.8 start_node /input.20 using sparse-spec alpha with unstable size 59 total_size 128 output_shape 128
layer /input.8 start_node /70 using sparse-spec alpha with unstable size 316 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /input.8 start_node /75 using sparse-spec alpha with unstable size 150 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /input.8 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /input.8 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /62 using sparse-features alpha with shape [43]; unstable size 43; total size 8192 (torch.Size([1, 128, 8, 8]))
layer /62 start_node /64 using sparse-spec alpha with unstable size 91 total_size 128 output_shape 128
layer /62 start_node /input.20 using sparse-spec alpha with unstable size 59 total_size 128 output_shape 128
layer /62 start_node /70 using sparse-spec alpha with unstable size 316 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /62 start_node /75 using sparse-spec alpha with unstable size 150 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /62 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /62 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /input.16 using sparse-features alpha with shape [337]; unstable size 337; total size 8192 (torch.Size([1, 128, 8, 8]))
layer /input.16 start_node /input.20 using sparse-spec alpha with unstable size 59 total_size 128 output_shape 128
layer /input.16 start_node /70 using sparse-spec alpha with unstable size 100 total_size 128 output_shape 128
layer /input.16 start_node /75 using sparse-spec alpha with unstable size 150 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /input.16 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /input.16 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /67 using sparse-features alpha with shape [108]; unstable size 108; total size 2048 (torch.Size([1, 128, 4, 4]))
layer /67 start_node /70 using sparse-spec alpha with unstable size 100 total_size 128 output_shape 128
layer /67 start_node /75 using sparse-spec alpha with unstable size 150 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /67 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /67 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /input.24 using sparse-features alpha with shape [316]; unstable size 316; total size 2048 (torch.Size([1, 128, 4, 4]))
layer /input.24 start_node /75 using sparse-spec alpha with unstable size 150 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /input.24 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /input.24 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /73 using sparse-features alpha with shape [0]; unstable size 0; total size 2048 (torch.Size([1, 128, 4, 4]))
layer /73 start_node /75 using sparse-spec alpha with unstable size 53 total_size 128 output_shape 128
layer /73 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /73 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /76 using sparse-features alpha with shape [150]; unstable size 150; total size 2048 (torch.Size([1, 128, 4, 4]))
layer /76 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /76 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /79 using sparse-features alpha with shape [12]; unstable size 12; total size 100 (torch.Size([1, 100]))
layer /79 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
Optimizable variables initialized.
initial CROWN bounds: tensor([[ 4.58201599,  4.65631104,  5.54419279,  1.16658831, -0.02561635,
          8.95760441,  2.92082739,  1.14079499,  1.54260159,  6.60651445,
          6.72118473,  4.72295523,  1.85433435,  3.96015120,  3.29507780,
          1.82076168,  6.14002752,  5.73220205,  3.15422893,  1.95755792,
          9.82365227,  1.88867235,  5.52393532,  7.77056026,  5.11357498,
          5.20151806,  1.33261919,  1.49767280,  6.21567631,  1.55252814,
          5.87450981,  1.85210681,  3.75290585,  0.78319836,  1.26455235,
          4.88834286,  6.21213055,  2.83589935,  1.20469117,  4.86897802,
          4.78672504,  3.89892817,  1.78502131,  3.59130073,  1.30915284,
          1.02204609,  4.03141737,  2.62421036,  1.27290440,  5.27491570,
          2.30410361,  0.47220731,  2.56467056,  7.35462856,  5.69668293,
          0.80267644,  0.71510744,  4.70079041,  3.13846779,  1.79706669,
          5.98687744,  8.38723850,  5.69914913,  2.59605742,  0.47852135,
          3.19327736, -0.67651486,  4.54048729,  4.93768597,  5.61079311,
          3.82027245,  6.05506516,  1.46648288,  4.81223869,  2.09049654,
          6.37115574,  1.13275540,  1.83720100,  0.85678673,  1.74134672,
          2.26106882,  4.88197899,  3.27520370,  6.57559776,  2.21175861,
          4.97303963,  6.46450424,  4.21740961,  0.68550730,  0.35515738,
          4.71084213,  4.08793831,  2.73747706,  7.69276810,  6.60700655,
          2.63158751,  1.51131105,  5.10305214,  2.18639207]], device='cuda:0') None
prune_after_crown optimization in use: original label size = 99 pruned label size = 2
best_l after optimization: 0.4482887387275696 with beta sum per layer: []
alpha/beta optimization time: 11.874351978302002
initial alpha-CROWN bounds: tensor([[ 0.01000000,  0.01000000,  0.01000000,  0.01000000,  0.44896847,
          0.01000000,  0.01000000,  0.01000000,  0.01000000,  0.01000000,
          0.01000000,  0.01000000,  0.01000000,  0.01000000,  0.01000000,
          0.01000000,  0.01000000,  0.01000000,  0.01000000,  0.01000000,
          0.01000000,  0.01000000,  0.01000000,  0.01000000,  0.01000000,
          0.01000000,  0.01000000,  0.01000000,  0.01000000,  0.01000000,
          0.01000000,  0.01000000,  0.01000000,  0.01000000,  0.01000000,
          0.01000000,  0.01000000,  0.01000000,  0.01000000,  0.01000000,
          0.01000000,  0.01000000,  0.01000000,  0.01000000,  0.01000000,
          0.01000000,  0.01000000,  0.01000000,  0.01000000,  0.01000000,
          0.01000000,  0.01000000,  0.01000000,  0.01000000,  0.01000000,
          0.01000000,  0.01000000,  0.01000000,  0.01000000,  0.01000000,
          0.01000000,  0.01000000,  0.01000000,  0.01000000,  0.01000000,
          0.01000000, -0.00067973,  0.01000000,  0.01000000,  0.01000000,
          0.01000000,  0.01000000,  0.01000000,  0.01000000,  0.01000000,
          0.01000000,  0.01000000,  0.01000000,  0.01000000,  0.01000000,
          0.01000000,  0.01000000,  0.01000000,  0.01000000,  0.01000000,
          0.01000000,  0.01000000,  0.01000000,  0.01000000,  0.01000000,
          0.01000000,  0.01000000,  0.01000000,  0.01000000,  0.01000000,
          0.01000000,  0.01000000,  0.01000000,  0.01000000]], device='cuda:0')
Worst class: (+ rhs) -0.0006797313690185547
  prune after CROWN overhead: 0.0019431114196777344 s
Total VNNLIB file length: 99, max property batch size: 100, total number of batches: 1
lA shape: [torch.Size([1, 99, 64, 15, 15]), torch.Size([1, 99, 128, 8, 8]), torch.Size([1, 99, 128, 8, 8]), torch.Size([1, 99, 128, 8, 8]), torch.Size([1, 99, 128, 8, 8]), torch.Size([1, 99, 128, 4, 4]), torch.Size([1, 99, 128, 4, 4]), torch.Size([1, 99, 128, 4, 4]), torch.Size([1, 99, 128, 4, 4]), torch.Size([1, 99, 100])]

Properties batch 0, size 99
Remaining timeout: 221.97548651695251
##### [0] Spec matrix: [[[-1.  0.  0. ...  0.  0.  0.]]

 [[ 0. -1.  0. ...  0.  0.  0.]]

 [[ 0.  0. -1. ...  0.  0.  0.]]

 ...

 [[ 0.  0.  0. ... -1.  0.  0.]]

 [[ 0.  0.  0. ...  0. -1.  0.]]

 [[ 0.  0.  0. ...  0.  0. -1.]]], thresh: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0.] ######
Init opt crown verified for spec index [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 67 68 69 70 71 72
 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96
 97 98] with bound tensor([[0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.44896847],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000],
        [0.01000000]], device='cuda:0').
Remaining spec index [66] with bounds tensor([[-0.00067973]], device='cuda:0') need to verify.
Model prediction is: tensor([ -6.16110611,  -5.35189247,  -6.63838196,  -1.86059761,   0.11116584,
        -10.11872673,  -4.05360031,  -1.74366450,  -3.32689142,  -8.15904236,
         -7.46693563,  -5.78805780,  -3.15143609,  -5.00590134,  -4.14910078,
         -2.56400585,  -7.67670918,  -7.34021759,  -4.19427729,  -2.98574638,
        -11.50354290,  -2.86428237,  -6.95179081,  -8.57429600,  -5.86174917,
         -6.12972975,  -1.81921124,  -1.88009501,  -7.23338795,  -2.77960277,
         -6.66013479,  -2.95222259,  -4.44099236,  -2.23306108,  -2.14823103,
         -6.19033241,  -7.01506472,  -3.64295626,  -1.63159943,  -6.60959435,
         -6.24223185,  -5.34258413,  -2.82549000,  -4.65815115,  -1.93024802,
         -1.66022003,  -5.19752359,  -4.90962315,  -3.16080785,  -6.14222050,
         -1.68901002,  -1.35682666,  -4.53342772,  -9.38375664,  -6.84528923,
         -0.98658538,  -2.42015982,  -6.15781927,  -4.54610157,  -3.36491632,
         -7.45315218,  -9.82804394,  -6.81166935,  -2.71696711,  -0.80461359,
         -3.63948226,  -0.40597302,  -4.75543308,  -6.19850063,  -6.96731520,
         -5.63448668,  -6.89007616,  -1.89141941,  -5.16311264,   2.23245382,
         -3.20890164,  -7.58390331,  -2.06751800,  -2.76550269,  -1.95667255,
         -2.20863008,  -3.25515842,  -5.95652390,  -4.48778105,  -7.88440990,
         -3.25094366,  -6.59201813,  -7.73082256,  -5.21276379,  -2.16033602,
         -1.06771100,  -5.50464869,  -5.21620941,  -3.12952518,  -9.58456707,
         -7.41099882,  -4.63919449,  -2.05928230,  -6.47336006,  -2.76289630],
       device='cuda:0')
build_the_model_with_refined_bounds batch [0/1]
setting alpha for layer /54 start_node /80 with alignment adjustment
setting alpha for layer /56 start_node /80 with alignment adjustment
setting alpha for layer /input.8 start_node /80 with alignment adjustment
setting alpha for layer /62 start_node /80 with alignment adjustment
setting alpha for layer /input.16 start_node /80 with alignment adjustment
setting alpha for layer /67 start_node /80 with alignment adjustment
setting alpha for layer /input.24 start_node /80 with alignment adjustment
setting alpha for layer /73 start_node /80 with alignment adjustment
setting alpha for layer /76 start_node /80 with alignment adjustment
setting alpha for layer /79 start_node /80 with alignment adjustment
all slope initialized
directly get lb and ub from refined bounds
lA shapes: [torch.Size([1, 1, 64, 15, 15]), torch.Size([1, 1, 128, 8, 8]), torch.Size([1, 1, 128, 8, 8]), torch.Size([1, 1, 128, 8, 8]), torch.Size([1, 1, 128, 8, 8]), torch.Size([1, 1, 128, 4, 4]), torch.Size([1, 1, 128, 4, 4]), torch.Size([1, 1, 128, 4, 4]), torch.Size([1, 1, 128, 4, 4]), torch.Size([1, 1, 100])]/home/zhouxingshi/onnx2pytorch/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  "Using experimental implementation that allows 'batch_size > 1'."
/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/abcrown.py:94: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_new.cpp:210.)
  arguments.Config["bab"]["decision_thresh"] = torch.tensor([item[1] for item in vnnlib[1]]).to(data)
/home/zhouxingshi/onnx2pytorch/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/zhouxingshi/onnx2pytorch/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/batch_branch_and_bound.py:567: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  decision_thresh = torch.tensor(decision_thresh, dtype=torch.get_default_dtype(), device=x.device)

c shape: torch.Size([1, 1, 100])
alpha-CROWN with fixed intermediate bounds: tensor([[-0.00067973]], device='cuda:0') tensor([[inf]], device='cuda:0')
Keeping slopes for these layers: ['/80']
Keeping slopes for these layers: ['/80']
layer 0 size torch.Size([14400]) unstable 553
layer 1 size torch.Size([8192]) unstable 212
layer 2 size torch.Size([8192]) unstable 396
layer 3 size torch.Size([8192]) unstable 41
layer 4 size torch.Size([8192]) unstable 325
layer 5 size torch.Size([2048]) unstable 101
layer 6 size torch.Size([2048]) unstable 300
layer 7 size torch.Size([2048]) unstable 0
layer 8 size torch.Size([2048]) unstable 143
layer 9 size torch.Size([100]) unstable 9
-----------------
# of unstable neurons: 2080
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 64, 15, 15]) pre split depth:  4
batch:  torch.Size([1, 64, 15, 15]) post split depth:  4
splitting decisions: 
split level 0: [9, 71] 
split level 1: [9, 49] 
split level 2: [6, 1466] 
split level 3: [9, 43] 
regular batch size: 2*8, diving batch size 1*0
(16, 3, 32, 32) torch.Size([16, 1, 100]) torch.Size([16, 1])

all verified at 0th iter
pruning_in_iteration open status: False
ratio of positive domain = 16 / 16 = 1.0
pruning-in-iteration extra time: 0.0001354217529296875
Tensors transferred: lA=0.8463M alpha=0.0654M beta=0.0001M
This batch time : update_bounds func: 0.0432	 prepare: 0.0076	 bound: 0.0306	 transfer: 0.0032	 finalize: 0.0017
Accumulated time: update_bounds func: 0.0432	 prepare: 0.0076	 bound: 0.0306	 transfer: 0.0032	 finalize: 0.0017
batch bounding time:  0.04320406913757324
length of domains: 0
Total time: 0.5992	 pickout: 0.0029	 decision: 0.5447	 get_bound: 0.0493	 add_domain: 0.0023
Accumulated time:	 pickout: 0.0029	 decision: 0.5447	 get_bound: 0.0493	 add_domain: 0.0023
No domains left, verification finished!
16 domains visited
Cumulative time: 0.9471635818481445

Result: safe in 19.5262 seconds
############# Summary #############
Final verified acc: 100.0% [total 1 examples]
Total verification count: 1 , total verified safe: 1 , verified unsafe: 0 , timeout: 0
mean time (bab) [total:1]: 1.6867027282714844
mean time [1] 19.526187896728516 max time 19.526187896728516
safe (total 1): [0]
