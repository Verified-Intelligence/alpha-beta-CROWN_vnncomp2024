Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: matrix
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  sparse_alpha: true
  save_adv_example: false
  precompile_jit: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: false
  get_crown_verified_acc: false
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2022_benchmarks/benchmarks/reach_prob_density/
model:
  path: null
  cache_onnx_conversion: false
  onnx_quirks: null
  name: mnist_9_200
  onnx_path: null
  onnx_path_prefix: ''
  onnx_optimization_flags: none
data:
  start: 24
  end: 25
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: Reach_probability
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: null
  vnnlib_path: null
  vnnlib_path_prefix: ''
solver:
  batch_size: 8192
  no_float64_last_iter: true
  no_amp: false
  early_stop_patience: 10
  start_save_best: 2
  bound_prop_method: alpha-crown
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
    full_conv_alpha: true
  beta-crown:
    min_batch_size_ratio: 0.1
    lr_alpha: 0.03
    lr_beta: 0.08
    lr_decay: 0.98
    optimizer: adam
    iteration: 100
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: true
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  multi_class:
    multi_class_method: allclass_domain
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 360
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_intermediate_layers: ''
  interm_transfer: true
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 100
    batch_size_primal: 100
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    max_num: 1000000000
    fixed_cuts: false
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
    lr: 0.01
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    sb_coeff_thresh: 0.001
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      sort_domain_interval: -1
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  attack_mode: PGD
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 5000000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
  enable_mip_attack: false
  cex_path: ./test_cex.txt
debug:
  lp_test: null

Experiments at Wed Aug 31 20:35:10 2022 on diablo.cs.ucla.edu
customized start/end sample from instance 24 to 25 in instances.csv
Internal results will be saved to a-b-crown_[instances]_start=24_end=25_iter=100_b=8192_timeout=360_branching=kfsb-min-3_lra-init=0.1_lra=0.03_lrb=0.08_PGD=before_cplex_cuts=False_initial_max_domains=1.npz.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 24 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx onnx/gcas.onnx
Using vnnlib vnnlib/gcas_0.vnnlib
Precompiled vnnlib file found at ../../vnncomp2022_benchmarks/benchmarks/reach_prob_density/vnnlib/gcas_0.vnnlib.compiled
Loading onnx ../../vnncomp2022_benchmarks/benchmarks/reach_prob_density/onnx/gcas.onnx wih quirks {}
Attack parameters: initialization=uniform, steps=100, restarts=30, alpha=1.3775911331176758, initialization=uniform, GAMA=False
model output: tensor([[ 0.26075032, -1.08884692,  1.12172675, -0.22521567, -1.14484394,
          1.19883776, -0.27130181, -0.21050687,  0.01739992, -0.62590063,
          0.45852482,  0.02647725,  0.81512761,  0.38268733]], device='cuda:0')
pgd prediction: tensor([[[ 0.28521582,  0.51084501,  0.10578465,  0.81158602,  0.46152946,
           1.26159692,  1.16192412, -0.40004733,  0.37031466,  0.04168780,
           1.66077614,  1.31724882, -1.82105517,  0.91413283]]],
       device='cuda:0')
pgd attack margin tensor([[[ 0.46275616, -0.28521582]]], device='cuda:0')
number of violation:  1
Attack finished in 1.1135 seconds.
pgd attack failed
Total VNNLIB file length: 1, max property batch size: 1, total number of batches: 1

Properties batch 0, size 1
Remaining timeout: 596.8110599517822
##### Instance 0 first 10 spec matrices: [[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]
  [-1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]]
thresholds: [-2.2838114  0.       ] ######
Model prediction is: tensor([ 0.26075032, -1.08884692,  1.12172675, -0.22521567, -1.14484394,
         1.19883776, -0.27130181, -0.21050687,  0.01739992, -0.62590063,
         0.45852482,  0.02647725,  0.81512761,  0.38268733], device='cuda:0')
layer /14 using full alpha with shape torch.Size([32]); unstable size 32; total size 32 (torch.Size([1, 32]))
layer /14 start_node /input.3 using full alpha with unstable size 32 total_size 32 output_shape torch.Size([32])
layer /14 start_node /17 using full alpha with unstable size None total_size 2 output_shape 2
layer /16 using full alpha with shape torch.Size([32]); unstable size 32; total size 32 (torch.Size([1, 32]))
layer /16 start_node /17 using full alpha with unstable size None total_size 2 output_shape 2
Optimizable variables initialized.
initial CROWN bounds: tensor([[-11.02604103,  -0.63487166]], device='cuda:0') None
best_l after optimization: -8.434370994567871 with beta sum per layer: []
alpha/beta optimization time: 2.625373125076294
initial alpha-CROWN bounds: tensor([[-7.94828224, -0.48608840]], device='cuda:0')
Worst class: (+ rhs) -7.948282241821289
preset mip_multi_proc as default setting: 40
Set parameter Username
Academic license - for non-commercial use only - expires 2023-08-09
mip_multi_proc: 40, mip_threads: 1, total threads used: 40
lp solver model built in 0.0253 seconds.
Keeping slopes for these layers: ['/17']
layer 0 size torch.Size([32]) unstable 32
layer 1 size torch.Size([32]) unstable 32
-----------------
# of unstable neurons: 64
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32]) pre split depth:  9
batch:  torch.Size([1, 32]) post split depth:  9
splitting decisions: 
split level 0: [1, 30] 
split level 1: [1, 1] 
split level 2: [1, 21] 
split level 3: [1, 27] 
split level 4: [1, 5] 
split level 5: [1, 6] 
split level 6: [1, 15] 
split level 7: [1, 8] 
split level 8: [1, 14] 
regular batch size: 2*256, diving batch size 1*0
(512, 14) torch.Size([512, 2, 14]) torch.Size([512, 2])
best_l after optimization: -1431.2998046875 with beta sum per layer: [0.0, 4.930501937866211]
alpha/beta optimization time: 0.863760232925415
pruning_in_iteration open status: True
ratio of positive domain = 221 / 512 = 0.431640625
pruning-in-iteration extra time: 0.06877565383911133
Tensors transferred: pre=0.0625M lA=0.0355M alpha=0.1250M beta=0.0044M
This batch time : update_bounds func: 0.9124	 prepare: 0.0353	 bound: 0.8642	 transfer: 0.0010	 finalize: 0.0109
Accumulated time: update_bounds func: 0.9124	 prepare: 0.0353	 bound: 0.8642	 transfer: 0.0010	 finalize: 0.0109
batch bounding time:  0.9125845432281494
Current worst splitting domains lb-rhs (depth):
-0.48293 (9), -0.47967 (9), -0.47776 (9), -0.47411 (9), -0.47384 (9), -0.47310 (9), -0.47171 (9), -0.47135 (9), -0.47129 (9), -0.47127 (9), -0.47123 (9), -0.47089 (9), -0.47079 (9), -0.47075 (9), -0.47069 (9), -0.47043 (9), -0.47038 (9), -0.47038 (9), -0.47031 (9), -0.47023 (9), 
length of domains: 291
Total time: 1.0694	 pickout: 0.0009	 decision: 0.0433	 get_bound: 0.9823	 add_domain: 0.0429
Accumulated time:	 pickout: 0.0009	 decision: 0.0433	 get_bound: 0.9823	 add_domain: 0.0429
Current (lb-rhs): -0.48293036222457886
221 domains visited
Cumulative time: 4.381744861602783

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([291, 32]) pre split depth:  1
batch:  torch.Size([291, 32]) post split depth:  1
splitting decisions: 
split level 0: [0, 26] [1, 3] [0, 26] [1, 3] [0, 9] [1, 3] [1, 22] [1, 3] [0, 26] [1, 3] 
regular batch size: 2*291, diving batch size 1*0
(582, 14) torch.Size([582, 2, 14]) torch.Size([582, 2])
best_l after optimization: -1565.27734375 with beta sum per layer: [1.2594314813613892, 11.342514038085938]
alpha/beta optimization time: 0.8982553482055664
pruning_in_iteration open status: True
ratio of positive domain = 295 / 582 = 0.506872852233677
pruning-in-iteration extra time: 0.07020330429077148
Tensors transferred: pre=0.0710M lA=0.0350M alpha=0.1421M beta=0.0061M
This batch time : update_bounds func: 0.9608	 prepare: 0.0474	 bound: 0.8988	 transfer: 0.0012	 finalize: 0.0125
Accumulated time: update_bounds func: 1.8732	 prepare: 0.0827	 bound: 1.7630	 transfer: 0.0022	 finalize: 0.0234
batch bounding time:  0.9608523845672607
Current worst splitting domains lb-rhs (depth):
-0.48293 (10), -0.47171 (10), -0.46985 (10), -0.46915 (10), -0.46915 (10), -0.46862 (10), -0.46849 (10), -0.46802 (10), -0.46775 (10), -0.46762 (10), -0.46733 (10), -0.46729 (10), -0.46724 (10), -0.46718 (10), -0.46707 (10), -0.46705 (10), -0.46694 (10), -0.46688 (10), -0.46673 (10), -0.46669 (10), 
length of domains: 287
Total time: 1.0743	 pickout: 0.0022	 decision: 0.0657	 get_bound: 0.9609	 add_domain: 0.0454
Accumulated time:	 pickout: 0.0032	 decision: 0.1091	 get_bound: 1.9432	 add_domain: 0.0883
Current (lb-rhs): -0.48293036222457886
516 domains visited
Cumulative time: 5.457305192947388

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([287, 32]) pre split depth:  1
batch:  torch.Size([287, 32]) post split depth:  1
splitting decisions: 
split level 0: [1, 3] [0, 9] [1, 3] [0, 9] [1, 22] [1, 3] [1, 22] [0, 26] [1, 3] [1, 3] 
regular batch size: 2*287, diving batch size 1*0
(574, 14) torch.Size([574, 2, 14]) torch.Size([574, 2])
best_l after optimization: -1519.96630859375 with beta sum per layer: [4.113089561462402, 12.872438430786133]
alpha/beta optimization time: 0.8960034847259521
pruning_in_iteration open status: True
ratio of positive domain = 302 / 574 = 0.5261324041811847
pruning-in-iteration extra time: 0.07016515731811523
Tensors transferred: pre=0.0701M lA=0.0332M alpha=0.1401M beta=0.0071M
This batch time : update_bounds func: 0.9584	 prepare: 0.0472	 bound: 0.8966	 transfer: 0.0010	 finalize: 0.0127
Accumulated time: update_bounds func: 2.8316	 prepare: 0.1299	 bound: 2.6596	 transfer: 0.0032	 finalize: 0.0361
batch bounding time:  0.9584708213806152
Current worst splitting domains lb-rhs (depth):
-0.46733 (11), -0.46718 (11), -0.46718 (11), -0.46688 (11), -0.46683 (11), -0.46669 (11), -0.46665 (11), -0.46656 (11), -0.46640 (11), -0.46572 (11), -0.46572 (11), -0.46559 (11), -0.46524 (11), -0.46513 (11), -0.46507 (11), -0.46505 (11), -0.46503 (11), -0.46495 (11), -0.46495 (11), -0.46487 (11), 
length of domains: 272
Total time: 1.0699	 pickout: 0.0019	 decision: 0.0648	 get_bound: 0.9585	 add_domain: 0.0447
Accumulated time:	 pickout: 0.0051	 decision: 0.1739	 get_bound: 2.9017	 add_domain: 0.1329
Current (lb-rhs): -0.4673321843147278
818 domains visited
Cumulative time: 6.528448581695557

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([272, 32]) pre split depth:  1
batch:  torch.Size([272, 32]) post split depth:  1
splitting decisions: 
split level 0: [1, 22] [1, 12] [1, 22] [1, 12] [1, 12] [0, 31] [1, 3] [1, 12] [1, 12] [1, 12] 
regular batch size: 2*272, diving batch size 1*0
(544, 14) torch.Size([544, 2, 14]) torch.Size([544, 2])
best_l after optimization: -1411.1923828125 with beta sum per layer: [5.311153411865234, 16.635644912719727]
alpha/beta optimization time: 0.8973150253295898
pruning_in_iteration open status: True
ratio of positive domain = 289 / 544 = 0.53125
pruning-in-iteration extra time: 0.07008719444274902
Tensors transferred: pre=0.0664M lA=0.0311M alpha=0.1328M beta=0.0078M
This batch time : update_bounds func: 0.9567	 prepare: 0.0447	 bound: 0.8978	 transfer: 0.0010	 finalize: 0.0124
Accumulated time: update_bounds func: 3.7883	 prepare: 0.1746	 bound: 3.5574	 transfer: 0.0042	 finalize: 0.0485
batch bounding time:  0.9567227363586426
Current worst splitting domains lb-rhs (depth):
-0.46688 (12), -0.46572 (12), -0.46572 (12), -0.46559 (12), -0.46513 (12), -0.46487 (12), -0.46487 (12), -0.46476 (12), -0.46451 (12), -0.46450 (12), -0.46422 (12), -0.46416 (12), -0.46385 (12), -0.46370 (12), -0.46359 (12), -0.46352 (12), -0.46333 (12), -0.46321 (12), -0.46320 (12), -0.46320 (12), 
length of domains: 255
Total time: 1.0629	 pickout: 0.0018	 decision: 0.0617	 get_bound: 0.9568	 add_domain: 0.0426
Accumulated time:	 pickout: 0.0069	 decision: 0.2356	 get_bound: 3.8585	 add_domain: 0.1755
Current (lb-rhs): -0.4668836295604706
1107 domains visited
Cumulative time: 7.592399597167969

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([255, 32]) pre split depth:  1
batch:  torch.Size([255, 32]) post split depth:  1
splitting decisions: 
split level 0: [0, 31] [0, 9] [1, 12] [1, 22] [0, 31] [1, 12] [1, 12] [1, 12] [0, 31] [1, 12] 
regular batch size: 2*255, diving batch size 1*0
(510, 14) torch.Size([510, 2, 14]) torch.Size([510, 2])
best_l after optimization: -1233.8509521484375 with beta sum per layer: [7.022912979125977, 17.92418670654297]
alpha/beta optimization time: 0.8993730545043945
pruning_in_iteration open status: True
ratio of positive domain = 340 / 510 = 0.6666666666666667
pruning-in-iteration extra time: 0.06972026824951172
Tensors transferred: pre=0.0623M lA=0.0208M alpha=0.1245M beta=0.0083M
This batch time : update_bounds func: 1.0185	 prepare: 0.0431	 bound: 0.8999	 transfer: 0.0010	 finalize: 0.0117
Accumulated time: update_bounds func: 4.8067	 prepare: 0.2177	 bound: 4.4573	 transfer: 0.0052	 finalize: 0.0602
batch bounding time:  1.0185205936431885
Current worst splitting domains lb-rhs (depth):
-0.46487 (13), -0.46487 (13), -0.46476 (13), -0.46385 (13), -0.46317 (13), -0.46317 (13), -0.46269 (13), -0.46219 (13), -0.46090 (13), -0.46090 (13)/home/zhouxingshi/onnx2pytorch/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)
  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))
/home/zhouxingshi/onnx2pytorch/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  "Using experimental implementation that allows 'batch_size > 1'."
, -0.46090 (13), -0.46090 (13), -0.46090 (13), -0.46003 (13), -0.45997 (13), -0.45997 (13), -0.45910 (13), -0.45905 (13), -0.45881 (13), -0.45845 (13), 
length of domains: 170
Total time: 1.1167	 pickout: 0.0018	 decision: 0.0588	 get_bound: 1.0186	 add_domain: 0.0376
Accumulated time:	 pickout: 0.0087	 decision: 0.2944	 get_bound: 4.8771	 add_domain: 0.2131
Current (lb-rhs): -0.46486711502075195
1447 domains visited
Cumulative time: 8.710336446762085

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([170, 32]) pre split depth:  2
batch:  torch.Size([170, 32]) post split depth:  2
splitting decisions: 
split level 0: [0, 9] [1, 12] [0, 9] [0, 9] [0, 9] [0, 0] [1, 22] [1, 12] [0, 31] [0, 9] 
split level 1: [1, 12] [0, 31] [1, 11] [1, 12] [0, 31] [0, 31] [0, 1] [0, 8] [1, 12] [1, 12] 
regular batch size: 2*340, diving batch size 1*0
(680, 14) torch.Size([680, 2, 14]) torch.Size([680, 2])
best_l after optimization: -1350.846923828125 with beta sum per layer: [19.257110595703125, 19.27409553527832]
alpha/beta optimization time: 0.893606424331665
pruning_in_iteration open status: True
ratio of positive domain = 582 / 680 = 0.8558823529411765
pruning-in-iteration extra time: 0.0699012279510498
Tensors transferred: pre=0.0830M lA=0.0120M alpha=0.1660M beta=0.0117M
This batch time : update_bounds func: 0.9697	 prepare: 0.0578	 bound: 0.8942	 transfer: 0.0012	 finalize: 0.0153
Accumulated time: update_bounds func: 5.7764	 prepare: 0.2755	 bound: 5.3515	 transfer: 0.0064	 finalize: 0.0756
batch bounding time:  0.9697587490081787
Current worst splitting domains lb-rhs (depth):
-0.45845 (15), -0.45520 (15), -0.44939 (15), -0.44850 (15), -0.44657 (15), -0.42018 (15), -0.40441 (15), -0.38244 (15), -0.36674 (15), -0.36579 (15), -0.34971 (15), -0.34941 (15), -0.34935 (15), -0.34929 (15), -0.34849 (15), -0.34847 (15), -0.34841 (15), -0.34834 (15), -0.34821 (15), -0.34766 (15), 
length of domains: 98
Total time: 1.1300	 pickout: 0.0016	 decision: 0.0633	 get_bound: 1.0202	 add_domain: 0.0449
Accumulated time:	 pickout: 0.0103	 decision: 0.3577	 get_bound: 5.8973	 add_domain: 0.2579
Current (lb-rhs): -0.4584459364414215
2029 domains visited
Cumulative time: 9.841540575027466

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([98, 32]) pre split depth:  3
batch:  torch.Size([98, 32]) post split depth:  3
splitting decisions: 
split level 0: [0, 9] [0, 0] [0, 18] [0, 22] [1, 12] [1, 12] [0, 9] [0, 21] [0, 21] [0, 22] 
split level 1: [0, 1] [0, 9] [1, 22] [0, 9] [0, 21] [0, 9] [1, 11] [0, 31] [0, 1] [1, 11] 
split level 2: [1, 12] [1, 12] [0, 10] [1, 12] [1, 11] [1, 11] [0, 22] [1, 11] [1, 12] [1, 23] 
regular batch size: 2*392, diving batch size 1*0
(784, 14) torch.Size([784, 2, 14]) torch.Size([784, 2])
best_l after optimization: -1283.17041015625 with beta sum per layer: [74.03067016601562, 32.135704040527344]
alpha/beta optimization time: 0.8960094451904297
pruning_in_iteration open status: True
ratio of positive domain = 746 / 784 = 0.951530612244898
pruning-in-iteration extra time: 0.07028532028198242
Tensors transferred: pre=0.0957M lA=0.0046M alpha=0.1914M beta=0.0164M
This batch time : update_bounds func: 0.9821	 prepare: 0.0648	 bound: 0.8965	 transfer: 0.0011	 finalize: 0.0183
Accumulated time: update_bounds func: 6.7585	 prepare: 0.3403	 bound: 6.2480	 transfer: 0.0075	 finalize: 0.0938
batch bounding time:  0.9821426868438721
Current worst splitting domains lb-rhs (depth):
-0.34458 (18), -0.32812 (18), -0.27082 (18), -0.23934 (18), -0.20988 (18), -0.18654 (18), -0.16271 (18), -0.14587 (18), -0.14132 (18), -0.13609 (18), -0.12834 (18), -0.12173 (18), -0.12164 (18), -0.11426 (18), -0.11377 (18), -0.11304 (18), -0.10469 (18), -0.10085 (18), -0.09621 (18), -0.09413 (18), 
length of domains: 38
Total time: 1.1719	 pickout: 0.0012	 decision: 0.0535	 get_bound: 1.0698	 add_domain: 0.0473
Accumulated time:	 pickout: 0.0115	 decision: 0.4112	 get_bound: 6.9671	 add_domain: 0.3052
Current (lb-rhs): -0.3445799648761749
2775 domains visited
Cumulative time: 11.01450514793396

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([38, 32]) pre split depth:  4
batch:  torch.Size([38, 32]) post split depth:  4
splitting decisions: 
split level 0: [0, 10] [0, 22] [0, 13] [1, 24] [0, 25] [1, 29] [1, 24] [0, 25] [0, 13] [0, 21] 
split level 1: [0, 29] [1, 29] [1, 23] [1, 23] [1, 24] [1, 25] [1, 29] [0, 18] [0, 24] [1, 24] 
split level 2: [1, 29] [1, 23] [1, 29] [1, 29] [1, 23] [1, 23] [1, 23] [1, 23] [1, 29] [1, 23] 
split level 3: [1, 23] [0, 23] [0, 23] [0, 23] [1, 29] [1, 24] [0, 23] [0, 22] [0, 23] [1, 29] 
regular batch size: 2*304, diving batch size 1*0
(608, 14) torch.Size([608, 2, 14]) torch.Size([608, 2])
best_l after optimization: -647.000244140625 with beta sum per layer: [20.973186492919922, 12.646373748779297]
alpha/beta optimization time: 0.8855252265930176
pruning_in_iteration open status: True
ratio of positive domain = 598 / 608 = 0.9835526315789473
pruning-in-iteration extra time: 0.06933426856994629
Tensors transferred: pre=0.0742M lA=0.0012M alpha=0.1484M beta=0.0151M
This batch time : update_bounds func: 0.9524	 prepare: 0.0506	 bound: 0.8860	 transfer: 0.0010	 finalize: 0.0139
Accumulated time: update_bounds func: 7.7110	 prepare: 0.3909	 bound: 7.1340	 transfer: 0.0085	 finalize: 0.1078
batch bounding time:  0.9525003433227539
Current worst splitting domains lb-rhs (depth):
-0.14935 (22), -0.10200 (22), -0.09978 (22), -0.09883 (22), -0.06115 (22), -0.05483 (22), -0.03037 (22), -0.02708 (22), -0.01081 (22), -0.00297 (22), 
length of domains: 10
Total time: 1.1107	 pickout: 0.0010	 decision: 0.0397	 get_bound: 1.0339	 add_domain: 0.0361
Accumulated time:	 pickout: 0.0125	 decision: 0.4509	 get_bound: 8.0010	 add_domain: 0.3413
Current (lb-rhs): -0.1493515968322754
3373 domains visited
Cumulative time: 12.126001834869385

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([10, 32]) pre split depth:  6
batch:  torch.Size([10, 32]) post split depth:  6
splitting decisions: 
split level 0: [0, 21] [0, 27] [0, 21] [0, 27] [0, 21] [1, 25] [0, 10] [0, 30] [1, 25] [0, 21] 
split level 1: [1, 25] [1, 29] [0, 10] [0, 13] [1, 25] [0, 11] [0, 11] [0, 27] [0, 11] [0, 13] 
split level 2: [1, 29] [1, 24] [1, 24] [1, 29] [1, 24] [0, 24] [1, 25] [1, 25] [0, 22] [0, 22] 
split level 3: [1, 24] [0, 0] [1, 25] [1, 24] [0, 12] [0, 30] [0, 22] [0, 24] [0, 24] [0, 12] 
split level 4: [0, 18] [0, 23] [0, 11] [0, 23] [0, 18] [0, 8] [0, 25] [0, 19] [0, 8] [0, 30] 
split level 5: [1, 23] [0, 3] [0, 18] [0, 10] [0, 19] [0, 19] [0, 18] [1, 13] [0, 19] [0, 18] 
regular batch size: 2*320, diving batch size 1*0
(640, 14) torch.Size([640, 2, 14]) torch.Size([640, 2])

all verified at 25th iter
best_l after optimization: -832.9056396484375 with beta sum per layer: [0.5786409378051758, 4.717194080352783]
alpha/beta optimization time: 0.2238454818725586
pruning_in_iteration open status: True
ratio of positive domain = 640 / 640 = 1.0
pruning-in-iteration extra time: 0.01752638816833496
Tensors transferred: pre=0.0781M lA=0.0001M alpha=0.1562M beta=0.0183M
This batch time : update_bounds func: 0.2953	 prepare: 0.0539	 bound: 0.2244	 transfer: 0.0013	 finalize: 0.0145
Accumulated time: update_bounds func: 8.0063	 prepare: 0.4448	 bound: 7.3584	 transfer: 0.0098	 finalize: 0.1223
batch bounding time:  0.29540443420410156
length of domains: 0
Total time: 0.4710	 pickout: 0.0009	 decision: 0.0371	 get_bound: 0.3973	 add_domain: 0.0356
Accumulated time:	 pickout: 0.0135	 decision: 0.4880	 get_bound: 8.3984	 add_domain: 0.3769
No domains left, verification finished!
4013 domains visited
Cumulative time: 12.59789514541626

Result: safe in 15.8633 seconds
############# Summary #############
Final verified acc: 100.0% [total 1 examples]
Total verification count: 1 , total verified safe: 1 , verified unsafe: 0 , timeout: 0
mean time (bab) [total:1]: 12.674268007278442
mean time [1] 15.863268613815308 max time 15.863268613815308
safe (total 1): [0]
