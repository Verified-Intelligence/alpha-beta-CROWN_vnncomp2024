Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: matrix
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  sparse_alpha: true
  save_adv_example: false
  precompile_jit: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: false
  get_crown_verified_acc: false
  csv_name: instances.csv
  results_file: null
  root_path: ../../vnncomp2022_benchmarks/benchmarks/reach_prob_density/
model:
  path: null
  cache_onnx_conversion: false
  onnx_quirks: null
  name: mnist_9_200
  onnx_path: null
  onnx_path_prefix: ''
  onnx_optimization_flags: none
data:
  start: 24
  end: 25
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: Reach_probability
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: null
  vnnlib_path: null
  vnnlib_path_prefix: ''
solver:
  batch_size: 8192
  no_float64_last_iter: true
  no_amp: false
  early_stop_patience: 10
  start_save_best: 2
  bound_prop_method: alpha-crown
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
    full_conv_alpha: true
  beta-crown:
    min_batch_size_ratio: 0.1
    lr_alpha: 0.03
    lr_beta: 0.08
    lr_decay: 0.98
    optimizer: adam
    iteration: 100
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: true
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  multi_class:
    multi_class_method: allclass_domain
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
bab:
  initial_max_domains: 1
  max_domains: 200000
  decision_thresh: 0
  timeout: 360
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_intermediate_layers: ''
  interm_transfer: true
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 100
    batch_size_primal: 100
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    max_num: 1000000000
    fixed_cuts: false
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
    lr: 0.01
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    sb_coeff_thresh: 0.001
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      sort_domain_interval: -1
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  attack_mode: PGD
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 5000000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
  enable_mip_attack: false
  cex_path: ./test_cex.txt
debug:
  lp_test: null

Experiments at Sun Aug 21 12:07:25 2022 on diablo.cs.ucla.edu
saving results to a-b-crown_[instances]_start=24_end=25_iter=100_b=8192_timeout=360_branching=kfsb-min-3_lra-init=0.1_lra=0.03_lrb=0.08_PGD=before_cplex_cuts=False_initial_max_domains=1.npz
customized start/end sample from 24 to 25

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 24 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx onnx/gcas.onnx
Using vnnlib vnnlib/gcas_0.vnnlib
Loading onnx ../../vnncomp2022_benchmarks/benchmarks/reach_prob_density/onnx/gcas.onnx wih quirks {}
ConvertModel(
  (Gemm_7): Linear(in_features=14, out_features=32, bias=True)
  (Relu_8): ReLU(inplace=True)
  (Gemm_9): Linear(in_features=32, out_features=32, bias=True)
  (Relu_10): ReLU(inplace=True)
  (Gemm_output): Linear(in_features=32, out_features=14, bias=True)
)
14 inputs and 14 outputs in vnnlib
Attack parameters: initialization=uniform, steps=100, restarts=30, alpha=1.3775911331176758, initialization=uniform, GAMA=False
model output: tensor([[ 0.26075032, -1.08884692,  1.12172675, -0.22521567, -1.14484394,
          1.19883776, -0.27130181, -0.21050687,  0.01739992, -0.62590063,
          0.45852482,  0.02647725,  0.81512761,  0.38268733]], device='cuda:0')
pgd prediction: tensor([[[ 0.28521582,  0.51084501,  0.10578465,  0.81158602,  0.46152946,
           1.26159692,  1.16192412, -0.40004733,  0.37031466,  0.04168780,
           1.66077614,  1.31724882, -1.82105517,  0.91413283]]],
       device='cuda:0')
pgd attack margin tensor([[[ 0.46275616, -0.28521582]]], device='cuda:0')
number of violation:  1
Attack finished in 1.0596 seconds.
pgd attack failed
Total VNNLIB file length: 1, max property batch size: 1, total number of batches: 1

Properties batch 0, size 1
Remaining timeout: 596.8191339969635
##### [0] Spec matrix: [[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]
  [-1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]], thresh: [-2.2838114  0.       ] ######
Model prediction is: tensor([ 0.26075032, -1.08884692,  1.12172675, -0.22521567, -1.14484394,
         1.19883776, -0.27130181, -0.21050687,  0.01739992, -0.62590063,
         0.45852482,  0.02647725,  0.81512761,  0.38268733], device='cuda:0')
layer /14 using full alpha with shape torch.Size([32]); unstable size 32; total size 32 (torch.Size([1, 32]))
layer /14 start_node /input.3 using full alpha with unstable size 32 total_size 32 output_shape torch.Size([32])
layer /14 start_node /17 using full alpha with unstable size None total_size 2 output_shape 2
layer /16 using full alpha with shape torch.Size([32]); unstable size 32; total size 32 (torch.Size([1, 32]))
layer /16 start_node /17 using full alpha with unstable size None total_size 2 output_shape 2
Optimizable variables initialized.
initial CROWN bounds: tensor([[-11.02604103,  -0.63487166]], device='cuda:0') None
best_l after optimization: -8.434370994567871 with beta sum per layer: []
alpha/beta optimization time: 2.5098607540130615
initial alpha-CROWN bounds: tensor([[-7.94828224, -0.48608840]], device='cuda:0')
Worst class: (+ rhs) -7.948282241821289
preset mip_multi_proc as default setting: 40
Set parameter Username
Academic license - for non-commercial use only - expires 2023-08-09
mip_multi_proc: 40, mip_threads: 1, total threads used: 40
lp solver model built in 0.0218 seconds.
Keeping slopes for these layers: ['/17']
layer 0 size torch.Size([32]) unstable 32
layer 1 size torch.Size([32]) unstable 32
-----------------
# of unstable neurons: 64
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32]) pre split depth:  9
batch:  torch.Size([1, 32]) post split depth:  9
splitting decisions: 
split level 0: [1, 30] 
split level 1: [1, 1] 
split level 2: [1, 21] 
split level 3: [1, 27] 
split level 4: [1, 5] 
split level 5: [1, 6] 
split level 6: [1, 15] 
split level 7: [1, 8] 
split level 8: [1, 14] 
regular batch size: 2*256, diving batch size 1*0
(512, 14) torch.Size([512, 2, 14]) torch.Size([512, 2])
best_l after optimization: -1431.2998046875 with beta sum per layer: [0.0, 4.930501937866211]
alpha/beta optimization time: 0.771906852722168
pruning_in_iteration open status: True
ratio of positive domain = 221 / 512 = 0.431640625
pruning-in-iteration extra time: 0.05068016052246094
Tensors transferred: pre=0.0625M lA=0.0355M alpha=0.1250M beta=0.0044M
This batch time : update_bounds func: 0.8025	 prepare: 0.0219	 bound: 0.7723	 transfer: 0.0010	 finalize: 0.0063
Accumulated time: update_bounds func: 0.8025	 prepare: 0.0219	 bound: 0.7723	 transfer: 0.0010	 finalize: 0.0063
batch bounding time:  0.8025076389312744
Current worst splitting domains lb-rhs (depth):
-0.48293 (9), -0.47967 (9), -0.47776 (9), -0.47411 (9), -0.47384 (9), -0.47310 (9), -0.47171 (9), -0.47135 (9), -0.47129 (9), -0.47127 (9), -0.47123 (9), -0.47089 (9), -0.47079 (9), -0.47075 (9), -0.47069 (9), -0.47043 (9), -0.47038 (9), -0.47038 (9), -0.47031 (9), -0.47023 (9), 
length of domains: 291
Total time: 0.9140	 pickout: 0.0007	 decision: 0.0350	 get_bound: 0.8493	 add_domain: 0.0290
Accumulated time:	 pickout: 0.0007	 decision: 0.0350	 get_bound: 0.8493	 add_domain: 0.0290
Current (lb-rhs): -0.48293036222457886
221 domains visited
Cumulative time: 4.090799331665039

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([291, 32]) pre split depth:  1
batch:  torch.Size([291, 32]) post split depth:  1
splitting decisions: 
split level 0: [0, 26] [1, 3] [0, 26] [1, 3] [0, 9] [1, 3] [1, 22] [1, 3] [0, 26] [1, 3] 
regular batch size: 2*291, diving batch size 1*0
(582, 14) torch.Size([582, 2, 14]) torch.Size([582, 2])
best_l after optimization: -1565.27734375 with beta sum per layer: [1.2594314813613892, 11.342514038085938]
alpha/beta optimization time: 0.8004369735717773
pruning_in_iteration open status: True
ratio of positive domain = 295 / 582 = 0.506872852233677
pruning-in-iteration extra time: 0.0509033203125
Tensors transferred: pre=0.0710M lA=0.0350M alpha=0.1421M beta=0.0061M
This batch time : update_bounds func: 0.8393	 prepare: 0.0288	 bound: 0.8009	 transfer: 0.0010	 finalize: 0.0078
Accumulated time: update_bounds func: 1.6418	 prepare: 0.0506	 bound: 1.5732	 transfer: 0.0020	 finalize: 0.0141
batch bounding time:  0.8393690586090088
Current worst splitting domains lb-rhs (depth):
-0.48293 (10), -0.47171 (10), -0.46985 (10), -0.46915 (10), -0.46915 (10), -0.46862 (10), -0.46849 (10), -0.46802 (10), -0.46775 (10), -0.46762 (10), -0.46733 (10), -0.46729 (10), -0.46724 (10), -0.46718 (10), -0.46707 (10), -0.46705 (10), -0.46694 (10), -0.46688 (10), -0.46673 (10), -0.46669 (10), 
length of domains: 287
Total time: 0.9227	 pickout: 0.0016	 decision: 0.0503	 get_bound: 0.8394	 add_domain: 0.0314
Accumulated time:	 pickout: 0.0023	 decision: 0.0853	 get_bound: 1.6887	 add_domain: 0.0604
Current (lb-rhs): -0.48293036222457886
516 domains visited
Cumulative time: 5.014464616775513

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([287, 32]) pre split depth:  1
batch:  torch.Size([287, 32]) post split depth:  1
splitting decisions: 
split level 0: [1, 3] [0, 9] [1, 3] [0, 9] [1, 22] [1, 3] [1, 22] [0, 26] [1, 3] [1, 3] 
regular batch size: 2*287, diving batch size 1*0
(574, 14) torch.Size([574, 2, 14]) torch.Size([574, 2])
best_l after optimization: -1519.96630859375 with beta sum per layer: [4.113089561462402, 12.872438430786133]
alpha/beta optimization time: 0.801490306854248
pruning_in_iteration open status: True
ratio of positive domain = 302 / 574 = 0.5261324041811847
pruning-in-iteration extra time: 0.050881147384643555
Tensors transferred: pre=0.0701M lA=0.0332M alpha=0.1401M beta=0.0071M
This batch time : update_bounds func: 0.8405	 prepare: 0.0289	 bound: 0.8019	 transfer: 0.0008	 finalize: 0.0079
Accumulated time: update_bounds func: 2.4823	 prepare: 0.0796	 bound: 2.3751	 transfer: 0.0028	 finalize: 0.0221
batch bounding time:  0.8405485153198242
Current worst splitting domains lb-rhs (depth):
-0.46733 (11), -0.46718 (11), -0.46718 (11), -0.46688 (11), -0.46683 (11), -0.46669 (11), -0.46665 (11), -0.46656 (11), -0.46640 (11), -0.46572 (11), -0.46572 (11), -0.46559 (11), -0.46524 (11), -0.46513 (11), -0.46507 (11), -0.46505 (11), -0.46503 (11), -0.46495 (11), -0.46495 (11), -0.46487 (11), 
length of domains: 272
Total time: 0.9231	 pickout: 0.0016	 decision: 0.0497	 get_bound: 0.8406	 add_domain: 0.0312
Accumulated time:	 pickout: 0.0040	 decision: 0.1350	 get_bound: 2.5293	 add_domain: 0.0916
Current (lb-rhs): -0.4673321843147278
818 domains visited
Cumulative time: 5.9386091232299805

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([272, 32]) pre split depth:  1
batch:  torch.Size([272, 32]) post split depth:  1
splitting decisions: 
split level 0: [1, 22] [1, 12] [1, 22] [1, 12] [1, 12] [0, 31] [1, 3] [1, 12] [1, 12] [1, 12] 
regular batch size: 2*272, diving batch size 1*0
(544, 14) torch.Size([544, 2, 14]) torch.Size([544, 2])
best_l after optimization: -1411.1923828125 with beta sum per layer: [5.311153411865234, 16.635644912719727]
alpha/beta optimization time: 0.7977089881896973
pruning_in_iteration open status: True
ratio of positive domain = 289 / 544 = 0.53125
pruning-in-iteration extra time: 0.05076885223388672
Tensors transferred: pre=0.0664M lA=0.0311M alpha=0.1328M beta=0.0078M
This batch time : update_bounds func: 0.8354	 prepare: 0.0278	 bound: 0.7981	 transfer: 0.0008	 finalize: 0.0079
Accumulated time: update_bounds func: 3.3177	 prepare: 0.1074	 bound: 3.1732	 transfer: 0.0037	 finalize: 0.0300
batch bounding time:  0.8354892730712891
Current worst splitting domains lb-rhs (depth):
-0.46688 (12), -0.46572 (12), -0.46572 (12), -0.46559 (12), -0.46513 (12), -0.46487 (12), -0.46487 (12), -0.46476 (12), -0.46451 (12), -0.46450 (12), -0.46422 (12), -0.46416 (12), -0.46385 (12), -0.46370 (12), -0.46359 (12), -0.46352 (12), -0.46333 (12), -0.46321 (12), -0.46320 (12), -0.46320 (12), 
length of domains: 255
Total time: 0.9152	 pickout: 0.0016	 decision: 0.0479	 get_bound: 0.8355	 add_domain: 0.0301
Accumulated time:	 pickout: 0.0055	 decision: 0.1829	 get_bound: 3.3648	 add_domain: 0.1217
Current (lb-rhs): -0.4668836295604706
1107 domains visited
Cumulative time: 6.854749441146851

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([255, 32]) pre split depth:  1
batch:  torch.Size([255, 32]) post split depth:  1
splitting decisions: 
split level 0: [0, 31] [0, 9] [1, 12] [1, 22] [0, 31] [1, 12] [1, 12] [1, 12] [0, 31] [1, 12] 
regular batch size: 2*255, diving batch size 1*0
(510, 14) torch.Size([510, 2, 14]) torch.Size([510, 2])
best_l after optimization: -1233.8509521484375 with beta sum per layer: [7.022912979125977, 17.92418670654297]
alpha/beta optimization time: 0.7996976375579834
pruning_in_iteration open status: True
ratio of positive domain = 340 / 510 = 0.6666666666666667
pruning-in-iteration extra time: 0.050650835037231445
Tensors transferred: pre=0.0623M lA=0.0208M alpha=0.1245M beta=0.0083M
This batch time : update_bounds func: 0.8999	 prepare: 0.0268	 bound: 0.8001	 transfer: 0.0008	 finalize: 0.0072
Accumulated time: update_bounds func: 4.2176	 prepare: 0.1342	 bound: 3.9734	 transfer: 0.0045	 finalize: 0.0372
batch bounding time:  0.8999278545379639
Current worst splitting domains lb-rhs (depth):
-0.46487 (13), -0.46487 (13), -0.46476 (13), -0.46385 (13), -0.46317 (13), -0.46317 (13), -0.46269 (13), -0.46219 (13), -0.46090 (13), -0.46090 (13)/home/zhouxingshi/onnx2pytorch/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)
  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))
/home/zhouxingshi/onnx2pytorch/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  "Using experimental implementation that allows 'batch_size > 1'."
, -0.46090 (13), -0.46090 (13), -0.46090 (13), -0.46003 (13), -0.45997 (13), -0.45997 (13), -0.45910 (13), -0.45905 (13), -0.45881 (13), -0.45845 (13), 
length of domains: 170
Total time: 0.9730	 pickout: 0.0015	 decision: 0.0455	 get_bound: 0.9000	 add_domain: 0.0260
Accumulated time:	 pickout: 0.0070	 decision: 0.2284	 get_bound: 4.2648	 add_domain: 0.1477
Current (lb-rhs): -0.46486711502075195
1447 domains visited
Cumulative time: 7.82886815071106

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([170, 32]) pre split depth:  2
batch:  torch.Size([170, 32]) post split depth:  2
splitting decisions: 
split level 0: [0, 9] [1, 12] [0, 9] [0, 9] [0, 9] [0, 0] [1, 22] [1, 12] [0, 31] [0, 9] 
split level 1: [1, 12] [0, 31] [1, 11] [1, 12] [0, 31] [0, 31] [0, 1] [0, 8] [1, 12] [1, 12] 
regular batch size: 2*340, diving batch size 1*0
(680, 14) torch.Size([680, 2, 14]) torch.Size([680, 2])
best_l after optimization: -1350.846923828125 with beta sum per layer: [19.257110595703125, 19.27409553527832]
alpha/beta optimization time: 0.7967941761016846
pruning_in_iteration open status: True
ratio of positive domain = 582 / 680 = 0.8558823529411765
pruning-in-iteration extra time: 0.05060243606567383
Tensors transferred: pre=0.0830M lA=0.0120M alpha=0.1660M beta=0.0117M
This batch time : update_bounds func: 0.8434	 prepare: 0.0346	 bound: 0.7972	 transfer: 0.0009	 finalize: 0.0094
Accumulated time: update_bounds func: 5.0610	 prepare: 0.1688	 bound: 4.7706	 transfer: 0.0054	 finalize: 0.0466
batch bounding time:  0.8434915542602539
Current worst splitting domains lb-rhs (depth):
-0.45845 (15), -0.45520 (15), -0.44939 (15), -0.44850 (15), -0.44657 (15), -0.42018 (15), -0.40441 (15), -0.38244 (15), -0.36674 (15), -0.36579 (15), -0.34971 (15), -0.34941 (15), -0.34935 (15), -0.34929 (15), -0.34849 (15), -0.34847 (15), -0.34841 (15), -0.34834 (15), -0.34821 (15), -0.34766 (15), 
length of domains: 98
Total time: 0.9560	 pickout: 0.0013	 decision: 0.0479	 get_bound: 0.8779	 add_domain: 0.0289
Accumulated time:	 pickout: 0.0083	 decision: 0.2763	 get_bound: 5.1427	 add_domain: 0.1767
Current (lb-rhs): -0.4584459364414215
2029 domains visited
Cumulative time: 8.785863637924194

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([98, 32]) pre split depth:  3
batch:  torch.Size([98, 32]) post split depth:  3
splitting decisions: 
split level 0: [0, 9] [0, 0] [0, 18] [0, 22] [1, 12] [1, 12] [0, 9] [0, 21] [0, 21] [0, 22] 
split level 1: [0, 1] [0, 9] [1, 22] [0, 9] [0, 21] [0, 9] [1, 11] [0, 31] [0, 1] [1, 11] 
split level 2: [1, 12] [1, 12] [0, 10] [1, 12] [1, 11] [1, 11] [0, 22] [1, 11] [1, 12] [1, 23] 
regular batch size: 2*392, diving batch size 1*0
(784, 14) torch.Size([784, 2, 14]) torch.Size([784, 2])
best_l after optimization: -1283.17041015625 with beta sum per layer: [74.03067016601562, 32.135704040527344]
alpha/beta optimization time: 0.7968151569366455
pruning_in_iteration open status: True
ratio of positive domain = 746 / 784 = 0.951530612244898
pruning-in-iteration extra time: 0.050600528717041016
Tensors transferred: pre=0.0957M lA=0.0046M alpha=0.1914M beta=0.0164M
This batch time : update_bounds func: 0.8510	 prepare: 0.0400	 bound: 0.7972	 transfer: 0.0010	 finalize: 0.0117
Accumulated time: update_bounds func: 5.9121	 prepare: 0.2088	 bound: 5.5678	 transfer: 0.0063	 finalize: 0.0583
batch bounding time:  0.8510856628417969
Current worst splitting domains lb-rhs (depth):
-0.34458 (18), -0.32812 (18), -0.27082 (18), -0.23934 (18), -0.20988 (18), -0.18654 (18), -0.16271 (18), -0.14587 (18), -0.14132 (18), -0.13609 (18), -0.12834 (18), -0.12173 (18), -0.12164 (18), -0.11426 (18), -0.11377 (18), -0.11304 (18), -0.10469 (18), -0.10085 (18), -0.09621 (18), -0.09413 (18), 
length of domains: 38
Total time: 0.9827	 pickout: 0.0010	 decision: 0.0407	 get_bound: 0.9112	 add_domain: 0.0298
Accumulated time:	 pickout: 0.0093	 decision: 0.3170	 get_bound: 6.0538	 add_domain: 0.2065
Current (lb-rhs): -0.3445799648761749
2775 domains visited
Cumulative time: 9.769537925720215

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([38, 32]) pre split depth:  4
batch:  torch.Size([38, 32]) post split depth:  4
splitting decisions: 
split level 0: [0, 10] [0, 22] [0, 13] [1, 24] [0, 25] [1, 29] [1, 24] [0, 25] [0, 13] [0, 21] 
split level 1: [0, 29] [1, 29] [1, 23] [1, 23] [1, 24] [1, 25] [1, 29] [0, 18] [0, 24] [1, 24] 
split level 2: [1, 29] [1, 23] [1, 29] [1, 29] [1, 23] [1, 23] [1, 23] [1, 23] [1, 29] [1, 23] 
split level 3: [1, 23] [0, 23] [0, 23] [0, 23] [1, 29] [1, 24] [0, 23] [0, 22] [0, 23] [1, 29] 
regular batch size: 2*304, diving batch size 1*0
(608, 14) torch.Size([608, 2, 14]) torch.Size([608, 2])
best_l after optimization: -647.000244140625 with beta sum per layer: [20.973186492919922, 12.646373748779297]
alpha/beta optimization time: 0.7872116565704346
pruning_in_iteration open status: True
ratio of positive domain = 598 / 608 = 0.9835526315789473
pruning-in-iteration extra time: 0.050307512283325195
Tensors transferred: pre=0.0742M lA=0.0012M alpha=0.1484M beta=0.0151M
This batch time : update_bounds func: 0.8292	 prepare: 0.0311	 bound: 0.7876	 transfer: 0.0008	 finalize: 0.0088
Accumulated time: update_bounds func: 6.7413	 prepare: 0.2399	 bound: 6.3554	 transfer: 0.0072	 finalize: 0.0671
batch bounding time:  0.8292927742004395
Current worst splitting domains lb-rhs (depth):
-0.14935 (22), -0.10200 (22), -0.09978 (22), -0.09883 (22), -0.06115 (22), -0.05483 (22), -0.03037 (22), -0.02708 (22), -0.01081 (22), -0.00297 (22), 
length of domains: 10
Total time: 0.9400	 pickout: 0.0008	 decision: 0.0309	 get_bound: 0.8863	 add_domain: 0.0220
Accumulated time:	 pickout: 0.0101	 decision: 0.3479	 get_bound: 6.9401	 add_domain: 0.2285
Current (lb-rhs): -0.1493515968322754
3373 domains visited
Cumulative time: 10.710282325744629

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([10, 32]) pre split depth:  6
batch:  torch.Size([10, 32]) post split depth:  6
splitting decisions: 
split level 0: [0, 21] [0, 27] [0, 21] [0, 27] [0, 21] [1, 25] [0, 10] [0, 30] [1, 25] [0, 21] 
split level 1: [1, 25] [1, 29] [0, 10] [0, 13] [1, 25] [0, 11] [0, 11] [0, 27] [0, 11] [0, 13] 
split level 2: [1, 29] [1, 24] [1, 24] [1, 29] [1, 24] [0, 24] [1, 25] [1, 25] [0, 22] [0, 22] 
split level 3: [1, 24] [0, 0] [1, 25] [1, 24] [0, 12] [0, 30] [0, 22] [0, 24] [0, 24] [0, 12] 
split level 4: [0, 18] [0, 23] [0, 11] [0, 23] [0, 18] [0, 8] [0, 25] [0, 19] [0, 8] [0, 30] 
split level 5: [1, 23] [0, 3] [0, 18] [0, 10] [0, 19] [0, 19] [0, 18] [1, 13] [0, 19] [0, 18] 
regular batch size: 2*320, diving batch size 1*0
(640, 14) torch.Size([640, 2, 14]) torch.Size([640, 2])

all verified at 25th iter
best_l after optimization: -832.9056396484375 with beta sum per layer: [0.5786409378051758, 4.717194080352783]
alpha/beta optimization time: 0.19922232627868652
pruning_in_iteration open status: True
ratio of positive domain = 640 / 640 = 1.0
pruning-in-iteration extra time: 0.01262807846069336
Tensors transferred: pre=0.0781M lA=0.0001M alpha=0.1562M beta=0.0183M
This batch time : update_bounds func: 0.2442	 prepare: 0.0337	 bound: 0.1996	 transfer: 0.0008	 finalize: 0.0089
Accumulated time: update_bounds func: 6.9855	 prepare: 0.2737	 bound: 6.5550	 transfer: 0.0080	 finalize: 0.0760
batch bounding time:  0.24423980712890625
length of domains: 0
Total time: 0.3665	 pickout: 0.0007	 decision: 0.0295	 get_bound: 0.3144	 add_domain: 0.0219
Accumulated time:	 pickout: 0.0107	 decision: 0.3773	 get_bound: 7.2546	 add_domain: 0.2504
No domains left, verification finished!
4013 domains visited
Cumulative time: 11.077447891235352

Result: safe in 14.3313 seconds
############# Summary #############
Final verified acc: 100.0% [total 1 examples]
Total verification count: 1 , total verified safe: 1 , verified unsafe: 0 , timeout: 0
mean time (bab) [total:1]: 11.150447845458984
mean time [1] 14.331347703933716 max time 14.331347703933716
safe (total 1): [0]
