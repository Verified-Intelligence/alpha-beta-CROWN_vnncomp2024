Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  sparse_alpha: true
  save_adv_example: false
  precompile_jit: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: false
  get_crown_verified_acc: false
  csv_name: marabou-cifar10_instances.csv
  results_file: null
  root_path: ../../vnncomp2021/benchmarks/marabou-cifar10
model:
  path: null
  cache_onnx_conversion: false
  onnx_quirks: null
  name: mnist_9_200
  onnx_path: null
  onnx_path_prefix: ''
  onnx_optimization_flags: none
data:
  start: 49
  end: 50
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: null
  vnnlib_path: null
  vnnlib_path_prefix: ''
solver:
  batch_size: 512
  no_float64_last_iter: true
  no_amp: false
  early_stop_patience: 10
  start_save_best: 2
  bound_prop_method: alpha-crown
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
    full_conv_alpha: true
  beta-crown:
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.5
    lr_decay: 0.98
    optimizer: adam
    iteration: 50
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  multi_class:
    multi_class_method: allclass_domain
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
bab:
  initial_max_domains: 1
  max_domains: 200000
  decision_thresh: 0
  timeout: 360
  timeout_scale: 0.25
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_intermediate_layers: ''
  interm_transfer: true
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 100
    batch_size_primal: 100
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    max_num: 1000000000
    fixed_cuts: false
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
    lr: 0.01
  branching:
    method: kfsb
    candidates: 5
    reduceop: min
    sb_coeff_thresh: 0.001
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      sort_domain_interval: -1
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  attack_mode: PGD
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 5000000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
  enable_mip_attack: false
  cex_path: ./test_cex.txt
debug:
  lp_test: null

Experiments at Tue Aug 23 12:41:44 2022 on diablo.cs.ucla.edu
saving results to a-b-crown_[marabou-cifar10_instances]_start=49_end=50_iter=50_b=512_timeout=360_branching=kfsb-min-5_lra-init=0.1_lra=0.01_lrb=0.5_PGD=skip_cplex_cuts=False_initial_max_domains=1.npz
customized start/end sample from 49 to 50

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 49 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx ./nets/cifar10_medium.onnx
Using vnnlib ./specs/networkcifar10_medium_index3364_eps0.012_target5_orig4.vnnlib
Precompiled vnnlib file found at ../../vnncomp2021/benchmarks/marabou-cifar10/./specs/networkcifar10_medium_index3364_eps0.012_target5_orig4.vnnlib.compiled
Loading onnx ../../vnncomp2021/benchmarks/marabou-cifar10/./nets/cifar10_medium.onnx wih quirks {}
ConvertModel(
  (Transpose_sequential_1/conv2d_2/BiasAdd__7:0): Transpose()
  (Conv_sequential_1/conv2d_2/BiasAdd:0): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2))
  (Relu_sequential_1/conv2d_2/Relu:0): ReLU(inplace=True)
  (Conv_sequential_1/conv2d_3/BiasAdd:0): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))
  (Relu_sequential_1/conv2d_3/Relu:0): ReLU(inplace=True)
  (Transpose_sequential_1/conv2d_3/BiasAdd__13:0): Transpose()
  (Reshape_sequential_1/flatten_1/Reshape:0): Reshape(shape=[  -1 1152])
  (MatMul_sequential_1/dense_3/BiasAdd:0): Linear(in_features=1152, out_features=128, bias=True)
  (Relu_sequential_1/dense_3/Relu:0): ReLU(inplace=True)
  (MatMul_sequential_1/dense_4/BiasAdd:0): Linear(in_features=128, out_features=64, bias=True)
  (Relu_sequential_1/dense_4/Relu:0): ReLU(inplace=True)
  (MatMul_Identity:0): Linear(in_features=64, out_features=10, bias=True)
)
Model converted to NCHW format: Sequential(
  (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2))
  (1): ReLU(inplace=True)
  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))
  (3): ReLU(inplace=True)
  (4): Transpose()
  (5): Flatten(start_dim=1, end_dim=-1)
  (6): Linear(in_features=1152, out_features=128, bias=True)
  (7): ReLU(inplace=True)
  (8): Linear(in_features=128, out_features=64, bias=True)
  (9): ReLU(inplace=True)
  (10): Linear(in_features=64, out_features=10, bias=True)
)
Scaling timeout: 300.0 -> 75.0
Total VNNLIB file length: 1, max property batch size: 1, total number of batches: 1

Properties batch 0, size 1
Remaining timeout: 72.71702122688293
##### [0] Spec matrix: [[[ 1.  0.  0.  0.  0. -1.  0.  0.  0.  0.]
  [ 0.  1.  0.  0.  0. -1.  0.  0.  0.  0.]
  [ 0.  0.  1.  0.  0. -1.  0.  0.  0.  0.]
  [ 0.  0.  0.  1.  0. -1.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  1. -1.  0.  0.  0.  0.]
  [ 0.  0.  0.  0.  0. -1.  1.  0.  0.  0.]
  [ 0.  0.  0.  0.  0. -1.  0.  1.  0.  0.]
  [ 0.  0.  0.  0.  0. -1.  0.  0.  1.  0.]
  [ 0.  0.  0.  0.  0. -1.  0.  0.  0.  1.]]], thresh: [0. 0. 0. 0. 0. 0. 0. 0. 0.] ######
Model prediction is: tensor([-3.33620238, -4.79356289,  1.20955896,  1.12973237,  2.80931067,
         1.22513616,  1.20022094, -0.33071816, -4.91894913, -4.55325508],
       device='cuda:0')
layer /12 using sparse-features alpha with shape [1062]; unstable size 1062; total size 3600 (torch.Size([1, 16, 15, 15]))
layer /12 start_node /input.4 using full alpha with unstable size 31 total_size 32 output_shape 32
layer /12 start_node /input.8 using full alpha with unstable size 128 total_size 128 output_shape torch.Size([128])
layer /12 start_node /input.12 using full alpha with unstable size 64 total_size 64 output_shape torch.Size([64])
layer /12 start_node /21 using full alpha with unstable size None total_size 9 output_shape 9
layer /14 using sparse-features alpha with shape [560]; unstable size 560; total size 1152 (torch.Size([1, 32, 6, 6]))
layer /14 start_node /input.8 using full alpha with unstable size 128 total_size 128 output_shape torch.Size([128])
layer /14 start_node /input.12 using full alpha with unstable size 64 total_size 64 output_shape torch.Size([64])
layer /14 start_node /21 using full alpha with unstable size None total_size 9 output_shape 9
layer /18 using full alpha with shape torch.Size([128]); unstable size 128; total size 128 (torch.Size([1, 128]))
layer /18 start_node /input.12 using full alpha with unstable size 64 total_size 64 output_shape torch.Size([64])
layer /18 start_node /21 using full alpha with unstable size None total_size 9 output_shape 9
layer /20 using full alpha with shape torch.Size([64]); unstable size 64; total size 64 (torch.Size([1, 64]))
layer /20 start_node /21 using full alpha with unstable size None total_size 9 output_shape 9
Optimizable variables initialized.
initial CROWN bounds: tensor([[-64.07769775, -75.22167969, -49.84337234, -33.66181946, -51.73512268,
         -62.82143402, -47.41224670, -68.15762329, -64.07236481]],
       device='cuda:0') None
best_l after optimization: -403.5543212890625 with beta sum per layer: []
alpha/beta optimization time: 10.119057416915894
initial alpha-CROWN bounds: tensor([[-50.82215500, -58.50831604, -38.16853714, -26.58187866, -39.11101913,
         -44.42251587, -37.08708954, -56.90442276, -51.94839859]],
       device='cuda:0')
Worst class: (+ rhs) -58.50831604003906
Keeping slopes for these layers: ['/21']
layer 0 size torch.Size([3600]) unstable 1062
layer 1 size torch.Size([1152]) unstable 537
layer 2 size torch.Size([128]) unstable 125
layer 3 size torch.Size([64]) unstable 64
-----------------
# of unstable neurons: 1788
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 15, 15]) pre split depth:  5
batch:  torch.Size([1, 16, 15, 15]) post split depth:  5
splitting decisions: 
split level 0: [3, 32] 
split level 1: [3, 12] 
split level 2: [3, 36] 
split level 3: [3, 54] 
split level 4: [3, 51] 
regular batch size: 2*16, diving batch size 1*0
(32, 3, 32, 32) torch.Size([32, 9, 10]) torch.Size([32, 9])
best_l after optimization: -10581.5771484375 with beta sum per layer: [0.0, 0.0, 0.0, 12.17310905456543]
alpha/beta optimization time: 1.3425204753875732
pruning_in_iteration open status: False
ratio of positive domain = 0 / 32 = 0.0
pruning-in-iteration extra time: 0.0001552104949951172
Tensors transferred: pre=0.3018M lA=1.3579M alpha=0.9965M beta=0.0002M
This batch time : update_bounds func: 1.3613	 prepare: 0.0066	 bound: 1.3431	 transfer: 0.0097	 finalize: 0.0017
Accumulated time: update_bounds func: 1.3613	 prepare: 0.0066	 bound: 1.3431	 transfer: 0.0097	 finalize: 0.0017
batch bounding time:  1.3613393306732178
Current worst splitting domains lb-rhs (depth):
-25.31791 (5), -25.20797 (5), -25.19544 (5), -25.16487 (5), -25.06139 (5), -25.01943 (5), -24.97938 (5), -24.96892 (5), -24.92798 (5), -24.90803 (5), -24.86385 (5), -24.86187 (5), -24.86137 (5), -24.82029 (5), -24.74750 (5), -24.73850 (5), -23.04869 (5), -22.99439 (5), -22.98802 (5), -22.97819 (5), 
length of domains: 32
Total time: 1.4171	 pickout: 0.0014	 decision: 0.0398	 get_bound: 1.3660	 add_domain: 0.0099
Accumulated time:	 pickout: 0.0014	 decision: 0.0398	 get_bound: 1.3660	 add_domain: 0.0099
Current (lb-rhs): -25.31790542602539
0 domains visited
Cumulative time: 14.568817853927612

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([32, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([32, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 5] [3, 5] [3, 5] [3, 5] [3, 5] [3, 5] [3, 5] [3, 5] [3, 5] [3, 5] 
regular batch size: 2*32, diving batch size 1*0
(64, 3, 32, 32) torch.Size([64, 9, 10]) torch.Size([64, 9])
best_l after optimization: -20311.02734375 with beta sum per layer: [0.0, 0.0, 0.0, 35.68265914916992]
alpha/beta optimization time: 0.6777877807617188
pruning_in_iteration open status: False
ratio of positive domain = 0 / 64 = 0.0
pruning-in-iteration extra time: 0.00013685226440429688
Tensors transferred: pre=0.6035M lA=2.7158M alpha=1.9929M beta=0.0004M
This batch time : update_bounds func: 0.7019	 prepare: 0.0098	 bound: 0.6784	 transfer: 0.0118	 finalize: 0.0018
Accumulated time: update_bounds func: 2.0632	 prepare: 0.0165	 bound: 2.0214	 transfer: 0.0215	 finalize: 0.0035
batch bounding time:  0.7019717693328857
Current worst splitting domains lb-rhs (depth):
-24.35766 (6), -24.34721 (6), -24.27503 (6), -24.24404 (6), -24.22495 (6), -24.18241 (6), -24.15299 (6), -24.12899 (6), -24.12382 (6), -24.12008 (6), -24.11462 (6), -24.10517 (6), -24.05410 (6), -24.05374 (6), -24.04734 (6), -23.99076 (6), -22.54507 (6), -22.29983 (6), -22.29763 (6), -22.11351 (6), 
length of domains: 64
Total time: 0.7948	 pickout: 0.0186	 decision: 0.0569	 get_bound: 0.7020	 add_domain: 0.0172
Accumulated time:	 pickout: 0.0201	 decision: 0.0967	 get_bound: 2.0680	 add_domain: 0.0272
Current (lb-rhs): -24.357662200927734
0 domains visited
Cumulative time: 15.364240407943726

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([64, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 35] [3, 0] [3, 35] [3, 35] [3, 35] [3, 0] [3, 35] [3, 35] [3, 35] [3, 0] 
regular batch size: 2*64, diving batch size 1*0
(128, 3, 32, 32) torch.Size([128, 9, 10]) torch.Size([128, 9])
best_l after optimization: -39250.109375 with beta sum per layer: [0.0, 0.0, 0.0, 82.3731689453125]
alpha/beta optimization time: 0.7652385234832764
pruning_in_iteration open status: False
ratio of positive domain = 0 / 128 = 0.0
pruning-in-iteration extra time: 0.00012254714965820312
Tensors transferred: pre=1.2070M lA=5.4316M alpha=3.9858M beta=0.0009M
This batch time : update_bounds func: 0.8067	 prepare: 0.0161	 bound: 0.7658	 transfer: 0.0211	 finalize: 0.0035
Accumulated time: update_bounds func: 2.8699	 prepare: 0.0325	 bound: 2.7872	 transfer: 0.0426	 finalize: 0.0070
batch bounding time:  0.8068044185638428
Current worst splitting domains lb-rhs (depth):
-23.54530 (7), -23.53849 (7), -23.53117 (7), -23.49250 (7), -23.46933 (7), -23.46663 (7), -23.44854 (7), -23.41525 (7), -23.40695 (7), -23.40311 (7), -23.37243 (7), -23.36812 (7), -23.36609 (7), -23.36161 (7), -23.35862 (7), -23.35704 (7), -23.35225 (7), -23.34851 (7), -23.33649 (7), -23.33158 (7), 
length of domains: 128
Total time: 0.9284	 pickout: 0.0118	 decision: 0.0949	 get_bound: 0.8069	 add_domain: 0.0148
Accumulated time:	 pickout: 0.0319	 decision: 0.1916	 get_bound: 2.8749	 add_domain: 0.0420
Current (lb-rhs): -23.54529571533203
0 domains visited
Cumulative time: 16.293525218963623

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([128, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([128, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 17] [3, 17] [3, 17] [3, 17] [3, 17] [3, 17] [3, 17] [3, 17] [3, 17] [3, 17] 
regular batch size: 2*128, diving batch size 1*0
(256, 3, 32, 32) torch.Size([256, 9, 10]) torch.Size([256, 9])
best_l after optimization: -76041.5078125 with beta sum per layer: [0.0, 0.0, 0.0, 223.1595458984375]
alpha/beta optimization time: 1.2228577136993408
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 0.00013971328735351562
Tensors transferred: pre=2.4141M lA=10.8633M alpha=7.9717M beta=0.0020M
This batch time : update_bounds func: 1.2910	 prepare: 0.0235	 bound: 1.2234	 transfer: 0.0371	 finalize: 0.0065
Accumulated time: update_bounds func: 4.1609	 prepare: 0.0560	 bound: 4.0106	 transfer: 0.0797	 finalize: 0.0135
batch bounding time:  1.2912685871124268
Current worst splitting domains lb-rhs (depth):
-22.72874 (8), -22.72864 (8), -22.71617 (8), -22.68028 (8), -22.66195 (8), -22.64357 (8), -22.60787 (8), -22.60625 (8), -22.56783 (8), -22.55299 (8), -22.55053 (8), -22.53776 (8), -22.52555 (8), -22.51954 (8), -22.51773 (8), -22.51245 (8), -22.49776 (8), -22.49360 (8), -22.49354 (8), -22.49052 (8), 
length of domains: 256
Total time: 1.4810	 pickout: 0.0093	 decision: 0.1539	 get_bound: 1.2913	 add_domain: 0.0265
Accumulated time:	 pickout: 0.0411	 decision: 0.3455	 get_bound: 4.1662	 add_domain: 0.0684
Current (lb-rhs): -22.728744506835938
0 domains visited
Cumulative time: 17.77812147140503

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([256, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 44] [3, 35] [3, 44] [3, 44] [3, 0] [3, 35] [3, 0] [3, 0] [3, 0] [3, 35] 
regular batch size: 2*256, diving batch size 1*0
(512, 3, 32, 32) torch.Size([512, 9, 10]) torch.Size([512, 9])
best_l after optimization: -147405.125 with beta sum per layer: [0.0, 0.0, 0.0, 494.3190612792969]
alpha/beta optimization time: 2.385469913482666
pruning_in_iteration open status: False
ratio of positive domain = 0 / 512 = 0.0
pruning-in-iteration extra time: 0.0001361370086669922
Tensors transferred: pre=4.8281M lA=21.7266M alpha=15.9434M beta=0.0044M
This batch time : update_bounds func: 2.5363	 prepare: 0.0443	 bound: 2.3860	 transfer: 0.0922	 finalize: 0.0130
Accumulated time: update_bounds func: 6.6972	 prepare: 0.1003	 bound: 6.3966	 transfer: 0.1719	 finalize: 0.0265
batch bounding time:  2.5366883277893066
Current worst splitting domains lb-rhs (depth):
-22.05323 (9), -22.03926 (9), -22.02612 (9), -21.98775 (9), -21.96564 (9), -21.95702 (9), -21.92833 (9), -21.90986 (9), -21.90827 (9), -21.88302 (9), -21.88172 (9), -21.87848 (9), -21.86805 (9), -21.86272 (9), -21.86029 (9), -21.83753 (9), -21.82588 (9), -21.82490 (9), -21.82176 (9), -21.82148 (9), 
length of domains: 512
Total time: 2.8840	 pickout: 0.0174	 decision: 0.2834	 get_bound: 2.5368	 add_domain: 0.0464
Accumulated time:	 pickout: 0.0585	 decision: 0.6289	 get_bound: 6.7030	 add_domain: 0.1148
Current (lb-rhs): -22.0532283782959
0 domains visited
Cumulative time: 20.665660619735718

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 0] [3, 44] [3, 0] [3, 0] [3, 44] [3, 44] [3, 44] [3, 44] [3, 44] [3, 44] 
regular batch size: 2*512, diving batch size 1*0
(1024, 3, 32, 32) torch.Size([1024, 9, 10]) torch.Size([1024, 9])
best_l after optimization: -284962.6875 with beta sum per layer: [0.0, 0.0, 0.0, 1101.8974609375]
alpha/beta optimization time: 4.570703983306885
pruning_in_iteration open status: False
ratio of positive domain = 0 / 1024 = 0.0
pruning-in-iteration extra time: 0.00012803077697753906
Tensors transferred: pre=9.6562M lA=43.4531M alpha=31.8867M beta=0.0098M
This batch time : update_bounds func: 4.8608	 prepare: 0.0851	 bound: 4.5712	 transfer: 0.1766	 finalize: 0.0260
Accumulated time: update_bounds func: 11.5580	 prepare: 0.1854	 bound: 10.9678	 transfer: 0.3485	 finalize: 0.0525
batch bounding time:  4.861427068710327
Current worst splitting domains lb-rhs (depth):
-21.38390 (10), -21.37568 (10), -21.36661 (10), -21.31319 (10), -21.29663 (10), -21.29149 (10), -21.28724 (10), -21.23832 (10), -21.23665 (10), -21.23459 (10), -21.23457 (10), -21.21933 (10), -21.19725 (10), -21.17773 (10), -21.16995 (10), -21.16580 (10), -21.16119 (10), -21.15269 (10), -21.14960 (10), -21.14783 (10), 
length of domains: 1024
Total time: 5.5317	 pickout: 0.0336	 decision: 0.5425	 get_bound: 4.8615	 add_domain: 0.0940
Accumulated time:	 pickout: 0.0921	 decision: 1.1714	 get_bound: 11.5645	 add_domain: 0.2089
Current (lb-rhs): -21.38389778137207
0 domains visited
Cumulative time: 26.203294277191162

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 59] [3, 59] [3, 9] [3, 9] [3, 59] [3, 59] [3, 59] [3, 14] [3, 59] [3, 59] 
regular batch size: 2*512, diving batch size 1*0
(1024, 3, 32, 32) torch.Size([1024, 9, 10]) torch.Size([1024, 9])
best_l after optimization: -272884.46875 with beta sum per layer: [0.0, 0.0, 0.0, 1230.69970703125]
alpha/beta optimization time: 4.5584704875946045
pruning_in_iteration open status: False
ratio of positive domain = 0 / 1024 = 0.0
pruning-in-iteration extra time: 0.000133514404296875
Tensors transferred: pre=9.6562M lA=43.4531M alpha=31.8867M beta=0.0107M
This batch time : update_bounds func: 4.8465	 prepare: 0.0848	 bound: 4.5590	 transfer: 0.1755	 finalize: 0.0256
Accumulated time: update_bounds func: 16.4044	 prepare: 0.2702	 bound: 15.5269	 transfer: 0.5240	 finalize: 0.0781
batch bounding time:  4.847064971923828
Current worst splitting domains lb-rhs (depth):
-21.38390 (10), -21.29663 (10), -21.29149 (10), -21.23832 (10), -21.23459 (10), -21.23457 (10), -21.21933 (10), -21.19725 (10), -21.17773 (10), -21.16995 (10), -21.16119 (10), -21.15269 (10), -21.14783 (10), -21.14595 (10), -21.14429 (10), -21.12043 (10), -21.08912 (10), -21.08865 (10), -21.08468 (10), -21.07419 (10), 
length of domains: 1536
Total time: 5.8102	 pickout: 0.0348	 decision: 0.5399	 get_bound: 4.8471	 add_domain: 0.3884
Accumulated time:	 pickout: 0.1269	 decision: 1.7113	 get_bound: 16.4117	 add_domain: 0.5973
Current (lb-rhs): -21.38389778137207
0 domains visited
Cumulative time: 32.01789164543152

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 9] [3, 14] [3, 59] [3, 59] [3, 14] [3, 14] [3, 9] [3, 59] [3, 14] [3, 9] 
regular batch size: 2*512, diving batch size 1*0
(1024, 3, 32, 32) torch.Size([1024, 9, 10]) torch.Size([1024, 9])
best_l after optimization: -256041.71875 with beta sum per layer: [0.0, 0.0, 0.0, 1498.0185546875]
alpha/beta optimization time: 4.56633448600769
pruning_in_iteration open status: False
ratio of positive domain = 0 / 1024 = 0.0
pruning-in-iteration extra time: 0.0001518726348876953
Tensors transferred: pre=9.6562M lA=43.4531M alpha=31.8867M beta=0.0117M
This batch time : update_bounds func: 4.8388	 prepare: 0.0858	 bound: 4.5669	 transfer: 0.1593	 finalize: 0.0251
Accumulated time: update_bounds func: 21.2432	 prepare: 0.3560	 bound: 20.0937	 transfer: 0.6833	 finalize: 0.1032
batch bounding time:  4.839600086212158
Current worst splitting domains lb-rhs (depth):
-21.38390 (10), -21.29663 (10), -21.29149 (10), -21.23832 (10), -21.23459 (10), -21.23457 (10), -21.21933 (10), -21.19725 (10), -21.17773 (10), -21.16995 (10), -21.16119 (10), -21.15269 (10), -21.14783 (10), -21.14595 (10), -21.14429 (10), -21.12043 (10), -21.08912 (10), -21.08865 (10), -21.08468 (10), -21.07419 (10), 
length of domains: 2048
Total time: 5.9229	 pickout: 0.0347	 decision: 0.5412	 get_bound: 4.8397	 add_domain: 0.5073
Accumulated time:	 pickout: 0.1615	 decision: 2.2525	 get_bound: 21.2514	 add_domain: 1.1046
Current (lb-rhs): -21.38389778137207
0 domains visited
Cumulative time: 37.94923806190491

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 23] [3, 23] [3, 23] [3, 23] [3, 23] [3, 23] [3, 23] [3, 23] [3, 23] [3, 23] 
regular batch size: 2*512, diving batch size 1*0
(1024, 3, 32, 32) torch.Size([1024, 9, 10]) torch.Size([1024, 9])
best_l after optimization: -243786.765625 with beta sum per layer: [0.0, 0.0, 0.0, 1622.287841796875]
alpha/beta optimization time: 4.601333141326904
pruning_in_iteration open status: False
ratio of positive domain = 0 / 1024 = 0.0
pruning-in-iteration extra time: 0.0001513957977294922
Tensors transferred: pre=9.6562M lA=43.4531M alpha=31.8867M beta=0.0127M
This batch time : update_bounds func: 4.8676	 prepare: 0.0930	 bound: 4.6019	 transfer: 0.1443	 finalize: 0.0269
Accumulated time: update_bounds func: 26.1109	 prepare: 0.4490	 bound: 24.6956	 transfer: 0.8276	 finalize: 0.1301
batch bounding time:  4.868275880813599
Current worst splitting domains lb-rhs (depth):
-21.38390 (10), -21.29663 (10), -21.29149 (10), -21.23832 (10), -21.23459 (10), -21.23457 (10), -21.21933 (10), -21.19725 (10), -21.17773 (10), -21.16995 (10), -21.16119 (10), -21.15269 (10), -21.14783 (10), -21.14595 (10), -21.14429 (10), -21.12043 (10), -21.08912 (10), -21.08865 (10), -21.08468 (10), -21.07419 (10), 
length of domains: 2560
Total time: 6.4667	 pickout: 0.0369	 decision: 0.5435	 get_bound: 4.8684	 add_domain: 1.0180
Accumulated time:	 pickout: 0.1984	 decision: 2.7960	 get_bound: 26.1197	 add_domain: 2.1226
Current (lb-rhs): -21.38389778137207
0 domains visited
Cumulative time: 44.42439341545105

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 14] [3, 9] [3, 14] [3, 14] [3, 9] [3, 9] [3, 14] [3, 9] [3, 9] [3, 14] 
regular batch size: 2*512, diving batch size 1*0
(1024, 3, 32, 32) torch.Size([1024, 9, 10]) torch.Size([1024, 9])
best_l after optimization: -230213.5625 with beta sum per layer: [0.0, 0.0, 0.0, 1758.275390625]
alpha/beta optimization time: 4.613079071044922
pruning_in_iteration open status: False
ratio of positive domain = 0 / 1024 = 0.0
pruning-in-iteration extra time: 0.00014829635620117188
Tensors transferred: pre=9.6562M lA=43.4531M alpha=31.8867M beta=0.0137M
This batch time : update_bounds func: 4.8904	 prepare: 0.0923	 bound: 4.6136	 transfer: 0.1557	 finalize: 0.0271
Accumulated time: update_bounds func: 31.0013	 prepare: 0.5413	 bound: 29.3093	 transfer: 0.9833	 finalize: 0.1571
batch bounding time:  4.891207456588745
Current worst splitting domains lb-rhs (depth):
-21.38390 (10), -21.29663 (10), -21.29149 (10), -21.23832 (10), -21.23459 (10), -21.23457 (10), -21.21933 (10), -21.19725 (10), -21.17773 (10), -21.16995 (10), -21.16119 (10), -21.15269 (10), -21.14783 (10), -21.14595 (10), -21.14429 (10), -21.12043 (10), -21.08912 (10), -21.08865 (10), -21.08468 (10), -21.07419 (10), 
length of domains: 3072
Total time: 5.7775	 pickout: 0.0450	 decision: 0.5452	 get_bound: 4.8913	 add_domain: 0.2959
Accumulated time:	 pickout: 0.2434	 decision: 3.3412	 get_bound: 31.0110	 add_domain: 2.4185
Current (lb-rhs): -21.38389778137207
0 domains visited
Cumulative time: 50.20664381980896

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 15] [3, 15] [3, 15] [3, 15] [3, 15] [3, 15] [3, 15] [3, 15] [3, 15] [3, 15] 
regular batch size: 2*512, diving batch size 1*0
(1024, 3, 32, 32) torch.Size([1024, 9, 10]) torch.Size([1024, 9])
best_l after optimization: -219081.25 with beta sum per layer: [0.0, 0.0, 0.0, 1739.4345703125]
alpha/beta optimization time: 4.653741121292114
pruning_in_iteration open status: False
ratio of positive domain = 0 / 1024 = 0.0
pruning-in-iteration extra time: 0.00022172927856445312
Tensors transferred: pre=9.6562M lA=43.4531M alpha=31.8867M beta=0.0146M
This batch time : update_bounds func: 5.0062	 prepare: 0.1414	 bound: 4.6545	 transfer: 0.1649	 finalize: 0.0438
Accumulated time: update_bounds func: 36.0075	 prepare: 0.6827	 bound: 33.9637	 transfer: 1.1482	 finalize: 0.2009
batch bounding time:  5.007035493850708
Current worst splitting domains lb-rhs (depth):
-21.38390 (10), -21.29663 (10), -21.29149 (10), -21.23832 (10), -21.23459 (10), -21.23457 (10), -21.21933 (10), -21.19725 (10), -21.17773 (10), -21.16995 (10), -21.16119 (10), -21.15269 (10), -21.14783 (10), -21.14595 (10), -21.14429 (10), -21.12043 (10), -21.08912 (10), -21.08865 (10), -21.08468 (10), -21.07419 (10), 
length of domains: 3584
Total time: 5.8818	 pickout: 0.0343	 decision: 0.5667	 get_bound: 5.0072	 add_domain: 0.2737
Accumulated time:	 pickout: 0.2777	 decision: 3.9078	 get_bound: 36.0182	 add_domain: 2.6922
Current (lb-rhs): -21.38389778137207
0 domains visited
Cumulative time: 56.09733438491821

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 10] [3, 10] [3, 10] [3, 10] [3, 10] [3, 10] [3, 10] [3, 10] [3, 10] [3, 10] 
regular batch size: 2*512, diving batch size 1*0
(1024, 3, 32, 32) torch.Size([1024, 9, 10]) torch.Size([1024, 9])
best_l after optimization: -207923.015625 with beta sum per layer: [0.0, 0.0, 0.0, 2038.1600341796875]
alpha/beta optimization time: 4.637762784957886
pruning_in_iteration open status: False
ratio of positive domain = 0 / 1024 = 0.0
pruning-in-iteration extra time: 0.00018787384033203125
Tensors transferred: pre=9.6562M lA=43.4531M alpha=31.8867M beta=0.0156M
This batch time : update_bounds func: 4.9771	 prepare: 0.1488	 bound: 4.6385	 transfer: 0.1460	 finalize: 0.0422
Accumulated time: update_bounds func: 40.9847	 prepare: 0.8315	 bound: 38.6022	 transfer: 1.2942	 finalize: 0.2431
batch bounding time:  4.977917671203613
Current worst splitting domains lb-rhs (depth):
-21.38390 (10), -21.29663 (10), -21.29149 (10), -21.23832 (10), -21.23459 (10), -21.23457 (10), -21.21933 (10), -21.19725 (10), -21.17773 (10), -21.16995 (10), -21.16119 (10), -21.15269 (10), -21.14783 (10), -21.14595 (10), -21.14429 (10), -21.12043 (10), -21.08912 (10), -21.08865 (10), -21.08468 (10), -21.07419 (10), 
length of domains: 4096
Total time: 5.9657	 pickout: 0.0471	 decision: 0.5685	 get_bound: 4.9781	 add_domain: 0.3720
Accumulated time:	 pickout: 0.3248	 decision: 4.4764	 get_bound: 40.9963	 add_domain: 3.0642
Current (lb-rhs): -21.38389778137207
0 domains visited
Cumulative time: 62.06786131858826

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 49] [3, 39] [3, 49] [3, 49] [3, 39] [3, 39] [3, 39] [3, 39] [3, 49] [3, 49] 
regular batch size: 2*512, diving batch size 1*0
(1024, 3, 32, 32) torch.Size([1024, 9, 10]) torch.Size([1024, 9])
best_l after optimization: -198751.34375 with beta sum per layer: [0.0, 0.0, 0.0, 1819.262939453125]
alpha/beta optimization time: 4.667259693145752
pruning_in_iteration open status: False
ratio of positive domain = 0 / 1024 = 0.0
pruning-in-iteration extra time: 0.00022339820861816406
Tensors transferred: pre=9.6562M lA=43.4531M alpha=31.8867M beta=0.0166M
This batch time : update_bounds func: 5.0020	 prepare: 0.1461	 bound: 4.6680	 transfer: 0.1459	 finalize: 0.0404
Accumulated time: update_bounds func: 45.9867	 prepare: 0.9776	 bound: 43.2702	 transfer: 1.4401	 finalize: 0.2835
batch bounding time:  5.002848863601685
Current worst splitting domains lb-rhs (depth):
-21.38390 (10), -21.29663 (10), -21.29149 (10), -21.23832 (10), -21.23459 (10), -21.23457 (10), -21.21933 (10), -21.19725 (10), -21.17773 (10), -21.16995 (10), -21.16119 (10), -21.15269 (10), -21.14783 (10), -21.14595 (10), -21.14429 (10), -21.12043 (10), -21.08912 (10), -21.08865 (10), -21.08468 (10), -21.07419 (10), 
length of domains: 4608
Total time: 6.9037	 pickout: 0.0355	 decision: 0.5686	 get_bound: 5.0030	 add_domain: 1.2966
Accumulated time:	 pickout: 0.3603	 decision: 5.0449	 get_bound: 45.9993	 add_domain: 4.3608
Current (lb-rhs): -21.38389778137207
0 domains visited
Cumulative time: 68.97650694847107

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 46] [3, 46] [3, 46] [3, 46] [3, 46] [3, 46] [3, 46] [3, 46] [3, 46] [3, 46] 
regular batch size: 2*512, diving batch size 1*0
(1024, 3, 32, 32) torch.Size([1024, 9, 10]) torch.Size([1024, 9])
best_l after optimization: -188750.375 with beta sum per layer: [0.0, 0.0, 0.0, 1903.304931640625]
alpha/beta optimization time: 4.653958559036255
pruning_in_iteration open status: False
ratio of positive domain = 0 / 1024 = 0.0
pruning-in-iteration extra time: 0.0002071857452392578
Tensors transferred: pre=9.6562M lA=43.4531M alpha=31.8867M beta=0.0176M
This batch time : update_bounds func: 5.0035	 prepare: 0.1489	 bound: 4.6547	 transfer: 0.1544	 finalize: 0.0437
Accumulated time: update_bounds func: 50.9902	 prepare: 1.1265	 bound: 47.9249	 transfer: 1.5945	 finalize: 0.3272
batch bounding time:  5.004343032836914
Current worst splitting domains lb-rhs (depth):
-21.38390 (10), -21.29663 (10), -21.29149 (10), -21.23832 (10), -21.23459 (10), -21.23457 (10), -21.21933 (10), -21.19725 (10), -21.17773 (10), -21.16995 (10), -21.16119 (10), -21.15269 (10), -21.14783 (10), -21.14595 (10), -21.14429 (10), -21.12043 (10), -21.08912 (10), -21.08865 (10), -21.08468 (10), -21.07419 (10)/home/zhouxingshi/onnx2pytorch/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)
  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))
/home/zhouxingshi/onnx2pytorch/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  "Using experimental implementation that allows 'batch_size > 1'."
, 
length of domains: 5120
Total time: 5.7353	 pickout: 0.0363	 decision: 0.5738	 get_bound: 5.0045	 add_domain: 0.1207
Accumulated time:	 pickout: 0.3966	 decision: 5.6188	 get_bound: 51.0037	 add_domain: 4.4814
Current (lb-rhs): -21.38389778137207
0 domains visited
Time out!!!!!!!!
Result: unknown in 77.7156 seconds
############# Summary #############
Final verified acc: 0.0% [total 1 examples]
Total verification count: 1 , total verified safe: 0 , verified unsafe: 0 , timeout: 1
mean time (bab) [total:1]: 75.43255567550659
mean time [1] 77.71560907363892 max time 77.71560907363892
unknown (total 1): [0]
