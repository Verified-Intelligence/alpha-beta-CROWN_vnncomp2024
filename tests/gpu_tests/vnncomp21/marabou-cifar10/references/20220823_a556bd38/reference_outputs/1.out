Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  sparse_alpha: true
  save_adv_example: false
  precompile_jit: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: false
  get_crown_verified_acc: false
  csv_name: marabou-cifar10_instances.csv
  results_file: null
  root_path: ../../vnncomp2021/benchmarks/marabou-cifar10
model:
  path: null
  cache_onnx_conversion: false
  onnx_quirks: null
  name: mnist_9_200
  onnx_path: null
  onnx_path_prefix: ''
  onnx_optimization_flags: none
data:
  start: 2
  end: 3
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: null
  vnnlib_path: null
  vnnlib_path_prefix: ''
solver:
  batch_size: 512
  no_float64_last_iter: true
  no_amp: false
  early_stop_patience: 10
  start_save_best: 2
  bound_prop_method: alpha-crown
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
    full_conv_alpha: true
  beta-crown:
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.5
    lr_decay: 0.98
    optimizer: adam
    iteration: 50
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  multi_class:
    multi_class_method: allclass_domain
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
bab:
  initial_max_domains: 1
  max_domains: 200000
  decision_thresh: 0
  timeout: 360
  timeout_scale: 0.25
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_intermediate_layers: ''
  interm_transfer: true
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 100
    batch_size_primal: 100
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    max_num: 1000000000
    fixed_cuts: false
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
    lr: 0.01
  branching:
    method: kfsb
    candidates: 5
    reduceop: min
    sb_coeff_thresh: 0.001
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      sort_domain_interval: -1
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  attack_mode: PGD
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 5000000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
  enable_mip_attack: false
  cex_path: ./test_cex.txt
debug:
  lp_test: null

Experiments at Tue Aug 23 12:32:31 2022 on diablo.cs.ucla.edu
saving results to a-b-crown_[marabou-cifar10_instances]_start=2_end=3_iter=50_b=512_timeout=360_branching=kfsb-min-5_lra-init=0.1_lra=0.01_lrb=0.5_PGD=skip_cplex_cuts=False_initial_max_domains=1.npz
customized start/end sample from 2 to 3

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 2 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx ./nets/cifar10_large.onnx
Using vnnlib ./specs/networkcifar10_large_index4089_eps0.012_target6_orig5.vnnlib
Precompiled vnnlib file found at ../../vnncomp2021/benchmarks/marabou-cifar10/./specs/networkcifar10_large_index4089_eps0.012_target6_orig5.vnnlib.compiled
Loading onnx ../../vnncomp2021/benchmarks/marabou-cifar10/./nets/cifar10_large.onnx wih quirks {}
ConvertModel(
  (Transpose_sequential_2/conv2d_4/BiasAdd__7:0): Transpose()
  (Conv_sequential_2/conv2d_4/BiasAdd:0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2))
  (Relu_sequential_2/conv2d_4/Relu:0): ReLU(inplace=True)
  (Conv_sequential_2/conv2d_5/BiasAdd:0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))
  (Relu_sequential_2/conv2d_5/Relu:0): ReLU(inplace=True)
  (Transpose_sequential_2/conv2d_5/BiasAdd__13:0): Transpose()
  (Reshape_sequential_2/flatten_2/Reshape:0): Reshape(shape=[  -1 2304])
  (MatMul_sequential_2/dense_6/BiasAdd:0): Linear(in_features=2304, out_features=128, bias=True)
  (Relu_sequential_2/dense_6/Relu:0): ReLU(inplace=True)
  (MatMul_sequential_2/dense_7/BiasAdd:0): Linear(in_features=128, out_features=64, bias=True)
  (Relu_sequential_2/dense_7/Relu:0): ReLU(inplace=True)
  (MatMul_Identity:0): Linear(in_features=64, out_features=10, bias=True)
)
Model converted to NCHW format: Sequential(
  (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2))
  (1): ReLU(inplace=True)
  (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))
  (3): ReLU(inplace=True)
  (4): Transpose()
  (5): Flatten(start_dim=1, end_dim=-1)
  (6): Linear(in_features=2304, out_features=128, bias=True)
  (7): ReLU(inplace=True)
  (8): Linear(in_features=128, out_features=64, bias=True)
  (9): ReLU(inplace=True)
  (10): Linear(in_features=64, out_features=10, bias=True)
)
Scaling timeout: 300.0 -> 75.0
Total VNNLIB file length: 1, max property batch size: 1, total number of batches: 1

Properties batch 0, size 1
Remaining timeout: 72.72647476196289
##### [0] Spec matrix: [[[ 1.  0.  0.  0.  0.  0. -1.  0.  0.  0.]
  [ 0.  1.  0.  0.  0.  0. -1.  0.  0.  0.]
  [ 0.  0.  1.  0.  0.  0. -1.  0.  0.  0.]
  [ 0.  0.  0.  1.  0.  0. -1.  0.  0.  0.]
  [ 0.  0.  0.  0.  1.  0. -1.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  1. -1.  0.  0.  0.]
  [ 0.  0.  0.  0.  0.  0. -1.  1.  0.  0.]
  [ 0.  0.  0.  0.  0.  0. -1.  0.  1.  0.]
  [ 0.  0.  0.  0.  0.  0. -1.  0.  0.  1.]]], thresh: [0. 0. 0. 0. 0. 0. 0. 0. 0.] ######
Model prediction is: tensor([-2.01929045, -3.69776988,  0.15410791,  1.10254169, -2.51202798,
         1.30258954, -1.70436347, -0.80027425,  0.34066057, -1.22107160],
       device='cuda:0')
layer /12 using sparse-features alpha with shape [1932]; unstable size 1932; total size 7200 (torch.Size([1, 32, 15, 15]))
layer /12 start_node /input.4 using full alpha with unstable size 64 total_size 64 output_shape 64
layer /12 start_node /input.8 using full alpha with unstable size 128 total_size 128 output_shape torch.Size([128])
layer /12 start_node /input.12 using full alpha with unstable size 64 total_size 64 output_shape torch.Size([64])
layer /12 start_node /21 using full alpha with unstable size None total_size 9 output_shape 9
layer /14 using sparse-features alpha with shape [1194]; unstable size 1194; total size 2304 (torch.Size([1, 64, 6, 6]))
layer /14 start_node /input.8 using full alpha with unstable size 128 total_size 128 output_shape torch.Size([128])
layer /14 start_node /input.12 using full alpha with unstable size 64 total_size 64 output_shape torch.Size([64])
layer /14 start_node /21 using full alpha with unstable size None total_size 9 output_shape 9
layer /18 using full alpha with shape torch.Size([128]); unstable size 128; total size 128 (torch.Size([1, 128]))
layer /18 start_node /input.12 using full alpha with unstable size 64 total_size 64 output_shape torch.Size([64])
layer /18 start_node /21 using full alpha with unstable size None total_size 9 output_shape 9
layer /20 using full alpha with shape torch.Size([64]); unstable size 64; total size 64 (torch.Size([1, 64]))
layer /20 start_node /21 using full alpha with unstable size None total_size 9 output_shape 9
Optimizable variables initialized.
initial CROWN bounds: tensor([[-151.55070496, -139.71725464, -120.21425629, -114.70453644,
         -142.69949341, -128.19577026, -160.28182983, -167.54518127,
         -151.54034424]], device='cuda:0') None
best_l after optimization: -879.6405029296875 with beta sum per layer: []
alpha/beta optimization time: 10.114843845367432
initial alpha-CROWN bounds: tensor([[-106.52709198, -103.33232117,  -78.35411072,  -73.73457336,
          -97.42877197,  -87.48648071, -105.90908051, -118.99958801,
         -107.86849976]], device='cuda:0')
Worst class: (+ rhs) -118.99958801269531
Keeping slopes for these layers: ['/21']
layer 0 size torch.Size([7200]) unstable 1932
layer 1 size torch.Size([2304]) unstable 1153
layer 2 size torch.Size([128]) unstable 128
layer 3 size torch.Size([64]) unstable 64
-----------------
# of unstable neurons: 3277
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 15, 15]) pre split depth:  5
batch:  torch.Size([1, 32, 15, 15]) post split depth:  5
splitting decisions: 
split level 0: [3, 3] 
split level 1: [3, 52] 
split level 2: [3, 26] 
split level 3: [3, 24] 
split level 4: [3, 25] 
regular batch size: 2*16, diving batch size 1*0
(32, 3, 32, 32) torch.Size([32, 9, 10]) torch.Size([32, 9])
best_l after optimization: -22215.673828125 with beta sum per layer: [0.0, 0.0, 0.0, 10.354179382324219]
alpha/beta optimization time: 1.1861810684204102
pruning_in_iteration open status: False
ratio of positive domain = 0 / 32 = 0.0
pruning-in-iteration extra time: 0.00014472007751464844
Tensors transferred: pre=0.5918M lA=2.6631M alpha=1.8226M beta=0.0002M
This batch time : update_bounds func: 1.2062	 prepare: 0.0038	 bound: 1.1867	 transfer: 0.0147	 finalize: 0.0009
Accumulated time: update_bounds func: 1.2062	 prepare: 0.0038	 bound: 1.1867	 transfer: 0.0147	 finalize: 0.0009
batch bounding time:  1.2062485218048096
Current worst splitting domains lb-rhs (depth):
-66.96779 (5), -66.70387 (5), -66.44344 (5), -66.31817 (5), -65.02297 (5), -64.75327 (5), -64.43353 (5), -63.48908 (5), -63.10451 (5), -63.04325 (5), -62.95577 (5), -62.66936 (5), -62.60818 (5), -62.54563 (5), -62.49914 (5), -62.47081 (5), -62.41458 (5), -62.27552 (5), -62.23739 (5), -62.00765 (5), 
length of domains: 32
Total time: 1.2569	 pickout: 0.0016	 decision: 0.0379	 get_bound: 1.2105	 add_domain: 0.0068
Accumulated time:	 pickout: 0.0016	 decision: 0.0379	 get_bound: 1.2105	 add_domain: 0.0068
Current (lb-rhs): -66.96778869628906
0 domains visited
Cumulative time: 14.59393572807312

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([32, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([32, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 43] [3, 43] [3, 43] [3, 43] [3, 4] [3, 43] [3, 43] [3, 43] [3, 4] [3, 4] 
regular batch size: 2*32, diving batch size 1*0
(64, 3, 32, 32) torch.Size([64, 9, 10]) torch.Size([64, 9])
best_l after optimization: -42846.859375 with beta sum per layer: [0.0, 0.0, 0.0, 28.42586898803711]
alpha/beta optimization time: 0.6706628799438477
pruning_in_iteration open status: False
ratio of positive domain = 0 / 64 = 0.0
pruning-in-iteration extra time: 0.0001246929168701172
Tensors transferred: pre=1.1836M lA=5.3262M alpha=3.6453M beta=0.0004M
This batch time : update_bounds func: 0.6976	 prepare: 0.0062	 bound: 0.6711	 transfer: 0.0184	 finalize: 0.0016
Accumulated time: update_bounds func: 1.9038	 prepare: 0.0100	 bound: 1.8579	 transfer: 0.0331	 finalize: 0.0025
batch bounding time:  0.6976156234741211
Current worst splitting domains lb-rhs (depth):
-64.14826 (6), -64.11575 (6), -64.02292 (6), -62.98440 (6), -62.61768 (6), -62.54968 (6), -62.43972 (6), -62.26093 (6), -61.98151 (6), -61.59806 (6), -61.38492 (6), -61.15392 (6), -60.84702 (6), -60.72816 (6), -60.54220 (6), -60.43301 (6), -60.41372 (6), -60.29652 (6), -60.29322 (6), -60.20599 (6), 
length of domains: 64
Total time: 0.7800	 pickout: 0.0042	 decision: 0.0677	 get_bound: 0.6977	 add_domain: 0.0104
Accumulated time:	 pickout: 0.0058	 decision: 0.1057	 get_bound: 1.9082	 add_domain: 0.0172
Current (lb-rhs): -64.14826202392578
0 domains visited
Cumulative time: 15.374373435974121

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([64, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 4] [3, 4] [3, 4] [3, 4] [3, 43] [3, 4] [3, 4] [3, 4] [3, 10] [3, 10] 
regular batch size: 2*64, diving batch size 1*0
(128, 3, 32, 32) torch.Size([128, 9, 10]) torch.Size([128, 9])
best_l after optimization: -82554.8828125 with beta sum per layer: [0.0, 0.0, 0.0, 72.86788940429688]
alpha/beta optimization time: 1.0060031414031982
pruning_in_iteration open status: False
ratio of positive domain = 0 / 128 = 0.0
pruning-in-iteration extra time: 0.0001266002655029297
Tensors transferred: pre=2.3672M lA=10.6523M alpha=7.2905M beta=0.0009M
This batch time : update_bounds func: 1.0562	 prepare: 0.0110	 bound: 1.0065	 transfer: 0.0354	 finalize: 0.0031
Accumulated time: update_bounds func: 2.9600	 prepare: 0.0210	 bound: 2.8643	 transfer: 0.0686	 finalize: 0.0056
batch bounding time:  1.0564262866973877
Current worst splitting domains lb-rhs (depth):
-61.83841 (7), -61.64629 (7), -61.31765 (7), -61.01529 (7), -60.71893 (7), -60.66110 (7), -60.60619 (7), -60.02919 (7), -59.97009 (7), -59.86288 (7), -59.49188 (7), -59.14529 (7), -58.99112 (7), -58.81329 (7), -58.48164 (7), -58.47411 (7), -58.29613 (7), -58.28175 (7), -58.27770 (7), -58.27578 (7), 
length of domains: 128
Total time: 1.1943	 pickout: 0.0079	 decision: 0.1112	 get_bound: 1.0565	 add_domain: 0.0188
Accumulated time:	 pickout: 0.0137	 decision: 0.2169	 get_bound: 2.9646	 add_domain: 0.0359
Current (lb-rhs): -61.838409423828125
0 domains visited
Cumulative time: 16.569905996322632

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([128, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([128, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 53] [3, 53] [3, 53] [3, 10] [3, 53] [3, 53] [3, 53] [3, 53] [3, 43] [3, 43] 
regular batch size: 2*128, diving batch size 1*0
(256, 3, 32, 32) torch.Size([256, 9, 10]) torch.Size([256, 9])
best_l after optimization: -157442.46875 with beta sum per layer: [0.0, 0.0, 0.0, 224.1966552734375]
alpha/beta optimization time: 1.8181099891662598
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 0.0001678466796875
Tensors transferred: pre=4.7344M lA=21.3047M alpha=14.5811M beta=0.0020M
This batch time : update_bounds func: 1.9313	 prepare: 0.0210	 bound: 1.8187	 transfer: 0.0850	 finalize: 0.0062
Accumulated time: update_bounds func: 4.8913	 prepare: 0.0420	 bound: 4.6830	 transfer: 0.1535	 finalize: 0.0118
batch bounding time:  1.931631088256836
Current worst splitting domains lb-rhs (depth):
-59.99282 (8), -59.93237 (8), -59.79562 (8), -59.51070 (8), -59.03171 (8), -58.87581 (8), -58.72770 (8), -58.39615 (8), -58.32383 (8), -58.28651 (8), -58.23637 (8), -58.16993 (8), -58.08263 (8), -57.95597 (8), -57.68070 (8), -57.32597 (8), -57.23568 (8), -56.94107 (8), -56.89349 (8), -56.67927 (8), 
length of domains: 256
Total time: 2.2049	 pickout: 0.0160	 decision: 0.2233	 get_bound: 1.9317	 add_domain: 0.0339
Accumulated time:	 pickout: 0.0298	 decision: 0.4402	 get_bound: 4.8963	 add_domain: 0.0698
Current (lb-rhs): -59.99282455444336
0 domains visited
Cumulative time: 18.778162717819214

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([256, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 48] [3, 48] [3, 48] [3, 48] [3, 48] [3, 48] [3, 48] [3, 48] [3, 48] [3, 48] 
regular batch size: 2*256, diving batch size 1*0
(512, 3, 32, 32) torch.Size([512, 9, 10]) torch.Size([512, 9])
best_l after optimization: -303810.6875 with beta sum per layer: [0.0, 0.0, 0.0, 502.65606689453125]
alpha/beta optimization time: 3.7179787158966064
pruning_in_iteration open status: False
ratio of positive domain = 0 / 512 = 0.0
pruning-in-iteration extra time: 0.00015401840209960938
Tensors transferred: pre=9.4688M lA=42.6094M alpha=29.1621M beta=0.0044M
This batch time : update_bounds func: 3.9452	 prepare: 0.0396	 bound: 3.7185	 transfer: 0.1741	 finalize: 0.0121
Accumulated time: update_bounds func: 8.8364	 prepare: 0.0816	 bound: 8.4016	 transfer: 0.3276	 finalize: 0.0239
batch bounding time:  3.9457931518554688
Current worst splitting domains lb-rhs (depth):
-57.81967 (9), -57.46817 (9), -57.41978 (9), -57.40604 (9), -57.29295 (9), -57.24231 (9), -57.20337 (9), -57.02800 (9), -56.91603 (9), -56.66013 (9), -56.34507 (9), -56.30375 (9), -56.26887 (9), -56.26798 (9), -56.23219 (9), -56.07646 (9), -56.01336 (9), -55.97588 (9), -55.93689 (9), -55.79955 (9), 
length of domains: 512
Total time: 4.4741	 pickout: 0.0318	 decision: 0.4331	 get_bound: 3.9459	 add_domain: 0.0633
Accumulated time:	 pickout: 0.0616	 decision: 0.8734	 get_bound: 8.8422	 add_domain: 0.1330
Current (lb-rhs): -57.819671630859375
0 domains visited
Cumulative time: 23.255486965179443

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 46] [3, 46] [3, 46] [3, 46] [3, 46] [3, 46] [3, 46] [3, 46] [3, 46] [3, 46] 
regular batch size: 2*512, diving batch size 1*0
(1024, 3, 32, 32) torch.Size([1024, 9, 10]) torch.Size([1024, 9])
best_l after optimization: -584298.625 with beta sum per layer: [0.0, 0.0, 0.0, 1193.5792236328125]
alpha/beta optimization time: 7.419374942779541
pruning_in_iteration open status: False
ratio of positive domain = 0 / 1024 = 0.0
pruning-in-iteration extra time: 0.00015497207641601562
Tensors transferred: pre=18.9375M lA=85.2188M alpha=58.3242M beta=0.0098M
This batch time : update_bounds func: 7.8552	 prepare: 0.0770	 bound: 7.4200	 transfer: 0.3327	 finalize: 0.0238
Accumulated time: update_bounds func: 16.6917	 prepare: 0.1586	 bound: 15.8215	 transfer: 0.6604	 finalize: 0.0478
batch bounding time:  7.8563666343688965
Current worst splitting domains lb-rhs (depth):
-56.10628 (10), -55.96861 (10), -55.54759 (10), -55.43511 (10), -55.41066 (10), -55.37886 (10), -55.30795 (10), -55.27254 (10), -55.14680 (10), -55.05569 (10), -54.84526 (10), -54.69846 (10), -54.50747 (10), -54.36538 (10), -54.32803 (10), -54.29302 (10), -54.28101 (10), -54.20341 (10), -54.15672 (10), -54.03275 (10), 
length of domains: 1024
Total time: 9.3410	 pickout: 0.0611	 decision: 1.2949	 get_bound: 7.8565	 add_domain: 0.1284
Accumulated time:	 pickout: 0.1227	 decision: 2.1683	 get_bound: 16.6987	 add_domain: 0.2615
Current (lb-rhs): -56.10628128051758
0 domains visited
Cumulative time: 32.60138654708862

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 10] [3, 10] [3, 10] [3, 53] [3, 10] [3, 10] [3, 10] [3, 10] [3, 35] [3, 35] 
regular batch size: 2*512, diving batch size 1*0
(1024, 3, 32, 32) torch.Size([1024, 9, 10]) torch.Size([1024, 9])
best_l after optimization: -552146.3125 with beta sum per layer: [0.0, 0.0, 0.0, 1518.392333984375]
alpha/beta optimization time: 7.431298494338989
pruning_in_iteration open status: False
ratio of positive domain = 0 / 1024 = 0.0
pruning-in-iteration extra time: 0.0001571178436279297
Tensors transferred: pre=18.9375M lA=85.2188M alpha=58.3242M beta=0.0107M
This batch time : update_bounds func: 7.8452	 prepare: 0.0765	 bound: 7.4319	 transfer: 0.3108	 finalize: 0.0245
Accumulated time: update_bounds func: 24.5369	 prepare: 0.2351	 bound: 23.2534	 transfer: 0.9712	 finalize: 0.0723
batch bounding time:  7.846461296081543
Current worst splitting domains lb-rhs (depth):
-56.10628 (10), -55.54759 (10), -55.43511 (10), -55.41066 (10), -55.37886 (10), -55.30795 (10), -55.27254 (10), -55.14680 (10), -55.05569 (10), -54.84526 (10), -54.69846 (10), -54.50747 (10), -54.36538 (10), -54.32803 (10), -54.29302 (10), -54.28101 (10), -54.26316 (11), -54.20341 (10), -54.15672 (10), -54.03275 (10), 
length of domains: 1536
Total time: 9.8085	 pickout: 0.0603	 decision: 1.1796	 get_bound: 7.8466	 add_domain: 0.7220
Accumulated time:	 pickout: 0.1830	 decision: 3.3479	 get_bound: 24.5453	 add_domain: 0.9834
Current (lb-rhs): -56.10628128051758
0 domains visited
Cumulative time: 42.41480898857117

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 0] [3, 0] [3, 0] [3, 0] [3, 0] [3, 0] [3, 0] [3, 0] [3, 0] [3, 0] 
regular batch size: 2*512, diving batch size 1*0
(1024, 3, 32, 32) torch.Size([1024, 9, 10]) torch.Size([1024, 9])
best_l after optimization: -522677.375 with beta sum per layer: [0.0, 0.0, 0.0, 1777.7841796875]
alpha/beta optimization time: 7.473379135131836
pruning_in_iteration open status: False
ratio of positive domain = 0 / 1024 = 0.0
pruning-in-iteration extra time: 0.0001811981201171875
Tensors transferred: pre=18.9375M lA=85.2188M alpha=58.3242M beta=0.0117M
This batch time : update_bounds func: 7.9044	 prepare: 0.0791	 bound: 7.4741	 transfer: 0.3097	 finalize: 0.0396
Accumulated time: update_bounds func: 32.4412	 prepare: 0.3141	 bound: 30.7275	 transfer: 1.2809	 finalize: 0.1119
batch bounding time:  7.905383825302124
Current worst splitting domains lb-rhs (depth):
-56.10628 (10), -55.54759 (10), -55.43511 (10), -55.41066 (10), -55.37886 (10), -55.30795 (10), -55.27254 (10), -55.14680 (10), -55.05569 (10), -54.84526 (10), -54.69846 (10), -54.50747 (10), -54.36538 (10), -54.32803 (10), -54.29302 (10), -54.28101 (10), -54.26316 (11), -54.20341 (10), -54.15672 (10), -54.03275 (10), 
length of domains: 2048
Total time: 9.3692	 pickout: 0.0608	 decision: 1.1851	 get_bound: 7.9055	 add_domain: 0.2177
Accumulated time:	 pickout: 0.2438	 decision: 4.5331	 get_bound: 32.4508	 add_domain: 1.2012
Current (lb-rhs): -56.10628128051758
0 domains visited
Cumulative time: 51.789186000823975

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 35] [3, 35] [3, 35] [3, 20] [3, 35] [3, 35] [3, 35] [3, 35] [3, 49] [3, 49] 
regular batch size: 2*512, diving batch size 1*0
(1024, 3, 32, 32) torch.Size([1024, 9, 10]) torch.Size([1024, 9])
best_l after optimization: -493295.375 with beta sum per layer: [0.0, 0.0, 0.0, 2050.9296875]
alpha/beta optimization time: 7.470183372497559
pruning_in_iteration open status: False
ratio of positive domain = 0 / 1024 = 0.0
pruning-in-iteration extra time: 0.00018739700317382812
Tensors transferred: pre=18.9375M lA=85.2188M alpha=58.3242M beta=0.0127M
This batch time : update_bounds func: 7.9543	 prepare: 0.1323	 bound: 7.4709	 transfer: 0.3090	 finalize: 0.0406
Accumulated time: update_bounds func: 40.3955	 prepare: 0.4465	 bound: 38.1984	 transfer: 1.5899	 finalize: 0.1525
batch bounding time:  7.9554762840271
Current worst splitting domains lb-rhs (depth):
-56.10628 (10), -55.54759 (10), -55.43511 (10), -55.41066 (10), -55.37886 (10), -55.30795 (10), -55.27254 (10), -55.14680 (10), -55.05569 (10), -54.84526 (10), -54.69846 (10), -54.50747 (10), -54.36538 (10), -54.32803 (10), -54.29302 (10), -54.28101 (10), -54.26316 (11), -54.20341 (10), -54.15672 (10), -54.03275 (10), 
length of domains: 2560
Total time: 10.5436	 pickout: 0.0617	 decision: 1.2060	 get_bound: 7.9556	 add_domain: 1.3203
Accumulated time:	 pickout: 0.3055	 decision: 5.7390	 get_bound: 40.4064	 add_domain: 2.5215
Current (lb-rhs): -56.10628128051758/home/zhouxingshi/onnx2pytorch/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)
  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))
/home/zhouxingshi/onnx2pytorch/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  "Using experimental implementation that allows 'batch_size > 1'."

0 domains visited
Cumulative time: 62.3398916721344

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 34] [3, 34] [3, 34] [3, 34] [3, 34] [3, 34] [3, 34] [3, 34] [3, 34] [3, 34] 
regular batch size: 2*512, diving batch size 1*0
(1024, 3, 32, 32) torch.Size([1024, 9, 10]) torch.Size([1024, 9])
best_l after optimization: -469427.8125 with beta sum per layer: [0.0, 0.0, 0.0, 2169.1318359375]
alpha/beta optimization time: 7.494976043701172
pruning_in_iteration open status: False
ratio of positive domain = 0 / 1024 = 0.0
pruning-in-iteration extra time: 0.00018930435180664062
Tensors transferred: pre=18.9375M lA=85.2188M alpha=58.3242M beta=0.0137M
This batch time : update_bounds func: 7.9854	 prepare: 0.1338	 bound: 7.4958	 transfer: 0.3286	 finalize: 0.0254
Accumulated time: update_bounds func: 48.3809	 prepare: 0.5803	 bound: 45.6941	 transfer: 1.9184	 finalize: 0.1779
batch bounding time:  7.986532211303711
Current worst splitting domains lb-rhs (depth):
-56.10628 (10), -55.54759 (10), -55.43511 (10), -55.41066 (10), -55.37886 (10), -55.30795 (10), -55.27254 (10), -55.14680 (10), -55.05569 (10), -54.84526 (10), -54.69846 (10), -54.50747 (10), -54.36538 (10), -54.32803 (10), -54.29302 (10), -54.28101 (10), -54.26316 (11), -54.20341 (10), -54.15672 (10), -54.03275 (10), 
length of domains: 3072
Total time: 9.4028	 pickout: 0.0621	 decision: 1.2081	 get_bound: 7.9867	 add_domain: 0.1459
Accumulated time:	 pickout: 0.3676	 decision: 6.9471	 get_bound: 48.3931	 add_domain: 2.6674
Current (lb-rhs): -56.10628128051758
0 domains visited
Cumulative time: 71.7491135597229

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 49] [3, 49] [3, 49] [3, 9] [3, 49] [3, 49] [3, 49] [3, 49] [3, 53] [3, 53] 
regular batch size: 2*512, diving batch size 1*0
(1024, 3, 32, 32) torch.Size([1024, 9, 10]) torch.Size([1024, 9])
best_l after optimization: -439474.84375 with beta sum per layer: [0.0, 0.0, 0.0, 2535.03369140625]
alpha/beta optimization time: 7.455298662185669
pruning_in_iteration open status: False
ratio of positive domain = 0 / 1024 = 0.0
pruning-in-iteration extra time: 0.0001811981201171875
Tensors transferred: pre=18.9375M lA=85.2188M alpha=58.3242M beta=0.0146M
This batch time : update_bounds func: 7.8730	 prepare: 0.0815	 bound: 7.4560	 transfer: 0.3081	 finalize: 0.0257
Accumulated time: update_bounds func: 56.2539	 prepare: 0.6618	 bound: 53.1501	 transfer: 2.2265	 finalize: 0.2036
batch bounding time:  7.874068975448608
Current worst splitting domains lb-rhs (depth):
-56.10628 (10), -55.54759 (10), -55.43511 (10), -55.41066 (10), -55.37886 (10), -55.30795 (10), -55.27254 (10), -55.14680 (10), -55.05569 (10), -54.84526 (10), -54.69846 (10), -54.50747 (10), -54.36538 (10), -54.32803 (10), -54.29302 (10), -54.28101 (10), -54.26316 (11), -54.20341 (10), -54.15672 (10), -54.03275 (10), 
length of domains: 3584
Total time: 9.2741	 pickout: 0.0641	 decision: 1.1903	 get_bound: 7.8742	 add_domain: 0.1454
Accumulated time:	 pickout: 0.4317	 decision: 8.1374	 get_bound: 56.2673	 add_domain: 2.8128
Current (lb-rhs): -56.10628128051758
0 domains visited
Time out!!!!!!!!
Result: unknown in 83.8862 seconds
############# Summary #############
Final verified acc: 0.0% [total 1 examples]
Total verification count: 1 , total verified safe: 0 , verified unsafe: 0 , timeout: 1
mean time (bab) [total:1]: 81.612628698349
mean time [1] 83.88623380661011 max time 83.88623380661011
unknown (total 1): [0]
