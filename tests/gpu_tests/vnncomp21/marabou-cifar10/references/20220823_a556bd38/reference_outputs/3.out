Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  sparse_alpha: true
  save_adv_example: false
  precompile_jit: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: false
  get_crown_verified_acc: false
  csv_name: marabou-cifar10_instances.csv
  results_file: null
  root_path: ../../vnncomp2021/benchmarks/marabou-cifar10
model:
  path: null
  cache_onnx_conversion: false
  onnx_quirks: null
  name: mnist_9_200
  onnx_path: null
  onnx_path_prefix: ''
  onnx_optimization_flags: none
data:
  start: 24
  end: 25
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: null
  vnnlib_path: null
  vnnlib_path_prefix: ''
solver:
  batch_size: 512
  no_float64_last_iter: true
  no_amp: false
  early_stop_patience: 10
  start_save_best: 2
  bound_prop_method: alpha-crown
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
    full_conv_alpha: true
  beta-crown:
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.5
    lr_decay: 0.98
    optimizer: adam
    iteration: 50
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  multi_class:
    multi_class_method: allclass_domain
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
bab:
  initial_max_domains: 1
  max_domains: 200000
  decision_thresh: 0
  timeout: 360
  timeout_scale: 0.25
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_intermediate_layers: ''
  interm_transfer: true
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 100
    batch_size_primal: 100
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    max_num: 1000000000
    fixed_cuts: false
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
    lr: 0.01
  branching:
    method: kfsb
    candidates: 5
    reduceop: min
    sb_coeff_thresh: 0.001
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      sort_domain_interval: -1
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  attack_mode: PGD
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 5000000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
  enable_mip_attack: false
  cex_path: ./test_cex.txt
debug:
  lp_test: null

Experiments at Tue Aug 23 12:34:03 2022 on diablo.cs.ucla.edu
saving results to a-b-crown_[marabou-cifar10_instances]_start=24_end=25_iter=50_b=512_timeout=360_branching=kfsb-min-5_lra-init=0.1_lra=0.01_lrb=0.5_PGD=skip_cplex_cuts=False_initial_max_domains=1.npz
customized start/end sample from 24 to 25

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 24 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx ./nets/cifar10_small.onnx
Using vnnlib ./specs/networkcifar10_small_index1783_eps0.012_target9_orig8.vnnlib
Precompiled vnnlib file found at ../../vnncomp2021/benchmarks/marabou-cifar10/./specs/networkcifar10_small_index1783_eps0.012_target9_orig8.vnnlib.compiled
Loading onnx ../../vnncomp2021/benchmarks/marabou-cifar10/./nets/cifar10_small.onnx wih quirks {}
ConvertModel(
  (Transpose_sequential/conv2d/BiasAdd__7:0): Transpose()
  (Conv_sequential/conv2d/BiasAdd:0): Conv2d(3, 8, kernel_size=(4, 4), stride=(2, 2))
  (Relu_sequential/conv2d/Relu:0): ReLU(inplace=True)
  (Conv_sequential/conv2d_1/BiasAdd:0): Conv2d(8, 16, kernel_size=(4, 4), stride=(2, 2))
  (Relu_sequential/conv2d_1/Relu:0): ReLU(inplace=True)
  (Transpose_sequential/conv2d_1/BiasAdd__13:0): Transpose()
  (Reshape_sequential/flatten/Reshape:0): Reshape(shape=[ -1 576])
  (MatMul_sequential/dense/BiasAdd:0): Linear(in_features=576, out_features=128, bias=True)
  (Relu_sequential/dense/Relu:0): ReLU(inplace=True)
  (MatMul_sequential/dense_1/BiasAdd:0): Linear(in_features=128, out_features=64, bias=True)
  (Relu_sequential/dense_1/Relu:0): ReLU(inplace=True)
  (MatMul_Identity:0): Linear(in_features=64, out_features=10, bias=True)
)
Model converted to NCHW format: Sequential(
  (0): Conv2d(3, 8, kernel_size=(4, 4), stride=(2, 2))
  (1): ReLU(inplace=True)
  (2): Conv2d(8, 16, kernel_size=(4, 4), stride=(2, 2))
  (3): ReLU(inplace=True)
  (4): Transpose()
  (5): Flatten(start_dim=1, end_dim=-1)
  (6): Linear(in_features=576, out_features=128, bias=True)
  (7): ReLU(inplace=True)
  (8): Linear(in_features=128, out_features=64, bias=True)
  (9): ReLU(inplace=True)
  (10): Linear(in_features=64, out_features=10, bias=True)
)
Scaling timeout: 300.0 -> 75.0
Total VNNLIB file length: 1, max property batch size: 1, total number of batches: 1

Properties batch 0, size 1
Remaining timeout: 72.88325595855713
##### [0] Spec matrix: [[[ 1.  0.  0.  0.  0.  0.  0.  0.  0. -1.]
  [ 0.  1.  0.  0.  0.  0.  0.  0.  0. -1.]
  [ 0.  0.  1.  0.  0.  0.  0.  0.  0. -1.]
  [ 0.  0.  0.  1.  0.  0.  0.  0.  0. -1.]
  [ 0.  0.  0.  0.  1.  0.  0.  0.  0. -1.]
  [ 0.  0.  0.  0.  0.  1.  0.  0.  0. -1.]
  [ 0.  0.  0.  0.  0.  0.  1.  0.  0. -1.]
  [ 0.  0.  0.  0.  0.  0.  0.  1.  0. -1.]
  [ 0.  0.  0.  0.  0.  0.  0.  0.  1. -1.]]], thresh: [0. 0. 0. 0. 0. 0. 0. 0. 0.] ######
Model prediction is: tensor([ 2.27582741,  1.22637284, -1.07642508, -2.45142412, -2.08305836,
        -3.41144156, -4.46754503, -3.24726820,  3.48711252,  0.46815947],
       device='cuda:0')
layer /12 using sparse-features alpha with shape [602]; unstable size 602; total size 1800 (torch.Size([1, 8, 15, 15]))
layer /12 start_node /input.4 using sparse-spec alpha with unstable size 265 total_size 576 output_shape (16, 6, 6)
layer /12 start_node /input.8 using sparse-spec alpha with unstable size 107 total_size 128 output_shape torch.Size([128])
layer /12 start_node /input.12 using full alpha with unstable size 64 total_size 64 output_shape torch.Size([64])
layer /12 start_node /21 using full alpha with unstable size None total_size 9 output_shape 9
layer /14 using sparse-features alpha with shape [265]; unstable size 265; total size 576 (torch.Size([1, 16, 6, 6]))
layer /14 start_node /input.8 using sparse-spec alpha with unstable size 107 total_size 128 output_shape torch.Size([128])
layer /14 start_node /input.12 using full alpha with unstable size 64 total_size 64 output_shape torch.Size([64])
layer /14 start_node /21 using full alpha with unstable size None total_size 9 output_shape 9
layer /18 using sparse-features alpha with shape [107]; unstable size 107; total size 128 (torch.Size([1, 128]))
layer /18 start_node /input.12 using full alpha with unstable size 64 total_size 64 output_shape torch.Size([64])
layer /18 start_node /21 using full alpha with unstable size None total_size 9 output_shape 9
layer /20 using full alpha with shape torch.Size([64]); unstable size 64; total size 64 (torch.Size([1, 64]))
layer /20 start_node /21 using full alpha with unstable size None total_size 9 output_shape 9
Optimizable variables initialized.
initial CROWN bounds: tensor([[-29.72047043, -24.59854126, -29.27325439, -28.98016739, -37.52478409,
         -28.32951546, -36.31826401, -31.37840462, -35.33438110]],
       device='cuda:0') None
best_l after optimization: -165.5199432373047 with beta sum per layer: []
alpha/beta optimization time: 8.550634860992432
initial alpha-CROWN bounds: tensor([[-12.86868286, -13.61236477, -17.32228088, -18.69902611, -21.62984467,
         -19.82636642, -24.58217430, -20.51721954, -16.46198273]],
       device='cuda:0')
Worst class: (+ rhs) -24.58217430114746
Keeping slopes for these layers: ['/21']
layer 0 size torch.Size([1800]) unstable 602
layer 1 size torch.Size([576]) unstable 259
layer 2 size torch.Size([128]) unstable 102
layer 3 size torch.Size([64]) unstable 64
-----------------
# of unstable neurons: 1027
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 8, 15, 15]) pre split depth:  5
batch:  torch.Size([1, 8, 15, 15]) post split depth:  5
splitting decisions: 
split level 0: [3, 14] 
split level 1: [3, 6] 
split level 2: [3, 2] 
split level 3: [3, 12] 
split level 4: [3, 23] 
regular batch size: 2*16, diving batch size 1*0
(32, 3, 32, 32) torch.Size([32, 9, 10]) torch.Size([32, 9])
best_l after optimization: -4372.083984375 with beta sum per layer: [0.0, 0.0, 0.0, 22.225284576416016]
alpha/beta optimization time: 1.1881494522094727
pruning_in_iteration open status: False
ratio of positive domain = 0 / 32 = 0.0
pruning-in-iteration extra time: 0.0001430511474609375
Tensors transferred: pre=0.1567M lA=0.7053M alpha=0.5702M beta=0.0002M
This batch time : update_bounds func: 1.2001	 prepare: 0.0062	 bound: 1.1887	 transfer: 0.0041	 finalize: 0.0011
Accumulated time: update_bounds func: 1.2001	 prepare: 0.0062	 bound: 1.1887	 transfer: 0.0041	 finalize: 0.0011
batch bounding time:  1.2001948356628418
Current worst splitting domains lb-rhs (depth):
-11.36811 (5), -11.32173 (5), -11.18324 (5), -11.16019 (5), -11.00106 (5), -10.90701 (5), -10.87785 (5), -10.86894 (5), -10.83824 (5), -10.82695 (5), -10.81354 (5), -10.79118 (5), -10.75041 (5), -10.70499 (5), -10.47600 (5), -10.42023 (5), -10.39133 (5), -10.38824 (5), -10.36171 (5), -10.34938 (5), 
length of domains: 32
Total time: 1.2500	 pickout: 0.0014	 decision: 0.0371	 get_bound: 1.2047	 add_domain: 0.0068
Accumulated time:	 pickout: 0.0014	 decision: 0.0371	 get_bound: 1.2047	 add_domain: 0.0068
Current (lb-rhs): -11.368110656738281
0 domains visited
Cumulative time: 12.633171081542969

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([32, 8, 15, 15]) pre split depth:  1
batch:  torch.Size([32, 8, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 16] [3, 16] [3, 16] [3, 16] [3, 16] [3, 16] [3, 16] [3, 16] [3, 16] [3, 16] 
regular batch size: 2*32, diving batch size 1*0
(64, 3, 32, 32) torch.Size([64, 9, 10]) torch.Size([64, 9])
best_l after optimization: -8392.8359375 with beta sum per layer: [0.0, 0.0, 0.0, 61.943824768066406]
alpha/beta optimization time: 0.5869483947753906
pruning_in_iteration open status: False
ratio of positive domain = 0 / 64 = 0.0
pruning-in-iteration extra time: 0.00012612342834472656
Tensors transferred: pre=0.3135M lA=1.4106M alpha=1.1404M beta=0.0004M
This batch time : update_bounds func: 0.6034	 prepare: 0.0072	 bound: 0.5874	 transfer: 0.0070	 finalize: 0.0016
Accumulated time: update_bounds func: 1.8035	 prepare: 0.0133	 bound: 1.7762	 transfer: 0.0111	 finalize: 0.0027
batch bounding time:  0.6034274101257324
Current worst splitting domains lb-rhs (depth):
-10.85678 (6), -10.84256 (6), -10.60620 (6), -10.60223 (6), -10.60047 (6), -10.59200 (6), -10.58368 (6), -10.50276 (6), -10.49001 (6), -10.47490 (6), -10.42585 (6), -10.41146 (6), -10.35373 (6), -10.35042 (6), -10.34368 (6), -10.29579 (6), -10.27106 (6), -10.20857 (6), -10.16123 (6), -10.15627 (6), 
length of domains: 64
Total time: 0.6619	 pickout: 0.0021	 decision: 0.0460	 get_bound: 0.6035	 add_domain: 0.0103
Accumulated time:	 pickout: 0.0034	 decision: 0.0831	 get_bound: 1.8082	 add_domain: 0.0172
Current (lb-rhs): -10.856780052185059
0 domains visited
Cumulative time: 13.295573711395264

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 8, 15, 15]) pre split depth:  1
batch:  torch.Size([64, 8, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 42] [3, 42] [3, 42] [3, 42] [3, 42] [3, 42] [3, 42] [3, 42] [3, 42] [3, 42] 
regular batch size: 2*64, diving batch size 1*0
(128, 3, 32, 32) torch.Size([128, 9, 10]) torch.Size([128, 9])
best_l after optimization: -16237.2109375 with beta sum per layer: [0.0, 0.0, 0.0, 145.4889373779297]
alpha/beta optimization time: 0.6436276435852051
pruning_in_iteration open status: False
ratio of positive domain = 0 / 128 = 0.0
pruning-in-iteration extra time: 0.0001232624053955078
Tensors transferred: pre=0.6270M lA=2.8213M alpha=2.2808M beta=0.0009M
This batch time : update_bounds func: 0.6724	 prepare: 0.0123	 bound: 0.6441	 transfer: 0.0125	 finalize: 0.0032
Accumulated time: update_bounds func: 2.4760	 prepare: 0.0257	 bound: 2.4203	 transfer: 0.0236	 finalize: 0.0059
batch bounding time:  0.6724860668182373
Current worst splitting domains lb-rhs (depth):
-10.13104 (7), -10.12383 (7), -10.10707 (7), -10.01100 (7), -9.96258 (7), -9.93040 (7), -9.89268 (7), -9.86964 (7), -9.85738 (7), -9.84234 (7), -9.82744 (7), -9.78213 (7), -9.72716 (7), -9.71954 (7), -9.70991 (7), -9.67912 (7), -9.64666 (7), -9.60178 (7), -9.57546 (7), -9.56919 (7), 
length of domains: 128
Total time: 0.7534	 pickout: 0.0031	 decision: 0.0655	 get_bound: 0.6725	 add_domain: 0.0123
Accumulated time:	 pickout: 0.0065	 decision: 0.1485	 get_bound: 2.4807	 add_domain: 0.0295
Current (lb-rhs): -10.1310396194458
0 domains visited
Cumulative time: 14.049739360809326

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([128, 8, 15, 15]) pre split depth:  1
batch:  torch.Size([128, 8, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 43] [3, 43] [3, 43] [3, 43] [3, 43] [3, 43] [3, 43] [3, 43] [3, 43] [3, 43] 
regular batch size: 2*128, diving batch size 1*0
(256, 3, 32, 32) torch.Size([256, 9, 10]) torch.Size([256, 9])
best_l after optimization: -31377.05078125 with beta sum per layer: [0.0, 0.0, 0.0, 322.10198974609375]
alpha/beta optimization time: 0.8889799118041992
pruning_in_iteration open status: False
ratio of positive domain = 0 / 256 = 0.0
pruning-in-iteration extra time: 0.00012445449829101562
Tensors transferred: pre=1.2539M lA=5.6426M alpha=4.5615M beta=0.0020M
This batch time : update_bounds func: 0.9394	 prepare: 0.0222	 bound: 0.8895	 transfer: 0.0211	 finalize: 0.0063
Accumulated time: update_bounds func: 3.4154	 prepare: 0.0479	 bound: 3.3097	 transfer: 0.0447	 finalize: 0.0122
batch bounding time:  0.939460277557373
Current worst splitting domains lb-rhs (depth):
-9.90882 (8), -9.82305 (8), -9.70121 (8), -9.63842 (8), -9.58444 (8), -9.54868 (8), -9.54482 (8), -9.52963 (8), -9.48368 (8), -9.41697 (8), -9.40697 (8), -9.38160 (8), -9.36361 (8), -9.29917 (8), -9.23903 (8), -9.22180 (8), -9.16990 (8), -9.16816 (8), -9.16331 (8), -9.13894 (8), 
length of domains: 256
Total time: 1.0802	 pickout: 0.0054	 decision: 0.1153	 get_bound: 0.9395	 add_domain: 0.0200
Accumulated time:	 pickout: 0.0119	 decision: 0.2638	 get_bound: 3.4202	 add_domain: 0.0495
Current (lb-rhs): -9.908815383911133
0 domains visited
Cumulative time: 15.133156776428223

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 8, 15, 15]) pre split depth:  1
batch:  torch.Size([256, 8, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 15] [3, 15] [3, 15] [3, 15] [3, 15] [3, 15] [3, 15] [3, 15] [3, 15] [3, 15] 
regular batch size: 2*256, diving batch size 1*0
(512, 3, 32, 32) torch.Size([512, 9, 10]) torch.Size([512, 9])
best_l after optimization: -59461.703125 with beta sum per layer: [0.0, 0.0, 0.0, 773.3990478515625]
alpha/beta optimization time: 1.6883397102355957
pruning_in_iteration open status: False
ratio of positive domain = 0 / 512 = 0.0
pruning-in-iteration extra time: 0.0001308917999267578
Tensors transferred: pre=2.5078M lA=11.2852M alpha=9.1230M beta=0.0044M
This batch time : update_bounds func: 1.7984	 prepare: 0.0422	 bound: 1.6888	 transfer: 0.0533	 finalize: 0.0128
Accumulated time: update_bounds func: 5.2138	 prepare: 0.0901	 bound: 4.9985	 transfer: 0.0980	 finalize: 0.0250
batch bounding time:  1.7986388206481934
Current worst splitting domains lb-rhs (depth):
-9.74905 (9), -9.65955 (9), -9.62285 (9), -9.50617 (9), -9.40944 (9), -9.37518 (9), -9.36576 (9), -9.33219 (9), -9.28616 (9), -9.25912 (9), -9.25650 (9), -9.25215 (9), -9.24724 (9), -9.24214 (9), -9.20880 (9), -9.19860 (9), -9.08886 (9), -9.07788 (9), -9.05642 (9), -9.02133 (9), 
length of domains: 512
Total time: 2.0519	 pickout: 0.0103	 decision: 0.2057	 get_bound: 1.7987	 add_domain: 0.0373
Accumulated time:	 pickout: 0.0221	 decision: 0.4695	 get_bound: 5.2189	 add_domain: 0.0867
Current (lb-rhs): -9.749049186706543
0 domains visited
Cumulative time: 17.187531232833862

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 8, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 8, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 36] [3, 36] [3, 36] [3, 36] [3, 36] [3, 36] [3, 36] [3, 36] [3, 36] [3, 36] 
regular batch size: 2*512, diving batch size 1*0
(1024, 3, 32, 32) torch.Size([1024, 9, 10]) torch.Size([1024, 9])
best_l after optimization: -114051.1875 with beta sum per layer: [0.0, 0.0, 0.0, 1903.6868896484375]
alpha/beta optimization time: 3.2076711654663086
pruning_in_iteration open status: False
ratio of positive domain = 0 / 1024 = 0.0
pruning-in-iteration extra time: 0.00016379356384277344
Tensors transferred: pre=5.0156M lA=22.5703M alpha=18.2461M beta=0.0098M
This batch time : update_bounds func: 3.3936	 prepare: 0.0831	 bound: 3.2082	 transfer: 0.0767	 finalize: 0.0239
Accumulated time: update_bounds func: 8.6074	 prepare: 0.1732	 bound: 8.2068	 transfer: 0.1747	 finalize: 0.0489
batch bounding time:  3.393848419189453
Current worst splitting domains lb-rhs (depth):
-9.21805 (10), -9.20719 (10), -8.92593 (10), -8.90593 (10), -8.86810 (10), -8.76322 (10), -8.72521 (10), -8.71504 (10), -8.64749 (10), -8.64208 (10), -8.62060 (10), -8.59860 (10), -8.58356 (10), -8.54904 (10), -8.53343 (10), -8.50808 (10), -8.49228 (10), -8.44560 (10), -8.43669 (10), -8.42101 (10), 
length of domains: 1024
Total time: 3.9045	 pickout: 0.0199	 decision: 0.4198	 get_bound: 3.3939	 add_domain: 0.0708
Accumulated time:	 pickout: 0.0421	 decision: 0.8893	 get_bound: 8.6129	 add_domain: 0.1575
Current (lb-rhs): -9.218045234680176
0 domains visited
Cumulative time: 21.095179080963135

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 8, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 8, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 1] [3, 1] [3, 1] [3, 1] [3, 1] [3, 1] [3, 50] [3, 1] [3, 1] [3, 1] 
regular batch size: 2*512, diving batch size 1*0
(1024, 3, 32, 32) torch.Size([1024, 9, 10]) torch.Size([1024, 9])
best_l after optimization: -107767.296875 with beta sum per layer: [0.0, 0.0, 0.0, 1856.271728515625]
alpha/beta optimization time: 3.2117581367492676
pruning_in_iteration open status: False
ratio of positive domain = 0 / 1024 = 0.0
pruning-in-iteration extra time: 0.00014853477478027344
Tensors transferred: pre=5.0156M lA=22.5703M alpha=18.2461M beta=0.0107M
This batch time : update_bounds func: 3.3866	 prepare: 0.0827	 bound: 3.2123	 transfer: 0.0663	 finalize: 0.0238
Accumulated time: update_bounds func: 11.9940	 prepare: 0.2559	 bound: 11.4190	 transfer: 0.2410	 finalize: 0.0727
batch bounding time:  3.3868608474731445
Current worst splitting domains lb-rhs (depth):
-9.21805 (10), -9.20719 (10), -8.92593 (10), -8.90593 (10), -8.86810 (10), -8.76322 (10), -8.72521 (10), -8.71504 (10), -8.64749 (10), -8.64208 (10), -8.62060 (10), -8.59860 (10), -8.58356 (10), -8.54904 (10), -8.53343 (10), -8.50808 (10), -8.49228 (10), -8.44560 (10), -8.43669 (10), -8.42101 (10), 
length of domains: 1536
Total time: 4.0402	 pickout: 0.0193	 decision: 0.3989	 get_bound: 3.3869	 add_domain: 0.2351
Accumulated time:	 pickout: 0.0614	 decision: 1.2882	 get_bound: 11.9998	 add_domain: 0.3926
Current (lb-rhs): -9.218045234680176
0 domains visited
Cumulative time: 25.138823986053467

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 8, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 8, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 50] [3, 53] [3, 50] [3, 50] [3, 50] [3, 50] [3, 1] [3, 50] [3, 50] [3, 53] 
regular batch size: 2*512, diving batch size 1*0
(1024, 3, 32, 32) torch.Size([1024, 9, 10]) torch.Size([1024, 9])
best_l after optimization: -95704.53125 with beta sum per layer: [0.0, 0.0, 0.0, 2304.256103515625]
alpha/beta optimization time: 3.2168900966644287
pruning_in_iteration open status: False
ratio of positive domain = 0 / 1024 = 0.0
pruning-in-iteration extra time: 0.000133514404296875
Tensors transferred: pre=5.0156M lA=22.5703M alpha=18.2461M beta=0.0117M
This batch time : update_bounds func: 3.3935	 prepare: 0.0836	 bound: 3.2174	 transfer: 0.0668	 finalize: 0.0241
Accumulated time: update_bounds func: 15.3875	 prepare: 0.3395	 bound: 14.6364	 transfer: 0.3078	 finalize: 0.0967
batch bounding time:  3.393751621246338
Current worst splitting domains lb-rhs (depth):
-9.21805 (10), -9.20719 (10), -8.92593 (10), -8.90593 (10), -8.86810 (10), -8.76322 (10), -8.72521 (10), -8.71504 (10), -8.64749 (10), -8.64208 (10), -8.62060 (10), -8.59860 (10), -8.58356 (10), -8.54904 (10), -8.53343 (10), -8.50808 (10), -8.49228 (10), -8.44560 (10), -8.43669 (10), -8.42101 (10), 
length of domains: 2048
Total time: 3.9273	 pickout: 0.0201	 decision: 0.3858	 get_bound: 3.3938	 add_domain: 0.1277
Accumulated time:	 pickout: 0.0815	 decision: 1.6739	 get_bound: 15.3936	 add_domain: 0.5203
Current (lb-rhs): -9.218045234680176
0 domains visited
Cumulative time: 29.069879055023193

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 8, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 8, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 10] [3, 10] [3, 10] [3, 10] [3, 10] [3, 10] [3, 10] [3, 10] [3, 10] [3, 10] 
regular batch size: 2*512, diving batch size 1*0
(1024, 3, 32, 32) torch.Size([1024, 9, 10]) torch.Size([1024, 9])
best_l after optimization: -86287.3984375 with beta sum per layer: [0.0, 0.0, 0.0, 2728.329345703125]
alpha/beta optimization time: 3.219379186630249
pruning_in_iteration open status: False
ratio of positive domain = 0 / 1024 = 0.0
pruning-in-iteration extra time: 0.000125885009765625
Tensors transferred: pre=5.0156M lA=22.5703M alpha=18.2461M beta=0.0127M
This batch time : update_bounds func: 3.3967	 prepare: 0.0836	 bound: 3.2199	 transfer: 0.0665	 finalize: 0.0252
Accumulated time: update_bounds func: 18.7842	 prepare: 0.4232	 bound: 17.8563	 transfer: 0.3743	 finalize: 0.1219
batch bounding time:  3.3969225883483887
Current worst splitting domains lb-rhs (depth):
-9.21805 (10), -9.20719 (10), -8.92593 (10), -8.90593 (10), -8.86810 (10), -8.76322 (10), -8.72521 (10), -8.71504 (10), -8.64749 (10), -8.64208 (10), -8.62060 (10), -8.59860 (10), -8.58356 (10), -8.54904 (10), -8.53343 (10), -8.50808 (10), -8.49228 (10), -8.44560 (10), -8.43669 (10), -8.42101 (10), 
length of domains: 2560
Total time: 4.1794	 pickout: 0.0196	 decision: 0.3866	 get_bound: 3.3970	 add_domain: 0.3762
Accumulated time:	 pickout: 0.1011	 decision: 2.0606	 get_bound: 18.7906	 add_domain: 0.8965
Current (lb-rhs): -9.218045234680176
0 domains visited
Cumulative time: 33.25328779220581

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 8, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 8, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 53] [3, 50] [3, 26] [3, 26] [3, 53] [3, 53] [3, 26] [3, 26] [3, 53] [3, 50] 
regular batch size: 2*512, diving batch size 1*0
(1024, 3, 32, 32) torch.Size([1024, 9, 10]) torch.Size([1024, 9])
best_l after optimization: -80622.8125 with beta sum per layer: [0.0, 0.0, 0.0, 2971.33740234375]
alpha/beta optimization time: 3.218355655670166
pruning_in_iteration open status: False
ratio of positive domain = 0 / 1024 = 0.0
pruning-in-iteration extra time: 0.00015115737915039062
Tensors transferred: pre=5.0156M lA=22.5703M alpha=18.2461M beta=0.0137M
This batch time : update_bounds func: 3.4111	 prepare: 0.0843	 bound: 3.2189	 transfer: 0.0806	 finalize: 0.0256
Accumulated time: update_bounds func: 22.1952	 prepare: 0.5075	 bound: 21.0752	 transfer: 0.4548	 finalize: 0.1475
batch bounding time:  3.4114482402801514
Current worst splitting domains lb-rhs (depth):
-9.21805 (10), -9.20719 (10), -8.92593 (10), -8.90593 (10), -8.86810 (10), -8.76322 (10), -8.72521 (10), -8.71504 (10), -8.64749 (10), -8.64208 (10), -8.62060 (10), -8.59860 (10), -8.58356 (10), -8.54904 (10), -8.53343 (10), -8.50808 (10), -8.49228 (10), -8.44560 (10), -8.43669 (10), -8.42101 (10), 
length of domains: 3072
Total time: 3.9226	 pickout: 0.0203	 decision: 0.3952	 get_bound: 3.4115	 add_domain: 0.0956
Accumulated time:	 pickout: 0.1213	 decision: 2.4557	 get_bound: 22.2021	 add_domain: 0.9921
Current (lb-rhs): -9.218045234680176
0 domains visited
Cumulative time: 37.1818482875824

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 8, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 8, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 26] [3, 26] [3, 53] [3, 53] [3, 26] [3, 26] [3, 53] [3, 53] [3, 26] [3, 26] 
regular batch size: 2*512, diving batch size 1*0
(1024, 3, 32, 32) torch.Size([1024, 9, 10]) torch.Size([1024, 9])
best_l after optimization: -75652.25 with beta sum per layer: [0.0, 0.0, 0.0, 2999.169677734375]
alpha/beta optimization time: 3.2188642024993896
pruning_in_iteration open status: False
ratio of positive domain = 0 / 1024 = 0.0
pruning-in-iteration extra time: 0.0001385211944580078
Tensors transferred: pre=5.0156M lA=22.5703M alpha=18.2461M beta=0.0146M
This batch time : update_bounds func: 3.4047	 prepare: 0.0912	 bound: 3.2195	 transfer: 0.0665	 finalize: 0.0259
Accumulated time: update_bounds func: 25.5999	 prepare: 0.5987	 bound: 24.2947	 transfer: 0.5213	 finalize: 0.1734
batch bounding time:  3.4049770832061768
Current worst splitting domains lb-rhs (depth):
-9.21805 (10), -9.20719 (10), -8.92593 (10), -8.90593 (10), -8.86810 (10), -8.76322 (10), -8.72521 (10), -8.71504 (10), -8.64749 (10), -8.64208 (10), -8.62060 (10), -8.59860 (10), -8.58356 (10), -8.54904 (10), -8.53343 (10), -8.50808 (10), -8.49228 (10), -8.44560 (10), -8.43669 (10), -8.42101 (10), 
length of domains: 3584
Total time: 3.9135	 pickout: 0.0198	 decision: 0.4025	 get_bound: 3.4051	 add_domain: 0.0860
Accumulated time:	 pickout: 0.1412	 decision: 2.8583	 get_bound: 25.6072	 add_domain: 1.0782
Current (lb-rhs): -9.218045234680176
0 domains visited
Cumulative time: 41.099977254867554

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 8, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 8, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 35] [3, 35] [3, 35] [3, 35] [3, 35] [3, 35] [3, 35] [3, 35] [3, 35] [3, 35] 
regular batch size: 2*512, diving batch size 1*0
(1024, 3, 32, 32) torch.Size([1024, 9, 10]) torch.Size([1024, 9])
best_l after optimization: -69652.3125 with beta sum per layer: [0.0, 0.0, 0.0, 2816.4609375]
alpha/beta optimization time: 3.216146230697632
pruning_in_iteration open status: False
ratio of positive domain = 0 / 1024 = 0.0
pruning-in-iteration extra time: 0.0001404285430908203
Tensors transferred: pre=5.0156M lA=22.5703M alpha=18.2461M beta=0.0166M
This batch time : update_bounds func: 3.3979	 prepare: 0.0875	 bound: 3.2167	 transfer: 0.0668	 finalize: 0.0253
Accumulated time: update_bounds func: 28.9978	 prepare: 0.6862	 bound: 27.5114	 transfer: 0.5881	 finalize: 0.1988
batch bounding time:  3.398160457611084
Current worst splitting domains lb-rhs (depth):
-9.21805 (10), -9.20719 (10), -8.92593 (10), -8.90593 (10), -8.86810 (10), -8.76322 (10), -8.72521 (10), -8.71504 (10), -8.64749 (10), -8.64208 (10), -8.62060 (10), -8.59860 (10), -8.58356 (10), -8.54904 (10), -8.53343 (10), -8.50808 (10), -8.49228 (10), -8.44560 (10), -8.43669 (10), -8.42101 (10), 
length of domains: 4096
Total time: 3.9745	 pickout: 0.0211	 decision: 0.3867	 get_bound: 3.3982	 add_domain: 0.1685
Accumulated time:	 pickout: 0.1622	 decision: 3.2449	 get_bound: 29.0054	 add_domain: 1.2467
Current (lb-rhs): -9.218045234680176
0 domains visited
Cumulative time: 45.078946590423584

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 8, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 8, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 0] [3, 0] [3, 0] [3, 0] [3, 0] [3, 0] [3, 0] [3, 0] [3, 0] [3, 0] 
regular batch size: 2*512, diving batch size 1*0
(1024, 3, 32, 32) torch.Size([1024, 9, 10]) torch.Size([1024, 9])
best_l after optimization: -63667.7421875 with beta sum per layer: [0.0, 0.0, 0.0, 2652.214111328125]
alpha/beta optimization time: 3.2140090465545654
pruning_in_iteration open status: False
ratio of positive domain = 0 / 1024 = 0.0
pruning-in-iteration extra time: 0.0001304149627685547
Tensors transferred: pre=5.0156M lA=22.5703M alpha=18.2461M beta=0.0176M
This batch time : update_bounds func: 3.4000	 prepare: 0.0883	 bound: 3.2145	 transfer: 0.0697	 finalize: 0.0259
Accumulated time: update_bounds func: 32.3978	 prepare: 0.7745	 bound: 30.7259	 transfer: 0.6579	 finalize: 0.2247
batch bounding time:  3.4002575874328613
Current worst splitting domains lb-rhs (depth):
-9.21805 (10), -9.20719 (10), -8.92593 (10), -8.90593 (10), -8.86810 (10), -8.76322 (10), -8.72521 (10), -8.71504 (10), -8.64749 (10), -8.64208 (10), -8.62060 (10), -8.59860 (10), -8.58356 (10), -8.54904 (10), -8.53343 (10), -8.50808 (10), -8.49228 (10), -8.44560 (10), -8.43669 (10), -8.42101 (10), 
length of domains: 4608
Total time: 4.4822	 pickout: 0.0198	 decision: 0.3867	 get_bound: 3.4003	 add_domain: 0.6753
Accumulated time:	 pickout: 0.1821	 decision: 3.6316	 get_bound: 32.4057	 add_domain: 1.9220
Current (lb-rhs): -9.218045234680176
0 domains visited
Cumulative time: 49.56561088562012

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 8, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 8, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 52] [3, 52] [3, 63] [3, 52] [3, 63] [3, 63] [3, 52] [3, 52] [3, 63] [3, 52] 
regular batch size: 2*512, diving batch size 1*0
(1024, 3, 32, 32) torch.Size([1024, 9, 10]) torch.Size([1024, 9])
best_l after optimization: -60100.5546875 with beta sum per layer: [0.0, 0.0, 6.3329925537109375, 2668.63818359375]
alpha/beta optimization time: 3.2290709018707275
pruning_in_iteration open status: False
ratio of positive domain = 0 / 1024 = 0.0
pruning-in-iteration extra time: 0.0001373291015625
Tensors transferred: pre=5.0156M lA=22.5703M alpha=18.2461M beta=0.0186M
This batch time : update_bounds func: 3.4138	 prepare: 0.0862	 bound: 3.2296	 transfer: 0.0701	 finalize: 0.0262
Accumulated time: update_bounds func: 35.8116	 prepare: 0.8608	 bound: 33.9554	 transfer: 0.7280	 finalize: 0.2509
batch bounding time:  3.4141223430633545
Current worst splitting domains lb-rhs (depth):
-9.21805 (10), -9.20719 (10), -8.92593 (10), -8.90593 (10), -8.86810 (10), -8.76322 (10), -8.72521 (10), -8.71504 (10), -8.64749 (10), -8.64208 (10), -8.62060 (10), -8.59860 (10), -8.58356 (10), -8.54904 (10), -8.53343 (10), -8.50808 (10), -8.49228 (10), -8.44560 (10), -8.43669 (10), -8.42101 (10), 
length of domains: 5120
Total time: 3.9284	 pickout: 0.0211	 decision: 0.4025	 get_bound: 3.4142	 add_domain: 0.0906
Accumulated time:	 pickout: 0.2032	 decision: 4.0341	 get_bound: 35.8199	 add_domain: 2.0126
Current (lb-rhs): -9.218045234680176
0 domains visited
Cumulative time: 53.49820613861084

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 8, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 8, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 63] [3, 63] [3, 52] [3, 63] [3, 52] [3, 52] [3, 63] [3, 63] [3, 52] [3, 63] 
regular batch size: 2*512, diving batch size 1*0
(1024, 3, 32, 32) torch.Size([1024, 9, 10]) torch.Size([1024, 9])
best_l after optimization: -56451.5625 with beta sum per layer: [0.0, 0.0, 3.3047280311584473, 2884.0048828125]
alpha/beta optimization time: 3.2173898220062256
pruning_in_iteration open status: False
ratio of positive domain = 0 / 1024 = 0.0
pruning-in-iteration extra time: 0.00013685226440429688
Tensors transferred: pre=5.0156M lA=22.5703M alpha=18.2461M beta=0.0205M
This batch time : update_bounds func: 3.4088	 prepare: 0.0894	 bound: 3.2179	 transfer: 0.0738	 finalize: 0.0261
Accumulated time: update_bounds func: 39.2204	 prepare: 0.9501	 bound: 37.1734	 transfer: 0.8018	 finalize: 0.2770
batch bounding time:  3.409188985824585
Current worst splitting domains lb-rhs (depth):
-9.21805 (10), -9.20719 (10), -8.92593 (10), -8.90593 (10), -8.86810 (10), -8.76322 (10), -8.72521 (10), -8.71504 (10), -8.64749 (10), -8.64208 (10), -8.62060 (10), -8.59860 (10), -8.58356 (10), -8.54904 (10), -8.53343 (10), -8.50808 (10), -8.49228 (10), -8.44560 (10), -8.43669 (10), -8.42101 (10), 
length of domains: 5632
Total time: 3.9820	 pickout: 0.0197	 decision: 0.3889	 get_bound: 3.4093	 add_domain: 0.1640
Accumulated time:	 pickout: 0.2229	 decision: 4.4230	 get_bound: 39.2292	 add_domain: 2.1767
Current (lb-rhs): -9.218045234680176
0 domains visited
Cumulative time: 57.48432111740112

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 8, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 8, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 9] [3, 13] [3, 13] [3, 13] [3, 9] [3, 13] [3, 28] [3, 28] [3, 61] [3, 29] 
regular batch size: 2*512, diving batch size 1*0
(1024, 3, 32, 32) torch.Size([1024, 9, 10]) torch.Size([1024, 9])
best_l after optimization: -52747.77734375 with beta sum per layer: [0.0, 0.0, 18.417316436767578, 3274.986328125]
alpha/beta optimization time: 3.231377601623535
pruning_in_iteration open status: False
ratio of positive domain = 0 / 1024 = 0.0
pruning-in-iteration extra time: 0.00012731552124023438
Tensors transferred: pre=5.0156M lA=22.5703M alpha=18.2461M beta=0.0225M
This batch time : update_bounds func: 3.4181	 prepare: 0.0878	 bound: 3.2319	 transfer: 0.0699	 finalize: 0.0269
Accumulated time: update_bounds func: 42.6385	 prepare: 1.0379	 bound: 40.4053	 transfer: 0.8717	 finalize: 0.3039
batch bounding time:  3.4183969497680664
Current worst splitting domains lb-rhs (depth):
-9.21805 (10), -9.20719 (10), -8.92593 (10), -8.90593 (10), -8.86810 (10), -8.76322 (10), -8.72521 (10), -8.71504 (10), -8.64749 (10), -8.64208 (10), -8.62060 (10), -8.59860 (10), -8.58356 (10), -8.54904 (10), -8.53343 (10), -8.50808 (10), -8.49228 (10), -8.44560 (10), -8.43669 (10), -8.42101 (10), 
length of domains: 6144
Total time: 3.9200	 pickout: 0.0197	 decision: 0.3872	 get_bound: 3.4185	 add_domain: 0.0947
Accumulated time:	 pickout: 0.2426	 decision: 4.8102	 get_bound: 42.6476	 add_domain: 2.2713
Current (lb-rhs): -9.218045234680176
0 domains visited
Cumulative time: 61.40859365463257

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 8, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 8, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 21] [2, 24] [2, 95] [3, 28] [3, 21] [3, 28] [2, 67] [3, 9] [3, 57] [3, 28] 
regular batch size: 2*512, diving batch size 1*0
(1024, 3, 32, 32) torch.Size([1024, 9, 10]) torch.Size([1024, 9])
best_l after optimization: -48606.40625 with beta sum per layer: [0.0, 0.0, 14.046957969665527, 3990.025390625]
alpha/beta optimization time: 3.2212772369384766
pruning_in_iteration open status: False
ratio of positive domain = 0 / 1024 = 0.0
pruning-in-iteration extra time: 0.00013065338134765625
Tensors transferred: pre=5.0156M lA=22.5703M alpha=18.2461M beta=0.0244M
This batch time : update_bounds func: 3.4071	 prepare: 0.0870	 bound: 3.2218	 transfer: 0.0699	 finalize: 0.0268
Accumulated time: update_bounds func: 46.0456	 prepare: 1.1248	 bound: 43.6271	 transfer: 0.9416	 finalize: 0.3307
batch bounding time:  3.40734601020813
Current worst splitting domains lb-rhs (depth):
-9.21805 (10), -9.20719 (10), -8.92593 (10), -8.90593 (10), -8.86810 (10), -8.76322 (10), -8.72521 (10), -8.71504 (10), -8.64749 (10), -8.64208 (10), -8.62060 (10), -8.59860 (10), -8.58356 (10), -8.54904 (10), -8.53343 (10), -8.50808 (10), -8.49228 (10), -8.44560 (10), -8.43669 (10), -8.42101 (10), 
length of domains: 6656
Total time: 3.9403	 pickout: 0.0197	 decision: 0.4135	 get_bound: 3.4074	 add_domain: 0.0996
Accumulated time:	 pickout: 0.2624	 decision: 5.2238	 get_bound: 46.0551	 add_domain: 2.3709
Current (lb-rhs): -9.218045234680176
0 domains visited
Cumulative time: 65.35299324989319

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 8, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 8, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 56] [2, 126] [2, 24] [2, 24] [2, 56] [3, 3] [3, 61] [2, 84] [3, 9] [3, 9] 
regular batch size: 2*512, diving batch size 1*0
(1024, 3, 32, 32) torch.Size([1024, 9, 10]) torch.Size([1024, 9])
best_l after optimization: -44380.5546875 with beta sum per layer: [0.0, 0.0, 63.92605209350586, 5243.75390625]
alpha/beta optimization time: 3.2223188877105713
pruning_in_iteration open status: False
ratio of positive domain = 1 / 1024 = 0.0009765625
pruning-in-iteration extra time: 0.00015473365783691406
Tensors transferred: pre=5.0156M lA=22.5703M alpha=18.2461M beta=0.0264M
This batch time : update_bounds func: 3.4114	 prepare: 0.0877	 bound: 3.2229	 transfer: 0.0721	 finalize: 0.0270
Accumulated time: update_bounds func: 49.4570	 prepare: 1.2126	 bound: 46.8499	 transfer: 1.0138	 finalize: 0.3577
batch bounding time:  3.4116506576538086
Current worst splitting domains lb-rhs (depth):
-9.21805 (10), -9.20719 (10), -8.92593 (10), -8.90593 (10), -8.86810 (10), -8.76322 (10), -8.72521 (10), -8.71504 (10), -8.64749 (10), -8.64208 (10), -8.62060 (10), -8.59860 (10), -8.58356 (10), -8.54904 (10), -8.53343 (10), -8.50808 (10), -8.49228 (10), -8.44560 (10), -8.43669 (10), -8.42101 (10), 
length of domains: 7167
Total time: 3.9207	 pickout: 0.0201	 decision: 0.3882	 get_bound: 3.4117	 add_domain: 0.1007
Accumulated time:	 pickout: 0.2824	 decision: 5.6120	 get_bound: 49.4668	 add_domain: 2.4716
Current (lb-rhs): -9.218045234680176
1 domains visited
Cumulative time: 69.27926898002625

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 8, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 8, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 61] [2, 95] [2, 111] [3, 9] [3, 3] [3, 21] [3, 13] [2, 73] [3, 21] [3, 3] 
regular batch size: 2*512, diving batch size 1*0
(1024, 3, 32, 32) torch.Size([1024, 9, 10]) torch.Size([1024, 9])
best_l after optimization: -39824.421875 with beta sum per layer: [0.0, 0.0, 266.6666259765625, 7905.330078125]
alpha/beta optimization time: 3.2212610244750977
pruning_in_iteration open status: False
ratio of positive domain = 18 / 1024 = 0.017578125
pruning-in-iteration extra time: 0.000156402587890625
Tensors transferred: pre=5.0156M lA=22.5703M alpha=18.2461M beta=0.0283M
This batch time : update_bounds func: 3.4078	 prepare: 0.0879	 bound: 3.2218	 transfer: 0.0698	 finalize: 0.0269
Accumulated time: update_bounds func: 52.8648	 prepare: 1.3004	 bound: 50.0717	 transfer: 1.0835	 finalize: 0.3846
batch bounding time:  3.4081103801727295
Current worst splitting domains lb-rhs (depth):
-9.21805 (10), -9.20719 (10), -8.92593 (10), -8.90593 (10), -8.86810 (10), -8.76322 (10), -8.72521 (10), -8.71504 (10), -8.64749 (10), -8.64208 (10), -8.62060 (10), -8.59860 (10), -8.58356 (10), -8.54904 (10), -8.53343 (10), -8.50808 (10), -8.49228 (10), -8.44560 (10), -8.43669 (10), -8.42101 (10), 
length of domains:/home/zhouxingshi/onnx2pytorch/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)
  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))
/home/zhouxingshi/onnx2pytorch/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  "Using experimental implementation that allows 'batch_size > 1'."
 7661
Total time: 4.0010	 pickout: 0.0199	 decision: 0.4701	 get_bound: 3.4082	 add_domain: 0.1028
Accumulated time:	 pickout: 0.3023	 decision: 6.0821	 get_bound: 52.8749	 add_domain: 2.5744
Current (lb-rhs): -9.218045234680176
19 domains visited
Time out!!!!!!!!
Result: unknown in 75.9979 seconds
############# Summary #############
Final verified acc: 0.0% [total 1 examples]
Total verification count: 1 , total verified safe: 0 , verified unsafe: 0 , timeout: 1
mean time (bab) [total:1]: 73.88107228279114
mean time [1] 75.9978699684143 max time 75.9978699684143
unknown (total 1): [0]
