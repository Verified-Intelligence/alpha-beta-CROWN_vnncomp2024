Building native CUDA modules...
/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
  csv_name: marabou-cifar10_instances.csv
  onnx_path: null
  vnnlib_path: null
  results_file: null
  root_path: ../../../../../vnncomp2021/benchmarks/marabou-cifar10
model:
  path: null
  name: mnist_9_200
data:
  start: 2
  end: 3
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR
  data_filter_path: null
specification:
  type: lp
  norm: .inf
  epsilon: null
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 1000
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.5
    lr_decay: 0.98
    optimizer: adam
    iteration: 50
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 360
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 5
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:23:21 2022 on ubuntu
saving results to vnn-comp_[marabou-cifar10_instances]_start=2_end=3_iter=50_b=1000_timeout=360_branching=kfsb-min-5_lra-init=0.1_lra=0.01_lrb=0.5_PGD=skip.npz
customized start/end sample from 2 to 3

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Notice: this ONNX file has NHWC order. We assume the X in vnnlib is also flattend in in NHWC order (1, 32, 32, 3)
[-2.019291   -3.6977699   0.15410781  1.1025418  -2.512028    1.3025895
 -1.7043635  -0.8002742   0.34066036 -1.2210718 ]
Model prediction is: tensor([[-2.0193, -3.6978,  0.1541,  1.1025, -2.5120,  1.3026, -1.7044, -0.8003,
          0.3407, -1.2211]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-125.2940, -136.8795, -122.6586,  -76.6990, -107.9738, -128.1958,
          -94.7283, -137.9840, -126.6147]], device='cuda:0') None
best_l after optimization: 782.505126953125 with beta sum per layer: []
alpha/beta optimization time: 10.755410432815552
initial alpha-CROWN bounds: tensor([[-100.0045,  -93.9476,  -89.5742,  -60.3139,  -79.3111,  -87.4855,
          -73.4933, -104.5150,  -93.8600]], device='cuda:0',
       grad_fn=<AsStridedBackward>)
worst class: tensor(-104.5150, device='cuda:0', grad_fn=<MinBackward1>)
##### [0] True label: 5, Tested against: 3, onnx_path: ./nets/cifar10_large.onnx, vnnlib_path: ./specs/networkcifar10_large_index4089_eps0.012_target6_orig5.vnnlib ######
Model prediction is: tensor([[-2.0193, -3.6978,  0.1541,  1.1025, -2.5120,  1.3026, -1.7044, -0.8003,
          0.3407, -1.2211]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /12 start_node /13
setting alpha for layer /12 start_node /16
setting alpha for layer /12 start_node /18
not setting layer /12 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 32, 15, 15]) != torch.Size([2, 9, 1, 32, 15, 15]))
setting alpha for layer /14 start_node /16
setting alpha for layer /14 start_node /18
not setting layer /14 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 64, 6, 6]) != torch.Size([2, 9, 1, 64, 6, 6]))
setting alpha for layer /17 start_node /18
not setting layer /17 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 128]) != torch.Size([2, 9, 1, 128]))
not setting layer /19 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 64]) != torch.Size([2, 9, 1, 64]))
0 /11 torch.Size([1, 32, 15, 15])
1 /13 torch.Size([1, 64, 6, 6])
2 /16 torch.Size([1, 128])
3 /18 torch.Size([1, 64])
best_l after optimization: 60.31293869018555 with beta sum per layer: []
alpha/beta optimization time: 2.0039796829223633
alpha-CROWN with fixed intermediate bounds: tensor([[-60.3129]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-60.31293869018555
layer 0 size torch.Size([7200]) unstable 1932
layer 1 size torch.Size([2304]) unstable 1152
layer 2 size torch.Size([128]) unstable 128
layer 3 size torch.Size([64]) unstable 64
-----------------
# of unstable neurons: 3276
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 15, 15]) pre split depth:  6
batch:  torch.Size([1, 32, 15, 15]) post split depth:  6
splitting decisions: 
split level 0: [3, 60] 
split level 1: [3, 14] 
split level 2: [3, 61] 
split level 3: [3, 50] 
split level 4: [3, 59] 
split level 5: [3, 16] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: 2649.999267578125 with beta sum per layer: [0.0, 0.0, 0.0, 27.032442092895508]
alpha/beta optimization time: 0.684730052947998
This batch time : update_bounds func: 0.7026	 prepare: 0.0063	 bound: 0.6850	 transfer: 0.0062	 finalize: 0.0049
Accumulated time: update_bounds func: 0.7026	 prepare: 0.0063	 bound: 0.6850	 transfer: 0.0062	 finalize: 0.0049
batch bounding time:  0.7028591632843018
Current worst splitting domains [lb, ub] (depth):
[-48.70913,   inf] (7), [-47.73587,   inf] (7), [-47.57957,   inf] (7), [-47.15453,   inf] (7), [-47.09599,   inf] (7), [-46.35880,   inf] (7), [-46.33281,   inf] (7), [-45.90443,   inf] (7), [-45.15788,   inf] (7), [-44.99017,   inf] (7), [-44.08487,   inf] (7), [-44.07071,   inf] (7), [-43.97075,   inf] (7), [-43.95692,   inf] (7), [-43.87411,   inf] (7), [-43.69719,   inf] (7), [-43.65882,   inf] (7), [-43.63795,   inf] (7), [-43.56909,   inf] (7), [-43.37555,   inf] (7), 
length of domains: 64
Total time: 0.7532	 pickout: 0.0010	 decision: 0.0382	 get_bound: 0.7111	 add_domain: 0.0029
Current lb:-48.70912551879883
64 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.694891929626465

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([64, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 23] [3, 23] [3, 23] [3, 23] [3, 18] [3, 23] [3, 23] [3, 23] [3, 23] [3, 23] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5000.8017578125 with beta sum per layer: [0.0, 0.0, 0.0, 59.61444091796875]
alpha/beta optimization time: 0.7157595157623291
This batch time : update_bounds func: 0.7556	 prepare: 0.0132	 bound: 0.7161	 transfer: 0.0166	 finalize: 0.0093
Accumulated time: update_bounds func: 1.4582	 prepare: 0.0195	 bound: 1.4011	 transfer: 0.0166	 finalize: 0.0142
batch bounding time:  0.7558526992797852
Current worst splitting domains [lb, ub] (depth):
[-46.44859,   inf] (9), [-46.42817,   inf] (9), [-45.57007,   inf] (9), [-45.54353,   inf] (9), [-45.52365,   inf] (9), [-45.42619,   inf] (9), [-45.20491,   inf] (9), [-45.03962,   inf] (9), [-45.00712,   inf] (9), [-44.20610,   inf] (9), [-44.09957,   inf] (9), [-44.05314,   inf] (9), [-43.90076,   inf] (9), [-43.74927,   inf] (9), [-43.48657,   inf] (9), [-43.20245,   inf] (9), [-42.93941,   inf] (9), [-42.92152,   inf] (9), [-42.88176,   inf] (9), [-42.67438,   inf] (9), 
length of domains: 128
Total time: 0.8307	 pickout: 0.0129	 decision: 0.0558	 get_bound: 0.7561	 add_domain: 0.0059
Current lb:-46.448585510253906
192 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.527023553848267

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([128, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([128, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 18] [3, 35] [3, 35] [3, 35] [3, 29] [3, 35] [3, 23] [3, 29] [3, 35] [3, 23] 
regular batch size: 2*128, diving batch size 1*0
best_l after optimization: 9439.666015625 with beta sum per layer: [0.0, 0.0, 0.0, 141.41921997070312]
alpha/beta optimization time: 0.8484632968902588
This batch time : update_bounds func: 0.9224	 prepare: 0.0251	 bound: 0.8488	 transfer: 0.0290	 finalize: 0.0189
Accumulated time: update_bounds func: 2.3806	 prepare: 0.0446	 bound: 2.2499	 transfer: 0.0290	 finalize: 0.0331
batch bounding time:  0.922809362411499
Current worst splitting domains [lb, ub] (depth):
[-44.74896,   inf] (11), [-44.72704,   inf] (11), [-44.65162,   inf] (11), [-44.02998,   inf] (11), [-43.91326,   inf] (11), [-43.89477,   inf] (11), [-43.78566,   inf] (11), [-43.73847,   inf] (11), [-43.73240,   inf] (11), [-43.69131,   inf] (11), [-43.46878,   inf] (11), [-43.40277,   inf] (11), [-43.36625,   inf] (11), [-43.20001,   inf] (11), [-43.18911,   inf] (11), [-43.06372,   inf] (11), [-42.41586,   inf] (11), [-42.27530,   inf] (11), [-42.24697,   inf] (11), [-42.16364,   inf] (11), 
length of domains: 256
Total time: 1.0426	 pickout: 0.0255	 decision: 0.0815	 get_bound: 0.9232	 add_domain: 0.0124
Current lb:-44.74896240234375
448 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.57213568687439

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([256, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 18] [3, 18] [3, 35] [3, 29] [3, 35] [3, 31] [3, 31] [3, 29] [3, 29] [3, 29] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 17745.109375 with beta sum per layer: [0.0, 0.0, 0.0, 356.20843505859375]
alpha/beta optimization time: 1.174072265625
This batch time : update_bounds func: 1.3666	 prepare: 0.0488	 bound: 1.1745	 transfer: 0.0532	 finalize: 0.0890
Accumulated time: update_bounds func: 3.7472	 prepare: 0.0934	 bound: 3.4243	 transfer: 0.0532	 finalize: 0.1222
batch bounding time:  1.3673720359802246
Current worst splitting domains [lb, ub] (depth):
[-43.14771,   inf] (13), [-43.08984,   inf] (13), [-43.07766,   inf] (13), [-42.96222,   inf] (13), [-42.54345,   inf] (13), [-42.52449,   inf] (13), [-42.27157,   inf] (13), [-42.24122,   inf] (13), [-42.19921,   inf] (13), [-42.18075,   inf] (13), [-42.16087,   inf] (13), [-41.92220,   inf] (13), [-41.90482,   inf] (13), [-41.85529,   inf] (13), [-41.79864,   inf] (13), [-41.77407,   inf] (13), [-41.69207,   inf] (13), [-41.68871,   inf] (13), [-41.63858,   inf] (13), [-41.51070,   inf] (13), 
length of domains: 512
Total time: 1.5797	 pickout: 0.0505	 decision: 0.1335	 get_bound: 1.3682	 add_domain: 0.0274
Current lb:-43.147705078125
960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.156768560409546

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 29] [3, 29] [3, 31] [3, 31] [3, 31] [3, 31] [3, 18] [3, 29] [3, 18] [3, 31] 
regular batch size: 2*512, diving batch size 1*0
best_l after optimization: 33229.4375 with beta sum per layer: [0.0, 0.0, 0.0, 873.8032836914062]
alpha/beta optimization time: 1.8656444549560547
This batch time : update_bounds func: 2.2279	 prepare: 0.0972	 bound: 1.8660	 transfer: 0.1225	 finalize: 0.1397
Accumulated time: update_bounds func: 5.9751	 prepare: 0.1905	 bound: 5.2904	 transfer: 0.1225	 finalize: 0.2619
batch bounding time:  2.2291388511657715
Current worst splitting domains [lb, ub] (depth):
[-41.69040,   inf] (15), [-41.67735,   inf] (15), [-41.54805,   inf] (15), [-41.50105,   inf] (15), [-41.17018,   inf] (15), [-41.05421,   inf] (15), [-40.82863,   inf] (15), [-40.78103,   inf] (15), [-40.74296,   inf] (15), [-40.66868,   inf] (15), [-40.63155,   inf] (15), [-40.47734,   inf] (15), [-40.46662,   inf] (15), [-40.44185,   inf] (15), [-40.34574,   inf] (15), [-40.33201,   inf] (15), [-40.33105,   inf] (15), [-40.28839,   inf] (15), [-40.25624,   inf] (15), [-40.09374,   inf] (15), 
length of domains: 1024
Total time: 2.6366	 pickout: 0.1066	 decision: 0.2410	 get_bound: 2.2309	 add_domain: 0.0582
Current lb:-41.690399169921875
1984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.803242683410645

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 31] [3, 31] [3, 29] [3, 29] [3, 18] [3, 18] [3, 31] [3, 31] [3, 18] [3, 29] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 61099.7890625 with beta sum per layer: [0.0, 0.0, 0.0, 1987.375]
alpha/beta optimization time: 3.2151894569396973
This batch time : update_bounds func: 3.8548	 prepare: 0.1888	 bound: 3.2156	 transfer: 0.2281	 finalize: 0.2177
Accumulated time: update_bounds func: 9.8299	 prepare: 0.3793	 bound: 8.5060	 transfer: 0.2281	 finalize: 0.4796
batch bounding time:  3.8569085597991943
Current worst splitting domains [lb, ub] (depth):
[-40.35610,   inf] (17), [-40.22591,   inf] (17), [-40.08163,   inf] (17), [-40.05333,   inf] (17), [-39.70546,   inf] (17), [-39.56056,   inf] (17), [-39.43066,   inf] (17), [-39.42600,   inf] (17), [-39.26289,   inf] (17), [-39.26104,   inf] (17), [-39.16637,   inf] (17), [-39.14359,   inf] (17), [-39.12368,   inf] (17), [-39.06386,   inf] (17), [-39.04302,   inf] (17), [-39.01327,   inf] (17), [-38.98720,   inf] (17), [-38.97892,   inf] (17), [-38.97412,   inf] (17), [-38.93156,   inf] (17), 
length of domains: 2024
Total time: 4.7346	 pickout: 0.2426	 decision: 0.5112	 get_bound: 3.8604	 add_domain: 0.1204
Current lb:-40.356101989746094
3984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.557219743728638

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 11] [3, 5] [3, 5] [3, 27] [3, 38] [3, 38] [3, 11] [3, 11] [3, 5] [3, 5] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 63145.6796875 with beta sum per layer: [0.0, 0.0, 0.0, 1872.3397216796875]
alpha/beta optimization time: 3.2080302238464355
This batch time : update_bounds func: 3.8732	 prepare: 0.1897	 bound: 3.2084	 transfer: 0.2370	 finalize: 0.2333
Accumulated time: update_bounds func: 13.7031	 prepare: 0.5691	 bound: 11.7144	 transfer: 0.2370	 finalize: 0.7128
batch bounding time:  3.875577449798584
Current worst splitting domains [lb, ub] (depth):
[-39.04649,   inf] (19), [-38.95669,   inf] (19), [-38.80739,   inf] (19), [-38.79382,   inf] (19), [-38.76725,   inf] (19), [-38.72911,   inf] (19), [-38.47859,   inf] (19), [-38.25971,   inf] (19), [-38.17510,   inf] (19), [-38.05908,   inf] (19), [-38.05219,   inf] (19), [-38.03252,   inf] (19), [-37.95320,   inf] (19), [-37.94414,   inf] (19), [-37.91485,   inf] (19), [-37.87962,   inf] (19), [-37.84969,   inf] (19), [-37.83497,   inf] (19), [-37.82937,   inf] (19), [-37.82468,   inf] (19), 
length of domains: 3024
Total time: 4.8113	 pickout: 0.2107	 decision: 0.5928	 get_bound: 3.8793	 add_domain: 0.1285
Current lb:-39.046485900878906
5984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 19.38892960548401

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 5] [3, 11] [3, 45] [3, 11] [3, 5] [3, 45] [3, 11] [3, 27] [3, 38] [3, 5] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 63270.546875 with beta sum per layer: [0.0, 0.0, 0.0, 1813.098388671875]
alpha/beta optimization time: 3.2155637741088867
This batch time : update_bounds func: 3.9030	 prepare: 0.1904	 bound: 3.2160	 transfer: 0.2392	 finalize: 0.2524
Accumulated time: update_bounds func: 17.6062	 prepare: 0.7595	 bound: 14.9304	 transfer: 0.2392	 finalize: 0.9652
batch bounding time:  3.9053499698638916
Current worst splitting domains [lb, ub] (depth):
[-37.80064,   inf] (21), [-37.75878,   inf] (21), [-37.59568,   inf] (21), [-37.56796,   inf] (21), [-37.56669,   inf] (21), [-37.50525,   inf] (21), [-37.47287,   inf] (21), [-37.47103,   inf] (21), [-37.39417,   inf] (21), [-37.38949,   inf] (21), [-37.29757,   inf] (21), [-37.08010,   inf] (21), [-36.98301,   inf] (21), [-36.80178,   inf] (21), [-36.78693,   inf] (21), [-36.77666,   inf] (21), [-36.70675,   inf] (21), [-36.69349,   inf] (21), [-36.64932,   inf] (21), [-36.64838,   inf] (21), 
length of domains: 4024
Total time: 4.8093	 pickout: 0.2149	 decision: 0.5479	 get_bound: 3.9095	 add_domain: 0.1371
Current lb:-37.80064010620117
7984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 24.21975803375244

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 45] [3, 27] [3, 45] [3, 51] [3, 45] [3, 45] [3, 11] [3, 11] [3, 11] [3, 45] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 62948.1015625 with beta sum per layer: [0.0, 0.0, 0.0, 1750.85107421875]
alpha/beta optimization time: 3.2044384479522705
This batch time : update_bounds func: 3.9180	 prepare: 0.1907	 bound: 3.2048	 transfer: 0.2260	 finalize: 0.1520
Accumulated time: update_bounds func: 21.5241	 prepare: 0.9502	 bound: 18.1352	 transfer: 0.2260	 finalize: 1.1172
batch bounding time:  3.9200305938720703
Current worst splitting domains [lb, ub] (depth):
[-36.61160,   inf] (23), [-36.54068,   inf] (23), [-36.49131,   inf] (23), [-36.36505,   inf] (23), [-36.32785,   inf] (23), [-36.32126,   inf] (23), [-36.31952,   inf] (23), [-36.31763,   inf] (23), [-36.29687,   inf] (23), [-36.26051,   inf] (23), [-36.23615,   inf] (23), [-36.20331,   inf] (23), [-36.20142,   inf] (23), [-36.18658,   inf] (23), [-36.13968,   inf] (23), [-36.12357,   inf] (23), [-36.12177,   inf] (23), [-35.86922,   inf] (23), [-35.77205,   inf] (23), [-35.61191,   inf] (23), 
length of domains: 5024
Total time: 4.8840	 pickout: 0.2280	 decision: 0.5903	 get_bound: 3.9235	 add_domain: 0.1422
Current lb:-36.611602783203125
9984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 29.12523579597473

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 51] [3, 51] [3, 51] [3, 11] [3, 27] [3, 27] [3, 51] [3, 51] [3, 11] [3, 27] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 62173.9921875 with beta sum per layer: [0.0, 0.0, 0.0, 1686.7784423828125]
alpha/beta optimization time: 3.217000722885132
This batch time : update_bounds func: 3.8039	 prepare: 0.1943	 bound: 3.2174	 transfer: 0.2321	 finalize: 0.1550
Accumulated time: update_bounds func: 25.3280	 prepare: 1.1445	 bound: 21.3526	 transfer: 0.2321	 finalize: 1.2722
batch bounding time:  3.806182622909546
Current worst splitting domains [lb, ub] (depth):
[-35.43212,   inf] (25), [-35.38474,   inf] (25), [-35.31846,   inf] (25), [-35.31047,   inf] (25), [-35.30459,   inf] (25), [-35.26552,   inf] (25), [-35.15331,   inf] (25), [-35.15156,   inf] (25), [-35.14997,   inf] (25), [-35.14919,   inf] (25), [-35.14726,   inf] (25), [-35.12592,   inf] (25), [-35.05163,   inf] (25), [-35.03443,   inf] (25), [-35.02472,   inf] (25), [-35.01656,   inf] (25), [-35.01069,   inf] (25), [-35.01007,   inf] (25), [-34.99907,   inf] (25), [-34.94334,   inf] (25), 
length of domains: 6024
Total time: 4.9493	 pickout: 0.2397	 decision: 0.7455	 get_bound: 3.8101	 add_domain: 0.1540
Current lb:-35.43212127685547
11984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 34.09905290603638

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 45] [3, 45] [3, 27] [3, 27] [3, 27] [3, 27] [3, 11] [3, 27] [3, 38] [3, 27] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 60871.0 with beta sum per layer: [0.0, 0.0, 0.0, 1590.973876953125]
alpha/beta optimization time: 3.2360939979553223
This batch time : update_bounds func: 4.0153	 prepare: 0.1940	 bound: 3.2365	 transfer: 0.2413	 finalize: 0.3385
Accumulated time: update_bounds func: 29.3432	 prepare: 1.3384	 bound: 24.5891	 transfer: 0.2413	 finalize: 1.6107
batch bounding time:  4.017822504043579
Current worst splitting domains [lb, ub] (depth):
[-34.31268,   inf] (27), [-34.27613,   inf] (27), [-34.23237,   inf] (27), [-34.22547,   inf] (27), [-34.20311,   inf] (27), [-34.15384,   inf] (27), [-34.05499,   inf] (27), [-34.04576,   inf] (27), [-34.03813,   inf] (27), [-34.03259,   inf] (27), [-34.00780,   inf] (27), [-33.95070,   inf] (27), [-33.94333,   inf] (27), [-33.93605,   inf] (27), [-33.92751,   inf] (27), [-33.91795,   inf] (27), [-33.90145,   inf] (27), [-33.89635,   inf] (27), [-33.87548,   inf] (27), [-33.84910,   inf] (27), 
length of domains: 7024
Total time: 5.0519	 pickout: 0.2345	 decision: 0.6365	 get_bound: 4.0221	 add_domain: 0.1588
Current lb:-34.31268310546875
13984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 39.174935817718506

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 38] [3, 33] [3, 38] [3, 38] [3, 38] [3, 38] [3, 38] [3, 33] [3, 51] [3, 38] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 59675.6015625 with beta sum per layer: [0.0, 0.0, 0.0, 1612.285888671875]
alpha/beta optimization time: 3.239248514175415
This batch time : update_bounds func: 4.0295	 prepare: 0.1982	 bound: 3.2397	 transfer: 0.2211	 finalize: 0.3652
Accumulated time: update_bounds func: 33.3727	 prepare: 1.5366	 bound: 27.8287	 transfer: 0.2211	 finalize: 1.9759
batch bounding time:  4.031969308853149
Current worst splitting domains [lb, ub] (depth):
[-33.26462,   inf] (29), [-33.22002,   inf] (29), [-33.20531,   inf] (29), [-33.19900,   inf] (29), [-33.12310,   inf] (29), [-33.11783,   inf] (29), [-33.05859,   inf] (29), [-33.04142,   inf] (29), [-33.01483,   inf] (29), [-32.99960,   inf] (29), [-32.98944,   inf] (29), [-32.94250,   inf] (29), [-32.93246,   inf] (29), [-32.90993,   inf] (29), [-32.90893,   inf] (29), [-32.89286,   inf] (29), [-32.86383,   inf] (29), [-32.83416,   inf] (29), [-32.82705,   inf] (29), [-32.79657,   inf] (29), 
length of domains: 8024
Total time: 5.1358	 pickout: 0.2838	 decision: 0.6527	 get_bound: 4.0362	 add_domain: 0.1632
Current lb:-33.26462173461914
15984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 44.33613467216492

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 38] [3, 33] [3, 33] [3, 33] [3, 33] [3, 33] [3, 38] [3, 33] [3, 51] [3, 33] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 58500.609375 with beta sum per layer: [0.0, 0.0, 0.0713634118437767, 1875.15185546875]
alpha/beta optimization time: 3.241147041320801
This batch time : update_bounds func: 3.8352	 prepare: 0.1992	 bound: 3.2416	 transfer: 0.2261	 finalize: 0.1627
Accumulated time: update_bounds func: 37.2079	 prepare: 1.7358	 bound: 31.0703	 transfer: 0.2261	 finalize: 2.1386
batch bounding time:  3.8376941680908203
Current worst splitting domains [lb, ub] (depth):
[-32.26938,   inf] (31), [-32.25741,   inf] (31), [-32.20675,   inf] (31), [-32.19357,   inf] (31), [-32.18791,   inf] (31), [-32.13630,   inf] (31), [-32.09331,   inf] (31), [-32.08840,   inf] (31), [-32.02751,   inf] (31), [-31.99907,   inf] (31), [-31.99273,   inf] (31), [-31.99227,   inf] (31), [-31.97008,   inf] (31), [-31.94244,   inf] (31), [-31.94155,   inf] (31), [-31.90743,   inf] (31), [-31.88403,   inf] (31), [-31.85348,   inf] (31), [-31.84760,   inf] (31), [-31.84223,   inf] (31), 
length of domains: 9024
Total time: 4.9458	 pickout: 0.2493	 decision: 0.6913	 get_bound: 3.8418	 add_domain: 0.1635
Current lb:-32.269378662109375
17984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 49.31130409240723

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 101] [2, 101] [2, 101] [2, 101] [2, 101] [2, 101] [2, 101] [2, 101] [2, 101] [2, 101] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 58041.625 with beta sum per layer: [0.0, 0.0, 1.5134906768798828, 1878.179443359375]
alpha/beta optimization time: 3.243565797805786
This batch time : update_bounds func: 4.1334	 prepare: 0.2000	 bound: 3.2440	 transfer: 0.2266	 finalize: 0.4571
Accumulated time: update_bounds func: 41.3414	 prepare: 1.9358	 bound: 34.3143	 transfer: 0.2266	 finalize: 2.5958
batch bounding time:  4.135883808135986
Current worst splitting domains [lb, ub] (depth):
[-31.48477,   inf] (33), [-31.48315,   inf] (33), [-31.48064,   inf] (33), [-31.42559,   inf] (33), [-31.39521,   inf] (33), [-31.39048,   inf] (33), [-31.36749,   inf] (33), [-31.29613,   inf] (33), [-31.25211,   inf] (33), [-31.22374,   inf] (33), [-31.19019,   inf] (33), [-31.18331,   inf] (33), [-31.17991,   inf] (33), [-31.14809,   inf] (33), [-31.14659,   inf] (33), [-31.13469,   inf] (33), [-31.11274,   inf] (33), [-31.10277,   inf] (33), [-31.09818,   inf] (33), [-31.09260,   inf] (33), 
length of domains: 10024
Total time: 5.3713	 pickout: 0.3019	 decision: 0.7635	 get_bound: 4.1417	 add_domain: 0.1642
Current lb:-31.48476791381836
19984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 54.70786499977112

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 21] [3, 21] [2, 14] [3, 21] [3, 21] [3, 21] [3, 21] [3, 21] [3, 21] [3, 21] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 57469.9140625 with beta sum per layer: [0.0, 0.0, 1.3357079029083252, 1973.16259765625]
alpha/beta optimization time: 3.2401626110076904
This batch time : update_bounds func: 4.1692	 prepare: 0.2023	 bound: 3.2406	 transfer: 0.2390	 finalize: 0.1689
Accumulated time: update_bounds func: 45.5106	 prepare: 2.1380	 bound: 37.5550	 transfer: 0.2390	 finalize: 2.7646
batch bounding time:  4.1717846393585205
Current worst splitting domains [lb, ub] (depth):
[-30.67279,   inf] (35), [-30.60544,   inf] (35), [-30.60229,   inf] (35), [-30.55156,   inf] (35), [-30.52205,   inf] (35), [-30.51423,   inf] (35), [-30.48927,   inf] (35), [-30.46998,   inf] (35), [-30.46681,   inf] (35), [-30.43351,   inf] (35), [-30.42452,   inf] (35), [-30.39736,   inf] (35), [-30.38297,   inf] (35), [-30.37630,   inf] (35), [-30.36971,   inf] (35), [-30.36516,   inf] (35), [-30.36231,   inf] (35), [-30.35423,   inf] (35), [-30.35178,   inf] (35), [-30.34818,   inf] (35), 
length of domains: 11024
Total time: 5.0732	 pickout: 0.2510	 decision: 0.4813	 get_bound: 4.1758	 add_domain: 0.1652
Current lb:-30.672786712646484
21984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 59.81521391868591

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 21] [2, 14] [3, 0] [2, 14] [2, 14] [3, 0] [2, 14] [3, 0] [2, 14] [2, 14] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 56965.23046875 with beta sum per layer: [0.0, 0.0, 1.475090742111206, 2036.114013671875]
alpha/beta optimization time: 3.2584662437438965
This batch time : update_bounds func: 3.8910	 prepare: 0.2054	 bound: 3.2589	 transfer: 0.2473	 finalize: 0.1729
Accumulated time: update_bounds func: 49.4016	 prepare: 2.3434	 bound: 40.8139	 transfer: 0.2473	 finalize: 2.9375
batch bounding time:  3.8935513496398926
Current worst splitting domains [lb, ub] (depth):
[-30.09482,   inf] (33), [-30.09478,   inf] (23), [-30.09469,   inf] (27), [-30.09467,   inf] (27), [-30.09459,   inf] (21), [-30.09429,   inf] (27), [-30.09418,   inf] (31), [-30.09362,   inf] (17), [-30.09347,   inf] (21), [-30.09319,   inf] (29), [-30.09312,   inf] (25), [-30.09293,   inf] (25), [-30.09264,   inf] (31), [-30.09170,   inf] (25), [-30.09166,   inf] (23), [-30.09166,   inf] (25), [-30.09160,   inf] (23), [-30.09129,   inf] (31), [-30.09109,   inf] (29), [-30.09085,   inf] (17), 
length of domains: 12024
Total time: 5.2230	 pickout: 0.2992	 decision: 0.8560	 get_bound: 3.8979	 add_domain: 0.1700
Current lb:-30.094818115234375
23984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 65.06843829154968

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 0] [3, 11] [3, 33] [3, 38] [3, 11] [3, 51] [3, 21] [3, 5] [3, 45] [3, 33] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 56595.52734375 with beta sum per layer: [0.0, 0.0, 2.059495687484741, 1961.29052734375]
alpha/beta optimization time: 3.25651478767395
This batch time : update_bounds func: 3.8716	 prepare: 0.2021	 bound: 3.2570	 transfer: 0.2347	 finalize: 0.1714
Accumulated time: update_bounds func: 53.2731	 prepare: 2.5455	 bound: 44.0708	 transfer: 0.2347	 finalize: 3.1090
batch bounding time:  3.874253273010254
Current worst splitting domains [lb, ub] (depth):
[-29.90860,   inf] (35), [-29.90848,   inf] (31), [-29.90846,   inf] (29), [-29.90839,   inf] (21), [-29.90821,   inf] (27), [-29.90818,   inf] (21), [-29.90807,   inf] (29), [-29.90799,   inf] (27), [-29.90786,   inf] (27), [-29.90767,   inf] (19), [-29.90762,   inf] (17), [-29.90761,   inf] (35), [-29.90744,   inf] (33), [-29.90742,   inf] (17), [-29.90740,   inf] (23), [-29.90733,   inf] (29), [-29.90723,   inf] (23), [-29.90722,   inf] (31), [-29.90704,   inf] (25), [-29.90698,   inf] (27), 
length of domains: 13024
Total time: 5.2266	 pickout: 0.2763	 decision: 0.9002	 get_bound: 3.8788	 add_domain: 0.1712
Current lb:-29.908599853515625
25984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 70.327965259552

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 0] [3, 21] [3, 33] [3, 5] [3, 33] [3, 5] [3, 33] [3, 33] [3, 38] [3, 5] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 56285.4296875 with beta sum per layer: [0.0, 0.0, 2.180675745010376, 2054.93017578125]
alpha/beta optimization time: 3.250431776046753
This batch time : update_bounds func: 3.8716	 prepare: 0.2024	 bound: 3.2508	 transfer: 0.2384	 finalize: 0.1734
Accumulated time: update_bounds func: 57.1448	 prepare: 2.7479	 bound: 47.3217	 transfer: 0.2384	 finalize: 3.2823
batch bounding time:  3.8742878437042236
Current worst splitting domains [lb, ub] (depth):
[-29.73236,   inf] (23), [-29.73232,   inf] (27), [-29.73219,   inf] (31), [-29.73214,   inf] (23), [-29.73204,   inf] (29), [-29.73190,   inf] (33), [-29.73182,   inf] (35), [-29.73155,   inf] (31), [-29.73153,   inf] (33), [-29.73141,   inf] (27), [-29.73096,   inf] (29), [-29.73087,   inf] (17), [-29.73059,   inf] (17), [-29.73059,   inf] (31), [-29.73030,   inf] (29), [-29.72936,   inf] (27), [-29.72913,   inf] (25), [-29.72881,   inf] (25), [-29.72859,   inf] (25), [-29.72847,   inf] (25), 
length of domains: 14024
Total time: 5.7151	 pickout: 0.2991	 decision: 0.9138	 get_bound: 3.8786	 add_domain: 0.6236
Current lb:-29.73235511779785
27984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 76.07360100746155

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 11] [3, 33] [3, 21] [3, 27] [3, 33] [2, 101] [3, 2] [3, 33] [3, 0] [3, 38] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 56025.140625 with beta sum per layer: [0.0, 0.0, 2.982029914855957, 2088.158203125]
alpha/beta optimization time: 3.2488977909088135
This batch time : update_bounds func: 3.8466	 prepare: 0.2024	 bound: 3.2494	 transfer: 0.2215	 finalize: 0.1665
Accumulated time: update_bounds func: 60.9914	 prepare: 2.9503	 bound: 50.5710	 transfer: 0.2215	 finalize: 3.4488
batch bounding time:  3.8493385314941406
Current worst splitting domains [lb, ub] (depth):
[-29.56613,   inf] (23), [-29.56610,   inf] (23), [-29.56594,   inf] (29), [-29.56577,   inf] (23), [-29.56574,   inf] (31), [-29.56572,   inf] (31), [-29.56571,   inf] (17), [-29.56569,   inf] (27), [-29.56497,   inf] (27), [-29.56481,   inf] (27), [-29.56476,   inf] (33), [-29.56382,   inf] (25), [-29.56379,   inf] (25), [-29.56376,   inf] (33), [-29.56371,   inf] (29), [-29.56357,   inf] (35), [-29.56334,   inf] (37), [-29.56324,   inf] (25), [-29.56311,   inf] (29), [-29.56295,   inf] (19), 
length of domains: 15024
Total time: 5.3819	 pickout: 0.3348	 decision: 0.4927	 get_bound: 3.8539	 add_domain: 0.7005
Current lb:-29.566129684448242
29984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 81.48314332962036

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 29] [3, 38] [3, 38] [3, 27] [3, 21] [3, 21] [3, 45] [3, 51] [3, 33] [3, 33] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 55687.0859375 with beta sum per layer: [0.0, 0.0, 2.565563678741455, 2101.01513671875]
alpha/beta optimization time: 3.2540178298950195
This batch time : update_bounds func: 3.8531	 prepare: 0.2041	 bound: 3.2545	 transfer: 0.2214	 finalize: 0.1670
Accumulated time: update_bounds func: 64.8445	 prepare: 3.1544	 bound: 53.8255	 transfer: 0.2214	 finalize: 3.6158
batch bounding time:  3.855825901031494
Current worst splitting domains [lb, ub] (depth):
[-29.41738,   inf] (21), [-29.41697,   inf] (23), [-29.41692,   inf] (25), [-29.41674,   inf] (29), [-29.41664,   inf] (21), [-29.41645,   inf] (23), [-29.41626,   inf] (31), [-29.41616,   inf] (37), [-29.41614,   inf] (35), [-29.41614,   inf] (25), [-29.41602,   inf] (25), [-29.41602,   inf] (25), [-29.41566,   inf] (19), [-29.41558,   inf] (29), [-29.41557,   inf] (29), [-29.41557,   inf] (31), [-29.41525,   inf] (25), [-29.41514,   inf] (17), [-29.41497,   inf] (27), [-29.41491,   inf] (35), 
length of domains: 16024
Total time: 4.8597	 pickout: 0.3320	 decision: 0.4943	 get_bound: 3.8602	 add_domain: 0.1731
Current lb:-29.417381286621094
31984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 86.37183952331543

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 18] [3, 38] [3, 27] [3, 38] [3, 27] [3, 38] [3, 21] [2, 14] [3, 21] [3, 27] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 55457.7734375 with beta sum per layer: [0.0, 0.0, 2.7826132774353027, 2065.533203125]
alpha/beta optimization time: 3.2557716369628906
This batch time : update_bounds func: 3.8684	 prepare: 0.2040	 bound: 3.2562	 transfer: 0.2313	 finalize: 0.1706
Accumulated time: update_bounds func: 68.7129	 prepare: 3.3584	 bound: 57.0818	 transfer: 0.2313	 finalize: 3.7864
batch bounding time:  3.8711585998535156
Current worst splitting domains [lb, ub] (depth):
[-29.28407,   inf] (25), [-29.28387,   inf] (29), [-29.28355,   inf] (25), [-29.28340,   inf] (25), [-29.28340,   inf] (35), [-29.28332,   inf] (27), [-29.28328,   inf] (31), [-29.28313,   inf] (23), [-29.28285,   inf] (31), [-29.28276,   inf] (33), [-29.28262,   inf] (29), [-29.28238,   inf] (23), [-29.28235,   inf] (25), [-29.28189,   inf] (23), [-29.28158,   inf] (27), [-29.28157,   inf] (19), [-29.28138,   inf] (25), [-29.28130,   inf] (25), [-29.28117,   inf] (31), [-29.28115,   inf] (25), 
length of domains: 17024
Total time: 5.3855	 pickout: 0.2938	 decision: 1.0416	 get_bound: 3.8757	 add_domain: 0.1743
Current lb:-29.284074783325195
33984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 91.79108738899231

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 51] [3, 33] [3, 27] [3, 33] [3, 0] [3, 18] [3, 21] [3, 5] [3, 33] [3, 21] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 55169.16015625 with beta sum per layer: [0.0, 0.0, 3.4939656257629395, 2157.3935546875]
alpha/beta optimization time: 3.2529456615448
This batch time : update_bounds func: 3.8789	 prepare: 0.2072	 bound: 3.2534	 transfer: 0.2374	 finalize: 0.1744
Accumulated time: update_bounds func: 72.5918	 prepare: 3.5656	 bound: 60.3352	 transfer: 0.2374	 finalize: 3.9609
batch bounding time:  3.8816611766815186
Current worst splitting domains [lb, ub] (depth):
[-29.15972,   inf] (27), [-29.15956,   inf] (29), [-29.15955,   inf] (29), [-29.15950,   inf] (23), [-29.15931,   inf] (23), [-29.15929,   inf] (27), [-29.15924,   inf] (21), [-29.15924,   inf] (27), [-29.15919,   inf] (33), [-29.15911,   inf] (29), [-29.15889,   inf] (29), [-29.15887,   inf] (27), [-29.15885,   inf] (23), [-29.15883,   inf] (29), [-29.15876,   inf] (31), [-29.15875,   inf] (33), [-29.15872,   inf] (25), [-29.15842,   inf] (27), [-29.15830,   inf] (19), [-29.15818,   inf] (25), 
length of domains: 18024
Total time: 5.4021	 pickout: 0.2813	 decision: 1.0592	 get_bound: 3.8865	 add_domain: 0.1752
Current lb:-29.159717559814453
35984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 97.22552752494812

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 51] [3, 21] [3, 33] [3, 45] [3, 27] [3, 33] [3, 51] [3, 33] [2, 101] [3, 33] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 54983.03515625 with beta sum per layer: [0.0, 0.0, 3.916740894317627, 2090.197509765625]
alpha/beta optimization time: 3.260263204574585
This batch time : update_bounds func: 3.8869	 prepare: 0.2120	 bound: 3.2608	 transfer: 0.2235	 finalize: 0.1839
Accumulated time: update_bounds func: 76.4787	 prepare: 3.7776	 bound: 63.5960	 transfer: 0.2235	 finalize: 4.1447
batch bounding time:  3.8897299766540527
Current worst splitting domains [lb, ub] (depth):
[-29.04799,   inf] (33), [-29.04782,   inf] (35), [-29.04770,   inf] (27), [-29.04758,   inf] (25), [-29.04749,   inf] (27), [-29.04739,   inf] (37), [-29.04708,   inf] (21), [-29.04702,   inf] (23), [-29.04698,   inf] (21), [-29.04691,   inf] (25), [-29.04687,   inf] (29), [-29.04671,   inf] (35), [-29.04640,   inf] (23), [-29.04630,   inf] (31), [-29.04622,   inf] (17), [-29.04498,   inf] (23), [-29.04457,   inf] (29), [-29.04455,   inf] (25), [-29.04444,   inf] (27), [-29.04432,   inf] (31), 
length of domains: 19024
Total time: 5.4495	 pickout: 0.2842	 decision: 1.0944	 get_bound: 3.8944	 add_domain: 0.1765
Current lb:-29.04798698425293
37984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 102.71402645111084

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 0] [3, 21] [3, 51] [3, 5] [3, 38] [3, 21] [3, 51] [3, 45] [3, 45] [3, 45] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 54759.81640625 with beta sum per layer: [0.0, 0.0, 3.1915667057037354, 2109.596435546875]
alpha/beta optimization time: 3.2574644088745117
This batch time : update_bounds func: 3.8887	 prepare: 0.2054	 bound: 3.2579	 transfer: 0.2439	 finalize: 0.1748
Accumulated time: update_bounds func: 80.3674	 prepare: 3.9830	 bound: 66.8539	 transfer: 0.2439	 finalize: 4.3195
batch bounding time:  3.891362190246582
Current worst splitting domains [lb, ub] (depth):
[-28.93649,   inf] (29), [-28.93647,   inf] (37), [-28.93635,   inf] (25), [-28.93630,   inf] (27), [-28.93628,   inf] (25), [-28.93613,   inf] (21), [-28.93588,   inf] (33), [-28.93566,   inf] (23), [-28.93565,   inf] (29), [-28.93561,   inf] (27), [-28.93558,   inf] (27), [-28.93553,   inf] (27), [-28.93551,   inf] (25), [-28.93546,   inf] (25), [-28.93532,   inf] (19), [-28.93514,   inf] (27), [-28.93496,   inf] (17), [-28.93489,   inf] (25), [-28.93484,   inf] (25), [-28.93464,   inf] (27), 
length of domains: 20024
Total time: 5.4983	 pickout: 0.2926	 decision: 1.1267	 get_bound: 3.8958	 add_domain: 0.1832
Current lb:-28.936492919921875
39984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 108.24379658699036

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 33] [2, 14] [3, 5] [3, 5] [3, 11] [3, 5] [3, 21] [3, 45] [3, 38] [3, 51] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 54594.421875 with beta sum per layer: [0.0, 0.0, 3.6516520977020264, 2118.378173828125]
alpha/beta optimization time: 3.2535223960876465
This batch time : update_bounds func: 4.5952	 prepare: 0.2061	 bound: 3.2540	 transfer: 0.2308	 finalize: 0.8976
Accumulated time: update_bounds func: 84.9627	 prepare: 4.1891	 bound: 70.1079	 transfer: 0.2308	 finalize: 5.2172
batch bounding time:  4.597880840301514
Current worst splitting domains [lb, ub] (depth):
[-28.83395,   inf] (33), [-28.83388,   inf] (31), [-28.83370,   inf] (19), [-28.83340,   inf] (33), [-28.83337,   inf] (23), [-28.83334,   inf] (23), [-28.83333,   inf] (27), [-28.83330,   inf] (23), [-28.83327,   inf] (23), [-28.83317,   inf] (31), [-28.83312,   inf] (23), [-28.83307,   inf] (29), [-28.83297,   inf] (27), [-28.83268,   inf] (29), [-28.83259,   inf] (29), [-28.83256,   inf] (29), [-28.83252,   inf] (25), [-28.83237,   inf] (23), [-28.83234,   inf] (27), [-28.83212,   inf] (29), 
length of domains: 21024
Total time: 5.5804	 pickout: 0.3023	 decision: 0.5000	 get_bound: 4.6023	 add_domain: 0.1759
Current lb:-28.833953857421875
41984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 113.8580150604248

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 14] [3, 21] [3, 11] [3, 0] [3, 29] [3, 51] [3, 38] [3, 35] [3, 38] [3, 21] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 54440.7578125 with beta sum per layer: [0.0, 0.0, 5.504327774047852, 2068.607666015625]
alpha/beta optimization time: 3.251668691635132
This batch time : update_bounds func: 3.8592	 prepare: 0.2058	 bound: 3.2521	 transfer: 0.2211	 finalize: 0.1732
Accumulated time: update_bounds func: 88.8219	 prepare: 4.3949	 bound: 73.3600	 transfer: 0.2211	 finalize: 5.3903
batch bounding time:  3.862072229385376
Current worst splitting domains [lb, ub] (depth):
[-28.73445,   inf] (19), [-28.73426,   inf] (23), [-28.73421,   inf] (23), [-28.73414,   inf] (27), [-28.73404,   inf] (35), [-28.73394,   inf] (33), [-28.73390,   inf] (31), [-28.73385,   inf] (31), [-28.73376,   inf] (37), [-28.73368,   inf] (25), [-28.73361,   inf] (25), [-28.73349,   inf] (29), [-28.73333,   inf] (29), [-28.73329,   inf] (29), [-28.73323,   inf] (23), [-28.73320,   inf] (29), [-28.73319,   inf] (31), [-28.73318,   inf] (27), [-28.73308,   inf] (33), [-28.73302,   inf] (25), 
length of domains: 22024
Total time: 4.8492	 pickout: 0.2993	 decision: 0.5025	 get_bound: 3.8669	 add_domain: 0.1805
Current lb:-28.73444938659668
43984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 118.73887157440186

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 5] [3, 38] [3, 38] [3, 51] [3, 0] [2, 101] [3, 21] [2, 101] [3, 0] [3, 45] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 54238.78125 with beta sum per layer: [0.0, 0.0, 6.648380279541016, 2112.95849609375]
alpha/beta optimization time: 3.251605272293091
This batch time : update_bounds func: 3.8705	 prepare: 0.2065	 bound: 3.2521	 transfer: 0.2296	 finalize: 0.1754
Accumulated time: update_bounds func: 92.6924	 prepare: 4.6014	 bound: 76.6121	 transfer: 0.2296	 finalize: 5.5658
batch bounding time:  3.87322735786438
Current worst splitting domains [lb, ub] (depth):
[-28.64163,   inf] (35), [-28.64154,   inf] (33), [-28.64120,   inf] (25), [-28.64118,   inf] (27), [-28.64108,   inf] (17), [-28.64077,   inf] (23), [-28.64074,   inf] (25), [-28.64070,   inf] (29), [-28.64065,   inf] (25), [-28.64052,   inf] (33), [-28.64034,   inf] (27), [-28.64024,   inf] (33), [-28.64013,   inf] (19), [-28.64008,   inf] (23), [-28.64003,   inf] (25), [-28.64002,   inf] (17), [-28.63985,   inf] (25), [-28.63974,   inf] (33), [-28.63956,   inf] (23), [-28.63953,   inf] (27), 
length of domains: 23024
Total time: 5.6260	 pickout: 0.3177	 decision: 1.2485	 get_bound: 3.8779	 add_domain: 0.1819
Current lb:-28.641626358032227
45984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 124.40138244628906

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 0] [2, 14] [3, 38] [3, 51] [3, 5] [3, 51] [3, 45] [3, 33] [3, 38] [3, 2] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 54133.890625 with beta sum per layer: [0.0, 0.0, 7.010251045227051, 2098.68603515625]
alpha/beta optimization time: 3.256425380706787
This batch time : update_bounds func: 4.6529	 prepare: 0.2076	 bound: 3.2569	 transfer: 0.2285	 finalize: 0.9530
Accumulated time: update_bounds func: 97.3453	 prepare: 4.8091	 bound: 79.8690	 transfer: 0.2285	 finalize: 6.5188
batch bounding time:  4.655319452285767
Current worst splitting domains [lb, ub] (depth):
[-28.54910,   inf] (35), [-28.54903,   inf] (23), [-28.54896,   inf] (33), [-28.54887,   inf] (33), [-28.54885,   inf] (39), [-28.54885,   inf] (33), [-28.54872,   inf] (35), [-28.54861,   inf] (23), [-28.54861,   inf] (31), [-28.54855,   inf] (39), [-28.54850,   inf] (37), [-28.54847,   inf] (29), [-28.54844,   inf] (31), [-28.54836,   inf] (33), [-28.54816,   inf] (21), [-28.54807,   inf] (33), [-28.54805,   inf] (31), [-28.54804,   inf] (39), [-28.54790,   inf] (31), [-28.54785,   inf] (29), 
length of domains: 24024
Total time: 5.6779	 pickout: 0.3305	 decision: 0.5079	 get_bound: 4.6593	 add_domain: 0.1802
Current lb:-28.54909896850586
47984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 130.1136589050293

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 21] [3, 45] [3, 21] [3, 0] [3, 46] [3, 0] [2, 101] [3, 38] [2, 101] [3, 48] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 53939.25390625 with beta sum per layer: [0.0, 0.0, 6.583555698394775, 2159.4150390625]
alpha/beta optimization time: 3.2569499015808105
This batch time : update_bounds func: 3.8750	 prepare: 0.2061	 bound: 3.2574	 transfer: 0.2289	 finalize: 0.1756
Accumulated time: update_bounds func: 101.2203	 prepare: 5.0152	 bound: 83.1264	 transfer: 0.2289	 finalize: 6.6944
batch bounding time:  3.8774726390838623
Current worst splitting domains [lb, ub] (depth):
[-28.46517,   inf] (39), [-28.46492,   inf] (35), [-28.46490,   inf] (29), [-28.46487,   inf] (25), [-28.46483,   inf] (29), [-28.46469,   inf] (17), [-28.46459,   inf] (29), [-28.46448,   inf] (23), [-28.46434,   inf] (25), [-28.46423,   inf] (33), [-28.46393,   inf] (33), [-28.46366,   inf] (27), [-28.46354,   inf] (33), [-28.46354,   inf] (31), [-28.46323,   inf] (17), [-28.46310,   inf] (25), [-28.46310,   inf] (39), [-28.46279,   inf] (33), [-28.46274,   inf] (25), [-28.46272,   inf] (27), 
length of domains: 25024
Total time: 4.8889	 pickout: 0.3183	 decision: 0.5045	 get_bound: 3.8816	 add_domain: 0.1845
Current lb:-28.465173721313477
49984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 135.04224634170532

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 46] [3, 46] [3, 38] [3, 33] [3, 33] [3, 27] [3, 38] [3, 29] [3, 27] [3, 0] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 53819.375 with beta sum per layer: [0.0, 0.0, 7.695263862609863, 2081.909423828125]
alpha/beta optimization time: 3.2541000843048096
This batch time : update_bounds func: 3.8751	 prepare: 0.2093	 bound: 3.2546	 transfer: 0.2298	 finalize: 0.1742
Accumulated time: update_bounds func: 105.0954	 prepare: 5.2245	 bound: 86.3810	 transfer: 0.2298	 finalize: 6.8686
batch bounding time:  3.877866744995117
Current worst splitting domains [lb, ub] (depth):
[-28.38595,   inf] (29), [-28.38595,   inf] (39), [-28.38587,   inf] (35), [-28.38580,   inf] (29), [-28.38573,   inf] (19), [-28.38565,   inf] (23), [-28.38560,   inf] (35), [-28.38560,   inf] (37), [-28.38551,   inf] (23), [-28.38532,   inf] (27), [-28.38528,   inf] (33), [-28.38525,   inf] (27), [-28.38523,   inf] (17), [-28.38518,   inf] (27), [-28.38516,   inf] (33), [-28.38515,   inf] (33), [-28.38478,   inf] (35), [-28.38447,   inf] (29), [-28.38445,   inf] (25), [-28.38445,   inf] (25), 
length of domains: 26024
Total time: 5.7562	 pickout: 0.3433	 decision: 1.3467	 get_bound: 3.8825	 add_domain: 0.1838
Current lb:-28.38595199584961
51984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 140.82917404174805

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 38] [2, 126] [3, 0] [3, 38] [3, 5] [3, 11] [3, 46] [3, 0] [3, 18] [3, 38] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 53650.9296875 with beta sum per layer: [0.0, 0.0, 8.50390625, 2174.124267578125]
alpha/beta optimization time: 3.2565433979034424
This batch time : update_bounds func: 4.7598	 prepare: 0.2068	 bound: 3.2570	 transfer: 0.2399	 finalize: 1.0488
Accumulated time: update_bounds func: 109.8553	 prepare: 5.4313	 bound: 89.6380	 transfer: 0.2399	 finalize: 7.9175
batch bounding time:  4.762309789657593
Current worst splitting domains [lb, ub] (depth):
[-28.31094,   inf] (21), [-28.31076,   inf] (31), [-28.31068,   inf] (31), [-28.31065,   inf] (33), [-28.31045,   inf] (27), [-28.31032,   inf] (31), [-28.31031,   inf] (21), [-28.31028,   inf] (33), [-28.31008,   inf] (25), [-28.31006,   inf] (23), [-28.31005,   inf] (31), [-28.31002,   inf] (33), [-28.30995,   inf] (31), [-28.30971,   inf] (35), [-28.30957,   inf] (27), [-28.30954,   inf] (29), [-28.30949,   inf] (25), [-28.30949,   inf] (39), [-28.30945,   inf] (25), [-28.30931,   inf] (31), 
length of domains: 27024
Total time: 5.7617	 pickout: 0.3075	 decision: 0.5070	 get_bound: 4.7666	 add_domain: 0.1807
Current lb:-28.310937881469727
53984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 146.62539339065552

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 5] [3, 21] [3, 21] [3, 0] [3, 38] [3, 21] [3, 5] [3, 0] [3, 5] [3, 51] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 53554.32421875 with beta sum per layer: [0.0, 0.0, 7.941421985626221, 2079.421875]
alpha/beta optimization time: 3.260054349899292
This batch time : update_bounds func: 3.8955	 prepare: 0.2078	 bound: 3.2605	 transfer: 0.2401	 finalize: 0.1802
Accumulated time: update_bounds func: 113.7508	 prepare: 5.6390	 bound: 92.8985	 transfer: 0.2401	 finalize: 8.0976
batch bounding time:  3.8987324237823486
Current worst splitting domains [lb, ub] (depth):
[-28.23743,   inf] (35), [-28.23735,   inf] (29), [-28.23723,   inf] (27), [-28.23705,   inf] (23), [-28.23705,   inf] (27), [-28.23699,   inf] (25), [-28.23695,   inf] (23), [-28.23694,   inf] (27), [-28.23679,   inf] (23), [-28.23674,   inf] (31), [-28.23668,   inf] (29), [-28.23662,   inf] (21), [-28.23655,   inf] (27), [-28.23639,   inf] (37), [-28.23628,   inf] (21), [-28.23625,   inf] (29), [-28.23616,   inf] (25), [-28.23615,   inf] (25), [-28.23614,   inf] (39), [-28.23610,   inf] (33), 
length of domains: 28024
Total time: 4.8987	 pickout: 0.3016	 decision: 0.5096	 get_bound: 3.9034	 add_domain: 0.1840
Current lb:-28.23743438720703
55984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 151.5758020877838

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 46] [3, 33] [3, 38] [3, 51] [3, 38] [3, 27] [3, 27] [3, 38] [3, 27] [3, 21] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 53427.4140625 with beta sum per layer: [0.0, 0.0, 6.91383171081543, 2150.7421875]
alpha/beta optimization time: 3.259305715560913
This batch time : update_bounds func: 3.8751	 prepare: 0.2083	 bound: 3.2598	 transfer: 0.2202	 finalize: 0.1795
Accumulated time: update_bounds func: 117.6259	 prepare: 5.8473	 bound: 96.1583	 transfer: 0.2202	 finalize: 8.2771
batch bounding time:  3.8778281211853027
Current worst splitting domains [lb, ub] (depth):
[-28.16300,   inf] (35), [-28.16292,   inf] (33), [-28.16287,   inf] (37), [-28.16284,   inf] (27), [-28.16280,   inf] (25), [-28.16277,   inf] (29), [-28.16276,   inf] (27), [-28.16271,   inf] (27), [-28.16255,   inf] (27), [-28.16251,   inf] (35), [-28.16238,   inf] (25), [-28.16237,   inf] (35), [-28.16222,   inf] (27), [-28.16217,   inf] (37), [-28.16211,   inf] (33), [-28.16209,   inf] (21), [-28.16198,   inf] (29), [-28.16191,   inf] (31), [-28.16186,   inf] (33), [-28.16183,   inf] (29), 
length of domains: 29024
Total time: 5.8939	 pickout: 0.3424	 decision: 1.4834	 get_bound: 3.8824	 add_domain: 0.1857
Current lb:-28.163002014160156
57984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 157.50603938102722

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 0] [3, 21] [2, 74] [3, 51] [3, 33] [3, 38] [3, 33] [3, 33] [3, 51] [3, 0] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 53301.72265625 with beta sum per layer: [0.0, 0.0, 7.926279544830322, 2117.458251953125]
alpha/beta optimization time: 3.2612013816833496
This batch time : update_bounds func: 3.9105	 prepare: 0.2101	 bound: 3.2617	 transfer: 0.2565	 finalize: 0.1749
Accumulated time: update_bounds func: 121.5364	 prepare: 6.0574	 bound: 99.4200	 transfer: 0.2565	 finalize: 8.4519
batch bounding time:  3.913191080093384
Current worst splitting domains [lb, ub] (depth):
[-28.09018,   inf] (27), [-28.09015,   inf] (27), [-28.09004,   inf] (21), [-28.08997,   inf] (33), [-28.08991,   inf] (29), [-28.08986,   inf] (33), [-28.08978,   inf] (33), [-28.08973,   inf] (25), [-28.08963,   inf] (31), [-28.08945,   inf] (35), [-28.08944,   inf] (29), [-28.08939,   inf] (23), [-28.08928,   inf] (25), [-28.08926,   inf] (33), [-28.08915,   inf] (31), [-28.08900,   inf] (29), [-28.08891,   inf] (33), [-28.08889,   inf] (27), [-28.08883,   inf] (35), [-28.08881,   inf] (37), 
length of domains: 30024
Total time: 4.9409	 pickout: 0.3197	 decision: 0.5125	 get_bound: 3.9178	 add_domain: 0.1910
Current lb:-28.09018325805664
59984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 162.48380947113037

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 38] [3, 33] [3, 5] [3, 0] [3, 33] [3, 21] [3, 48] [3, 27] [3, 0] [3, 0] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 53164.1875 with beta sum per layer: [0.0, 0.0, 8.014654159545898, 2164.19189453125]
alpha/beta optimization time: 3.2604126930236816
This batch time : update_bounds func: 3.8808	 prepare: 0.2091	 bound: 3.2609	 transfer: 0.2293	 finalize: 0.1740
Accumulated time: update_bounds func: 125.4172	 prepare: 6.2665	 bound: 102.6808	 transfer: 0.2293	 finalize: 8.6260
batch bounding time:  3.8834939002990723
Current worst splitting domains [lb, ub] (depth):
[-28.02289,   inf] (37), [-28.02280,   inf] (31), [-28.02280,   inf] (21), [-28.02276,   inf] (29), [-28.02272,   inf] (37), [-28.02268,   inf] (19), [-28.02266,   inf] (27), [-28.02261,   inf] (31), [-28.02257,   inf] (29), [-28.02238,   inf] (33), [-28.02237,   inf] (17), [-28.02229,   inf] (31), [-28.02216,   inf] (35), [-28.02212,   inf] (21), [-28.02209,   inf] (37), [-28.02206,   inf] (23), [-28.02204,   inf] (33), [-28.02188,   inf] (31), [-28.02188,   inf] (27), [-28.02186,   inf] (35), 
length of domains: 31024
Total time: 6.0105	 pickout: 0.3400	 decision: 1.5985	 get_bound: 3.8881	 add_domain: 0.1839
Current lb:-28.022886276245117
61984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 168.525461435318

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 46] [3, 21] [3, 51] [3, 33] [3, 48] [3, 5] [3, 51] [2, 86] [3, 33] [3, 0] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 53027.87109375 with beta sum per layer: [0.0, 0.0, 7.3948259353637695, 2157.068603515625]
alpha/beta optimization time: 3.253096103668213
This batch time : update_bounds func: 3.8866	 prepare: 0.2084	 bound: 3.2536	 transfer: 0.2407	 finalize: 0.1764
Accumulated time: update_bounds func: 129.3038	 prepare: 6.4750	 bound: 105.9344	 transfer: 0.2407	 finalize: 8.8024
batch bounding time:  3.8893096446990967
Current worst splitting domains [lb, ub] (depth):
[-27.96000,   inf] (29), [-27.95999,   inf] (35), [-27.95994,   inf] (27), [-27.95985,   inf] (29), [-27.95983,   inf] (33), [-27.95977,   inf] (37), [-27.95971,   inf] (29), [-27.95969,   inf] (17), [-27.95966,   inf] (29), [-27.95962,   inf] (25), [-27.95954,   inf] (29), [-27.95949,   inf] (33), [-27.95940,   inf] (27), [-27.95923,   inf] (33), [-27.95917,   inf] (25), [-27.95899,   inf] (35), [-27.95893,   inf] (35), [-27.95889,   inf] (35), [-27.95889,   inf] (25), [-27.95884,   inf] (21), 
length of domains: 32024
Total time: 4.9071	 pickout: 0.3149	 decision: 0.5111	 get_bound: 3.8940	 add_domain: 0.1871
Current lb:-27.95999526977539
63984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 173.47036981582642

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 38] [3, 48] [3, 51] [3, 33] [3, 0] [3, 48] [3, 33] [3, 5] [3, 38] [3, 45] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 52977.53125 with beta sum per layer: [0.0, 0.0, 6.954598426818848, 2150.37939453125]
alpha/beta optimization time: 3.2510268688201904
This batch time : update_bounds func: 3.8753	 prepare: 0.2101	 bound: 3.2515	 transfer: 0.2279	 finalize: 0.1782
Accumulated time: update_bounds func: 133.1791	 prepare: 6.6850	 bound: 109.1859	 transfer: 0.2279	 finalize: 8.9807
batch bounding time:  3.878080129623413
Current worst splitting domains [lb, ub] (depth):
[-27.90315,   inf] (25), [-27.90310,   inf] (29), [-27.90292,   inf] (35), [-27.90291,   inf] (39), [-27.90288,   inf] (21), [-27.90278,   inf] (27), [-27.90267,   inf] (31), [-27.90261,   inf] (41), [-27.90257,   inf] (31), [-27.90256,   inf] (29), [-27.90254,   inf] (35), [-27.90235,   inf] (33), [-27.90229,   inf] (21), [-27.90216,   inf] (29), [-27.90210,   inf] (25), [-27.90201,   inf] (33), [-27.90178,   inf] (39), [-27.90175,   inf] (21), [-27.90171,   inf] (25), [-27.90170,   inf] (37), 
length of domains: 33024
Total time: 6.0266	 pickout: 0.3455	 decision: 1.6098	 get_bound: 3.8828	 add_domain: 0.1885
Current lb:-27.903146743774414
65984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 179.52970576286316

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 51] [3, 33] [3, 46] [3, 46] [3, 27] [3, 18] [3, 38] [3, 48] [3, 21] [3, 33] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 52795.3359375 with beta sum per layer: [0.0, 0.0, 7.9451799392700195, 2158.96630859375]
alpha/beta optimization time: 3.2460145950317383
This batch time : update_bounds func: 3.8705	 prepare: 0.2117	 bound: 3.2465	 transfer: 0.2295	 finalize: 0.1750
Accumulated time: update_bounds func: 137.0496	 prepare: 6.8968	 bound: 112.4324	 transfer: 0.2295	 finalize: 9.1557
batch bounding time:  3.8730549812316895
Current worst splitting domains [lb, ub] (depth):
[-27.84839,   inf] (27), [-27.84837,   inf] (29), [-27.84834,   inf] (29), [-27.84829,   inf] (33), [-27.84827,   inf] (31), [-27.84823,   inf] (23), [-27.84820,   inf] (21), [-27.84812,   inf] (37), [-27.84804,   inf] (21), [-27.84793,   inf] (33), [-27.84792,   inf] (37), [-27.84791,   inf] (37), [-27.84771,   inf] (31), [-27.84765,   inf] (41), [-27.84759,   inf] (27), [-27.84735,   inf] (39), [-27.84711,   inf] (33), [-27.84710,   inf] (33), [-27.84701,   inf] (35), [-27.84692,   inf] (29), 
length of domains: 34024
Total time: 4.8915	 pickout: 0.3147	 decision: 0.5105	 get_bound: 3.8773	 add_domain: 0.1891
Current lb:-27.848392486572266
67984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 184.46207332611084

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 27] [3, 33] [3, 21] [2, 102] [3, 21] [3, 45] [3, 27] [2, 14] [3, 5] [3, 0] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 52710.28125 with beta sum per layer: [0.0, 0.0, 6.80668306350708, 2100.138671875]
alpha/beta optimization time: 3.24641489982605
This batch time : update_bounds func: 3.8671	 prepare: 0.2101	 bound: 3.2469	 transfer: 0.2280	 finalize: 0.1753
Accumulated time: update_bounds func: 140.9167	 prepare: 7.1069	 bound: 115.6793	 transfer: 0.2280	 finalize: 9.3310
batch bounding time:  3.8700449466705322
Current worst splitting domains [lb, ub] (depth):
[-27.79048,   inf] (31), [-27.79023,   inf] (35), [-27.79019,   inf] (29), [-27.79006,   inf] (25), [-27.79003,   inf] (39), [-27.78999,   inf] (23), [-27.78991,   inf] (23), [-27.78990,   inf] (37), [-27.78979,   inf] (33), [-27.78978,   inf] (39), [-27.78977,   inf] (37), [-27.78963,   inf] (41), [-27.78962,   inf] (37), [-27.78959,   inf] (31), [-27.78958,   inf] (27), [-27.78954,   inf] (37), [-27.78948,   inf] (25), [-27.78940,   inf] (29), [-27.78938,   inf] (31), [-27.78935,   inf] (35), 
length of domains: 35024
Total time: 6.0574	 pickout: 0.3298	 decision: 1.6636	 get_bound: 3.8749	 add_domain: 0.1890
Current lb:-27.790481567382812
69984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 190.55640602111816

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 108] [3, 48] [3, 38] [3, 45] [3, 46] [3, 11] [3, 45] [2, 14] [2, 101] [3, 46] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 52665.6015625 with beta sum per layer: [0.0, 0.0, 11.040142059326172, 2126.081787109375]
alpha/beta optimization time: 3.2496182918548584
This batch time : update_bounds func: 3.8675	 prepare: 0.2103	 bound: 3.2501	 transfer: 0.2224	 finalize: 0.1778
Accumulated time: update_bounds func: 144.7842	 prepare: 7.3172	 bound: 118.9294	 transfer: 0.2224	 finalize: 9.5088
batch bounding time:  3.870462417602539
Current worst splitting domains [lb, ub] (depth):
[-27.73372,   inf] (25), [-27.73367,   inf] (27), [-27.73358,   inf] (29), [-27.73353,   inf] (29), [-27.73344,   inf] (39), [-27.73338,   inf] (33), [-27.73332,   inf] (27), [-27.73330,   inf] (35), [-27.73318,   inf] (37), [-27.73318,   inf] (31), [-27.73314,   inf] (37), [-27.73293,   inf] (23), [-27.73293,   inf] (29), [-27.73287,   inf] (27), [-27.73287,   inf] (33), [-27.73283,   inf] (31), [-27.73283,   inf] (25), [-27.73282,   inf] (35), [-27.73277,   inf] (25), [-27.73276,   inf] (21), 
length of domains: 36024
Total time: 4.9281	 pickout: 0.3476	 decision: 0.5148	 get_bound: 3.8756	 add_domain: 0.1901
Current lb:-27.733722686767578
71984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 195.51951265335083

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 51] [3, 51] [3, 38] [3, 33] [3, 46] [2, 14] [3, 51] [2, 14] [2, 126] [3, 21] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 52610.546875 with beta sum per layer: [0.0, 0.0, 10.635549545288086, 2145.68359375]
alpha/beta optimization time: 3.245856523513794
This batch time : update_bounds func: 3.8607	 prepare: 0.2111	 bound: 3.2463	 transfer: 0.2228	 finalize: 0.1736
Accumulated time: update_bounds func: 148.6449	 prepare: 7.5283	 bound: 122.1757	 transfer: 0.2228	 finalize: 9.6824
batch bounding time:  3.8634278774261475
Current worst splitting domains [lb, ub] (depth):
[-27.68399,   inf] (37), [-27.68394,   inf] (37), [-27.68387,   inf] (21), [-27.68386,   inf] (29), [-27.68384,   inf] (33), [-27.68379,   inf] (27), [-27.68372,   inf] (25), [-27.68372,   inf] (35), [-27.68371,   inf] (33), [-27.68361,   inf] (35), [-27.68359,   inf] (33), [-27.68350,   inf] (39), [-27.68339,   inf] (35), [-27.68330,   inf] (19), [-27.68308,   inf] (37), [-27.68304,   inf] (23), [-27.68302,   inf] (35), [-27.68301,   inf] (25), [-27.68293,   inf] (35), [-27.68292,   inf] (25), 
length of domains: 37024
Total time: 6.1824	 pickout: 0.3432	 decision: 1.7812	 get_bound: 3.8681	 add_domain: 0.1899
Current lb:-27.683990478515625
73984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 201.73357772827148

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 48] [3, 48] [3, 5] [3, 33] [3, 0] [3, 51] [3, 51] [3, 48] [3, 0] [3, 2] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 52478.85546875 with beta sum per layer: [0.0, 0.0, 10.699501991271973, 2133.4560546875]
alpha/beta optimization time: 3.251598358154297
This batch time : update_bounds func: 3.8959	 prepare: 0.2148	 bound: 3.2521	 transfer: 0.2395	 finalize: 0.1825
Accumulated time: update_bounds func: 152.5407	 prepare: 7.7431	 bound: 125.4279	 transfer: 0.2395	 finalize: 9.8649
batch bounding time:  3.8987812995910645
Current worst splitting domains [lb, ub] (depth):
[-27.63364,   inf] (27), [-27.63362,   inf] (27), [-27.63360,   inf] (31), [-27.63353,   inf] (35), [-27.63347,   inf] (35), [-27.63340,   inf] (31), [-27.63338,   inf] (31), [-27.63333,   inf] (21), [-27.63324,   inf] (33), [-27.63321,   inf] (37), [-27.63319,   inf] (37), [-27.63318,   inf] (27), [-27.63315,   inf] (35), [-27.63315,   inf] (31), [-27.63314,   inf] (27), [-27.63309,   inf] (23), [-27.63300,   inf] (37), [-27.63299,   inf] (37), [-27.63285,   inf] (33), [-27.63284,   inf] (39), 
length of domains: 38024
Total time: 4.9311	 pickout: 0.3087	 decision: 0.5264	 get_bound: 3.9036	 add_domain: 0.1924
Current lb:-27.633638381958008
75984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 206.71775841712952

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 51] [3, 51] [3, 33] [3, 0] [3, 46] [2, 101] [3, 21] [3, 11] [3, 0] [3, 2] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 52483.66015625 with beta sum per layer: [0.0, 0.0, 10.363709449768066, 2076.738525390625]
alpha/beta optimization time: 3.2485454082489014
This batch time : update_bounds func: 3.8817	 prepare: 0.2144	 bound: 3.2490	 transfer: 0.2282	 finalize: 0.1830
Accumulated time: update_bounds func: 156.4224	 prepare: 7.9575	 bound: 128.6769	 transfer: 0.2282	 finalize: 10.0479
batch bounding time:  3.884507656097412
Current worst splitting domains [lb, ub] (depth):
[-27.58485,   inf] (19), [-27.58478,   inf] (29), [-27.58468,   inf] (25), [-27.58456,   inf] (33), [-27.58455,   inf] (33), [-27.58453,   inf] (33), [-27.58451,   inf] (29), [-27.58449,   inf] (21), [-27.58443,   inf] (27), [-27.58441,   inf] (37), [-27.58434,   inf] (33), [-27.58431,   inf] (25), [-27.58427,   inf] (35), [-27.58425,   inf] (39), [-27.58406,   inf] (39), [-27.58406,   inf] (25), [-27.58388,   inf] (23), [-27.58387,   inf] (19), [-27.58369,   inf] (31), [-27.58368,   inf] (33), 
length of domains: 39024
Total time: 6.2588	 pickout: 0.3266	 decision: 1.8477	 get_bound: 3.8891	 add_domain: 0.1954
Current lb:-27.584848403930664
77984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 213.01867246627808

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 27] [3, 33] [3, 45] [3, 21] [3, 0] [2, 14] [3, 33] [3, 11] [3, 38] [3, 46] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 52328.0546875 with beta sum per layer: [0.0, 0.0, 11.927392959594727, 2165.84521484375]
alpha/beta optimization time: 3.249457836151123
This batch time : update_bounds func: 3.8974	 prepare: 0.2131	 bound: 3.2499	 transfer: 0.2486	 finalize: 0.1788
Accumulated time: update_bounds func: 160.3198	 prepare: 8.1706	 bound: 131.9268	 transfer: 0.2486	 finalize: 10.2266
batch bounding time:  3.900360584259033
Current worst splitting domains [lb, ub] (depth):
[-27.53892,   inf] (27), [-27.53888,   inf] (33), [-27.53885,   inf] (31), [-27.53873,   inf] (37), [-27.53871,   inf] (31), [-27.53870,   inf] (31), [-27.53851,   inf] (29), [-27.53845,   inf] (25), [-27.53842,   inf] (31), [-27.53838,   inf] (29), [-27.53824,   inf] (41), [-27.53817,   inf] (39), [-27.53806,   inf] (23), [-27.53800,   inf] (31), [-27.53790,   inf] (39), [-27.53788,   inf] (27), [-27.53788,   inf] (31), [-27.53784,   inf] (31), [-27.53780,   inf] (39), [-27.53776,   inf] (31), 
length of domains: 40024
Total time: 4.9537	 pickout: 0.3390	 decision: 0.5129	 get_bound: 3.9053	 add_domain: 0.1965
Current lb:-27.538915634155273
79984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 218.01079559326172

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 38] [3, 21] [3, 21] [3, 2] [3, 21] [2, 101] [3, 33] [3, 45] [2, 101] [3, 33] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 52276.79296875 with beta sum per layer: [0.0, 0.0, 12.910690307617188, 2121.15283203125]
alpha/beta optimization time: 3.24773907661438
This batch time : update_bounds func: 5.3617	 prepare: 0.2116	 bound: 3.2482	 transfer: 0.2226	 finalize: 1.6722
Accumulated time: update_bounds func: 165.6815	 prepare: 8.3822	 bound: 135.1751	 transfer: 0.2226	 finalize: 11.8988
batch bounding time:  5.364490032196045
Current worst splitting domains [lb, ub] (depth):
[-27.49132,   inf] (21), [-27.49132,   inf] (33), [-27.49123,   inf] (37), [-27.49121,   inf] (23), [-27.49102,   inf] (19), [-27.49102,   inf] (33), [-27.49095,   inf] (37), [-27.49094,   inf] (39), [-27.49093,   inf] (31), [-27.49090,   inf] (27), [-27.49078,   inf] (33), [-27.49077,   inf] (23), [-27.49074,   inf] (37), [-27.49067,   inf] (33), [-27.49066,   inf] (39), [-27.49065,   inf] (21), [-27.49061,   inf] (23), [-27.49043,   inf] (33), [-27.49025,   inf] (25), [-27.49023,   inf] (21), 
length of domains: 41024
Total time: 6.4435	 pickout: 0.3665	 decision: 0.5159	 get_bound: 5.3692	 add_domain: 0.1919
Current lb:-27.491323471069336
81984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 224.48605728149414

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 45] [3, 48] [3, 46] [3, 27] [3, 11] [3, 0] [3, 46] [3, 0] [2, 101] [3, 21] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 52173.890625 with beta sum per layer: [0.0, 0.0, 10.989078521728516, 2120.21630859375]
alpha/beta optimization time: 3.249169111251831
This batch time : update_bounds func: 3.8773	 prepare: 0.2110	 bound: 3.2496	 transfer: 0.2292	 finalize: 0.1800
Accumulated time: update_bounds func: 169.5588	 prepare: 8.5932	 bound: 138.4247	 transfer: 0.2292	 finalize: 12.0788
batch bounding time:  3.8799381256103516
Current worst splitting domains [lb, ub] (depth):
[-27.44453,   inf] (37), [-27.44453,   inf] (29), [-27.44451,   inf] (33), [-27.44446,   inf] (31), [-27.44430,   inf] (25), [-27.44429,   inf] (33), [-27.44426,   inf] (33), [-27.44426,   inf] (37), [-27.44424,   inf] (35), [-27.44423,   inf] (25), [-27.44421,   inf] (33), [-27.44421,   inf] (37), [-27.44418,   inf] (31), [-27.44417,   inf] (29), [-27.44416,   inf] (27), [-27.44406,   inf] (31), [-27.44400,   inf] (19), [-27.44396,   inf] (29), [-27.44372,   inf] (29), [-27.44370,   inf] (29), 
length of domains: 42024
Total time: 4.9096	 pickout: 0.3124	 decision: 0.5199	 get_bound: 3.8844	 add_domain: 0.1930
Current lb:-27.444530487060547
83984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 229.4339485168457

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 48] [3, 38] [3, 0] [3, 21] [3, 51] [3, 0] [3, 21] [3, 2] [3, 46] [3, 35] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 52033.0703125 with beta sum per layer: [0.0, 0.0, 9.989096641540527, 2234.17236328125]
alpha/beta optimization time: 3.2473182678222656
This batch time : update_bounds func: 3.8857	 prepare: 0.2088	 bound: 3.2478	 transfer: 0.2374	 finalize: 0.1843
Accumulated time: update_bounds func: 173.4445	 prepare: 8.8020	 bound: 141.6725	 transfer: 0.2374	 finalize: 12.2631
batch bounding time:  3.8884952068328857
Current worst splitting domains [lb, ub] (depth):
[-27.39985,   inf] (23), [-27.39977,   inf] (25), [-27.39977,   inf] (33), [-27.39974,   inf] (29), [-27.39964,   inf] (29), [-27.39963,   inf] (33), [-27.39961,   inf] (23), [-27.39955,   inf] (35), [-27.39952,   inf] (39), [-27.39951,   inf] (21), [-27.39948,   inf] (39), [-27.39939,   inf] (29), [-27.39937,   inf] (33), [-27.39929,   inf] (31), [-27.39929,   inf] (27), [-27.39925,   inf] (35), [-27.39923,   inf] (37), [-27.39919,   inf] (29), [-27.39918,   inf] (33), [-27.39916,   inf] (35), 
length of domains: 43024
Total time: 4.9251	 pickout: 0.3170	 decision: 0.5187	 get_bound: 3.8933	 add_domain: 0.1961
Current lb:-27.399845123291016
85984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 234.3977563381195

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 45] [3, 29] [3, 0] [3, 33] [3, 33] [3, 0] [3, 51] [3, 0] [3, 46] [3, 5] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 51990.5625 with beta sum per layer: [0.0, 0.0, 10.858291625976562, 2180.52099609375]
alpha/beta optimization time: 3.246269941329956
This batch time : update_bounds func: 3.8760	 prepare: 0.2133	 bound: 3.2467	 transfer: 0.2298	 finalize: 0.1787
Accumulated time: update_bounds func: 177.3206	 prepare: 9.0153	 bound: 144.9193	 transfer: 0.2298	 finalize: 12.4418
batch bounding time:  3.879112720489502
Current worst splitting domains [lb, ub] (depth):
[-27.35577,   inf] (37), [-27.35575,   inf] (39), [-27.35568,   inf] (27), [-27.35567,   inf] (35), [-27.35564,   inf] (39), [-27.35563,   inf] (29), [-27.35555,   inf] (31), [-27.35546,   inf] (23), [-27.35536,   inf] (29), [-27.35536,   inf] (39), [-27.35521,   inf] (37), [-27.35516,   inf] (25), [-27.35510,   inf] (37), [-27.35509,   inf] (31), [-27.35501,   inf] (25), [-27.35501,   inf] (31), [-27.35499,   inf] (27), [-27.35496,   inf] (33), [-27.35483,   inf] (33), [-27.35479,   inf] (31), 
length of domains: 44024
Total time: 6.4878	 pickout: 0.3619	 decision: 2.0475	 get_bound: 3.8844	 add_domain: 0.1940
Current lb:-27.355772018432617
87984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 240.91878652572632

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 101] [3, 46] [3, 38] [3, 46] [3, 46] [3, 38] [3, 21] [3, 18] [3, 33] [3, 48] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 51935.0390625 with beta sum per layer: [0.0, 0.0, 11.283111572265625, 2142.35009765625]
alpha/beta optimization time: 3.2481889724731445
This batch time : update_bounds func: 3.8739	 prepare: 0.2117	 bound: 3.2487	 transfer: 0.2281	 finalize: 0.1781
Accumulated time: update_bounds func: 181.1945	 prepare: 9.2270	 bound: 148.1679	 transfer: 0.2281	 finalize: 12.6199
batch bounding time:  3.876805543899536
Current worst splitting domains [lb, ub] (depth):
[-27.31305,   inf] (35), [-27.31296,   inf] (41), [-27.31294,   inf] (31), [-27.31285,   inf] (27), [-27.31285,   inf] (27), [-27.31279,   inf] (29), [-27.31279,   inf] (39), [-27.31278,   inf] (23), [-27.31277,   inf] (25), [-27.31274,   inf] (27), [-27.31270,   inf] (35), [-27.31266,   inf] (27), [-27.31262,   inf] (35), [-27.31253,   inf] (25), [-27.31248,   inf] (21), [-27.31244,   inf] (31), [-27.31241,   inf] (27), [-27.31241,   inf] (33), [-27.31240,   inf] (41), [-27.31233,   inf] (33), 
length of domains: 45024
Total time: 4.9159	 pickout: 0.3199	 decision: 0.5178	 get_bound: 3.8818	 add_domain: 0.1963
Current lb:-27.313053131103516
89984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 245.87545585632324

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 2] [3, 48] [3, 21] [3, 27] [3, 33] [3, 33] [3, 48] [3, 38] [3, 11] [3, 29] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 51762.671875 with beta sum per layer: [0.0, 0.0, 11.071882247924805, 2221.5986328125]
alpha/beta optimization time: 3.247562885284424
This batch time : update_bounds func: 5.5017	 prepare: 0.2132	 bound: 3.2480	 transfer: 0.2271	 finalize: 1.8058
Accumulated time: update_bounds func: 186.6961	 prepare: 9.4402	 bound: 151.4160	 transfer: 0.2271	 finalize: 14.4257
batch bounding time:  5.504658460617065
Current worst splitting domains [lb, ub] (depth):
[-27.27203,   inf] (27), [-27.27194,   inf] (27), [-27.27192,   inf] (37), [-27.27183,   inf] (31), [-27.27172,   inf] (37), [-27.27167,   inf] (39), [-27.27156,   inf] (27), [-27.27154,   inf] (37), [-27.27152,   inf] (27), [-27.27145,   inf] (25), [-27.27138,   inf] (37), [-27.27134,   inf] (25), [-27.27131,   inf] (43), [-27.27130,   inf] (33), [-27.27125,   inf] (27), [-27.27122,   inf] (33), [-27.27120,   inf] (35), [-27.27120,   inf] (31), [-27.27115,   inf] (37), [-27.27112,   inf] (33), 
length of domains: 46024
Total time: 6.5476	 pickout: 0.3289	 decision: 0.5172	 get_bound: 5.5097	 add_domain: 0.1918
Current lb:-27.272031784057617
91984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 252.45979499816895

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 38] [3, 51] [3, 48] [3, 21] [3, 2] [3, 48] [3, 38] [3, 48] [3, 33] [3, 38] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 51666.22265625 with beta sum per layer: [0.0, 0.0, 11.636942863464355, 2238.6142578125]
alpha/beta optimization time: 3.2456254959106445
This batch time : update_bounds func: 3.8678	 prepare: 0.2096	 bound: 3.2461	 transfer: 0.2274	 finalize: 0.1774
Accumulated time: update_bounds func: 190.5640	 prepare: 9.6498	 bound: 154.6621	 transfer: 0.2274	 finalize: 14.6031
batch bounding time:  3.8704988956451416
Current worst splitting domains [lb, ub] (depth):
[-27.23058,   inf] (25), [-27.23057,   inf] (29), [-27.23052,   inf] (33), [-27.23045,   inf] (35), [-27.23044,   inf] (25), [-27.23044,   inf] (25), [-27.23042,   inf] (23), [-27.23039,   inf] (39), [-27.23037,   inf] (29), [-27.23031,   inf] (23), [-27.23024,   inf] (27), [-27.23021,   inf] (37), [-27.23021,   inf] (25), [-27.23006,   inf] (37), [-27.23006,   inf] (31), [-27.23005,   inf] (29), [-27.22988,   inf] (35), [-27.22965,   inf] (35), [-27.22950,   inf] (27), [-27.22944,   inf] (39), 
length of domains: 47024
Total time: 4.9104	 pickout: 0.3204	 decision: 0.5201	 get_bound: 3.8752	 add_domain: 0.1947
Current lb:-27.230579376220703
93984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 257.408810377121

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 51] [3, 33] [3, 0] [3, 2] [3, 38] [3, 11] [3, 45] [3, 46] [3, 33] [3, 11] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 51714.8125 with beta sum per layer: [0.0, 0.0, 14.084193229675293, 2171.21142578125]
alpha/beta optimization time: 3.248739242553711
This batch time : update_bounds func: 3.8793	 prepare: 0.2143	 bound: 3.2493	 transfer: 0.2271	 finalize: 0.1799
Accumulated time: update_bounds func: 194.4432	 prepare: 9.8641	 bound: 157.9114	 transfer: 0.2271	 finalize: 14.7830
batch bounding time:  3.88213849067688
Current worst splitting domains [lb, ub] (depth):
[-27.19176,   inf] (37), [-27.19174,   inf] (41), [-27.19170,   inf] (27), [-27.19164,   inf] (37), [-27.19159,   inf] (35), [-27.19158,   inf] (29), [-27.19153,   inf] (37), [-27.19138,   inf] (37), [-27.19130,   inf] (29), [-27.19115,   inf] (29), [-27.19115,   inf] (33), [-27.19111,   inf] (27), [-27.19109,   inf] (31), [-27.19104,   inf] (33), [-27.19104,   inf] (27), [-27.19100,   inf] (25), [-27.19098,   inf] (41), [-27.19089,   inf] (35), [-27.19088,   inf] (19), [-27.19077,   inf] (35), 
length of domains: 48024
Total time: 4.9255	 pickout: 0.3222	 decision: 0.5205	 get_bound: 3.8870	 add_domain: 0.1959
Current lb:-27.191761016845703
95984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 262.37339091300964

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 48] [2, 126] [3, 38] [3, 46] [3, 21] [3, 51] [2, 39] [3, 48] [3, 38] [3, 33] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 51596.52734375 with beta sum per layer: [0.0, 0.0, 17.39722442626953, 2135.517578125]
alpha/beta optimization time: 3.2481651306152344
This batch time : update_bounds func: 5.5892	 prepare: 0.2116	 bound: 3.2486	 transfer: 0.2237	 finalize: 1.8978
Accumulated time: update_bounds func: 200.0324	 prepare: 10.0757	 bound: 161.1600	 transfer: 0.2237	 finalize: 16.6807
batch bounding time:  5.592323064804077
Current worst splitting domains [lb, ub] (depth):
[-27.15202,   inf] (29), [-27.15202,   inf] (35), [-27.15196,   inf] (27), [-27.15193,   inf] (27), [-27.15189,   inf] (23), [-27.15173,   inf] (31), [-27.15171,   inf] (27), [-27.15170,   inf] (39), [-27.15169,   inf] (25), [-27.15161,   inf] (33), [-27.15159,   inf] (23), [-27.15158,   inf] (35), [-27.15156,   inf] (33), [-27.15154,   inf] (33), [-27.15154,   inf] (37), [-27.15153,   inf] (33), [-27.15152,   inf] (35), [-27.15149,   inf] (35), [-27.15139,   inf] (25), [-27.15137,   inf] (35), 
length of domains: 49024
Total time: 6.6718	 pickout: 0.3610	 decision: 0.5205	 get_bound: 5.5972	 add_domain: 0.1931
Current lb:-27.152021408081055
97984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 269.08237290382385

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 33] [3, 48] [3, 38] [3, 45] [3, 51] [3, 21] [3, 33] [3, 0] [3, 51] [3, 0] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 51529.3515625 with beta sum per layer: [0.0, 0.0, 14.168106079101562, 2213.39111328125]
alpha/beta optimization time: 3.2389066219329834
This batch time : update_bounds func: 3.8659	 prepare: 0.2141	 bound: 3.2394	 transfer: 0.2234	 finalize: 0.1818
Accumulated time: update_bounds func: 203.8984	 prepare: 10.2898	 bound: 164.3994	 transfer: 0.2234	 finalize: 16.8625
batch bounding time:  3.8687703609466553
Current worst splitting domains [lb, ub] (depth):
[-27.11263,   inf] (39), [-27.11263,   inf] (27), [-27.11260,   inf] (35), [-27.11258,   inf] (35), [-27.11257,   inf] (41), [-27.11251,   inf] (19), [-27.11251,   inf] (33), [-27.11239,   inf] (35), [-27.11238,   inf] (41), [-27.11233,   inf] (31), [-27.11233,   inf] (37), [-27.11222,   inf] (33), [-27.11215,   inf] (37), [-27.11214,   inf] (21), [-27.11211,   inf] (39), [-27.11208,   inf] (27), [-27.11207,   inf] (39), [-27.11205,   inf] (37), [-27.11199,   inf] (27), [-27.11192,   inf] (35), 
length of domains: 50024
Total time: 4.9192	 pickout: 0.3323	 decision: 0.5206	 get_bound: 3.8732	 add_domain: 0.1930
Current lb:-27.112634658813477
99984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 274.04527711868286

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 46] [3, 33] [3, 48] [2, 101] [2, 101] [3, 45] [2, 108] [3, 0] [3, 46] [3, 21] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 51496.87109375 with beta sum per layer: [0.0, 0.0, 16.35085678100586, 2163.25927734375]
alpha/beta optimization time: 3.234290838241577
This batch time : update_bounds func: 3.8548	 prepare: 0.2099	 bound: 3.2348	 transfer: 0.2232	 finalize: 0.1799
Accumulated time: update_bounds func: 207.7532	 prepare: 10.4998	 bound: 167.6341	 transfer: 0.2232	 finalize: 17.0424
batch bounding time:  3.8573801517486572
Current worst splitting domains [lb, ub] (depth):
[-27.07504,   inf] (37), [-27.07502,   inf] (33), [-27.07498,   inf] (41), [-27.07497,   inf] (37), [-27.07497,   inf] (37), [-27.07495,   inf] (29), [-27.07495,   inf] (31), [-27.07494,   inf] (43), [-27.07489,   inf] (39), [-27.07488,   inf] (37), [-27.07485,   inf] (27), [-27.07482,   inf] (19), [-27.07462,   inf] (37), [-27.07460,   inf] (37), [-27.07452,   inf] (25), [-27.07450,   inf] (33), [-27.07450,   inf] (35), [-27.07442,   inf] (29), [-27.07432,   inf] (33), [-27.07432,   inf] (41), 
length of domains: 51024
Total time: 4.8961	 pickout: 0.3245	 decision: 0.5147	 get_bound: 3.8619	 add_domain: 0.1949
Current lb:-27.075040817260742
101984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 278.9870584011078

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 2] [3, 0] [3, 48] [2, 101] [3, 48] [3, 33] [3, 21] [2, 126] [3, 2] [3, 0] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 51460.3046875 with beta sum per layer: [0.0, 0.0, 14.76073932647705, 2180.8837890625]
alpha/beta optimization time: 3.2310049533843994
This batch time : update_bounds func: 5.7701	 prepare: 0.2123	 bound: 3.2315	 transfer: 0.2235	 finalize: 2.0957
Accumulated time: update_bounds func: 213.5232	 prepare: 10.7120	 bound: 170.8656	 transfer: 0.2235	 finalize: 19.1381
batch bounding time:  5.77283787727356
Current worst splitting domains [lb, ub] (depth):
[-27.04069,   inf] (35), [-27.04067,   inf] (19), [-27.04066,   inf] (25), [-27.04061,   inf] (27), [-27.04059,   inf] (23), [-27.04054,   inf] (35), [-27.04053,   inf] (37), [-27.04049,   inf] (23), [-27.04047,   inf] (37), [-27.04046,   inf] (33), [-27.04046,   inf] (43), [-27.04040,   inf] (35), [-27.04039,   inf] (31), [-27.04016,   inf] (39), [-27.04015,   inf] (43), [-27.04014,   inf] (23), [-27.04010,   inf] (33), [-27.04010,   inf] (33), [-27.04002,   inf] (19), [-27.04000,   inf] (35), 
length of domains: 52024
Total time: 6.8282	 pickout: 0.3453	 decision: 0.5121	 get_bound: 5.7773	 add_domain: 0.1935
Current lb:-27.040691375732422
103984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 285.8523118495941

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 2] [3, 38] [3, 33] [3, 38] [3, 45] [3, 46] [3, 48] [3, 27] [3, 2] [3, 48] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 51392.40625 with beta sum per layer: [0.0, 0.0, 16.928565979003906, 2151.048828125]
alpha/beta optimization time: 3.2363929748535156
This batch time : update_bounds func: 3.8737	 prepare: 0.2103	 bound: 3.2369	 transfer: 0.2417	 finalize: 0.1774
Accumulated time: update_bounds func: 217.3970	 prepare: 10.9223	 bound: 174.1025	 transfer: 0.2417	 finalize: 19.3155
batch bounding time:  3.8764052391052246
Current worst splitting domains [lb, ub] (depth):
[-27.00593,   inf] (27), [-27.00588,   inf] (43), [-27.00587,   inf] (31), [-27.00578,   inf] (39), [-27.00577,   inf] (21), [-27.00574,   inf] (41), [-27.00574,   inf] (29), [-27.00572,   inf] (33), [-27.00572,   inf] (33), [-27.00572,   inf] (29), [-27.00572,   inf] (33), [-27.00570,   inf] (29), [-27.00561,   inf] (39), [-27.00557,   inf] (23), [-27.00550,   inf] (33), [-27.00549,   inf] (25), [-27.00547,   inf] (29), [-27.00546,   inf] (31), [-27.00541,   inf] (35), [-27.00541,   inf] (31), 
length of domains: 53024
Total time: 4.9302	 pickout: 0.3272	 decision: 0.5214	 get_bound: 3.8809	 add_domain: 0.2007
Current lb:-27.005929946899414
105984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 290.8239574432373

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 27] [2, 126] [3, 21] [3, 48] [3, 51] [3, 48] [3, 33] [3, 2] [3, 0] [3, 33] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 51304.38671875 with beta sum per layer: [0.0, 0.0, 18.533977508544922, 2114.625]
alpha/beta optimization time: 3.2468931674957275
This batch time : update_bounds func: 3.8686	 prepare: 0.2095	 bound: 3.2473	 transfer: 0.2296	 finalize: 0.1746
Accumulated time: update_bounds func: 221.2656	 prepare: 11.1319	 bound: 177.3498	 transfer: 0.2296	 finalize: 19.4902
batch bounding time:  3.871223211288452
Current worst splitting domains [lb, ub] (depth):
[-26.97148,   inf] (25), [-26.97147,   inf] (33), [-26.97147,   inf] (31), [-26.97146,   inf] (33), [-26.97145,   inf] (23), [-26.97142,   inf] (43), [-26.97141,   inf] (31), [-26.97139,   inf] (27), [-26.97139,   inf] (31), [-26.97138,   inf] (31), [-26.97137,   inf] (35), [-26.97135,   inf] (31), [-26.97128,   inf] (39), [-26.97124,   inf] (39), [-26.97123,   inf] (23), [-26.97120,   inf] (27), [-26.97120,   inf] (27), [-26.97119,   inf] (41), [-26.97117,   inf] (31), [-26.97113,   inf] (35), 
length of domains: 54024
Total time: 4.9264	 pickout: 0.3345	 decision: 0.5196	 get_bound: 3.8755	 add_domain: 0.1968
Current lb:-26.971477508544922
107984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 295.78277587890625

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 32, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 32, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 45] [3, 0] [2, 101] [3, 0] [3, 27] [2, 126] [3, 21] [3, 38] [3, 38] [3, 21] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 51247.9375 with beta sum per layer: [0.0, 0.0, 15.712533950805664, 2161.693115234375]
alpha/beta optimization time: 3.209050416946411
This batch time : update_bounds func: 5.7132	 prepare: 0.2086	 bound: 3.2095	 transfer: 0.2233	 finalize: 2.0645
Accumulated time: update_bounds func: 226.9787	 prepare: 11.3405	 bound: 180.5593	 transfer: 0.2233	 finalize: 21.5547
batch bounding time:  5.715707540512085
Current worst splitting domains [lb, ub] (depth):
[-26.93759,   inf] (41), [-26.93750,   inf] (37), [-26.93750,   inf] (19), [-26.93747,   inf] (37), [-26.93747,   inf] (39), [-26.93744,   inf] (39), [-26.93744,   inf] (21), [-26.93741,   inf] (31), [-26.93738,   inf] (35), [-26.93736,   inf] (29), [-26.93736,   inf] (21), [-26.93735,   inf] (37), [-26.93735,   inf] (31), [-26.93732,   inf] (25), [-26.93732,   inf] (33), [-26.93731,   inf] (37), [-26.93730,   inf] (37), [-26.93730,   inf] (25), [-26.93729,   inf] (27), [-26.93726,   inf] (35), 
length of domains: 55024
Total time: 6.7489	 pickout: 0.3227	 decision: 0.5124	 get_bound: 5.7199	 add_domain: 0.1938
Current lb:-26.937591552734375
109984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Time out!!!!!!!!
Image 0 against label 3 verification end, Time cost: 304.5345387458801
Result: unknown in 320.6171 seconds


[[     0.            -26.93759155 109984.            304.53453875
       3.        ]]
############# Summary #############
Final verified acc: 0.0% [total 1 examples]
Total verification count: 1 , total verified safe:/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:25: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1627336316785/work/torch/csrc/utils/tensor_numpy.cpp:143.)
  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))
 0 , verified unsafe: 0 , timeout: 1
mean time [total:1]: 304.5345387458801
mean time [cnt:1]: 304.5345387458801
max time 320.617075920105
unknown (total 1): [0]
