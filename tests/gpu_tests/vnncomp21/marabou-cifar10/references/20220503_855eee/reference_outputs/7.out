Building native CUDA modules...
/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
  csv_name: marabou-cifar10_instances.csv
  onnx_path: null
  vnnlib_path: null
  results_file: null
  root_path: ../../../../../vnncomp2021/benchmarks/marabou-cifar10
model:
  path: null
  name: mnist_9_200
data:
  start: 49
  end: 50
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR
  data_filter_path: null
specification:
  type: lp
  norm: .inf
  epsilon: null
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 1000
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.5
    lr_decay: 0.98
    optimizer: adam
    iteration: 50
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 360
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 5
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:35:17 2022 on ubuntu
saving results to vnn-comp_[marabou-cifar10_instances]_start=49_end=50_iter=50_b=1000_timeout=360_branching=kfsb-min-5_lra-init=0.1_lra=0.01_lrb=0.5_PGD=skip.npz
customized start/end sample from 49 to 50

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Notice: this ONNX file has NHWC order. We assume the X in vnnlib is also flattend in in NHWC order (1, 32, 32, 3)
[-3.3362026  -4.7935624   1.2095591   1.1297324   2.8093104   1.2251365
  1.2002211  -0.33071804 -4.9189496  -4.553255  ]
Model prediction is: tensor([[-3.3362, -4.7936,  1.2096,  1.1297,  2.8093,  1.2251,  1.2002, -0.3307,
         -4.9189, -4.5533]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-80.0912, -84.8317, -53.6432, -54.6565, -51.7351, -63.2373, -55.4971,
         -80.4472, -82.0829]], device='cuda:0') None
best_l after optimization: 390.0514831542969 with beta sum per layer: []
alpha/beta optimization time: 10.658367395401001
initial alpha-CROWN bounds: tensor([[-48.7394, -50.5567, -38.5320, -39.0566, -39.1108, -43.6300, -39.1276,
         -43.5209, -47.7776]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-50.5567, device='cuda:0', grad_fn=<MinBackward1>)
##### [0] True label: 4, Tested against: 2, onnx_path: ./nets/cifar10_medium.onnx, vnnlib_path: ./specs/networkcifar10_medium_index3364_eps0.012_target5_orig4.vnnlib ######
Model prediction is: tensor([[-3.3362, -4.7936,  1.2096,  1.1297,  2.8093,  1.2251,  1.2002, -0.3307,
         -4.9189, -4.5533]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /12 start_node /13
setting alpha for layer /12 start_node /16
setting alpha for layer /12 start_node /18
not setting layer /12 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 16, 15, 15]) != torch.Size([2, 9, 1, 16, 15, 15]))
setting alpha for layer /14 start_node /16
setting alpha for layer /14 start_node /18
not setting layer /14 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 32, 6, 6]) != torch.Size([2, 9, 1, 32, 6, 6]))
setting alpha for layer /17 start_node /18
not setting layer /17 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 128]) != torch.Size([2, 9, 1, 128]))
not setting layer /19 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 64]) != torch.Size([2, 9, 1, 64]))
0 /11 torch.Size([1, 16, 15, 15])
1 /13 torch.Size([1, 32, 6, 6])
2 /16 torch.Size([1, 128])
3 /18 torch.Size([1, 64])
best_l after optimization: 38.53136444091797 with beta sum per layer: []
alpha/beta optimization time: 2.0745575428009033
alpha-CROWN with fixed intermediate bounds: tensor([[-38.5314]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-38.531368255615234
layer 0 size torch.Size([3600]) unstable 1062
layer 1 size torch.Size([1152]) unstable 537
layer 2 size torch.Size([128]) unstable 125
layer 3 size torch.Size([64]) unstable 64
-----------------
# of unstable neurons: 1788
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 15, 15]) pre split depth:  6
batch:  torch.Size([1, 16, 15, 15]) post split depth:  6
splitting decisions: 
split level 0: [3, 56] 
split level 1: [3, 18] 
split level 2: [3, 30] 
split level 3: [3, 48] 
split level 4: [3, 61] 
split level 5: [3, 54] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: 1770.4677734375 with beta sum per layer: [0.0, 0.0, 0.0, 13.548276901245117]
alpha/beta optimization time: 0.701019287109375
This batch time : update_bounds func: 0.7151	 prepare: 0.0063	 bound: 0.7014	 transfer: 0.0026	 finalize: 0.0046
Accumulated time: update_bounds func: 0.7151	 prepare: 0.0063	 bound: 0.7014	 transfer: 0.0026	 finalize: 0.0046
batch bounding time:  0.7154107093811035
Current worst splitting domains [lb, ub] (depth):
[-30.84691,   inf] (7), [-30.68190,   inf] (7), [-30.00359,   inf] (7), [-29.81669,   inf] (7), [-29.61282,   inf] (7), [-29.59429,   inf] (7), [-29.59084,   inf] (7), [-29.22087,   inf] (7), [-29.21594,   inf] (7), [-29.14467,   inf] (7), [-29.07684,   inf] (7), [-29.00644,   inf] (7), [-28.92925,   inf] (7), [-28.90273,   inf] (7), [-28.69020,   inf] (7), [-28.62023,   inf] (7), [-28.46087,   inf] (7), [-28.42497,   inf] (7), [-28.41485,   inf] (7), [-28.32771,   inf] (7), 
length of domains: 64
Total time: 0.7656	 pickout: 0.0010	 decision: 0.0377	 get_bound: 0.7237	 add_domain: 0.0030
Current lb:-30.846914291381836
64 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.778860330581665

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([64, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 32] [3, 32] [3, 32] [3, 32] [3, 32] [3, 32] [3, 32] [3, 32] [3, 32] [3, 32] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 3346.353271484375 with beta sum per layer: [0.0, 0.0, 0.0, 35.693363189697266]
alpha/beta optimization time: 0.6981709003448486
This batch time : update_bounds func: 0.7285	 prepare: 0.0131	 bound: 0.6985	 transfer: 0.0076	 finalize: 0.0089
Accumulated time: update_bounds func: 1.4436	 prepare: 0.0193	 bound: 1.3999	 transfer: 0.0076	 finalize: 0.0136
batch bounding time:  0.7288076877593994
Current worst splitting domains [lb, ub] (depth):
[-29.49925,   inf] (9), [-29.36116,   inf] (9), [-29.15288,   inf] (9), [-28.82607,   inf] (9), [-28.70058,   inf] (9), [-28.50046,   inf] (9), [-28.49399,   inf] (9), [-28.29958,   inf] (9), [-28.26979,   inf] (9), [-28.19858,   inf] (9), [-28.18350,   inf] (9), [-28.13196,   inf] (9), [-28.11974,   inf] (9), [-28.09036,   inf] (9), [-28.04734,   inf] (9), [-27.85777,   inf] (9), [-27.84085,   inf] (9), [-27.83291,   inf] (9), [-27.82238,   inf] (9), [-27.72956,   inf] (9), 
length of domains: 128
Total time: 0.7990	 pickout: 0.0107	 decision: 0.0531	 get_bound: 0.7290	 add_domain: 0.0061
Current lb:-29.49924659729004
192 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.579243183135986

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([128, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([128, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 55] [3, 51] [3, 51] [3, 51] [3, 55] [3, 51] [3, 51] [3, 51] [3, 51] [3, 55] 
regular batch size: 2*128, diving batch size 1*0
best_l after optimization: 6325.3876953125 with beta sum per layer: [0.0, 0.0, 0.0, 97.30966186523438]
alpha/beta optimization time: 0.7393615245819092
This batch time : update_bounds func: 0.7986	 prepare: 0.0250	 bound: 0.7397	 transfer: 0.0151	 finalize: 0.0182
Accumulated time: update_bounds func: 2.2422	 prepare: 0.0443	 bound: 2.1396	 transfer: 0.0151	 finalize: 0.0317
batch bounding time:  0.7990541458129883
Current worst splitting domains [lb, ub] (depth):
[-28.60913,   inf] (11), [-28.40673,   inf] (11), [-28.21224,   inf] (11), [-27.88971,   inf] (11), [-27.84391,   inf] (11), [-27.52393,   inf] (11), [-27.48212,   inf] (11), [-27.37533,   inf] (11), [-27.33110,   inf] (11), [-27.21733,   inf] (11), [-27.16347,   inf] (11), [-27.14351,   inf] (11), [-27.08904,   inf] (11), [-27.03694,   inf] (11), [-27.02849,   inf] (11), [-26.97618,   inf] (11), [-26.94393,   inf] (11), [-26.88458,   inf] (11), [-26.88391,   inf] (11), [-26.78968,   inf] (11), 
length of domains: 256
Total time: 0.9085	 pickout: 0.0213	 decision: 0.0750	 get_bound: 0.7995	 add_domain: 0.0127
Current lb:-28.609130859375
448 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.4904944896698

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([256, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 51] [3, 55] [3, 55] [3, 55] [3, 51] [3, 55] [3, 55] [3, 55] [3, 51] [3, 55] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 11875.38671875 with beta sum per layer: [0.0, 0.0, 0.0, 301.7444152832031]
alpha/beta optimization time: 0.8919045925140381
This batch time : update_bounds func: 1.0788	 prepare: 0.0487	 bound: 0.8924	 transfer: 0.0278	 finalize: 0.1087
Accumulated time: update_bounds func: 3.3210	 prepare: 0.0930	 bound: 3.0319	 transfer: 0.0278	 finalize: 0.1405
batch bounding time:  1.079664707183838
Current worst splitting domains [lb, ub] (depth):
[-27.79351,   inf] (13), [-27.68867,   inf] (13), [-27.40717,   inf] (13), [-27.16006,   inf] (13), [-26.92205,   inf] (13), [-26.68323,   inf] (13), [-26.64096,   inf] (13), [-26.58240,   inf] (13), [-26.49219,   inf] (13), [-26.48855,   inf] (13), [-26.38158,   inf] (13), [-26.38107,   inf] (13), [-26.36686,   inf] (13), [-26.23601,   inf] (13), [-26.21086,   inf] (13), [-26.18777,   inf] (13), [-26.17208,   inf] (13), [-26.16344,   inf] (13), [-26.13026,   inf] (13), [-26.11066,   inf] (13), 
length of domains: 512
Total time: 1.2664	 pickout: 0.0407	 decision: 0.1168	 get_bound: 1.0806	 add_domain: 0.0283
Current lb:-27.793508529663086
960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.7623162269592285

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([512, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 35] [3, 35] [3, 35] [3, 35] [3, 35] [3, 35] [3, 35] [3, 35] [3, 35] [3, 35] 
regular batch size: 2*512, diving batch size 1*0
best_l after optimization: 22378.509765625 with beta sum per layer: [0.0, 0.0, 0.0, 872.4627685546875]
alpha/beta optimization time: 1.2439486980438232
This batch time : update_bounds func: 1.5185	 prepare: 0.0953	 bound: 1.2443	 transfer: 0.0537	 finalize: 0.1227
Accumulated time: update_bounds func: 4.8395	 prepare: 0.1883	 bound: 4.2762	 transfer: 0.0537	 finalize: 0.2631
batch bounding time:  1.5197007656097412
Current worst splitting domains [lb, ub] (depth):
[-26.96657,   inf] (15), [-26.90784,   inf] (15), [-26.59398,   inf] (15), [-26.39045,   inf] (15), [-26.08259,   inf] (15), [-26.00765,   inf] (15), [-25.79734,   inf] (15), [-25.76078,   inf] (15), [-25.75901,   inf] (15), [-25.75042,   inf] (15), [-25.74226,   inf] (15), [-25.64931,   inf] (15), [-25.57137,   inf] (15), [-25.54908,   inf] (15), [-25.52799,   inf] (15), [-25.46760,   inf] (15), [-25.45805,   inf] (15), [-25.45257,   inf] (15), [-25.44676,   inf] (15), [-25.39563,   inf] (15), 
length of domains: 1024
Total time: 1.8687	 pickout: 0.0851	 decision: 0.2025	 get_bound: 1.5215	 add_domain: 0.0596
Current lb:-26.96657371520996
1984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.640629291534424

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 7] [3, 7] [3, 7] [3, 7] [3, 28] [3, 7] [3, 7] [3, 28] [3, 7] [3, 7] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 41192.3515625 with beta sum per layer: [0.0, 0.0, 0.0, 2024.28271484375]
alpha/beta optimization time: 1.9743049144744873
This batch time : update_bounds func: 2.4776	 prepare: 0.1852	 bound: 1.9747	 transfer: 0.1141	 finalize: 0.1990
Accumulated time: update_bounds func: 7.3171	 prepare: 0.3735	 bound: 6.2509	 transfer: 0.1141	 finalize: 0.4621
batch bounding time:  2.4797940254211426
Current worst splitting domains [lb, ub] (depth):
[-26.23869,   inf] (17), [-26.17182,   inf] (17), [-25.79137,   inf] (17), [-25.59261,   inf] (17), [-25.45875,   inf] (17), [-25.33459,   inf] (17), [-25.27387,   inf] (17), [-25.25505,   inf] (17), [-25.20056,   inf] (17), [-25.19312,   inf] (17), [-25.08747,   inf] (17), [-25.07519,   inf] (17), [-25.05211,   inf] (17), [-25.02688,   inf] (17), [-24.98073,   inf] (17), [-24.83975,   inf] (17), [-24.82506,   inf] (17), [-24.82377,   inf] (17), [-24.80642,   inf] (17), [-24.75108,   inf] (17), 
length of domains: 2024
Total time: 3.2159	 pickout: 0.1670	 decision: 0.4414	 get_bound: 2.4834	 add_domain: 0.1241
Current lb:-26.238689422607422
3984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.876863241195679

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 24] [3, 24] [3, 24] [3, 24] [3, 24] [3, 24] [3, 24] [3, 24] [3, 24] [3, 24] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 41971.375 with beta sum per layer: [0.0, 0.0, 0.0, 1741.03076171875]
alpha/beta optimization time: 1.9579176902770996
This batch time : update_bounds func: 2.4961	 prepare: 0.1866	 bound: 1.9583	 transfer: 0.1165	 finalize: 0.2299
Accumulated time: update_bounds func: 9.8133	 prepare: 0.5601	 bound: 8.2092	 transfer: 0.1165	 finalize: 0.6920
batch bounding time:  2.4984915256500244
Current worst splitting domains [lb, ub] (depth):
[-25.28590,   inf] (19), [-25.25107,   inf] (19), [-25.20188,   inf] (19), [-25.16791,   inf] (19), [-24.85410,   inf] (19), [-24.76937,   inf] (19), [-24.61897,   inf] (19), [-24.58341,   inf] (19), [-24.50316,   inf] (19), [-24.41631,   inf] (19), [-24.40749,   inf] (19), [-24.38810,   inf] (19), [-24.34135,   inf] (19), [-24.28096,   inf] (19), [-24.27178,   inf] (19), [-24.27120,   inf] (19), [-24.26690,   inf] (19), [-24.22382,   inf] (19), [-24.19597,   inf] (19), [-24.13411,   inf] (19), 
length of domains: 3024
Total time: 3.3295	 pickout: 0.1764	 decision: 0.5176	 get_bound: 2.5027	 add_domain: 0.1329
Current lb:-25.285900115966797
5984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.228113889694214

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 28] [3, 58] [3, 58] [3, 58] [3, 58] [3, 58] [3, 58] [3, 58] [3, 58] [3, 58] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 41479.58984375 with beta sum per layer: [0.0, 0.0, 0.0, 1556.3369140625]
alpha/beta optimization time: 1.9680750370025635
This batch time : update_bounds func: 2.5234	 prepare: 0.1871	 bound: 1.9685	 transfer: 0.1159	 finalize: 0.2466
Accumulated time: update_bounds func: 12.3367	 prepare: 0.7471	 bound: 10.1777	 transfer: 0.1159	 finalize: 0.9387
batch bounding time:  2.5258820056915283
Current worst splitting domains [lb, ub] (depth):
[-24.56065,   inf] (21), [-24.50574,   inf] (21), [-24.43617,   inf] (21), [-24.40112,   inf] (21), [-24.05247,   inf] (21), [-24.02067,   inf] (21), [-23.82783,   inf] (21), [-23.75063,   inf] (21), [-23.68748,   inf] (21), [-23.66380,   inf] (21), [-23.64097,   inf] (21), [-23.63366,   inf] (21), [-23.62752,   inf] (21), [-23.61981,   inf] (21), [-23.59907,   inf] (21), [-23.58329,   inf] (21), [-23.58176,   inf] (21), [-23.57132,   inf] (21), [-23.49560,   inf] (21), [-23.45931,   inf] (21), 
length of domains: 4024
Total time: 3.3176	 pickout: 0.1759	 decision: 0.4693	 get_bound: 2.5301	 add_domain: 0.1423
Current lb:-24.560649871826172
7984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.566067934036255

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 58] [3, 28] [3, 28] [3, 28] [3, 28] [3, 28] [3, 28] [3, 28] [3, 42] [3, 46] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 39969.359375 with beta sum per layer: [0.0, 0.0, 0.0, 1790.6236572265625]
alpha/beta optimization time: 1.9832429885864258
This batch time : update_bounds func: 2.5725	 prepare: 0.1898	 bound: 1.9837	 transfer: 0.1251	 finalize: 0.1530
Accumulated time: update_bounds func: 14.9092	 prepare: 0.9369	 bound: 12.1614	 transfer: 0.1251	 finalize: 1.0916
batch bounding time:  2.5751757621765137
Current worst splitting domains [lb, ub] (depth):
[-23.88816,   inf] (23), [-23.84004,   inf] (23), [-23.74701,   inf] (23), [-23.73600,   inf] (23), [-23.31491,   inf] (23), [-23.25875,   inf] (23), [-23.06030,   inf] (23), [-23.03114,   inf] (23), [-23.00051,   inf] (23), [-22.99387,   inf] (23), [-22.98975,   inf] (23), [-22.97921,   inf] (23), [-22.93693,   inf] (23), [-22.89120,   inf] (23), [-22.86865,   inf] (23), [-22.86474,   inf] (23), [-22.83898,   inf] (23), [-22.82374,   inf] (23), [-22.81844,   inf] (23), [-22.81389,   inf] (23), 
length of domains: 5024
Total time: 3.4023	 pickout: 0.1771	 decision: 0.4913	 get_bound: 2.5797	 add_domain: 0.1541
Current lb:-23.88816261291504
9984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 21.99903106689453

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 46] [3, 42] [3, 46] [3, 42] [3, 46] [3, 46] [3, 43] [3, 43] [3, 28] [3, 42] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 39315.8125 with beta sum per layer: [0.0, 0.0, 0.0, 1766.354736328125]
alpha/beta optimization time: 1.971161127090454
This batch time : update_bounds func: 2.4345	 prepare: 0.1909	 bound: 1.9716	 transfer: 0.1168	 finalize: 0.1499
Accumulated time: update_bounds func: 17.3437	 prepare: 1.1278	 bound: 14.1330	 transfer: 0.1168	 finalize: 1.2415
batch bounding time:  2.4369618892669678
Current worst splitting domains [lb, ub] (depth):
[-23.24405,   inf] (25), [-23.18413,   inf] (25), [-23.12626,   inf] (25), [-23.11329,   inf] (25), [-22.89707,   inf] (25), [-22.72137,   inf] (25), [-22.68808,   inf] (25), [-22.68466,   inf] (25), [-22.39411,   inf] (25), [-22.37941,   inf] (25), [-22.37523,   inf] (25), [-22.35716,   inf] (25), [-22.34886,   inf] (25), [-22.30519,   inf] (25), [-22.28448,   inf] (25), [-22.27124,   inf] (25), [-22.24401,   inf] (25), [-22.22676,   inf] (25), [-22.22201,   inf] (25), [-22.17005,   inf] (25), 
length of domains: 6024
Total time: 3.4760	 pickout: 0.1952	 decision: 0.6865	 get_bound: 2.4412	 add_domain: 0.1530
Current lb:-23.24404525756836
11984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 25.498008966445923

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 43] [3, 46] [3, 46] [3, 43] [3, 43] [3, 42] [3, 43] [3, 43] [3, 46] [3, 42] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 38426.3359375 with beta sum per layer: [0.0, 0.0, 0.0, 1859.767578125]
alpha/beta optimization time: 1.9754974842071533
This batch time : update_bounds func: 2.6322	 prepare: 0.1943	 bound: 1.9759	 transfer: 0.1218	 finalize: 0.3347
Accumulated time: update_bounds func: 19.9759	 prepare: 1.3221	 bound: 16.1089	 transfer: 0.1218	 finalize: 1.5762
batch bounding time:  2.6347413063049316
Current worst splitting domains [lb, ub] (depth):
[-22.63528,   inf] (27), [-22.56354,   inf] (27), [-22.51958,   inf] (27), [-22.47788,   inf] (27), [-22.25381,   inf] (27), [-22.24072,   inf] (27), [-22.06527,   inf] (27), [-22.05706,   inf] (27), [-22.05693,   inf] (27), [-22.00312,   inf] (27), [-21.82034,   inf] (27), [-21.78149,   inf] (27), [-21.76673,   inf] (27), [-21.75003,   inf] (27), [-21.73835,   inf] (27), [-21.66760,   inf] (27), [-21.63696,   inf] (27), [-21.62426,   inf] (27), [-21.58918,   inf] (27), [-21.58357,   inf] (27), 
length of domains: 7024
Total time: 3.5370	 pickout: 0.1879	 decision: 0.5525	 get_bound: 2.6392	 add_domain: 0.1574
Current lb:-22.635284423828125
13984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 29.060160636901855

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 42] [3, 43] [3, 41] [3, 42] [3, 43] [3, 42] [3, 43] [3, 43] [3, 41] [3, 42] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 37874.484375 with beta sum per layer: [0.0, 0.0, 0.0, 1930.1302490234375]
alpha/beta optimization time: 1.9755456447601318
This batch time : update_bounds func: 2.6777	 prepare: 0.1952	 bound: 1.9760	 transfer: 0.1133	 finalize: 0.3877
Accumulated time: update_bounds func: 22.6536	 prepare: 1.5173	 bound: 18.0849	 transfer: 0.1133	 finalize: 1.9640
batch bounding time:  2.6802992820739746
Current worst splitting domains [lb, ub] (depth):
[-22.06033,   inf] (29), [-21.98049,   inf] (29), [-21.92990,   inf] (29), [-21.89931,   inf] (29), [-21.64259,   inf] (29), [-21.60234,   inf] (29), [-21.47377,   inf] (29), [-21.44172,   inf] (29), [-21.38243,   inf] (29), [-21.36479,   inf] (29), [-21.24932,   inf] (29), [-21.21824,   inf] (29), [-21.19771,   inf] (29), [-21.17904,   inf] (29), [-21.14234,   inf] (29), [-21.08467,   inf] (29), [-21.06806,   inf] (29), [-21.02690,   inf] (29), [-21.01800,   inf] (29), [-20.99474,   inf] (29), 
length of domains: 8024
Total time: 3.6399	 pickout: 0.1978	 decision: 0.5956	 get_bound: 2.6847	 add_domain: 0.1619
Current lb:-22.060325622558594
15984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 32.72748279571533

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 41] [3, 41] [3, 43] [2, 52] [3, 41] [3, 41] [3, 37] [3, 41] [3, 41] [3, 2] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 37484.1796875 with beta sum per layer: [0.0, 0.0, 0.020345451310276985, 2027.9090576171875]
alpha/beta optimization time: 1.9770119190216064
This batch time : update_bounds func: 2.4609	 prepare: 0.1957	 bound: 1.9775	 transfer: 0.1219	 finalize: 0.1597
Accumulated time: update_bounds func: 25.1146	 prepare: 1.7130	 bound: 20.0624	 transfer: 0.1219	 finalize: 2.1237
batch bounding time:  2.463428497314453
Current worst splitting domains [lb, ub] (depth):
[-21.54447,   inf] (31), [-21.43505,   inf] (31), [-21.35457,   inf] (31), [-21.34612,   inf] (31), [-21.08664,   inf] (31), [-21.01792,   inf] (31), [-20.92217,   inf] (31), [-20.85962,   inf] (31), [-20.85156,   inf] (31), [-20.77192,   inf] (31), [-20.76262,   inf] (31), [-20.66304,   inf] (31), [-20.66103,   inf] (31), [-20.63611,   inf] (31), [-20.63561,   inf] (31), [-20.61987,   inf] (31), [-20.60311,   inf] (31), [-20.57172,   inf] (31), [-20.56109,   inf] (31), [-20.51355,   inf] (31), 
length of domains: 9024
Total time: 3.4582	 pickout: 0.1883	 decision: 0.6422	 get_bound: 2.4675	 add_domain: 0.1602
Current lb:-21.544471740722656
17984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 36.21266293525696

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 37] [3, 27] [3, 37] [2, 52] [3, 37] [2, 52] [2, 52] [3, 27] [2, 52] [3, 37] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 37079.125 with beta sum per layer: [0.0, 0.0, 0.41740602254867554, 2088.486328125]
alpha/beta optimization time: 1.9807465076446533
This batch time : update_bounds func: 2.7649	 prepare: 0.1962	 bound: 1.9812	 transfer: 0.1206	 finalize: 0.4610
Accumulated time: update_bounds func: 27.8794	 prepare: 1.9092	 bound: 22.0435	 transfer: 0.1206	 finalize: 2.5847
batch bounding time:  2.7676002979278564
Current worst splitting domains [lb, ub] (depth):
[-21.02430,   inf] (33), [-20.91166,   inf] (33), [-20.81860,   inf] (33), [-20.78287,   inf] (33), [-20.50233,   inf] (33), [-20.48298,   inf] (33), [-20.39750,   inf] (33), [-20.34530,   inf] (33), [-20.30544,   inf] (33), [-20.28605,   inf] (33), [-20.19224,   inf] (33), [-20.17886,   inf] (33), [-20.12556,   inf] (33), [-20.10392,   inf] (33), [-20.08850,   inf] (33), [-20.06659,   inf] (33), [-20.05447,   inf] (33), [-20.05259,   inf] (33), [-20.05209,   inf] (33), [-20.03736,   inf] (33), 
length of domains: 10024
Total time: 3.8112	 pickout: 0.1886	 decision: 0.6870	 get_bound: 2.7723	 add_domain: 0.1633
Current lb:-21.024295806884766
19984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 40.05290699005127

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 52] [2, 41] [2, 63] [3, 27] [3, 27] [3, 2] [3, 42] [3, 41] [3, 27] [3, 27] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 36738.640625 with beta sum per layer: [0.0, 0.0, 0.8995301723480225, 2076.05908203125]
alpha/beta optimization time: 1.9894678592681885
This batch time : update_bounds func: 2.8111	 prepare: 0.1987	 bound: 1.9900	 transfer: 0.1260	 finalize: 0.1694
Accumulated time: update_bounds func: 30.6906	 prepare: 2.1080	 bound: 24.0335	 transfer: 0.1260	 finalize: 2.7541
batch bounding time:  2.8136966228485107
Current worst splitting domains [lb, ub] (depth):
[-20.48488,   inf] (35), [-20.36306,   inf] (35), [-20.26306,   inf] (35), [-20.24907,   inf] (35), [-20.22769,   inf] (35), [-20.09526,   inf] (35), [-20.08813,   inf] (35), [-19.98780,   inf] (35), [-19.97619,   inf] (35), [-19.90899,   inf] (35), [-19.84355,   inf] (35), [-19.79844,   inf] (35), [-19.75542,   inf] (35), [-19.66108,   inf] (35), [-19.64093,   inf] (19), [-19.64082,   inf] (21), [-19.64081,   inf] (25), [-19.64073,   inf] (27), [-19.64071,   inf] (17), [-19.64042,   inf] (25), 
length of domains: 11024
Total time: 3.5782	 pickout: 0.1959	 decision: 0.3989	 get_bound: 2.8178	 add_domain: 0.1656
Current lb:-20.48487663269043
21984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 43.668389320373535

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 27] [3, 2] [3, 41] [2, 63] [3, 41] [2, 52] [3, 27] [2, 41] [2, 52] [2, 63] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 36326.61328125 with beta sum per layer: [0.0, 0.0, 0.5401360988616943, 2212.310546875]
alpha/beta optimization time: 1.994370460510254
This batch time : update_bounds func: 2.4918	 prepare: 0.1971	 bound: 1.9948	 transfer: 0.1217	 finalize: 0.1716
Accumulated time: update_bounds func: 33.1824	 prepare: 2.3050	 bound: 26.0283	 transfer: 0.1217	 finalize: 2.9257
batch bounding time:  2.49461030960083
Current worst splitting domains [lb, ub] (depth):
[-19.97096,   inf] (37), [-19.82622,   inf] (37), [-19.73557,   inf] (37), [-19.73195,   inf] (37), [-19.71415,   inf] (37), [-19.68469,   inf] (37), [-19.57466,   inf] (37), [-19.50185,   inf] (21), [-19.50156,   inf] (21), [-19.50148,   inf] (27), [-19.50142,   inf] (23), [-19.50135,   inf] (25), [-19.50134,   inf] (21), [-19.50115,   inf] (19), [-19.50113,   inf] (27), [-19.50099,   inf] (21), [-19.50072,   inf] (19), [-19.50067,   inf] (35), [-19.50063,   inf] (23), [-19.50034,   inf] (23), 
length of domains: 12024
Total time: 3.6712	 pickout: 0.2098	 decision: 0.7914	 get_bound: 2.4993	 add_domain: 0.1707
Current lb:-19.970964431762695
23984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 47.3726921081543

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 63] [2, 52] [3, 37] [3, 27] [3, 37] [3, 27] [3, 2] [3, 42] [3, 43] [3, 37] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 36015.375 with beta sum per layer: [0.0, 0.0, 1.0438873767852783, 2216.433837890625]
alpha/beta optimization time: 1.9868125915527344
This batch time : update_bounds func: 2.4697	 prepare: 0.1976	 bound: 1.9873	 transfer: 0.1141	 finalize: 0.1640
Accumulated time: update_bounds func: 35.6521	 prepare: 2.5026	 bound: 28.0156	 transfer: 0.1141	 finalize: 3.0896
batch bounding time:  2.4723758697509766
Current worst splitting domains [lb, ub] (depth):
[-19.44844,   inf] (39), [-19.44819,   inf] (39), [-19.36930,   inf] (21), [-19.36926,   inf] (25), [-19.36911,   inf] (25), [-19.36905,   inf] (33), [-19.36900,   inf] (19), [-19.36885,   inf] (35), [-19.36844,   inf] (23), [-19.36844,   inf] (25), [-19.36838,   inf] (23), [-19.36823,   inf] (23), [-19.36823,   inf] (25), [-19.36822,   inf] (27), [-19.36819,   inf] (25), [-19.36807,   inf] (19), [-19.36802,   inf] (27), [-19.36796,   inf] (25), [-19.36792,   inf] (27), [-19.36782,   inf] (21), 
length of domains: 13024
Total time: 3.6884	 pickout: 0.2311	 decision: 0.8127	 get_bound: 2.4769	 add_domain: 0.1677
Current lb:-19.44843864440918
25984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 51.092275619506836

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 2] [3, 2] [3, 28] [3, 37] [3, 46] [3, 37] [3, 58] [3, 2] [3, 46] [3, 42] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 35818.83984375 with beta sum per layer: [0.0, 0.0, 0.6892325282096863, 2227.899658203125]
alpha/beta optimization time: 1.9894413948059082
This batch time : update_bounds func: 2.4853	 prepare: 0.1990	 bound: 1.9899	 transfer: 0.1220	 finalize: 0.1674
Accumulated time: update_bounds func: 38.1374	 prepare: 2.7016	 bound: 30.0055	 transfer: 0.1220	 finalize: 3.2570
batch bounding time:  2.4880669116973877
Current worst splitting domains [lb, ub] (depth):
[-19.24745,   inf] (21), [-19.24720,   inf] (27), [-19.24712,   inf] (19), [-19.24709,   inf] (23), [-19.24701,   inf] (25), [-19.24691,   inf] (29), [-19.24677,   inf] (23), [-19.24674,   inf] (19), [-19.24674,   inf] (23), [-19.24672,   inf] (29), [-19.24662,   inf] (23), [-19.24661,   inf] (31), [-19.24656,   inf] (25), [-19.24652,   inf] (21), [-19.24650,   inf] (25), [-19.24648,   inf] (25), [-19.24637,   inf] (21), [-19.24629,   inf] (23), [-19.24607,   inf] (23), [-19.24591,   inf] (25), 
length of domains: 14024
Total time: 4.2113	 pickout: 0.2239	 decision: 0.8559	 get_bound: 2.4925	 add_domain: 0.6390
Current lb:-19.247446060180664
27984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 55.33368372917175

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 37] [3, 2] [3, 58] [3, 42] [3, 46] [3, 41] [3, 41] [3, 58] [3, 7] [3, 37] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 35531.75 with beta sum per layer: [0.0, 0.0, 0.6923947930335999, 2283.46484375]
alpha/beta optimization time: 1.9900867938995361
This batch time : update_bounds func: 2.4700	 prepare: 0.1982	 bound: 1.9905	 transfer: 0.1143	 finalize: 0.1602
Accumulated time: update_bounds func: 40.6073	 prepare: 2.8998	 bound: 31.9960	 transfer: 0.1143	 finalize: 3.4172
batch bounding time:  2.472623109817505
Current worst splitting domains [lb, ub] (depth):
[-19.14024,   inf] (33), [-19.14021,   inf] (23), [-19.14013,   inf] (25), [-19.14012,   inf] (27), [-19.13995,   inf] (25), [-19.13995,   inf] (19), [-19.13994,   inf] (25), [-19.13991,   inf] (27), [-19.13979,   inf] (17), [-19.13973,   inf] (29), [-19.13972,   inf] (25), [-19.13962,   inf] (29), [-19.13957,   inf] (27), [-19.13942,   inf] (23), [-19.13941,   inf] (33), [-19.13923,   inf] (23), [-19.13921,   inf] (23), [-19.13901,   inf] (21), [-19.13894,   inf] (23), [-19.13890,   inf] (33), 
length of domains: 15024
Total time: 3.8090	 pickout: 0.2374	 decision: 0.4104	 get_bound: 2.4774	 add_domain: 0.6838
Current lb:-19.140235900878906
29984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 59.169169425964355

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 2] [3, 43] [3, 37] [2, 41] [3, 7] [3, 58] [3, 37] [3, 42] [3, 24] [3, 37] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 35217.203125 with beta sum per layer: [0.0, 0.0, 0.732380747795105, 2390.5888671875]
alpha/beta optimization time: 1.986952304840088
This batch time : update_bounds func: 2.4813	 prepare: 0.2028	 bound: 1.9874	 transfer: 0.1184	 finalize: 0.1662
Accumulated time: update_bounds func: 43.0887	 prepare: 3.1026	 bound: 33.9834	 transfer: 0.1184	 finalize: 3.5834
batch bounding time:  2.4838337898254395
Current worst splitting domains [lb, ub] (depth):
[-19.03838,   inf] (25), [-19.03836,   inf] (27), [-19.03835,   inf] (23), [-19.03833,   inf] (19), [-19.03826,   inf] (25), [-19.03824,   inf] (19), [-19.03821,   inf] (21), [-19.03811,   inf] (27), [-19.03809,   inf] (23), [-19.03803,   inf] (19), [-19.03802,   inf] (29), [-19.03782,   inf] (19), [-19.03781,   inf] (21), [-19.03777,   inf] (29), [-19.03764,   inf] (25), [-19.03756,   inf] (23), [-19.03755,   inf] (35), [-19.03749,   inf] (25), [-19.03704,   inf] (27), [-19.03703,   inf] (25), 
length of domains: 16024
Total time: 3.2684	 pickout: 0.2048	 decision: 0.4081	 get_bound: 2.4880	 add_domain: 0.1675
Current lb:-19.038379669189453
31984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 62.46842002868652

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 42] [3, 37] [3, 41] [3, 58] [3, 7] [3, 58] [3, 58] [3, 46] [3, 41] [3, 58] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 35205.71875 with beta sum per layer: [0.0, 0.0, 0.8767366409301758, 2355.584716796875]
alpha/beta optimization time: 1.9906284809112549
This batch time : update_bounds func: 2.4859	 prepare: 0.1982	 bound: 1.9910	 transfer: 0.1212	 finalize: 0.1687
Accumulated time: update_bounds func: 45.5746	 prepare: 3.3008	 bound: 35.9744	 transfer: 0.1212	 finalize: 3.7521
batch bounding time:  2.4887776374816895
Current worst splitting domains [lb, ub] (depth):
[-18.94411,   inf] (41), [-18.94404,   inf] (27), [-18.94394,   inf] (19), [-18.94390,   inf] (33), [-18.94376,   inf] (23), [-18.94366,   inf] (29), [-18.94364,   inf] (29), [-18.94336,   inf] (25), [-18.94331,   inf] (27), [-18.94320,   inf] (25), [-18.94306,   inf] (23), [-18.94279,   inf] (23), [-18.94227,   inf] (21), [-18.94227,   inf] (27), [-18.94208,   inf] (25), [-18.94185,   inf] (23), [-18.94149,   inf] (21), [-18.94149,   inf] (29), [-18.94145,   inf] (37), [-18.94141,   inf] (21), 
length of domains: 17024
Total time: 3.7971	 pickout: 0.2010	 decision: 0.9288	 get_bound: 2.4938	 add_domain: 0.1735
Current lb:-18.94410514831543
33984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 66.29900979995728

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 110] [3, 2] [3, 58] [3, 41] [3, 41] [3, 37] [3, 41] [3, 28] [3, 2] [3, 37] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 34912.21484375 with beta sum per layer: [0.0, 0.0, 1.0809588432312012, 2391.7568359375]
alpha/beta optimization time: 1.985856056213379
This batch time : update_bounds func: 2.4663	 prepare: 0.1992	 bound: 1.9863	 transfer: 0.1132	 finalize: 0.1609
Accumulated time: update_bounds func: 48.0409	 prepare: 3.5000	 bound: 37.9607	 transfer: 0.1132	 finalize: 3.9130
batch bounding time:  2.4687986373901367
Current worst splitting domains [lb, ub] (depth):
[-18.85466,   inf] (27), [-18.85461,   inf] (25), [-18.85439,   inf] (23), [-18.85427,   inf] (31), [-18.85426,   inf] (21), [-18.85421,   inf] (21), [-18.85402,   inf] (23), [-18.85399,   inf] (21), [-18.85387,   inf] (27), [-18.85373,   inf] (19), [-18.85361,   inf] (27), [-18.85359,   inf] (27), [-18.85334,   inf] (25), [-18.85330,   inf] (27), [-18.85327,   inf] (21), [-18.85326,   inf] (21), [-18.85316,   inf] (25), [-18.85315,   inf] (21), [-18.85315,   inf] (29), [-18.85296,   inf] (27), 
length of domains: 18024
Total time: 3.8198	 pickout: 0.2198	 decision: 0.9590	 get_bound: 2.4729	 add_domain: 0.1681
Current lb:-18.854663848876953
35984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 70.14673662185669

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 37] [3, 43] [3, 41] [3, 37] [3, 28] [3, 46] [3, 41] [3, 28] [3, 37] [3, 58] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 34757.12109375 with beta sum per layer: [0.0, 0.0, 0.6391077041625977, 2369.6064453125]
alpha/beta optimization time: 1.9861364364624023
This batch time : update_bounds func: 2.4727	 prepare: 0.1992	 bound: 1.9866	 transfer: 0.1148	 finalize: 0.1653
Accumulated time: update_bounds func: 50.5136	 prepare: 3.6992	 bound: 39.9473	 transfer: 0.1148	 finalize: 4.0783
batch bounding time:  2.475590229034424
Current worst splitting domains [lb, ub] (depth):
[-18.76989,   inf] (25), [-18.76969,   inf] (21), [-18.76967,   inf] (23), [-18.76960,   inf] (23), [-18.76960,   inf] (25), [-18.76957,   inf] (21), [-18.76941,   inf] (27), [-18.76941,   inf] (19), [-18.76934,   inf] (29), [-18.76933,   inf] (21), [-18.76929,   inf] (23), [-18.76921,   inf] (29), [-18.76912,   inf] (23), [-18.76903,   inf] (29), [-18.76900,   inf] (29), [-18.76884,   inf] (23), [-18.76862,   inf] (25), [-18.76854,   inf] (27), [-18.76853,   inf] (23), [-18.76853,   inf] (27), 
length of domains: 19024
Total time: 3.8825	 pickout: 0.2063	 decision: 1.0179	 get_bound: 2.4804	 add_domain: 0.1779
Current lb:-18.769887924194336
37984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 74.07556009292603

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 43] [3, 7] [3, 55] [3, 41] [3, 41] [3, 7] [3, 42] [3, 58] [3, 37] [3, 7] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 34527.4453125 with beta sum per layer: [0.0, 0.0, 1.1218249797821045, 2419.581787109375]
alpha/beta optimization time: 1.9964759349822998
This batch time : update_bounds func: 2.4848	 prepare: 0.1979	 bound: 1.9969	 transfer: 0.1138	 finalize: 0.1696
Accumulated time: update_bounds func: 52.9984	 prepare: 3.8972	 bound: 41.9442	 transfer: 0.1138	 finalize: 4.2478
batch bounding time:  2.487772226333618
Current worst splitting domains [lb, ub] (depth):
[-18.68733,   inf] (25), [-18.68731,   inf] (29), [-18.68729,   inf] (25), [-18.68727,   inf] (31), [-18.68719,   inf] (23), [-18.68714,   inf] (25), [-18.68698,   inf] (29), [-18.68691,   inf] (25), [-18.68680,   inf] (29), [-18.68613,   inf] (21), [-18.68601,   inf] (19), [-18.68595,   inf] (25), [-18.68584,   inf] (25), [-18.68581,   inf] (25), [-18.68572,   inf] (23), [-18.68568,   inf] (29), [-18.68567,   inf] (21), [-18.68552,   inf] (27), [-18.68534,   inf] (25), [-18.68496,   inf] (31), 
length of domains: 20024
Total time: 3.9267	 pickout: 0.2155	 decision: 1.0434	 get_bound: 2.4927	 add_domain: 0.1752
Current lb:-18.687334060668945
39984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 78.03341436386108

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 46] [3, 37] [3, 46] [3, 37] [3, 42] [3, 46] [3, 7] [3, 46] [3, 41] [3, 43] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 34505.109375 with beta sum per layer: [0.0, 0.0, 0.27964508533477783, 2472.64990234375]
alpha/beta optimization time: 1.9912934303283691
This batch time : update_bounds func: 3.2030	 prepare: 0.1994	 bound: 1.9918	 transfer: 0.1126	 finalize: 0.8925
Accumulated time: update_bounds func: 56.2014	 prepare: 4.0965	 bound: 43.9360	 transfer: 0.1126	 finalize: 5.1403
batch bounding time:  3.205548048019409
Current worst splitting domains [lb, ub] (depth):
[-18.60893,   inf] (23), [-18.60887,   inf] (27), [-18.60885,   inf] (25), [-18.60877,   inf] (25), [-18.60874,   inf] (27), [-18.60872,   inf] (19), [-18.60865,   inf] (29), [-18.60864,   inf] (39), [-18.60856,   inf] (25), [-18.60848,   inf] (25), [-18.60847,   inf] (29), [-18.60838,   inf] (23), [-18.60824,   inf] (25), [-18.60821,   inf] (17), [-18.60821,   inf] (25), [-18.60815,   inf] (25), [-18.60803,   inf] (33), [-18.60791,   inf] (27), [-18.60790,   inf] (33), [-18.60766,   inf] (25), 
length of domains: 21024
Total time: 4.0080	 pickout: 0.2102	 decision: 0.4163	 get_bound: 3.2099	 add_domain: 0.1716
Current lb:-18.608930587768555
41984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 82.07340097427368

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 41] [3, 27] [3, 46] [3, 41] [3, 43] [3, 58] [3, 27] [3, 37] [3, 42] [3, 42] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 34269.62890625 with beta sum per layer: [0.0, 0.0, 1.857330322265625, 2453.388671875]
alpha/beta optimization time: 1.9931888580322266
This batch time : update_bounds func: 2.4940	 prepare: 0.1998	 bound: 1.9936	 transfer: 0.1256	 finalize: 0.1680
Accumulated time: update_bounds func: 58.6953	 prepare: 4.2963	 bound: 45.9296	 transfer: 0.1256	 finalize: 5.3083
batch bounding time:  2.4964358806610107
Current worst splitting domains [lb, ub] (depth):
[-18.53756,   inf] (19), [-18.53744,   inf] (25), [-18.53735,   inf] (19), [-18.53727,   inf] (23), [-18.53720,   inf] (37), [-18.53719,   inf] (29), [-18.53719,   inf] (23), [-18.53718,   inf] (27), [-18.53677,   inf] (25), [-18.53673,   inf] (31), [-18.53662,   inf] (23), [-18.53658,   inf] (23), [-18.53639,   inf] (21), [-18.53635,   inf] (25), [-18.53634,   inf] (21), [-18.53630,   inf] (21), [-18.53627,   inf] (31), [-18.53625,   inf] (27), [-18.53625,   inf] (19), [-18.53617,   inf] (25), 
length of domains: 22024
Total time: 3.3076	 pickout: 0.2129	 decision: 0.4142	 get_bound: 2.5006	 add_domain: 0.1798
Current lb:-18.53755760192871
43984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 85.41756749153137

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 58] [3, 37] [3, 58] [3, 28] [3, 37] [3, 41] [3, 58] [3, 42] [3, 46] [3, 27] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 34188.5625 with beta sum per layer: [0.0, 0.0, 1.3042333126068115, 2490.8642578125]
alpha/beta optimization time: 1.9882426261901855
This batch time : update_bounds func: 2.4788	 prepare: 0.2012	 bound: 1.9887	 transfer: 0.1157	 finalize: 0.1661
Accumulated time: update_bounds func: 61.1741	 prepare: 4.4975	 bound: 47.9183	 transfer: 0.1157	 finalize: 5.4744
batch bounding time:  2.4812848567962646
Current worst splitting domains [lb, ub] (depth):
[-18.46920,   inf] (21), [-18.46915,   inf] (27), [-18.46903,   inf] (27), [-18.46902,   inf] (23), [-18.46902,   inf] (27), [-18.46897,   inf] (23), [-18.46880,   inf] (21), [-18.46877,   inf] (33), [-18.46874,   inf] (21), [-18.46873,   inf] (25), [-18.46859,   inf] (25), [-18.46841,   inf] (25), [-18.46840,   inf] (25), [-18.46833,   inf] (23), [-18.46829,   inf] (31), [-18.46827,   inf] (21), [-18.46825,   inf] (21), [-18.46809,   inf] (25), [-18.46809,   inf] (27), [-18.46797,   inf] (33), 
length of domains: 23024
Total time: 4.0570	 pickout: 0.2252	 decision: 1.1718	 get_bound: 2.4855	 add_domain: 0.1745
Current lb:-18.469196319580078
45984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 89.50619888305664

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 42] [3, 46] [3, 46] [3, 42] [3, 43] [3, 42] [3, 28] [3, 27] [3, 28] [3, 41] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 34055.9921875 with beta sum per layer: [0.0, 0.0, 2.0999956130981445, 2399.812255859375]
alpha/beta optimization time: 1.992074728012085
This batch time : update_bounds func: 3.2587	 prepare: 0.2000	 bound: 1.9925	 transfer: 0.1156	 finalize: 0.9437
Accumulated time: update_bounds func: 64.4328	 prepare: 4.6975	 bound: 49.9109	 transfer: 0.1156	 finalize: 6.4181
batch bounding time:  3.2615041732788086
Current worst splitting domains [lb, ub] (depth):
[-18.39966,   inf] (29), [-18.39943,   inf] (37), [-18.39938,   inf] (29), [-18.39937,   inf] (33), [-18.39926,   inf] (21), [-18.39923,   inf] (33), [-18.39920,   inf] (25), [-18.39900,   inf] (19), [-18.39895,   inf] (29), [-18.39894,   inf] (25), [-18.39892,   inf] (19), [-18.39874,   inf] (27), [-18.39870,   inf] (29), [-18.39858,   inf] (23), [-18.39841,   inf] (25), [-18.39838,   inf] (23), [-18.39818,   inf] (25), [-18.39815,   inf] (21), [-18.39812,   inf] (19), [-18.39812,   inf] (17), 
length of domains: 24024
Total time: 4.0893	 pickout: 0.2292	 decision: 0.4185	 get_bound: 3.2662	 add_domain: 0.1754
Current lb:-18.399662017822266
47984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 93.62373518943787

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 46] [2, 52] [3, 2] [3, 46] [3, 28] [3, 27] [3, 42] [3, 58] [3, 7] [3, 37] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 33820.96875 with beta sum per layer: [0.0, 0.0, 2.7953338623046875, 2527.24658203125]
alpha/beta optimization time: 1.991156816482544
This batch time : update_bounds func: 2.4884	 prepare: 0.2048	 bound: 1.9916	 transfer: 0.1157	 finalize: 0.1684
Accumulated time: update_bounds func: 66.9212	 prepare: 4.9023	 bound: 51.9025	 transfer: 0.1157	 finalize: 6.5864
batch bounding time:  2.491010904312134
Current worst splitting domains [lb, ub] (depth):
[-18.33370,   inf] (31), [-18.33369,   inf] (25), [-18.33368,   inf] (27), [-18.33362,   inf] (19), [-18.33357,   inf] (25), [-18.33350,   inf] (25), [-18.33341,   inf] (31), [-18.33336,   inf] (33), [-18.33329,   inf] (37), [-18.33327,   inf] (21), [-18.33316,   inf] (29), [-18.33316,   inf] (23), [-18.33302,   inf] (37), [-18.33296,   inf] (37), [-18.33295,   inf] (19), [-18.33294,   inf] (21), [-18.33291,   inf] (17), [-18.33281,   inf] (27), [-18.33281,   inf] (35), [-18.33272,   inf] (25), 
length of domains: 25024
Total time: 3.3280	 pickout: 0.2344	 decision: 0.4209	 get_bound: 2.4954	 add_domain: 0.1773
Current lb:-18.333702087402344
49984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 96.98581671714783

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 58] [3, 28] [3, 42] [3, 58] [3, 42] [3, 42] [3, 37] [3, 2] [3, 37] [3, 37] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 33843.4765625 with beta sum per layer: [0.0, 0.0, 1.5831010341644287, 2486.59765625]
alpha/beta optimization time: 1.9902262687683105
This batch time : update_bounds func: 2.4819	 prepare: 0.2024	 bound: 1.9907	 transfer: 0.1135	 finalize: 0.1678
Accumulated time: update_bounds func: 69.4031	 prepare: 5.1048	 bound: 53.8932	 transfer: 0.1135	 finalize: 6.7543
batch bounding time:  2.484544038772583
Current worst splitting domains [lb, ub] (depth):
[-18.27278,   inf] (27), [-18.27273,   inf] (23), [-18.27271,   inf] (23), [-18.27258,   inf] (29), [-18.27258,   inf] (21), [-18.27255,   inf] (27), [-18.27251,   inf] (31), [-18.27249,   inf] (21), [-18.27236,   inf] (31), [-18.27234,   inf] (35), [-18.27234,   inf] (27), [-18.27221,   inf] (25), [-18.27218,   inf] (19), [-18.27202,   inf] (21), [-18.27195,   inf] (29), [-18.27170,   inf] (31), [-18.27165,   inf] (27), [-18.27158,   inf] (31), [-18.27152,   inf] (29), [-18.27140,   inf] (31), 
length of domains: 26024
Total time: 4.1566	 pickout: 0.2373	 decision: 1.2541	 get_bound: 2.4889	 add_domain: 0.1762
Current lb:-18.27277946472168
51984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 101.17561960220337

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 46] [3, 28] [3, 46] [3, 27] [3, 7] [3, 46] [3, 27] [3, 43] [3, 43] [3, 28] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 33576.5859375 with beta sum per layer: [0.0, 0.0, 1.695180058479309, 2546.80810546875]
alpha/beta optimization time: 1.9961137771606445
This batch time : update_bounds func: 3.3734	 prepare: 0.2001	 bound: 1.9965	 transfer: 0.1139	 finalize: 1.0558
Accumulated time: update_bounds func: 72.7765	 prepare: 5.3049	 bound: 55.8898	 transfer: 0.1139	 finalize: 7.8101
batch bounding time:  3.3758387565612793
Current worst splitting domains [lb, ub] (depth):
[-18.21263,   inf] (27), [-18.21262,   inf] (29), [-18.21255,   inf] (27), [-18.21252,   inf] (25), [-18.21214,   inf] (19), [-18.21206,   inf] (31), [-18.21202,   inf] (19), [-18.21176,   inf] (35), [-18.21173,   inf] (27), [-18.21172,   inf] (35), [-18.21162,   inf] (21), [-18.21150,   inf] (27), [-18.21139,   inf] (21), [-18.21138,   inf] (27), [-18.21123,   inf] (29), [-18.21122,   inf] (21), [-18.21113,   inf] (21), [-18.21108,   inf] (19), [-18.21104,   inf] (37), [-18.21104,   inf] (27), 
length of domains: 27024
Total time: 4.2399	 pickout: 0.2548	 decision: 0.4272	 get_bound: 3.3800	 add_domain: 0.1779
Current lb:-18.21263313293457
53984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 105.44430112838745

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 28] [3, 37] [3, 37] [3, 41] [3, 58] [3, 46] [3, 58] [2, 52] [3, 41] [3, 27] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 33564.67578125 with beta sum per layer: [0.0, 0.0, 1.9519011974334717, 2565.3359375]
alpha/beta optimization time: 1.9939556121826172
This batch time : update_bounds func: 2.4873	 prepare: 0.1996	 bound: 1.9944	 transfer: 0.1141	 finalize: 0.1721
Accumulated time: update_bounds func: 75.2638	 prepare: 5.5045	 bound: 57.8842	 transfer: 0.1141	 finalize: 7.9822
batch bounding time:  2.4898338317871094
Current worst splitting domains [lb, ub] (depth):
[-18.15470,   inf] (23), [-18.15457,   inf] (29), [-18.15452,   inf] (31), [-18.15448,   inf] (25), [-18.15447,   inf] (33), [-18.15445,   inf] (27), [-18.15426,   inf] (29), [-18.15415,   inf] (21), [-18.15390,   inf] (37), [-18.15388,   inf] (33), [-18.15382,   inf] (29), [-18.15382,   inf] (33), [-18.15377,   inf] (25), [-18.15375,   inf] (25), [-18.15371,   inf] (25), [-18.15368,   inf] (23), [-18.15363,   inf] (19), [-18.15351,   inf] (23), [-18.15336,   inf] (27), [-18.15331,   inf] (27), 
length of domains: 28024
Total time: 3.3413	 pickout: 0.2409	 decision: 0.4267	 get_bound: 2.4942	 add_domain: 0.1794
Current lb:-18.15470314025879
55984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 108.82137370109558

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 41] [3, 28] [3, 42] [3, 37] [3, 42] [3, 42] [3, 7] [3, 28] [2, 87] [3, 37] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 33370.98046875 with beta sum per layer: [0.0, 0.0, 2.566934585571289, 2532.30224609375]
alpha/beta optimization time: 1.9950287342071533
This batch time : update_bounds func: 2.4932	 prepare: 0.2024	 bound: 1.9955	 transfer: 0.1157	 finalize: 0.1726
Accumulated time: update_bounds func: 77.7569	 prepare: 5.7068	 bound: 59.8796	 transfer: 0.1157	 finalize: 8.1549
batch bounding time:  2.4959144592285156
Current worst splitting domains [lb, ub] (depth):
[-18.09997,   inf] (19), [-18.09991,   inf] (23), [-18.09975,   inf] (19), [-18.09953,   inf] (33), [-18.09949,   inf] (23), [-18.09946,   inf] (33), [-18.09940,   inf] (19), [-18.09931,   inf] (27), [-18.09931,   inf] (21), [-18.09924,   inf] (27), [-18.09924,   inf] (23), [-18.09921,   inf] (25), [-18.09921,   inf] (19), [-18.09917,   inf] (27), [-18.09911,   inf] (35), [-18.09909,   inf] (23), [-18.09889,   inf] (25), [-18.09876,   inf] (27), [-18.09874,   inf] (25), [-18.09867,   inf] (27), 
length of domains: 29024
Total time: 4.2959	 pickout: 0.2407	 decision: 1.3726	 get_bound: 2.5006	 add_domain: 0.1820
Current lb:-18.0999698638916
57984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 113.14910244941711

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 58] [3, 42] [3, 58] [3, 42] [3, 41] [3, 28] [3, 58] [3, 46] [3, 37] [3, 7] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 33291.2734375 with beta sum per layer: [0.0, 0.0, 1.6262401342391968, 2627.131103515625]
alpha/beta optimization time: 1.9990456104278564
This batch time : update_bounds func: 2.4961	 prepare: 0.2025	 bound: 1.9995	 transfer: 0.1139	 finalize: 0.1727
Accumulated time: update_bounds func: 80.2531	 prepare: 5.9094	 bound: 61.8792	 transfer: 0.1139	 finalize: 8.3275
batch bounding time:  2.499042510986328
Current worst splitting domains [lb, ub] (depth):
[-18.04567,   inf] (17), [-18.04566,   inf] (27), [-18.04562,   inf] (27), [-18.04545,   inf] (25), [-18.04537,   inf] (25), [-18.04536,   inf] (27), [-18.04523,   inf] (25), [-18.04516,   inf] (27), [-18.04512,   inf] (23), [-18.04509,   inf] (43), [-18.04503,   inf] (23), [-18.04501,   inf] (27), [-18.04496,   inf] (25), [-18.04491,   inf] (31), [-18.04490,   inf] (31), [-18.04488,   inf] (27), [-18.04486,   inf] (31), [-18.04479,   inf] (33), [-18.04475,   inf] (19), [-18.04465,   inf] (21), 
length of domains: 30024
Total time: 3.3513	 pickout: 0.2398	 decision: 0.4254	 get_bound: 2.5040	 add_domain: 0.1822
Current lb:-18.045669555664062
59984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 116.53484725952148

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 24] [3, 28] [3, 27] [3, 27] [3, 28] [3, 46] [3, 43] [3, 2] [3, 41] [2, 41] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 33243.8515625 with beta sum per layer: [0.0, 0.0, 1.8516123294830322, 2618.474609375]
alpha/beta optimization time: 1.9977538585662842
This batch time : update_bounds func: 2.4956	 prepare: 0.2043	 bound: 1.9982	 transfer: 0.1158	 finalize: 0.1696
Accumulated time: update_bounds func: 82.7486	 prepare: 6.1136	 bound: 63.8774	 transfer: 0.1158	 finalize: 8.4972
batch bounding time:  2.4984142780303955
Current worst splitting domains [lb, ub] (depth):
[-17.99393,   inf] (29), [-17.99390,   inf] (23), [-17.99384,   inf] (27), [-17.99379,   inf] (29), [-17.99378,   inf] (19), [-17.99364,   inf] (29), [-17.99345,   inf] (27), [-17.99342,   inf] (31), [-17.99329,   inf] (21), [-17.99322,   inf] (23), [-17.99322,   inf] (19), [-17.99314,   inf] (27), [-17.99308,   inf] (45), [-17.99296,   inf] (29), [-17.99288,   inf] (29), [-17.99281,   inf] (23), [-17.99280,   inf] (29), [-17.99280,   inf] (25), [-17.99278,   inf] (27), [-17.99272,   inf] (29), 
length of domains: 31024
Total time: 4.3685	 pickout: 0.2277	 decision: 1.4565	 get_bound: 2.5034	 add_domain: 0.1808
Current lb:-17.993928909301758
61984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 120.93687725067139

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 28] [3, 37] [3, 42] [3, 2] [3, 58] [3, 41] [3, 37] [3, 41] [3, 46] [3, 41] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 33071.72265625 with beta sum per layer: [0.0, 0.0, 4.0573344230651855, 2574.8720703125]
alpha/beta optimization time: 1.9991230964660645
This batch time : update_bounds func: 2.5040	 prepare: 0.2025	 bound: 1.9996	 transfer: 0.1210	 finalize: 0.1732
Accumulated time: update_bounds func: 85.2526	 prepare: 6.3161	 bound: 65.8770	 transfer: 0.1210	 finalize: 8.6704
batch bounding time:  2.5067756175994873
Current worst splitting domains [lb, ub] (depth):
[-17.94625,   inf] (27), [-17.94622,   inf] (27), [-17.94620,   inf] (23), [-17.94616,   inf] (25), [-17.94615,   inf] (25), [-17.94604,   inf] (37), [-17.94596,   inf] (41), [-17.94594,   inf] (17), [-17.94594,   inf] (27), [-17.94585,   inf] (25), [-17.94574,   inf] (31), [-17.94568,   inf] (25), [-17.94567,   inf] (25), [-17.94565,   inf] (35), [-17.94564,   inf] (23), [-17.94559,   inf] (25), [-17.94559,   inf] (25), [-17.94558,   inf] (29), [-17.94555,   inf] (27), [-17.94547,   inf] (19), 
length of domains: 32024
Total time: 3.3354	 pickout: 0.2159	 decision: 0.4273	 get_bound: 2.5115	 add_domain: 0.1808
Current lb:-17.946245193481445
63984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 124.30768084526062

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 37] [3, 46] [3, 41] [3, 43] [3, 27] [3, 2] [2, 110] [3, 24] [3, 43] [3, 27] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 33019.18359375 with beta sum per layer: [0.0, 0.0, 3.026369094848633, 2580.73583984375]
alpha/beta optimization time: 2.0008621215820312
This batch time : update_bounds func: 2.4886	 prepare: 0.2015	 bound: 2.0013	 transfer: 0.1123	 finalize: 0.1659
Accumulated time: update_bounds func: 87.7412	 prepare: 6.5176	 bound: 67.8783	 transfer: 0.1123	 finalize: 8.8363
batch bounding time:  2.4914703369140625
Current worst splitting domains [lb, ub] (depth):
[-17.89845,   inf] (31), [-17.89842,   inf] (21), [-17.89838,   inf] (33), [-17.89819,   inf] (29), [-17.89812,   inf] (35), [-17.89803,   inf] (25), [-17.89799,   inf] (31), [-17.89797,   inf] (21), [-17.89793,   inf] (29), [-17.89792,   inf] (27), [-17.89788,   inf] (25), [-17.89783,   inf] (29), [-17.89773,   inf] (29), [-17.89763,   inf] (31), [-17.89762,   inf] (23), [-17.89761,   inf] (25), [-17.89751,   inf] (23), [-17.89751,   inf] (19), [-17.89751,   inf] (25), [-17.89748,   inf] (31), 
length of domains: 33024
Total time: 4.4492	 pickout: 0.2324	 decision: 1.5389	 get_bound: 2.4962	 add_domain: 0.1818
Current lb:-17.89845085144043
65984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 128.7879500389099

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 2] [3, 58] [3, 27] [3, 42] [3, 28] [3, 41] [3, 41] [3, 58] [3, 42] [3, 42] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 32921.3046875 with beta sum per layer: [0.0, 0.0, 3.9887545108795166, 2696.875732421875]
alpha/beta optimization time: 1.9970993995666504
This batch time : update_bounds func: 2.4923	 prepare: 0.2031	 bound: 1.9975	 transfer: 0.1144	 finalize: 0.1692
Accumulated time: update_bounds func: 90.2335	 prepare: 6.7208	 bound: 69.8758	 transfer: 0.1144	 finalize: 9.0055
batch bounding time:  2.495426893234253
Current worst splitting domains [lb, ub] (depth):
[-17.85223,   inf] (31), [-17.85216,   inf] (25), [-17.85214,   inf] (33), [-17.85210,   inf] (33), [-17.85203,   inf] (19), [-17.85201,   inf] (25), [-17.85198,   inf] (23), [-17.85189,   inf] (25), [-17.85187,   inf] (31), [-17.85184,   inf] (21), [-17.85184,   inf] (25), [-17.85181,   inf] (21), [-17.85170,   inf] (37), [-17.85159,   inf] (25), [-17.85157,   inf] (23), [-17.85148,   inf] (33), [-17.85145,   inf] (27), [-17.85138,   inf] (27), [-17.85138,   inf] (29), [-17.85131,   inf] (39), 
length of domains: 34024
Total time: 3.3358	 pickout: 0.2233	 decision: 0.4270	 get_bound: 2.5008	 add_domain: 0.1847
Current lb:-17.852230072021484
67984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 132.1582214832306

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 27] [3, 41] [2, 87] [3, 37] [3, 58] [3, 41] [3, 28] [3, 37] [3, 27] [3, 46] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 32796.234375 with beta sum per layer: [0.0, 0.0, 4.20219612121582, 2688.4775390625]
alpha/beta optimization time: 1.9944367408752441
This batch time : update_bounds func: 2.5017	 prepare: 0.2035	 bound: 1.9950	 transfer: 0.1218	 finalize: 0.1746
Accumulated time: update_bounds func: 92.7352	 prepare: 6.9243	 bound: 71.8708	 transfer: 0.1218	 finalize: 9.1802
batch bounding time:  2.504837989807129
Current worst splitting domains [lb, ub] (depth):
[-17.80943,   inf] (21), [-17.80933,   inf] (31), [-17.80927,   inf] (31), [-17.80926,   inf] (33), [-17.80904,   inf] (23), [-17.80900,   inf] (23), [-17.80894,   inf] (27), [-17.80891,   inf] (31), [-17.80890,   inf] (25), [-17.80878,   inf] (33), [-17.80861,   inf] (31), [-17.80853,   inf] (27), [-17.80839,   inf] (21), [-17.80837,   inf] (25), [-17.80836,   inf] (27), [-17.80832,   inf] (23), [-17.80826,   inf] (29), [-17.80824,   inf] (37), [-17.80822,   inf] (29), [-17.80820,   inf] (25), 
length of domains: 35024
Total time: 4.5036	 pickout: 0.2078	 decision: 1.6011	 get_bound: 2.5098	 add_domain: 0.1849
Current lb:-17.809432983398438
69984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 136.70196151733398

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 46] [3, 28] [3, 27] [3, 2] [3, 41] [3, 42] [3, 43] [3, 27] [3, 43] [3, 37] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 32737.7109375 with beta sum per layer: [0.0, 0.0, 2.7284493446350098, 2596.5029296875]
alpha/beta optimization time: 1.9941039085388184
This batch time : update_bounds func: 2.4986	 prepare: 0.2122	 bound: 1.9946	 transfer: 0.1141	 finalize: 0.1706
Accumulated time: update_bounds func: 95.2339	 prepare: 7.1365	 bound: 73.8654	 transfer: 0.1141	 finalize: 9.3508
batch bounding time:  2.501415729522705
Current worst splitting domains [lb, ub] (depth):
[-17.76555,   inf] (25), [-17.76552,   inf] (27), [-17.76536,   inf] (31), [-17.76525,   inf] (23), [-17.76525,   inf] (29), [-17.76525,   inf] (29), [-17.76506,   inf] (21), [-17.76505,   inf] (25), [-17.76493,   inf] (27), [-17.76492,   inf] (29), [-17.76491,   inf] (25), [-17.76485,   inf] (31), [-17.76483,   inf] (27), [-17.76482,   inf] (27), [-17.76482,   inf] (27), [-17.76481,   inf] (27), [-17.76478,   inf] (31), [-17.76474,   inf] (25), [-17.76471,   inf] (25), [-17.76465,   inf] (31), 
length of domains: 36024
Total time: 3.3558	 pickout: 0.2289	 decision: 0.4330	 get_bound: 2.5059	 add_domain: 0.1881
Current lb:-17.765548706054688
71984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 140.09669637680054

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 27] [3, 42] [3, 27] [3, 42] [3, 37] [3, 37] [3, 43] [3, 41] [3, 28] [3, 37] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 32668.81640625 with beta sum per layer: [0.0, 0.0, 3.687487840652466, 2656.719970703125]
alpha/beta optimization time: 1.9820120334625244
This batch time : update_bounds func: 2.4862	 prepare: 0.2028	 bound: 1.9824	 transfer: 0.1203	 finalize: 0.1737
Accumulated time: update_bounds func: 97.7201	 prepare: 7.3393	 bound: 75.8478	 transfer: 0.1203	 finalize: 9.5245
batch bounding time:  2.4892218112945557
Current worst splitting domains [lb, ub] (depth):
[-17.72154,   inf] (35), [-17.72153,   inf] (23), [-17.72151,   inf] (31), [-17.72150,   inf] (19), [-17.72143,   inf] (37), [-17.72143,   inf] (23), [-17.72141,   inf] (23), [-17.72140,   inf] (31), [-17.72129,   inf] (27), [-17.72128,   inf] (21), [-17.72127,   inf] (29), [-17.72123,   inf] (29), [-17.72122,   inf] (31), [-17.72117,   inf] (31), [-17.72113,   inf] (25), [-17.72108,   inf] (27), [-17.72103,   inf] (19), [-17.72094,   inf] (41), [-17.72094,   inf] (23), [-17.72092,   inf] (41), 
length of domains: 37024
Total time: 4.5778	 pickout: 0.2157	 decision: 1.6789	 get_bound: 2.4942	 add_domain: 0.1889
Current lb:-17.721538543701172
73984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 144.71315932273865

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 27] [3, 24] [3, 37] [3, 58] [3, 2] [3, 55] [3, 28] [3, 27] [3, 37] [3, 43] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 32621.951171875 with beta sum per layer: [0.0, 0.0, 4.01743221282959, 2656.435791015625]
alpha/beta optimization time: 1.9818291664123535
This batch time : update_bounds func: 2.4759	 prepare: 0.2032	 bound: 1.9823	 transfer: 0.1119	 finalize: 0.1714
Accumulated time: update_bounds func: 100.1960	 prepare: 7.5425	 bound: 77.8301	 transfer: 0.1119	 finalize: 9.6959
batch bounding time:  2.4786581993103027
Current worst splitting domains [lb, ub] (depth):
[-17.67797,   inf] (29), [-17.67795,   inf] (31), [-17.67792,   inf] (29), [-17.67784,   inf] (31), [-17.67775,   inf] (23), [-17.67773,   inf] (27), [-17.67770,   inf] (39), [-17.67766,   inf] (29), [-17.67762,   inf] (27), [-17.67742,   inf] (29), [-17.67739,   inf] (29), [-17.67738,   inf] (35), [-17.67727,   inf] (33), [-17.67723,   inf] (27), [-17.67721,   inf] (23), [-17.67720,   inf] (19), [-17.67720,   inf] (25), [-17.67713,   inf] (23), [-17.67713,   inf] (23), [-17.67709,   inf] (29), 
length of domains: 38024
Total time: 3.3223	 pickout: 0.2310	 decision: 0.4210	 get_bound: 2.4835	 add_domain: 0.1868
Current lb:-17.677967071533203
75984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 148.0715310573578

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 7] [2, 87] [3, 28] [3, 42] [3, 41] [3, 37] [2, 18] [3, 27] [3, 42] [3, 37] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 32546.591796875 with beta sum per layer: [0.0, 0.0, 4.2548298835754395, 2687.674560546875]
alpha/beta optimization time: 1.9835865497589111
This batch time : update_bounds func: 2.4933	 prepare: 0.2030	 bound: 1.9840	 transfer: 0.1269	 finalize: 0.1724
Accumulated time: update_bounds func: 102.6893	 prepare: 7.7455	 bound: 79.8141	 transfer: 0.1269	 finalize: 9.8683
batch bounding time:  2.4959566593170166
Current worst splitting domains [lb, ub] (depth):
[-17.63861,   inf] (25), [-17.63859,   inf] (23), [-17.63857,   inf] (25), [-17.63857,   inf] (25), [-17.63856,   inf] (35), [-17.63851,   inf] (29), [-17.63848,   inf] (27), [-17.63844,   inf] (31), [-17.63842,   inf] (37), [-17.63838,   inf] (33), [-17.63836,   inf] (31), [-17.63833,   inf] (29), [-17.63829,   inf] (29), [-17.63827,   inf] (29), [-17.63818,   inf] (43), [-17.63814,   inf] (29), [-17.63795,   inf] (21), [-17.63793,   inf] (27), [-17.63787,   inf] (25), [-17.63783,   inf] (23), 
length of domains: 39024
Total time: 4.7136	 pickout: 0.2225	 decision: 1.8035	 get_bound: 2.5004	 add_domain: 0.1872
Current lb:-17.638612747192383
77984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 152.8205544948578

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 43] [3, 41] [3, 27] [3, 27] [3, 28] [3, 2] [3, 37] [3, 2] [2, 52] [2, 87] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 32449.173828125 with beta sum per layer: [0.0, 0.0, 5.836090087890625, 2652.22265625]
alpha/beta optimization time: 1.9837126731872559
This batch time : update_bounds func: 2.4876	 prepare: 0.2033	 bound: 1.9841	 transfer: 0.1203	 finalize: 0.1726
Accumulated time: update_bounds func: 105.1769	 prepare: 7.9488	 bound: 81.7983	 transfer: 0.1203	 finalize: 10.0409
batch bounding time:  2.4905078411102295
Current worst splitting domains [lb, ub] (depth):
[-17.60070,   inf] (27), [-17.60065,   inf] (31), [-17.60062,   inf] (29), [-17.60058,   inf] (27), [-17.60035,   inf] (27), [-17.60033,   inf] (25), [-17.60029,   inf] (33), [-17.60024,   inf] (23), [-17.60023,   inf] (33), [-17.60017,   inf] (27), [-17.60013,   inf] (25), [-17.60010,   inf] (21), [-17.60009,   inf] (33), [-17.60008,   inf] (31), [-17.60007,   inf] (23), [-17.60006,   inf] (29), [-17.60002,   inf] (21), [-17.59999,   inf] (29), [-17.59995,   inf] (23), [-17.59995,   inf] (27), 
length of domains: 40024
Total time: 3.3280	 pickout: 0.2200	 decision: 0.4230	 get_bound: 2.4955	 add_domain: 0.1895
Current lb:-17.600696563720703
79984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 156.18325090408325

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 46] [3, 42] [3, 42] [3, 43] [3, 27] [3, 28] [3, 27] [3, 41] [3, 27] [3, 7] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 32380.87890625 with beta sum per layer: [0.0, 0.0, 2.4661853313446045, 2720.397705078125]
alpha/beta optimization time: 1.9848005771636963
This batch time : update_bounds func: 3.9134	 prepare: 0.2023	 bound: 1.9853	 transfer: 0.1202	 finalize: 1.5984
Accumulated time: update_bounds func: 109.0903	 prepare: 8.1511	 bound: 83.7836	 transfer: 0.1202	 finalize: 11.6394
batch bounding time:  3.9159884452819824
Current worst splitting domains [lb, ub] (depth):
[-17.56442,   inf] (27), [-17.56440,   inf] (25), [-17.56438,   inf] (31), [-17.56436,   inf] (27), [-17.56436,   inf] (25), [-17.56430,   inf] (17), [-17.56427,   inf] (27), [-17.56418,   inf] (25), [-17.56417,   inf] (31), [-17.56417,   inf] (27), [-17.56413,   inf] (27), [-17.56411,   inf] (27), [-17.56406,   inf] (29), [-17.56404,   inf] (29), [-17.56403,   inf] (27), [-17.56401,   inf] (35), [-17.56398,   inf] (23), [-17.56395,   inf] (29), [-17.56393,   inf] (33), [-17.56390,   inf] (35), 
length of domains: 41024
Total time: 4.7461	 pickout: 0.2149	 decision: 0.4257	 get_bound: 3.9203	 add_domain: 0.1852
Current lb:-17.564422607421875
81984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 160.96529746055603

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 37] [3, 28] [3, 27] [3, 46] [3, 28] [3, 24] [3, 42] [3, 41] [3, 42] [3, 43] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 32289.369140625 with beta sum per layer: [0.0, 0.0, 3.505723476409912, 2681.16552734375]
alpha/beta optimization time: 1.9807677268981934
This batch time : update_bounds func: 2.4820	 prepare: 0.2086	 bound: 1.9812	 transfer: 0.1121	 finalize: 0.1730
Accumulated time: update_bounds func: 111.5723	 prepare: 8.3597	 bound: 85.7648	 transfer: 0.1121	 finalize: 11.8124
batch bounding time:  2.4846839904785156
Current worst splitting domains [lb, ub] (depth):
[-17.52627,   inf] (31), [-17.52625,   inf] (29), [-17.52618,   inf] (19), [-17.52617,   inf] (29), [-17.52612,   inf] (25), [-17.52610,   inf] (29), [-17.52609,   inf] (29), [-17.52607,   inf] (25), [-17.52605,   inf] (25), [-17.52602,   inf] (29), [-17.52601,   inf] (21), [-17.52586,   inf] (25), [-17.52584,   inf] (35), [-17.52577,   inf] (45), [-17.52568,   inf] (23), [-17.52567,   inf] (25), [-17.52567,   inf] (27), [-17.52566,   inf] (27), [-17.52550,   inf] (27), [-17.52548,   inf] (19), 
length of domains: 42024
Total time: 3.3342	 pickout: 0.2252	 decision: 0.4280	 get_bound: 2.4891	 add_domain: 0.1918
Current lb:-17.52626609802246
83984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 164.3340985774994

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 37] [3, 27] [3, 58] [3, 28] [3, 41] [3, 37] [3, 42] [3, 58] [3, 43] [3, 46] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 32251.263671875 with beta sum per layer: [0.0, 0.0, 7.22711181640625, 2630.64306640625]
alpha/beta optimization time: 2.0025405883789062
This batch time : update_bounds func: 2.4965	 prepare: 0.2048	 bound: 2.0030	 transfer: 0.1132	 finalize: 0.1684
Accumulated time: update_bounds func: 114.0688	 prepare: 8.5644	 bound: 87.7679	 transfer: 0.1132	 finalize: 11.9807
batch bounding time:  2.4992456436157227
Current worst splitting domains [lb, ub] (depth):
[-17.48964,   inf] (31), [-17.48961,   inf] (27), [-17.48960,   inf] (27), [-17.48952,   inf] (25), [-17.48949,   inf] (33), [-17.48947,   inf] (29), [-17.48941,   inf] (25), [-17.48940,   inf] (33), [-17.48937,   inf] (29), [-17.48931,   inf] (27), [-17.48923,   inf] (29), [-17.48922,   inf] (23), [-17.48919,   inf] (23), [-17.48916,   inf] (35), [-17.48915,   inf] (29), [-17.48905,   inf] (21), [-17.48897,   inf] (23), [-17.48895,   inf] (25), [-17.48894,   inf] (25), [-17.48888,   inf] (23), 
length of domains: 43024
Total time: 3.3815	 pickout: 0.2606	 decision: 0.4269	 get_bound: 2.5038	 add_domain: 0.1901
Current lb:-17.489641189575195
85984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 167.7471535205841

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 27] [3, 46] [3, 7] [3, 27] [3, 2] [3, 27] [3, 46] [3, 2] [3, 7] [3, 27] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 32162.005859375 with beta sum per layer: [0.0, 0.0, 3.315277099609375, 2710.3583984375]
alpha/beta optimization time: 1.9902353286743164
This batch time : update_bounds func: 2.4894	 prepare: 0.2039	 bound: 1.9907	 transfer: 0.1200	 finalize: 0.1672
Accumulated time: update_bounds func: 116.5582	 prepare: 8.7683	 bound: 89.7585	 transfer: 0.1200	 finalize: 12.1480
batch bounding time:  2.4921281337738037
Current worst splitting domains [lb, ub] (depth):
[-17.45372,   inf] (27), [-17.45371,   inf] (45), [-17.45368,   inf] (41), [-17.45365,   inf] (31), [-17.45364,   inf] (27), [-17.45363,   inf] (21), [-17.45359,   inf] (27), [-17.45355,   inf] (33), [-17.45354,   inf] (25), [-17.45354,   inf] (25), [-17.45346,   inf] (25), [-17.45344,   inf] (23), [-17.45343,   inf] (31), [-17.45342,   inf] (35), [-17.45339,   inf] (33), [-17.45336,   inf] (27), [-17.45334,   inf] (27), [-17.45328,   inf] (33), [-17.45324,   inf] (25), [-17.45322,   inf] (31), 
length of domains: 44024
Total time: 4.8267	 pickout: 0.2416	 decision: 1.9026	 get_bound: 2.4967	 add_domain: 0.1858
Current lb:-17.453718185424805
87984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 172.6101861000061

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 2] [2, 41] [2, 125] [3, 46] [3, 42] [3, 42] [3, 28] [3, 2] [3, 46] [3, 37] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 32100.689453125 with beta sum per layer: [0.0, 0.0, 7.851770877838135, 2678.0341796875]
alpha/beta optimization time: 2.0237841606140137
This batch time : update_bounds func: 2.5970	 prepare: 0.2045	 bound: 2.0242	 transfer: 0.1142	 finalize: 0.2469
Accumulated time: update_bounds func: 119.1552	 prepare: 8.9729	 bound: 91.7828	 transfer: 0.1142	 finalize: 12.3949
batch bounding time:  2.599855422973633
Current worst splitting domains [lb, ub] (depth):
[-17.41743,   inf] (25), [-17.41742,   inf] (23), [-17.41741,   inf] (31), [-17.41741,   inf] (23), [-17.41740,   inf] (31), [-17.41738,   inf] (29), [-17.41738,   inf] (39), [-17.41735,   inf] (29), [-17.41735,   inf] (29), [-17.41733,   inf] (41), [-17.41732,   inf] (33), [-17.41727,   inf] (21), [-17.41725,   inf] (35), [-17.41719,   inf] (27), [-17.41710,   inf] (27), [-17.41708,   inf] (25), [-17.41708,   inf] (27), [-17.41705,   inf] (25), [-17.41701,   inf] (29), [-17.41694,   inf] (39), 
length of domains: 45024
Total time: 3.4879	 pickout: 0.2547	 decision: 0.4326	 get_bound: 2.6047	 add_domain: 0.1959
Current lb:-17.41742706298828
89984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 176.12998867034912

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 37] [3, 41] [3, 28] [3, 41] [2, 52] [3, 27] [2, 18] [3, 2] [3, 43] [2, 110] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 32028.91015625 with beta sum per layer: [0.0, 0.0, 4.489816665649414, 2718.480224609375]
alpha/beta optimization time: 2.0301527976989746
This batch time : update_bounds func: 4.2612	 prepare: 0.3206	 bound: 2.0307	 transfer: 0.1206	 finalize: 1.7821
Accumulated time: update_bounds func: 123.4165	 prepare: 9.2935	 bound: 93.8134	 transfer: 0.1206	 finalize: 14.1770
batch bounding time:  4.26446008682251
Current worst splitting domains [lb, ub] (depth):
[-17.38316,   inf] (31), [-17.38313,   inf] (31), [-17.38307,   inf] (33), [-17.38307,   inf] (29), [-17.38295,   inf] (31), [-17.38291,   inf] (37), [-17.38289,   inf] (33), [-17.38286,   inf] (25), [-17.38284,   inf] (25), [-17.38283,   inf] (23), [-17.38279,   inf] (27), [-17.38279,   inf] (33), [-17.38273,   inf] (35), [-17.38266,   inf] (29), [-17.38264,   inf] (31), [-17.38262,   inf] (27), [-17.38258,   inf] (27), [-17.38258,   inf] (31), [-17.38256,   inf] (25), [-17.38256,   inf] (45), 
length of domains: 46024
Total time: 5.2707	 pickout: 0.2958	 decision: 0.5116	 get_bound: 4.2698	 add_domain: 0.1935
Current lb:-17.383155822753906
91984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 181.43573117256165

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 42] [3, 2] [3, 37] [3, 2] [3, 2] [3, 42] [3, 27] [3, 43] [3, 42] [3, 43] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 31875.16796875 with beta sum per layer: [0.0, 0.0, 6.961691856384277, 2779.08984375]
alpha/beta optimization time: 2.0298688411712646
This batch time : update_bounds func: 2.7235	 prepare: 0.3208	 bound: 2.0304	 transfer: 0.1141	 finalize: 0.2511
Accumulated time: update_bounds func: 126.1400	 prepare: 9.6143	 bound: 95.8438	 transfer: 0.1141	 finalize: 14.4280
batch bounding time:  2.7262778282165527
Current worst splitting domains [lb, ub] (depth):
[-17.35042,   inf] (27), [-17.35041,   inf] (21), [-17.35038,   inf] (27), [-17.35029,   inf] (29), [-17.35028,   inf] (35), [-17.35026,   inf] (27), [-17.35025,   inf] (25), [-17.35023,   inf] (25), [-17.35021,   inf] (29), [-17.35021,   inf] (33), [-17.35015,   inf] (37), [-17.35015,   inf] (23), [-17.35014,   inf] (33), [-17.35012,   inf] (33), [-17.35008,   inf] (25), [-17.35008,   inf] (27), [-17.35005,   inf] (29), [-17.35001,   inf] (31), [-17.34996,   inf] (37), [-17.34995,   inf] (25), 
length of domains: 47024
Total time: 3.7391	 pickout: 0.2983	 decision: 0.5145	 get_bound: 2.7310	 add_domain: 0.1953
Current lb:-17.35042381286621
93984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 185.2113115787506

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 42] [3, 7] [3, 7] [3, 28] [2, 63] [3, 41] [3, 27] [3, 43] [3, 41] [3, 27] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 31880.78515625 with beta sum per layer: [0.0, 0.0, 7.030308723449707, 2691.668701171875]
alpha/beta optimization time: 2.031090021133423
This batch time : update_bounds func: 2.7314	 prepare: 0.3234	 bound: 2.0316	 transfer: 0.1125	 finalize: 0.2566
Accumulated time: update_bounds func: 128.8714	 prepare: 9.9377	 bound: 97.8754	 transfer: 0.1125	 finalize: 14.6846
batch bounding time:  2.7343029975891113
Current worst splitting domains [lb, ub] (depth):
[-17.31981,   inf] (43), [-17.31978,   inf] (25), [-17.31977,   inf] (43), [-17.31970,   inf] (29), [-17.31968,   inf] (29), [-17.31967,   inf] (25), [-17.31964,   inf] (31), [-17.31961,   inf] (25), [-17.31960,   inf] (45), [-17.31958,   inf] (21), [-17.31954,   inf] (21), [-17.31952,   inf] (21), [-17.31952,   inf] (27), [-17.31951,   inf] (23), [-17.31951,   inf] (37), [-17.31949,   inf] (29), [-17.31945,   inf] (27), [-17.31942,   inf] (31), [-17.31941,   inf] (33), [-17.31941,   inf] (31), 
length of domains: 48024
Total time: 3.7412	 pickout: 0.2976	 decision: 0.5098	 get_bound: 2.7391	 add_domain: 0.1946
Current lb:-17.319805145263672
95984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 188.9906826019287

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 125] [3, 55] [2, 41] [3, 41] [3, 37] [3, 42] [3, 37] [3, 42] [2, 79] [3, 43] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 31838.19921875 with beta sum per layer: [0.0, 0.0, 5.9365339279174805, 2671.1513671875]
alpha/beta optimization time: 2.0335285663604736
This batch time : update_bounds func: 4.3877	 prepare: 0.3228	 bound: 2.0340	 transfer: 0.1233	 finalize: 1.9003
Accumulated time: update_bounds func: 133.2591	 prepare: 10.2605	 bound: 99.9094	 transfer: 0.1233	 finalize: 16.5849
batch bounding time:  4.390430450439453
Current worst splitting domains [lb, ub] (depth):
[-17.28879,   inf] (29), [-17.28878,   inf] (27), [-17.28868,   inf] (37), [-17.28846,   inf] (23), [-17.28845,   inf] (31), [-17.28845,   inf] (25), [-17.28843,   inf] (25), [-17.28841,   inf] (25), [-17.28831,   inf] (27), [-17.28821,   inf] (35), [-17.28811,   inf] (31), [-17.28810,   inf] (33), [-17.28808,   inf] (23), [-17.28803,   inf] (25), [-17.28801,   inf] (27), [-17.28796,   inf] (45), [-17.28795,   inf] (39), [-17.28794,   inf] (27), [-17.28788,   inf] (27), [-17.28783,   inf] (45), 
length of domains: 49024
Total time: 5.3858	 pickout: 0.2873	 decision: 0.5086	 get_bound: 4.3951	 add_domain: 0.1948
Current lb:-17.288785934448242
97984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 194.41143655776978

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 41] [3, 28] [2, 52] [3, 58] [3, 27] [3, 27] [3, 37] [3, 37] [3, 7] [3, 27] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 31882.462890625 with beta sum per layer: [0.0, 0.0, 8.96058464050293, 2694.638916015625]
alpha/beta optimization time: 2.032290458679199
This batch time : update_bounds func: 2.7275	 prepare: 0.3258	 bound: 2.0328	 transfer: 0.1125	 finalize: 0.2489
Accumulated time: update_bounds func: 135.9866	 prepare: 10.5862	 bound: 101.9422	 transfer: 0.1125	 finalize: 16.8339
batch bounding time:  2.730412244796753
Current worst splitting domains [lb, ub] (depth):
[-17.25694,   inf] (39), [-17.25691,   inf] (21), [-17.25690,   inf] (37), [-17.25684,   inf] (25), [-17.25677,   inf] (21), [-17.25674,   inf] (25), [-17.25669,   inf] (39), [-17.25669,   inf] (31), [-17.25668,   inf] (23), [-17.25665,   inf] (21), [-17.25659,   inf] (31), [-17.25651,   inf] (23), [-17.25644,   inf] (23), [-17.25642,   inf] (31), [-17.25638,   inf] (27), [-17.25633,   inf] (25), [-17.25632,   inf] (33), [-17.25623,   inf] (25), [-17.25620,   inf] (33), [-17.25618,   inf] (31), 
length of domains: 50024
Total time: 3.7314	 pickout: 0.2858	 decision: 0.5129	 get_bound: 2.7351	 add_domain: 0.1976
Current lb:-17.256938934326172
99984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 198.17835903167725

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 55] [3, 7] [3, 2] [3, 46] [3, 46] [3, 41] [2, 18] [3, 46] [3, 41] [3, 42] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 31721.498046875 with beta sum per layer: [0.0, 0.0, 7.649087905883789, 2721.43017578125]
alpha/beta optimization time: 1.9941270351409912
This batch time : update_bounds func: 2.6159	 prepare: 0.3246	 bound: 1.9946	 transfer: 0.1192	 finalize: 0.1703
Accumulated time: update_bounds func: 138.6025	 prepare: 10.9108	 bound: 103.9369	 transfer: 0.1192	 finalize: 17.0041
batch bounding time:  2.618403196334839
Current worst splitting domains [lb, ub] (depth):
[-17.22653,   inf] (41), [-17.22650,   inf] (25), [-17.22649,   inf] (37), [-17.22648,   inf] (35), [-17.22641,   inf] (17), [-17.22635,   inf] (23), [-17.22632,   inf] (37), [-17.22629,   inf] (23), [-17.22627,   inf] (21), [-17.22626,   inf] (29), [-17.22625,   inf] (33), [-17.22624,   inf] (35), [-17.22623,   inf] (39), [-17.22621,   inf] (31), [-17.22619,   inf] (23), [-17.22618,   inf] (27), [-17.22614,   inf] (23), [-17.22612,   inf] (33), [-17.22603,   inf] (33), [-17.22594,   inf] (23), 
length of domains: 51024
Total time: 3.6107	 pickout: 0.2854	 decision: 0.5158	 get_bound: 2.6226	 add_domain: 0.1868
Current lb:-17.22652816772461
101984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 201.8268735408783

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 79] [3, 27] [3, 37] [3, 28] [3, 24] [3, 41] [2, 18] [3, 58] [3, 7] [3, 46] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 31648.458984375 with beta sum per layer: [0.0, 0.0, 8.027308464050293, 2779.87109375]
alpha/beta optimization time: 1.9750885963439941
This batch time : update_bounds func: 4.2507	 prepare: 0.2027	 bound: 1.9756	 transfer: 0.1197	 finalize: 1.9455
Accumulated time: update_bounds func: 142.8532	 prepare: 11.1135	 bound: 105.9124	 transfer: 0.1197	 finalize: 18.9497
batch bounding time:  4.253500461578369
Current worst splitting domains [lb, ub] (depth):
[-17.19683,   inf] (33), [-17.19682,   inf] (29), [-17.19680,   inf] (27), [-17.19680,   inf] (29), [-17.19677,   inf] (29), [-17.19670,   inf] (25), [-17.19667,   inf] (23), [-17.19662,   inf] (27), [-17.19662,   inf] (25), [-17.19660,   inf] (25), [-17.19660,   inf] (35), [-17.19657,   inf] (23), [-17.19656,   inf] (27), [-17.19655,   inf] (31), [-17.19651,   inf] (29), [-17.19649,   inf] (33), [-17.19647,   inf] (27), [-17.19646,   inf] (25), [-17.19646,   inf] (35), [-17.19644,   inf] (29), 
length of domains: 52024
Total time: 5.0894	 pickout: 0.2213	 decision: 0.4210	 get_bound: 4.2581	 add_domain: 0.1889
Current lb:-17.196826934814453
103984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 206.96204805374146

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 42] [3, 27] [3, 28] [3, 27] [3, 37] [3, 42] [3, 42] [3, 37] [3, 37] [3, 41] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 31544.423828125 with beta sum per layer: [0.0, 0.0, 6.761590480804443, 2795.899658203125]
alpha/beta optimization time: 1.9666337966918945
This batch time : update_bounds func: 2.4603	 prepare: 0.2025	 bound: 1.9671	 transfer: 0.1107	 finalize: 0.1729
Accumulated time: update_bounds func: 145.3135	 prepare: 11.3160	 bound: 107.8795	 transfer: 0.1107	 finalize: 19.1225
batch bounding time:  2.4629855155944824
Current worst splitting domains [lb, ub] (depth):
[-17.16829,   inf] (25), [-17.16827,   inf] (25), [-17.16827,   inf] (29), [-17.16822,   inf] (27), [-17.16819,   inf] (29), [-17.16817,   inf] (37), [-17.16813,   inf] (35), [-17.16812,   inf] (35), [-17.16799,   inf] (29), [-17.16795,   inf] (25), [-17.16790,   inf] (27), [-17.16789,   inf] (29), [-17.16789,   inf] (31), [-17.16788,   inf] (25), [-17.16784,   inf] (39), [-17.16783,   inf] (23), [-17.16780,   inf] (45), [-17.16778,   inf] (33), [-17.16776,   inf] (31), [-17.16776,   inf] (23), 
length of domains: 53024
Total time: 3.3079	 pickout: 0.2309	 decision: 0.4196	 get_bound: 2.4674	 add_domain: 0.1900
Current lb:-17.16828727722168
105984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 210.31373143196106

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 37] [3, 27] [3, 7] [3, 46] [3, 37] [3, 2] [2, 87] [3, 37] [3, 42] [3, 43] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 31554.283203125 with beta sum per layer: [0.0, 0.0, 6.969542503356934, 2794.249755859375]
alpha/beta optimization time: 1.960479974746704
This batch time : update_bounds func: 2.4638	 prepare: 0.2023	 bound: 1.9609	 transfer: 0.1193	 finalize: 0.1739
Accumulated time: update_bounds func: 147.7772	 prepare: 11.5182	 bound: 109.8404	 transfer: 0.1193	 finalize: 19.2964
batch bounding time:  2.466536283493042
Current worst splitting domains [lb, ub] (depth):
[-17.13979,   inf] (27), [-17.13977,   inf] (31), [-17.13976,   inf] (25), [-17.13973,   inf] (23), [-17.13972,   inf] (27), [-17.13967,   inf] (27), [-17.13966,   inf] (29), [-17.13964,   inf] (29), [-17.13964,   inf] (21), [-17.13963,   inf] (33), [-17.13963,   inf] (31), [-17.13960,   inf] (31), [-17.13959,   inf] (31), [-17.13955,   inf] (27), [-17.13954,   inf] (27), [-17.13953,   inf] (27), [-17.13942,   inf] (31), [-17.13935,   inf] (33), [-17.13932,   inf] (25), [-17.13922,   inf] (23), 
length of domains: 54024
Total time: 3.3114	 pickout: 0.2265	 decision: 0.4218	 get_bound: 2.4712	 add_domain: 0.1920
Current lb:-17.139793395996094
107984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 213.66338324546814

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 46] [3, 37] [3, 37] [3, 7] [3, 37] [3, 41] [3, 37] [3, 37] [3, 37] [3, 2] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 31458.01171875 with beta sum per layer: [0.0, 0.0, 6.3431854248046875, 2781.12744140625]
alpha/beta optimization time: 1.9604108333587646
This batch time : update_bounds func: 4.4077	 prepare: 0.2025	 bound: 1.9608	 transfer: 0.1108	 finalize: 2.1262
Accumulated time: update_bounds func: 152.1850	 prepare: 11.7207	 bound: 111.8012	 transfer: 0.1108	 finalize: 21.4226
batch bounding time:  4.4104297161102295
Current worst splitting domains [lb, ub] (depth):
[-17.11132,   inf] (33), [-17.11129,   inf] (31), [-17.11128,   inf] (31), [-17.11126,   inf] (29), [-17.11125,   inf] (27), [-17.11122,   inf] (25), [-17.11112,   inf] (31), [-17.11110,   inf] (29), [-17.11104,   inf] (25), [-17.11102,   inf] (41), [-17.11098,   inf] (29), [-17.11096,   inf] (33), [-17.11088,   inf] (25), [-17.11087,   inf] (29), [-17.11081,   inf] (27), [-17.11080,   inf] (21), [-17.11077,   inf] (33), [-17.11076,   inf] (31), [-17.11073,   inf] (25), [-17.11071,   inf] (25), 
length of domains: 55024
Total time: 5.2650	 pickout: 0.2393	 decision: 0.4220	 get_bound: 4.4150	 add_domain: 0.1887
Current lb:-17.1113224029541
109984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 218.96338891983032

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 41] [3, 42] [3, 42] [3, 2] [3, 46] [3, 37] [3, 37] [3, 2] [3, 37] [2, 18] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 31488.658203125 with beta sum per layer: [0.0, 0.0, 11.704063415527344, 2782.92431640625]
alpha/beta optimization time: 1.9537134170532227
This batch time : update_bounds func: 2.4631	 prepare: 0.2044	 bound: 1.9542	 transfer: 0.1258	 finalize: 0.1712
Accumulated time: update_bounds func: 154.6480	 prepare: 11.9251	 bound: 113.7554	 transfer: 0.1258	 finalize: 21.5938
batch bounding time:  2.4657039642333984
Current worst splitting domains [lb, ub] (depth):
[-17.08204,   inf] (49), [-17.08194,   inf] (29), [-17.08191,   inf] (23), [-17.08187,   inf] (29), [-17.08185,   inf] (27), [-17.08182,   inf] (27), [-17.08180,   inf] (27), [-17.08175,   inf] (25), [-17.08174,   inf] (31), [-17.08167,   inf] (23), [-17.08166,   inf] (23), [-17.08166,   inf] (39), [-17.08165,   inf] (25), [-17.08163,   inf] (25), [-17.08161,   inf] (27), [-17.08158,   inf] (21), [-17.08152,   inf] (29), [-17.08151,   inf] (33), [-17.08145,   inf] (35), [-17.08143,   inf] (21), 
length of domains: 56024
Total time: 3.3135	 pickout: 0.2323	 decision: 0.4185	 get_bound: 2.4701	 add_domain: 0.1927
Current lb:-17.0820369720459
111984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 222.31222939491272

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 13] [3, 41] [3, 41] [3, 27] [3, 37] [3, 42] [3, 2] [3, 37] [3, 37] [3, 41] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 31406.404296875 with beta sum per layer: [0.0, 0.0, 8.003499984741211, 2838.71435546875]
alpha/beta optimization time: 1.9567749500274658
This batch time : update_bounds func: 2.4504	 prepare: 0.2040	 bound: 1.9572	 transfer: 0.1109	 finalize: 0.1709
Accumulated time: update_bounds func: 157.0984	 prepare: 12.1291	 bound: 115.7126	 transfer: 0.1109	 finalize: 21.7648
batch bounding time:  2.453071117401123
Current worst splitting domains [lb, ub] (depth):
[-17.05520,   inf] (35), [-17.05516,   inf] (27), [-17.05516,   inf] (35), [-17.05511,   inf] (29), [-17.05510,   inf] (31), [-17.05505,   inf] (25), [-17.05504,   inf] (31), [-17.05502,   inf] (29), [-17.05499,   inf] (31), [-17.05497,   inf] (37), [-17.05497,   inf] (35), [-17.05494,   inf] (41), [-17.05493,   inf] (21), [-17.05489,   inf] (27), [-17.05485,   inf] (27), [-17.05484,   inf] (33), [-17.05482,   inf] (27), [-17.05479,   inf] (39), [-17.05477,   inf] (27), [-17.05476,   inf] (33), 
length of domains: 57024
Total time: 3.3060	 pickout: 0.2345	 decision: 0.4228	 get_bound: 2.4576	 add_domain: 0.1911
Current lb:-17.055198669433594
113984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 225.65341019630432

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 37] [3, 37] [3, 46] [3, 46] [3, 37] [3, 43] [3, 27] [3, 2] [3, 27] [2, 52] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 31455.828125 with beta sum per layer: [0.0, 0.0, 10.499774932861328, 2770.9013671875]
alpha/beta optimization time: 1.956840991973877
This batch time : update_bounds func: 4.4636	 prepare: 0.2048	 bound: 1.9573	 transfer: 0.1166	 finalize: 2.1776
Accumulated time: update_bounds func: 161.5620	 prepare: 12.3339	 bound: 117.6698	 transfer: 0.1166	 finalize: 23.9424
batch bounding time:  4.466521501541138
Current worst splitting domains [lb, ub] (depth):
[-17.02910,   inf] (35), [-17.02907,   inf] (37), [-17.02906,   inf] (27), [-17.02904,   inf] (23), [-17.02904,   inf] (29), [-17.02899,   inf] (39), [-17.02897,   inf] (43), [-17.02897,   inf] (29), [-17.02895,   inf] (25), [-17.02888,   inf] (23), [-17.02883,   inf] (35), [-17.02881,   inf] (29), [-17.02878,   inf] (37), [-17.02872,   inf] (29), [-17.02871,   inf] (27), [-17.02868,   inf] (43), [-17.02868,   inf] (43), [-17.02866,   inf] (25), [-17.02858,   inf] (41), [-17.02850,   inf] (33), 
length of domains: 58024
Total time: 5.3071	 pickout: 0.2278	 decision: 0.4186	 get_bound: 4.4714	 add_domain: 0.1893
Current lb:-17.029102325439453
115984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 230.9982442855835

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 63] [2, 52] [3, 42] [3, 43] [3, 46] [2, 18] [3, 13] [3, 41] [3, 27] [3, 42] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 31334.05078125 with beta sum per layer: [0.0, 0.0, 8.769153594970703, 2799.71728515625]
alpha/beta optimization time: 1.9989783763885498
This batch time : update_bounds func: 2.4895	 prepare: 0.2040	 bound: 1.9995	 transfer: 0.1073	 finalize: 0.1714
Accumulated time: update_bounds func: 164.0515	 prepare: 12.5379	 bound: 119.6693	 transfer: 0.1073	 finalize: 24.1138
batch bounding time:  2.492050886154175
Current worst splitting domains [lb, ub] (depth):
[-17.00439,   inf] (29), [-17.00434,   inf] (25), [-17.00433,   inf] (29), [-17.00432,   inf] (33), [-17.00430,   inf] (23), [-17.00428,   inf] (27), [-17.00427,   inf] (27), [-17.00423,   inf] (39), [-17.00422,   inf] (21), [-17.00421,   inf] (25), [-17.00419,   inf] (27), [-17.00418,   inf] (25), [-17.00418,   inf] (27), [-17.00417,   inf] (21), [-17.00415,   inf] (27), [-17.00415,   inf] (27), [-17.00410,   inf] (27), [-17.00410,   inf] (41), [-17.00408,   inf] (33), [-17.00406,   inf] (31), 
length of domains: 59024
Total time: 3.3377	 pickout: 0.2280	 decision: 0.4225	 get_bound: 2.4963	 add_domain: 0.1909
Current lb:-17.00439453125
117984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 234.3725266456604

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 27] [3, 41] [3, 46] [3, 27] [3, 41] [3, 42] [3, 37] [3, 46] [3, 46] [3, 27] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 31335.09375 with beta sum per layer: [0.0, 0.0, 13.243043899536133, 2754.3896484375]
alpha/beta optimization time: 1.9620957374572754
This batch time : update_bounds func: 2.4553	 prepare: 0.2040	 bound: 1.9625	 transfer: 0.1139	 finalize: 0.1673
Accumulated time: update_bounds func: 166.5069	 prepare: 12.7419	 bound: 121.6318	 transfer: 0.1139	 finalize: 24.2811
batch bounding time:  2.458163261413574
Current worst splitting domains [lb, ub] (depth):
[-16.97976,   inf] (41), [-16.97975,   inf] (43), [-16.97974,   inf] (33), [-16.97967,   inf] (35), [-16.97965,   inf] (29), [-16.97962,   inf] (25), [-16.97961,   inf] (29), [-16.97958,   inf] (33), [-16.97949,   inf] (35), [-16.97948,   inf] (33), [-16.97947,   inf] (33), [-16.97945,   inf] (23), [-16.97935,   inf] (23), [-16.97932,   inf] (29), [-16.97931,   inf] (39), [-16.97927,   inf] (23), [-16.97927,   inf] (31), [-16.97925,   inf] (27), [-16.97921,   inf] (31), [-16.97919,   inf] (25), 
length of domains: 60024
Total time: 3.3418	 pickout: 0.2590	 decision: 0.4233	 get_bound: 2.4633	 add_domain: 0.1961
Current lb:-16.97976303100586
119984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 237.74714469909668

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 63] [2, 87] [3, 7] [3, 42] [3, 46] [3, 41] [3, 2] [3, 27] [3, 37] [3, 43] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 31273.41796875 with beta sum per layer: [0.0, 0.0, 12.321701049804688, 2766.3095703125]
alpha/beta optimization time: 1.9739758968353271
This batch time : update_bounds func: 2.4699	 prepare: 0.2044	 bound: 1.9744	 transfer: 0.1136	 finalize: 0.1700
Accumulated time: update_bounds func: 168.9768	 prepare: 12.9463	 bound: 123.6062	 transfer: 0.1136	 finalize: 24.4511
batch bounding time:  2.472602605819702
Current worst splitting domains [lb, ub] (depth):
[-16.95469,   inf] (41), [-16.95468,   inf] (23), [-16.95468,   inf] (35), [-16.95467,   inf] (27), [-16.95463,   inf] (25), [-16.95463,   inf] (33), [-16.95463,   inf] (29), [-16.95461,   inf] (31), [-16.95461,   inf] (31), [-16.95457,   inf] (37), [-16.95455,   inf] (25), [-16.95449,   inf] (29), [-16.95448,   inf] (29), [-16.95445,   inf] (25), [-16.95443,   inf] (33), [-16.95443,   inf] (29), [-16.95441,   inf] (29), [-16.95437,   inf] (33), [-16.95435,   inf] (29), [-16.95434,   inf] (23), 
length of domains: 61024
Total time: 3.3356	 pickout: 0.2388	 decision: 0.4280	 get_bound: 2.4770	 add_domain: 0.1919
Current lb:-16.954692840576172
121984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 241.11867308616638

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 52] [3, 42] [2, 41] [3, 43] [3, 42] [3, 37] [3, 7] [3, 2] [3, 37] [2, 52] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 31139.931640625 with beta sum per layer: [0.0, 0.0, 8.84291934967041, 2837.14111328125]
alpha/beta optimization time: 1.959547519683838
This batch time : update_bounds func: 2.4526	 prepare: 0.2066	 bound: 1.9600	 transfer: 0.1049	 finalize: 0.1735
Accumulated time: update_bounds func: 171.4294	 prepare: 13.1529	 bound: 125.5662	 transfer: 0.1049	 finalize: 24.6246
batch bounding time:  2.4551475048065186
Current worst splitting domains [lb, ub] (depth):
[-16.93056,   inf] (21), [-16.93047,   inf] (21), [-16.93044,   inf] (25), [-16.93042,   inf] (29), [-16.93040,   inf] (37), [-16.93037,   inf] (27), [-16.93036,   inf] (31), [-16.93036,   inf] (33), [-16.93036,   inf] (31), [-16.93035,   inf] (25), [-16.93034,   inf] (39), [-16.93030,   inf] (31), [-16.93029,   inf] (25), [-16.93029,   inf] (35), [-16.93027,   inf] (43), [-16.93026,   inf] (35), [-16.93025,   inf] (23), [-16.93021,   inf] (29), [-16.93018,   inf] (23), [-16.93008,   inf] (33), 
length of domains: 62024
Total time: 5.3897	 pickout: 0.2498	 decision: 2.4880	 get_bound: 2.4597	 add_domain: 0.1922
Current lb:-16.930564880371094
123984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 246.54545783996582

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 42] [3, 24] [3, 41] [3, 37] [3, 27] [3, 27] [3, 27] [3, 46] [3, 27] [3, 7] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 31090.4375 with beta sum per layer: [0.0, 0.0, 10.614428520202637, 2752.794921875]
alpha/beta optimization time: 1.9644651412963867
This batch time : update_bounds func: 2.4627	 prepare: 0.2056	 bound: 1.9649	 transfer: 0.1138	 finalize: 0.1708
Accumulated time: update_bounds func: 173.8921	 prepare: 13.3585	 bound: 127.5311	 transfer: 0.1138	 finalize: 24.7954
batch bounding time:  2.46531343460083
Current worst splitting domains [lb, ub] (depth):
[-16.90723,   inf] (27), [-16.90722,   inf] (31), [-16.90716,   inf] (35), [-16.90716,   inf] (27), [-16.90715,   inf] (29), [-16.90711,   inf] (19), [-16.90711,   inf] (39), [-16.90711,   inf] (29), [-16.90710,   inf] (23), [-16.90708,   inf] (33), [-16.90706,   inf] (25), [-16.90705,   inf] (27), [-16.90703,   inf] (25), [-16.90702,   inf] (39), [-16.90702,   inf] (25), [-16.90699,   inf] (39), [-16.90695,   inf] (25), [-16.90693,   inf] (31), [-16.90692,   inf] (23), [-16.90690,   inf] (29), 
length of domains: 63024
Total time: 3.3228	 pickout: 0.2392	 decision: 0.4211	 get_bound: 2.4699	 add_domain: 0.1925
Current lb:-16.907228469848633
125984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 249.9061381816864

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 28] [3, 27] [3, 42] [3, 2] [3, 28] [3, 58] [2, 87] [3, 46] [3, 7] [3, 2] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 31043.0546875 with beta sum per layer: [0.0, 0.0, 13.857915878295898, 2758.65234375]
alpha/beta optimization time: 1.9610955715179443
This batch time : update_bounds func: 2.4635	 prepare: 0.2076	 bound: 1.9615	 transfer: 0.1139	 finalize: 0.1729
Accumulated time: update_bounds func: 176.3556	 prepare: 13.5660	 bound: 129.4926	 transfer: 0.1139	 finalize: 24.9683
batch bounding time:  2.4660794734954834
Current worst splitting domains [lb, ub] (depth):
[-16.88410,   inf] (27), [-16.88409,   inf] (39), [-16.88402,   inf] (33), [-16.88401,   inf] (31), [-16.88400,   inf] (27), [-16.88395,   inf] (29), [-16.88394,   inf] (33), [-16.88392,   inf] (23), [-16.88389,   inf] (27), [-16.88387,   inf] (31), [-16.88387,   inf] (47), [-16.88387,   inf] (21), [-16.88381,   inf] (25), [-16.88378,   inf] (27), [-16.88378,   inf] (29), [-16.88377,   inf] (33), [-16.88377,   inf] (37), [-16.88376,   inf] (45), [-16.88374,   inf] (23), [-16.88370,   inf] (39), 
length of domains: 64024
Total time: 3.3248	 pickout: 0.2411	 decision: 0.4196	 get_bound: 2.4707	 add_domain: 0.1934
Current lb:-16.884096145629883
127984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 253.26863050460815

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 42] [2, 18] [3, 27] [3, 27] [3, 2] [3, 43] [2, 87] [3, 42] [3, 37] [3, 27] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 31063.310546875 with beta sum per layer: [0.0, 0.0, 12.237003326416016, 2791.140380859375]
alpha/beta optimization time: 1.9587571620941162
This batch time : update_bounds func: 4.6524	 prepare: 0.2078	 bound: 1.9592	 transfer: 0.1130	 finalize: 2.3647
Accumulated time: update_bounds func: 181.0080	 prepare: 13.7738	 bound: 131.4518	 transfer: 0.1130	 finalize: 27.3331
batch bounding time:  4.655251979827881
Current worst splitting domains [lb, ub] (depth):
[-16.86138,   inf] (33), [-16.86136,   inf] (23), [-16.86132,   inf] (29), [-16.86131,   inf] (33), [-16.86130,   inf] (25), [-16.86129,   inf] (31), [-16.86127,   inf] (29), [-16.86125,   inf] (23), [-16.86125,   inf] (23), [-16.86122,   inf] (27), [-16.86118,   inf] (27), [-16.86110,   inf] (29), [-16.86109,   inf] (25), [-16.86108,   inf] (39), [-16.86103,   inf] (39), [-16.86102,   inf] (29), [-16.86101,   inf] (27), [-16.86095,   inf] (23), [-16.86090,   inf] (27), [-16.86083,   inf] (29), 
length of domains: 65024
Total time: 5.5148	 pickout: 0.2409	 decision: 0.4206	 get_bound: 4.6599	 add_domain: 0.1933
Current lb:-16.86138343811035
129984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 258.8231439590454

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 46] [3, 41] [3, 37] [3, 37] [3, 41] [3, 37] [3, 2] [3, 43] [3, 37] [3, 42] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 31042.8203125 with beta sum per layer: [0.0, 0.0, 10.132862091064453, 2759.947998046875]
alpha/beta optimization time: 1.966200828552246
This batch time : update_bounds func: 2.4687	 prepare: 0.2039	 bound: 1.9666	 transfer: 0.1201	 finalize: 0.1703
Accumulated time: update_bounds func: 183.4767	 prepare: 13.9777	 bound: 133.4184	 transfer: 0.1201	 finalize: 27.5034
batch bounding time:  2.471613883972168
Current worst splitting domains [lb, ub] (depth):
[-16.83797,   inf] (27), [-16.83794,   inf] (27), [-16.83791,   inf] (27), [-16.83788,   inf] (39), [-16.83788,   inf] (23), [-16.83788,   inf] (23), [-16.83788,   inf] (21), [-16.83787,   inf] (25), [-16.83786,   inf] (45), [-16.83785,   inf] (25), [-16.83784,   inf] (35), [-16.83783,   inf] (25), [-16.83781,   inf] (27), [-16.83780,   inf] (33), [-16.83779,   inf] (27), [-16.83778,   inf] (23), [-16.83778,   inf] (37), [-16.83775,   inf] (49), [-16.83775,   inf] (39), [-16.83772,   inf] (29), 
length of domains: 66024
Total time: 3.3385	 pickout: 0.2318	 decision: 0.4310	 get_bound: 2.4767	 add_domain: 0.1990
Current lb:-16.83796501159668
131984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 262.19944977760315

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 28] [3, 46] [3, 46] [2, 18] [3, 42] [3, 46] [3, 58] [3, 46] [2, 18] [3, 7] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 30983.826171875 with beta sum per layer: [0.0, 0.0, 20.075889587402344, 2702.7568359375]
alpha/beta optimization time: 1.976987361907959
This batch time : update_bounds func: 2.4671	 prepare: 0.2061	 bound: 1.9775	 transfer: 0.1091	 finalize: 0.1667
Accumulated time: update_bounds func: 185.9438	 prepare: 14.1838	 bound: 135.3958	 transfer: 0.1091	 finalize: 27.6701
batch bounding time:  2.47023606300354
Current worst splitting domains [lb, ub] (depth):
[-16.81547,   inf] (35), [-16.81547,   inf] (25), [-16.81542,   inf] (43), [-16.81542,   inf] (23), [-16.81541,   inf] (23), [-16.81535,   inf] (25), [-16.81533,   inf] (29), [-16.81533,   inf] (27), [-16.81532,   inf] (45), [-16.81530,   inf] (37), [-16.81525,   inf] (31), [-16.81523,   inf] (39), [-16.81522,   inf] (31), [-16.81522,   inf] (31), [-16.81520,   inf] (31), [-16.81518,   inf] (35), [-16.81517,   inf] (33), [-16.81515,   inf] (29), [-16.81514,   inf] (29), [-16.81511,   inf] (45), 
length of domains: 67024
Total time: 3.3486	 pickout: 0.2469	 decision: 0.4235	 get_bound: 2.4757	 add_domain: 0.2026
Current lb:-16.815471649169922
133984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 265.5865695476532

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 41] [3, 27] [2, 18] [3, 43] [3, 7] [3, 27] [3, 43] [3, 46] [2, 63] [2, 110] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 30961.8828125 with beta sum per layer: [0.0, 0.0, 14.709663391113281, 2818.028564453125]
alpha/beta optimization time: 1.9564640522003174
This batch time : update_bounds func: 2.4526	 prepare: 0.2050	 bound: 1.9569	 transfer: 0.1140	 finalize: 0.1689
Accumulated time: update_bounds func: 188.3964	 prepare: 14.3887	 bound: 137.3527	 transfer: 0.1140	 finalize: 27.8390
batch bounding time:  2.455275297164917
Current worst splitting domains [lb, ub] (depth):
[-16.79107,   inf] (39), [-16.79106,   inf] (33), [-16.79106,   inf] (37), [-16.79105,   inf] (29), [-16.79103,   inf] (25), [-16.79101,   inf] (37), [-16.79100,   inf] (29), [-16.79100,   inf] (29), [-16.79099,   inf] (43), [-16.79098,   inf] (41), [-16.79098,   inf] (31), [-16.79095,   inf] (29), [-16.79094,   inf] (35), [-16.79094,   inf] (29), [-16.79089,   inf] (27), [-16.79086,   inf] (37), [-16.79080,   inf] (33), [-16.79077,   inf] (35), [-16.79074,   inf] (35), [-16.79073,   inf] (31), 
length of domains: 68024
Total time: 3.3354	 pickout: 0.2422	 decision: 0.4396	 get_bound: 2.4597	 add_domain: 0.1939
Current lb:-16.79106903076172
135984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 268.9598801136017

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 87] [3, 42] [2, 18] [3, 28] [3, 42] [2, 79] [3, 37] [3, 7] [2, 41] [2, 84] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 30955.619140625 with beta sum per layer: [0.0, 0.0, 19.913293838500977, 2776.966796875]
alpha/beta optimization time: 1.9513661861419678
This batch time : update_bounds func: 4.8428	 prepare: 0.2047	 bound: 1.9518	 transfer: 0.1145	 finalize: 2.5640
Accumulated time: update_bounds func: 193.2392	 prepare: 14.5934	 bound: 139.3045	 transfer: 0.1145	 finalize: 30.4030
batch bounding time:  4.84564208984375
Current worst splitting domains [lb, ub] (depth):
[-16.76836,   inf] (27), [-16.76836,   inf] (33), [-16.76828,   inf] (25), [-16.76827,   inf] (27), [-16.76823,   inf] (33), [-16.76823,   inf] (33), [-16.76821,   inf] (25), [-16.76818,   inf] (27), [-16.76818,   inf] (33), [-16.76817,   inf] (31), [-16.76812,   inf] (41), [-16.76810,   inf] (25), [-16.76808,   inf] (37), [-16.76807,   inf] (29), [-16.76805,   inf] (37), [-16.76805,   inf] (29), [-16.76804,   inf] (25), [-16.76803,   inf] (23), [-16.76796,   inf] (27), [-16.76792,   inf] (31), 
length of domains: 69024
Total time: 5.7109	 pickout: 0.2417	 decision: 0.4254	 get_bound: 4.8501	 add_domain: 0.1938
Current lb:-16.768360137939453
137984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 274.71706986427307

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 37] [3, 42] [3, 27] [3, 43] [3, 2] [3, 37] [3, 41] [3, 37] [3, 46] [3, 42] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 30872.771484375 with beta sum per layer: [0.0, 0.0, 15.302345275878906, 2815.9697265625]
alpha/beta optimization time: 1.9513485431671143
This batch time : update_bounds func: 2.4526	 prepare: 0.2072	 bound: 1.9518	 transfer: 0.1124	 finalize: 0.1740
Accumulated time: update_bounds func: 195.6918	 prepare: 14.8006	 bound: 141.2563	 transfer: 0.1124	 finalize: 30.5770
batch bounding time:  2.45527720451355
Current worst splitting domains [lb, ub] (depth):
[-16.74672,   inf] (27), [-16.74671,   inf] (25), [-16.74668,   inf] (29), [-16.74668,   inf] (27), [-16.74667,   inf] (35), [-16.74662,   inf] (47), [-16.74661,   inf] (25), [-16.74660,   inf] (25), [-16.74659,   inf] (25), [-16.74656,   inf] (27), [-16.74656,   inf] (37), [-16.74656,   inf] (23), [-16.74653,   inf] (33), [-16.74652,   inf] (29), [-16.74650,   inf] (27), [-16.74648,   inf] (25), [-16.74646,   inf] (37), [-16.74644,   inf] (23), [-16.74644,   inf] (45), [-16.74644,   inf] (49), 
length of domains: 70024
Total time: 3.3304	 pickout: 0.2394	 decision: 0.4312	 get_bound: 2.4596	 add_domain: 0.2002
Current lb:-16.74671745300293
139984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 278.09802746772766

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 46] [3, 37] [3, 2] [3, 41] [2, 63] [2, 65] [3, 41] [3, 37] [3, 37] [3, 27] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 30811.111328125 with beta sum per layer: [0.0, 0.0, 16.970909118652344, 2784.60986328125]
alpha/beta optimization time: 1.9515068531036377
This batch time : update_bounds func: 2.4504	 prepare: 0.2085	 bound: 1.9520	 transfer: 0.1117	 finalize: 0.1712
Accumulated time: update_bounds func: 198.1422	 prepare: 15.0091	 bound: 143.2083	 transfer: 0.1117	 finalize: 30.7482
batch bounding time:  2.453101873397827
Current worst splitting domains [lb, ub] (depth):
[-16.72560,   inf] (31), [-16.72558,   inf] (29), [-16.72555,   inf] (27), [-16.72551,   inf] (21), [-16.72548,   inf] (43), [-16.72543,   inf] (23), [-16.72542,   inf] (31), [-16.72541,   inf] (27), [-16.72540,   inf] (21), [-16.72539,   inf] (31), [-16.72537,   inf] (33), [-16.72537,   inf] (35), [-16.72530,   inf] (29), [-16.72529,   inf] (25), [-16.72523,   inf] (31), [-16.72523,   inf] (37), [-16.72522,   inf] (31), [-16.72522,   inf] (25), [-16.72521,   inf] (29), [-16.72518,   inf] (23), 
length of domains: 71024
Total time: 3.3451	 pickout: 0.2656	 decision: 0.4251	 get_bound: 2.4576	 add_domain: 0.1969
Current lb:-16.725595474243164
141984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 281.4793131351471

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 46] [3, 42] [3, 42] [3, 7] [2, 79] [3, 28] [3, 37] [3, 46] [3, 42] [3, 27] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 30773.44140625 with beta sum per layer: [0.0, 0.0, 16.215303421020508, 2814.3486328125]
alpha/beta optimization time: 1.9520153999328613
This batch time : update_bounds func: 2.4541	 prepare: 0.2059	 bound: 1.9524	 transfer: 0.1180	 finalize: 0.1708
Accumulated time: update_bounds func: 200.5963	 prepare: 15.2150	 bound: 145.1607	 transfer: 0.1180	 finalize: 30.9189
batch bounding time:  2.4568703174591064
Current worst splitting domains [lb, ub] (depth):
[-16.70443,   inf] (27), [-16.70442,   inf] (47), [-16.70442,   inf] (29), [-16.70433,   inf] (41), [-16.70428,   inf] (25), [-16.70426,   inf] (31), [-16.70423,   inf] (25), [-16.70423,   inf] (29), [-16.70420,   inf] (29), [-16.70420,   inf] (29), [-16.70417,   inf] (29), [-16.70415,   inf] (25), [-16.70415,   inf] (31), [-16.70413,   inf] (35), [-16.70409,   inf] (31), [-16.70408,   inf] (45), [-16.70408,   inf] (33), [-16.70408,   inf] (29), [-16.70403,   inf] (27), [-16.70403,   inf] (29), 
length of domains: 72024
Total time: 3.3310	 pickout: 0.2398	 decision: 0.4294	 get_bound: 2.4616	 add_domain: 0.2002
Current lb:-16.704431533813477
143984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 284.85076451301575

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 42] [3, 11] [3, 27] [2, 18] [3, 41] [3, 37] [3, 37] [3, 2] [3, 2] [3, 27] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 30737.890625 with beta sum per layer: [0.0, 0.0, 16.184906005859375, 2766.85595703125]
alpha/beta optimization time: 1.9627118110656738
This batch time : update_bounds func: 5.1148	 prepare: 0.2064	 bound: 1.9631	 transfer: 0.1210	 finalize: 2.8173
Accumulated time: update_bounds func: 205.7112	 prepare: 15.4213	 bound: 147.1238	 transfer: 0.1210	 finalize: 33.7362
batch bounding time:  5.117424964904785
Current worst splitting domains [lb, ub] (depth):
[-16.68415,   inf] (33), [-16.68413,   inf] (33), [-16.68412,   inf] (33), [-16.68410,   inf] (29), [-16.68409,   inf] (39), [-16.68408,   inf] (29), [-16.68408,   inf] (43), [-16.68407,   inf] (23), [-16.68406,   inf] (23), [-16.68406,   inf] (33), [-16.68402,   inf] (25), [-16.68400,   inf] (41), [-16.68398,   inf] (31), [-16.68396,   inf] (37), [-16.68395,   inf] (27), [-16.68395,   inf] (31), [-16.68394,   inf] (23), [-16.68394,   inf] (23), [-16.68394,   inf] (27), [-16.68393,   inf] (29), 
length of domains: 73024
Total time: 5.9949	 pickout: 0.2496	 decision: 0.4244	 get_bound: 5.1218	 add_domain: 0.1991
Current lb:-16.68415069580078
145984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 290.88199400901794

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 28] [3, 7] [3, 27] [3, 28] [2, 18] [3, 27] [2, 18] [3, 41] [3, 43] [3, 27] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 30722.17578125 with beta sum per layer: [0.0, 0.0, 14.950447082519531, 2823.406982421875]
alpha/beta optimization time: 1.9532744884490967
This batch time : update_bounds func: 2.4505	 prepare: 0.2042	 bound: 1.9537	 transfer: 0.1122	 finalize: 0.1731
Accumulated time: update_bounds func: 208.1616	 prepare: 15.6255	 bound: 149.0776	 transfer: 0.1122	 finalize: 33.9093
batch bounding time:  2.4530081748962402
Current worst splitting domains [lb, ub] (depth):
[-16.66293,   inf] (39), [-16.66290,   inf] (27), [-16.66288,   inf] (19), [-16.66285,   inf] (25), [-16.66282,   inf] (39), [-16.66281,   inf] (41), [-16.66280,   inf] (35), [-16.66280,   inf] (27), [-16.66276,   inf] (29), [-16.66267,   inf] (21), [-16.66265,   inf] (21), [-16.66261,   inf] (23), [-16.66250,   inf] (31), [-16.66245,   inf] (29), [-16.66242,   inf] (31), [-16.66241,   inf] (23), [-16.66239,   inf] (31), [-16.66238,   inf] (23), [-16.66237,   inf] (43), [-16.66233,   inf] (23), 
length of domains: 74024
Total time: 3.3311	 pickout: 0.2471	 decision: 0.4250	 get_bound: 2.4573	 add_domain: 0.2017
Current lb:-16.662931442260742
147984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 294.2498514652252

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 63] [3, 43] [3, 58] [3, 42] [3, 27] [2, 55] [3, 37] [3, 37] [3, 42] [3, 24] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 30691.66796875 with beta sum per layer: [0.0, 0.0, 16.535844802856445, 2827.60009765625]
alpha/beta optimization time: 1.9458131790161133
This batch time : update_bounds func: 2.4424	 prepare: 0.2048	 bound: 1.9462	 transfer: 0.1115	 finalize: 0.1729
Accumulated time: update_bounds func: 210.6041	 prepare: 15.8303	 bound: 151.0238	 transfer: 0.1115	 finalize: 34.0822
batch bounding time:  2.444974660873413
Current worst splitting domains [lb, ub] (depth):
[-16.64313,   inf] (33), [-16.64309,   inf] (27), [-16.64309,   inf] (23), [-16.64309,   inf] (31), [-16.64307,   inf] (27), [-16.64304,   inf] (31), [-16.64303,   inf] (33), [-16.64302,   inf] (25), [-16.64297,   inf] (33), [-16.64297,   inf] (39), [-16.64296,   inf] (47), [-16.64291,   inf] (25), [-16.64291,   inf] (21), [-16.64288,   inf] (33), [-16.64286,   inf] (35), [-16.64284,   inf] (27), [-16.64284,   inf] (43), [-16.64283,   inf] (39), [-16.64282,   inf] (35), [-16.64282,   inf] (45), 
length of domains: 75024
Total time: 3.3189	 pickout: 0.2457	 decision: 0.4242	 get_bound: 2.4492	 add_domain: 0.1998
Current lb:-16.64313316345215
149984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 297.6054813861847

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1000, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1000, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [3, 2] [3, 46] [3, 43] [3, 27] [3, 2] [3, 37] [3, 27] [3, 43] [3, 37] [2, 18] 
regular batch size: 2*1000, diving batch size 1*0
best_l after optimization: 30639.7265625 with beta sum per layer: [0.0, 0.0, 15.415212631225586, 2868.384765625]
alpha/beta optimization time: 1.9471843242645264
This batch time : update_bounds func: 2.4541	 prepare: 0.2044	 bound: 1.9476	 transfer: 0.1205	 finalize: 0.1743
Accumulated time: update_bounds func: 213.0581	 prepare: 16.0347	 bound: 152.9714	 transfer: 0.1205	 finalize: 34.2566
batch bounding time:  2.456768274307251
Current worst splitting domains [lb, ub] (depth):
[-16.62366,   inf] (37), [-16.62362,   inf] (37), [-16.62355,   inf] (29), [-16.62355,   inf] (29), [-16.62351,   inf] (25), [-16.62351,   inf] (35), [-16.62349,   inf] (37), [-16.62347,   inf] (23), [-16.62347,   inf] (25), [-16.62346,   inf] (33), [-16.62344,   inf] (21), [-16.62337,   inf] (35), [-16.62333,   inf] (27), [-16.62333,   inf] (23), [-16.62333,   inf] (29), [-16.62331,   inf] (45), [-16.62330,   inf] (41), [-16.62327,   inf] (39), [-16.62325,   inf] (29), [-16.62322,   inf] (35), 
length of domains: 76024
Total time: 3.3185	 pickout: 0.2354	 decision: 0.4251	 get_bound: 2.4613	 add_domain: 0.1966
Current lb:-16.623655319213867
151984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Time out!!!!!!!!
Image 0 against label 2 verification end, Time cost: 303.3045873641968/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:25: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1627336316785/work/torch/csrc/utils/tensor_numpy.cpp:143.)
  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))

Result: unknown in 319.2734 seconds


[[     0.            -16.62365532 151984.            303.30458736
       2.        ]]
############# Summary #############
Final verified acc: 0.0% [total 1 examples]
Total verification count: 1 , total verified safe: 0 , verified unsafe: 0 , timeout: 1
mean time [total:1]: 303.3045873641968
mean time [cnt:1]: 303.3045873641968
max time 319.27335262298584
unknown (total 1): [0]
