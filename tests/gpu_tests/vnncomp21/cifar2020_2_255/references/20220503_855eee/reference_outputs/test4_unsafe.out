Building native CUDA modules...
/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
  csv_name: cifar2020_instances.csv
  onnx_path: null
  vnnlib_path: null
  results_file: null
  root_path: ../../../../../vnncomp2021/benchmarks/cifar2020
model:
  path: null
  name: mnist_9_200
data:
  start: 0
  end: 1
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR
  data_filter_path: null
specification:
  type: lp
  norm: .inf
  epsilon: null
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 200
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.01
    lr_decay: 0.98
    optimizer: adam
    iteration: 50
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 360
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 10
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:42:48 2022 on ubuntu
saving results to vnn-comp_[cifar2020_instances]_start=0_end=1_iter=50_b=200_timeout=360_branching=kfsb-max-10_lra-init=0.1_lra=0.01_lrb=0.01_PGD=skip.npz
customized start/end sample from 0 to 1

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Model prediction is: tensor([[-0.6753, -1.5227,  0.6371,  4.4140,  0.7916,  3.9431,  1.3852, -1.2393,
         -1.2149, -1.9070]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 1.8647,  3.1596,  1.9843,  1.7047, -0.8076,  1.5215,  3.2766,  2.5574,
          3.5169]], device='cuda:0') None
best_l after optimization: -20.167646408081055 with beta sum per layer: []
alpha/beta optimization time: 11.983150959014893
initial alpha-CROWN bounds: tensor([[ 2.0843,  3.3533,  2.1228,  1.8125, -0.7145,  1.6210,  3.4252,  2.7657,
          3.6973]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.7145, device='cuda:0', grad_fn=<MinBackward1>)
##### [0] True label: 3, Tested against: 0, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_0_eps_0.00784_n1.vnnlib ######
init opt crown verified for label 0 with bound 2.0842792987823486
Image 0 against label 0 verification end, Time cost: 0.000301361083984375
##### [0] True label: 3, Tested against: 1, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_0_eps_0.00784_n1.vnnlib ######
init opt crown verified for label 1 with bound 3.3533027172088623
Image 0 against label 1 verification end, Time cost: 0.00031256675720214844
##### [0] True label: 3, Tested against: 2, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_0_eps_0.00784_n1.vnnlib ######
init opt crown verified for label 2 with bound 2.122831344604492
Image 0 against label 2 verification end, Time cost: 0.0003082752227783203
##### [0] True label: 3, Tested against: 4, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_0_eps_0.00784_n1.vnnlib ######
init opt crown verified for label 4 with bound 1.8124550580978394
Image 0 against label 4 verification end, Time cost: 0.0003027915954589844
##### [0] True label: 3, Tested against: 5, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_0_eps_0.00784_n1.vnnlib ######
Model prediction is: tensor([[-0.6753, -1.5227,  0.6371,  4.4140,  0.7916,  3.9431,  1.3852, -1.2393,
         -1.2149, -1.9070]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /12 start_node /13
setting alpha for layer /12 start_node /15
setting alpha for layer /12 start_node /18
not setting layer /12 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 32, 32, 32]) != torch.Size([2, 9, 1, 32, 32, 32]))
setting alpha for layer /14 start_node /15
setting alpha for layer /14 start_node /18
not setting layer /14 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /16 start_node /18
not setting layer /16 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /19 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /11 torch.Size([1, 32, 32, 32])
1 /13 torch.Size([1, 32, 16, 16])
2 /15 torch.Size([1, 128, 8, 8])
3 /18 torch.Size([1, 250])
best_l after optimization: 0.7144590616226196 with beta sum per layer: []
alpha/beta optimization time: 2.2990636825561523
alpha-CROWN with fixed intermediate bounds: tensor([[-0.7145]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.7144590616226196
layer 0 size torch.Size([32768]) unstable 1480
layer 1 size torch.Size([8192]) unstable 813
layer 2 size torch.Size([8192]) unstable 692
layer 3 size torch.Size([250]) unstable 56
-----------------
# of unstable neurons: 3041
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 32, 32]) pre split depth:  4
batch:  torch.Size([1, 32, 32, 32]) post split depth:  4
splitting decisions: 
split level 0: [3, 91] 
split level 1: [3, 55] 
split level 2: [3, 231] 
split level 3: [3, 12] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 3.530705451965332 with beta sum per layer: [0.0, 0.0, 0.0, 6.536750793457031]
alpha/beta optimization time: 0.7706019878387451
This batch time : update_bounds func: 0.7798	 prepare: 0.0030	 bound: 0.7712	 transfer: 0.0041	 finalize: 0.0014
Accumulated time: update_bounds func: 0.7798	 prepare: 0.0030	 bound: 0.7712	 transfer: 0.0041	 finalize: 0.0014
batch bounding time:  0.7799971103668213
Current worst splitting domains [lb, ub] (depth):
[-0.54936,   inf] (5), [-0.52933,   inf] (5), [-0.48761,   inf] (5), [-0.46326,   inf] (5), [-0.28965,   inf] (5), [-0.26806,   inf] (5), [-0.23043,   inf] (5), [-0.22463,   inf] (5), [-0.20461,   inf] (5), [-0.16112,   inf] (5), [-0.13744,   inf] (5), [-0.07254,   inf] (5), [-0.00658,   inf] (5), 
length of domains: 13
Total time: 0.8479	 pickout: 0.0013	 decision: 0.0638	 get_bound: 0.7821	 add_domain: 0.0006
Current lb:-0.5493568181991577
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.10474419593811

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([13, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([13, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 200] [3, 38] [3, 200] [3, 38] [3, 38] [3, 38] [3, 38] [3, 38] [3, 38] [3, 38] 
regular batch size: 2*13, diving batch size 1*0
best_l after optimization: 4.805257797241211 with beta sum per layer: [0.0, 0.0, 0.0, 21.050830841064453]
alpha/beta optimization time: 0.7502055168151855
This batch time : update_bounds func: 0.7690	 prepare: 0.0039	 bound: 0.7505	 transfer: 0.0123	 finalize: 0.0021
Accumulated time: update_bounds func: 1.5488	 prepare: 0.0070	 bound: 1.5217	 transfer: 0.0123	 finalize: 0.0035
batch bounding time:  0.7691788673400879
Current worst splitting domains [lb, ub] (depth):
[-0.54177,   inf] (7), [-0.50787,   inf] (7), [-0.47304,   inf] (7), [-0.44484,   inf] (7), [-0.44151,   inf] (7), [-0.43431,   inf] (7), [-0.37164,   inf] (7), [-0.36979,   inf] (7), [-0.21077,   inf] (7), [-0.19000,   inf] (7), [-0.14945,   inf] (7), [-0.13807,   inf] (7), [-0.13523,   inf] (7), [-0.11266,   inf] (7), [-0.11115,   inf] (7), [-0.07389,   inf] (7), [-0.07010,   inf] (7), [-0.06223,   inf] (7), [-0.05502,   inf] (7), [-0.03337,   inf] (7), 
length of domains: 20
Total time: 0.8622	 pickout: 0.0071	 decision: 0.0849	 get_bound: 0.7692	 add_domain: 0.0009
Current lb:-0.5417657494544983
42 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.9673755168914795

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([20, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([20, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 38] [3, 200] [3, 38] [3, 38] [3, 200] [3, 200] [3, 200] [3, 38] [3, 200] [3, 200] 
regular batch size: 2*20, diving batch size 1*0
best_l after optimization: 6.521389484405518 with beta sum per layer: [0.0, 0.0, 0.0, 46.97613525390625]
alpha/beta optimization time: 0.8435163497924805
This batch time : update_bounds func: 0.8728	 prepare: 0.0053	 bound: 0.8438	 transfer: 0.0206	 finalize: 0.0029
Accumulated time: update_bounds func: 2.4216	 prepare: 0.0123	 bound: 2.3655	 transfer: 0.0206	 finalize: 0.0064
batch bounding time:  0.8729727268218994
Current worst splitting domains [lb, ub] (depth):
[-0.51985,   inf] (9), [-0.50062,   inf] (9), [-0.45863,   inf] (9), [-0.44948,   inf] (9), [-0.42605,   inf] (9), [-0.42124,   inf] (9), [-0.40496,   inf] (9), [-0.39065,   inf] (9), [-0.38312,   inf] (9), [-0.35170,   inf] (9), [-0.32161,   inf] (9), [-0.31958,   inf] (9), [-0.31907,   inf] (9), [-0.30010,   inf] (9), [-0.24262,   inf] (9), [-0.24109,   inf] (9), [-0.15570,   inf] (9), [-0.13462,   inf] (9), [-0.09772,   inf] (9), [-0.07323,   inf] (9), 
length of domains: 26
Total time: 0.9867	 pickout: 0.0107	 decision: 0.1015	 get_bound: 0.8731	 add_domain: 0.0013
Current lb:-0.5198540091514587
82 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.954635381698608

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([26, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([26, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3] [3, 3] [3, 3] [3, 3] [3, 3] [3, 3] [3, 3] [3, 3] [3, 3] [3, 227] 
regular batch size: 2*26, diving batch size 1*0
best_l after optimization: 9.613746643066406 with beta sum per layer: [0.0, 0.0, 0.0, 72.35865783691406]
alpha/beta optimization time: 0.9140989780426025
This batch time : update_bounds func: 0.9555	 prepare: 0.0064	 bound: 0.9144	 transfer: 0.0305	 finalize: 0.0041
Accumulated time: update_bounds func: 3.3771	 prepare: 0.0186	 bound: 3.2800	 transfer: 0.0305	 finalize: 0.0105
batch bounding time:  0.9557740688323975
Current worst splitting domains [lb, ub] (depth):
[-0.51518,   inf] (11), [-0.49581,   inf] (11), [-0.44450,   inf] (11), [-0.44299,   inf] (11), [-0.42072,   inf] (11), [-0.41409,   inf] (11), [-0.41248,   inf] (11), [-0.39785,   inf] (11), [-0.37455,   inf] (11), [-0.35980,   inf] (11), [-0.34657,   inf] (11), [-0.34171,   inf] (11), [-0.33228,   inf] (11), [-0.32752,   inf] (11), [-0.32350,   inf] (11), [-0.30980,   inf] (11), [-0.27983,   inf] (11), [-0.26852,   inf] (11), [-0.26796,   inf] (11), [-0.26584,   inf] (11), 
length of domains: 37
Total time: 1.0837	 pickout: 0.0136	 decision: 0.1121	 get_bound: 0.9559	 add_domain: 0.0020
Current lb:-0.5151785612106323
134 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.039177417755127

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([37, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([37, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 227] [3, 227] [3, 227] [3, 227] [3, 227] [3, 227] [3, 227] [3, 227] [3, 227] [3, 227] 
regular batch size: 2*37, diving batch size 1*0
best_l after optimization: 13.681278228759766 with beta sum per layer: [0.0, 0.0, 0.0, 130.05001831054688]
alpha/beta optimization time: 1.0670228004455566
This batch time : update_bounds func: 1.1172	 prepare: 0.0085	 bound: 1.0673	 transfer: 0.0358	 finalize: 0.0054
Accumulated time: update_bounds func: 4.4943	 prepare: 0.0271	 bound: 4.3473	 transfer: 0.0358	 finalize: 0.0159
batch bounding time:  1.1174957752227783
Current worst splitting domains [lb, ub] (depth):
[-0.49449,   inf] (13), [-0.47421,   inf] (13), [-0.45962,   inf] (13), [-0.44566,   inf] (13), [-0.42498,   inf] (13), [-0.42070,   inf] (13), [-0.39992,   inf] (13), [-0.39193,   inf] (13), [-0.38125,   inf] (13), [-0.37431,   inf] (13), [-0.36362,   inf] (13), [-0.35646,   inf] (13), [-0.35228,   inf] (13), [-0.33333,   inf] (13), [-0.32179,   inf] (13), [-0.32151,   inf] (13), [-0.30668,   inf] (13), [-0.30618,   inf] (13), [-0.30163,   inf] (13), [-0.29932,   inf] (13), 
length of domains: 62
Total time: 1.2785	 pickout: 0.0223	 decision: 0.1354	 get_bound: 1.1176	 add_domain: 0.0032
Current lb:-0.494492769241333
208 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.318589687347412

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([62, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([62, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 133] [2, 4755] [3, 133] [3, 133] [2, 4755] [3, 133] [2, 1106] [2, 4755] [2, 4755] [3, 133] 
regular batch size: 2*62, diving batch size 1*0
best_l after optimization: 19.336135864257812 with beta sum per layer: [0.0, 0.0, 11.902170181274414, 251.45864868164062]
alpha/beta optimization time: 1.4545085430145264
This batch time : update_bounds func: 1.5343	 prepare: 0.0136	 bound: 1.4548	 transfer: 0.0566	 finalize: 0.0089
Accumulated time: update_bounds func: 6.0286	 prepare: 0.0407	 bound: 5.8021	 transfer: 0.0566	 finalize: 0.0248
batch bounding time:  1.5346357822418213
Current worst splitting domains [lb, ub] (depth):
[-0.49120,   inf] (15), [-0.47252,   inf] (15), [-0.45231,   inf] (15), [-0.44023,   inf] (15), [-0.42343,   inf] (15), [-0.41743,   inf] (15), [-0.41627,   inf] (15), [-0.39260,   inf] (15), [-0.38969,   inf] (15), [-0.37332,   inf] (15), [-0.37177,   inf] (15), [-0.36181,   inf] (15), [-0.35949,   inf] (15), [-0.35764,   inf] (15), [-0.35664,   inf] (15), [-0.34936,   inf] (15), [-0.34896,   inf] (15), [-0.32796,   inf] (15), [-0.32060,   inf] (15), [-0.31981,   inf] (15), 
length of domains: 99
Total time: 1.7881	 pickout: 0.0324	 decision: 0.2148	 get_bound: 1.5349	 add_domain: 0.0060
Current lb:-0.4911975860595703
332 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.10823941230774

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([99, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([99, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 4755] [2, 1106] [2, 4755] [2, 4755] [3, 114] [2, 1106] [2, 4755] [2, 4755] [2, 1106] [3, 114] 
regular batch size: 2*99, diving batch size 1*0
best_l after optimization: 27.573318481445312 with beta sum per layer: [0.0, 0.0, 57.58583068847656, 433.104248046875]
alpha/beta optimization time: 2.12357234954834
This batch time : update_bounds func: 2.2610	 prepare: 0.0220	 bound: 2.1239	 transfer: 0.0998	 finalize: 0.0147
Accumulated time: update_bounds func: 8.2896	 prepare: 0.0627	 bound: 7.9261	 transfer: 0.0998	 finalize: 0.0395
batch bounding time:  2.2614247798919678
Current worst splitting domains [lb, ub] (depth):
[-0.48969,   inf] (17), [-0.46715,   inf] (17), [-0.44994,   inf] (17), [-0.43939,   inf] (17), [-0.43802,   inf] (17), [-0.43780,   inf] (17), [-0.41465,   inf] (17), [-0.41421,   inf] (17), [-0.39721,   inf] (17), [-0.39564,   inf] (17), [-0.39086,   inf] (17), [-0.38286,   inf] (17), [-0.38178,   inf] (17), [-0.36336,   inf] (17), [-0.36000,   inf] (17), [-0.35931,   inf] (17), [-0.35711,   inf] (17), [-0.35676,   inf] (17), [-0.35533,   inf] (17), [-0.35530,   inf] (17), 
length of domains: 160
Total time: 2.6336	 pickout: 0.0513	 decision: 0.3113	 get_bound: 2.2618	 add_domain: 0.0092
Current lb:-0.4896864891052246
530 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.744444131851196

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([160, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([160, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 114] [3, 133] [3, 114] [3, 114] [2, 1106] [3, 133] [3, 47] [3, 114] [3, 114] [3, 133] 
regular batch size: 2*160, diving batch size 1*0
best_l after optimization: 38.306007385253906 with beta sum per layer: [0.0, 0.0, 137.04188537597656, 746.6290283203125]
alpha/beta optimization time: 3.1138744354248047
This batch time : update_bounds func: 3.3362	 prepare: 0.0355	 bound: 3.1142	 transfer: 0.1617	 finalize: 0.0240
Accumulated time: update_bounds func: 11.6258	 prepare: 0.0982	 bound: 11.0403	 transfer: 0.1617	 finalize: 0.0635
batch bounding time:  3.3367443084716797
Current worst splitting domains [lb, ub] (depth):
[-0.48081,   inf] (19), [-0.46397,   inf] (19), [-0.44025,   inf] (19), [-0.43377,   inf] (19), [-0.43128,   inf] (19), [-0.42750,   inf] (19), [-0.41387,   inf] (19), [-0.40642,   inf] (19), [-0.40480,   inf] (19), [-0.40469,   inf] (19), [-0.39068,   inf] (19), [-0.38177,   inf] (19), [-0.37892,   inf] (19), [-0.37330,   inf] (19), [-0.36897,   inf] (19), [-0.36473,   inf] (19), [-0.36107,   inf] (19), [-0.35712,   inf] (19), [-0.35635,   inf] (19), [-0.35014,   inf] (19), 
length of domains: 236
Total time: 3.9867	 pickout: 0.0882	 decision: 0.5471	 get_bound: 3.3373	 add_domain: 0.0141
Current lb:-0.480806827545166
850 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.738406896591187

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 47] [3, 47] [3, 47] [3, 47] [3, 47] [3, 47] [3, 47] [3, 47] [2, 6435] [3, 47] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 53.12299346923828 with beta sum per layer: [0.0, 0.0, 235.12159729003906, 907.741455078125]
alpha/beta optimization time: 3.9502131938934326
This batch time : update_bounds func: 4.2651	 prepare: 0.0443	 bound: 3.9506	 transfer: 0.2407	 finalize: 0.0284
Accumulated time: update_bounds func: 15.8908	 prepare: 0.1425	 bound: 14.9909	 transfer: 0.2407	 finalize: 0.0919
batch bounding time:  4.26571798324585
Current worst splitting domains [lb, ub] (depth):
[-0.47072,   inf] (21), [-0.45460,   inf] (21), [-0.43411,   inf] (21), [-0.43066,   inf] (21), [-0.42418,   inf] (21), [-0.42234,   inf] (21), [-0.40837,   inf] (21), [-0.39827,   inf] (21), [-0.39687,   inf] (21), [-0.39453,   inf] (21), [-0.39214,   inf] (21), [-0.39183,   inf] (21), [-0.38683,   inf] (21), [-0.38328,   inf] (21), [-0.37807,   inf] (21), [-0.37216,   inf] (21), [-0.37035,   inf] (21), [-0.36974,   inf] (21), [-0.36013,   inf] (21), [-0.35962,   inf] (21), 
length of domains: 374
Total time: 5.0332	 pickout: 0.1041	 decision: 0.5923	 get_bound: 4.2664	 add_domain: 0.0703
Current lb:-0.4707205295562744
1250 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 21.776241779327393

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 6435] [2, 6435] [2, 6435] [2, 6435] [2, 6435] [3, 114] [2, 6435] [3, 133] [3, 114] [2, 6435] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 71.51504516601562 with beta sum per layer: [0.0, 0.0, 278.2972412109375, 793.2044677734375]
alpha/beta optimization time: 3.9521608352661133
This batch time : update_bounds func: 4.2831	 prepare: 0.0448	 bound: 3.9526	 transfer: 0.2527	 finalize: 0.0320
Accumulated time: update_bounds func: 20.1740	 prepare: 0.1873	 bound: 18.9435	 transfer: 0.2527	 finalize: 0.1239
batch bounding time:  4.28386116027832
Current worst splitting domains [lb, ub] (depth):
[-0.46582,   inf] (23), [-0.45075,   inf] (23), [-0.44053,   inf] (23), [-0.42515,   inf] (23), [-0.42021,   inf] (23), [-0.41613,   inf] (23), [-0.41554,   inf] (23), [-0.41261,   inf] (23), [-0.40058,   inf] (23), [-0.39432,   inf] (23), [-0.39082,   inf] (23), [-0.38903,   inf] (23), [-0.38667,   inf] (23), [-0.38663,   inf] (23), [-0.38660,   inf] (23), [-0.37991,   inf] (23), [-0.37862,   inf] (23), [-0.37858,   inf] (23), [-0.36861,   inf] (23), [-0.36815,   inf] (23), 
length of domains: 570
Total time: 5.0452	 pickout: 0.1438	 decision: 0.5901	 get_bound: 4.2846	 add_domain: 0.0268
Current lb:-0.46582111716270447
1650 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 26.827170372009277

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 4] [3, 114] [3, 4] [3, 4] [3, 114] [3, 114] [3, 4] [2, 6435] [3, 4] [3, 4] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 92.62515258789062 with beta sum per layer: [0.0, 0.0, 327.6563720703125, 658.1287841796875]
alpha/beta optimization time: 3.9492931365966797
This batch time : update_bounds func: 4.2712	 prepare: 0.0441	 bound: 3.9497	 transfer: 0.2467	 finalize: 0.0297
Accumulated time: update_bounds func: 24.4451	 prepare: 0.2314	 bound: 22.8932	 transfer: 0.2467	 finalize: 0.1535
batch bounding time:  4.2718117237091064
Current worst splitting domains [lb, ub] (depth):
[-0.44899,   inf] (25), [-0.44778,   inf] (25), [-0.44160,   inf] (25), [-0.42129,   inf] (25), [-0.42032,   inf] (25), [-0.41076,   inf] (25), [-0.40822,   inf] (25), [-0.40821,   inf] (25), [-0.40721,   inf] (25), [-0.40216,   inf] (25), [-0.39350,   inf] (25), [-0.39216,   inf] (25), [-0.38765,   inf] (25), [-0.38223,   inf] (25), [-0.38052,   inf] (25), [-0.37964,   inf] (25), [-0.37751,   inf] (25), [-0.37633,   inf] (25), [-0.37600,   inf] (25), [-0.37362,   inf] (25), 
length of domains: 770
Total time: 5.0831	 pickout: 0.1257	 decision: 0.6570	 get_bound: 4.2725	 add_domain: 0.0279
Current lb:-0.4489903450012207
2050 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 31.914708137512207

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 44] [3, 44] [3, 4] [3, 44] [3, 44] [3, 4] [3, 4] [3, 44] [3, 44] [3, 4] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 109.0829086303711 with beta sum per layer: [0.0, 0.0, 283.66815185546875, 553.174072265625]
alpha/beta optimization time: 3.946049690246582
This batch time : update_bounds func: 4.2695	 prepare: 0.0441	 bound: 3.9465	 transfer: 0.2481	 finalize: 0.0299
Accumulated time: update_bounds func: 28.7147	 prepare: 0.2755	 bound: 26.8397	 transfer: 0.2481	 finalize: 0.1834
batch bounding time:  4.270206928253174
Current worst splitting domains [lb, ub] (depth):
[-0.43270,   inf] (27), [-0.43185,   inf] (27), [-0.43149,   inf] (27), [-0.43055,   inf] (27), [-0.42457,   inf] (27), [-0.42347,   inf] (27), [-0.40478,   inf] (27), [-0.40384,   inf] (27), [-0.40233,   inf] (27), [-0.40126,   inf] (27), [-0.39403,   inf] (27), [-0.39240,   inf] (27), [-0.39239,   inf] (27), [-0.39142,   inf] (27), [-0.39136,   inf] (27), [-0.39021,   inf] (27), [-0.38998,   inf] (27), [-0.38907,   inf] (27), [-0.38392,   inf] (27), [-0.38288,   inf] (27), 
length of domains: 970
Total time: 5.0685	 pickout: 0.1194	 decision: 0.6480	 get_bound: 4.2709	 add_domain: 0.0302
Current lb:-0.43269777297973633
2450 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 36.98783254623413

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5069] [2, 5069] [2, 5069] [2, 5069] [3, 44] [3, 44] [2, 5069] [2, 5069] [2, 5069] [2, 5069] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 117.80172729492188 with beta sum per layer: [0.0, 0.0, 196.46749877929688, 471.2549133300781]
alpha/beta optimization time: 3.9464025497436523
This batch time : update_bounds func: 4.2708	 prepare: 0.0443	 bound: 3.9468	 transfer: 0.2496	 finalize: 0.0291
Accumulated time: update_bounds func: 32.9854	 prepare: 0.3198	 bound: 30.7865	 transfer: 0.2496	 finalize: 0.2125
batch bounding time:  4.271432638168335
Current worst splitting domains [lb, ub] (depth):
[-0.43037,   inf] (29), [-0.42948,   inf] (29), [-0.42916,   inf] (29), [-0.42820,   inf] (29), [-0.40859,   inf] (29), [-0.40846,   inf] (29), [-0.40748,   inf] (29), [-0.40743,   inf] (29), [-0.40729,   inf] (29), [-0.40673,   inf] (29), [-0.40619,   inf] (29), [-0.40583,   inf] (29), [-0.40216,   inf] (29), [-0.40125,   inf] (29), [-0.39962,   inf] (29), [-0.39860,   inf] (29), [-0.38958,   inf] (29), [-0.38776,   inf] (29), [-0.38642,   inf] (29), [-0.38532,   inf] (29), 
length of domains: 1170
Total time: 5.0676	 pickout: 0.1152	 decision: 0.5882	 get_bound: 4.2722	 add_domain: 0.0921
Current lb:-0.4303722381591797
2850 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 42.060112953186035

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 225] [3, 225] [3, 225] [3, 225] [3, 225] [3, 225] [3, 225] [3, 225] [3, 225] [3, 225] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 120.07723236083984 with beta sum per layer: [0.0, 0.0, 201.8209228515625, 371.11346435546875]
alpha/beta optimization time: 3.938422918319702
This batch time : update_bounds func: 4.2621	 prepare: 0.0447	 bound: 3.9388	 transfer: 0.2484	 finalize: 0.0292
Accumulated time: update_bounds func: 37.2476	 prepare: 0.3644	 bound: 34.7253	 transfer: 0.2484	 finalize: 0.2417
batch bounding time:  4.2628138065338135
Current worst splitting domains [lb, ub] (depth):
[-0.42659,   inf] (31), [-0.42574,   inf] (31), [-0.42544,   inf] (31), [-0.42452,   inf] (31), [-0.40492,   inf] (31), [-0.40376,   inf] (31), [-0.40305,   inf] (31), [-0.40214,   inf] (31), [-0.40162,   inf] (31), [-0.40081,   inf] (31), [-0.40034,   inf] (31), [-0.39936,   inf] (31), [-0.39844,   inf] (31), [-0.39758,   inf] (31), [-0.39591,   inf] (31), [-0.39493,   inf] (31), [-0.38588,   inf] (31), [-0.38494,   inf] (31), [-0.38351,   inf] (31), [-0.38241,   inf] (31), 
length of domains: 1370
Total time: 5.0061	 pickout: 0.1196	 decision: 0.5899	 get_bound: 4.2636	 add_domain: 0.0331
Current lb:-0.4265930652618408
3250 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 47.071271657943726

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 1106] [2, 1106] [2, 1106] [2, 1106] [2, 4747] [2, 4747] [2, 4747] [2, 4747] [2, 1106] [2, 1106] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 127.71190643310547 with beta sum per layer: [0.0, 0.0, 217.31857299804688, 282.69476318359375]
alpha/beta optimization time: 3.9366838932037354
This batch time : update_bounds func: 4.2614	 prepare: 0.0438	 bound: 3.9371	 transfer: 0.2494	 finalize: 0.0301
Accumulated time: update_bounds func: 41.5090	 prepare: 0.4083	 bound: 38.6624	 transfer: 0.2494	 finalize: 0.2718
batch bounding time:  4.262123346328735
Current worst splitting domains [lb, ub] (depth):
[-0.42232,   inf] (33), [-0.42150,   inf] (33), [-0.42124,   inf] (33), [-0.42029,   inf] (33), [-0.41245,   inf] (33), [-0.41133,   inf] (33), [-0.40867,   inf] (33), [-0.40747,   inf] (33), [-0.39872,   inf] (33), [-0.39740,   inf] (33), [-0.39667,   inf] (33), [-0.39594,   inf] (33), [-0.39576,   inf] (33), [-0.39526,   inf] (33), [-0.39463,   inf] (33), [-0.39404,   inf] (33), [-0.39377,   inf] (33), [-0.39327,   inf] (33), [-0.39157,   inf] (33), [-0.39053,   inf] (33), 
length of domains: 1570
Total time: 5.0680	 pickout: 0.1176	 decision: 0.6535	 get_bound: 4.2628	 add_domain: 0.0341
Current lb:-0.4223201274871826
3650 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 52.145378828048706

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 6426] [2, 6426] [2, 4747] [2, 4747] [2, 6426] [2, 6426] [2, 6426] [2, 6426] [3, 192] [3, 192] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 133.88409423828125 with beta sum per layer: [0.0, 0.0, 214.16653442382812, 237.17486572265625]
alpha/beta optimization time: 3.9390745162963867
This batch time : update_bounds func: 4.3374	 prepare: 0.0451	 bound: 3.9395	 transfer: 0.2509	 finalize: 0.1007
Accumulated time: update_bounds func: 45.8463	 prepare: 0.4534	 bound: 42.6019	 transfer: 0.2509	 finalize: 0.3726
batch bounding time:  4.338131904602051
Current worst splitting domains [lb, ub] (depth):
[-0.41547,   inf] (35), [-0.41516,   inf] (35), [-0.41465,   inf] (35), [-0.41403,   inf] (35), [-0.41076,   inf] (35), [-0.41012,   inf] (35), [-0.40970,   inf] (35), [-0.40891,   inf] (35), [-0.40531,   inf] (35), [-0.40411,   inf] (35), [-0.40145,   inf] (35), [-0.40020,   inf] (35), [-0.39975,   inf] (35), [-0.39879,   inf] (35), [-0.39678,   inf] (35), [-0.39578,   inf] (35), [-0.39140,   inf] (35), [-0.39004,   inf] (35), [-0.38937,   inf] (35), [-0.38866,   inf] (35), 
length of domains: 1770
Total time: 5.0873	 pickout: 0.1200	 decision: 0.5923	 get_bound: 4.3389	 add_domain: 0.0360
Current lb:-0.4154665470123291
4050 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 57.23776912689209

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 60] [3, 60] [3, 60] [3, 60] [3, 60] [3, 60] [3, 60] [3, 60] [3, 60] [3, 60] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 132.613525390625 with beta sum per layer: [0.0, 0.0, 194.63595581054688, 204.72532653808594]
alpha/beta optimization time: 3.939678192138672
This batch time : update_bounds func: 4.2779	 prepare: 0.0452	 bound: 3.9402	 transfer: 0.2603	 finalize: 0.0312
Accumulated time: update_bounds func: 50.1242	 prepare: 0.4986	 bound: 46.5421	 transfer: 0.2603	 finalize: 0.4038
batch bounding time:  4.278519630432129
Current worst splitting domains [lb, ub] (depth):
[-0.41282,   inf] (37), [-0.41249,   inf] (37), [-0.41199,   inf] (37), [-0.41136,   inf] (37), [-0.40803,   inf] (37), [-0.40735,   inf] (37), [-0.40694,   inf] (37), [-0.40623,   inf] (37), [-0.40250,   inf] (37), [-0.40129,   inf] (37), [-0.39866,   inf] (37), [-0.39739,   inf] (37), [-0.39681,   inf] (37), [-0.39584,   inf] (37), [-0.39385,   inf] (37), [-0.39291,   inf] (37), [-0.38871,   inf] (37), [-0.38734,   inf] (37), [-0.38669,   inf] (37), [-0.38593,   inf] (37), 
length of domains: 1970
Total time: 5.0256	 pickout: 0.1194	 decision: 0.5912	 get_bound: 4.2792	 add_domain: 0.0358
Current lb:-0.41282129287719727
4450 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 62.268754959106445

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 4747] [2, 6426] [2, 4747] [2, 6426] [2, 4747] [2, 4747] [2, 6426] [2, 6426] [3, 66] [3, 192] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 135.634521484375 with beta sum per layer: [0.0, 0.0, 207.68142700195312, 176.7617950439453]
alpha/beta optimization time: 3.9328417778015137
This batch time : update_bounds func: 4.2496	 prepare: 0.0452	 bound: 3.9333	 transfer: 0.2399	 finalize: 0.0303
Accumulated time: update_bounds func: 54.3738	 prepare: 0.5438	 bound: 50.4754	 transfer: 0.2399	 finalize: 0.4340
batch bounding time:  4.250339984893799
Current worst splitting domains [lb, ub] (depth):
[-0.40668,   inf] (39), [-0.40574,   inf] (39), [-0.40555,   inf] (39), [-0.40442,   inf] (39), [-0.40169,   inf] (39), [-0.40167,   inf] (39), [-0.40131,   inf] (39), [-0.40110,   inf] (39), [-0.40088,   inf] (39), [-0.40042,   inf] (39), [-0.39991,   inf] (39), [-0.39919,   inf] (39), [-0.39725,   inf] (39), [-0.39673,   inf] (39), [-0.39629,   inf] (39), [-0.39574,   inf] (39), [-0.39539,   inf] (39), [-0.39382,   inf] (39), [-0.39148,   inf] (39), [-0.38981,   inf] (39), 
length of domains: 2170
Total time: 5.0816	 pickout: 0.1300	 decision: 0.6621	 get_bound: 4.2511	 add_domain: 0.0385
Current lb:-0.4066812992095947
4850 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 67.35674738883972

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 66] [3, 66] [3, 66] [3, 192] [3, 66] [3, 192] [3, 192] [3, 192] [3, 192] [3, 192] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 140.35787963867188 with beta sum per layer: [0.0, 0.0, 221.1934814453125, 123.63478088378906]
alpha/beta optimization time: 3.9349470138549805
This batch time : update_bounds func: 4.3686	 prepare: 0.0452	 bound: 3.9354	 transfer: 0.2493	 finalize: 0.1376
Accumulated time: update_bounds func: 58.7424	 prepare: 0.5890	 bound: 54.4108	 transfer: 0.2493	 finalize: 0.5716
batch bounding time:  4.369280576705933
Current worst splitting domains [lb, ub] (depth):
[-0.39959,   inf] (41), [-0.39865,   inf] (41), [-0.39854,   inf] (41), [-0.39696,   inf] (41), [-0.39454,   inf] (41), [-0.39429,   inf] (41), [-0.39385,   inf] (41), [-0.39359,   inf] (41), [-0.39353,   inf] (41), [-0.39298,   inf] (41), [-0.39289,   inf] (41), [-0.39165,   inf] (41), [-0.38975,   inf] (41), [-0.38931,   inf] (41), [-0.38882,   inf] (41), [-0.38878,   inf] (41), [-0.38829,   inf] (41), [-0.38828,   inf] (41), [-0.38823,   inf] (41), [-0.38815,   inf] (41), 
length of domains: 2370
Total time: 5.1423	 pickout: 0.1420	 decision: 0.5913	 get_bound: 4.3700	 add_domain: 0.0390
Current lb:-0.39958977699279785
5250 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 72.5047128200531

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 192] [3, 192] [3, 192] [3, 66] [3, 192] [3, 66] [3, 66] [3, 66] [3, 66] [3, 66] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 141.9822235107422 with beta sum per layer: [0.0, 0.0, 170.8792724609375, 117.06674194335938]
alpha/beta optimization time: 3.934248447418213
This batch time : update_bounds func: 4.2435	 prepare: 0.0452	 bound: 3.9347	 transfer: 0.2333	 finalize: 0.0293
Accumulated time: update_bounds func: 62.9859	 prepare: 0.6342	 bound: 58.3454	 transfer: 0.2333	 finalize: 0.6009
batch bounding time:  4.244276285171509
Current worst splitting domains [lb, ub] (depth):
[-0.39214,   inf] (43), [-0.39125,   inf] (43), [-0.39106,   inf] (43), [-0.38985,   inf] (43), [-0.38795,   inf] (43), [-0.38746,   inf] (43), [-0.38723,   inf] (43), [-0.38713,   inf] (43), [-0.38700,   inf] (43), [-0.38671,   inf] (43), [-0.38659,   inf] (43), [-0.38644,   inf] (43), [-0.38638,   inf] (43), [-0.38575,   inf] (43), [-0.38537,   inf] (43), [-0.38534,   inf] (43), [-0.38453,   inf] (43), [-0.38342,   inf] (43), [-0.38288,   inf] (43), [-0.38253,   inf] (43), 
length of domains: 2570
Total time: 4.9952	 pickout: 0.1177	 decision: 0.5916	 get_bound: 4.2450	 add_domain: 0.0409
Current lb:-0.3921356201171875
5650 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 77.50556349754333

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 4677] [2, 4677] [2, 4678] [2, 4677] [3, 192] [3, 192] [3, 192] [2, 4678] [2, 4678] [2, 4678] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 142.6990966796875 with beta sum per layer: [0.0, 0.0, 148.35096740722656, 101.00881958007812]
alpha/beta optimization time: 3.939993143081665
This batch time : update_bounds func: 4.2528	 prepare: 0.0454	 bound: 3.9404	 transfer: 0.2350	 finalize: 0.0310
Accumulated time: update_bounds func: 67.2388	 prepare: 0.6796	 bound: 62.2859	 transfer: 0.2350	 finalize: 0.6320
batch bounding time:  4.253483057022095
Current worst splitting domains [lb, ub] (depth):
[-0.39011,   inf] (45), [-0.38973,   inf] (45), [-0.38921,   inf] (45), [-0.38782,   inf] (45), [-0.38579,   inf] (45), [-0.38564,   inf] (45), [-0.38539,   inf] (45), [-0.38445,   inf] (45), [-0.38440,   inf] (45), [-0.38436,   inf] (45), [-0.38434,   inf] (45), [-0.38402,   inf] (45), [-0.38325,   inf] (45), [-0.38318,   inf] (45), [-0.38118,   inf] (45), [-0.38072,   inf] (45), [-0.38026,   inf] (45), [-0.38021,   inf] (45), [-0.37998,   inf] (45), [-0.37992,   inf] (45), 
length of domains: 2770
Total time: 5.1186	 pickout: 0.1344	 decision: 0.6897	 get_bound: 4.2542	 add_domain: 0.0403
Current lb:-0.3901064395904541
6050 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 82.62993884086609

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 4678] [2, 4677] [2, 4678] [2, 4678] [2, 4677] [2, 4677] [2, 4677] [2, 4747] [2, 4677] [2, 4678] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 142.8006591796875 with beta sum per layer: [0.0, 0.0, 146.1242218017578, 101.03880310058594]
alpha/beta optimization time: 3.9436874389648438
This batch time : update_bounds func: 4.2532	 prepare: 0.0455	 bound: 3.9441	 transfer: 0.2320	 finalize: 0.0305
Accumulated time: update_bounds func: 71.4920	 prepare: 0.7251	 bound: 66.2300	 transfer: 0.2320	 finalize: 0.6625
batch bounding time:  4.253904342651367
Current worst splitting domains [lb, ub] (depth):
[-0.38868,   inf] (47), [-0.38778,   inf] (47), [-0.38766,   inf] (47), [-0.38642,   inf] (47), [-0.38370,   inf] (47), [-0.38351,   inf] (47), [-0.38330,   inf] (47), [-0.38294,   inf] (47), [-0.38292,   inf] (47), [-0.38231,   inf] (47), [-0.38190,   inf] (47), [-0.38106,   inf] (47), [-0.37903,   inf] (47), [-0.37860,   inf] (47), [-0.37829,   inf] (47), [-0.37820,   inf] (47), [-0.37813,   inf] (47), [-0.37790,   inf] (47), [-0.37785,   inf] (47), [-0.37749,   inf] (47), 
length of domains: 2970
Total time: 5.0370	 pickout: 0.1459	 decision: 0.5948	 get_bound: 4.2546	 add_domain: 0.0417
Current lb:-0.3886847496032715
6450 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 87.67276501655579

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 188] [3, 188] [3, 188] [3, 188] [3, 188] [3, 188] [3, 188] [3, 188] [3, 188] [3, 188] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 138.294189453125 with beta sum per layer: [0.0, 0.0, 125.12348937988281, 131.92755126953125]
alpha/beta optimization time: 3.9461066722869873
This batch time : update_bounds func: 4.2660	 prepare: 0.0456	 bound: 3.9466	 transfer: 0.2420	 finalize: 0.0307
Accumulated time: update_bounds func: 75.7580	 prepare: 0.7707	 bound: 70.1765	 transfer: 0.2420	 finalize: 0.6932
batch bounding time:  4.266818046569824
Current worst splitting domains [lb, ub] (depth):
[-0.38578,   inf] (49), [-0.38489,   inf] (49), [-0.38478,   inf] (49), [-0.38355,   inf] (49), [-0.38073,   inf] (49), [-0.38061,   inf] (49), [-0.38036,   inf] (49), [-0.38005,   inf] (49), [-0.38000,   inf] (49), [-0.37939,   inf] (49), [-0.37904,   inf] (49), [-0.37821,   inf] (49), [-0.37632,   inf] (49), [-0.37609,   inf] (49), [-0.37590,   inf] (49), [-0.37567,   inf] (49), [-0.37546,   inf] (49), [-0.37524,   inf] (49), [-0.37521,   inf] (49), [-0.37501,   inf] (49), 
length of domains: 3170
Total time: 5.1256	 pickout: 0.1196	 decision: 0.6938	 get_bound: 4.2675	 add_domain: 0.0447
Current lb:-0.38578128814697266
6850 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 92.80616521835327

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 1762] [2, 1762] [2, 1762] [2, 1762] [2, 4690] [2, 1762] [2, 1762] [2, 1762] [2, 4690] [2, 1113] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 140.25100708007812 with beta sum per layer: [0.0, 0.0, 119.4509048461914, 108.10254669189453]
alpha/beta optimization time: 3.92596697807312
This batch time : update_bounds func: 4.2465	 prepare: 0.0458	 bound: 3.9264	 transfer: 0.2430	 finalize: 0.0302
Accumulated time: update_bounds func: 80.0045	 prepare: 0.8165	 bound: 74.1030	 transfer: 0.2430	 finalize: 0.7234
batch bounding time:  4.247235536575317
Current worst splitting domains [lb, ub] (depth):
[-0.38148,   inf] (51), [-0.38052,   inf] (51), [-0.38033,   inf] (51), [-0.37897,   inf] (51), [-0.37647,   inf] (51), [-0.37629,   inf] (51), [-0.37602,   inf] (51), [-0.37597,   inf] (51), [-0.37571,   inf] (51), [-0.37569,   inf] (51), [-0.37536,   inf] (51), [-0.37479,   inf] (51), [-0.37456,   inf] (51), [-0.37398,   inf] (51), [-0.37367,   inf] (51), [-0.37330,   inf] (51), [-0.37308,   inf] (51), [-0.37287,   inf] (51), [-0.37277,   inf] (51), [-0.37246,   inf] (51), 
length of domains: 3370
Total time: 5.1446	 pickout: 0.1335	 decision: 0.5917	 get_bound: 4.2480	 add_domain: 0.1714
Current lb:-0.3814809322357178
7250 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 97.95649361610413

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 4690] [2, 4690] [2, 1113] [2, 1113] [2, 4690] [2, 4690] [2, 1762] [2, 1113] [2, 4690] [2, 4690] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 142.34120178222656 with beta sum per layer: [0.0, 0.0, 114.7246322631836, 78.93193817138672]
alpha/beta optimization time: 3.925377368927002
This batch time : update_bounds func: 4.2541	 prepare: 0.0458	 bound: 3.9258	 transfer: 0.2504	 finalize: 0.0310
Accumulated time: update_bounds func: 84.2586	 prepare: 0.8623	 bound: 78.0288	 transfer: 0.2504	 finalize: 0.7544
batch bounding time:  4.25486421585083
Current worst splitting domains [lb, ub] (depth):
[-0.37702,   inf] (53), [-0.37560,   inf] (53), [-0.37460,   inf] (53), [-0.37374,   inf] (53), [-0.37339,   inf] (53), [-0.37278,   inf] (53), [-0.37268,   inf] (53), [-0.37196,   inf] (53), [-0.37144,   inf] (53), [-0.37119,   inf] (53), [-0.37097,   inf] (53), [-0.37055,   inf] (53), [-0.37027,   inf] (53), [-0.36984,   inf] (53), [-0.36976,   inf] (53), [-0.36961,   inf] (53), [-0.36908,   inf] (53), [-0.36901,   inf] (53), [-0.36884,   inf] (53), [-0.36879,   inf] (53), 
length of domains: 3570
Total time: 5.0134	 pickout: 0.1198	 decision: 0.5908	 get_bound: 4.2556	 add_domain: 0.0472
Current lb:-0.3770153522491455
7650 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 102.97662115097046

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 144] [3, 144] [3, 144] [2, 1113] [2, 1113] [2, 1113] [3, 144] [3, 144] [3, 144] [3, 144] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 140.16265869140625 with beta sum per layer: [0.0, 0.0, 106.81440734863281, 78.4999008178711]
alpha/beta optimization time: 3.9270362854003906
This batch time : update_bounds func: 4.2369	 prepare: 0.0459	 bound: 3.9274	 transfer: 0.2321	 finalize: 0.0304
Accumulated time: update_bounds func: 88.4955	 prepare: 0.9082	 bound: 81.9562	 transfer: 0.2321	 finalize: 0.7848
batch bounding time:  4.237588882446289
Current worst splitting domains [lb, ub] (depth):
[-0.37346,   inf] (55), [-0.37203,   inf] (55), [-0.37108,   inf] (55), [-0.37068,   inf] (55), [-0.37016,   inf] (55), [-0.36969,   inf] (55), [-0.36901,   inf] (55), [-0.36834,   inf] (55), [-0.36777,   inf] (55), [-0.36759,   inf] (55), [-0.36732,   inf] (55), [-0.36683,   inf] (55), [-0.36669,   inf] (55), [-0.36666,   inf] (55), [-0.36636,   inf] (55), [-0.36570,   inf] (55), [-0.36560,   inf] (55), [-0.36549,   inf] (55), [-0.36539,   inf] (55), [-0.36527,   inf] (55), 
length of domains: 3770
Total time: 5.1408	 pickout: 0.1329	 decision: 0.5915	 get_bound: 4.2383	 add_domain: 0.1781
Current lb:-0.37346386909484863
8050 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 108.12324953079224

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 4690] [2, 4690] [2, 1113] [3, 144] [3, 144] [3, 144] [2, 2196] [2, 4690] [2, 4690] [2, 4690] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 137.93045043945312 with beta sum per layer: [0.0, 0.0, 110.64608001708984, 86.25492095947266]
alpha/beta optimization time: 3.9120302200317383
This batch time : update_bounds func: 4.2416	 prepare: 0.0457	 bound: 3.9125	 transfer: 0.2501	 finalize: 0.0323
Accumulated time: update_bounds func: 92.7371	 prepare: 0.9538	 bound: 85.8687	 transfer: 0.2501	 finalize: 0.8171
batch bounding time:  4.242312908172607
Current worst splitting domains [lb, ub] (depth):
[-0.36789,   inf] (57), [-0.36715,   inf] (57), [-0.36694,   inf] (57), [-0.36664,   inf] (57), [-0.36647,   inf] (57), [-0.36637,   inf] (57), [-0.36617,   inf] (57), [-0.36498,   inf] (57), [-0.36489,   inf] (57), [-0.36468,   inf] (57), [-0.36311,   inf] (57), [-0.36278,   inf] (57), [-0.36209,   inf] (57), [-0.36205,   inf] (57), [-0.36193,   inf] (57), [-0.36181,   inf] (57), [-0.36153,   inf] (57), [-0.36152,   inf] (57), [-0.36134,   inf] (57), [-0.36130,   inf] (57), 
length of domains: 3970
Total time: 5.0052	 pickout: 0.1211	 decision: 0.5938	 get_bound: 4.2430	 add_domain: 0.0473
Current lb:-0.3678934574127197
8450 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 113.13439393043518

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 191] [2, 2196] [2, 4690] [3, 191] [2, 2196] [2, 2196] [3, 191] [3, 191] [3, 191] [2, 4690] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 136.49703979492188 with beta sum per layer: [0.0, 0.0, 126.85054779052734, 81.6070327758789]
alpha/beta optimization time: 3.9066572189331055
This batch time : update_bounds func: 4.2430	 prepare: 0.0460	 bound: 3.9071	 transfer: 0.2573	 finalize: 0.0314
Accumulated time: update_bounds func: 96.9801	 prepare: 0.9999	 bound: 89.7758	 transfer: 0.2573	 finalize: 0.8485
batch bounding time:  4.2437379360198975
Current worst splitting domains [lb, ub] (depth):
[-0.36578,   inf] (59), [-0.36512,   inf] (59), [-0.36454,   inf] (59), [-0.36444,   inf] (59), [-0.36432,   inf] (59), [-0.36405,   inf] (59), [-0.36284,   inf] (59), [-0.36278,   inf] (59), [-0.36107,   inf] (59), [-0.36068,   inf] (59), [-0.36036,   inf] (59), [-0.35999,   inf] (59), [-0.35994,   inf] (59), [-0.35983,   inf] (59), [-0.35971,   inf] (59), [-0.35947,   inf] (59), [-0.35945,   inf] (59), [-0.35941,   inf] (59), [-0.35905,   inf] (59), [-0.35901,   inf] (59), 
length of domains: 4170
Total time: 5.0271	 pickout: 0.1415	 decision: 0.5938	 get_bound: 4.2445	 add_domain: 0.0473
Current lb:-0.3657817840576172
8850 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 118.16757440567017

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2196] [3, 191] [2, 4686] [3, 191] [3, 191] [2, 4686] [2, 4686] [2, 4686] [3, 191] [2, 2196] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 136.51956176757812 with beta sum per layer: [0.0, 0.0, 134.92141723632812, 77.59242248535156]
alpha/beta optimization time: 3.9080371856689453
This batch time : update_bounds func: 4.2348	 prepare: 0.0458	 bound: 3.9085	 transfer: 0.2485	 finalize: 0.0309
Accumulated time: update_bounds func: 101.2149	 prepare: 1.0457	 bound: 93.6842	 transfer: 0.2485	 finalize: 0.8793
batch bounding time:  4.235480785369873
Current worst splitting domains [lb, ub] (depth):
[-0.36376,   inf] (61), [-0.36307,   inf] (61), [-0.36301,   inf] (61), [-0.36257,   inf] (61), [-0.36232,   inf] (61), [-0.36218,   inf] (61), [-0.36134,   inf] (61), [-0.36129,   inf] (61), [-0.35896,   inf] (61), [-0.35870,   inf] (61), [-0.35846,   inf] (61), [-0.35836,   inf] (61), [-0.35824,   inf] (61), [-0.35800,   inf] (61), [-0.35772,   inf] (61), [-0.35758,   inf] (61), [-0.35751,   inf] (61), [-0.35741,   inf] (61), [-0.35737,   inf] (61), [-0.35737,   inf] (61), 
length of domains: 4370
Total time: 5.1549	 pickout: 0.1360	 decision: 0.7340	 get_bound: 4.2362	 add_domain: 0.0488
Current lb:-0.3637576103210449
9250 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 123.32869529724121

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 4686] [2, 2196] [2, 4686] [2, 2196] [2, 4686] [2, 4686] [2, 2196] [2, 2196] [2, 4686] [2, 5070] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 136.83392333984375 with beta sum per layer: [0.0, 0.0, 141.36328125, 80.02835083007812]
alpha/beta optimization time: 3.910574197769165
This batch time : update_bounds func: 4.2389	 prepare: 0.0458	 bound: 3.9110	 transfer: 0.2500	 finalize: 0.0309
Accumulated time: update_bounds func: 105.4538	 prepare: 1.0915	 bound: 97.5952	 transfer: 0.2500	 finalize: 0.9102
batch bounding time:  4.239585638046265
Current worst splitting domains [lb, ub] (depth):
[-0.36227,   inf] (63), [-0.36152,   inf] (63), [-0.36109,   inf] (63), [-0.36083,   inf] (63), [-0.36069,   inf] (63), [-0.36057,   inf] (63), [-0.35934,   inf] (63), [-0.35930,   inf] (63), [-0.35746,   inf] (63), [-0.35675,   inf] (63), [-0.35673,   inf] (63), [-0.35647,   inf] (63), [-0.35641,   inf] (63), [-0.35624,   inf] (63), [-0.35614,   inf] (63), [-0.35587,   inf] (63), [-0.35579,   inf] (63), [-0.35562,   inf] (63), [-0.35555,   inf] (63), [-0.35549,   inf] (63), 
length of domains: 4570
Total time: 5.0300	 pickout: 0.1478	 decision: 0.5926	 get_bound: 4.2403	 add_domain: 0.0493
Current lb:-0.36226868629455566
9650 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 128.36473035812378

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5892] [2, 5892] [2, 5892] [2, 5892] [2, 5892] [2, 5892] [2, 5892] [2, 5892] [2, 4676] [2, 4686] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 136.334228515625 with beta sum per layer: [0.0, 0.0, 149.37442016601562, 79.38194274902344]
alpha/beta optimization time: 3.8995261192321777
This batch time : update_bounds func: 4.2256	 prepare: 0.0459	 bound: 3.9000	 transfer: 0.2476	 finalize: 0.0310
Accumulated time: update_bounds func: 109.6795	 prepare: 1.1375	 bound: 101.4952	 transfer: 0.2476	 finalize: 0.9412
batch bounding time:  4.226381540298462
Current worst splitting domains [lb, ub] (depth):
[-0.36103,   inf] (65), [-0.36027,   inf] (65), [-0.35981,   inf] (65), [-0.35952,   inf] (65), [-0.35938,   inf] (65), [-0.35932,   inf] (65), [-0.35802,   inf] (65), [-0.35797,   inf] (65), [-0.35735,   inf] (65), [-0.35662,   inf] (65), [-0.35631,   inf] (65), [-0.35613,   inf] (65), [-0.35575,   inf] (65), [-0.35567,   inf] (65), [-0.35545,   inf] (65), [-0.35527,   inf] (65), [-0.35520,   inf] (65), [-0.35518,   inf] (65), [-0.35507,   inf] (65), [-0.35471,   inf] (65), 
length of domains: 4770
Total time: 5.1678	 pickout: 0.1440	 decision: 0.7469	 get_bound: 4.2272	 add_domain: 0.0497
Current lb:-0.36103248596191406
10050 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 133.5385298728943

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5070] [2, 4676] [2, 5070] [2, 4676] [2, 4676] [2, 5070] [2, 4676] [2, 4676] [2, 5892] [2, 5070] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 135.972900390625 with beta sum per layer: [0.0, 0.0, 149.74285888671875, 73.67576599121094]
alpha/beta optimization time: 3.907231569290161
This batch time : update_bounds func: 4.2354	 prepare: 0.0462	 bound: 3.9077	 transfer: 0.2499	 finalize: 0.0305
Accumulated time: update_bounds func: 113.9148	 prepare: 1.1837	 bound: 105.4028	 transfer: 0.2499	 finalize: 0.9716
batch bounding time:  4.236083507537842
Current worst splitting domains [lb, ub] (depth):
[-0.36015,   inf] (67), [-0.35941,   inf] (67), [-0.35927,   inf] (67), [-0.35790,   inf] (67), [-0.35786,   inf] (67), [-0.35610,   inf] (67), [-0.35553,   inf] (67), [-0.35516,   inf] (67), [-0.35469,   inf] (67), [-0.35456,   inf] (67), [-0.35451,   inf] (67), [-0.35437,   inf] (67), [-0.35424,   inf] (67), [-0.35404,   inf] (67), [-0.35395,   inf] (67), [-0.35389,   inf] (67), [-0.35378,   inf] (67), [-0.35375,   inf] (67), [-0.35360,   inf] (67), [-0.35328,   inf] (67), 
length of domains: 4970
Total time: 5.0542	 pickout: 0.1731	 decision: 0.5935	 get_bound: 4.2369	 add_domain: 0.0507
Current lb:-0.360154390335083
10450 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 138.59884762763977

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5070] [2, 5070] [2, 5070] [2, 5070] [2, 5070] [2, 5070] [2, 4676] [2, 5070] [2, 4676] [2, 5070] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 135.8167724609375 with beta sum per layer: [0.0, 0.0, 147.1903533935547, 80.45223999023438]
alpha/beta optimization time: 3.9162797927856445
This batch time : update_bounds func: 4.4291	 prepare: 0.0453	 bound: 3.9167	 transfer: 0.2474	 finalize: 0.2184
Accumulated time: update_bounds func: 118.3439	 prepare: 1.2290	 bound: 109.3196	 transfer: 0.2474	 finalize: 1.1900
batch bounding time:  4.4297730922698975
Current worst splitting domains [lb, ub] (depth):
[-0.35538,   inf] (69), [-0.35468,   inf] (69), [-0.35449,   inf] (69), [-0.35409,   inf] (69), [-0.35394,   inf] (69), [-0.35381,   inf] (69), [-0.35378,   inf] (69), [-0.35363,   inf] (69), [-0.35338,   inf] (69), [-0.35309,   inf] (69), [-0.35293,   inf] (69), [-0.35284,   inf] (69), [-0.35235,   inf] (69), [-0.35230,   inf] (69), [-0.35175,   inf] (69), [-0.35171,   inf] (69), [-0.35164,   inf] (69), [-0.35115,   inf] (65), [-0.35114,   inf] (69), [-0.35102,   inf] (69), 
length of domains: 5170
Total time: 5.2178	 pickout: 0.1425	 decision: 0.5946	 get_bound: 4.4306	 add_domain: 0.0502
Current lb:-0.3553752899169922
10850 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 143.8227195739746

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 4892] [2, 3290] [2, 475] [2, 475] [2, 4892] [2, 475] [2, 3290] [2, 475] [2, 475] [2, 475] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 135.5159912109375 with beta sum per layer: [0.0, 0.0, 145.52484130859375, 84.47000122070312]
alpha/beta optimization time: 3.9098973274230957
This batch time : update_bounds func: 4.2377	 prepare: 0.0462	 bound: 3.9103	 transfer: 0.2474	 finalize: 0.0326
Accumulated time: update_bounds func: 122.5816	 prepare: 1.2752	 bound: 113.2299	 transfer: 0.2474	 finalize: 1.2226
batch bounding time:  4.238483428955078
Current worst splitting domains [lb, ub] (depth):
[-0.35313,   inf] (71), [-0.35201,   inf] (71), [-0.35159,   inf] (71), [-0.35147,   inf] (71), [-0.35127,   inf] (71), [-0.35112,   inf] (71), [-0.35096,   inf] (71), [-0.35074,   inf] (71), [-0.35065,   inf] (71), [-0.35052,   inf] (65), [-0.35039,   inf] (71), [-0.35035,   inf] (63), [-0.35019,   inf] (65), [-0.35018,   inf] (71), [-0.35018,   inf] (71), [-0.35016,   inf] (67), [-0.35007,   inf] (65), [-0.35005,   inf] (59), [-0.35005,   inf] (49), [-0.35005,   inf] (55), 
length of domains: 5370
Total time: 5.0220	 pickout: 0.1384	 decision: 0.5949	 get_bound: 4.2392	 add_domain: 0.0495
Current lb:-0.35312962532043457
11250 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 148.8512101173401

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 1771] [2, 4892] [2, 475] [2, 1771] [2, 4892] [2, 1771] [2, 1771] [2, 1771] [2, 4892] [2, 5070] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 134.98907470703125 with beta sum per layer: [0.0, 0.0, 151.40951538085938, 96.2182388305664]
alpha/beta optimization time: 3.9192304611206055
This batch time : update_bounds func: 4.2443	 prepare: 0.0460	 bound: 3.9197	 transfer: 0.2459	 finalize: 0.0314
Accumulated time: update_bounds func: 126.8259	 prepare: 1.3212	 bound: 117.1496	 transfer: 0.2459	 finalize: 1.2541
batch bounding time:  4.2450244426727295
Current worst splitting domains [lb, ub] (depth):
[-0.35186,   inf] (73), [-0.35020,   inf] (73), [-0.34982,   inf] (73), [-0.34981,   inf] (73), [-0.34974,   inf] (67), [-0.34967,   inf] (73), [-0.34957,   inf] (47), [-0.34950,   inf] (69), [-0.34945,   inf] (73), [-0.34942,   inf] (51), [-0.34941,   inf] (47), [-0.34941,   inf] (65), [-0.34941,   inf] (49), [-0.34941,   inf] (45), [-0.34940,   inf] (53), [-0.34940,   inf] (45), [-0.34940,   inf] (43), [-0.34940,   inf] (53), [-0.34940,   inf] (61), [-0.34940,   inf] (61), 
length of domains: 5570
Total time: 5.2257	 pickout: 0.1389	 decision: 0.5949	 get_bound: 4.2458	 add_domain: 0.2461
Current lb:-0.35185861587524414
11650 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 154.0832200050354

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 475] [2, 4892] [2, 475] [2, 1771] [2, 5070] [2, 4892] [2, 4747] [2, 475] [2, 4892] [2, 1113] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 134.52481079101562 with beta sum per layer: [0.0, 0.0, 155.75498962402344, 87.98223114013672]
alpha/beta optimization time: 3.9102234840393066
This batch time : update_bounds func: 4.2373	 prepare: 0.0459	 bound: 3.9106	 transfer: 0.2479	 finalize: 0.0316
Accumulated time: update_bounds func: 131.0632	 prepare: 1.3672	 bound: 121.0602	 transfer: 0.2479	 finalize: 1.2856
batch bounding time:  4.238091468811035
Current worst splitting domains [lb, ub] (depth):
[-0.34937,   inf] (75), [-0.34924,   inf] (65), [-0.34915,   inf] (65), [-0.34910,   inf] (65), [-0.34896,   inf] (69), [-0.34893,   inf] (65), [-0.34888,   inf] (49), [-0.34885,   inf] (61), [-0.34885,   inf] (59), [-0.34885,   inf] (53), [-0.34885,   inf] (57), [-0.34884,   inf] (57), [-0.34884,   inf] (55), [-0.34884,   inf] (61), [-0.34884,   inf] (63), [-0.34884,   inf] (57), [-0.34884,   inf] (49), [-0.34883,   inf] (61), [-0.34883,   inf] (53), [-0.34883,   inf] (57), 
length of domains: 5770
Total time: 5.0210	 pickout: 0.1367	 decision: 0.5937	 get_bound: 4.2389	 add_domain: 0.0517
Current lb:-0.34937167167663574
12050 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 159.11063146591187

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 3290] [2, 5070] [2, 5892] [2, 475] [2, 5070] [2, 5070] [3, 188] [2, 2196] [2, 5070] [2, 1113] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 134.18856811523438 with beta sum per layer: [0.0, 0.0, 164.79632568359375, 91.58000183105469]
alpha/beta optimization time: 3.9127237796783447
This batch time : update_bounds func: 4.2383	 prepare: 0.0461	 bound: 3.9132	 transfer: 0.2462	 finalize: 0.0316
Accumulated time: update_bounds func: 135.3015	 prepare: 1.4132	 bound: 124.9734	 transfer: 0.2462	 finalize: 1.3172
batch bounding time:  4.239220142364502
Current worst splitting domains [lb, ub] (depth):
[-0.34873,   inf] (65), [-0.34862,   inf] (65), [-0.34860,   inf] (69), [-0.34853,   inf] (67), [-0.34853,   inf] (67), [-0.34850,   inf] (65), [-0.34841,   inf] (47), [-0.34840,   inf] (67), [-0.34838,   inf] (65), [-0.34828,   inf] (69), [-0.34825,   inf] (43), [-0.34825,   inf] (47), [-0.34824,   inf] (47), [-0.34824,   inf] (51), [-0.34824,   inf] (55), [-0.34824,   inf] (61), [-0.34824,   inf] (69), [-0.34824,   inf] (63), [-0.34823,   inf] (63), [-0.34821,   inf] (51), 
length of domains: 5970
Total time: 5.0419	 pickout: 0.1569	 decision: 0.5931	 get_bound: 4.2400	 add_domain: 0.0520
Current lb:-0.34873080253601074
12450 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 164.16097331047058

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5070] [2, 5892] [2, 475] [2, 5070] [2, 5070] [2, 5892] [2, 4747] [2, 5070] [2, 5070] [2, 5070] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 133.8362274169922 with beta sum per layer: [0.0, 0.0, 171.9274444580078, 93.33055114746094]
alpha/beta optimization time: 3.9120521545410156
This batch time : update_bounds func: 4.4446	 prepare: 0.0460	 bound: 3.9125	 transfer: 0.2469	 finalize: 0.2379
Accumulated time: update_bounds func: 139.7461	 prepare: 1.4592	 bound: 128.8859	 transfer: 0.2469	 finalize: 1.5551
batch bounding time:  4.445286512374878
Current worst splitting domains [lb, ub] (depth):
[-0.34812,   inf] (65), [-0.34809,   inf] (65), [-0.34798,   inf] (49), [-0.34796,   inf] (67), [-0.34794,   inf] (69), [-0.34794,   inf] (67), [-0.34779,   inf] (65), [-0.34778,   inf] (65), [-0.34771,   inf] (73), [-0.34770,   inf] (69), [-0.34770,   inf] (51), [-0.34769,   inf] (51), [-0.34769,   inf] (69), [-0.34768,   inf] (57), [-0.34768,   inf] (67), [-0.34768,   inf] (61), [-0.34768,   inf] (63), [-0.34768,   inf] (59), [-0.34768,   inf] (43), [-0.34768,   inf] (67), 
length of domains: 6170
Total time: 5.2140	 pickout: 0.1222	 decision: 0.5949	 get_bound: 4.4460	 add_domain: 0.0507
Current lb:-0.3481175899505615
12850 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 169.38124418258667

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5070] [2, 5070] [3, 188] [2, 5070] [2, 475] [2, 5070] [2, 5070] [2, 5070] [2, 4892] [2, 475] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 133.70985412597656 with beta sum per layer: [0.0, 0.0, 163.30841064453125, 101.46788024902344]
alpha/beta optimization time: 3.9086735248565674
This batch time : update_bounds func: 4.2403	 prepare: 0.0475	 bound: 3.9091	 transfer: 0.2483	 finalize: 0.0341
Accumulated time: update_bounds func: 143.9864	 prepare: 1.5068	 bound: 132.7950	 transfer: 0.2483	 finalize: 1.5893
batch bounding time:  4.241052150726318
Current worst splitting domains [lb, ub] (depth):
[-0.34757,   inf] (69), [-0.34755,   inf] (65), [-0.34727,   inf] (67), [-0.34723,   inf] (67), [-0.34723,   inf] (57), [-0.34723,   inf] (53), [-0.34722,   inf] (49), [-0.34721,   inf] (47), [-0.34721,   inf] (55), [-0.34721,   inf] (51), [-0.34721,   inf] (65), [-0.34721,   inf] (55), [-0.34720,   inf] (71), [-0.34720,   inf] (51), [-0.34720,   inf] (63), [-0.34720,   inf] (41), [-0.34720,   inf] (69), [-0.34720,   inf] (67), [-0.34720,   inf] (55), [-0.34719,   inf] (63), 
length of domains: 6370
Total time: 5.0199	 pickout: 0.1325	 decision: 0.5954	 get_bound: 4.2418	 add_domain: 0.0502
Current lb:-0.34757423400878906
13250 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 174.40835332870483

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5070] [2, 5070] [2, 5070] [2, 4676] [3, 144] [2, 4690] [2, 4690] [3, 188] [2, 1113] [2, 1762] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 133.823974609375 with beta sum per layer: [0.0, 0.0, 169.62326049804688, 93.98779296875]
alpha/beta optimization time: 3.9099478721618652
This batch time : update_bounds func: 4.2303	 prepare: 0.0465	 bound: 3.9104	 transfer: 0.2394	 finalize: 0.0327
Accumulated time: update_bounds func: 148.2167	 prepare: 1.5533	 bound: 136.7054	 transfer: 0.2394	 finalize: 1.6220
batch bounding time:  4.2310521602630615
Current worst splitting domains [lb, ub] (depth):
[-0.34703,   inf] (67), [-0.34701,   inf] (69), [-0.34676,   inf] (65), [-0.34673,   inf] (53), [-0.34673,   inf] (57), [-0.34672,   inf] (49), [-0.34671,   inf] (45), [-0.34671,   inf] (53), [-0.34671,   inf] (55), [-0.34671,   inf] (63), [-0.34671,   inf] (53), [-0.34671,   inf] (59), [-0.34671,   inf] (63), [-0.34671,   inf] (43), [-0.34670,   inf] (49), [-0.34670,   inf] (53), [-0.34670,   inf] (61), [-0.34670,   inf] (61), [-0.34670,   inf] (71), [-0.34670,   inf] (71), 
length of domains: 6570
Total time: 5.0298	 pickout: 0.1522	 decision: 0.5947	 get_bound: 4.2318	 add_domain: 0.0511
Current lb:-0.3470344543457031
13650 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 179.44476175308228

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5070] [2, 475] [2, 5070] [2, 1113] [2, 4686] [2, 1762] [3, 188] [2, 1762] [2, 2196] [2, 5070] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 133.39895629882812 with beta sum per layer: [0.0, 0.0, 180.1637725830078, 102.05293273925781]
alpha/beta optimization time: 3.9101505279541016
This batch time : update_bounds func: 4.2305	 prepare: 0.0467	 bound: 3.9106	 transfer: 0.2396	 finalize: 0.0323
Accumulated time: update_bounds func: 152.4472	 prepare: 1.6000	 bound: 140.6160	 transfer: 0.2396	 finalize: 1.6543
batch bounding time:  4.231234073638916
Current worst splitting domains [lb, ub] (depth):
[-0.34650,   inf] (65), [-0.34649,   inf] (65), [-0.34647,   inf] (65), [-0.34646,   inf] (67), [-0.34641,   inf] (61), [-0.34638,   inf] (65), [-0.34627,   inf] (65), [-0.34624,   inf] (61), [-0.34624,   inf] (57), [-0.34624,   inf] (69), [-0.34623,   inf] (47), [-0.34623,   inf] (61), [-0.34623,   inf] (61), [-0.34623,   inf] (55), [-0.34622,   inf] (53), [-0.34622,   inf] (55), [-0.34621,   inf] (53), [-0.34621,   inf] (71), [-0.34621,   inf] (55), [-0.34621,   inf] (41), 
length of domains: 6770
Total time: 5.2299	 pickout: 0.1358	 decision: 0.8106	 get_bound: 4.2320	 add_domain: 0.0516
Current lb:-0.34650373458862305
14050 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 184.68127179145813

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5070] [2, 475] [2, 5070] [2, 5892] [2, 5070] [2, 5070] [2, 5070] [2, 4686] [3, 191] [2, 475] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 133.53958129882812 with beta sum per layer: [0.0, 0.0, 174.5128173828125, 94.45304870605469]
alpha/beta optimization time: 3.915529251098633
This batch time : update_bounds func: 4.2523	 prepare: 0.0467	 bound: 3.9160	 transfer: 0.2571	 finalize: 0.0313
Accumulated time: update_bounds func: 156.6995	 prepare: 1.6467	 bound: 144.5319	 transfer: 0.2571	 finalize: 1.6856
batch bounding time:  4.252971649169922
Current worst splitting domains [lb, ub] (depth):
[-0.34602,   inf] (65), [-0.34597,   inf] (65), [-0.34589,   inf] (67), [-0.34581,   inf] (49), [-0.34580,   inf] (57), [-0.34580,   inf] (53), [-0.34580,   inf] (51), [-0.34579,   inf] (63), [-0.34579,   inf] (65), [-0.34579,   inf] (53), [-0.34579,   inf] (41), [-0.34579,   inf] (55), [-0.34579,   inf] (55), [-0.34578,   inf] (41), [-0.34578,   inf] (59), [-0.34578,   inf] (41), [-0.34578,   inf] (59), [-0.34578,   inf] (53), [-0.34577,   inf] (77), [-0.34577,   inf] (47), 
length of domains: 6970
Total time: 5.0748	 pickout: 0.1746	 decision: 0.5948	 get_bound: 4.2537	 add_domain: 0.0516
Current lb:-0.3460235595703125
14450 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 189.76261925697327

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5892] [2, 5070] [2, 5892] [3, 188] [3, 144] [2, 1113] [2, 1113] [2, 4686] [2, 4676] [2, 4690] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 133.06747436523438 with beta sum per layer: [0.0, 0.0, 177.65931701660156, 97.90034484863281]
alpha/beta optimization time: 3.908402681350708
This batch time : update_bounds func: 4.2273	 prepare: 0.0456	 bound: 3.9088	 transfer: 0.2410	 finalize: 0.0307
Accumulated time: update_bounds func: 160.9268	 prepare: 1.6923	 bound: 148.4407	 transfer: 0.2410	 finalize: 1.7163
batch bounding time:  4.227961540222168
Current worst splitting domains [lb, ub] (depth):
[-0.34568,   inf] (67), [-0.34561,   inf] (65), [-0.34557,   inf] (67), [-0.34557,   inf] (67), [-0.34556,   inf] (61), [-0.34555,   inf] (67), [-0.34550,   inf] (65), [-0.34547,   inf] (65), [-0.34541,   inf] (63), [-0.34541,   inf] (63), [-0.34540,   inf] (61), [-0.34540,   inf] (53), [-0.34540,   inf] (75), [-0.34540,   inf] (69), [-0.34540,   inf] (55), [-0.34540,   inf] (69), [-0.34539,   inf] (49), [-0.34539,   inf] (59), [-0.34539,   inf] (51), [-0.34539,   inf] (59), 
length of domains: 7170
Total time: 5.0217	 pickout: 0.1486	 decision: 0.5932	 get_bound: 4.2287	 add_domain: 0.0511
Current lb:-0.34567785263061523
14850 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 194.79117226600647

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 475] [2, 5070] [2, 5892] [2, 5892] [2, 5070] [2, 5892] [2, 5070] [2, 5892] [2, 5070] [2, 5070] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 133.14385986328125 with beta sum per layer: [0.0, 0.0, 170.49703979492188, 93.02433776855469]
alpha/beta optimization time: 3.907632827758789
This batch time : update_bounds func: 4.2255	 prepare: 0.0456	 bound: 3.9081	 transfer: 0.2380	 finalize: 0.0326
Accumulated time: update_bounds func: 165.1523	 prepare: 1.7379	 bound: 152.3488	 transfer: 0.2380	 finalize: 1.7489
batch bounding time:  4.226178407669067
Current worst splitting domains [lb, ub] (depth):
[-0.34528,   inf] (61), [-0.34528,   inf] (67), [-0.34519,   inf] (65), [-0.34509,   inf] (67), [-0.34505,   inf] (65), [-0.34505,   inf] (65), [-0.34504,   inf] (67), [-0.34503,   inf] (67), [-0.34502,   inf] (73), [-0.34501,   inf] (55), [-0.34501,   inf] (57), [-0.34501,   inf] (73), [-0.34501,   inf] (53), [-0.34501,   inf] (55), [-0.34501,   inf] (51), [-0.34501,   inf] (67), [-0.34500,   inf] (63), [-0.34500,   inf] (51), [-0.34500,   inf] (55), [-0.34500,   inf] (55), 
length of domains: 7370
Total time: 5.2895	 pickout: 0.1747	 decision: 0.8378	 get_bound: 4.2269	 add_domain: 0.0500
Current lb:-0.3452799320220947
15250 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 200.08713626861572

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5070] [2, 5892] [2, 5070] [2, 5070] [2, 475] [2, 5070] [2, 475] [2, 5892] [2, 4892] [2, 4690] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 133.11082458496094 with beta sum per layer: [0.0, 0.0, 177.95724487304688, 92.79827880859375]
alpha/beta optimization time: 3.9091336727142334
This batch time : update_bounds func: 4.2287	 prepare: 0.0462	 bound: 3.9096	 transfer: 0.2390	 finalize: 0.0327
Accumulated time: update_bounds func: 169.3810	 prepare: 1.7841	 bound: 156.2584	 transfer: 0.2390	 finalize: 1.7816
batch bounding time:  4.229424953460693
Current worst splitting domains [lb, ub] (depth):
[-0.34481,   inf] (65), [-0.34475,   inf] (65), [-0.34462,   inf] (65), [-0.34458,   inf] (71), [-0.34458,   inf] (67), [-0.34458,   inf] (47), [-0.34458,   inf] (45), [-0.34458,   inf] (49), [-0.34458,   inf] (57), [-0.34458,   inf] (71), [-0.34458,   inf] (59), [-0.34457,   inf] (55), [-0.34457,   inf] (73), [-0.34457,   inf] (73), [-0.34456,   inf] (69), [-0.34456,   inf] (61), [-0.34456,   inf] (55), [-0.34456,   inf] (45), [-0.34456,   inf] (57), [-0.34456,   inf] (57), 
length of domains: 7570
Total time: 5.0540	 pickout: 0.1780	 decision: 0.5956	 get_bound: 4.2302	 add_domain: 0.0502
Current lb:-0.34480977058410645
15650 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 205.1477861404419

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5070] [2, 5070] [2, 5892] [2, 1771] [2, 5892] [3, 188] [2, 4678] [3, 188] [3, 191] [2, 1771] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 132.97946166992188 with beta sum per layer: [0.0, 0.0, 176.64401245117188, 83.17190551757812]
alpha/beta optimization time: 3.9060351848602295
This batch time : update_bounds func: 4.2337	 prepare: 0.0462	 bound: 3.9065	 transfer: 0.2473	 finalize: 0.0325
Accumulated time: update_bounds func: 173.6146	 prepare: 1.8302	 bound: 160.1648	 transfer: 0.2473	 finalize: 1.8140
batch bounding time:  4.234390735626221
Current worst splitting domains [lb, ub] (depth):
[-0.34439,   inf] (65), [-0.34439,   inf] (67), [-0.34438,   inf] (67), [-0.34436,   inf] (67), [-0.34430,   inf] (67), [-0.34427,   inf] (67), [-0.34423,   inf] (65), [-0.34423,   inf] (49), [-0.34423,   inf] (59), [-0.34423,   inf] (47), [-0.34422,   inf] (55), [-0.34422,   inf] (69), [-0.34422,   inf] (53), [-0.34422,   inf] (67), [-0.34422,   inf] (59), [-0.34422,   inf] (65), [-0.34421,   inf] (67), [-0.34421,   inf] (51), [-0.34421,   inf] (51), [-0.34421,   inf] (41), 
length of domains: 7770
Total time: 5.0514	 pickout: 0.1689	 decision: 0.5949	 get_bound: 4.2352	 add_domain: 0.0524
Current lb:-0.3443894386291504
16050 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 210.20583176612854

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5070] [2, 5892] [2, 5892] [2, 5892] [2, 5070] [2, 5892] [2, 5070] [2, 1762] [2, 2196] [3, 188] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 132.6173858642578 with beta sum per layer: [0.0, 0.0, 182.9744110107422, 87.69163513183594]
alpha/beta optimization time: 3.9021551609039307
This batch time : update_bounds func: 4.2291	 prepare: 0.0463	 bound: 3.9026	 transfer: 0.2469	 finalize: 0.0320
Accumulated time: update_bounds func: 177.8437	 prepare: 1.8765	 bound: 164.0674	 transfer: 0.2469	 finalize: 1.8460
batch bounding time:  4.229852199554443
Current worst splitting domains [lb, ub] (depth):
[-0.34412,   inf] (67), [-0.34409,   inf] (67), [-0.34404,   inf] (67), [-0.34403,   inf] (61), [-0.34402,   inf] (67), [-0.34401,   inf] (65), [-0.34400,   inf] (67), [-0.34393,   inf] (67), [-0.34392,   inf] (67), [-0.34389,   inf] (53), [-0.34389,   inf] (51), [-0.34389,   inf] (55), [-0.34389,   inf] (75), [-0.34389,   inf] (69), [-0.34388,   inf] (61), [-0.34388,   inf] (57), [-0.34388,   inf] (41), [-0.34388,   inf] (45), [-0.34388,   inf] (77), [-0.34388,   inf] (59), 
length of domains: 7970
Total time: 5.2858	 pickout: 0.1609	 decision: 0.8410	 get_bound: 4.2306	 add_domain: 0.0532
Current lb:-0.3441176414489746
16450 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 215.4987769126892

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5892] [2, 5892] [2, 5892] [2, 5070] [2, 475] [2, 5892] [2, 5892] [2, 5070] [2, 5892] [2, 1113] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 132.98922729492188 with beta sum per layer: [0.0, 0.0, 175.19461059570312, 90.60685729980469]
alpha/beta optimization time: 3.9066483974456787
This batch time : update_bounds func: 4.2345	 prepare: 0.0465	 bound: 3.9071	 transfer: 0.2479	 finalize: 0.0317
Accumulated time: update_bounds func: 182.0782	 prepare: 1.9230	 bound: 167.9745	 transfer: 0.2479	 finalize: 1.8778
batch bounding time:  4.235190153121948
Current worst splitting domains [lb, ub] (depth):
[-0.34377,   inf] (67), [-0.34374,   inf] (65), [-0.34367,   inf] (65), [-0.34367,   inf] (67), [-0.34363,   inf] (69), [-0.34362,   inf] (65), [-0.34357,   inf] (53), [-0.34357,   inf] (57), [-0.34357,   inf] (63), [-0.34357,   inf] (53), [-0.34356,   inf] (53), [-0.34356,   inf] (57), [-0.34356,   inf] (53), [-0.34356,   inf] (57), [-0.34356,   inf] (57), [-0.34355,   inf] (67), [-0.34355,   inf] (51), [-0.34355,   inf] (57), [-0.34354,   inf] (41), [-0.34354,   inf] (55), 
length of domains: 8170
Total time: 5.0399	 pickout: 0.1576	 decision: 0.5932	 get_bound: 4.2360	 add_domain: 0.0531
Current lb:-0.3437652587890625
16850 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 220.54584193229675

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5892] [2, 5892] [2, 5070] [2, 5892] [2, 5070] [2, 5070] [3, 144] [3, 144] [2, 4676] [3, 144] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 132.55323791503906 with beta sum per layer: [0.0, 0.0, 166.71829223632812, 96.87195587158203]
alpha/beta optimization time: 3.9093189239501953
This batch time : update_bounds func: 4.2447	 prepare: 0.0486	 bound: 3.9098	 transfer: 0.2484	 finalize: 0.0366
Accumulated time: update_bounds func: 186.3229	 prepare: 1.9717	 bound: 171.8843	 transfer: 0.2484	 finalize: 1.9144
batch bounding time:  4.24562931060791
Current worst splitting domains [lb, ub] (depth):
[-0.34346,   inf] (65), [-0.34338,   inf] (65), [-0.34337,   inf] (67), [-0.34335,   inf] (65), [-0.34333,   inf] (69), [-0.34326,   inf] (61), [-0.34325,   inf] (65), [-0.34318,   inf] (61), [-0.34317,   inf] (65), [-0.34317,   inf] (59), [-0.34317,   inf] (43), [-0.34316,   inf] (59), [-0.34316,   inf] (69), [-0.34316,   inf] (57), [-0.34316,   inf] (75), [-0.34316,   inf] (63), [-0.34315,   inf] (61), [-0.34315,   inf] (53), [-0.34315,   inf] (59), [-0.34315,   inf] (57), 
length of domains: 8370
Total time: 5.0658	 pickout: 0.1675	 decision: 0.5928	 get_bound: 4.2467	 add_domain: 0.0588
Current lb:-0.3434607982635498
17250 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 225.62096667289734

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5070] [2, 5070] [2, 5892] [2, 5070] [2, 4892] [2, 5070] [2, 5070] [3, 191] [2, 5070] [2, 2196] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 132.4569549560547 with beta sum per layer: [0.0, 0.0, 181.22708129882812, 93.30937194824219]
alpha/beta optimization time: 3.908372163772583
This batch time : update_bounds func: 4.2346	 prepare: 0.0467	 bound: 3.9088	 transfer: 0.2448	 finalize: 0.0331
Accumulated time: update_bounds func: 190.5576	 prepare: 2.0184	 bound: 175.7931	 transfer: 0.2448	 finalize: 1.9474
batch bounding time:  4.235364675521851
Current worst splitting domains [lb, ub] (depth):
[-0.34304,   inf] (65), [-0.34299,   inf] (69), [-0.34299,   inf] (69), [-0.34291,   inf] (65), [-0.34284,   inf] (65), [-0.34284,   inf] (61), [-0.34284,   inf] (75), [-0.34283,   inf] (49), [-0.34283,   inf] (59), [-0.34283,   inf] (51), [-0.34283,   inf] (57), [-0.34283,   inf] (65), [-0.34283,   inf] (49), [-0.34282,   inf] (57), [-0.34282,   inf] (51), [-0.34282,   inf] (53), [-0.34282,   inf] (59), [-0.34282,   inf] (55), [-0.34282,   inf] (47), [-0.34282,   inf] (67), 
length of domains: 8570
Total time: 5.3397	 pickout: 0.1532	 decision: 0.8987	 get_bound: 4.2361	 add_domain: 0.0518
Current lb:-0.3430442810058594
17650 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 230.96756196022034

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5892] [2, 5892] [2, 5892] [2, 5070] [2, 4676] [3, 191] [2, 3849] [3, 191] [2, 2196] [2, 1113] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 132.2206268310547 with beta sum per layer: [0.0, 0.0, 185.2731170654297, 92.84516143798828]
alpha/beta optimization time: 3.9071757793426514
This batch time : update_bounds func: 4.2329	 prepare: 0.0461	 bound: 3.9076	 transfer: 0.2448	 finalize: 0.0331
Accumulated time: update_bounds func: 194.7905	 prepare: 2.0645	 bound: 179.7007	 transfer: 0.2448	 finalize: 1.9805
batch bounding time:  4.233597278594971
Current worst splitting domains [lb, ub] (depth):
[-0.34273,   inf] (67), [-0.34269,   inf] (67), [-0.34267,   inf] (65), [-0.34260,   inf] (69), [-0.34260,   inf] (65), [-0.34256,   inf] (61), [-0.34254,   inf] (65), [-0.34252,   inf] (57), [-0.34252,   inf] (65), [-0.34252,   inf] (41), [-0.34252,   inf] (49), [-0.34252,   inf] (53), [-0.34252,   inf] (49), [-0.34251,   inf] (77), [-0.34251,   inf] (53), [-0.34251,   inf] (45), [-0.34251,   inf] (55), [-0.34251,   inf] (59), [-0.34251,   inf] (61), [-0.34250,   inf] (41), 
length of domains: 8770
Total time: 5.0297	 pickout: 0.1478	 decision: 0.5960	 get_bound: 4.2343	 add_domain: 0.0515
Current lb:-0.3427281379699707
18050 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 236.0050151348114

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5892] [2, 5892] [2, 5070] [2, 3290] [2, 5070] [2, 5070] [2, 5070] [2, 5070] [2, 475] [2, 1113] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 132.108154296875 with beta sum per layer: [0.0, 0.0, 169.48196411132812, 94.67510986328125]
alpha/beta optimization time: 3.90865421295166
This batch time : update_bounds func: 4.2354	 prepare: 0.0479	 bound: 3.9091	 transfer: 0.2441	 finalize: 0.0330
Accumulated time: update_bounds func: 199.0259	 prepare: 2.1124	 bound: 183.6098	 transfer: 0.2441	 finalize: 2.0135
batch bounding time:  4.236198663711548
Current worst splitting domains [lb, ub] (depth):
[-0.34233,   inf] (61), [-0.34231,   inf] (69), [-0.34229,   inf] (65), [-0.34225,   inf] (69), [-0.34222,   inf] (69), [-0.34222,   inf] (55), [-0.34222,   inf] (47), [-0.34222,   inf] (61), [-0.34222,   inf] (47), [-0.34222,   inf] (61), [-0.34222,   inf] (75), [-0.34222,   inf] (61), [-0.34221,   inf] (61), [-0.34221,   inf] (45), [-0.34221,   inf] (65), [-0.34221,   inf] (49), [-0.34221,   inf] (53), [-0.34221,   inf] (69), [-0.34221,   inf] (61), [-0.34221,   inf] (63), 
length of domains: 8970
Total time: 5.0294	 pickout: 0.1404	 decision: 0.5983	 get_bound: 4.2370	 add_domain: 0.0537
Current lb:-0.3423337936401367
18450 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 241.04260325431824

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5070] [2, 5892] [2, 5070] [2, 475] [2, 5070] [2, 1113] [2, 4690] [3, 191] [3, 191] [2, 4686] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 131.53143310546875 with beta sum per layer: [0.0, 0.0, 181.56414794921875, 93.48734283447266]
alpha/beta optimization time: 3.91231107711792
This batch time : update_bounds func: 4.5723	 prepare: 0.0487	 bound: 3.9128	 transfer: 0.2368	 finalize: 0.3728
Accumulated time: update_bounds func: 203.5982	 prepare: 2.1610	 bound: 187.5226	 transfer: 0.2368	 finalize: 2.3862
batch bounding time:  4.5731117725372314
Current worst splitting domains [lb, ub] (depth):
[-0.34204,   inf] (67), [-0.34203,   inf] (65), [-0.34193,   inf] (77), [-0.34192,   inf] (73), [-0.34192,   inf] (71), [-0.34192,   inf] (67), [-0.34192,   inf] (51), [-0.34192,   inf] (57), [-0.34192,   inf] (67), [-0.34192,   inf] (47), [-0.34192,   inf] (53), [-0.34192,   inf] (55), [-0.34191,   inf] (75), [-0.34191,   inf] (75), [-0.34191,   inf] (59), [-0.34191,   inf] (51), [-0.34191,   inf] (55), [-0.34191,   inf] (65), [-0.34191,   inf] (57), [-0.34191,   inf] (57), 
length of domains: 9170
Total time: 5.3822	 pickout: 0.1583	 decision: 0.5955	 get_bound: 4.5739	 add_domain: 0.0546
Current lb:-0.3420405387878418
18850 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 246.43165516853333

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 475] [2, 5070] [2, 3849] [2, 1771] [2, 4892] [2, 5892] [2, 1762] [3, 144] [2, 5892] [3, 191] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 131.75611877441406 with beta sum per layer: [0.0, 0.0, 182.62667846679688, 92.07100677490234]
alpha/beta optimization time: 3.9160099029541016
This batch time : update_bounds func: 4.2429	 prepare: 0.0469	 bound: 3.9165	 transfer: 0.2462	 finalize: 0.0321
Accumulated time: update_bounds func: 207.8411	 prepare: 2.2079	 bound: 191.4391	 transfer: 0.2462	 finalize: 2.4184
batch bounding time:  4.243719577789307
Current worst splitting domains [lb, ub] (depth):
[-0.34178,   inf] (65), [-0.34174,   inf] (65), [-0.34171,   inf] (69), [-0.34171,   inf] (69), [-0.34171,   inf] (69), [-0.34165,   inf] (55), [-0.34165,   inf] (65), [-0.34165,   inf] (55), [-0.34164,   inf] (69), [-0.34164,   inf] (55), [-0.34164,   inf] (55), [-0.34164,   inf] (55), [-0.34164,   inf] (67), [-0.34164,   inf] (69), [-0.34164,   inf] (53), [-0.34163,   inf] (63), [-0.34163,   inf] (63), [-0.34163,   inf] (65), [-0.34163,   inf] (41), [-0.34163,   inf] (59), 
length of domains: 9370
Total time: 5.0351	 pickout: 0.1417	 decision: 0.5940	 get_bound: 4.2446	 add_domain: 0.0548
Current lb:-0.34177732467651367
19250 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 251.47371912002563

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5070] [2, 5070] [2, 475] [2, 4892] [2, 475] [2, 2196] [3, 191] [3, 144] [2, 5892] [3, 144] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 131.94436645507812 with beta sum per layer: [0.0, 0.0, 182.40318298339844, 91.39195251464844]
alpha/beta optimization time: 3.903534412384033
This batch time : update_bounds func: 4.2301	 prepare: 0.0491	 bound: 3.9040	 transfer: 0.2439	 finalize: 0.0319
Accumulated time: update_bounds func: 212.0713	 prepare: 2.2570	 bound: 195.3431	 transfer: 0.2439	 finalize: 2.4502
batch bounding time:  4.230871200561523
Current worst splitting domains [lb, ub] (depth):
[-0.34151,   inf] (65), [-0.34149,   inf] (67), [-0.34140,   inf] (67), [-0.34137,   inf] (65), [-0.34136,   inf] (57), [-0.34136,   inf] (63), [-0.34136,   inf] (55), [-0.34136,   inf] (77), [-0.34136,   inf] (77), [-0.34136,   inf] (59), [-0.34136,   inf] (71), [-0.34136,   inf] (59), [-0.34136,   inf] (71), [-0.34136,   inf] (73), [-0.34136,   inf] (55), [-0.34136,   inf] (67), [-0.34136,   inf] (51), [-0.34135,   inf] (59), [-0.34135,   inf] (45), [-0.34134,   inf] (69), 
length of domains: 9570
Total time: 5.0307	 pickout: 0.1483	 decision: 0.5955	 get_bound: 4.2316	 add_domain: 0.0553
Current lb:-0.3415064811706543
19650 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 256.51202273368835

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5070] [2, 1771] [2, 5892] [2, 5070] [2, 5070] [2, 4686] [2, 2196] [2, 3849] [2, 3290] [2, 4686] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 131.753662109375 with beta sum per layer: [0.0, 0.0, 183.12391662597656, 94.922119140625]
alpha/beta optimization time: 3.9101598262786865
This batch time : update_bounds func: 4.2534	 prepare: 0.0468	 bound: 3.9106	 transfer: 0.2609	 finalize: 0.0338
Accumulated time: update_bounds func: 216.3246	 prepare: 2.3038	 bound: 199.2537	 transfer: 0.2609	 finalize: 2.4840
batch bounding time:  4.2540600299835205
Current worst splitting domains [lb, ub] (depth):
[-0.34122,   inf] (71), [-0.34112,   inf] (67), [-0.34105,   inf] (63), [-0.34105,   inf] (55), [-0.34105,   inf] (55), [-0.34105,   inf] (59), [-0.34105,   inf] (71), [-0.34105,   inf] (53), [-0.34105,   inf] (69), [-0.34105,   inf] (41), [-0.34105,   inf] (65), [-0.34104,   inf] (79), [-0.34104,   inf] (71), [-0.34104,   inf] (55), [-0.34104,   inf] (61), [-0.34104,   inf] (65), [-0.34104,   inf] (63), [-0.34104,   inf] (71), [-0.34104,   inf] (55), [-0.34104,   inf] (67), 
length of domains: 9770
Total time: 5.0723	 pickout: 0.1696	 decision: 0.5958	 get_bound: 4.2548	 add_domain: 0.0521
Current lb:-0.34122323989868164
20050 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 261.5915448665619

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 475] [2, 5892] [2, 4676] [2, 1771] [3, 144] [2, 2196] [2, 1771] [2, 4690] [2, 475] [2, 6426] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 131.39491271972656 with beta sum per layer: [0.0, 0.0, 173.2989044189453, 99.51692199707031]
alpha/beta optimization time: 3.900163412094116
This batch time : update_bounds func: 4.2374	 prepare: 0.0468	 bound: 3.9006	 transfer: 0.2547	 finalize: 0.0340
Accumulated time: update_bounds func: 220.5620	 prepare: 2.3506	 bound: 203.1542	 transfer: 0.2547	 finalize: 2.5181
batch bounding time:  4.238113164901733
Current worst splitting domains [lb, ub] (depth):
[-0.34083,   inf] (65), [-0.34081,   inf] (71), [-0.34081,   inf] (51), [-0.34080,   inf] (73), [-0.34080,   inf] (53), [-0.34080,   inf] (57), [-0.34080,   inf] (67), [-0.34080,   inf] (49), [-0.34080,   inf] (65), [-0.34080,   inf] (57), [-0.34080,   inf] (69), [-0.34080,   inf] (47), [-0.34080,   inf] (63), [-0.34079,   inf] (77), [-0.34079,   inf] (63), [-0.34079,   inf] (67), [-0.34079,   inf] (59), [-0.34079,   inf] (63), [-0.34079,   inf] (43), [-0.34078,   inf] (43), 
length of domains: 9970
Total time: 5.4082	 pickout: 0.1962	 decision: 0.9202	 get_bound: 4.2389	 add_domain: 0.0529
Current lb:-0.34082603454589844
20450 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 267.0071096420288

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5070] [2, 1771] [2, 1113] [2, 4892] [2, 1762] [2, 5070] [2, 5892] [2, 1762] [3, 191] [3, 144] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 131.42767333984375 with beta sum per layer: [0.0, 0.0, 188.07269287109375, 92.92672729492188]
alpha/beta optimization time: 3.9041409492492676
This batch time : update_bounds func: 4.2293	 prepare: 0.0465	 bound: 3.9045	 transfer: 0.2438	 finalize: 0.0331
Accumulated time: update_bounds func: 224.7913	 prepare: 2.3972	 bound: 207.0588	 transfer: 0.2438	 finalize: 2.5511
batch bounding time:  4.230086088180542
Current worst splitting domains [lb, ub] (depth):
[-0.34069,   inf] (67), [-0.34068,   inf] (61), [-0.34065,   inf] (65), [-0.34061,   inf] (65), [-0.34060,   inf] (67), [-0.34055,   inf] (69), [-0.34054,   inf] (59), [-0.34054,   inf] (69), [-0.34054,   inf] (41), [-0.34054,   inf] (55), [-0.34054,   inf] (43), [-0.34054,   inf] (55), [-0.34054,   inf] (61), [-0.34053,   inf] (47), [-0.34053,   inf] (53), [-0.34053,   inf] (57), [-0.34053,   inf] (81), [-0.34053,   inf] (53), [-0.34053,   inf] (57), [-0.34053,   inf] (63), 
length of domains: 10170
Total time: 5.0393	 pickout: 0.1585	 decision: 0.5957	 get_bound: 4.2309	 add_domain: 0.0542
Current lb:-0.3406858444213867
20850 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 272.05321860313416

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 1771] [2, 5070] [2, 5070] [2, 475] [2, 5892] [2, 5892] [3, 191] [2, 475] [3, 66] [2, 4690] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 131.24554443359375 with beta sum per layer: [0.0, 0.0, 187.18653869628906, 97.55552673339844]
alpha/beta optimization time: 3.8933732509613037
This batch time : update_bounds func: 4.2196	 prepare: 0.0463	 bound: 3.8938	 transfer: 0.2464	 finalize: 0.0319
Accumulated time: update_bounds func: 229.0109	 prepare: 2.4434	 bound: 210.9526	 transfer: 0.2464	 finalize: 2.5830
batch bounding time:  4.220269203186035
Current worst splitting domains [lb, ub] (depth):
[-0.34032,   inf] (67), [-0.34027,   inf] (67), [-0.34025,   inf] (49), [-0.34025,   inf] (45), [-0.34025,   inf] (65), [-0.34025,   inf] (61), [-0.34025,   inf] (51), [-0.34025,   inf] (45), [-0.34025,   inf] (75), [-0.34025,   inf] (69), [-0.34025,   inf] (55), [-0.34025,   inf] (65), [-0.34024,   inf] (59), [-0.34024,   inf] (49), [-0.34024,   inf] (45), [-0.34024,   inf] (59), [-0.34024,   inf] (73), [-0.34024,   inf] (57), [-0.34024,   inf] (55), [-0.34024,   inf] (55), 
length of domains: 10370
Total time: 5.0374	 pickout: 0.1691	 decision: 0.5931	 get_bound: 4.2210	 add_domain: 0.0543
Current lb:-0.3403172492980957
21250 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 277.09758472442627

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 475] [2, 5892] [3, 191] [2, 3284] [2, 5070] [2, 2196] [3, 144] [3, 188] [2, 3849] [2, 475] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 131.0563507080078 with beta sum per layer: [0.0, 0.0, 178.66744995117188, 95.3670883178711]
alpha/beta optimization time: 3.8792076110839844
This batch time : update_bounds func: 4.2044	 prepare: 0.0471	 bound: 3.8797	 transfer: 0.2447	 finalize: 0.0316
Accumulated time: update_bounds func: 233.2153	 prepare: 2.4905	 bound: 214.8322	 transfer: 0.2447	 finalize: 2.6146
batch bounding time:  4.205101013183594
Current worst splitting domains [lb, ub] (depth):
[-0.34013,   inf] (65), [-0.34012,   inf] (67), [-0.34008,   inf] (59), [-0.34008,   inf] (69), [-0.34004,   inf] (67), [-0.34003,   inf] (67), [-0.34000,   inf] (49), [-0.34000,   inf] (55), [-0.34000,   inf] (75), [-0.34000,   inf] (65), [-0.34000,   inf] (69), [-0.33999,   inf] (45), [-0.33999,   inf] (69), [-0.33999,   inf] (53), [-0.33999,   inf] (71), [-0.33999,   inf] (57), [-0.33999,   inf] (55), [-0.33999,   inf] (75), [-0.33999,   inf] (53), [-0.33999,   inf] (55), 
length of domains: 10570
Total time: 5.0490	 pickout: 0.1932	 decision: 0.5962	 get_bound: 4.2059	 add_domain: 0.0537
Current lb:-0.34012603759765625
21650 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 282.1532814502716

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 475] [2, 5070] [2, 5070] [2, 5892] [2, 5892] [2, 1771] [3, 144] [3, 144] [2, 4746] [3, 191] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 131.1668701171875 with beta sum per layer: [0.0, 0.0, 187.49395751953125, 102.5125732421875]
alpha/beta optimization time: 3.8707549571990967
This batch time : update_bounds func: 4.1899	 prepare: 0.0462	 bound: 3.8712	 transfer: 0.2399	 finalize: 0.0314
Accumulated time: update_bounds func: 237.4052	 prepare: 2.5367	 bound: 218.7034	 transfer: 0.2399	 finalize: 2.6460
batch bounding time:  4.1906421184539795
Current worst splitting domains [lb, ub] (depth):
[-0.33987,   inf] (71), [-0.33986,   inf] (67), [-0.33985,   inf] (69), [-0.33982,   inf] (69), [-0.33980,   inf] (67), [-0.33978,   inf] (57), [-0.33978,   inf] (63), [-0.33978,   inf] (51), [-0.33978,   inf] (57), [-0.33978,   inf] (51), [-0.33978,   inf] (79), [-0.33978,   inf] (61), [-0.33977,   inf] (53), [-0.33977,   inf] (77), [-0.33977,   inf] (53), [-0.33977,   inf] (71), [-0.33977,   inf] (79), [-0.33977,   inf] (57), [-0.33977,   inf] (59), [-0.33976,   inf] (47), 
length of domains: 10770
Total time: 5.3507	 pickout: 0.1759	 decision: 0.9293	 get_bound: 4.1914	 add_domain: 0.0541
Current lb:-0.3398706912994385
22050 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 287.51074862480164

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 475] [2, 5892] [2, 1771] [2, 475] [2, 5892] [2, 2196] [2, 5070] [2, 4690] [3, 144] [2, 1762] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 131.2772979736328 with beta sum per layer: [0.0, 0.0, 188.7144775390625, 99.41346740722656]
alpha/beta optimization time: 3.8745298385620117
This batch time : update_bounds func: 4.2029	 prepare: 0.0464	 bound: 3.8749	 transfer: 0.2463	 finalize: 0.0340
Accumulated time: update_bounds func: 241.6081	 prepare: 2.5831	 bound: 222.5783	 transfer: 0.2463	 finalize: 2.6800
batch bounding time:  4.203565835952759
Current worst splitting domains [lb, ub] (depth):
[-0.33961,   inf] (69), [-0.33961,   inf] (59), [-0.33960,   inf] (69), [-0.33959,   inf] (69), [-0.33958,   inf] (67), [-0.33957,   inf] (67), [-0.33955,   inf] (67), [-0.33954,   inf] (59), [-0.33954,   inf] (59), [-0.33954,   inf] (63), [-0.33954,   inf] (73), [-0.33953,   inf] (69), [-0.33953,   inf] (47), [-0.33953,   inf] (55), [-0.33953,   inf] (71), [-0.33953,   inf] (55), [-0.33953,   inf] (71), [-0.33953,   inf] (51), [-0.33953,   inf] (59), [-0.33953,   inf] (51), 
length of domains: 10970
Total time: 5.0266	 pickout: 0.1725	 decision: 0.5945	 get_bound: 4.2044	 add_domain: 0.0553
Current lb:-0.33960866928100586
22450 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 292.5448775291443

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 1771] [2, 5070] [2, 475] [2, 1771] [2, 5892] [2, 5892] [2, 475] [2, 2196] [2, 475] [2, 4686] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 131.0179443359375 with beta sum per layer: [0.0, 0.0, 193.42898559570312, 92.33641052246094]
alpha/beta optimization time: 3.8720574378967285
This batch time : update_bounds func: 4.1988	 prepare: 0.0465	 bound: 3.8725	 transfer: 0.2458	 finalize: 0.0328
Accumulated time: update_bounds func: 245.8069	 prepare: 2.6296	 bound: 226.4508	 transfer: 0.2458	 finalize: 2.7129
batch bounding time:  4.199518203735352
Current worst splitting domains [lb, ub] (depth):
[-0.33941,   inf] (67), [-0.33937,   inf] (61), [-0.33933,   inf] (51), [-0.33933,   inf] (67), [-0.33933,   inf] (57), [-0.33933,   inf] (69), [-0.33933,   inf] (59), [-0.33933,   inf] (67), [-0.33933,   inf] (61), [-0.33933,   inf] (53), [-0.33933,   inf] (75), [-0.33932,   inf] (59), [-0.33932,   inf] (41), [-0.33932,   inf] (57), [-0.33932,   inf] (71), [-0.33932,   inf] (51), [-0.33932,   inf] (71), [-0.33932,   inf] (55), [-0.33931,   inf] (77), [-0.33931,   inf] (79), 
length of domains: 11170
Total time: 5.0109	 pickout: 0.1649	 decision: 0.5935	 get_bound: 4.2003	 add_domain: 0.0522
Current lb:-0.33940577507019043
22850 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 297.5625431537628

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5070] [2, 5070] [2, 4690] [2, 5892] [2, 4690] [2, 475] [2, 5070] [2, 5892] [3, 191] [2, 1113] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 131.17286682128906 with beta sum per layer: [0.0, 0.0, 181.60498046875, 98.26226806640625]
alpha/beta optimization time: 3.894587516784668
This batch time : update_bounds func: 4.2412	 prepare: 0.0485	 bound: 3.8950	 transfer: 0.2595	 finalize: 0.0369
Accumulated time: update_bounds func: 250.0481	 prepare: 2.6781	 bound: 230.3458	 transfer: 0.2595	 finalize: 2.7497
batch bounding time:  4.24200963973999
Current worst splitting domains [lb, ub] (depth):
[-0.33921,   inf] (67), [-0.33916,   inf] (67), [-0.33911,   inf] (67), [-0.33909,   inf] (71), [-0.33909,   inf] (71), [-0.33909,   inf] (61), [-0.33909,   inf] (55), [-0.33909,   inf] (49), [-0.33909,   inf] (65), [-0.33909,   inf] (71), [-0.33909,   inf] (49), [-0.33909,   inf] (53), [-0.33909,   inf] (67), [-0.33908,   inf] (53), [-0.33908,   inf] (65), [-0.33908,   inf] (61), [-0.33908,   inf] (47), [-0.33908,   inf] (65), [-0.33908,   inf] (61), [-0.33908,   inf] (57), 
length of domains: 11370
Total time: 5.0757	 pickout: 0.1813	 decision: 0.5936	 get_bound: 4.2431	 add_domain: 0.0576/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:25: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1627336316785/work/torch/csrc/utils/tensor_numpy.cpp:143.)
  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))

Current lb:-0.33921384811401367
23250 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Time out!!!!!!!!
Image 0 against label 5 verification end, Time cost: 303.49290561676025
Result: unknown in 320.5771 seconds


[[    0.             2.0842793      0.             0.00030136
      0.        ]
 [    0.             3.35330272     0.             0.00031257
      1.        ]
 [    0.             2.12283134     0.             0.00030828
      2.        ]
 [    0.             1.81245506     0.             0.00030279
      4.        ]
 [    0.            -0.33921385 23250.           303.49290562
      5.        ]]
############# Summary #############
Final verified acc: 0.0% [total 1 examples]
Total verification count: 1 , total verified safe: 0 , verified unsafe: 0 , timeout: 1
mean time [total:1]: 303.4941306114197
mean time [cnt:1]: 303.4941306114197
max time 320.577143907547
unknown (total 1): [0]
