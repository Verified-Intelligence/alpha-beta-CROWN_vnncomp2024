Building native CUDA modules...
/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
  csv_name: cifar2020_instances.csv
  onnx_path: null
  vnnlib_path: null
  results_file: null
  root_path: ../../../../../vnncomp2021/benchmarks/cifar2020
model:
  path: null
  name: mnist_9_200
data:
  start: 70
  end: 71
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR
  data_filter_path: null
specification:
  type: lp
  norm: .inf
  epsilon: null
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 200
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.01
    lr_decay: 0.98
    optimizer: adam
    iteration: 50
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 360
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 10
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:48:12 2022 on ubuntu
saving results to vnn-comp_[cifar2020_instances]_start=70_end=71_iter=50_b=200_timeout=360_branching=kfsb-max-10_lra-init=0.1_lra=0.01_lrb=0.01_PGD=skip.npz
customized start/end sample from 70 to 71

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Model prediction is: tensor([[ 1.2686,  0.6243,  3.0474,  1.2617,  1.5002,  1.1929, -3.0547,  0.0808,
          0.1030,  1.6996]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-0.5659, -0.3431, -0.4211, -0.2601, -0.4118,  3.9570,  0.9279,  0.0056,
         -1.6702]], device='cuda:0') None
best_l after optimization: -2.563244342803955 with beta sum per layer: []
alpha/beta optimization time: 12.190811157226562
initial alpha-CROWN bounds: tensor([[-0.4157, -0.1605, -0.2923, -0.1346, -0.2896,  4.0839,  1.0405,  0.2166,
         -1.4850]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-1.4850, device='cuda:0', grad_fn=<MinBackward1>)
##### [0] True label: 2, Tested against: 0, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_86_eps_0.00784_n1.vnnlib ######
Model prediction is: tensor([[ 1.2686,  0.6243,  3.0474,  1.2617,  1.5002,  1.1929, -3.0547,  0.0808,
          0.1030,  1.6996]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /12 start_node /13
setting alpha for layer /12 start_node /15
setting alpha for layer /12 start_node /18
not setting layer /12 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 32, 32, 32]) != torch.Size([2, 9, 1, 32, 32, 32]))
setting alpha for layer /14 start_node /15
setting alpha for layer /14 start_node /18
not setting layer /14 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /16 start_node /18
not setting layer /16 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /19 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /11 torch.Size([1, 32, 32, 32])
1 /13 torch.Size([1, 32, 16, 16])
2 /15 torch.Size([1, 128, 8, 8])
3 /18 torch.Size([1, 250])
best_l after optimization: 0.41561436653137207 with beta sum per layer: []
alpha/beta optimization time: 2.257634162902832
alpha-CROWN with fixed intermediate bounds: tensor([[-0.4156]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.41561436653137207
layer 0 size torch.Size([32768]) unstable 1360
layer 1 size torch.Size([8192]) unstable 652
layer 2 size torch.Size([8192]) unstable 502
layer 3 size torch.Size([250]) unstable 65
-----------------
# of unstable neurons: 2579
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 32, 32]) pre split depth:  4
batch:  torch.Size([1, 32, 32, 32]) post split depth:  4
splitting decisions: 
split level 0: [3, 178] 
split level 1: [3, 78] 
split level 2: [3, 211] 
split level 3: [3, 221] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -4.688488960266113 with beta sum per layer: [0.0, 0.0, 0.0, 0.5677248239517212]
alpha/beta optimization time: 0.7272250652313232
This batch time : update_bounds func: 0.7401	 prepare: 0.0032	 bound: 0.7278	 transfer: 0.0075	 finalize: 0.0015
Accumulated time: update_bounds func: 0.7401	 prepare: 0.0032	 bound: 0.7278	 transfer: 0.0075	 finalize: 0.0015
batch bounding time:  0.7403113842010498
Current worst splitting domains [lb, ub] (depth):
[-0.22550,   inf] (5), [-0.00974,   inf] (5), 
length of domains: 2
Total time: 0.8096	 pickout: 0.0016	 decision: 0.0652	 get_bound: 0.7425	 add_domain: 0.0002
Current lb:-0.2254951000213623
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.032390356063843

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2, 32, 32, 32]) pre split depth:  3
batch:  torch.Size([2, 32, 32, 32]) post split depth:  3
splitting decisions: 
split level 0: [3, 164] [3, 164] 
split level 1: [3, 129] [3, 129] 
split level 2: [3, 145] [3, 145] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -4.261512279510498 with beta sum per layer: [0.0, 0.0, 0.0, 2.490755081176758]
alpha/beta optimization time: 0.7245965003967285
This batch time : update_bounds func: 0.7378	 prepare: 0.0030	 bound: 0.7249	 transfer: 0.0085	 finalize: 0.0013
Accumulated time: update_bounds func: 1.4778	 prepare: 0.0061	 bound: 1.4527	 transfer: 0.0085	 finalize: 0.0028
batch bounding time:  0.7379481792449951
Current worst splitting domains [lb, ub] (depth):
[-0.04264,   inf] (9), [-0.03479,   inf] (9), 
length of domains: 2
Total time: 0.8083	 pickout: 0.0020	 decision: 0.0662	 get_bound: 0.7399	 add_domain: 0.0002
Current lb:-0.04264448955655098
32 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.841033458709717

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2, 32, 32, 32]) pre split depth:  3
batch:  torch.Size([2, 32, 32, 32]) post split depth:  3
splitting decisions: 
split level 0: [3, 140] [3, 140] 
split level 1: [3, 236] [3, 236] 
split level 2: [3, 76] [3, 176] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -3.7053470611572266 with beta sum per layer: [0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.00999140739440918
This batch time : update_bounds func: 0.0194	 prepare: 0.0029	 bound: 0.0103	 transfer: 0.0048	 finalize: 0.0013
Accumulated time: update_bounds func: 1.4972	 prepare: 0.0091	 bound: 1.4630	 transfer: 0.0048	 finalize: 0.0041
batch bounding time:  0.019577741622924805
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0886	 pickout: 0.0017	 decision: 0.0653	 get_bound: 0.0216	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 4.930020093917847

Image 0 against label 0 verification end, Time cost: 5.013376474380493
##### [0] True label: 2, Tested against: 1, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_86_eps_0.00784_n1.vnnlib ######
Model prediction is: tensor([[ 1.2686,  0.6243,  3.0474,  1.2617,  1.5002,  1.1929, -3.0547,  0.0808,
          0.1030,  1.6996]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /12 start_node /13
setting alpha for layer /12 start_node /15
setting alpha for layer /12 start_node /18
not setting layer /12 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 32, 32, 32]) != torch.Size([2, 9, 1, 32, 32, 32]))
setting alpha for layer /14 start_node /15
setting alpha for layer /14 start_node /18
not setting layer /14 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /16 start_node /18
not setting layer /16 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /19 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /11 torch.Size([1, 32, 32, 32])
1 /13 torch.Size([1, 32, 16, 16])
2 /15 torch.Size([1, 128, 8, 8])
3 /18 torch.Size([1, 250])
best_l after optimization: 0.16044998168945312 with beta sum per layer: []
alpha/beta optimization time: 1.386338472366333
alpha-CROWN with fixed intermediate bounds: tensor([[-0.1604]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.16044998168945312
layer 0 size torch.Size([32768]) unstable 1360
layer 1 size torch.Size([8192]) unstable 652
layer 2 size torch.Size([8192]) unstable 502
layer 3 size torch.Size([250]) unstable 65
-----------------
# of unstable neurons: 2579
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 32, 32]) pre split depth:  4
batch:  torch.Size([1, 32, 32, 32]) post split depth:  4
splitting decisions: 
split level 0: [3, 249] 
split level 1: [3, 165] 
split level 2: [3, 84] 
split level 3: [3, 223] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -9.426870346069336 with beta sum per layer: [0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.011141300201416016
This batch time : update_bounds func: 0.0198	 prepare: 0.0026	 bound: 0.0117	 transfer: 0.0039	 finalize: 0.0014
Accumulated time: update_bounds func: 1.5170	 prepare: 0.0117	 bound: 1.4747	 transfer: 0.0039	 finalize: 0.0056
batch bounding time:  0.019846677780151367
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0863	 pickout: 0.0012	 decision: 0.0627	 get_bound: 0.0224	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.5164105892181396

Image 0 against label 1 verification end, Time cost: 1.5919902324676514
##### [0] True label: 2, Tested against: 3, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_86_eps_0.00784_n1.vnnlib ######
Model prediction is: tensor([[ 1.2686,  0.6243,  3.0474,  1.2617,  1.5002,  1.1929, -3.0547,  0.0808,
          0.1030,  1.6996]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /12 start_node /13
setting alpha for layer /12 start_node /15
setting alpha for layer /12 start_node /18
not setting layer /12 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 32, 32, 32]) != torch.Size([2, 9, 1, 32, 32, 32]))
setting alpha for layer /14 start_node /15
setting alpha for layer /14 start_node /18
not setting layer /14 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /16 start_node /18
not setting layer /16 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /19 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /11 torch.Size([1, 32, 32, 32])
1 /13 torch.Size([1, 32, 16, 16])
2 /15 torch.Size([1, 128, 8, 8])
3 /18 torch.Size([1, 250])
best_l after optimization: 0.2922184467315674 with beta sum per layer: []
alpha/beta optimization time: 1.3962688446044922
alpha-CROWN with fixed intermediate bounds: tensor([[-0.2922]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.2922184467315674
layer 0 size torch.Size([32768]) unstable 1360
layer 1 size torch.Size([8192]) unstable 652
layer 2 size torch.Size([8192]) unstable 502
layer 3 size torch.Size([250]) unstable 65
-----------------
# of unstable neurons: 2579
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 32, 32]) pre split depth:  4
batch:  torch.Size([1, 32, 32, 32]) post split depth:  4
splitting decisions: 
split level 0: [3, 236] 
split level 1: [3, 184] 
split level 2: [3, 176] 
split level 3: [3, 139] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -1.9395402669906616 with beta sum per layer: [0.0, 0.0, 0.0, 0.28677645325660706]
alpha/beta optimization time: 0.7294924259185791
This batch time : update_bounds func: 0.7394	 prepare: 0.0032	 bound: 0.7302	 transfer: 0.0044	 finalize: 0.0015
Accumulated time: update_bounds func: 2.2564	 prepare: 0.0149	 bound: 2.2049	 transfer: 0.0044	 finalize: 0.0070
batch bounding time:  0.739605188369751
Current worst splitting domains [lb, ub] (depth):
[-0.07559,   inf] (5), [-0.03941,   inf] (5), 
length of domains: 2
Total time: 0.8066	 pickout: 0.0013	 decision: 0.0634	 get_bound: 0.7418	 add_domain: 0.0002
Current lb:-0.07559261471033096
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.246807813644409

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2, 32, 32, 32]) pre split depth:  3
batch:  torch.Size([2, 32, 32, 32]) post split depth:  3
splitting decisions: 
split level 0: [3, 7] [3, 7] 
split level 1: [3, 76] [3, 76] 
split level 2: [3, 148] [3, 148] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -2.9666872024536133 with beta sum per layer: [0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.010097026824951172
This batch time : update_bounds func: 0.0200	 prepare: 0.0029	 bound: 0.0104	 transfer: 0.0053	 finalize: 0.0013
Accumulated time: update_bounds func: 2.2764	 prepare: 0.0178	 bound: 2.2153	 transfer: 0.0053	 finalize: 0.0083
batch bounding time:  0.020091772079467773
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0884	 pickout: 0.0018	 decision: 0.0645	 get_bound: 0.0220	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 2.3355023860931396

Image 0 against label 3 verification end, Time cost: 2.417170286178589
##### [0] True label: 2, Tested against: 4, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_86_eps_0.00784_n1.vnnlib ######
Model prediction is: tensor([[ 1.2686,  0.6243,  3.0474,  1.2617,  1.5002,  1.1929, -3.0547,  0.0808,
          0.1030,  1.6996]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /12 start_node /13
setting alpha for layer /12 start_node /15
setting alpha for layer /12 start_node /18
not setting layer /12 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 32, 32, 32]) != torch.Size([2, 9, 1, 32, 32, 32]))
setting alpha for layer /14 start_node /15
setting alpha for layer /14 start_node /18
not setting layer /14 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /16 start_node /18
not setting layer /16 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /19 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /11 torch.Size([1, 32, 32, 32])
1 /13 torch.Size([1, 32, 16, 16])
2 /15 torch.Size([1, 128, 8, 8])
3 /18 torch.Size([1, 250])
best_l after optimization: 0.13457131385803223 with beta sum per layer: []
alpha/beta optimization time: 1.4259498119354248
alpha-CROWN with fixed intermediate bounds: tensor([[-0.1346]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.13457131385803223
layer 0 size torch.Size([32768]) unstable 1360
layer 1 size torch.Size([8192]) unstable 652
layer 2 size torch.Size([8192]) unstable 502
layer 3 size torch.Size([250]) unstable 65
-----------------
# of unstable neurons: 2579
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 32, 32]) pre split depth:  4
batch:  torch.Size([1, 32, 32, 32]) post split depth:  4
splitting decisions: 
split level 0: [3, 84] 
split level 1: [3, 52] 
split level 2: [3, 47] 
split level 3: [3, 128] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -5.318896293640137 with beta sum per layer: [0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.011286020278930664
This batch time : update_bounds func: 0.0247	 prepare: 0.0033	 bound: 0.0116	 transfer: 0.0082	 finalize: 0.0014
Accumulated time: update_bounds func: 2.3011	 prepare: 0.0212	 bound: 2.2269	 transfer: 0.0082	 finalize: 0.0098
batch bounding time:  0.02472400665283203
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0916	 pickout: 0.0015	 decision: 0.0631	 get_bound: 0.0269	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.5614688396453857

Image 0 against label 4 verification end, Time cost: 1.6376326084136963
##### [0] True label: 2, Tested against: 5, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_86_eps_0.00784_n1.vnnlib ######
Model prediction is: tensor([[ 1.2686,  0.6243,  3.0474,  1.2617,  1.5002,  1.1929, -3.0547,  0.0808,
          0.1030,  1.6996]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /12 start_node /13
setting alpha for layer /12 start_node /15
setting alpha for layer /12 start_node /18
not setting layer /12 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 32, 32, 32]) != torch.Size([2, 9, 1, 32, 32, 32]))
setting alpha for layer /14 start_node /15
setting alpha for layer /14 start_node /18
not setting layer /14 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /16 start_node /18
not setting layer /16 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /19 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /11 torch.Size([1, 32, 32, 32])
1 /13 torch.Size([1, 32, 16, 16])
2 /15 torch.Size([1, 128, 8, 8])
3 /18 torch.Size([1, 250])
best_l after optimization: 0.28950756788253784 with beta sum per layer: []
alpha/beta optimization time: 1.3839080333709717
alpha-CROWN with fixed intermediate bounds: tensor([[-0.2895]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.28950756788253784
layer 0 size torch.Size([32768]) unstable 1360
layer 1 size torch.Size([8192]) unstable 652
layer 2 size torch.Size([8192]) unstable 502
layer 3 size torch.Size([250]) unstable 65
-----------------
# of unstable neurons: 2579
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 32, 32]) pre split depth:  4
batch:  torch.Size([1, 32, 32, 32]) post split depth:  4
splitting decisions: 
split level 0: [3, 181] 
split level 1: [3, 231] 
split level 2: [3, 210] 
split level 3: [3, 91] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -3.139349937438965 with beta sum per layer: [0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.7240753173828125
This batch time : update_bounds func: 0.7339	 prepare: 0.0039	 bound: 0.7246	 transfer: 0.0038	 finalize: 0.0014
Accumulated time: update_bounds func: 3.0350	 prepare: 0.0251	 bound: 2.9515	 transfer: 0.0038	 finalize: 0.0112
batch bounding time:  0.7340989112854004
Current worst splitting domains [lb, ub] (depth):
[-0.01517,   inf] (5), 
length of domains: 1
Total time: 0.8021	 pickout: 0.0012	 decision: 0.0646	 get_bound: 0.7362	 add_domain: 0.0001
Current lb:-0.015168779529631138
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.2294254302978516

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 32, 32]) pre split depth:  4
batch:  torch.Size([1, 32, 32, 32]) post split depth:  4
splitting decisions: 
split level 0: [3, 7] 
split level 1: [3, 76] 
split level 2: [3, 119] 
split level 3: [3, 236] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -4.236745357513428 with beta sum per layer: [0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.011322498321533203
This batch time : update_bounds func: 0.0280	 prepare: 0.0065	 bound: 0.0117	 transfer: 0.0083	 finalize: 0.0014
Accumulated time: update_bounds func: 3.0630	 prepare: 0.0316	 bound: 2.9632	 transfer: 0.0083	 finalize: 0.0126
batch bounding time:  0.02811574935913086
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0938	 pickout: 0.0012	 decision: 0.0622	 get_bound: 0.0303	 add_domain: 0.0001
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 2.323676109313965

Image 0 against label 5 verification end, Time cost: 2.401198148727417
##### [0] True label: 2, Tested against: 6, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_86_eps_0.00784_n1.vnnlib ######
init opt crown verified for label 6 with bound 4.083876132965088
Image 0 against label 6 verification end, Time cost: 0.00029778480529785156
##### [0] True label: 2, Tested against: 7, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_86_eps_0.00784_n1.vnnlib ######
init opt crown verified for label 7 with bound 1.0404598712921143
Image 0 against label 7 verification end, Time cost: 0.0005066394805908203
##### [0] True label: 2, Tested against: 8, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_86_eps_0.00784_n1.vnnlib ######
init opt crown verified for label 8 with bound 0.21656902134418488
Image 0 against label 8 verification end, Time cost: 0.0002868175506591797
##### [0] True label: 2, Tested against: 9, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_86_eps_0.00784_n1.vnnlib ######
Model prediction is: tensor([[ 1.2686,  0.6243,  3.0474,  1.2617,  1.5002,  1.1929, -3.0547,  0.0808,
          0.1030,  1.6996]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /12 start_node /13
setting alpha for layer /12 start_node /15
setting alpha for layer /12 start_node /18
not setting layer /12 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 32, 32, 32]) != torch.Size([2, 9, 1, 32, 32, 32]))
setting alpha for layer /14 start_node /15
setting alpha for layer /14 start_node /18
not setting layer /14 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /16 start_node /18
not setting layer /16 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /19 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /11 torch.Size([1, 32, 32, 32])
1 /13 torch.Size([1, 32, 16, 16])
2 /15 torch.Size([1, 128, 8, 8])
3 /18 torch.Size([1, 250])
best_l after optimization: 1.4849869012832642 with beta sum per layer: []
alpha/beta optimization time: 1.3724970817565918
alpha-CROWN with fixed intermediate bounds: tensor([[-1.4850]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-1.4849870204925537
layer 0 size torch.Size([32768]) unstable 1360
layer 1 size torch.Size([8192]) unstable 652
layer 2 size torch.Size([8192]) unstable 502
layer 3 size torch.Size([250]) unstable 65
-----------------
# of unstable neurons: 2579
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 32, 32]) pre split depth:  4
batch:  torch.Size([1, 32, 32, 32]) post split depth:  4
splitting decisions: 
split level 0: [3, 172] 
split level 1: [3, 173] 
split level 2: [3, 58] 
split level 3: [3, 165] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 12.44316291809082 with beta sum per layer: [0.0, 0.0, 0.0, 9.860527992248535]
alpha/beta optimization time: 0.7280693054199219
This batch time : update_bounds func: 0.7376	 prepare: 0.0030	 bound: 0.7286	 transfer: 0.0044	 finalize: 0.0015
Accumulated time: update_bounds func: 3.8006	 prepare: 0.0346	 bound: 3.6919	 transfer: 0.0044	 finalize: 0.0141
batch bounding time:  0.7377972602844238
Current worst splitting domains [lb, ub] (depth):
[-1.20570,   inf] (5), [-1.07732,   inf] (5), [-1.06321,   inf] (5), [-0.98736,   inf] (5), [-0.93092,   inf] (5), [-0.85925,   inf] (5), [-0.85189,   inf] (5), [-0.82713,   inf] (5), [-0.71735,   inf] (5), [-0.69450,   inf] (5), [-0.69019,   inf] (5), [-0.62828,   inf] (5), [-0.55440,   inf] (5), [-0.50893,   inf] (5), [-0.48608,   inf] (5), [-0.36067,   inf] (5), 
length of domains: 16
Total time: 0.8057	 pickout: 0.0013	 decision: 0.0637	 get_bound: 0.7399	 add_domain: 0.0007
Current lb:-1.2056999206542969
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.222022771835327

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([16, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([16, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 129] [3, 129] [3, 129] [3, 129] [3, 129] [3, 129] [3, 129] [3, 129] [3, 129] [3, 129] 
regular batch size: 2*16, diving batch size 1*0
best_l after optimization: 16.545833587646484 with beta sum per layer: [0.0, 0.0, 0.0, 43.637351989746094]
alpha/beta optimization time: 0.7876977920532227
This batch time : update_bounds func: 0.8131	 prepare: 0.0047	 bound: 0.7881	 transfer: 0.0177	 finalize: 0.0025
Accumulated time: update_bounds func: 4.6137	 prepare: 0.0393	 bound: 4.4799	 transfer: 0.0177	 finalize: 0.0166
batch bounding time:  0.8133087158203125
Current worst splitting domains [lb, ub] (depth):
[-1.18674,   inf] (7), [-1.04549,   inf] (7), [-1.02622,   inf] (7), [-0.91668,   inf] (7), [-0.87744,   inf] (7), [-0.86412,   inf] (7), [-0.77721,   inf] (7), [-0.76352,   inf] (7), [-0.72729,   inf] (7), [-0.72435,   inf] (7), [-0.71278,   inf] (7), [-0.61290,   inf] (7), [-0.58755,   inf] (7), [-0.57794,   inf] (7), [-0.56811,   inf] (7), [-0.56754,   inf] (7), [-0.48195,   inf] (7), [-0.45532,   inf] (7), [-0.44489,   inf] (7), [-0.41693,   inf] (7), 
length of domains: 30
Total time: 0.9151	 pickout: 0.0091	 decision: 0.0913	 get_bound: 0.8134	 add_domain: 0.0014
Current lb:-1.1867388486862183
48 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.1375467777252197

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([30, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([30, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 211] [3, 211] [3, 211] [3, 211] [3, 211] [3, 211] [3, 211] [3, 211] [3, 211] [3, 211] 
regular batch size: 2*30, diving batch size 1*0
best_l after optimization: 18.464385986328125 with beta sum per layer: [0.0, 0.0, 0.0, 118.11357116699219]
alpha/beta optimization time: 0.9825811386108398
This batch time : update_bounds func: 1.0285	 prepare: 0.0072	 bound: 0.9829	 transfer: 0.0337	 finalize: 0.0046
Accumulated time: update_bounds func: 5.6422	 prepare: 0.0465	 bound: 5.4628	 transfer: 0.0337	 finalize: 0.0212
batch bounding time:  1.0287253856658936
Current worst splitting domains [lb, ub] (depth):
[-1.16367,   inf] (9), [-1.01310,   inf] (9), [-0.98966,   inf] (9), [-0.84777,   inf] (9), [-0.83986,   inf] (9), [-0.82757,   inf] (9), [-0.76678,   inf] (9), [-0.71291,   inf] (9), [-0.70450,   inf] (9), [-0.68273,   inf] (9), [-0.66473,   inf] (9), [-0.62491,   inf] (9), [-0.62076,   inf] (9), [-0.60519,   inf] (9), [-0.52233,   inf] (9), [-0.52160,   inf] (9), [-0.51590,   inf] (9), [-0.46687,   inf] (9), [-0.45037,   inf] (9), [-0.44855,   inf] (9), 
length of domains: 44
Total time: 1.1692	 pickout: 0.0159	 decision: 0.1223	 get_bound: 1.0288	 add_domain: 0.0021
Current lb:-1.1636744737625122
108 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.307572603225708

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([44, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([44, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 223] [3, 223] [3, 223] [3, 223] [3, 223] [3, 223] [3, 223] [3, 223] [3, 223] [3, 223] 
regular batch size: 2*44, diving batch size 1*0
best_l after optimization: 20.161630630493164 with beta sum per layer: [0.0, 0.0, 0.0, 213.77545166015625]
alpha/beta optimization time: 1.1759321689605713
This batch time : update_bounds func: 1.2390	 prepare: 0.0101	 bound: 1.1763	 transfer: 0.0456	 finalize: 0.0068
Accumulated time: update_bounds func: 6.8812	 prepare: 0.0565	 bound: 6.6391	 transfer: 0.0456	 finalize: 0.0280
batch bounding time:  1.23923921585083
Current worst splitting domains [lb, ub] (depth):
[-1.08237,   inf] (11), [-0.93935,   inf] (11), [-0.92900,   inf] (11), [-0.89174,   inf] (11), [-0.78820,   inf] (11), [-0.77738,   inf] (11), [-0.72570,   inf] (11), [-0.71426,   inf] (11), [-0.67082,   inf] (11), [-0.62200,   inf] (11), [-0.61657,   inf] (11), [-0.60480,   inf] (11), [-0.56398,   inf] (11), [-0.54924,   inf] (11), [-0.54459,   inf] (11), [-0.54009,   inf] (11), [-0.49141,   inf] (11), [-0.47711,   inf] (11), [-0.47476,   inf] (11), [-0.47422,   inf] (11), 
length of domains: 59
Total time: 1.4177	 pickout: 0.0234	 decision: 0.1520	 get_bound: 1.2394	 add_domain: 0.0029
Current lb:-1.08236825466156
196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.7264933586120605

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([59, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([59, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 56] [3, 56] [3, 56] [3, 56] [3, 56] [3, 56] [3, 56] [3, 56] [3, 56] [3, 56] 
regular batch size: 2*59, diving batch size 1*0
best_l after optimization: 22.058731079101562 with beta sum per layer: [0.0, 0.0, 0.0, 322.1448669433594]
alpha/beta optimization time: 1.4058172702789307
This batch time : update_bounds func: 1.4955	 prepare: 0.0130	 bound: 1.4062	 transfer: 0.0668	 finalize: 0.0092
Accumulated time: update_bounds func: 8.3766	 prepare: 0.0695	 bound: 8.0453	 transfer: 0.0668	 finalize: 0.0371
batch bounding time:  1.4958746433258057
Current worst splitting domains [lb, ub] (depth):
[-0.96663,   inf] (13), [-0.93231,   inf] (13), [-0.80759,   inf] (13), [-0.80061,   inf] (13), [-0.78824,   inf] (13), [-0.77759,   inf] (13), [-0.76513,   inf] (13), [-0.71420,   inf] (13), [-0.64927,   inf] (13), [-0.64539,   inf] (13), [-0.62212,   inf] (13), [-0.60305,   inf] (13), [-0.58075,   inf] (13), [-0.57138,   inf] (13), [-0.55480,   inf] (13), [-0.51932,   inf] (13), [-0.48107,   inf] (13), [-0.47893,   inf] (13), [-0.46819,   inf] (13), [-0.44484,   inf] (13), 
length of domains: 73
Total time: 1.7389	 pickout: 0.0311	 decision: 0.2077	 get_bound: 1.4961	 add_domain: 0.0040
Current lb:-0.966625988483429
314 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.467425346374512

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([73, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([73, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 99] [3, 237] [3, 249] [3, 237] [3, 249] [3, 249] [3, 237] [3, 237] [3, 99] [3, 249] 
regular batch size: 2*73, diving batch size 1*0
best_l after optimization: 29.63515853881836 with beta sum per layer: [0.0, 0.0, 0.0, 451.96820068359375]
alpha/beta optimization time: 1.6263253688812256
This batch time : update_bounds func: 1.7275	 prepare: 0.0158	 bound: 1.6267	 transfer: 0.0742	 finalize: 0.0103
Accumulated time: update_bounds func: 10.1041	 prepare: 0.0854	 bound: 9.6720	 transfer: 0.0742	 finalize: 0.0474
batch bounding time:  1.7279040813446045
Current worst splitting domains [lb, ub] (depth):
[-0.90479,   inf] (15), [-0.90321,   inf] (15), [-0.83718,   inf] (15), [-0.78981,   inf] (15), [-0.77035,   inf] (15), [-0.76250,   inf] (15), [-0.75876,   inf] (15), [-0.75387,   inf] (15), [-0.72105,   inf] (15), [-0.67350,   inf] (15), [-0.62085,   inf] (15), [-0.61075,   inf] (15), [-0.59774,   inf] (15), [-0.59396,   inf] (15), [-0.58604,   inf] (15), [-0.57729,   inf] (15), [-0.57347,   inf] (15), [-0.57250,   inf] (15), [-0.57084,   inf] (15), [-0.53128,   inf] (15), 
length of domains: 104
Total time: 2.0459	 pickout: 0.0589	 decision: 0.2532	 get_bound: 1.7282	 add_domain: 0.0056
Current lb:-0.9047940969467163
460 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.51536250114441

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([104, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([104, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 249] [3, 237] [3, 249] [3, 99] [3, 99] [3, 99] [3, 99] [3, 237] [3, 99] [3, 249] 
regular batch size: 2*104, diving batch size 1*0
best_l after optimization: 36.20066452026367 with beta sum per layer: [0.0, 0.0, 0.0, 717.0560913085938]
alpha/beta optimization time: 2.1769444942474365
This batch time : update_bounds func: 2.3783	 prepare: 0.0215	 bound: 2.1773	 transfer: 0.0958	 finalize: 0.0831
Accumulated time: update_bounds func: 12.4824	 prepare: 0.1068	 bound: 11.8493	 transfer: 0.0958	 finalize: 0.1306
batch bounding time:  2.378732681274414
Current worst splitting domains [lb, ub] (depth):
[-0.88549,   inf] (17), [-0.87556,   inf] (17), [-0.80484,   inf] (17), [-0.74544,   inf] (17), [-0.72780,   inf] (17), [-0.72526,   inf] (17), [-0.71062,   inf] (17), [-0.70845,   inf] (17), [-0.68798,   inf] (17), [-0.65829,   inf] (17), [-0.65173,   inf] (17), [-0.64743,   inf] (17), [-0.64128,   inf] (17), [-0.63560,   inf] (17), [-0.63145,   inf] (17), [-0.61842,   inf] (17), [-0.59236,   inf] (17), [-0.57778,   inf] (17), [-0.57666,   inf] (17), [-0.55153,   inf] (17), 
length of domains: 135
Total time: 2.7677	 pickout: 0.0576	 decision: 0.3234	 get_bound: 2.3791	 add_domain: 0.0076
Current lb:-0.885487973690033
668 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.28723430633545

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([135, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([135, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 99] [3, 249] [3, 237] [3, 249] [3, 237] [3, 99] [3, 99] [3, 237] [3, 249] [3, 237] 
regular batch size: 2*135, diving batch size 1*0
best_l after optimization: 44.81195831298828 with beta sum per layer: [0.0, 0.0, 0.0, 1050.8251953125]
alpha/beta optimization time: 2.706784248352051
This batch time : update_bounds func: 2.9147	 prepare: 0.0287	 bound: 2.7072	 transfer: 0.1579	 finalize: 0.0202
Accumulated time: update_bounds func: 15.3971	 prepare: 0.1356	 bound: 14.5565	 transfer: 0.1579	 finalize: 0.1508
batch bounding time:  2.915309429168701
Current worst splitting domains [lb, ub] (depth):
[-0.85625,   inf] (19), [-0.82273,   inf] (19), [-0.76824,   inf] (19), [-0.75053,   inf] (19), [-0.70053,   inf] (19), [-0.68943,   inf] (19), [-0.68366,   inf] (19), [-0.68220,   inf] (19), [-0.66536,   inf] (19), [-0.65887,   inf] (19), [-0.63240,   inf] (19), [-0.62396,   inf] (19), [-0.61844,   inf] (19), [-0.60384,   inf] (19), [-0.59573,   inf] (19), [-0.58781,   inf] (19), [-0.58042,   inf] (19), [-0.57651,   inf] (19), [-0.56700,   inf] (19), [-0.56685,   inf] (19), 
length of domains: 181
Total time: 3.4121	 pickout: 0.0731	 decision: 0.4106	 get_bound: 2.9159	 add_domain: 0.0125
Current lb:-0.8562520742416382
938 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.704799175262451

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([181, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([181, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 169] [3, 169] [3, 169] [3, 169] [3, 169] [3, 169] [3, 169] [3, 169] [3, 169] [3, 169] 
regular batch size: 2*181, diving batch size 1*0
best_l after optimization: 52.911067962646484 with beta sum per layer: [0.0, 0.0, 0.0, 1530.82470703125]
alpha/beta optimization time: 3.4589507579803467
This batch time : update_bounds func: 3.8099	 prepare: 0.0377	 bound: 3.4594	 transfer: 0.2134	 finalize: 0.0982
Accumulated time: update_bounds func: 19.2069	 prepare: 0.1733	 bound: 18.0158	 transfer: 0.2134	 finalize: 0.2490
batch bounding time:  3.8105216026306152
Current worst splitting domains [lb, ub] (depth):
[-0.81369,   inf] (21), [-0.77989,   inf] (21), [-0.72616,   inf] (21), [-0.72252,   inf] (21), [-0.69279,   inf] (21), [-0.69122,   inf] (21), [-0.65788,   inf] (21), [-0.63890,   inf] (21), [-0.62632,   inf] (21), [-0.62321,   inf] (21), [-0.61959,   inf] (21), [-0.60419,   inf] (21), [-0.59937,   inf] (21), [-0.58420,   inf] (21), [-0.58237,   inf] (21), [-0.57319,   inf] (21), [-0.56750,   inf] (21), [-0.55631,   inf] (21), [-0.55571,   inf] (21), [-0.54345,   inf] (21), 
length of domains: 232
Total time: 4.4944	 pickout: 0.1194	 decision: 0.5481	 get_bound: 3.8112	 add_domain: 0.0156
Current lb:-0.8136904835700989
1300 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 20.20695424079895

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 236] [3, 236] [3, 236] [3, 236] [3, 236] [3, 236] [3, 236] [3, 236] [3, 236] [3, 236] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 71.25868225097656 with beta sum per layer: [0.0, 0.0, 0.0, 1732.5936279296875]
alpha/beta optimization time: 3.9479153156280518
This batch time : update_bounds func: 4.2918	 prepare: 0.0659	 bound: 3.9486	 transfer: 0.2445	 finalize: 0.0316
Accumulated time: update_bounds func: 23.4987	 prepare: 0.2392	 bound: 21.9644	 transfer: 0.2445	 finalize: 0.2807
batch bounding time:  4.292639255523682
Current worst splitting domains [lb, ub] (depth):
[-0.79758,   inf] (23), [-0.76385,   inf] (23), [-0.70445,   inf] (23), [-0.69258,   inf] (23), [-0.68680,   inf] (23), [-0.66622,   inf] (23), [-0.65730,   inf] (23), [-0.65151,   inf] (23), [-0.64222,   inf] (23), [-0.62350,   inf] (23), [-0.60922,   inf] (23), [-0.60312,   inf] (23), [-0.59744,   inf] (23), [-0.57934,   inf] (23), [-0.57655,   inf] (23), [-0.56730,   inf] (23), [-0.55665,   inf] (23), [-0.55548,   inf] (23), [-0.54611,   inf] (23), [-0.54531,   inf] (23), 
length of domains: 350
Total time: 5.0515	 pickout: 0.1366	 decision: 0.5987	 get_bound: 4.2935	 add_domain: 0.0228
Current lb:-0.7975822687149048
1700 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 25.26637840270996

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 221] [3, 221] [3, 221] [3, 221] [3, 221] [3, 221] [3, 221] [3, 221] [3, 221] [3, 221] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 88.37281799316406 with beta sum per layer: [0.0, 0.0, 0.3060595989227295, 1672.9716796875]
alpha/beta optimization time: 3.933696985244751
This batch time : update_bounds func: 4.2551	 prepare: 0.0415	 bound: 3.9341	 transfer: 0.2326	 finalize: 0.0458
Accumulated time: update_bounds func: 27.7538	 prepare: 0.2807	 bound: 25.8985	 transfer: 0.2326	 finalize: 0.3265
batch bounding time:  4.25600004196167
Current worst splitting domains [lb, ub] (depth):
[-0.78313,   inf] (25), [-0.74974,   inf] (25), [-0.68926,   inf] (25), [-0.68429,   inf] (25), [-0.65287,   inf] (25), [-0.64707,   inf] (25), [-0.64524,   inf] (25), [-0.63907,   inf] (25), [-0.62859,   inf] (25), [-0.61638,   inf] (25), [-0.60980,   inf] (25), [-0.60254,   inf] (25), [-0.59381,   inf] (25), [-0.59361,   inf] (25), [-0.58875,   inf] (25), [-0.55171,   inf] (25), [-0.55164,   inf] (25), [-0.54415,   inf] (25), [-0.54197,   inf] (25), [-0.53815,   inf] (25), 
length of domains: 520
Total time: 5.0882	 pickout: 0.1419	 decision: 0.6600	 get_bound: 4.2570	 add_domain: 0.0292
Current lb:-0.7831338047981262
2100 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 30.36083722114563

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 119] [3, 119] [3, 119] [3, 119] [3, 119] [3, 119] [3, 119] [3, 119] [3, 119] [3, 119] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 103.70118713378906 with beta sum per layer: [0.0, 0.0, 0.9122554063796997, 1591.4140625]
alpha/beta optimization time: 3.9442999362945557
This batch time : update_bounds func: 4.3065	 prepare: 0.0446	 bound: 3.9448	 transfer: 0.2846	 finalize: 0.0314
Accumulated time: update_bounds func: 32.0603	 prepare: 0.3253	 bound: 29.8432	 transfer: 0.2846	 finalize: 0.3580
batch bounding time:  4.307220220565796
Current worst splitting domains [lb, ub] (depth):
[-0.73802,   inf] (27), [-0.72406,   inf] (27), [-0.70519,   inf] (27), [-0.68776,   inf] (27), [-0.64436,   inf] (27), [-0.62943,   inf] (27), [-0.59774,   inf] (27), [-0.59096,   inf] (27), [-0.59083,   inf] (27), [-0.58353,   inf] (27), [-0.58040,   inf] (27), [-0.57982,   inf] (27), [-0.57901,   inf] (27), [-0.56924,   inf] (27), [-0.56559,   inf] (27), [-0.55502,   inf] (27), [-0.55386,   inf] (27), [-0.55111,   inf] (27), [-0.54945,   inf] (27), [-0.54836,   inf] (27), 
length of domains: 720
Total time: 5.1243	 pickout: 0.1297	 decision: 0.6567	 get_bound: 4.3080	 add_domain: 0.0299
Current lb:-0.7380159497261047
2500 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 35.490368366241455

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 7225] [2, 7225] [3, 18] [3, 18] [2, 7225] [2, 7225] [3, 18] [2, 7225] [3, 18] [3, 18] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 114.84445190429688 with beta sum per layer: [0.0, 0.0, 16.277219772338867, 1479.0758056640625]
alpha/beta optimization time: 3.9366276264190674
This batch time : update_bounds func: 4.2691	 prepare: 0.0434	 bound: 3.9371	 transfer: 0.2556	 finalize: 0.0319
Accumulated time: update_bounds func: 36.3294	 prepare: 0.3687	 bound: 33.7803	 transfer: 0.2556	 finalize: 0.3899
batch bounding time:  4.270601272583008
Current worst splitting domains [lb, ub] (depth):
[-0.73560,   inf] (29), [-0.72129,   inf] (29), [-0.69053,   inf] (29), [-0.67121,   inf] (29), [-0.66663,   inf] (29), [-0.65302,   inf] (29), [-0.64314,   inf] (29), [-0.62749,   inf] (29), [-0.59726,   inf] (29), [-0.58216,   inf] (29), [-0.57827,   inf] (29), [-0.57497,   inf] (29), [-0.56856,   inf] (29), [-0.56437,   inf] (29), [-0.56240,   inf] (29), [-0.56062,   inf] (29), [-0.55378,   inf] (29), [-0.55075,   inf] (29), [-0.54527,   inf] (29), [-0.54062,   inf] (29), 
length of domains: 920
Total time: 5.1130	 pickout: 0.1288	 decision: 0.5960	 get_bound: 4.2714	 add_domain: 0.1169
Current lb:-0.7356029152870178
2900 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 40.60846567153931

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 18] [3, 18] [3, 83] [3, 83] [3, 18] [3, 18] [3, 18] [3, 18] [3, 83] [3, 83] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 122.62140655517578 with beta sum per layer: [0.0, 0.0, 33.339820861816406, 1375.8651123046875]
alpha/beta optimization time: 3.9360194206237793
This batch time : update_bounds func: 4.2641	 prepare: 0.0451	 bound: 3.9365	 transfer: 0.2466	 finalize: 0.0348
Accumulated time: update_bounds func: 40.5935	 prepare: 0.4138	 bound: 37.7168	 transfer: 0.2466	 finalize: 0.4247
batch bounding time:  4.265014886856079
Current worst splitting domains [lb, ub] (depth):
[-0.72097,   inf] (31), [-0.70666,   inf] (31), [-0.67387,   inf] (31), [-0.65420,   inf] (31), [-0.64030,   inf] (31), [-0.62898,   inf] (31), [-0.62878,   inf] (31), [-0.62748,   inf] (31), [-0.61391,   inf] (31), [-0.61329,   inf] (31), [-0.60580,   inf] (31), [-0.58704,   inf] (31), [-0.56616,   inf] (31), [-0.55126,   inf] (31), [-0.54953,   inf] (31), [-0.54773,   inf] (31), [-0.54611,   inf] (31), [-0.53870,   inf] (31), [-0.53626,   inf] (31), [-0.53402,   inf] (31), 
length of domains: 1120
Total time: 5.0447	 pickout: 0.1506	 decision: 0.5961	 get_bound: 4.2658	 add_domain: 0.0322
Current lb:-0.7209732532501221
3300 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 45.66191291809082

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 83] [3, 83] [2, 7225] [2, 7225] [3, 83] [3, 83] [3, 83] [3, 83] [3, 83] [3, 83] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 130.0631103515625 with beta sum per layer: [0.0, 0.0, 74.72894287109375, 1261.875]
alpha/beta optimization time: 3.9274024963378906
This batch time : update_bounds func: 4.2483	 prepare: 0.0430	 bound: 3.9278	 transfer: 0.2453	 finalize: 0.0311
Accumulated time: update_bounds func: 44.8418	 prepare: 0.4568	 bound: 41.6446	 transfer: 0.2453	 finalize: 0.4558
batch bounding time:  4.248943090438843
Current worst splitting domains [lb, ub] (depth):
[-0.70448,   inf] (33), [-0.68992,   inf] (33), [-0.67166,   inf] (33), [-0.65173,   inf] (33), [-0.63594,   inf] (33), [-0.62275,   inf] (33), [-0.61852,   inf] (33), [-0.61331,   inf] (33), [-0.61305,   inf] (33), [-0.60551,   inf] (33), [-0.59703,   inf] (33), [-0.59578,   inf] (33), [-0.56893,   inf] (33), [-0.56478,   inf] (33), [-0.56320,   inf] (33), [-0.55191,   inf] (33), [-0.54713,   inf] (33), [-0.54481,   inf] (33), [-0.54136,   inf] (33), [-0.53999,   inf] (33), 
length of domains: 1320
Total time: 5.1314	 pickout: 0.1724	 decision: 0.6773	 get_bound: 4.2497	 add_domain: 0.0321
Current lb:-0.7044808864593506
3700 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 50.79871916770935

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 3419] [3, 176] [3, 176] [3, 176] [2, 3419] [2, 3419] [2, 3419] [3, 176] [2, 3419] [3, 176] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 142.12489318847656 with beta sum per layer: [0.0, 0.0, 114.62419128417969, 1166.121826171875]
alpha/beta optimization time: 3.9359002113342285
This batch time : update_bounds func: 4.2693	 prepare: 0.0443	 bound: 3.9363	 transfer: 0.2562	 finalize: 0.0315
Accumulated time: update_bounds func: 49.1111	 prepare: 0.5011	 bound: 45.5809	 transfer: 0.2562	 finalize: 0.4873
batch bounding time:  4.270122289657593
Current worst splitting domains [lb, ub] (depth):
[-0.70311,   inf] (35), [-0.66429,   inf] (35), [-0.65537,   inf] (35), [-0.64736,   inf] (35), [-0.63029,   inf] (35), [-0.62669,   inf] (35), [-0.61909,   inf] (35), [-0.61369,   inf] (35), [-0.61341,   inf] (35), [-0.61163,   inf] (35), [-0.60110,   inf] (35), [-0.59562,   inf] (35), [-0.58772,   inf] (35), [-0.57745,   inf] (35), [-0.57602,   inf] (35), [-0.56684,   inf] (35), [-0.56099,   inf] (35), [-0.55954,   inf] (35), [-0.54668,   inf] (35), [-0.54019,   inf] (35), 
length of domains: 1520
Total time: 5.0963	 pickout: 0.1247	 decision: 0.6638	 get_bound: 4.2709	 add_domain: 0.0369
Current lb:-0.7031083106994629
4100 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 55.90118479728699

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 176] [2, 3419] [3, 215] [3, 215] [3, 215] [3, 215] [3, 176] [3, 215] [3, 176] [3, 176] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 153.13853454589844 with beta sum per layer: [0.0, 0.0, 149.87692260742188, 1072.7418212890625]
alpha/beta optimization time: 3.943549633026123
This batch time : update_bounds func: 4.2909	 prepare: 0.0553	 bound: 3.9441	 transfer: 0.2570	 finalize: 0.0333
Accumulated time: update_bounds func: 53.4020	 prepare: 0.5564	 bound: 49.5251	 transfer: 0.2570	 finalize: 0.5207
batch bounding time:  4.291789531707764
Current worst splitting domains [lb, ub] (depth):
[-0.67815,   inf] (37), [-0.66508,   inf] (37), [-0.66298,   inf] (37), [-0.63066,   inf] (37), [-0.62559,   inf] (37), [-0.62270,   inf] (37), [-0.61885,   inf] (37), [-0.60189,   inf] (37), [-0.60117,   inf] (37), [-0.59956,   inf] (37), [-0.59924,   inf] (37), [-0.58633,   inf] (37), [-0.58618,   inf] (37), [-0.58588,   inf] (37), [-0.58471,   inf] (37), [-0.57846,   inf] (37), [-0.57452,   inf] (37), [-0.57230,   inf] (37), [-0.57220,   inf] (37), [-0.56972,   inf] (37), 
length of domains: 1720
Total time: 5.1685	 pickout: 0.1254	 decision: 0.6092	 get_bound: 4.2926	 add_domain: 0.1412
Current lb:-0.6781465411186218
4500 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 61.075284242630005

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 215] [3, 215] [3, 215] [2, 1803] [2, 1803] [2, 954] [2, 954] [2, 954] [2, 954] [2, 954] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 165.74273681640625 with beta sum per layer: [0.0, 0.0, 206.64352416992188, 922.8310546875]
alpha/beta optimization time: 3.9461185932159424
This batch time : update_bounds func: 4.2899	 prepare: 0.0455	 bound: 3.9466	 transfer: 0.2617	 finalize: 0.0349
Accumulated time: update_bounds func: 57.6919	 prepare: 0.6019	 bound: 53.4716	 transfer: 0.2617	 finalize: 0.5556
batch bounding time:  4.290813207626343
Current worst splitting domains [lb, ub] (depth):
[-0.65428,   inf] (39), [-0.64666,   inf] (39), [-0.63947,   inf] (39), [-0.63891,   inf] (39), [-0.63353,   inf] (39), [-0.63258,   inf] (39), [-0.62874,   inf] (39), [-0.62359,   inf] (39), [-0.60573,   inf] (39), [-0.60073,   inf] (39), [-0.59500,   inf] (39), [-0.59197,   inf] (39), [-0.58528,   inf] (39), [-0.58233,   inf] (39), [-0.58170,   inf] (39), [-0.57950,   inf] (39), [-0.57314,   inf] (39), [-0.57152,   inf] (39), [-0.57135,   inf] (39), [-0.56990,   inf] (39), 
length of domains: 1920
Total time: 5.1070	 pickout: 0.1822	 decision: 0.5942	 get_bound: 4.2917	 add_domain: 0.0390
Current lb:-0.6542770266532898
4900 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 66.18981742858887

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 954] [2, 954] [2, 1803] [2, 954] [2, 1803] [2, 954] [2, 954] [2, 954] [2, 996] [2, 996] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 176.61053466796875 with beta sum per layer: [0.0, 0.0, 243.4136199951172, 802.7646484375]
alpha/beta optimization time: 3.9693963527679443
This batch time : update_bounds func: 4.3062	 prepare: 0.0445	 bound: 3.9699	 transfer: 0.2587	 finalize: 0.0321
Accumulated time: update_bounds func: 61.9981	 prepare: 0.6463	 bound: 57.4415	 transfer: 0.2587	 finalize: 0.5877
batch bounding time:  4.307143926620483
Current worst splitting domains [lb, ub] (depth):
[-0.63989,   inf] (41), [-0.63718,   inf] (41), [-0.63271,   inf] (41), [-0.63148,   inf] (41), [-0.63119,   inf] (41), [-0.62563,   inf] (41), [-0.62516,   inf] (41), [-0.61759,   inf] (41), [-0.61693,   inf] (41), [-0.61472,   inf] (41), [-0.61130,   inf] (41), [-0.60882,   inf] (41), [-0.60684,   inf] (41), [-0.60235,   inf] (41), [-0.60142,   inf] (41), [-0.59648,   inf] (41), [-0.59048,   inf] (41), [-0.58746,   inf] (41), [-0.58056,   inf] (41), [-0.57743,   inf] (41), 
length of domains: 2120
Total time: 5.1999	 pickout: 0.1603	 decision: 0.6911	 get_bound: 4.3080	 add_domain: 0.0405
Current lb:-0.639894962310791
5300 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 71.39770865440369

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 1010] [2, 954] [2, 1010] [2, 1010] [2, 954] [2, 1010] [2, 714] [2, 714] [2, 714] [2, 714] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 186.90045166015625 with beta sum per layer: [0.0, 0.0, 298.0845031738281, 650.603515625]
alpha/beta optimization time: 3.931776285171509
This batch time : update_bounds func: 4.2627	 prepare: 0.0448	 bound: 3.9323	 transfer: 0.2515	 finalize: 0.0332
Accumulated time: update_bounds func: 66.2608	 prepare: 0.6911	 bound: 61.3738	 transfer: 0.2515	 finalize: 0.6209
batch bounding time:  4.263563394546509
Current worst splitting domains [lb, ub] (depth):
[-0.63319,   inf] (43), [-0.62543,   inf] (43), [-0.62443,   inf] (43), [-0.62276,   inf] (43), [-0.61882,   inf] (43), [-0.61830,   inf] (43), [-0.61640,   inf] (43), [-0.61552,   inf] (43), [-0.61543,   inf] (43), [-0.61125,   inf] (43), [-0.61100,   inf] (43), [-0.61004,   inf] (43), [-0.60831,   inf] (43), [-0.60789,   inf] (43), [-0.60697,   inf] (43), [-0.60549,   inf] (43), [-0.60527,   inf] (43), [-0.60150,   inf] (43), [-0.60098,   inf] (43), [-0.59988,   inf] (43), 
length of domains: 2320
Total time: 5.0264	 pickout: 0.1314	 decision: 0.5913	 get_bound: 4.2644	 add_domain: 0.0393
Current lb:-0.6331875324249268
5700 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 76.43207287788391

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 714] [2, 714] [2, 714] [2, 1010] [2, 714] [2, 714] [2, 1010] [2, 1010] [2, 1010] [2, 714] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 197.13856506347656 with beta sum per layer: [0.0, 0.0, 403.7779541015625, 558.0654296875]
alpha/beta optimization time: 3.9173407554626465
This batch time : update_bounds func: 4.2295	 prepare: 0.0452	 bound: 3.9178	 transfer: 0.2321	 finalize: 0.0334
Accumulated time: update_bounds func: 70.4903	 prepare: 0.7363	 bound: 65.2915	 transfer: 0.2321	 finalize: 0.6543
batch bounding time:  4.230296611785889
Current worst splitting domains [lb, ub] (depth):
[-0.62393,   inf] (45), [-0.61690,   inf] (45), [-0.61608,   inf] (45), [-0.61596,   inf] (45), [-0.61525,   inf] (45), [-0.60982,   inf] (45), [-0.60933,   inf] (45), [-0.60904,   inf] (45), [-0.60896,   inf] (45), [-0.60834,   inf] (45), [-0.60828,   inf] (45), [-0.60419,   inf] (45), [-0.60287,   inf] (45), [-0.60219,   inf] (45), [-0.60201,   inf] (45), [-0.60198,   inf] (45), [-0.60111,   inf] (45), [-0.59978,   inf] (45), [-0.59782,   inf] (45), [-0.59772,   inf] (45), 
length of domains: 2520
Total time: 5.1061	 pickout: 0.1297	 decision: 0.7059	 get_bound: 4.2310	 add_domain: 0.0395
Current lb:-0.6239345073699951
6100 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 81.5457968711853

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 3172] [2, 3172] [2, 714] [2, 3172] [2, 3172] [2, 3172] [2, 714] [2, 3172] [2, 3172] [2, 3172] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 209.1346435546875 with beta sum per layer: [0.0, 0.0, 458.39453125, 385.50799560546875]
alpha/beta optimization time: 3.9151501655578613
This batch time : update_bounds func: 4.3632	 prepare: 0.0447	 bound: 3.9156	 transfer: 0.2380	 finalize: 0.1639
Accumulated time: update_bounds func: 74.8535	 prepare: 0.7809	 bound: 69.2071	 transfer: 0.2380	 finalize: 0.8182
batch bounding time:  4.364028215408325
Current worst splitting domains [lb, ub] (depth):
[-0.61259,   inf] (47), [-0.61012,   inf] (47), [-0.60715,   inf] (47), [-0.60487,   inf] (47), [-0.60461,   inf] (47), [-0.60400,   inf] (47), [-0.60239,   inf] (47), [-0.60209,   inf] (47), [-0.60114,   inf] (47), [-0.60061,   inf] (47), [-0.59932,   inf] (47), [-0.59915,   inf] (47), [-0.59863,   inf] (47), [-0.59778,   inf] (47), [-0.59692,   inf] (47), [-0.59664,   inf] (47), [-0.59630,   inf] (47), [-0.59485,   inf] (47), [-0.59439,   inf] (47), [-0.59410,   inf] (47), 
length of domains: 2720
Total time: 5.1695	 pickout: 0.1643	 decision: 0.5966	 get_bound: 4.3648	 add_domain: 0.0438
Current lb:-0.612590491771698
6500 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 86.72249817848206

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 7436] [2, 7436] [2, 3172] [2, 4884] [2, 7436] [2, 7436] [2, 4884] [2, 7436] [3, 140] [2, 3172] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 214.4989471435547 with beta sum per layer: [0.0, 0.0, 313.68353271484375, 325.06903076171875]
alpha/beta optimization time: 3.9114341735839844
This batch time : update_bounds func: 4.2405	 prepare: 0.0459	 bound: 3.9119	 transfer: 0.2499	 finalize: 0.0318
Accumulated time: update_bounds func: 79.0940	 prepare: 0.8268	 bound: 73.1190	 transfer: 0.2499	 finalize: 0.8500
batch bounding time:  4.241276741027832
Current worst splitting domains [lb, ub] (depth):
[-0.60690,   inf] (49), [-0.60437,   inf] (49), [-0.59932,   inf] (49), [-0.59892,   inf] (49), [-0.59849,   inf] (49), [-0.59674,   inf] (49), [-0.59631,   inf] (49), [-0.59600,   inf] (49), [-0.59594,   inf] (49), [-0.59583,   inf] (49), [-0.59560,   inf] (49), [-0.59495,   inf] (49), [-0.59415,   inf] (49), [-0.59380,   inf] (49), [-0.59338,   inf] (49), [-0.59189,   inf] (49), [-0.59137,   inf] (49), [-0.59078,   inf] (49), [-0.58950,   inf] (49), [-0.58874,   inf] (49), 
length of domains: 2920
Total time: 5.0131	 pickout: 0.1331	 decision: 0.5929	 get_bound: 4.2421	 add_domain: 0.0449
Current lb:-0.6069047451019287
6900 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 91.742595911026

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 4884] [2, 4884] [2, 7436] [2, 4884] [2, 2894] [2, 7436] [2, 4884] [2, 7436] [2, 4884] [2, 4884] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 220.5948486328125 with beta sum per layer: [0.0, 0.0, 393.12548828125, 210.7777099609375]
alpha/beta optimization time: 3.9448189735412598
This batch time : update_bounds func: 4.4192	 prepare: 0.0460	 bound: 3.9453	 transfer: 0.2547	 finalize: 0.1721
Accumulated time: update_bounds func: 83.5132	 prepare: 0.8728	 bound: 77.0643	 transfer: 0.2547	 finalize: 1.0220
batch bounding time:  4.419942140579224
Current worst splitting domains [lb, ub] (depth):
[-0.60115,   inf] (51), [-0.59855,   inf] (51), [-0.59611,   inf] (51), [-0.59355,   inf] (51), [-0.59315,   inf] (51), [-0.59315,   inf] (51), [-0.59260,   inf] (51), [-0.59149,   inf] (51), [-0.59094,   inf] (51), [-0.59070,   inf] (51), [-0.59046,   inf] (51), [-0.58949,   inf] (51), [-0.58925,   inf] (51), [-0.58921,   inf] (51), [-0.58901,   inf] (51), [-0.58887,   inf] (51), [-0.58836,   inf] (51), [-0.58721,   inf] (51), [-0.58655,   inf] (51), [-0.58558,   inf] (51), 
length of domains: 3120
Total time: 5.1774	 pickout: 0.1221	 decision: 0.5901	 get_bound: 4.4207	 add_domain: 0.0445
Current lb:-0.6011469960212708
7300 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 96.92685437202454

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 73] [3, 73] [3, 73] [3, 73] [3, 73] [3, 73] [2, 4884] [3, 73] [3, 73] [3, 73] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 216.33680725097656 with beta sum per layer: [0.0, 0.0, 375.358642578125, 185.53085327148438]
alpha/beta optimization time: 3.9087297916412354
This batch time : update_bounds func: 4.2502	 prepare: 0.0491	 bound: 3.9092	 transfer: 0.2564	 finalize: 0.0341
Accumulated time: update_bounds func: 87.7634	 prepare: 0.9220	 bound: 80.9735	 transfer: 0.2564	 finalize: 1.0561
batch bounding time:  4.250945568084717
Current worst splitting domains [lb, ub] (depth):
[-0.59830,   inf] (53), [-0.59568,   inf] (53), [-0.59327,   inf] (53), [-0.59071,   inf] (53), [-0.59030,   inf] (53), [-0.59029,   inf] (53), [-0.58807,   inf] (53), [-0.58788,   inf] (53), [-0.58760,   inf] (53), [-0.58690,   inf] (53), [-0.58605,   inf] (53), [-0.58591,   inf] (53), [-0.58576,   inf] (53), [-0.58551,   inf] (53), [-0.58395,   inf] (53), [-0.58338,   inf] (53), [-0.58321,   inf] (53), [-0.58319,   inf] (53), [-0.58274,   inf] (53), [-0.58244,   inf] (53), 
length of domains: 3320
Total time: 5.0154	 pickout: 0.1220	 decision: 0.5958	 get_bound: 4.2518	 add_domain: 0.0458
Current lb:-0.5982967019081116
7700 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 101.95064926147461

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2894] [2, 2894] [2, 4884] [2, 2894] [2, 2894] [2, 7436] [2, 2894] [3, 140] [2, 2894] [2, 7436] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 218.03280639648438 with beta sum per layer: [0.0, 0.0, 368.58135986328125, 189.89434814453125]
alpha/beta optimization time: 3.914824962615967
This batch time : update_bounds func: 4.2500	 prepare: 0.0458	 bound: 3.9153	 transfer: 0.2545	 finalize: 0.0334
Accumulated time: update_bounds func: 92.0134	 prepare: 0.9677	 bound: 84.8888	 transfer: 0.2545	 finalize: 1.0895
batch bounding time:  4.2508111000061035
Current worst splitting domains [lb, ub] (depth):
[-0.59598,   inf] (55), [-0.59336,   inf] (55), [-0.58839,   inf] (55), [-0.58798,   inf] (55), [-0.58755,   inf] (55), [-0.58576,   inf] (55), [-0.58528,   inf] (55), [-0.58477,   inf] (55), [-0.58345,   inf] (55), [-0.58218,   inf] (55), [-0.58133,   inf] (55), [-0.58075,   inf] (55), [-0.58042,   inf] (55), [-0.58035,   inf] (55), [-0.58007,   inf] (55), [-0.57939,   inf] (55), [-0.57818,   inf] (55), [-0.57816,   inf] (55), [-0.57791,   inf] (55), [-0.57772,   inf] (55), 
length of domains: 3520
Total time: 5.1637	 pickout: 0.1255	 decision: 0.7373	 get_bound: 4.2516	 add_domain: 0.0493
Current lb:-0.5959790945053101
8100 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 107.12336802482605

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 140] [3, 140] [3, 140] [3, 140] [2, 1803] [3, 140] [3, 140] [2, 1803] [3, 140] [2, 169] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 217.47845458984375 with beta sum per layer: [0.0, 0.0, 392.0146484375, 162.19869995117188]
alpha/beta optimization time: 3.8936660289764404
This batch time : update_bounds func: 4.2219	 prepare: 0.0457	 bound: 3.8941	 transfer: 0.2472	 finalize: 0.0337
Accumulated time: update_bounds func: 96.2353	 prepare: 1.0135	 bound: 88.7829	 transfer: 0.2472	 finalize: 1.1232
batch bounding time:  4.222786903381348
Current worst splitting domains [lb, ub] (depth):
[-0.59063,   inf] (57), [-0.58799,   inf] (57), [-0.58627,   inf] (57), [-0.58351,   inf] (57), [-0.58302,   inf] (57), [-0.58260,   inf] (57), [-0.58038,   inf] (57), [-0.58006,   inf] (57), [-0.57988,   inf] (57), [-0.57862,   inf] (57), [-0.57842,   inf] (57), [-0.57817,   inf] (57), [-0.57692,   inf] (57), [-0.57556,   inf] (57), [-0.57544,   inf] (57), [-0.57540,   inf] (57), [-0.57515,   inf] (57), [-0.57509,   inf] (57), [-0.57503,   inf] (57), [-0.57407,   inf] (57), 
length of domains: 3720
Total time: 5.0025	 pickout: 0.1384	 decision: 0.5914	 get_bound: 4.2235	 add_domain: 0.0492
Current lb:-0.5906264185905457
8500 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 112.13538360595703

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 1803] [2, 1803] [3, 140] [2, 4884] [2, 1803] [2, 1803] [2, 1803] [3, 140] [2, 1803] [2, 7436] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 215.56802368164062 with beta sum per layer: [0.0, 0.0, 374.2351379394531, 149.7330780029297]
alpha/beta optimization time: 3.884761333465576
This batch time : update_bounds func: 4.2236	 prepare: 0.0462	 bound: 3.8852	 transfer: 0.2556	 finalize: 0.0354
Accumulated time: update_bounds func: 100.4588	 prepare: 1.0597	 bound: 92.6681	 transfer: 0.2556	 finalize: 1.1587
batch bounding time:  4.225004196166992
Current worst splitting domains [lb, ub] (depth):
[-0.58948,   inf] (59), [-0.58685,   inf] (59), [-0.58169,   inf] (59), [-0.58144,   inf] (59), [-0.58085,   inf] (59), [-0.57906,   inf] (59), [-0.57872,   inf] (59), [-0.57781,   inf] (59), [-0.57691,   inf] (59), [-0.57459,   inf] (59), [-0.57418,   inf] (59), [-0.57368,   inf] (59), [-0.57325,   inf] (59), [-0.57306,   inf] (59), [-0.57297,   inf] (59), [-0.57151,   inf] (59), [-0.57138,   inf] (59), [-0.57096,   inf] (59), [-0.57047,   inf] (59), [-0.56992,   inf] (59), 
length of domains: 3920
Total time: 5.1599	 pickout: 0.1285	 decision: 0.7539	 get_bound: 4.2259	 add_domain: 0.0517
Current lb:-0.5894843935966492
8900 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 117.30845379829407

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 169] [2, 169] [2, 169] [2, 169] [2, 169] [2, 169] [2, 169] [2, 169] [2, 169] [3, 84] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 214.00962829589844 with beta sum per layer: [0.0, 0.0, 376.63031005859375, 153.2344207763672]
alpha/beta optimization time: 3.8883116245269775
This batch time : update_bounds func: 4.2247	 prepare: 0.0468	 bound: 3.8888	 transfer: 0.2540	 finalize: 0.0341
Accumulated time: update_bounds func: 104.6836	 prepare: 1.1064	 bound: 96.5568	 transfer: 0.2540	 finalize: 1.1928
batch bounding time:  4.225551605224609
Current worst splitting domains [lb, ub] (depth):
[-0.58563,   inf] (61), [-0.58299,   inf] (61), [-0.57783,   inf] (61), [-0.57763,   inf] (61), [-0.57727,   inf] (61), [-0.57520,   inf] (61), [-0.57493,   inf] (61), [-0.57422,   inf] (61), [-0.57306,   inf] (61), [-0.57217,   inf] (61), [-0.57209,   inf] (61), [-0.57190,   inf] (61), [-0.57032,   inf] (61), [-0.56987,   inf] (61), [-0.56946,   inf] (61), [-0.56938,   inf] (61), [-0.56932,   inf] (61), [-0.56796,   inf] (61), [-0.56717,   inf] (61), [-0.56633,   inf] (61), 
length of domains: 4120
Total time: 5.0050	 pickout: 0.1359	 decision: 0.5900	 get_bound: 4.2265	 add_domain: 0.0527
Current lb:-0.5856274962425232
9300 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 122.32104086875916

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 84] [3, 84] [3, 84] [3, 84] [3, 84] [3, 84] [3, 84] [3, 84] [3, 84] [2, 169] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 211.52369689941406 with beta sum per layer: [0.0, 0.0, 357.96710205078125, 150.44882202148438]
alpha/beta optimization time: 3.8781790733337402
This batch time : update_bounds func: 4.2187	 prepare: 0.0462	 bound: 3.8786	 transfer: 0.2601	 finalize: 0.0327
Accumulated time: update_bounds func: 108.9023	 prepare: 1.1527	 bound: 100.4354	 transfer: 0.2601	 finalize: 1.2255
batch bounding time:  4.219642639160156
Current worst splitting domains [lb, ub] (depth):
[-0.58328,   inf] (63), [-0.58065,   inf] (63), [-0.57548,   inf] (63), [-0.57526,   inf] (63), [-0.57486,   inf] (63), [-0.57285,   inf] (63), [-0.57257,   inf] (63), [-0.57182,   inf] (63), [-0.57066,   inf] (63), [-0.56867,   inf] (63), [-0.56805,   inf] (63), [-0.56751,   inf] (63), [-0.56715,   inf] (63), [-0.56694,   inf] (63), [-0.56554,   inf] (63), [-0.56481,   inf] (63), [-0.56472,   inf] (63), [-0.56391,   inf] (63), [-0.56371,   inf] (63), [-0.56320,   inf] (63), 
length of domains: 4320
Total time: 5.1738	 pickout: 0.1367	 decision: 0.7650	 get_bound: 4.2204	 add_domain: 0.0517
Current lb:-0.5832786560058594
9700 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 127.50445556640625

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5715] [2, 5715] [2, 5715] [2, 5715] [2, 5715] [2, 5715] [2, 5715] [2, 996] [2, 5715] [2, 5715] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 210.96665954589844 with beta sum per layer: [0.0, 0.0, 360.8466796875, 153.01197814941406]
alpha/beta optimization time: 3.864635467529297
This batch time : update_bounds func: 4.1929	 prepare: 0.0468	 bound: 3.8651	 transfer: 0.2452	 finalize: 0.0347
Accumulated time: update_bounds func: 113.0952	 prepare: 1.1995	 bound: 104.3006	 transfer: 0.2452	 finalize: 1.2601
batch bounding time:  4.193924427032471
Current worst splitting domains [lb, ub] (depth):
[-0.58029,   inf] (65), [-0.57764,   inf] (65), [-0.57261,   inf] (65), [-0.57228,   inf] (65), [-0.57188,   inf] (65), [-0.57003,   inf] (65), [-0.56997,   inf] (65), [-0.56959,   inf] (65), [-0.56749,   inf] (65), [-0.56571,   inf] (65), [-0.56475,   inf] (65), [-0.56467,   inf] (65), [-0.56465,   inf] (65), [-0.56408,   inf] (65), [-0.56373,   inf] (65), [-0.56213,   inf] (65), [-0.56201,   inf] (65), [-0.56194,   inf] (65), [-0.56137,   inf] (65), [-0.56035,   inf] (65), 
length of domains: 4520
Total time: 4.9927	 pickout: 0.1492	 decision: 0.5967	 get_bound: 4.1947	 add_domain: 0.0521
Current lb:-0.5802875757217407
10100 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 132.50821113586426

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 3619] [2, 3619] [2, 3619] [2, 3619] [2, 3619] [2, 3619] [2, 3619] [2, 3619] [2, 3619] [2, 996] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 212.8560333251953 with beta sum per layer: [0.0, 0.6074120998382568, 386.3338623046875, 141.16397094726562]
alpha/beta optimization time: 3.8655335903167725
This batch time : update_bounds func: 4.1970	 prepare: 0.0472	 bound: 3.8660	 transfer: 0.2478	 finalize: 0.0348
Accumulated time: update_bounds func: 117.2922	 prepare: 1.2467	 bound: 108.1666	 transfer: 0.2478	 finalize: 1.2950
batch bounding time:  4.197913646697998
Current worst splitting domains [lb, ub] (depth):
[-0.57213,   inf] (67), [-0.57038,   inf] (67), [-0.56903,   inf] (67), [-0.56843,   inf] (67), [-0.56447,   inf] (67), [-0.56411,   inf] (67), [-0.56391,   inf] (67), [-0.56365,   inf] (67), [-0.56268,   inf] (67), [-0.56245,   inf] (67), [-0.56201,   inf] (67), [-0.56138,   inf] (67), [-0.56135,   inf] (67), [-0.56103,   inf] (67), [-0.56073,   inf] (67), [-0.56063,   inf] (67), [-0.56040,   inf] (67), [-0.55967,   inf] (67), [-0.55923,   inf] (67), [-0.55811,   inf] (67), 
length of domains: 4720
Total time: 5.1978	 pickout: 0.1627	 decision: 0.7828	 get_bound: 4.1988	 add_domain: 0.0536
Current lb:-0.5721330046653748
10500 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 137.71354150772095

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 6052] [2, 6052] [3, 91] [2, 6052] [2, 6052] [2, 6052] [2, 3619] [2, 996] [2, 6052] [2, 6052] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 212.71263122558594 with beta sum per layer: [0.0, 0.6146210432052612, 372.4679260253906, 144.5246124267578]
alpha/beta optimization time: 3.861684560775757
This batch time : update_bounds func: 4.2118	 prepare: 0.0473	 bound: 3.8623	 transfer: 0.2596	 finalize: 0.0414
Accumulated time: update_bounds func: 121.5040	 prepare: 1.2940	 bound: 112.0288	 transfer: 0.2596	 finalize: 1.3364
batch bounding time:  4.212838411331177
Current worst splitting domains [lb, ub] (depth):
[-0.56998,   inf] (69), [-0.56820,   inf] (69), [-0.56617,   inf] (69), [-0.56398,   inf] (69), [-0.56232,   inf] (69), [-0.56199,   inf] (69), [-0.56187,   inf] (69), [-0.56050,   inf] (69), [-0.56029,   inf] (69), [-0.56021,   inf] (69), [-0.55910,   inf] (69), [-0.55847,   inf] (69), [-0.55842,   inf] (69), [-0.55817,   inf] (69), [-0.55767,   inf] (69), [-0.55599,   inf] (69), [-0.55569,   inf] (69), [-0.55437,   inf] (69), [-0.55426,   inf] (69), [-0.55423,   inf] (69), 
length of domains: 4920
Total time: 5.0100	 pickout: 0.1496	 decision: 0.5921	 get_bound: 4.2136	 add_domain: 0.0545
Current lb:-0.5699819922447205
10900 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 142.73386931419373

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 91] [3, 91] [3, 91] [2, 6052] [3, 91] [3, 91] [3, 91] [3, 91] [3, 91] [3, 91] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 210.2851104736328 with beta sum per layer: [0.0, 0.920994758605957, 368.055419921875, 158.3504638671875]
alpha/beta optimization time: 3.873119354248047
This batch time : update_bounds func: 4.4051	 prepare: 0.0481	 bound: 3.8736	 transfer: 0.2404	 finalize: 0.2417
Accumulated time: update_bounds func: 125.9090	 prepare: 1.3421	 bound: 115.9025	 transfer: 0.2404	 finalize: 1.5782
batch bounding time:  4.405870199203491
Current worst splitting domains [lb, ub] (depth):
[-0.56495,   inf] (71), [-0.56318,   inf] (71), [-0.56174,   inf] (71), [-0.56115,   inf] (71), [-0.55730,   inf] (71), [-0.55696,   inf] (71), [-0.55675,   inf] (71), [-0.55549,   inf] (71), [-0.55528,   inf] (71), [-0.55510,   inf] (71), [-0.55407,   inf] (71), [-0.55377,   inf] (71), [-0.55347,   inf] (71), [-0.55325,   inf] (71), [-0.55316,   inf] (71), [-0.55254,   inf] (71), [-0.55215,   inf] (71), [-0.55093,   inf] (71), [-0.55060,   inf] (71), [-0.55037,   inf] (71), 
length of domains: 5120
Total time: 5.2424	 pickout: 0.1866	 decision: 0.5953	 get_bound: 4.4067	 add_domain: 0.0539
Current lb:-0.5649492740631104
11300 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 147.98298573493958

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 7781] [3, 30] [1, 1944] [2, 7781] [2, 7781] [2, 7781] [2, 7781] [3, 30] [3, 30] [2, 2273] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 208.3243408203125 with beta sum per layer: [0.0, 3.378286361694336, 399.44232177734375, 146.98580932617188]
alpha/beta optimization time: 3.883471727371216
This batch time : update_bounds func: 4.2205	 prepare: 0.0475	 bound: 3.8839	 transfer: 0.2527	 finalize: 0.0352
Accumulated time: update_bounds func: 130.1295	 prepare: 1.3896	 bound: 119.7864	 transfer: 0.2527	 finalize: 1.6134
batch bounding time:  4.221334934234619
Current worst splitting domains [lb, ub] (depth):
[-0.56161,   inf] (73), [-0.56108,   inf] (73), [-0.56022,   inf] (73), [-0.55713,   inf] (73), [-0.55391,   inf] (73), [-0.55371,   inf] (73), [-0.55348,   inf] (73), [-0.55343,   inf] (73), [-0.55310,   inf] (73), [-0.55292,   inf] (73), [-0.55255,   inf] (73), [-0.55227,   inf] (73), [-0.55221,   inf] (73), [-0.55174,   inf] (73), [-0.54945,   inf] (73), [-0.54920,   inf] (73), [-0.54879,   inf] (73), [-0.54867,   inf] (73), [-0.54827,   inf] (73), [-0.54732,   inf] (73), 
length of domains: 5320
Total time: 5.0267	 pickout: 0.1559	 decision: 0.5911	 get_bound: 4.2223	 add_domain: 0.0575
Current lb:-0.5616052746772766
11700 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 153.0172884464264

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [1, 5609] [3, 30] [3, 30] [3, 30] [1, 5609] [1, 5609] [3, 30] [3, 30] [3, 30] [2, 2273] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 201.49278259277344 with beta sum per layer: [0.0, 2.629821538925171, 394.6241760253906, 158.52272033691406]
alpha/beta optimization time: 3.873462677001953
This batch time : update_bounds func: 4.2118	 prepare: 0.0478	 bound: 3.8740	 transfer: 0.2543	 finalize: 0.0345
Accumulated time: update_bounds func: 134.3413	 prepare: 1.4374	 bound: 123.6603	 transfer: 0.2543	 finalize: 1.6479
batch bounding time:  4.21282958984375
Current worst splitting domains [lb, ub] (depth):
[-0.56049,   inf] (75), [-0.55946,   inf] (75), [-0.55864,   inf] (75), [-0.55554,   inf] (75), [-0.55280,   inf] (75), [-0.55267,   inf] (75), [-0.55194,   inf] (75), [-0.55180,   inf] (75), [-0.55152,   inf] (75), [-0.55130,   inf] (75), [-0.55096,   inf] (75), [-0.55070,   inf] (75), [-0.55012,   inf] (75), [-0.54986,   inf] (75), [-0.54786,   inf] (75), [-0.54767,   inf] (75), [-0.54761,   inf] (75), [-0.54704,   inf] (75), [-0.54666,   inf] (75), [-0.54579,   inf] (75), 
length of domains: 5520
Total time: 5.0216	 pickout: 0.1607	 decision: 0.5920	 get_bound: 4.2136	 add_domain: 0.0554
Current lb:-0.5604926347732544
12100 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 158.04937148094177

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 7781] [1, 5609] [1, 5609] [1, 5609] [2, 7781] [2, 2273] [1, 5609] [1, 5609] [1, 5609] [3, 30] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 206.33099365234375 with beta sum per layer: [0.0, 8.143299102783203, 389.70892333984375, 158.7713165283203]
alpha/beta optimization time: 3.8724119663238525
This batch time : update_bounds func: 4.2066	 prepare: 0.0505	 bound: 3.8729	 transfer: 0.2456	 finalize: 0.0364
Accumulated time: update_bounds func: 138.5479	 prepare: 1.4880	 bound: 127.5333	 transfer: 0.2456	 finalize: 1.6843
batch bounding time:  4.207773447036743
Current worst splitting domains [lb, ub] (depth):
[-0.55835,   inf] (77), [-0.55753,   inf] (77), [-0.55654,   inf] (77), [-0.55443,   inf] (77), [-0.55113,   inf] (77), [-0.55087,   inf] (77), [-0.55068,   inf] (77), [-0.55047,   inf] (77), [-0.54985,   inf] (77), [-0.54976,   inf] (77), [-0.54966,   inf] (77), [-0.54884,   inf] (77), [-0.54858,   inf] (77), [-0.54858,   inf] (77), [-0.54792,   inf] (77), [-0.54674,   inf] (77), [-0.54657,   inf] (77), [-0.54614,   inf] (77), [-0.54554,   inf] (77), [-0.54549,   inf] (77), 
length of domains: 5720
Total time: 5.2599	 pickout: 0.1762	 decision: 0.8192	 get_bound: 4.2086	 add_domain: 0.0560
Current lb:-0.5583474040031433
12500 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 163.3208830356598

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2273] [2, 7781] [2, 2273] [2, 1299] [2, 7781] [2, 7781] [2, 1299] [2, 2273] [2, 7781] [1, 5609] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 206.47079467773438 with beta sum per layer: [0.0, 4.3252482414245605, 419.8997802734375, 149.60455322265625]
alpha/beta optimization time: 3.887049913406372
This batch time : update_bounds func: 4.2322	 prepare: 0.0504	 bound: 3.8875	 transfer: 0.2545	 finalize: 0.0386
Accumulated time: update_bounds func: 142.7802	 prepare: 1.5383	 bound: 131.4208	 transfer: 0.2545	 finalize: 1.7229
batch bounding time:  4.233091354370117
Current worst splitting domains [lb, ub] (depth):
[-0.55680,   inf] (79), [-0.55501,   inf] (79), [-0.55349,   inf] (79), [-0.54935,   inf] (79), [-0.54892,   inf] (79), [-0.54869,   inf] (79), [-0.54810,   inf] (79), [-0.54751,   inf] (79), [-0.54731,   inf] (79), [-0.54721,   inf] (79), [-0.54702,   inf] (79), [-0.54604,   inf] (79), [-0.54585,   inf] (79), [-0.54581,   inf] (79), [-0.54503,   inf] (79), [-0.54443,   inf] (79), [-0.54399,   inf] (79), [-0.54363,   inf] (79), [-0.54346,   inf] (79), [-0.54304,   inf] (79), 
length of domains: 5920
Total time: 5.0487	 pickout: 0.1627	 decision: 0.5942	 get_bound: 4.2341	 add_domain: 0.0577
Current lb:-0.556797981262207
12900 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 168.37901878356934

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 1299] [2, 1299] [2, 2273] [2, 2273] [2, 1299] [2, 1299] [2, 7781] [2, 7781] [2, 1299] [2, 1299] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 206.28158569335938 with beta sum per layer: [0.0, 3.289311408996582, 398.82696533203125, 167.31707763671875]
alpha/beta optimization time: 3.882023811340332
This batch time : update_bounds func: 4.4592	 prepare: 0.0484	 bound: 3.8825	 transfer: 0.2544	 finalize: 0.2726
Accumulated time: update_bounds func: 147.2394	 prepare: 1.5867	 bound: 135.3033	 transfer: 0.2544	 finalize: 1.9955
batch bounding time:  4.459962368011475
Current worst splitting domains [lb, ub] (depth):
[-0.55195,   inf] (81), [-0.55175,   inf] (81), [-0.54992,   inf] (81), [-0.54781,   inf] (81), [-0.54450,   inf] (81), [-0.54427,   inf] (81), [-0.54412,   inf] (81), [-0.54390,   inf] (81), [-0.54372,   inf] (81), [-0.54369,   inf] (81), [-0.54363,   inf] (81), [-0.54291,   inf] (81), [-0.54263,   inf] (81), [-0.54215,   inf] (81), [-0.54201,   inf] (81), [-0.54192,   inf] (81), [-0.54189,   inf] (81), [-0.54058,   inf] (81), [-0.54052,   inf] (81), [-0.54022,   inf] (81), 
length of domains: 6120
Total time: 5.2807	 pickout: 0.1705	 decision: 0.5934	 get_bound: 4.4608	 add_domain: 0.0560
Current lb:-0.5519494414329529
13300 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 173.66653060913086

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 1299] [2, 3260] [2, 3260] [1, 1944] [2, 3260] [2, 1299] [2, 1299] [2, 3260] [2, 3260] [2, 3260] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 208.48760986328125 with beta sum per layer: [0.0, 5.406371593475342, 443.90533447265625, 161.5188751220703]
alpha/beta optimization time: 3.8827693462371826
This batch time : update_bounds func: 4.2160	 prepare: 0.0486	 bound: 3.8832	 transfer: 0.2465	 finalize: 0.0365
Accumulated time: update_bounds func: 151.4553	 prepare: 1.6353	 bound: 139.1865	 transfer: 0.2465	 finalize: 2.0320
batch bounding time:  4.216862916946411
Current worst splitting domains [lb, ub] (depth):
[-0.54867,   inf] (83), [-0.54687,   inf] (83), [-0.54683,   inf] (83), [-0.54627,   inf] (83), [-0.54140,   inf] (83), [-0.54086,   inf] (83), [-0.54069,   inf] (83), [-0.53960,   inf] (83), [-0.53958,   inf] (83), [-0.53952,   inf] (83), [-0.53909,   inf] (83), [-0.53907,   inf] (83), [-0.53901,   inf] (83), [-0.53898,   inf] (83), [-0.53894,   inf] (83), [-0.53882,   inf] (83), [-0.53864,   inf] (83), [-0.53842,   inf] (83), [-0.53800,   inf] (83), [-0.53794,   inf] (69), 
length of domains: 6320
Total time: 5.0421	 pickout: 0.1735	 decision: 0.5904	 get_bound: 4.2179	 add_domain: 0.0603
Current lb:-0.5486670136451721
13700 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 178.71703958511353

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 1675] [2, 3260] [2, 1675] [2, 3260] [2, 1675] [2, 996] [1, 1944] [2, 3260] [2, 1675] [2, 1675] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 206.64146423339844 with beta sum per layer: [0.0, 3.5642812252044678, 423.26092529296875, 164.148193359375]
alpha/beta optimization time: 3.893109083175659
This batch time : update_bounds func: 4.2431	 prepare: 0.0521	 bound: 3.8936	 transfer: 0.2564	 finalize: 0.0397
Accumulated time: update_bounds func: 155.6984	 prepare: 1.6874	 bound: 143.0801	 transfer: 0.2564	 finalize: 2.0717
batch bounding time:  4.244047164916992
Current worst splitting domains [lb, ub] (depth):
[-0.54524,   inf] (85), [-0.54377,   inf] (85), [-0.54340,   inf] (85), [-0.54317,   inf] (85), [-0.53918,   inf] (85), [-0.53906,   inf] (85), [-0.53806,   inf] (85), [-0.53753,   inf] (85), [-0.53751,   inf] (85), [-0.53735,   inf] (85), [-0.53704,   inf] (53), [-0.53704,   inf] (75), [-0.53703,   inf] (77), [-0.53703,   inf] (61), [-0.53703,   inf] (71), [-0.53703,   inf] (57), [-0.53703,   inf] (55), [-0.53702,   inf] (65), [-0.53702,   inf] (69), [-0.53701,   inf] (49), 
length of domains: 6520
Total time: 5.0748	 pickout: 0.1735	 decision: 0.5955	 get_bound: 4.2451	 add_domain: 0.0607
Current lb:-0.5452370047569275
14100 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 183.80295658111572

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [1, 1944] [2, 1675] [2, 1004] [2, 1675] [2, 6052] [2, 1675] [1, 1944] [2, 1675] [2, 6052] [2, 1675] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 204.49717712402344 with beta sum per layer: [0.0, 1.8139605522155762, 485.4317321777344, 161.38186645507812]
alpha/beta optimization time: 3.9055044651031494
This batch time : update_bounds func: 4.2477	 prepare: 0.0478	 bound: 3.9060	 transfer: 0.2552	 finalize: 0.0375
Accumulated time: update_bounds func: 159.9462	 prepare: 1.7352	 bound: 146.9861	 transfer: 0.2552	 finalize: 2.1092
batch bounding time:  4.248769998550415
Current worst splitting domains [lb, ub] (depth):
[-0.54373,   inf] (87), [-0.54035,   inf] (87), [-0.53975,   inf] (87), [-0.53792,   inf] (87), [-0.53737,   inf] (87), [-0.53656,   inf] (87), [-0.53629,   inf] (57), [-0.53628,   inf] (51), [-0.53628,   inf] (63), [-0.53628,   inf] (71), [-0.53628,   inf] (67), [-0.53627,   inf] (65), [-0.53627,   inf] (79), [-0.53627,   inf] (61), [-0.53626,   inf] (65), [-0.53626,   inf] (61), [-0.53626,   inf] (55), [-0.53625,   inf] (69), [-0.53625,   inf] (81), [-0.53625,   inf] (65), 
length of domains: 6720
Total time: 5.3323	 pickout: 0.1804	 decision: 0.8475	 get_bound: 4.2495	 add_domain: 0.0549
Current lb:-0.543730616569519
14500 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 189.14672207832336

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 1004] [2, 1004] [2, 1004] [2, 3101] [2, 1004] [2, 1004] [2, 169] [2, 3170] [3, 91] [2, 7781] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 205.14913940429688 with beta sum per layer: [0.0, 2.945211410522461, 427.3567199707031, 180.20663452148438]
alpha/beta optimization time: 3.9004485607147217
This batch time : update_bounds func: 4.2339	 prepare: 0.0479	 bound: 3.9009	 transfer: 0.2443	 finalize: 0.0396
Accumulated time: update_bounds func: 164.1801	 prepare: 1.7831	 bound: 150.8870	 transfer: 0.2443	 finalize: 2.1488
batch bounding time:  4.236676216125488
Current worst splitting domains [lb, ub] (depth):
[-0.53832,   inf] (89), [-0.53624,   inf] (89), [-0.53551,   inf] (53), [-0.53551,   inf] (69), [-0.53550,   inf] (63), [-0.53550,   inf] (69), [-0.53550,   inf] (53), [-0.53549,   inf] (67), [-0.53549,   inf] (65), [-0.53549,   inf] (51), [-0.53549,   inf] (67), [-0.53548,   inf] (63), [-0.53548,   inf] (57), [-0.53547,   inf] (79), [-0.53546,   inf] (69), [-0.53546,   inf] (69), [-0.53546,   inf] (57), [-0.53545,   inf] (71), [-0.53544,   inf] (63), [-0.53544,   inf] (71), 
length of domains: 6920
Total time: 5.0839	 pickout: 0.1931	 decision: 0.5939	 get_bound: 4.2377	 add_domain: 0.0593
Current lb:-0.5383226275444031
14900 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 194.24520421028137

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 3101] [2, 3101] [2, 2894] [3, 91] [3, 91] [2, 7781] [2, 7781] [2, 5715] [3, 84] [2, 7436] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 204.40118408203125 with beta sum per layer: [0.0, 5.103456497192383, 457.7642517089844, 170.427001953125]
alpha/beta optimization time: 3.893528461456299
This batch time : update_bounds func: 4.2451	 prepare: 0.0499	 bound: 3.8940	 transfer: 0.2607	 finalize: 0.0392
Accumulated time: update_bounds func: 168.4252	 prepare: 1.8330	 bound: 154.7810	 transfer: 0.2607	 finalize: 2.1881
batch bounding time:  4.246082067489624
Current worst splitting domains [lb, ub] (depth):
[-0.53473,   inf] (63), [-0.53473,   inf] (57), [-0.53473,   inf] (57), [-0.53473,   inf] (63), [-0.53472,   inf] (57), [-0.53472,   inf] (61), [-0.53471,   inf] (53), [-0.53471,   inf] (83), [-0.53471,   inf] (61), [-0.53470,   inf] (55), [-0.53470,   inf] (65), [-0.53470,   inf] (73), [-0.53470,   inf] (77), [-0.53470,   inf] (65), [-0.53470,   inf] (57), [-0.53470,   inf] (63), [-0.53469,   inf] (71), [-0.53469,   inf] (75), [-0.53468,   inf] (59), [-0.53468,   inf] (63), 
length of domains: 7120
Total time: 5.0800	 pickout: 0.1744	 decision: 0.5940	 get_bound: 4.2471	 add_domain: 0.0645
Current lb:-0.5347301959991455
15300 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 199.33644342422485

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 6052] [2, 3619] [2, 169] [2, 7781] [2, 169] [3, 84] [3, 140] [2, 3260] [3, 91] [2, 169] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 205.14065551757812 with beta sum per layer: [0.0, 4.723085403442383, 473.3523864746094, 169.55990600585938]
alpha/beta optimization time: 3.8810946941375732
This batch time : update_bounds func: 4.2218	 prepare: 0.0485	 bound: 3.8816	 transfer: 0.2543	 finalize: 0.0361
Accumulated time: update_bounds func: 172.6470	 prepare: 1.8815	 bound: 158.6626	 transfer: 0.2543	 finalize: 2.2241
batch bounding time:  4.222904205322266
Current worst splitting domains [lb, ub] (depth):
[-0.53401,   inf] (53), [-0.53400,   inf] (85), [-0.53399,   inf] (57), [-0.53399,   inf] (67), [-0.53399,   inf] (55), [-0.53399,   inf] (75), [-0.53398,   inf] (65), [-0.53398,   inf] (73), [-0.53397,   inf] (61), [-0.53396,   inf] (67), [-0.53396,   inf] (51), [-0.53396,   inf] (63), [-0.53395,   inf] (79), [-0.53395,   inf] (67), [-0.53394,   inf] (51), [-0.53394,   inf] (73), [-0.53393,   inf] (73), [-0.53393,   inf] (57), [-0.53393,   inf] (55), [-0.53392,   inf] (49), 
length of domains: 7320
Total time: 5.3379	 pickout: 0.1846	 decision: 0.8725	 get_bound: 4.2237	 add_domain: 0.0571
Current lb:-0.5340064764022827
15700 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 204.68588495254517

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 140] [2, 1004] [2, 169] [2, 5715] [2, 169] [1, 5609] [2, 3260] [2, 3260] [2, 3619] [3, 91] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 205.07192993164062 with beta sum per layer: [0.0, 3.880415678024292, 484.2309265136719, 172.30538940429688]
alpha/beta optimization time: 3.882596731185913
This batch time : update_bounds func: 4.2194	 prepare: 0.0491	 bound: 3.8831	 transfer: 0.2483	 finalize: 0.0377
Accumulated time: update_bounds func: 176.8664	 prepare: 1.9305	 bound: 162.5457	 transfer: 0.2483	 finalize: 2.2619
batch bounding time:  4.2202770709991455
Current worst splitting domains [lb, ub] (depth):
[-0.53335,   inf] (53), [-0.53335,   inf] (71), [-0.53335,   inf] (65), [-0.53335,   inf] (71), [-0.53334,   inf] (73), [-0.53333,   inf] (73), [-0.53333,   inf] (67), [-0.53332,   inf] (63), [-0.53332,   inf] (61), [-0.53331,   inf] (61), [-0.53331,   inf] (65), [-0.53330,   inf] (55), [-0.53330,   inf] (61), [-0.53330,   inf] (73), [-0.53329,   inf] (63), [-0.53328,   inf] (61), [-0.53328,   inf] (81), [-0.53327,   inf] (73), [-0.53327,   inf] (77), [-0.53327,   inf] (81), 
length of domains: 7520
Total time: 5.0612	 pickout: 0.1864	 decision: 0.5908	 get_bound: 4.2214	 add_domain: 0.0627
Current lb:-0.5333524942398071
16100 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 209.75630235671997

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 140] [2, 7781] [2, 3619] [2, 3260] [1, 5609] [2, 5715] [3, 84] [2, 5715] [2, 3619] [3, 91] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 203.5946044921875 with beta sum per layer: [0.0, 3.9227616786956787, 486.8858337402344, 168.4376678466797]
alpha/beta optimization time: 3.889002799987793
This batch time : update_bounds func: 4.2262	 prepare: 0.0516	 bound: 3.8895	 transfer: 0.2494	 finalize: 0.0346
Accumulated time: update_bounds func: 181.0926	 prepare: 1.9821	 bound: 166.4352	 transfer: 0.2494	 finalize: 2.2965
batch bounding time:  4.227162837982178
Current worst splitting domains [lb, ub] (depth):
[-0.53262,   inf] (73), [-0.53262,   inf] (55), [-0.53261,   inf] (61), [-0.53261,   inf] (71), [-0.53260,   inf] (61), [-0.53260,   inf] (65), [-0.53260,   inf] (77), [-0.53260,   inf] (81), [-0.53259,   inf] (73), [-0.53259,   inf] (73), [-0.53258,   inf] (59), [-0.53258,   inf] (67), [-0.53258,   inf] (63), [-0.53258,   inf] (67), [-0.53257,   inf] (63), [-0.53257,   inf] (53), [-0.53257,   inf] (55), [-0.53257,   inf] (63), [-0.53257,   inf] (57), [-0.53257,   inf] (57), 
length of domains: 7720
Total time: 5.0557	 pickout: 0.1743	 decision: 0.5932	 get_bound: 4.2280	 add_domain: 0.0602
Current lb:-0.532617449760437
16500 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 214.82474493980408

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2273] [2, 3619] [3, 84] [2, 1299] [3, 84] [2, 1299] [2, 5715] [2, 3260] [3, 30] [3, 30] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 201.65476989746094 with beta sum per layer: [0.0, 3.3175208568573, 502.91571044921875, 168.23373413085938]
alpha/beta optimization time: 3.894775629043579
This batch time : update_bounds func: 4.2339	 prepare: 0.0481	 bound: 3.8953	 transfer: 0.2501	 finalize: 0.0391
Accumulated time: update_bounds func: 185.3265	 prepare: 2.0302	 bound: 170.3305	 transfer: 0.2501	 finalize: 2.3356
batch bounding time:  4.234702110290527
Current worst splitting domains [lb, ub] (depth):
[-0.53194,   inf] (63), [-0.53194,   inf] (81), [-0.53194,   inf] (81), [-0.53194,   inf] (71), [-0.53193,   inf] (55), [-0.53193,   inf] (51), [-0.53193,   inf] (63), [-0.53192,   inf] (75), [-0.53192,   inf] (69), [-0.53191,   inf] (61), [-0.53191,   inf] (49), [-0.53191,   inf] (61), [-0.53190,   inf] (69), [-0.53190,   inf] (67), [-0.53190,   inf] (61), [-0.53189,   inf] (63), [-0.53188,   inf] (53), [-0.53188,   inf] (67), [-0.53188,   inf] (67), [-0.53187,   inf] (81), 
length of domains: 7920
Total time: 5.3840	 pickout: 0.1894	 decision: 0.8989	 get_bound: 4.2358	 add_domain: 0.0599
Current lb:-0.5319430828094482
16900 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 220.21775269508362

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5715] [2, 1299] [2, 1675] [2, 3260] [2, 169] [2, 1612] [3, 91] [2, 7781] [2, 7781] [3, 84] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 203.71336364746094 with beta sum per layer: [0.0, 8.916421890258789, 444.3748474121094, 165.14501953125]
alpha/beta optimization time: 3.895047664642334
This batch time : update_bounds func: 4.2497	 prepare: 0.0507	 bound: 3.8957	 transfer: 0.2659	 finalize: 0.0360
Accumulated time: update_bounds func: 189.5761	 prepare: 2.0809	 bound: 174.2262	 transfer: 0.2659	 finalize: 2.3716
batch bounding time:  4.250492572784424
Current worst splitting domains [lb, ub] (depth):
[-0.53137,   inf] (55), [-0.53136,   inf] (57), [-0.53136,   inf] (59), [-0.53136,   inf] (67), [-0.53135,   inf] (67), [-0.53135,   inf] (81), [-0.53135,   inf] (61), [-0.53135,   inf] (75), [-0.53135,   inf] (75), [-0.53134,   inf] (63), [-0.53133,   inf] (67), [-0.53132,   inf] (59), [-0.53132,   inf] (67), [-0.53132,   inf] (61), [-0.53132,   inf] (73), [-0.53131,   inf] (57), [-0.53131,   inf] (57), [-0.53131,   inf] (77), [-0.53131,   inf] (59), [-0.53130,   inf] (59), 
length of domains: 8120
Total time: 5.0926	 pickout: 0.1873	 decision: 0.5963	 get_bound: 4.2513	 add_domain: 0.0578
Current lb:-0.5313652157783508
17300 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 225.32173371315002

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 3619] [2, 4884] [2, 1803] [2, 1299] [2, 3419] [2, 1299] [3, 140] [1, 5609] [2, 996] [2, 1299] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 203.40728759765625 with beta sum per layer: [0.0, 4.685100555419922, 487.18048095703125, 202.02317810058594]
alpha/beta optimization time: 3.894278049468994
This batch time : update_bounds func: 4.2294	 prepare: 0.0488	 bound: 3.8948	 transfer: 0.2466	 finalize: 0.0379
Accumulated time: update_bounds func: 193.8055	 prepare: 2.1297	 bound: 178.1210	 transfer: 0.2466	 finalize: 2.4095
batch bounding time:  4.230260848999023
Current worst splitting domains [lb, ub] (depth):
[-0.53084,   inf] (69), [-0.53084,   inf] (75), [-0.53084,   inf] (67), [-0.53084,   inf] (69), [-0.53083,   inf] (59), [-0.53083,   inf] (75), [-0.53083,   inf] (75), [-0.53082,   inf] (61), [-0.53082,   inf] (61), [-0.53082,   inf] (65), [-0.53081,   inf] (57), [-0.53081,   inf] (65), [-0.53080,   inf] (53), [-0.53079,   inf] (75), [-0.53079,   inf] (79), [-0.53079,   inf] (65), [-0.53078,   inf] (75), [-0.53078,   inf] (61), [-0.53078,   inf] (55), [-0.53078,   inf] (67), 
length of domains: 8320
Total time: 5.0841	 pickout: 0.1963	 decision: 0.5939	 get_bound: 4.2314	 add_domain: 0.0627
Current lb:-0.5308418869972229
17700 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 230.41578674316406

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 91] [1, 5609] [2, 7781] [2, 5715] [2, 1803] [2, 979] [2, 5715] [2, 1299] [2, 996] [2, 2894] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 203.9383544921875 with beta sum per layer: [0.0, 2.976539373397827, 492.35565185546875, 195.25392150878906]
alpha/beta optimization time: 3.9000802040100098
This batch time : update_bounds func: 4.2430	 prepare: 0.0511	 bound: 3.9006	 transfer: 0.2543	 finalize: 0.0356
Accumulated time: update_bounds func: 198.0485	 prepare: 2.1808	 bound: 182.0215	 transfer: 0.2543	 finalize: 2.4452
batch bounding time:  4.24382209777832
Current worst splitting domains [lb, ub] (depth):
[-0.53025,   inf] (85), [-0.53025,   inf] (57), [-0.53025,   inf] (73), [-0.53025,   inf] (69), [-0.53024,   inf] (75), [-0.53024,   inf] (55), [-0.53024,   inf] (57), [-0.53024,   inf] (67), [-0.53024,   inf] (51), [-0.53023,   inf] (63), [-0.53023,   inf] (51), [-0.53023,   inf] (53), [-0.53022,   inf] (71), [-0.53022,   inf] (81), [-0.53022,   inf] (75), [-0.53022,   inf] (69), [-0.53021,   inf] (69), [-0.53021,   inf] (83), [-0.53021,   inf] (75), [-0.53021,   inf] (67), 
length of domains: 8520
Total time: 5.4152	 pickout: 0.1810	 decision: 0.9310	 get_bound: 4.2446	 add_domain: 0.0585
Current lb:-0.5302512049674988
18100 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 235.8407392501831

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 1675] [2, 169] [2, 3260] [2, 7781] [3, 30] [2, 169] [2, 169] [3, 91] [2, 3170] [3, 84] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 202.90969848632812 with beta sum per layer: [0.0, 5.607493877410889, 475.1338806152344, 174.81063842773438]
alpha/beta optimization time: 3.895796298980713
This batch time : update_bounds func: 4.2355	 prepare: 0.0490	 bound: 3.8963	 transfer: 0.2508	 finalize: 0.0382
Accumulated time: update_bounds func: 202.2840	 prepare: 2.2297	 bound: 185.9178	 transfer: 0.2508	 finalize: 2.4833
batch bounding time:  4.236392259597778
Current worst splitting domains [lb, ub] (depth):
[-0.52970,   inf] (73), [-0.52970,   inf] (57), [-0.52970,   inf] (85), [-0.52970,   inf] (67), [-0.52970,   inf] (65), [-0.52970,   inf] (71), [-0.52969,   inf] (81), [-0.52969,   inf] (55), [-0.52968,   inf] (93), [-0.52968,   inf] (73), [-0.52968,   inf] (75), [-0.52968,   inf] (77), [-0.52967,   inf] (75), [-0.52967,   inf] (57), [-0.52967,   inf] (59), [-0.52967,   inf] (59), [-0.52967,   inf] (77), [-0.52967,   inf] (69), [-0.52966,   inf] (59), [-0.52966,   inf] (61), 
length of domains: 8720
Total time: 5.0809	 pickout: 0.1882	 decision: 0.5909	 get_bound: 4.2375	 add_domain: 0.0643
Current lb:-0.52969890832901
18500 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 240.93146634101868

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 3260] [2, 169] [2, 1675] [2, 3619] [3, 84] [2, 5715] [2, 1299] [2, 1803] [2, 92] [2, 1299] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 201.4791259765625 with beta sum per layer: [0.0, 4.16707706451416, 497.4640808105469, 174.78277587890625]
alpha/beta optimization time: 3.889385938644409
This batch time : update_bounds func: 4.2321	 prepare: 0.0498	 bound: 3.8899	 transfer: 0.2568	 finalize: 0.0344
Accumulated time: update_bounds func: 206.5161	 prepare: 2.2795	 bound: 189.8077	 transfer: 0.2568	 finalize: 2.5178
batch bounding time:  4.233034372329712
Current worst splitting domains [lb, ub] (depth):
[-0.52918,   inf] (65), [-0.52918,   inf] (63), [-0.52918,   inf] (73), [-0.52918,   inf] (55), [-0.52918,   inf] (81), [-0.52917,   inf] (71), [-0.52917,   inf] (79), [-0.52917,   inf] (83), [-0.52917,   inf] (59), [-0.52917,   inf] (75), [-0.52916,   inf] (65), [-0.52916,   inf] (61), [-0.52916,   inf] (81), [-0.52916,   inf] (67), [-0.52916,   inf] (75), [-0.52915,   inf] (65), [-0.52915,   inf] (63), [-0.52915,   inf] (61), [-0.52915,   inf] (51), [-0.52915,   inf] (61), 
length of domains: 8920
Total time: 5.0694	 pickout: 0.1819	 decision: 0.5939	 get_bound: 4.2338	 add_domain: 0.0597
Current lb:-0.5291802883148193
18900 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 246.011864900589

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 1803] [2, 5715] [2, 3260] [3, 84] [2, 1299] [2, 7781] [2, 1299] [1, 1944] [3, 91] [3, 30] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 201.3570556640625 with beta sum per layer: [0.0, 4.808640003204346, 501.14068603515625, 171.5749969482422]
alpha/beta optimization time: 3.9008734226226807
This batch time : update_bounds func: 4.2442	 prepare: 0.0499	 bound: 3.9014	 transfer: 0.2487	 finalize: 0.0430
Accumulated time: update_bounds func: 210.7603	 prepare: 2.3294	 bound: 193.7091	 transfer: 0.2487	 finalize: 2.5608
batch bounding time:  4.245640754699707
Current worst splitting domains [lb, ub] (depth):
[-0.52863,   inf] (69), [-0.52863,   inf] (63), [-0.52862,   inf] (65), [-0.52862,   inf] (69), [-0.52862,   inf] (65), [-0.52862,   inf] (67), [-0.52861,   inf] (49), [-0.52861,   inf] (59), [-0.52861,   inf] (73), [-0.52860,   inf] (61), [-0.52860,   inf] (65), [-0.52860,   inf] (63), [-0.52860,   inf] (55), [-0.52860,   inf] (61), [-0.52860,   inf] (73), [-0.52859,   inf] (61), [-0.52859,   inf] (67), [-0.52859,   inf] (75), [-0.52859,   inf] (69), [-0.52858,   inf] (79), 
length of domains: 9120
Total time: 5.4577	 pickout: 0.1873	 decision: 0.5946	 get_bound: 4.2467	 add_domain: 0.4291
Current lb:-0.5286339521408081
19300 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 251.47900938987732

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 7781] [3, 91] [2, 996] [3, 91] [2, 5715] [2, 6052] [2, 1612] [3, 91] [3, 30] [3, 140] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 202.4365997314453 with beta sum per layer: [0.0, 4.467998504638672, 501.6156005859375, 185.29953002929688]
alpha/beta optimization time: 3.890188217163086
This batch time : update_bounds func: 4.2325	 prepare: 0.0493	 bound: 3.8906	 transfer: 0.2563	 finalize: 0.0350
Accumulated time: update_bounds func: 214.9928	 prepare: 2.3787	 bound: 197.5997	 transfer: 0.2563	 finalize: 2.5958
batch bounding time:  4.233269929885864
Current worst splitting domains [lb, ub] (depth):
[-0.52813,   inf] (91), [-0.52813,   inf] (77), [-0.52813,   inf] (71), [-0.52813,   inf] (55), [-0.52813,   inf] (67), [-0.52813,   inf] (71), [-0.52813,   inf] (69), [-0.52812,   inf] (59), [-0.52812,   inf] (63), [-0.52812,   inf] (67), [-0.52811,   inf] (59), [-0.52811,   inf] (77), [-0.52811,   inf] (73), [-0.52811,   inf] (59), [-0.52810,   inf] (59), [-0.52810,   inf] (65), [-0.52810,   inf] (71), [-0.52809,   inf] (65), [-0.52809,   inf] (67), [-0.52809,   inf] (85), 
length of domains: 9320
Total time: 5.0629	 pickout: 0.1758	 decision: 0.5951	 get_bound: 4.2341	 add_domain: 0.0579
Current lb:-0.5281320810317993
19700 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 256.55032777786255

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 3541] [3, 30] [2, 1675] [2, 169] [2, 1675] [2, 1004] [1, 1944] [3, 140] [2, 7436] [2, 7781] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 202.0574188232422 with beta sum per layer: [0.0, 5.933114051818848, 504.87738037109375, 173.71205139160156]
alpha/beta optimization time: 3.9026811122894287
This batch time : update_bounds func: 4.2520	 prepare: 0.0544	 bound: 3.9034	 transfer: 0.2545	 finalize: 0.0384
Accumulated time: update_bounds func: 219.2448	 prepare: 2.4331	 bound: 201.5031	 transfer: 0.2545	 finalize: 2.6342
batch bounding time:  4.253296375274658
Current worst splitting domains [lb, ub] (depth):
[-0.52764,   inf] (57), [-0.52763,   inf] (77), [-0.52763,   inf] (61), [-0.52763,   inf] (55), [-0.52762,   inf] (65), [-0.52762,   inf] (65), [-0.52762,   inf] (65), [-0.52762,   inf] (67), [-0.52762,   inf] (55), [-0.52761,   inf] (63), [-0.52761,   inf] (81), [-0.52761,   inf] (59), [-0.52761,   inf] (69), [-0.52761,   inf] (73), [-0.52761,   inf] (71), [-0.52761,   inf] (79), [-0.52760,   inf] (67), [-0.52760,   inf] (51), [-0.52760,   inf] (63), [-0.52760,   inf] (65), 
length of domains: 9520
Total time: 5.1061	 pickout: 0.1893	 decision: 0.5995	 get_bound: 4.2544	 add_domain: 0.0630
Current lb:-0.5276380777359009
20100 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 261.6700031757355

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 169] [2, 1675] [3, 91] [2, 3619] [2, 1803] [3, 91] [3, 91] [2, 5715] [2, 7781] [2, 5715] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 201.71929931640625 with beta sum per layer: [0.0, 5.653355598449707, 502.2861328125, 189.46237182617188]
alpha/beta optimization time: 3.885770559310913
This batch time : update_bounds func: 4.2270	 prepare: 0.0497	 bound: 3.8863	 transfer: 0.2552	 finalize: 0.0346
Accumulated time: update_bounds func: 223.4718	 prepare: 2.4828	 bound: 205.3893	 transfer: 0.2552	 finalize: 2.6687
batch bounding time:  4.227925539016724
Current worst splitting domains [lb, ub] (depth):
[-0.52718,   inf] (79), [-0.52717,   inf] (73), [-0.52716,   inf] (53), [-0.52715,   inf] (63), [-0.52715,   inf] (55), [-0.52715,   inf] (69), [-0.52715,   inf] (69), [-0.52715,   inf] (67), [-0.52713,   inf] (89), [-0.52713,   inf] (73), [-0.52713,   inf] (75), [-0.52713,   inf] (71), [-0.52712,   inf] (71), [-0.52712,   inf] (65), [-0.52712,   inf] (57), [-0.52711,   inf] (67), [-0.52711,   inf] (51), [-0.52710,   inf] (73), [-0.52710,   inf] (79), [-0.52710,   inf] (83), 
length of domains: 9720
Total time: 5.0672	 pickout: 0.1856	 decision: 0.5925	 get_bound: 4.2288	 add_domain: 0.0603
Current lb:-0.5271775126457214
20500 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 266.74685192108154

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5866] [2, 1299] [2, 2894] [2, 2894] [2, 7781] [2, 5715] [3, 91] [2, 5715] [2, 3101] [2, 1675] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 202.6362762451172 with beta sum per layer: [0.0, 5.1082048416137695, 526.4989013671875, 153.86367797851562]
alpha/beta optimization time:/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:25: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1627336316785/work/torch/csrc/utils/tensor_numpy.cpp:143.)
  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))
 3.9340062141418457
This batch time : update_bounds func: 4.2973	 prepare: 0.0486	 bound: 3.9346	 transfer: 0.2612	 finalize: 0.0516
Accumulated time: update_bounds func: 227.7691	 prepare: 2.5314	 bound: 209.3240	 transfer: 0.2612	 finalize: 2.7203
batch bounding time:  4.2984418869018555
Current worst splitting domains [lb, ub] (depth):
[-0.52666,   inf] (91), [-0.52666,   inf] (67), [-0.52666,   inf] (69), [-0.52665,   inf] (57), [-0.52665,   inf] (83), [-0.52665,   inf] (49), [-0.52664,   inf] (91), [-0.52664,   inf] (83), [-0.52664,   inf] (73), [-0.52664,   inf] (59), [-0.52664,   inf] (69), [-0.52664,   inf] (77), [-0.52664,   inf] (57), [-0.52664,   inf] (73), [-0.52663,   inf] (67), [-0.52663,   inf] (63), [-0.52663,   inf] (67), [-0.52663,   inf] (87), [-0.52663,   inf] (85), [-0.52662,   inf] (77), 
length of domains: 9920
Total time: 5.5362	 pickout: 0.1991	 decision: 0.9648	 get_bound: 4.2996	 add_domain: 0.0726
Current lb:-0.5266569256782532
20900 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 272.2950999736786

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 3541] [2, 7781] [2, 3260] [3, 73] [2, 3260] [2, 3172] [2, 3101] [2, 6052] [2, 7781] [3, 140] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 201.53366088867188 with beta sum per layer: [0.0, 6.122448921203613, 536.7389526367188, 167.25010681152344]
alpha/beta optimization time: 3.914907932281494
This batch time : update_bounds func: 4.2739	 prepare: 0.0819	 bound: 3.9156	 transfer: 0.2385	 finalize: 0.0364
Accumulated time: update_bounds func: 232.0430	 prepare: 2.6133	 bound: 213.2396	 transfer: 0.2385	 finalize: 2.7567
batch bounding time:  4.2751054763793945
Current worst splitting domains [lb, ub] (depth):
[-0.52626,   inf] (67), [-0.52625,   inf] (53), [-0.52625,   inf] (59), [-0.52625,   inf] (59), [-0.52625,   inf] (77), [-0.52625,   inf] (53), [-0.52624,   inf] (71), [-0.52623,   inf] (65), [-0.52623,   inf] (87), [-0.52622,   inf] (55), [-0.52622,   inf] (63), [-0.52622,   inf] (89), [-0.52622,   inf] (51), [-0.52622,   inf] (69), [-0.52621,   inf] (59), [-0.52621,   inf] (83), [-0.52621,   inf] (61), [-0.52621,   inf] (69), [-0.52621,   inf] (77), [-0.52621,   inf] (65), 
length of domains: 10120
Total time: 5.1650	 pickout: 0.2086	 decision: 0.6153	 get_bound: 4.2761	 add_domain: 0.0650
Current lb:-0.5262618660926819
21300 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 277.47488617897034

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5715] [2, 7436] [3, 84] [2, 6052] [2, 5866] [3, 140] [2, 7781] [2, 5715] [2, 3101] [2, 169] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 201.03567504882812 with beta sum per layer: [0.0, 5.654261589050293, 504.4893798828125, 191.18357849121094]
alpha/beta optimization time: 3.8894166946411133
This batch time : update_bounds func: 4.2372	 prepare: 0.0509	 bound: 3.8899	 transfer: 0.2588	 finalize: 0.0362
Accumulated time: update_bounds func: 236.2802	 prepare: 2.6643	 bound: 217.1295	 transfer: 0.2588	 finalize: 2.7929
batch bounding time:  4.237955570220947
Current worst splitting domains [lb, ub] (depth):
[-0.52581,   inf] (71), [-0.52581,   inf] (71), [-0.52581,   inf] (69), [-0.52581,   inf] (61), [-0.52581,   inf] (61), [-0.52581,   inf] (69), [-0.52581,   inf] (57), [-0.52580,   inf] (89), [-0.52580,   inf] (85), [-0.52580,   inf] (81), [-0.52580,   inf] (61), [-0.52580,   inf] (83), [-0.52579,   inf] (75), [-0.52578,   inf] (65), [-0.52578,   inf] (69), [-0.52578,   inf] (79), [-0.52578,   inf] (71), [-0.52578,   inf] (77), [-0.52578,   inf] (63), [-0.52578,   inf] (57), 
length of domains: 10320
Total time: 5.0810	 pickout: 0.1828	 decision: 0.6016	 get_bound: 4.2387	 add_domain: 0.0580
Current lb:-0.5258134603500366
21700 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 282.5636396408081

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([200, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 7781] [2, 7781] [2, 1299] [2, 2894] [2, 5715] [2, 5715] [2, 3619] [2, 3101] [1, 1944] [2, 1299] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 202.1557159423828 with beta sum per layer: [0.0, 3.578716993331909, 504.3975830078125, 175.55184936523438]
alpha/beta optimization time: 3.905644178390503
This batch time : update_bounds func: 4.2488	 prepare: 0.0544	 bound: 3.9062	 transfer: 0.2488	 finalize: 0.0380
Accumulated time: update_bounds func: 240.5290	 prepare: 2.7186	 bound: 221.0357	 transfer: 0.2488	 finalize: 2.8309
batch bounding time:  4.250002861022949
Current worst splitting domains [lb, ub] (depth):
[-0.52538,   inf] (61), [-0.52538,   inf] (61), [-0.52538,   inf] (71), [-0.52537,   inf] (67), [-0.52537,   inf] (79), [-0.52537,   inf] (71), [-0.52537,   inf] (83), [-0.52537,   inf] (53), [-0.52536,   inf] (59), [-0.52536,   inf] (55), [-0.52536,   inf] (67), [-0.52536,   inf] (69), [-0.52535,   inf] (71), [-0.52535,   inf] (65), [-0.52534,   inf] (61), [-0.52534,   inf] (97), [-0.52534,   inf] (73), [-0.52534,   inf] (81), [-0.52534,   inf] (55), [-0.52534,   inf] (63), 
length of domains: 10520
Total time: 5.1279	 pickout: 0.1982	 decision: 0.6165	 get_bound: 4.2510	 add_domain: 0.0621
Current lb:-0.5253821015357971
22100 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Time out!!!!!!!!
Image 0 against label 9 verification end, Time cost: 288.4705011844635
Result: unknown in 319.3233 seconds


[[    0.             0.0000001     48.             5.01337647
      0.        ]
 [    0.             0.0000001     16.             1.59199023
      1.        ]
 [    0.             0.0000001     32.             2.41717029
      3.        ]
 [    0.             0.0000001     16.             1.63763261
      4.        ]
 [    0.             0.0000001     32.             2.40119815
      5.        ]
 [    0.             4.08387613     0.             0.00029778
      6.        ]
 [    0.             1.04045987     0.             0.00050664
      7.        ]
 [    0.             0.21656902     0.             0.00028682
      8.        ]
 [    0.            -0.5253821  22100.           288.47050118
      9.        ]]
############# Summary #############
Final verified acc: 0.0% [total 1 examples]
Total verification count: 1 , total verified safe: 0 , verified unsafe: 0 , timeout: 1
mean time [total:1]: 301.5329601764679
mean time [cnt:1]: 301.5329601764679
max time 319.32333517074585
unknown (total 1): [0]
