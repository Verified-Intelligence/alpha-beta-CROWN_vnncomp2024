Building native CUDA modules...
/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
  csv_name: cifar2020_instances.csv
  onnx_path: null
  vnnlib_path: null
  results_file: null
  root_path: ../../../../../vnncomp2021/benchmarks/cifar2020
model:
  path: null
  name: mnist_9_200
data:
  start: 44
  end: 45
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR
  data_filter_path: null
specification:
  type: lp
  norm: .inf
  epsilon: null
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 200
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.01
    lr_decay: 0.98
    optimizer: adam
    iteration: 50
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 360
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 10
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:42:00 2022 on ubuntu
saving results to vnn-comp_[cifar2020_instances]_start=44_end=45_iter=50_b=200_timeout=360_branching=kfsb-max-10_lra-init=0.1_lra=0.01_lrb=0.01_PGD=before.npz
customized start/end sample from 44 to 45

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
##### PGD attack: True label: 9, Tested against: [0, 1, 2, 3, 4, 5, 6, 7, 8] ######
pgd prediction: tensor([ 5.4905,  0.2637,  2.7543, -1.0234, -2.4740, -2.1644, -0.8689,  2.3453,
         0.1441,  5.8187], device='cuda:0', grad_fn=<SqueezeBackward1>)
attack margin tensor([0.3282, 5.5550, 3.0644, 6.8421, 8.2927, 7.9831, 6.6876, 3.4734, 5.6746,
           inf], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[ 4.9294e+00,  3.5428e-01,  2.6970e+00, -1.0065e+00, -2.6282e+00,
         -2.0981e+00, -8.1195e-01,  2.3155e+00, -5.0923e-03,  6.1863e+00]],
       device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-0.3737,  4.0945,  1.3643,  5.3294,  6.4459,  6.3959,  5.1015,  1.8886,
          4.1377]], device='cuda:0') None
best_l after optimization: -35.77345657348633 with beta sum per layer: []
alpha/beta optimization time: 11.711488962173462
initial alpha-CROWN bounds: tensor([[-0.2462,  4.2123,  1.5379,  5.4944,  6.6347,  6.5577,  5.2523,  2.0259,
          4.3044]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.2462, device='cuda:0', grad_fn=<MinBackward1>)
##### [0] True label: 9, Tested against: 0, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_50_eps_0.00784_n1.vnnlib ######
Model prediction is: tensor([[ 4.9294e+00,  3.5428e-01,  2.6970e+00, -1.0065e+00, -2.6282e+00,
         -2.0981e+00, -8.1195e-01,  2.3155e+00, -5.0923e-03,  6.1863e+00]],
       device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /12 start_node /13
setting alpha for layer /12 start_node /15
setting alpha for layer /12 start_node /18
not setting layer /12 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 32, 32, 32]) != torch.Size([2, 9, 1, 32, 32, 32]))
setting alpha for layer /14 start_node /15
setting alpha for layer /14 start_node /18
not setting layer /14 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /16 start_node /18
not setting layer /16 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /19 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /11 torch.Size([1, 32, 32, 32])
1 /13 torch.Size([1, 32, 16, 16])
2 /15 torch.Size([1, 128, 8, 8])
3 /18 torch.Size([1, 250])
best_l after optimization: 0.24601960182189941 with beta sum per layer: []
alpha/beta optimization time: 2.283738374710083
alpha-CROWN with fixed intermediate bounds: tensor([[-0.2460]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.24601960182189941
layer 0 size torch.Size([32768]) unstable 1269
layer 1 size torch.Size([8192]) unstable 629
layer 2 size torch.Size([8192]) unstable 488
layer 3 size torch.Size([250]) unstable 34
-----------------
# of unstable neurons: 2420
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 32, 32]) pre split depth:  4
batch:  torch.Size([1, 32, 32, 32]) post split depth:  4
splitting decisions: 
split level 0: [3, 78] 
split level 1: [3, 184] 
split level 2: [3, 112] 
split level 3: [3, 24] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -4.008033752441406 with beta sum per layer: [0.0, 0.0, 0.0, 0.83642578125]
alpha/beta optimization time: 0.713953971862793
This batch time : update_bounds func: 0.7247	 prepare: 0.0030	 bound: 0.7145	 transfer: 0.0057	 finalize: 0.0014
Accumulated time: update_bounds func: 0.7247	 prepare: 0.0030	 bound: 0.7145	 transfer: 0.0057	 finalize: 0.0014
batch bounding time:  0.7249014377593994
Current worst splitting domains [lb, ub] (depth):
[-0.19108,   inf] (5), [-0.09849,   inf] (5), 
length of domains: 2
Total time: 0.7919	 pickout: 0.0012	 decision: 0.0634	 get_bound: 0.7271	 add_domain: 0.0002
Current lb:-0.1910766363143921
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.02735447883606

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2, 32, 32, 32]) pre split depth:  3
batch:  torch.Size([2, 32, 32, 32]) post split depth:  3
splitting decisions: 
split level 0: [3, 81] [3, 81] 
split level 1: [3, 17] [3, 17] 
split level 2: [3, 97] [3, 97] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -2.212911605834961 with beta sum per layer: [0.0, 0.0, 0.0, 3.0156426429748535]
alpha/beta optimization time: 0.7049589157104492
This batch time : update_bounds func: 0.7154	 prepare: 0.0029	 bound: 0.7053	 transfer: 0.0059	 finalize: 0.0013
Accumulated time: update_bounds func: 1.4401	 prepare: 0.0059	 bound: 1.4197	 transfer: 0.0059	 finalize: 0.0027
batch bounding time:  0.7155489921569824
Current worst splitting domains [lb, ub] (depth):
[-0.09928,   inf] (9), [-0.06630,   inf] (9), 
length of domains: 2
Total time: 0.7845	 pickout: 0.0017	 decision: 0.0651	 get_bound: 0.7175	 add_domain: 0.0002
Current lb:-0.09927575290203094
32 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.812209844589233

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2, 32, 32, 32]) pre split depth:  3
batch:  torch.Size([2, 32, 32, 32]) post split depth:  3
splitting decisions: 
split level 0: [3, 115] [3, 115] 
split level 1: [2, 5994] [2, 5994] 
split level 2: [3, 15] [3, 15] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.08136044442653656 with beta sum per layer: [0.0, 0.0, 1.071048617362976, 3.573701858520508]
alpha/beta optimization time: 0.7132482528686523
This batch time : update_bounds func: 0.7227	 prepare: 0.0030	 bound: 0.7136	 transfer: 0.0047	 finalize: 0.0013
Accumulated time: update_bounds func: 2.1628	 prepare: 0.0089	 bound: 2.1333	 transfer: 0.0047	 finalize: 0.0040
batch bounding time:  0.7228667736053467
Current worst splitting domains [lb, ub] (depth):
[-0.06455,   inf] (13), [-0.06373,   inf] (13), [-0.02800,   inf] (13), [-0.02641,   inf] (13), [-0.02318,   inf] (13), [-0.02239,   inf] (13), 
length of domains: 6
Total time: 0.7916	 pickout: 0.0017	 decision: 0.0645	 get_bound: 0.7249	 add_domain: 0.0005
Current lb:-0.064545176923275
48 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.604083061218262

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([6, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([6, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5993] [2, 5993] [2, 5993] [2, 5993] [2, 7462] [3, 52] 
regular batch size: 2*6, diving batch size 1*0
best_l after optimization: 0.2069767713546753 with beta sum per layer: [0.0, 0.0, 2.607591152191162, 2.389139413833618]
alpha/beta optimization time: 0.7059571743011475
This batch time : update_bounds func: 0.7137	 prepare: 0.0028	 bound: 0.7063	 transfer: 0.0033	 finalize: 0.0013
Accumulated time: update_bounds func: 2.8765	 prepare: 0.0117	 bound: 2.8396	 transfer: 0.0033	 finalize: 0.0053
batch bounding time:  0.7138900756835938
Current worst splitting domains [lb, ub] (depth):
[-0.05599,   inf] (15), [-0.05540,   inf] (15), [-0.03152,   inf] (15), [-0.03081,   inf] (15), [-0.01826,   inf] (15), [-0.01653,   inf] (15), [-0.00859,   inf] (15), 
length of domains: 7
Total time: 0.7889	 pickout: 0.0038	 decision: 0.0707	 get_bound: 0.7139	 add_domain: 0.0005
Current lb:-0.05599450320005417
60 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.393266916275024

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([7, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([7, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 787] [2, 787] [2, 787] [2, 787] [3, 52] [2, 7461] [2, 5993] 
regular batch size: 2*7, diving batch size 1*0
best_l after optimization: 0.15377569198608398 with beta sum per layer: [0.0, 0.0, 3.8639731407165527, 2.5125975608825684]
alpha/beta optimization time: 0.7129776477813721
This batch time : update_bounds func: 0.7215	 prepare: 0.0031	 bound: 0.7133	 transfer: 0.0037	 finalize: 0.0014
Accumulated time: update_bounds func: 3.5980	 prepare: 0.0148	 bound: 3.5529	 transfer: 0.0037	 finalize: 0.0067
batch bounding time:  0.7216694355010986
Current worst splitting domains [lb, ub] (depth):
[-0.05446,   inf] (17), [-0.05368,   inf] (17), [-0.02699,   inf] (17), [-0.02605,   inf] (17), [-0.01047,   inf] (17), [-0.00890,   inf] (17), [-0.00794,   inf] (17), 
length of domains: 7
Total time: 0.8000	 pickout: 0.0043	 decision: 0.0735	 get_bound: 0.7217	 add_domain: 0.0005
Current lb:-0.05445981025695801
74 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.193606376647949

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([7, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([7, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 7461] [3, 52] [2, 7462] [3, 52] [2, 787] [3, 52] [2, 7462] 
regular batch size: 2*7, diving batch size 1*0
best_l after optimization: 0.12144279479980469 with beta sum per layer: [0.0, 0.0, 3.7974894046783447, 1.8791930675506592]
alpha/beta optimization time: 0.7138347625732422
This batch time : update_bounds func: 0.7227	 prepare: 0.0031	 bound: 0.7141	 transfer: 0.0040	 finalize: 0.0014
Accumulated time: update_bounds func: 4.3207	 prepare: 0.0178	 bound: 4.2670	 transfer: 0.0040	 finalize: 0.0081
batch bounding time:  0.7228248119354248
Current worst splitting domains [lb, ub] (depth):
[-0.04978,   inf] (19), [-0.03513,   inf] (19), [-0.02943,   inf] (19), [-0.02631,   inf] (19), [-0.02490,   inf] (19), [-0.00882,   inf] (19), [-0.00665,   inf] (19), [-0.00284,   inf] (19), 
length of domains: 8
Total time: 0.7998	 pickout: 0.0042	 decision: 0.0721	 get_bound: 0.7229	 add_domain: 0.0006
Current lb:-0.04977727308869362
88 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.9937498569488525

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 7462] [2, 7461] [2, 7461] [3, 52] [2, 7461] [3, 52] [2, 7461] [2, 7461] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.09361699223518372 with beta sum per layer: [0.0, 0.0, 5.0320844650268555, 2.542462110519409]
alpha/beta optimization time: 0.7156503200531006
This batch time : update_bounds func: 0.7248	 prepare: 0.0033	 bound: 0.7160	 transfer: 0.0041	 finalize: 0.0013
Accumulated time: update_bounds func: 5.0454	 prepare: 0.0211	 bound: 4.9830	 transfer: 0.0041	 finalize: 0.0093
batch bounding time:  0.7249259948730469
Current worst splitting domains [lb, ub] (depth):
[-0.04786,   inf] (21), [-0.03058,   inf] (21), [-0.02477,   inf] (21), [-0.01975,   inf] (21), [-0.00970,   inf] (21), [-0.00727,   inf] (21), [-0.00591,   inf] (21), [-0.00266,   inf] (21), [-0.00215,   inf] (21), [-0.00190,   inf] (21), 
length of domains: 10
Total time: 0.8049	 pickout: 0.0047	 decision: 0.0744	 get_bound: 0.7250	 add_domain: 0.0008
Current lb:-0.047856081277132034
104 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.798915147781372

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([10, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([10, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 52] [3, 134] [3, 134] [3, 52] [3, 52] [3, 134] [3, 134] [3, 134] [3, 134] [2, 7462] 
regular batch size: 2*10, diving batch size 1*0
best_l after optimization: -0.03909962251782417 with beta sum per layer: [0.0, 0.0, 5.81026554107666, 1.9105556011199951]
alpha/beta optimization time: 0.7309558391571045
This batch time : update_bounds func: 0.7437	 prepare: 0.0038	 bound: 0.7313	 transfer: 0.0071	 finalize: 0.0015
Accumulated time: update_bounds func: 5.7892	 prepare: 0.0249	 bound: 5.7143	 transfer: 0.0071	 finalize: 0.0109
batch bounding time:  0.7438898086547852
Current worst splitting domains [lb, ub] (depth):
[-0.02885,   inf] (23), [-0.02462,   inf] (23), [-0.02415,   inf] (23), [-0.01822,   inf] (23), [-0.00027,   inf] (23), [-0.00014,   inf] (23), 
length of domains: 6
Total time: 0.8295	 pickout: 0.0059	 decision: 0.0791	 get_bound: 0.7440	 add_domain: 0.0005
Current lb:-0.028849512338638306
124 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.628825426101685

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([6, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([6, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 134] [3, 134] [2, 369] [2, 369] [3, 134] [3, 134] 
regular batch size: 2*6, diving batch size 1*0
best_l after optimization: 0.0015405556187033653 with beta sum per layer: [0.0, 0.0, 2.5018868446350098, 1.1465964317321777]
alpha/beta optimization time: 0.7187790870666504
This batch time : update_bounds func: 0.7300	 prepare: 0.0029	 bound: 0.7191	 transfer: 0.0065	 finalize: 0.0014
Accumulated time: update_bounds func: 6.5192	 prepare: 0.0278	 bound: 6.4334	 transfer: 0.0065	 finalize: 0.0123
batch bounding time:  0.7302634716033936
Current worst splitting domains [lb, ub] (depth):
[-0.02246,   inf] (25), [-0.01985,   inf] (25), [-0.01802,   inf] (25), [-0.01372,   inf] (25), [-0.00036,   inf] (25), 
length of domains: 5
Total time: 0.8056	 pickout: 0.0038	 decision: 0.0709	 get_bound: 0.7303	 add_domain: 0.0006
Current lb:-0.022462094202637672
136 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.434842109680176

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([5, 32, 32, 32]) pre split depth:  2
batch:  torch.Size([5, 32, 32, 32]) post split depth:  2
splitting decisions: 
split level 0: [2, 369] [2, 7462] [2, 369] [2, 7462] [2, 7462] 
split level 1: [2, 5355] [2, 5355] [2, 5355] [2, 5355] [2, 5389] 
regular batch size: 2*10, diving batch size 1*0
best_l after optimization: -0.09457206726074219 with beta sum per layer: [0.0, 0.0, 1.9621580839157104, 1.978653907775879]
alpha/beta optimization time: 0.7311973571777344
This batch time : update_bounds func: 0.7465	 prepare: 0.0036	 bound: 0.7315	 transfer: 0.0098	 finalize: 0.0015
Accumulated time: update_bounds func: 7.2657	 prepare: 0.0314	 bound: 7.1650	 transfer: 0.0098	 finalize: 0.0138
batch bounding time:  0.7467081546783447
Current worst splitting domains [lb, ub] (depth):
[-0.01698,   inf] (28), [-0.01696,   inf] (28), [-0.01217,   inf] (28), [-0.01071,   inf] (28), 
length of domains: 4
Total time: 0.8234	 pickout: 0.0039	 decision: 0.0703	 get_bound: 0.7487	 add_domain: 0.0005
Current lb:-0.01698102243244648
156 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.258572340011597

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 32, 32, 32]) pre split depth:  2
batch:  torch.Size([4, 32, 32, 32]) post split depth:  2
splitting decisions: 
split level 0: [2, 5389] [2, 5389] [2, 5389] [2, 5389] 
split level 1: [2, 3594] [2, 3594] [2, 3594] [2, 3594] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.036317963153123856 with beta sum per layer: [0.0, 0.0, 0.05962417647242546, 2.0984139442443848]
alpha/beta optimization time: 0.720365047454834
This batch time : update_bounds func: 0.7306	 prepare: 0.0031	 bound: 0.7207	 transfer: 0.0055	 finalize: 0.0013
Accumulated time: update_bounds func: 7.9963	 prepare: 0.0345	 bound: 7.8857	 transfer: 0.0055	 finalize: 0.0151
batch bounding time:  0.7308213710784912
Current worst splitting domains [lb, ub] (depth):
[-0.00868,   inf] (31), [-0.00839,   inf] (31), [-0.00546,   inf] (31), [-0.00531,   inf] (31), [-0.00309,   inf] (31), [-0.00185,   inf] (31), [-0.00045,   inf] (31), 
length of domains: 7
Total time: 0.8037	 pickout: 0.0029	 decision: 0.0676	 get_bound: 0.7325	 add_domain: 0.0007
Current lb:-0.008677395060658455
172 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.062556028366089

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([7, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([7, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5986] [2, 5986] [2, 5986] [2, 5986] [2, 5986] [2, 5986] [2, 5986] 
regular batch size: 2*7, diving batch size 1*0
best_l after optimization: -0.03496638685464859 with beta sum per layer: [0.0, 0.0, 0.14460694789886475, 1.5766834020614624]
alpha/beta optimization time: 0.7162721157073975
This batch time : update_bounds func: 0.7248	 prepare: 0.0030	 bound: 0.7166	 transfer: 0.0038	 finalize: 0.0013
Accumulated time: update_bounds func: 8.7211	 prepare: 0.0375	 bound: 8.6022	 transfer: 0.0038	 finalize: 0.0164
batch bounding time:  0.7249143123626709
Current worst splitting domains [lb, ub] (depth):
[-0.00426,   inf] (33), [-0.00399,   inf] (33), [-0.00123,   inf] (33), [-0.00105,   inf] (33), 
length of domains: 4
Total time: 0.8026	 pickout: 0.0044	 decision: 0.0728	 get_bound: 0.7250	 add_domain: 0.0004
Current lb:-0.00426061637699604
186 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.865498781204224

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 32, 32, 32]) pre split depth:  2
batch:  torch.Size([4, 32, 32, 32]) post split depth:  2
splitting decisions: 
split level 0: [2, 5932] [2, 5932] [2, 5932] [2, 5932] 
split level 1: [2, 2793] [2, 2793] [2, 7331] [2, 7331] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -0.20295333862304688 with beta sum per layer: [0.0, 0.0, 0.17711040377616882, 0.0]
alpha/beta optimization time: 0.010075569152832031
This batch time : update_bounds func: 0.0189	 prepare: 0.0032	 bound: 0.0104	 transfer: 0.0041	 finalize: 0.0013
Accumulated time: update_bounds func: 8.7400	 prepare: 0.0407	 bound: 8.6126	 transfer: 0.0041	 finalize: 0.0177
batch bounding time:  0.01900959014892578
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0907	 pickout: 0.0028	 decision: 0.0672	 get_bound: 0.0207	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 12.956592798233032

Image 0 against label 0 verification end, Time cost: 13.036700963973999
##### [0] True label: 9, Tested against: 1, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_50_eps_0.00784_n1.vnnlib ######
init opt crown verified for label 1 with bound 4.212304592132568
Image 0 against label 1 verification end, Time cost: 0.00032138824462890625
##### [0] True label: 9, Tested against: 2, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_50_eps_0.00784_n1.vnnlib ######
init opt crown verified for label 2 with bound 1.5378952026367188
Image 0 against label 2 verification end, Time cost: 0.00031113624572753906
##### [0] True label: 9, Tested against: 3, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_50_eps_0.00784_n1.vnnlib ######
init opt crown verified for label 3 with bound 5.494441986083984
Image 0 against label 3 verification end, Time cost: 0.000301361083984375
##### [0] True label: 9, Tested against: 4, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_50_eps_0.00784_n1.vnnlib ######
init opt crown verified for label 4 with bound 6.634695529937744
Image 0 against label 4 verification end, Time cost: 0.00030231475830078125
##### [0] True label: 9, Tested against: 5, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_50_eps_0.00784_n1.vnnlib ######
init opt crown verified for label 5 with bound 6.557673454284668
Image 0 against label 5 verification end, Time cost: 0.0003046989440917969
##### [0] True label: 9, Tested against: 6, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_50_eps_0.00784_n1.vnnlib ######
init opt crown verified for label 6 with bound 5.252328395843506
Image 0 against label 6 verification end, Time cost: 0.00029921531677246094
##### [0] True label: 9, Tested against: 7, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_50_eps_0.00784_n1.vnnlib ######
init opt crown verified for label 7 with bound 2.0258960723876953
Image 0 against label 7 verification end, Time cost: 0.00029921531677246094
##### [0] True label: 9, Tested against: 8, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_50_eps_0.00784_n1.vnnlib ######
init opt crown verified for label 8 with bound 4.304388999938965
Image 0 against label 8 verification end, Time cost: 0.0003063678741455078
Result: safe-bab in 32.0956 seconds


[[  0.           0.0000001  202.          13.03670096   0.        ]
 [  0.           4.21230459   0.           0.00032139   1.        ]
 [  0.           1.5378952    0.           0.00031114   2.        ]
 [  0.           5.49444199   0.           0.00030136   3.        ]
 [  0.           6.63469553   0.           0.00030231   4.        ]
 [  0.           6.55767345   0.           0.0003047    5.        ]
 [  0.           5.2523284    0.           0.00029922   6.        ]
 [  0.           2.02589607   0.           0.00029922   7.        ]
 [  0.           4.304389     0.           0.00030637   8.        ]]
############# Summary #############
Final verified acc: 100.0% [total 1 examples]
Total verification count:/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:25: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1627336316785/work/torch/csrc/utils/tensor_numpy.cpp:143.)
  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))
 1 , total verified safe: 1 , verified unsafe: 0 , timeout: 0
mean time [total:1]: 13.039146661758423
mean time [cnt:1]: 13.039146661758423
max time 32.095614194869995
safe-bab (total 1): [0]
