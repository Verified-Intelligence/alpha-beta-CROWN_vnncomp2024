Building native CUDA modules...
/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
  csv_name: cifar2020_instances.csv
  onnx_path: null
  vnnlib_path: null
  results_file: null
  root_path: ../../../../../vnncomp2021/benchmarks/cifar2020
model:
  path: null
  name: mnist_9_200
data:
  start: 27
  end: 28
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR
  data_filter_path: null
specification:
  type: lp
  norm: .inf
  epsilon: null
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 200
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.01
    lr_decay: 0.98
    optimizer: adam
    iteration: 50
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 360
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 10
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:41:17 2022 on ubuntu
saving results to vnn-comp_[cifar2020_instances]_start=27_end=28_iter=50_b=200_timeout=360_branching=kfsb-max-10_lra-init=0.1_lra=0.01_lrb=0.01_PGD=before.npz
customized start/end sample from 27 to 28

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
##### PGD attack: True label: 6, Tested against: [0, 1, 2, 3, 4, 5, 7, 8, 9] ######
pgd prediction: tensor([-0.7417, -1.6642,  0.6819,  2.6587,  0.7492,  1.8953,  2.9896,  0.7911,
        -4.0657, -2.4890], device='cuda:0', grad_fn=<SqueezeBackward1>)
attack margin tensor([3.7313, 4.6538, 2.3077, 0.3309, 2.2404, 1.0943,    inf, 2.1985, 7.0553,
        5.4786], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[-0.7880, -1.5258,  0.6233,  2.5660,  0.7377,  1.8136,  3.5006,  0.7722,
         -4.2142, -2.3631]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 2.0784,  2.5298,  0.8583, -0.5400,  1.0010, -0.0298,  0.2632,  5.0855,
          3.2775]], device='cuda:0') None
best_l after optimization: -16.700538635253906 with beta sum per layer: []
alpha/beta optimization time: 12.088379859924316
initial alpha-CROWN bounds: tensor([[ 2.2484,  2.8228,  1.0894, -0.3750,  1.2137,  0.1658,  0.5278,  5.4074,
          3.6001]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.3750, device='cuda:0', grad_fn=<MinBackward1>)
##### [0] True label: 6, Tested against: 0, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_30_eps_0.00784_n1.vnnlib ######
init opt crown verified for label 0 with bound 2.248434543609619
Image 0 against label 0 verification end, Time cost: 0.0003173351287841797
##### [0] True label: 6, Tested against: 1, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_30_eps_0.00784_n1.vnnlib ######
init opt crown verified for label 1 with bound 2.8228282928466797
Image 0 against label 1 verification end, Time cost: 0.0003285408020019531
##### [0] True label: 6, Tested against: 2, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_30_eps_0.00784_n1.vnnlib ######
init opt crown verified for label 2 with bound 1.089444875717163
Image 0 against label 2 verification end, Time cost: 0.0003178119659423828
##### [0] True label: 6, Tested against: 3, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_30_eps_0.00784_n1.vnnlib ######
Model prediction is: tensor([[-0.7880, -1.5258,  0.6233,  2.5660,  0.7377,  1.8136,  3.5006,  0.7722,
         -4.2142, -2.3631]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /12 start_node /13
setting alpha for layer /12 start_node /15
setting alpha for layer /12 start_node /18
not setting layer /12 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 32, 32, 32]) != torch.Size([2, 9, 1, 32, 32, 32]))
setting alpha for layer /14 start_node /15
setting alpha for layer /14 start_node /18
not setting layer /14 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /16 start_node /18
not setting layer /16 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /19 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /11 torch.Size([1, 32, 32, 32])
1 /13 torch.Size([1, 32, 16, 16])
2 /15 torch.Size([1, 128, 8, 8])
3 /18 torch.Size([1, 250])
best_l after optimization: 0.37493467330932617 with beta sum per layer: []
alpha/beta optimization time: 2.3648681640625
alpha-CROWN with fixed intermediate bounds: tensor([[-0.3749]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.37493467330932617
layer 0 size torch.Size([32768]) unstable 2156
layer 1 size torch.Size([8192]) unstable 835
layer 2 size torch.Size([8192]) unstable 577
layer 3 size torch.Size([250]) unstable 61
-----------------
# of unstable neurons: 3629
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 32, 32]) pre split depth:  4
batch:  torch.Size([1, 32, 32, 32]) post split depth:  4
splitting decisions: 
split level 0: [3, 207] 
split level 1: [3, 238] 
split level 2: [3, 179] 
split level 3: [3, 76] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 1.7069133520126343 with beta sum per layer: [0.0, 0.0, 0.0, 6.960041046142578]
alpha/beta optimization time: 0.7206699848175049
This batch time : update_bounds func: 0.7300	 prepare: 0.0031	 bound: 0.7212	 transfer: 0.0041	 finalize: 0.0014
Accumulated time: update_bounds func: 0.7300	 prepare: 0.0031	 bound: 0.7212	 transfer: 0.0041	 finalize: 0.0014
batch bounding time:  0.7301299571990967
Current worst splitting domains [lb, ub] (depth):
[-0.22672,   inf] (5), [-0.22646,   inf] (5), [-0.18585,   inf] (5), [-0.17928,   inf] (5), [-0.12766,   inf] (5), [-0.12638,   inf] (5), [-0.12573,   inf] (5), [-0.12493,   inf] (5), [-0.09340,   inf] (5), [-0.08694,   inf] (5), [-0.08402,   inf] (5), [-0.07631,   inf] (5), [-0.02861,   inf] (5), [-0.02641,   inf] (5), 
length of domains: 14
Total time: 0.7985	 pickout: 0.0013	 decision: 0.0643	 get_bound: 0.7323	 add_domain: 0.0007
Current lb:-0.2267213612794876
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.122733116149902

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([14, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([14, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 12] [3, 12] [3, 12] [3, 12] [3, 12] [3, 12] [3, 12] [3, 12] [3, 12] [3, 12] 
regular batch size: 2*14, diving batch size 1*0
best_l after optimization: 1.4309518337249756 with beta sum per layer: [0.0, 0.0, 0.0, 17.105201721191406]
alpha/beta optimization time: 0.7516884803771973
This batch time : update_bounds func: 0.7721	 prepare: 0.0041	 bound: 0.7520	 transfer: 0.0137	 finalize: 0.0022
Accumulated time: update_bounds func: 1.5021	 prepare: 0.0071	 bound: 1.4732	 transfer: 0.0137	 finalize: 0.0036
batch bounding time:  0.7723085880279541
Current worst splitting domains [lb, ub] (depth):
[-0.17807,   inf] (7), [-0.17724,   inf] (7), [-0.17148,   inf] (7), [-0.16667,   inf] (7), [-0.13585,   inf] (7), [-0.12976,   inf] (7), [-0.12673,   inf] (7), [-0.11424,   inf] (7), [-0.04944,   inf] (7), [-0.04737,   inf] (7), [-0.04613,   inf] (7), [-0.04174,   inf] (7), [-0.04002,   inf] (7), [-0.03193,   inf] (7), [-0.03059,   inf] (7), [-0.02736,   inf] (7), [-0.01973,   inf] (7), [-0.01627,   inf] (7), [-0.00352,   inf] (7), [-0.00187,   inf] (7), 
length of domains: 20
Total time: 0.8686	 pickout: 0.0076	 decision: 0.0877	 get_bound: 0.7724	 add_domain: 0.0009
Current lb:-0.17806971073150635
44 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.991831302642822

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([20, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([20, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 175] [3, 175] [3, 175] [3, 175] [3, 175] [3, 175] [3, 175] [3, 175] [3, 175] [3, 175] 
regular batch size: 2*20, diving batch size 1*0
best_l after optimization: 1.4063705205917358 with beta sum per layer: [0.0, 0.0, 0.0, 25.669795989990234]
alpha/beta optimization time: 0.8223695755004883
This batch time : update_bounds func: 0.8509	 prepare: 0.0053	 bound: 0.8227	 transfer: 0.0197	 finalize: 0.0030
Accumulated time: update_bounds func: 2.3529	 prepare: 0.0124	 bound: 2.2959	 transfer: 0.0197	 finalize: 0.0067
batch bounding time:  0.8510909080505371
Current worst splitting domains [lb, ub] (depth):
[-0.15948,   inf] (9), [-0.15879,   inf] (9), [-0.15230,   inf] (9), [-0.14738,   inf] (9), [-0.11696,   inf] (9), [-0.11029,   inf] (9), [-0.10786,   inf] (9), [-0.10658,   inf] (9), [-0.10445,   inf] (9), [-0.09990,   inf] (9), [-0.09614,   inf] (9), [-0.09478,   inf] (9), [-0.06220,   inf] (9), [-0.05846,   inf] (9), [-0.05350,   inf] (9), [-0.04185,   inf] (9), [-0.01229,   inf] (9), [-0.01019,   inf] (9), [-0.00173,   inf] (9), 
length of domains: 19
Total time: 0.9593	 pickout: 0.0105	 decision: 0.0967	 get_bound: 0.8512	 add_domain: 0.0010
Current lb:-0.1594788283109665
84 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.951842308044434

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([19, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([19, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 168] [3, 168] [3, 171] [3, 168] [3, 171] [3, 171] [3, 171] [3, 171] [3, 168] [3, 171] 
regular batch size: 2*19, diving batch size 1*0
best_l after optimization: 1.7052497863769531 with beta sum per layer: [0.0, 0.0, 0.0, 26.21347427368164]
alpha/beta optimization time: 0.8112664222717285
This batch time : update_bounds func: 0.8313	 prepare: 0.0050	 bound: 0.8116	 transfer: 0.0118	 finalize: 0.0028
Accumulated time: update_bounds func: 3.1843	 prepare: 0.0174	 bound: 3.1075	 transfer: 0.0118	 finalize: 0.0095
batch bounding time:  0.831519365310669
Current worst splitting domains [lb, ub] (depth):
[-0.15271,   inf] (11), [-0.15200,   inf] (11), [-0.14041,   inf] (11), [-0.12685,   inf] (11), [-0.10785,   inf] (11), [-0.09302,   inf] (11), [-0.08689,   inf] (11), [-0.08288,   inf] (11), [-0.07855,   inf] (11), [-0.07155,   inf] (11), [-0.07004,   inf] (11), [-0.06928,   inf] (11), [-0.06780,   inf] (11), [-0.06420,   inf] (11), [-0.06080,   inf] (11), [-0.06045,   inf] (11), [-0.05910,   inf] (11), [-0.05505,   inf] (11), [-0.05269,   inf] (11), [-0.04511,   inf] (11), 
length of domains: 27
Total time: 0.9396	 pickout: 0.0101	 decision: 0.0964	 get_bound: 0.8316	 add_domain: 0.0014
Current lb:-0.15271329879760742
122 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.891953945159912

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([27, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([27, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 171] [3, 155] [3, 155] [3, 168] [3, 155] [3, 168] [3, 168] [3, 155] [3, 171] [3, 171] 
regular batch size: 2*27, diving batch size 1*0
best_l after optimization: 1.4081521034240723 with beta sum per layer: [0.0, 0.0, 0.0, 42.729331970214844]
alpha/beta optimization time: 0.9175045490264893
This batch time : update_bounds func: 0.9502	 prepare: 0.0066	 bound: 0.9178	 transfer: 0.0216	 finalize: 0.0040
Accumulated time: update_bounds func: 4.1344	 prepare: 0.0240	 bound: 4.0253	 transfer: 0.0216	 finalize: 0.0135
batch bounding time:  0.9503819942474365
Current worst splitting domains [lb, ub] (depth):
[-0.12839,   inf] (13), [-0.12826,   inf] (13), [-0.11977,   inf] (13), [-0.11666,   inf] (13), [-0.10458,   inf] (13), [-0.10344,   inf] (13), [-0.08981,   inf] (13), [-0.08590,   inf] (13), [-0.08406,   inf] (13), [-0.07981,   inf] (13), [-0.05864,   inf] (13), [-0.04962,   inf] (13), [-0.04860,   inf] (13), [-0.04593,   inf] (13), [-0.04582,   inf] (13), [-0.04463,   inf] (13), [-0.04284,   inf] (13), [-0.04059,   inf] (13), [-0.03608,   inf] (13), [-0.03515,   inf] (13), 
length of domains: 34
Total time: 1.0777	 pickout: 0.0141	 decision: 0.1114	 get_bound: 0.9505	 add_domain: 0.0018
Current lb:-0.1283901482820511
176 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.970455169677734

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([34, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([34, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 234] [3, 234] [3, 234] [3, 234] [3, 234] [3, 234] [3, 234] [3, 234] [3, 234] [3, 234] 
regular batch size: 2*34, diving batch size 1*0
best_l after optimization: 0.3765600919723511 with beta sum per layer: [0.0, 0.0, 0.0, 54.769866943359375]
alpha/beta optimization time: 1.0001428127288818
This batch time : update_bounds func: 1.0384	 prepare: 0.0079	 bound: 1.0005	 transfer: 0.0247	 finalize: 0.0051
Accumulated time: update_bounds func: 5.1728	 prepare: 0.0319	 bound: 5.0258	 transfer: 0.0247	 finalize: 0.0186
batch bounding time:  1.03857421875
Current worst splitting domains [lb, ub] (depth):
[-0.12251,   inf] (15), [-0.12229,   inf] (15), [-0.11393,   inf] (15), [-0.11069,   inf] (15), [-0.09656,   inf] (15), [-0.09558,   inf] (15), [-0.08083,   inf] (15), [-0.08060,   inf] (15), [-0.07778,   inf] (15), [-0.07429,   inf] (15), [-0.05321,   inf] (15), [-0.04335,   inf] (15), [-0.04019,   inf] (15), [-0.03672,   inf] (15), [-0.03611,   inf] (15), [-0.03339,   inf] (15), [-0.02991,   inf] (15), [-0.02738,   inf] (15), [-0.02736,   inf] (15), [-0.01947,   inf] (15), 
length of domains: 26
Total time: 1.1844	 pickout: 0.0178	 decision: 0.1263	 get_bound: 1.0387	 add_domain: 0.0015
Current lb:-0.12251221388578415
244 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.155832767486572

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([26, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([26, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 171] [3, 155] [3, 155] [3, 171] [3, 155] [3, 171] [3, 171] [3, 155] [3, 168] [3, 155] 
regular batch size: 2*26, diving batch size 1*0
best_l after optimization: 1.095037579536438 with beta sum per layer: [0.0, 0.0, 0.0, 38.60689163208008]
alpha/beta optimization time: 0.8987033367156982
This batch time : update_bounds func: 0.9202	 prepare: 0.0065	 bound: 0.8990	 transfer: 0.0107	 finalize: 0.0039
Accumulated time: update_bounds func: 6.0930	 prepare: 0.0384	 bound: 5.9248	 transfer: 0.0107	 finalize: 0.0225
batch bounding time:  0.9204974174499512
Current worst splitting domains [lb, ub] (depth):
[-0.09813,   inf] (17), [-0.09751,   inf] (17), [-0.08996,   inf] (17), [-0.08541,   inf] (17), [-0.07753,   inf] (17), [-0.07405,   inf] (17), [-0.07355,   inf] (17), [-0.07161,   inf] (17), [-0.07062,   inf] (17), [-0.06525,   inf] (17), [-0.06484,   inf] (17), [-0.05647,   inf] (17), [-0.05629,   inf] (17), [-0.05037,   inf] (17), [-0.04586,   inf] (17), [-0.04089,   inf] (17), [-0.03925,   inf] (17), [-0.03298,   inf] (17), [-0.03291,   inf] (17), [-0.02941,   inf] (17), 
length of domains: 30
Total time: 1.0454	 pickout: 0.0135	 decision: 0.1095	 get_bound: 0.9206	 add_domain: 0.0018
Current lb:-0.09813261032104492
296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.202008485794067

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([30, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([30, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 107] [3, 107] [3, 107] [3, 107] [3, 107] [3, 107] [3, 107] [3, 107] [3, 111] [3, 107] 
regular batch size: 2*30, diving batch size 1*0
best_l after optimization: 0.971727192401886 with beta sum per layer: [0.0, 0.0, 0.0, 44.99095916748047]
alpha/beta optimization time: 0.9468193054199219
This batch time : update_bounds func: 0.9710	 prepare: 0.0071	 bound: 0.9471	 transfer: 0.0121	 finalize: 0.0044
Accumulated time: update_bounds func: 7.0640	 prepare: 0.0455	 bound: 6.8719	 transfer: 0.0121	 finalize: 0.0269
batch bounding time:  0.9711871147155762
Current worst splitting domains [lb, ub] (depth):
[-0.08992,   inf] (19), [-0.08935,   inf] (19), [-0.08168,   inf] (19), [-0.07704,   inf] (19), [-0.06796,   inf] (19), [-0.06496,   inf] (19), [-0.06415,   inf] (19), [-0.06353,   inf] (19), [-0.06047,   inf] (19), [-0.05496,   inf] (19), [-0.05302,   inf] (19), [-0.04861,   inf] (19), [-0.04790,   inf] (19), [-0.04233,   inf] (19), [-0.03807,   inf] (19), [-0.02735,   inf] (19), [-0.02508,   inf] (19), [-0.02506,   inf] (19), [-0.02324,   inf] (19), [-0.02142,   inf] (19), 
length of domains: 34
Total time: 1.1067	 pickout: 0.0154	 decision: 0.1179	 get_bound: 0.9713	 add_domain: 0.0021
Current lb:-0.08992275595664978
356 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.309644937515259

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([34, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([34, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 111] [3, 111] [3, 111] [3, 111] [3, 111] [3, 111] [3, 111] [3, 111] [3, 107] [3, 111] 
regular batch size: 2*34, diving batch size 1*0
best_l after optimization: 0.5545405149459839 with beta sum per layer: [0.0, 0.0, 0.0, 43.52672576904297]
alpha/beta optimization time: 1.0012023448944092
This batch time : update_bounds func: 1.0336	 prepare: 0.0079	 bound: 1.0015	 transfer: 0.0191	 finalize: 0.0050
Accumulated time: update_bounds func: 8.0976	 prepare: 0.0534	 bound: 7.8734	 transfer: 0.0191	 finalize: 0.0319
batch bounding time:  1.0338644981384277
Current worst splitting domains [lb, ub] (depth):
[-0.08017,   inf] (21), [-0.07989,   inf] (21), [-0.07227,   inf] (21), [-0.06738,   inf] (21), [-0.05739,   inf] (21), [-0.05461,   inf] (21), [-0.05408,   inf] (21), [-0.05381,   inf] (21), [-0.05193,   inf] (21), [-0.04488,   inf] (21), [-0.04393,   inf] (21), [-0.03955,   inf] (21), [-0.03800,   inf] (21), [-0.03296,   inf] (21), [-0.02885,   inf] (21), [-0.02150,   inf] (21), [-0.01881,   inf] (21), [-0.01626,   inf] (21), [-0.01554,   inf] (21), [-0.01336,   inf] (21), 
length of domains: 32
Total time: 1.1809	 pickout: 0.0179	 decision: 0.1269	 get_bound: 1.0340	 add_domain: 0.0021
Current lb:-0.08017349243164062
424 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.491527557373047

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([32, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([32, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 112] [3, 112] [3, 112] [3, 112] [3, 112] [3, 112] [3, 112] [3, 112] [3, 112] [3, 112] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: 0.23416191339492798 with beta sum per layer: [0.0, 0.0, 0.0, 41.564937591552734]
alpha/beta optimization time: 0.9621849060058594
This batch time : update_bounds func: 0.9877	 prepare: 0.0075	 bound: 0.9625	 transfer: 0.0129	 finalize: 0.0046
Accumulated time: update_bounds func: 9.0853	 prepare: 0.0609	 bound: 8.8359	 transfer: 0.0129	 finalize: 0.0365
batch bounding time:  0.987907886505127
Current worst splitting domains [lb, ub] (depth):
[-0.06400,   inf] (23), [-0.06368,   inf] (23), [-0.05666,   inf] (23), [-0.05195,   inf] (23), [-0.03974,   inf] (23), [-0.03769,   inf] (23), [-0.03716,   inf] (23), [-0.03698,   inf] (23), [-0.03520,   inf] (23), [-0.03432,   inf] (23), [-0.03349,   inf] (23), [-0.02896,   inf] (23), [-0.02705,   inf] (23), [-0.02407,   inf] (23), [-0.02228,   inf] (23), [-0.02217,   inf] (23), [-0.01746,   inf] (23), [-0.01707,   inf] (23), [-0.01589,   inf] (23), [-0.01563,   inf] (23), 
length of domains: 26
Total time: 1.1285	 pickout: 0.0164	 decision: 0.1219	 get_bound: 0.9880	 add_domain: 0.0021
Current lb:-0.06399688869714737
488 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.620981931686401

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([26, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([26, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 106] [3, 106] [3, 106] [3, 106] [3, 106] [3, 106] [3, 106] [3, 106] [3, 106] [3, 106] 
regular batch size: 2*26, diving batch size 1*0
best_l after optimization: 0.19671159982681274 with beta sum per layer: [0.0, 0.0, 0.0, 25.280059814453125]
alpha/beta optimization time: 0.8987491130828857
This batch time : update_bounds func: 0.9347	 prepare: 0.0064	 bound: 0.8991	 transfer: 0.0250	 finalize: 0.0041
Accumulated time: update_bounds func: 10.0200	 prepare: 0.0673	 bound: 9.7350	 transfer: 0.0250	 finalize: 0.0405
batch bounding time:  0.9349803924560547
Current worst splitting domains [lb, ub] (depth):
[-0.05938,   inf] (25), [-0.05899,   inf] (25), [-0.05190,   inf] (25), [-0.04731,   inf] (25), [-0.03504,   inf] (25), [-0.03295,   inf] (25), [-0.03249,   inf] (25), [-0.03231,   inf] (25), [-0.03042,   inf] (25), [-0.02435,   inf] (25), [-0.02414,   inf] (25), [-0.02235,   inf] (25), [-0.02196,   inf] (25), [-0.01763,   inf] (25), [-0.01758,   inf] (25), [-0.01122,   inf] (25), [-0.01067,   inf] (25), [-0.00988,   inf] (25), [-0.00795,   inf] (25), [-0.00723,   inf] (25), 
length of domains: 21
Total time: 1.0592	 pickout: 0.0136	 decision: 0.1088	 get_bound: 0.9351	 add_domain: 0.0017
Current lb:-0.05938281863927841
540 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.681190252304077

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([21, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([21, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 1] [3, 1] [3, 1] [3, 1] [3, 1] [3, 1] [3, 1] [3, 1] [3, 1] [3, 1] 
regular batch size: 2*21, diving batch size 1*0
best_l after optimization: 0.19085510075092316 with beta sum per layer: [0.0, 0.0, 0.0, 19.478731155395508]
alpha/beta optimization time: 0.8316597938537598
This batch time : update_bounds func: 0.8594	 prepare: 0.0055	 bound: 0.8320	 transfer: 0.0187	 finalize: 0.0031
Accumulated time: update_bounds func: 10.8793	 prepare: 0.0728	 bound: 10.5670	 transfer: 0.0187	 finalize: 0.0436
batch bounding time:  0.8595895767211914
Current worst splitting domains [lb, ub] (depth):
[-0.05404,   inf] (27), [-0.05348,   inf] (27), [-0.04633,   inf] (27), [-0.04188,   inf] (27), [-0.02902,   inf] (27), [-0.02752,   inf] (27), [-0.02717,   inf] (27), [-0.02646,   inf] (27), [-0.02447,   inf] (27), [-0.01874,   inf] (27), [-0.01781,   inf] (27), [-0.01648,   inf] (27), [-0.01539,   inf] (27), [-0.01226,   inf] (27), [-0.01195,   inf] (27), [-0.00580,   inf] (27), [-0.00350,   inf] (27), [-0.00280,   inf] (27), [-0.00164,   inf] (27), [-0.00152,   inf] (27), 
length of domains: 20
Total time: 0.9747	 pickout: 0.0133	 decision: 0.1000	 get_bound: 0.8597	 add_domain: 0.0018
Current lb:-0.054035186767578125
582 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.656638622283936

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([20, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([20, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 35] [3, 35] [3, 35] [3, 35] [3, 35] [3, 35] [3, 35] [3, 35] [3, 35] [3, 35] 
regular batch size: 2*20, diving batch size 1*0
best_l after optimization: 0.08745355904102325 with beta sum per layer: [0.0, 0.0, 0.0, 18.37608528137207]
alpha/beta optimization time: 0.8132212162017822
This batch time : update_bounds func: 0.8320	 prepare: 0.0052	 bound: 0.8135	 transfer: 0.0101	 finalize: 0.0030
Accumulated time: update_bounds func: 11.7113	 prepare: 0.0780	 bound: 11.3805	 transfer: 0.0101	 finalize: 0.0466
batch bounding time:  0.8321683406829834
Current worst splitting domains [lb, ub] (depth):
[-0.04864,   inf] (29), [-0.04818,   inf] (29), [-0.04106,   inf] (29), [-0.03655,   inf] (29), [-0.02362,   inf] (29), [-0.02253,   inf] (29), [-0.02207,   inf] (29), [-0.02100,   inf] (29), [-0.01912,   inf] (29), [-0.01375,   inf] (29), [-0.01216,   inf] (29), [-0.01106,   inf] (29), [-0.00961,   inf] (29), [-0.00712,   inf] (29), [-0.00684,   inf] (29), [-0.00065,   inf] (29), 
length of domains: 16
Total time: 0.9411	 pickout: 0.0108	 decision: 0.0968	 get_bound: 0.8322	 add_domain: 0.0013
Current lb:-0.04863595962524414
622 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.59846591949463

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([16, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([16, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 74] [3, 74] [3, 74] [3, 74] [3, 74] [3, 74] [3, 74] [3, 74] [3, 74] [3, 74] 
regular batch size: 2*16, diving batch size 1*0
best_l after optimization: 0.033354222774505615 with beta sum per layer: [0.0, 0.0, 0.0, 12.67122745513916]
alpha/beta optimization time: 0.7671713829040527
This batch time : update_bounds func: 0.7828	 prepare: 0.0045	 bound: 0.7675	 transfer: 0.0083	 finalize: 0.0025
Accumulated time: update_bounds func: 12.4941	 prepare: 0.0825	 bound: 12.1480	 transfer: 0.0083	 finalize: 0.0491
batch bounding time:  0.783013105392456
Current worst splitting domains [lb, ub] (depth):
[-0.03748,   inf] (31), [-0.03698,   inf] (31), [-0.03025,   inf] (31), [-0.02560,   inf] (31), [-0.01202,   inf] (31), [-0.01177,   inf] (31), [-0.01128,   inf] (31), [-0.00916,   inf] (31), [-0.00775,   inf] (31), [-0.00324,   inf] (31), [-0.00070,   inf] (31), [-0.00058,   inf] (31), 
length of domains: 12
Total time: 0.8824	 pickout: 0.0087	 decision: 0.0896	 get_bound: 0.7831	 add_domain: 0.0010
Current lb:-0.03748369216918945
654 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.481411695480347

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([12, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([12, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 245] [3, 245] [3, 182] [3, 182] [3, 245] [3, 245] [3, 182] [3, 245] [3, 182] [3, 182] 
regular batch size: 2*12, diving batch size 1*0
best_l after optimization: -0.01777435839176178 with beta sum per layer: [0.0, 0.0, 0.0, 7.9411773681640625]
alpha/beta optimization time: 0.7338411808013916
This batch time : update_bounds func: 0.7455	 prepare: 0.0037	 bound: 0.7342	 transfer: 0.0057	 finalize: 0.0019
Accumulated time: update_bounds func: 13.2396	 prepare: 0.0861	 bound: 12.8822	 transfer: 0.0057	 finalize: 0.0509
batch bounding time:  0.7456440925598145
Current worst splitting domains [lb, ub] (depth):
[-0.03371,   inf] (33), [-0.03333,   inf] (33), [-0.02142,   inf] (33), [-0.01694,   inf] (33), [-0.00837,   inf] (33), [-0.00820,   inf] (33), [-0.00521,   inf] (33), [-0.00256,   inf] (33), 
length of domains: 8
Total time: 0.8347	 pickout: 0.0066	 decision: 0.0816	 get_bound: 0.7457	 add_domain: 0.0007
Current lb:-0.03371429443359375
678 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.31657338142395

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 165] [3, 165] [3, 245] [3, 245] [3, 182] [3, 165] [3, 165] [3, 245] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.021555490791797638 with beta sum per layer: [0.0, 0.0, 0.0, 3.8746132850646973]
alpha/beta optimization time: 0.7103650569915771
This batch time : update_bounds func: 0.7191	 prepare: 0.0030	 bound: 0.7107	 transfer: 0.0041	 finalize: 0.0013
Accumulated time: update_bounds func: 13.9587	 prepare: 0.0891	 bound: 13.5929	 transfer: 0.0041	 finalize: 0.0522
batch bounding time:  0.7192776203155518
Current worst splitting domains [lb, ub] (depth):
[-0.03034,   inf] (35), [-0.02998,   inf] (35), [-0.01780,   inf] (35), [-0.01319,   inf] (35), [-0.00524,   inf] (35), [-0.00224,   inf] (35), 
length of domains: 6
Total time: 0.7983	 pickout: 0.0047	 decision: 0.0737	 get_bound: 0.7193	 add_domain: 0.0006
Current lb:-0.030337810516357422
694 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 19.115211963653564

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([6, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([6, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 147] [3, 147] [3, 165] [3, 165] [3, 147] [3, 147] 
regular batch size: 2*6, diving batch size 1*0
best_l after optimization: -0.0008357614278793335 with beta sum per layer: [0.0, 0.0, 0.0, 2.171959638595581]
alpha/beta optimization time: 0.7090637683868408
This batch time : update_bounds func: 0.7165	 prepare: 0.0026	 bound: 0.7094	 transfer: 0.0033	 finalize: 0.0012
Accumulated time: update_bounds func: 14.6752	 prepare: 0.0917	 bound: 14.3022	 transfer: 0.0033	 finalize: 0.0534
batch bounding time:  0.7166562080383301
Current worst splitting domains [lb, ub] (depth):
[-0.02722,   inf] (37), [-0.02681,   inf] (37), [-0.01445,   inf] (37), [-0.00977,   inf] (37), [-0.00197,   inf] (37), 
length of domains: 5
Total time: 0.7916	 pickout: 0.0040	 decision: 0.0703	 get_bound: 0.7167	 add_domain: 0.0005
Current lb:-0.027218341827392578
706 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 19.910313844680786

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([5, 32, 32, 32]) pre split depth:  2
batch:  torch.Size([5, 32, 32, 32]) post split depth:  2
splitting decisions: 
split level 0: [3, 182] [3, 182] [3, 147] [3, 147] [3, 182] 
split level 1: [3, 50] [3, 247] [3, 247] [3, 50] [3, 50] 
regular batch size: 2*10, diving batch size 1*0
best_l after optimization: -0.23780179023742676 with beta sum per layer: [0.0, 0.0, 0.0, 1.9161872863769531]
alpha/beta optimization time: 0.7243294715881348
This batch time : update_bounds func: 0.7388	 prepare: 0.0033	 bound: 0.7247	 transfer: 0.0092	 finalize: 0.0015
Accumulated time: update_bounds func: 15.4140	 prepare: 0.0950	 bound: 15.0269	 transfer: 0.0092	 finalize: 0.0550
batch bounding time:  0.7389700412750244
Current worst splitting domains [lb, ub] (depth):
[-0.00998,   inf] (40), [-0.00639,   inf] (40), [-0.00307,   inf] (40), 
length of domains: 3
Total time: 0.8147	 pickout: 0.0034	 decision: 0.0700	 get_bound: 0.7409	 add_domain: 0.0004
Current lb:-0.009977059438824654
726 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 20.725410223007202

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3, 32, 32, 32]) pre split depth:  2
batch:  torch.Size([3, 32, 32, 32]) post split depth:  2
splitting decisions: 
split level 0: [3, 205] [3, 185] [3, 50] 
split level 1: [3, 50] [3, 205] [3, 183] 
regular batch size: 2*6, diving batch size 1*0/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:25: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1627336316785/work/torch/csrc/utils/tensor_numpy.cpp:143.)
  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))

best_l after optimization: -0.2643886208534241 with beta sum per layer: [0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.6447885036468506
This batch time : update_bounds func: 0.6520	 prepare: 0.0025	 bound: 0.6451	 transfer: 0.0033	 finalize: 0.0010
Accumulated time: update_bounds func: 16.0660	 prepare: 0.0975	 bound: 15.6720	 transfer: 0.0033	 finalize: 0.0560
batch bounding time:  0.6521711349487305
Current worst splitting domains [lb, ub] (depth):
[-0.00104,   inf] (43), 
length of domains: 1
Total time: 0.7220	 pickout: 0.0024	 decision: 0.0659	 get_bound: 0.6535	 add_domain: 0.0002
Current lb:-0.0010418668389320374
738 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 21.447649717330933

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 32, 32]) pre split depth:  4
batch:  torch.Size([1, 32, 32, 32]) post split depth:  4
splitting decisions: 
split level 0: [3, 247] 
split level 1: [3, 183] 
split level 2: [3, 23] 
split level 3: [3, 127] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -0.7837839126586914 with beta sum per layer: [0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.012207508087158203
This batch time : update_bounds func: 0.0208	 prepare: 0.0029	 bound: 0.0125	 transfer: 0.0041	 finalize: 0.0013
Accumulated time: update_bounds func: 16.0868	 prepare: 0.1004	 bound: 15.6845	 transfer: 0.0041	 finalize: 0.0572
batch bounding time:  0.020827054977416992
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0875	 pickout: 0.0013	 decision: 0.0627	 get_bound: 0.0235	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 21.53543257713318

Image 0 against label 3 verification end, Time cost: 21.61687183380127
##### [0] True label: 6, Tested against: 4, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_30_eps_0.00784_n1.vnnlib ######
init opt crown verified for label 4 with bound 1.2136776447296143
Image 0 against label 4 verification end, Time cost: 0.00030875205993652344
##### [0] True label: 6, Tested against: 5, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_30_eps_0.00784_n1.vnnlib ######
init opt crown verified for label 5 with bound 0.16584841907024384
Image 0 against label 5 verification end, Time cost: 0.00031065940856933594
##### [0] True label: 6, Tested against: 7, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_30_eps_0.00784_n1.vnnlib ######
init opt crown verified for label 7 with bound 0.5278414487838745
Image 0 against label 7 verification end, Time cost: 0.0003044605255126953
##### [0] True label: 6, Tested against: 8, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_30_eps_0.00784_n1.vnnlib ######
init opt crown verified for label 8 with bound 5.407393455505371
Image 0 against label 8 verification end, Time cost: 0.0002970695495605469
##### [0] True label: 6, Tested against: 9, onnx_path: nets/cifar10_2_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_30_eps_0.00784_n1.vnnlib ######
init opt crown verified for label 9 with bound 3.60006046295166
Image 0 against label 9 verification end, Time cost: 0.0003056526184082031
Result: safe-bab in 40.9711 seconds


[[  0.           2.24843454   0.           0.00031734   0.        ]
 [  0.           2.82282829   0.           0.00032854   1.        ]
 [  0.           1.08944488   0.           0.00031781   2.        ]
 [  0.           0.0000001  754.          21.61687183   3.        ]
 [  0.           1.21367764   0.           0.00030875   4.        ]
 [  0.           0.16584842   0.           0.00031066   5.        ]
 [  0.           0.52784145   0.           0.00030446   7.        ]
 [  0.           5.40739346   0.           0.00029707   8.        ]
 [  0.           3.60006046   0.           0.00030565   9.        ]]
############# Summary #############
Final verified acc: 100.0% [total 1 examples]
Total verification count: 1 , total verified safe: 1 , verified unsafe: 0 , timeout: 0
mean time [total:1]: 21.619362115859985
mean time [cnt:1]: 21.619362115859985
max time 40.971078395843506
safe-bab (total 1): [0]
