Building native CUDA modules...
/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab-refine
  enable_incomplete_verification: true
  get_crown_verified_acc: false
  csv_name: mnistfc_instances.csv
  onnx_path: null
  vnnlib_path: null
  results_file: null
  root_path: ../../../../../vnncomp2021/benchmarks/mnistfc
model:
  path: null
  name: mnist_9_200
data:
  start: 32
  end: 33
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: MNIST
  data_filter_path: null
specification:
  type: lp
  norm: .inf
  epsilon: null
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 500
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: 16
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 360
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 5
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 20:52:47 2022 on ubuntu
saving results to vnn-comp_[mnistfc_instances]_start=32_end=33_iter=20_b=500_timeout=360_branching=kfsb-max-5_lra-init=0.1_lra=0.01_lrb=0.03_PGD=skip.npz
customized start/end sample from 32 to 33

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Unexpected input shape in onnx: (784, 1), given (1, 28, 28)
Model prediction is: tensor([[ 0.6778,  0.0255,  0.0146, -0.0302,  0.0153,  0.0094,  0.1152,  0.1021,
          0.0067,  0.0255]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-2.7949, -2.7646, -2.3948, -2.5142, -2.3411, -3.1436, -3.8618, -2.8174,
         -2.6316]], device='cuda:0') None
best_l after optimization: 1.7903335094451904 with beta sum per layer: []
alpha/beta optimization time: 7.07042121887207
initial alpha-CROWN bounds: tensor([[-0.1079, -0.1369, -0.1355, -0.0681, -0.1354, -0.1992, -0.6737, -0.1729,
         -0.1607]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.6737, device='cuda:0', grad_fn=<MinBackward1>)
Start solving intermediate bounds with MIP...
alpha-CROWN optimizable variables initialized.
Academic license - for non-commercial use only - expires 2022-10-30
Using license file /home/zhouxingshi/gurobi.lic
mip_multi_proc: 16, mip_threads: 1,total threads used: 16, mip_perneuron_refine_timeout: 15
[total time budget for MIP: 240.0]

Linear(in_features=784, out_features=256, bias=True) 0 2 torch.Size([256])
Linear(in_features=256, out_features=256, bias=True) 1 4 torch.Size([256])
sorted candidates ['lay4_73', 'lay4_168', 'lay4_103', 'lay4_201', 'lay4_41', 'lay4_0', 'lay4_178', 'lay4_253', 'lay4_78', 'lay4_66', 'lay4_218', 'lay4_25', 'lay4_167', 'lay4_148', 'lay4_251', 'lay4_5', 'lay4_11', 'lay4_174', 'lay4_37', 'lay4_140', 'lay4_202', 'lay4_152', 'lay4_157', 'lay4_142', 'lay4_7', 'lay4_55', 'lay4_235', 'lay4_165', 'lay4_191', 'lay4_177', 'lay4_248', 'lay4_34', 'lay4_123', 'lay4_99', 'lay4_22', 'lay4_102', 'lay4_242', 'lay4_108', 'lay4_136', 'lay4_161', 'lay4_245', 'lay4_21'] filter: 1.0
/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:25: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1627336316785/work/torch/csrc/utils/tensor_numpy.cpp:143.)
  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))
Solving MIP for lay4_25, [-0.8170597553253174,5.3307576179504395]=>[1e-05,5.3307576179504395] (15,-1; -1,-1), time: 0.7511s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_11, [-5.798579216003418,0.13985121250152588]=>[-5.798579216003418,-1e-05] (-1,-1; 15,-1), time: 0.4528s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_73, [-5.426278114318848,3.19993257522583]=>[-4.135491490013912,2.585988058540673] (2,-1; 2,-1), time: 1.6144s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_0, [-0.9780846834182739,5.263062000274658]=>[-0.5528367440732687,4.173301834639965] (2,-1; 2,-1), time: 1.6369s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_66, [-1.2702350616455078,3.1152186393737793]=>[-0.7075703568551955,2.7853649398984732] (2,-1; 2,-1), time: 1.7351s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_251, [-2.744217872619629,1.223832368850708]=>[-2.0339359197043687,0.9963238794865379] (2,-1; 2,-1), time: 1.7446s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_253, [-1.7375056743621826,4.192713737487793]=>[-0.8888055659947351,3.906155917487844] (2,-1; 2,-1), time: 1.7609s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_218, [-5.4376091957092285,1.0742626190185547]=>[-4.817500275454553,0.7240994003043189] (2,-1; 2,-1), time: 1.7641s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_168, [-4.261836051940918,4.013910293579102]=>[-3.2581578541678655,3.4368993343829466] (2,-1; 2,-1), time: 1.7919s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_103, [-5.958019256591797,1.2284568548202515]=>[-5.132173173187762,0.5388768664167365] (2,-1; 2,-1), time: 1.8104s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_5, [-1.1804773807525635,6.479453086853027]=>[-0.7400455660827698,5.7169497837020895] (2,-1; 2,-1), time: 1.8344s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_201, [-1.7091948986053467,3.5005202293395996]=>[-0.8601522143006166,3.2552370079636255] (2,-1; 2,-1), time: 1.8866s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_148, [-6.033064365386963,2.0717196464538574]=>[-5.086338749745114,1.5035503505668062] (2,-1; 2,-1), time: 1.9015s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_167, [-4.021992206573486,2.0488290786743164]=>[-3.2030514592036337,1.5400030562402778] (2,-1; 2,-1), time: 1.9631s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_140, [-0.3147728443145752,6.344489574432373]=>[1e-05,6.344489574432373] (15,-1; -1,-1), time: 0.3920s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_178, [-4.162996292114258,1.1346796751022339]=>[-3.785590709136393,0.4311662440695864] (2,-1; 2,-1), time: 2.0392s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_41, [-2.6528964042663574,1.5607277154922485]=>[-2.077015658443429,1.0172636447695262] (2,-1; 2,-1), time: 2.0671s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_202, [-4.712140083312988,0.07941794395446777]=>[-4.712140083312988,-1e-05] (-1,-1; 15,-1), time: 0.4511s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_37, [-1.0765705108642578,5.647904872894287]=>[1e-05,5.647904872894287] (15,-1; -1,-1), time: 0.7234s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_78, [-3.9863803386688232,2.299055814743042]=>[-3.7007967870750367,1.4996205843707826] (2,-1; 2,-1), time: 2.4653s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_248, [-0.5265921354293823,5.226115703582764]=>[1e-05,5.226115703582764] (15,-1; -1,-1), time: 0.4774s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_174, [-4.974677085876465,0.7234600782394409]=>[-4.401920320215177,0.29335949927088667] (2,-1; 2,-1), time: 1.6834s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_152, [-5.864716053009033,0.1284092664718628]=>[-4.72105329915718,0.033187923877946] (2,-1; 2,-1), time: 1.4467s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_157, [-2.9034290313720703,3.168834686279297]=>[-1.8284876617319772,2.876876878466418] (2,-1; 2,-1), time: 1.4435s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_142, [-1.4257090091705322,3.5934109687805176]=>[-0.6080725437718555,3.334805588701044] (2,-1; 2,-1), time: 1.4499s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_177, [-1.6946885585784912,3.362726926803589]=>[-1.0443463593679616,2.9412290270071266] (2,-1; 2,-1), time: 1.4110s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_235, [-2.714390993118286,2.154881715774536]=>[-2.2716734953874433,1.6794792875243487] (2,-1; 2,-1), time: 1.5623s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_165, [-1.9875843524932861,4.709199905395508]=>[-1.7378788418039668,3.883521795905527] (2,-1; 2,-1), time: 1.5978s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_55, [-3.3833560943603516,0.8490394949913025]=>[-2.655335585961309,0.38092841195316285] (2,-1; 2,-1), time: 1.6842s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_7, [-4.430842399597168,2.553905963897705]=>[-3.527676849340368,2.0298924238723757] (2,-1; 2,-1), time: 1.7796s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_245, [-5.226349353790283,0.2866649627685547]=>[-5.226349353790283,-1e-05] (-1,-1; 15,-1), time: 0.4088s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_123, [-2.6187214851379395,2.9865574836730957]=>[-1.5236577330655268,2.8402051027713897] (2,-1; 2,-1), time: 1.5824s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_34, [-5.978731155395508,0.9093186259269714]=>[-5.211510150622348,0.20687419348860303] (2,-1; 2,-1), time: 1.6556s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_242, [-2.3088572025299072,2.2573142051696777]=>[-1.7879421765009345,1.9381814246563978] (2,-1; 2,-1), time: 1.4150s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_99, [-3.9594476222991943,2.1298329830169678]=>[-2.6783245665652577,2.046931721017001] (2,-1; 2,-1), time: 1.8553s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_102, [-4.218007564544678,1.2243608236312866]=>[-3.4112004792014448,0.6181607133510199] (2,-1; 2,-1), time: 1.6821s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_22, [-3.9282755851745605,1.116091012954712]=>[-3.2048266763564435,0.48556068716380774] (2,-1; 2,-1), time: 1.8909s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_191, [-3.131021022796631,2.9015631675720215]=>[-2.4232906402271084,2.091056877748214] (2,-1; 2,-1), time: 2.3262s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_108, [-3.620485305786133,2.9710543155670166]=>[-2.637291360246585,2.6912438129940632] (2,-1; 2,-1), time: 1.6489s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_21, [-6.740950584411621,1.54878568649292]=>[-5.643524873302954,1.2568892627399064] (2,-1; 2,-1), time: 1.4656s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_136, [-3.2643299102783203,2.6380152702331543]=>[-2.4046906597962017,2.1972097721869592] (2,-1; 2,-1), time: 1.7348s, #vars: 1337, #constrs: 572, improved: True
Solving MIP for lay4_161, [-5.25100040435791,0.6988367438316345]=>[-4.151900694283381,0.6016651746711494] (2,-1; 2,-1), time: 1.7651s, #vars: 1337, #constrs: 572, improved: True
MIP improved 42 nodes out of 42 unstable nodes, lb improved 29.840980529785156, ub improved 16.9998779296875, time 5.7113
maximum relu layer improved by MIP so far 1 last_relu_layer_refined: True
Linear(in_features=256, out_features=256, bias=True) 2 6 torch.Size([256])
sorted candidates ['lay6_252'] filter: 1.0
Solving MIP for lay6_252, [-10.321806907653809,11.619589805603027]=>[-4.848330383325534,8.67529498016686] (2,-1; 2,-1), time: 8.2912s, #vars: 1663, #constrs: 933, improved: True
Run alpha-CROWN after refining layer 4 and relu idx 1
0 /12 torch.Size([1, 256])
1 /14 torch.Size([1, 256])
best_l after optimization: 1.1146225929260254 with beta sum per layer: []
alpha/beta optimization time: 3.4021828174591064
alpha-CROWN with intermediate bounds by MIP: tensor([[-0.0650, -0.0713, -0.0383, -0.0090, -0.0569, -0.1714, -0.4960, -0.1192,
         -0.0875]], device='cuda:0', grad_fn=<AsStridedBackward>) None
MIP improved 1 nodes out of 1 unstable nodes, lb improved 5.473476409912109, ub improved 2.9442949295043945, time 9.0125
maximum relu layer improved by MIP so far 2
Linear(in_features=256, out_features=256, bias=True) 3 8 torch.Size([256])
sorted candidates ['lay8_179', 'lay8_85', 'lay8_239', 'lay8_120', 'lay8_106', 'lay8_235', 'lay8_46', 'lay8_150', 'lay8_142', 'lay8_198', 'lay8_217', 'lay8_183', 'lay8_55', 'lay8_241', 'lay8_129', 'lay8_107', 'lay8_81', 'lay8_143', 'lay8_181', 'lay8_248', 'lay8_86', 'lay8_191'] filter: 1.0
Solving MIP for lay8_107, [-3.363891839981079,0.050116658210754395]=>[-3.363891839981079,-1e-05] (-1,-1; 15,-1), time: 0.2232s, #vars: 1921, #constrs: 1192, improved: True
Solving MIP for lay8_46, [-2.612220048904419,0.02273273468017578]=>[-2.612220048904419,-1e-05] (-1,-1; 15,-1), time: 0.2625s, #vars: 1921, #constrs: 1192, improved: True
Solving MIP for lay8_198, [-3.4348373413085938,0.07623547315597534]=>[-3.4348373413085938,-1e-05] (-1,-1; 15,-1), time: 0.3630s, #vars: 1921, #constrs: 1192, improved: True
Solving MIP for lay8_143, [-2.495018243789673,0.015442967414855957]=>[-2.495018243789673,-1e-05] (-1,-1; 15,-1), time: 0.1971s, #vars: 1921, #constrs: 1192, improved: True
Solving MIP for lay8_217, [-0.7049366235733032,0.1530171036720276]=>[-0.7049366235733032,-1e-05] (-1,-1; 15,-1), time: 0.4755s, #vars: 1921, #constrs: 1192, improved: True
Solving MIP for lay8_241, [-2.2080562114715576,0.5066989660263062]=>[-2.2080562114715576,-1e-05] (-1,-1; 15,-1), time: 0.4781s, #vars: 1921, #constrs: 1192, improved: True
Solving MIP for lay8_81, [-4.125998497009277,0.08265423774719238]=>[-4.125998497009277,-1e-05] (-1,-1; 15,-1), time: 0.2494s, #vars: 1921, #constrs: 1192, improved: True
Solving MIP for lay8_181, [-3.6198415756225586,0.03825736045837402]=>[-3.6198415756225586,-1e-05] (-1,-1; 15,-1), time: 0.2501s, #vars: 1921, #constrs: 1192, improved: True
Solving MIP for lay8_86, [-2.656695604324341,0.19795536994934082]=>[-2.656695604324341,-1e-05] (-1,-1; 15,-1), time: 0.3336s, #vars: 1921, #constrs: 1192, improved: True
Solving MIP for lay8_191, [-1.8280967473983765,0.2961280345916748]=>[-1.8280967473983765,-1e-05] (-1,-1; 15,-1), time: 0.3327s, #vars: 1921, #constrs: 1192, improved: True
Solving MIP for lay8_248, [-3.3615827560424805,0.2477787733078003]=>[-3.3615827560424805,-1e-05] (-1,-1; 15,-1), time: 0.4193s, #vars: 1921, #constrs: 1192, improved: True
Solving MIP for lay8_55, [-1.8355528116226196,0.7792977094650269]=>[-1.8355528116226196,-0.002967810514337737] (-1,-1; 2,-1), time: 2.0353s, #vars: 1921, #constrs: 1192, improved: True
Solving MIP for lay8_150, [-1.713374376296997,2.8978211879730225]=>[-1.021251273788379,0.763530835300319] (2,-1; 2,-1), time: 3.9112s, #vars: 1921, #constrs: 1192, improved: True
Solving MIP for lay8_129, [-2.1026744842529297,0.44621726870536804]=>[-1.475002686552283,0.42504298371568394] (2,-1; 2,-1), time: 3.9246s, #vars: 1921, #constrs: 1192, improved: True
Solving MIP for lay8_235, [-2.7169950008392334,4.7206130027771]=>[-1.5450592694365786,1.513104905614342] (2,-1; 2,-1), time: 4.0452s, #vars: 1921, #constrs: 1192, improved: True
Solving MIP for lay8_142, [-3.1444778442382812,5.284176349639893]=>[-1.7985137980663843,1.7185630266760474] (2,-1; 2,-1), time: 4.0897s, #vars: 1921, #constrs: 1192, improved: True
Solving MIP for lay8_183, [-0.6239650249481201,2.5362696647644043]=>[-0.07784040219916266,1.3136577448491562] (2,-1; 2,-1), time: 4.1018s, #vars: 1921, #constrs: 1192, improved: True
Solving MIP for lay8_85, [-1.1690073013305664,0.6648097038269043]=>[-0.6815045821498706,0.5460236635329823] (2,-1; 2,-1), time: 4.2550s, #vars: 1921, #constrs: 1192, improved: True
Solving MIP for lay8_179, [-3.297511577606201,0.8855786323547363]=>[-2.2721993805233267,0.7397796539126671] (2,-1; 2,-1), time: 4.3135s, #vars: 1921, #constrs: 1192, improved: True
Solving MIP for lay8_239, [-1.2922943830490112,0.8524096012115479]=>[-1.0996501540474726,0.22528471482999618] (2,-1; 2,-1), time: 4.4156s, #vars: 1921, #constrs: 1192, improved: True
Solving MIP for lay8_120, [-2.4584357738494873,0.3758613169193268]=>[-1.7801164556063631,0.3190221984988797] (2,-1; 2,-1), time: 4.6682s, #vars: 1921, #constrs: 1192, improved: True
Solving MIP for lay8_106, [-2.413278102874756,0.41657599806785583]=>[-1.7493087438509052,0.33266298384861487] (2,-1; 2,-1), time: 4.8852s, #vars: 1921, #constrs: 1192, improved: True
Run alpha-CROWN after refining layer 6 and relu idx 2
0 /12 torch.Size([1, 256])
1 /14 torch.Size([1, 256])
2 /16 torch.Size([1, 256])
best_l after optimization: 0.7759843468666077 with beta sum per layer: []
alpha/beta optimization time: 3.835355520248413
alpha-CROWN with intermediate bounds by MIP: tensor([[-0.0328, -0.0352, -0.0020,  0.0216, -0.0227, -0.1573, -0.4090, -0.0880,
         -0.0506]], device='cuda:0', grad_fn=<AsStridedBackward>) None
MIP improved 22 nodes out of 22 unstable nodes, lb improved 7.4315667152404785, ub improved 13.653054237365723, time 5.6023
maximum relu layer improved by MIP so far 3
Linear(in_features=256, out_features=10, bias=True) 4 10 torch.Size([10])
MIP finished with 27.48944592475891s
Run final alpha-CROWN after MIP solving on layer 10 and relu idx 4
0 /12 torch.Size([1, 256])
1 /14 torch.Size([1, 256])
2 /16 torch.Size([1, 256])
3 /18 torch.Size([1, 256])
best_l after optimization: -0.31669560074806213 with beta sum per layer: []
alpha/beta optimization time: 3.29410982131958
alpha-CROWN with intermediate bounds improved by MIP: tensor([[ 0.0744,  0.0822,  0.1110,  0.1270,  0.0765, -0.0958, -0.1128,  0.0084,
          0.0457]], device='cuda:0', grad_fn=<AsStridedBackward>) None
refined global lb: tensor([[ 0.0000,  0.0744,  0.0822,  0.1110,  0.1270,  0.0765, -0.0958, -0.1128,
          0.0084,  0.0457]], device='cuda:0') min: tensor(-0.1128, device='cuda:0')
time threshold left for bab: 269.18983125686646
##### [0] True label: 0, Tested against: 1, onnx_path: mnist-net_256x4.onnx, vnnlib_path: prop_2_0.03.vnnlib ######
init opt crown verified for label 1 with bound 0.07438697665929794
Image 0 against label 1 verification end, Time cost: 0.00033473968505859375
##### [0] True label: 0, Tested against: 2, onnx_path: mnist-net_256x4.onnx, vnnlib_path: prop_2_0.03.vnnlib ######
init opt crown verified for label 2 with bound 0.08216200023889542
Image 0 against label 2 verification end, Time cost: 0.00032830238342285156
##### [0] True label: 0, Tested against: 3, onnx_path: mnist-net_256x4.onnx, vnnlib_path: prop_2_0.03.vnnlib ######
init opt crown verified for label 3 with bound 0.1110171377658844
Image 0 against label 3 verification end, Time cost: 0.00033211708068847656
##### [0] True label: 0, Tested against: 4, onnx_path: mnist-net_256x4.onnx, vnnlib_path: prop_2_0.03.vnnlib ######
init opt crown verified for label 4 with bound 0.12702761590480804
Image 0 against label 4 verification end, Time cost: 0.00032639503479003906
##### [0] True label: 0, Tested against: 5, onnx_path: mnist-net_256x4.onnx, vnnlib_path: prop_2_0.03.vnnlib ######
init opt crown verified for label 5 with bound 0.07650558650493622
Image 0 against label 5 verification end, Time cost: 0.00032401084899902344
##### [0] True label: 0, Tested against: 6, onnx_path: mnist-net_256x4.onnx, vnnlib_path: prop_2_0.03.vnnlib ######
Model prediction is: tensor([[ 0.6778,  0.0255,  0.0146, -0.0302,  0.0153,  0.0094,  0.1152,  0.1021,
          0.0067,  0.0255]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /13 start_node /14
setting alpha for layer /13 start_node /16
setting alpha for layer /13 start_node /18
not setting layer /13 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 256]) != torch.Size([2, 9, 1, 256]))
setting alpha for layer /15 start_node /16
setting alpha for layer /15 start_node /18
not setting layer /15 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 256]) != torch.Size([2, 9, 1, 256]))
setting alpha for layer /17 start_node /18
not setting layer /17 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 256]) != torch.Size([2, 9, 1, 256]))
not setting layer /19 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 256]) != torch.Size([2, 9, 1, 256]))
0 /12 torch.Size([1, 256])
1 /14 torch.Size([1, 256])
2 /16 torch.Size([1, 256])
3 /18 torch.Size([1, 256])
best_l after optimization: 0.09681901335716248 with beta sum per layer: []
alpha/beta optimization time: 1.0232598781585693
alpha-CROWN with fixed intermediate bounds: tensor([[-0.0968]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.09681901335716248
layer 0 size torch.Size([256]) unstable 20
layer 1 size torch.Size([256]) unstable 35
layer 2 size torch.Size([256]) unstable 1
layer 3 size torch.Size([256]) unstable 10
-----------------
# of unstable neurons: 66
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 256]) pre split depth:  5
batch:  torch.Size([1, 256]) post split depth:  5
splitting decisions: 
split level 0: [2, 252] 
split level 1: [0, 242] 
split level 2: [0, 214] 
split level 3: [3, 85] 
split level 4: [3, 179] 
regular batch size: 2*16, diving batch size 1*0

all verified at 12th iter
best_l after optimization: -2.346673011779785 with beta sum per layer: [0.2755048871040344, 0.0, 0.020270492881536484, 0.0]
alpha/beta optimization time: 0.16539716720581055
This batch time : update_bounds func: 0.1731	 prepare: 0.0038	 bound: 0.1657	 transfer: 0.0011	 finalize: 0.0024
Accumulated time: update_bounds func: 0.1731	 prepare: 0.0038	 bound: 0.1657	 transfer: 0.0011	 finalize: 0.0024
batch bounding time:  0.17328119277954102
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.2090	 pickout: 0.0009	 decision: 0.0307	 get_bound: 0.1774	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.2510218620300293

Image 0 against label 6 verification end, Time cost: 1.2991278171539307
##### [0] True label: 0, Tested against: 7, onnx_path: mnist-net_256x4.onnx, vnnlib_path: prop_2_0.03.vnnlib ######
Model prediction is: tensor([[ 0.6778,  0.0255,  0.0146, -0.0302,  0.0153,  0.0094,  0.1152,  0.1021,
          0.0067,  0.0255]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /13 start_node /14
setting alpha for layer /13 start_node /16
setting alpha for layer /13 start_node /18
not setting layer /13 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 256]) != torch.Size([2, 9, 1, 256]))
setting alpha for layer /15 start_node /16
setting alpha for layer /15 start_node /18
not setting layer /15 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 256]) != torch.Size([2, 9, 1, 256]))
setting alpha for layer /17 start_node /18
not setting layer /17 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 256]) != torch.Size([2, 9, 1, 256]))
not setting layer /19 start_node /20 because shape mismatch (torch.Size([2, 1, 1, 256]) != torch.Size([2, 9, 1, 256]))
0 /12 torch.Size([1, 256])
1 /14 torch.Size([1, 256])
2 /16 torch.Size([1, 256])
3 /18 torch.Size([1, 256])
best_l after optimization: 0.11378279328346252 with beta sum per layer: []
alpha/beta optimization time: 0.9447996616363525
alpha-CROWN with fixed intermediate bounds: tensor([[-0.1138]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.11378280073404312
layer 0 size torch.Size([256]) unstable 20
layer 1 size torch.Size([256]) unstable 35
layer 2 size torch.Size([256]) unstable 1
layer 3 size torch.Size([256]) unstable 10
-----------------
# of unstable neurons: 66
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 256]) pre split depth:  5
batch:  torch.Size([1, 256]) post split depth:  5
splitting decisions: 
split level 0: [3, 142] 
split level 1: [3, 235] 
split level 2: [3, 183] 
split level 3: [3, 239] 
split level 4: [3, 179] 
regular batch size: 2*16, diving batch size 1*0
best_l after optimization: -2.7919511795043945 with beta sum per layer: [0.0, 0.0, 0.0, 4.283382415771484]
alpha/beta optimization time: 0.25381016731262207
This batch time : update_bounds func: 0.2607	 prepare: 0.0035	 bound: 0.2541	 transfer: 0.0006	 finalize: 0.0024
Accumulated time: update_bounds func: 0.4338	 prepare: 0.0072	 bound: 0.4198	 transfer: 0.0006	 finalize: 0.0048
batch bounding time:  0.26085948944091797
Current worst splitting domains [lb, ub] (depth):
[-0.11378,   inf] (6), [-0.11378,   inf] (6), [-0.04583,   inf] (6), [-0.04197,   inf] (6), [-0.01842,   inf] (6), [-0.01065,   inf] (6), [-0.00734,   inf] (6), 
length of domains: 7
Total time: 0.2963	 pickout: 0.0008	 decision: 0.0302	 get_bound: 0.2649	 add_domain: 0.0004
Current lb:-0.11378280073404312
32 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.2580547332763672

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([7, 256]) pre split depth:  2
batch:  torch.Size([7, 256]) post split depth:  2
splitting decisions: 
split level 0: [3, 85] [3, 85] [2, 252] [2, 252] [3, 85] [3, 85] [3, 85] 
split level 1: [2, 252] [2, 252] [3, 85] [3, 85] [0, 132] [0, 132] [0, 132] 
regular batch size: 2*14, diving batch size 1*0
best_l after optimization: -3.039330005645752 with beta sum per layer: [0.029999997466802597, 0.0, 0.0, 4.855902671813965]
alpha/beta optimization time: 0.2608520984649658
This batch time : update_bounds func: 0.2685	 prepare: 0.0041	 bound: 0.2612	 transfer: 0.0009	 finalize: 0.0022
Accumulated time: update_bounds func: 0.7024	 prepare: 0.0114	 bound: 0.6810	 transfer: 0.0009	 finalize: 0.0070
batch bounding time:  0.26872825622558594
Current worst splitting domains [lb, ub] (depth):
[-0.11378,   inf] (9), [-0.11378,   inf] (9), [-0.04047,   inf] (9), [-0.02619,   inf] (9), 
length of domains: 4
Total time: 0.3055	 pickout: 0.0016	 decision: 0.0327	 get_bound: 0.2709	 add_domain: 0.0003
Current lb:-0.11378280073404312
60 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.5639479160308838

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 256]) pre split depth:  3
batch:  torch.Size([4, 256]) post split depth:  3
splitting decisions: 
split level 0: [0, 132] [0, 132] [0, 89] [0, 89] 
split level 1: [0, 208] [0, 89] [0, 208] [0, 208] 
split level 2: [1, 168] [0, 208] [0, 111] [1, 168] 
regular batch size: 2*16, diving batch size 1*0
best_l after optimization: 1.5363059043884277 with beta sum per layer: [1.557673454284668, 0.013483677059412003, 0.0, 5.092801094055176]
alpha/beta optimization time: 0.26314353942871094
This batch time : update_bounds func: 0.2716	 prepare: 0.0047	 bound: 0.2635	 transfer: 0.0007	 finalize: 0.0025
Accumulated time: update_bounds func: 0.9739	 prepare: 0.0161	 bound: 0.9445	 transfer: 0.0007	 finalize: 0.0095
batch bounding time:  0.2717270851135254
Current worst splitting domains [lb, ub] (depth):
[-0.11378,   inf] (13), [-0.11378,   inf] (13), [-0.11378,   inf] (13), [-0.11347,   inf] (13), [-0.10738,   inf] (13), [-0.10447,   inf] (13), [-0.09942,   inf] (13), [-0.09743,   inf] (13), [-0.06110,   inf] (13), [-0.05665,   inf] (13), [-0.04266,   inf] (13), [-0.04100,   inf] (13), [-0.03596,   inf] (13), [-0.02896,   inf] (13), [-0.02815,   inf] (13), [-0.02625,   inf] (13), [-0.02499,   inf] (13), [-0.02389,   inf] (13), [-0.02116,   inf] (13), [-0.02033,   inf] (13), 
length of domains: 31
Total time: 0.3105	 pickout: 0.0012	 decision: 0.0321	 get_bound: 0.2753	 add_domain: 0.0018
Current lb:-0.11378280073404312
92 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.8746531009674072

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([31, 256]) pre split depth:  1
batch:  torch.Size([31, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 168] [1, 168] [1, 168] [0, 89] [0, 89] [0, 89] [1, 168] [0, 89] [0, 89] [1, 168] 
regular batch size: 2*31, diving batch size 1*0
best_l after optimization: 1.4228054285049438 with beta sum per layer: [5.008127212524414, 0.028566161170601845, 0.0, 9.934391021728516]
alpha/beta optimization time: 0.26422905921936035
This batch time : update_bounds func: 0.2811	 prepare: 0.0082	 bound: 0.2646	 transfer: 0.0016	 finalize: 0.0066
Accumulated time: update_bounds func: 1.2550	 prepare: 0.0243	 bound: 1.2090	 transfer: 0.0016	 finalize: 0.0161
batch bounding time:  0.28132200241088867
Current worst splitting domains [lb, ub] (depth):
[-0.11378,   inf] (15), [-0.11378,   inf] (15), [-0.11378,   inf] (15), [-0.10790,   inf] (15), [-0.10388,   inf] (15), [-0.10375,   inf] (15), [-0.10117,   inf] (15), [-0.09787,   inf] (15), [-0.09769,   inf] (15), [-0.09139,   inf] (15), [-0.08386,   inf] (15), [-0.08340,   inf] (15), [-0.08127,   inf] (15), [-0.08118,   inf] (15), [-0.06323,   inf] (15), [-0.06306,   inf] (15), [-0.02979,   inf] (15), [-0.02556,   inf] (15), [-0.02485,   inf] (15), [-0.02327,   inf] (15), 
length of domains: 37
Total time: 0.3265	 pickout: 0.0050	 decision: 0.0376	 get_bound: 0.2814	 add_domain: 0.0024
Current lb:-0.11378280073404312
154 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.202018976211548

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([37, 256]) pre split depth:  1
batch:  torch.Size([37, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 5] [1, 73] [1, 5] [0, 111] [1, 5] [1, 5] [0, 111] [0, 111] [0, 111] [0, 111] 
regular batch size: 2*37, diving batch size 1*0
best_l after optimization: 0.4869340658187866 with beta sum per layer: [3.3753390312194824, 2.5597405433654785, 0.0, 10.814021110534668]
alpha/beta optimization time: 0.26665592193603516
This batch time : update_bounds func: 0.2850	 prepare: 0.0097	 bound: 0.2670	 transfer: 0.0023	 finalize: 0.0058
Accumulated time: update_bounds func: 1.5400	 prepare: 0.0340	 bound: 1.4760	 transfer: 0.0023	 finalize: 0.0219
batch bounding time:  0.2852003574371338
Current worst splitting domains [lb, ub] (depth):
[-0.11378,   inf] (17), [-0.11300,   inf] (17), [-0.10925,   inf] (17), [-0.09950,   inf] (17), [-0.09823,   inf] (17), [-0.09559,   inf] (17), [-0.09375,   inf] (17), [-0.08682,   inf] (17), [-0.08564,   inf] (17), [-0.08423,   inf] (17), [-0.08104,   inf] (17), [-0.08102,   inf] (17), [-0.08090,   inf] (17), [-0.07854,   inf] (17), [-0.07806,   inf] (17), [-0.07659,   inf] (17), [-0.07296,   inf] (17), [-0.07094,   inf] (17), [-0.06061,   inf] (17), [-0.05959,   inf] (17), 
length of domains: 40
Total time: 0.3328	 pickout: 0.0059	 decision: 0.0389	 get_bound: 0.2853	 add_domain: 0.0026
Current lb:-0.11378280073404312
228 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.535858631134033

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([40, 256]) pre split depth:  1
batch:  torch.Size([40, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 0] [0, 111] [1, 5] [1, 0] [1, 73] [1, 0] [1, 0] [1, 73] [1, 73] [1, 0] 
regular batch size: 2*40, diving batch size 1*0
best_l after optimization: 0.515303373336792 with beta sum per layer: [3.607489585876465, 2.081085681915283, 0.0, 11.490898132324219]
alpha/beta optimization time: 0.27007150650024414
This batch time : update_bounds func: 0.2888	 prepare: 0.0107	 bound: 0.2704	 transfer: 0.0017	 finalize: 0.0058
Accumulated time: update_bounds func: 1.8288	 prepare: 0.0447	 bound: 1.7464	 transfer: 0.0017	 finalize: 0.0277
batch bounding time:  0.28899264335632324
Current worst splitting domains [lb, ub] (depth):
[-0.11378,   inf] (19), [-0.10254,   inf] (19), [-0.09703,   inf] (19), [-0.09448,   inf] (19), [-0.09281,   inf] (19), [-0.09212,   inf] (19), [-0.08569,   inf] (19), [-0.08359,   inf] (19), [-0.08292,   inf] (19), [-0.08187,   inf] (19), [-0.08099,   inf] (19), [-0.07736,   inf] (19), [-0.07468,   inf] (19), [-0.06897,   inf] (19), [-0.06840,   inf] (19), [-0.05648,   inf] (19), [-0.05101,   inf] (19), [-0.04385,   inf] (19), [-0.04110,   inf] (19), [-0.03385,   inf] (19), 
length of domains: 47
Total time: 0.3389	 pickout: 0.0063	 decision: 0.0397	 get_bound: 0.2891	 add_domain: 0.0038
Current lb:-0.11378280073404312
308 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.8758511543273926

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([47, 256]) pre split depth:  1
batch:  torch.Size([47, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 73] [0, 111] [0, 111] [1, 73] [1, 73] [0, 111] [1, 73] [1, 0] [1, 5] [1, 0] 
regular batch size: 2*47, diving batch size 1*0
best_l after optimization: -0.2658839523792267 with beta sum per layer: [5.169917583465576, 2.465881824493408, 0.0, 13.694135665893555]
alpha/beta optimization time: 0.27022266387939453
This batch time : update_bounds func: 0.2918	 prepare: 0.0120	 bound: 0.2707	 transfer: 0.0020	 finalize: 0.0069
Accumulated time: update_bounds func: 2.1205	 prepare: 0.0568	 bound: 2.0171	 transfer: 0.0020	 finalize: 0.0345
batch bounding time:  0.2920570373535156
Current worst splitting domains [lb, ub] (depth):
[-0.11317,   inf] (21), [-0.08875,   inf] (21), [-0.08681,   inf] (21), [-0.08225,   inf] (21), [-0.08154,   inf] (21), [-0.08120,   inf] (21), [-0.08032,   inf] (21), [-0.07987,   inf] (21), [-0.07931,   inf] (21), [-0.07726,   inf] (21), [-0.07589,   inf] (21), [-0.07155,   inf] (21), [-0.07145,   inf] (21), [-0.06691,   inf] (21), [-0.06538,   inf] (21), [-0.06510,   inf] (21), [-0.06489,   inf] (21), [-0.05476,   inf] (21), [-0.04576,   inf] (21), [-0.04389,   inf] (21), 
length of domains: 46
Total time: 0.3436	 pickout: 0.0073	 decision: 0.0408	 get_bound: 0.2922	 add_domain: 0.0033
Current lb:-0.11316698044538498
402 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.2210381031036377

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([46, 256]) pre split depth:  1
batch:  torch.Size([46, 256]) post split depth:  1
splitting decisions: 
split level 0: [0, 111] [1, 5] [1, 5] [1, 0] [1, 73] [1, 73] [1, 103] [1, 0] [1, 5] [1, 0] 
regular batch size: 2*46, diving batch size 1*0
best_l after optimization: 0.35951852798461914 with beta sum per layer: [5.062431812286377, 2.944723606109619, 0.0, 17.062408447265625]
alpha/beta optimization time: 0.26522064208984375
This batch time : update_bounds func: 0.2856	 prepare: 0.0118	 bound: 0.2656	 transfer: 0.0016	 finalize: 0.0065
Accumulated time: update_bounds func: 2.4062	 prepare: 0.0685	 bound: 2.2827	 transfer: 0.0016	 finalize: 0.0411
batch bounding time:  0.28586769104003906
Current worst splitting domains [lb, ub] (depth):
[-0.09124,   inf] (23), [-0.08904,   inf] (23), [-0.08740,   inf] (23), [-0.08549,   inf] (23), [-0.08027,   inf] (23), [-0.07792,   inf] (23), [-0.07779,   inf] (23), [-0.07771,   inf] (23), [-0.07546,   inf] (23), [-0.07542,   inf] (23), [-0.07499,   inf] (23), [-0.07342,   inf] (23), [-0.06918,   inf] (23), [-0.06914,   inf] (23), [-0.06269,   inf] (23), [-0.06254,   inf] (23), [-0.05818,   inf] (23), [-0.05495,   inf] (23), [-0.05299,   inf] (23), [-0.04537,   inf] (23), 
length of domains: 46
Total time: 0.3374	 pickout: 0.0074	 decision: 0.0406	 get_bound: 0.2860	 add_domain: 0.0034
Current lb:-0.09123563766479492
494 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.560032367706299

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([46, 256]) pre split depth:  1
batch:  torch.Size([46, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 103] [1, 103] [1, 103] [1, 103] [1, 103] [1, 103] [1, 5] [1, 66] [1, 103] [1, 103] 
regular batch size: 2*46, diving batch size 1*0
best_l after optimization: 0.6586669087409973 with beta sum per layer: [5.102499961853027, 2.366588592529297, 0.0, 21.107799530029297]
alpha/beta optimization time: 0.26703357696533203
This batch time : update_bounds func: 0.2872	 prepare: 0.0120	 bound: 0.2674	 transfer: 0.0010	 finalize: 0.0065
Accumulated time: update_bounds func: 2.6934	 prepare: 0.0806	 bound: 2.5500	 transfer: 0.0010	 finalize: 0.0476
batch bounding time:  0.2874743938446045
Current worst splitting domains [lb, ub] (depth):
[-0.08851,   inf] (25), [-0.08665,   inf] (25), [-0.08502,   inf] (25), [-0.08340,   inf] (25), [-0.07740,   inf] (25), [-0.07647,   inf] (25), [-0.07613,   inf] (25), [-0.07500,   inf] (25), [-0.07371,   inf] (25), [-0.07281,   inf] (25), [-0.07276,   inf] (25), [-0.07203,   inf] (25), [-0.06741,   inf] (25), [-0.06618,   inf] (25), [-0.06050,   inf] (25), [-0.05931,   inf] (25), [-0.05834,   inf] (25), [-0.05814,   inf] (25), [-0.05753,   inf] (25), [-0.05590,   inf] (25), 
length of domains: 56
Total time: 0.3407	 pickout: 0.0074	 decision: 0.0413	 get_bound: 0.2876	 add_domain: 0.0043
Current lb:-0.08850602060556412
586 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.902090311050415

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([56, 256]) pre split depth:  1
batch:  torch.Size([56, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 66] [1, 66] [1, 66] [1, 66] [1, 66] [0, 70] [1, 41] [0, 70] [1, 103] [1, 66] 
regular batch size: 2*56, diving batch size 1*0
best_l after optimization: 0.469362735748291 with beta sum per layer: [5.018476486206055, 6.415689945220947, 0.0, 20.513107299804688]
alpha/beta optimization time: 0.2674827575683594
This batch time : update_bounds func: 0.2921	 prepare: 0.0140	 bound: 0.2679	 transfer: 0.0020	 finalize: 0.0080
Accumulated time: update_bounds func: 2.9855	 prepare: 0.0946	 bound: 2.8179	 transfer: 0.0020	 finalize: 0.0556
batch bounding time:  0.29241371154785156
Current worst splitting domains [lb, ub] (depth):
[-0.08711,   inf] (27), [-0.08525,   inf] (27), [-0.08410,   inf] (27), [-0.08239,   inf] (27), [-0.07564,   inf] (27), [-0.07512,   inf] (27), [-0.07360,   inf] (27), [-0.07249,   inf] (27), [-0.07122,   inf] (27), [-0.07117,   inf] (27), [-0.07106,   inf] (27), [-0.06871,   inf] (27), [-0.06864,   inf] (27), [-0.06440,   inf] (27), [-0.06438,   inf] (27), [-0.06263,   inf] (27), [-0.05750,   inf] (27), [-0.05726,   inf] (27), [-0.05511,   inf] (27), [-0.05485,   inf] (27), 
length of domains: 67
Total time: 0.3492	 pickout: 0.0087	 decision: 0.0425	 get_bound: 0.2926	 add_domain: 0.0053
Current lb:-0.08711209893226624
698 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.25295352935791

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([67, 256]) pre split depth:  1
batch:  torch.Size([67, 256]) post split depth:  1
splitting decisions: 
split level 0: [0, 70] [0, 70] [0, 70] [0, 144] [1, 41] [1, 103] [1, 66] [1, 66] [0, 70] [0, 70] 
regular batch size: 2*67, diving batch size 1*0
best_l after optimization: 0.864356517791748 with beta sum per layer: [8.020694732666016, 8.443632125854492, 0.0, 26.04894256591797]
alpha/beta optimization time: 0.2668955326080322
This batch time : update_bounds func: 0.2956	 prepare: 0.0168	 bound: 0.2673	 transfer: 0.0016	 finalize: 0.0096
Accumulated time: update_bounds func: 3.2811	 prepare: 0.1113	 bound: 3.0852	 transfer: 0.0016	 finalize: 0.0651
batch bounding time:  0.2958827018737793
Current worst splitting domains [lb, ub] (depth):
[-0.08573,   inf] (29), [-0.08420,   inf] (29), [-0.08343,   inf] (29), [-0.07767,   inf] (29), [-0.07227,   inf] (29), [-0.07213,   inf] (29), [-0.07175,   inf] (29), [-0.07104,   inf] (29), [-0.07004,   inf] (29), [-0.07001,   inf] (29), [-0.06970,   inf] (29), [-0.06722,   inf] (29), [-0.06690,   inf] (29), [-0.06689,   inf] (29), [-0.06021,   inf] (29), [-0.06020,   inf] (29), [-0.05999,   inf] (29), [-0.05994,   inf] (29), [-0.05980,   inf] (29), [-0.05435,   inf] (29), 
length of domains: 80
Total time: 0.3581	 pickout: 0.0102	 decision: 0.0447	 get_bound: 0.2961	 add_domain: 0.0071
Current lb:-0.08573195338249207
832 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.613050937652588

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([80, 256]) pre split depth:  1
batch:  torch.Size([80, 256]) post split depth:  1
splitting decisions: 
split level 0: [0, 168] [0, 168] [0, 144] [1, 41] [0, 168] [0, 168] [0, 144] [0, 144] [0, 168] [0, 168] 
regular batch size: 2*80, diving batch size 1*0
best_l after optimization: 0.18141967058181763 with beta sum per layer: [12.373236656188965, 8.656787872314453, 0.0, 27.697772979736328]
alpha/beta optimization time: 0.2810831069946289
This batch time : update_bounds func: 0.3170	 prepare: 0.0198	 bound: 0.2815	 transfer: 0.0030	 finalize: 0.0119
Accumulated time: update_bounds func: 3.5981	 prepare: 0.1311	 bound: 3.3666	 transfer: 0.0030	 finalize: 0.0771
batch bounding time:  0.31739163398742676
Current worst splitting domains [lb, ub] (depth):
[-0.08522,   inf] (31), [-0.08378,   inf] (31), [-0.07900,   inf] (31), [-0.07443,   inf] (31), [-0.07163,   inf] (31), [-0.07157,   inf] (31), [-0.07118,   inf] (31), [-0.07091,   inf] (31), [-0.06957,   inf] (31), [-0.06954,   inf] (31), [-0.06865,   inf] (31), [-0.06736,   inf] (31), [-0.06696,   inf] (31), [-0.06371,   inf] (31), [-0.06316,   inf] (31), [-0.06295,   inf] (31), [-0.05999,   inf] (31), [-0.05996,   inf] (31), [-0.05841,   inf] (31), [-0.05790,   inf] (31), 
length of domains: 91
Total time: 0.3930	 pickout: 0.0123	 decision: 0.0550	 get_bound: 0.3177	 add_domain: 0.0080
Current lb:-0.08522234112024307
992 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.008836984634399

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([91, 256]) pre split depth:  1
batch:  torch.Size([91, 256]) post split depth:  1
splitting decisions: 
split level 0: [0, 144] [0, 144] [1, 41] [0, 70] [1, 21] [0, 144] [0, 168] [1, 178] [0, 144] [0, 144] 
regular batch size: 2*91, diving batch size 1*0
best_l after optimization: -2.4075024127960205 with beta sum per layer: [11.444293975830078, 10.630609512329102, 0.0, 26.539608001708984]
alpha/beta optimization time: 0.2675323486328125
This batch time : update_bounds func: 0.3710	 prepare: 0.0226	 bound: 0.2679	 transfer: 0.0034	 finalize: 0.0129
Accumulated time: update_bounds func: 3.9691	 prepare: 0.1537	 bound: 3.6345	 transfer: 0.0034	 finalize: 0.0899
batch bounding time:  0.3714103698730469
Current worst splitting domains [lb, ub] (depth):
[-0.07999,   inf] (33), [-0.07777,   inf] (33), [-0.07546,   inf] (33), [-0.07365,   inf] (33), [-0.07289,   inf] (33), [-0.07129,   inf] (33), [-0.07109,   inf] (33), [-0.07074,   inf] (33), [-0.07004,   inf] (33), [-0.06818,   inf] (33), [-0.06818,   inf] (33), [-0.06687,   inf] (33), [-0.06656,   inf] (33), [-0.06642,   inf] (33), [-0.06394,   inf] (33), [-0.06390,   inf] (33), [-0.06346,   inf] (33), [-0.06171,   inf] (33), [-0.06071,   inf] (33), [-0.05936,   inf] (33), 
length of domains: 104
Total time: 0.4455	 pickout: 0.0142	 decision: 0.0506	 get_bound: 0.3717	 add_domain: 0.0089
Current lb:-0.07998964935541153
1174 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.457155704498291

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([104, 256]) pre split depth:  1
batch:  torch.Size([104, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 41] [1, 41] [0, 168] [0, 168] [0, 168] [0, 144] [1, 41] [1, 21] [0, 168] [1, 21] 
regular batch size: 2*104, diving batch size 1*0
best_l after optimization: -3.5222229957580566 with beta sum per layer: [11.67539119720459, 10.944215774536133, 0.0, 35.58800506591797]
alpha/beta optimization time: 0.27167272567749023
This batch time : update_bounds func: 0.3150	 prepare: 0.0251	 bound: 0.2720	 transfer: 0.0028	 finalize: 0.0145
Accumulated time: update_bounds func: 4.2841	 prepare: 0.1788	 bound: 3.9066	 transfer: 0.0028	 finalize: 0.1045
batch bounding time:  0.3153817653656006
Current worst splitting domains [lb, ub] (depth):
[-0.07560,   inf] (35), [-0.07493,   inf] (35), [-0.07378,   inf] (35), [-0.07328,   inf] (35), [-0.07306,   inf] (35), [-0.07238,   inf] (35), [-0.07057,   inf] (35), [-0.07030,   inf] (35), [-0.06967,   inf] (35), [-0.06766,   inf] (35), [-0.06668,   inf] (35), [-0.06612,   inf] (35), [-0.06578,   inf] (35), [-0.06574,   inf] (35), [-0.06489,   inf] (35), [-0.06337,   inf] (35), [-0.06328,   inf] (35), [-0.06301,   inf] (35), [-0.06286,   inf] (35), [-0.06274,   inf] (35), 
length of domains: 116
Total time: 0.3973	 pickout: 0.0161	 decision: 0.0540	 get_bound: 0.3158	 add_domain: 0.0115
Current lb:-0.07560151815414429
1382 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.8576507568359375

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([116, 256]) pre split depth:  1
batch:  torch.Size([116, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 178] [1, 178] [1, 201] [1, 178] [1, 21] [1, 21] [1, 21] [1, 41] [0, 170] [1, 41] 
regular batch size: 2*116, diving batch size 1*0
best_l after optimization: -2.3630247116088867 with beta sum per layer: [14.794227600097656, 11.146211624145508, 0.0, 42.82123947143555]
alpha/beta optimization time: 0.2937655448913574
This batch time : update_bounds func: 0.3423	 prepare: 0.0278	 bound: 0.2942	 transfer: 0.0031	 finalize: 0.0166
Accumulated time: update_bounds func: 4.6264	 prepare: 0.2066	 bound: 4.2007	 transfer: 0.0031	 finalize: 0.1211
batch bounding time:  0.3427870273590088
Current worst splitting domains [lb, ub] (depth):
[-0.07477,   inf] (37), [-0.07409,   inf] (37), [-0.07256,   inf] (37), [-0.07248,   inf] (37), [-0.07209,   inf] (37), [-0.07172,   inf] (37), [-0.07007,   inf] (37), [-0.06695,   inf] (37), [-0.06527,   inf] (37), [-0.06503,   inf] (37), [-0.06416,   inf] (37), [-0.06406,   inf] (37), [-0.06401,   inf] (37), [-0.06389,   inf] (37), [-0.06235,   inf] (37), [-0.06223,   inf] (37), [-0.06126,   inf] (37), [-0.06115,   inf] (37), [-0.06090,   inf] (37), [-0.06085,   inf] (37), 
length of domains: 133
Total time: 0.4289	 pickout: 0.0174	 decision: 0.0561	 get_bound: 0.3432	 add_domain: 0.0122
Current lb:-0.07476598024368286
1614 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.290454864501953

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([133, 256]) pre split depth:  1
batch:  torch.Size([133, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 21] [1, 21] [1, 178] [1, 21] [1, 178] [1, 178] [1, 178] [0, 70] [1, 178] [1, 21] 
regular batch size: 2*133, diving batch size 1*0
best_l after optimization: -1.4810400009155273 with beta sum per layer: [19.581371307373047, 15.033687591552734, 0.0, 45.29902648925781]
alpha/beta optimization time: 0.27176833152770996
This batch time : update_bounds func: 0.3262	 prepare: 0.0317	 bound: 0.2721	 transfer: 0.0028	 finalize: 0.0189
Accumulated time: update_bounds func: 4.9526	 prepare: 0.2384	 bound: 4.4728	 transfer: 0.0028	 finalize: 0.1400
batch bounding time:  0.32670092582702637
Current worst splitting domains [lb, ub] (depth):
[-0.07434,   inf] (39), [-0.07382,   inf] (39), [-0.07218,   inf] (39), [-0.07172,   inf] (39), [-0.07131,   inf] (39), [-0.07097,   inf] (39), [-0.06924,   inf] (39), [-0.06649,   inf] (39), [-0.06455,   inf] (39), [-0.06447,   inf] (39), [-0.06344,   inf] (39), [-0.06319,   inf] (39), [-0.06313,   inf] (39), [-0.06306,   inf] (39), [-0.06172,   inf] (39), [-0.06037,   inf] (39), [-0.06020,   inf] (39), [-0.06016,   inf] (39), [-0.06014,   inf] (39), [-0.05966,   inf] (39), 
length of domains: 163
Total time: 0.4222	 pickout: 0.0201	 decision: 0.0595	 get_bound: 0.3272	 add_domain: 0.0154
Current lb:-0.0743422731757164
1880 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.716741561889648

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([163, 256]) pre split depth:  1
batch:  torch.Size([163, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 201] [1, 201] [0, 170] [1, 201] [0, 170] [1, 21] [1, 201] [1, 21] [1, 201] [0, 138] 
regular batch size: 2*163, diving batch size 1*0
best_l after optimization: 1.1611554622650146 with beta sum per layer: [23.883617401123047, 16.091997146606445, 0.0, 44.20216369628906]
alpha/beta optimization time: 0.26662349700927734
This batch time : update_bounds func: 0.3332	 prepare: 0.0382	 bound: 0.2670	 transfer: 0.0034	 finalize: 0.0238
Accumulated time: update_bounds func: 5.2858	 prepare: 0.2766	 bound: 4.7398	 transfer: 0.0034	 finalize: 0.1639
batch bounding time:  0.33375000953674316
Current worst splitting domains [lb, ub] (depth):
[-0.07211,   inf] (41), [-0.07147,   inf] (41), [-0.07058,   inf] (41), [-0.06990,   inf] (41), [-0.06916,   inf] (41), [-0.06852,   inf] (41), [-0.06735,   inf] (41), [-0.06676,   inf] (41), [-0.06619,   inf] (41), [-0.06600,   inf] (41), [-0.06403,   inf] (41), [-0.06259,   inf] (41), [-0.06229,   inf] (41), [-0.06212,   inf] (41), [-0.06209,   inf] (41), [-0.06078,   inf] (41), [-0.06030,   inf] (41), [-0.06009,   inf] (41), [-0.05983,   inf] (41), [-0.05980,   inf] (41), 
length of domains: 207
Total time: 0.4880	 pickout: 0.0248	 decision: 0.1089	 get_bound: 0.3343	 add_domain: 0.0199
Current lb:-0.07211076468229294
2206 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.209784269332886

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([207, 256]) pre split depth:  1
batch:  torch.Size([207, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 174] [1, 174] [1, 174] [1, 174] [0, 170] [0, 242] [1, 201] [0, 170] [0, 242] [0, 138] 
regular batch size: 2*207, diving batch size 1*0
best_l after optimization: -0.5811497569084167 with beta sum per layer: [27.58327865600586, 25.321720123291016, 0.0, 57.044708251953125]
alpha/beta optimization time: 0.26880645751953125
This batch time : update_bounds func: 0.3546	 prepare: 0.0492	 bound: 0.2694	 transfer: 0.0043	 finalize: 0.0308
Accumulated time: update_bounds func: 5.6404	 prepare: 0.3258	 bound: 5.0092	 transfer: 0.0043	 finalize: 0.1947
batch bounding time:  0.35524511337280273
Current worst splitting domains [lb, ub] (depth):
[-0.07185,   inf] (43), [-0.07119,   inf] (43), [-0.07031,   inf] (43), [-0.06962,   inf] (43), [-0.06821,   inf] (43), [-0.06612,   inf] (43), [-0.06583,   inf] (43), [-0.06560,   inf] (43), [-0.06481,   inf] (43), [-0.06466,   inf] (43), [-0.06387,   inf] (43), [-0.06202,   inf] (43), [-0.06133,   inf] (43), [-0.06119,   inf] (43), [-0.06107,   inf] (43), [-0.06055,   inf] (43), [-0.06043,   inf] (43), [-0.06011,   inf] (43), [-0.05985,   inf] (43), [-0.05969,   inf] (43), 
length of domains: 256
Total time: 0.4877	 pickout: 0.0306	 decision: 0.0756	 get_bound: 0.3560	 add_domain: 0.0255
Current lb:-0.07185088098049164
2620 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.703614234924316

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 256]) pre split depth:  1
batch:  torch.Size([256, 256]) post split depth:  1
splitting decisions: 
split level 0: [0, 138] [0, 170] [0, 170] [1, 201] [1, 201] [1, 218] [1, 201] [1, 174] [1, 174] [1, 174] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: -1.4452238082885742 with beta sum per layer: [37.438751220703125, 30.000207901000977, 0.0, 78.1120834350586]
alpha/beta optimization time: 0.2699558734893799
This batch time : update_bounds func: 0.4190	 prepare: 0.0604	 bound: 0.2706	 transfer: 0.0050	 finalize: 0.0817
Accumulated time: update_bounds func: 6.0594	 prepare: 0.3861	 bound: 5.2799	 transfer: 0.0050	 finalize: 0.2764
batch bounding time:  0.41969943046569824
Current worst splitting domains [lb, ub] (depth):
[-0.07155,   inf] (45), [-0.06933,   inf] (45), [-0.06804,   inf] (45), [-0.06789,   inf] (45), [-0.06745,   inf] (45), [-0.06563,   inf] (45), [-0.06557,   inf] (45), [-0.06527,   inf] (45), [-0.06456,   inf] (45), [-0.06444,   inf] (45), [-0.06358,   inf] (45), [-0.06339,   inf] (45), [-0.06332,   inf] (45), [-0.06112,   inf] (45), [-0.06074,   inf] (45), [-0.06001,   inf] (45), [-0.05982,   inf] (45), [-0.05978,   inf] (45), [-0.05937,   inf] (45), [-0.05903,   inf] (45), 
length of domains: 300
Total time: 0.5755	 pickout: 0.0375	 decision: 0.0855	 get_bound: 0.4206	 add_domain: 0.0319
Current lb:-0.07154783606529236
3132 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.286794662475586

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([300, 256]) pre split depth:  1
batch:  torch.Size([300, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 218] [1, 177] [0, 138] [0, 138] [0, 138] [1, 174] [1, 174] [1, 201] [1, 218] [0, 177] 
regular batch size: 2*300, diving batch size 1*0
best_l after optimization: -8.947555541992188 with beta sum per layer: [46.0709228515625, 40.38917541503906, 0.0, 98.35862731933594]
alpha/beta optimization time: 0.276775598526001
This batch time : update_bounds func: 0.3991	 prepare: 0.0704	 bound: 0.2771	 transfer: 0.0060	 finalize: 0.0441
Accumulated time: update_bounds func: 6.4585	 prepare: 0.4565	 bound: 5.5570	 transfer: 0.0060	 finalize: 0.3204
batch bounding time:  0.399874210357666
Current worst splitting domains [lb, ub] (depth):
[-0.07102,   inf] (47), [-0.06903,   inf] (47), [-0.06771,   inf] (47), [-0.06753,   inf] (47), [-0.06719,   inf] (47), [-0.06542,   inf] (47), [-0.06535,   inf] (47), [-0.06403,   inf] (47), [-0.06316,   inf] (47), [-0.06315,   inf] (47), [-0.06310,   inf] (47), [-0.06309,   inf] (47), [-0.06271,   inf] (47), [-0.06046,   inf] (47), [-0.06019,   inf] (47), [-0.05968,   inf] (47), [-0.05949,   inf] (47), [-0.05938,   inf] (47), [-0.05899,   inf] (47), [-0.05885,   inf] (47), 
length of domains: 333
Total time: 0.5768	 pickout: 0.0443	 decision: 0.0968	 get_bound: 0.4009	 add_domain: 0.0348
Current lb:-0.07101751118898392
3732 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.873117446899414

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([333, 256]) pre split depth:  1
batch:  torch.Size([333, 256]) post split depth:  1
splitting decisions: 
split level 0: [0, 170] [0, 138] [1, 177] [1, 218] [1, 177] [1, 177] [1, 253] [1, 253] [1, 177] [1, 218] 
regular batch size: 2*333, diving batch size 1*0
best_l after optimization: -2.643836498260498 with beta sum per layer: [50.14021301269531, 41.268280029296875, 0.0, 109.72265625]
alpha/beta optimization time: 0.31390881538391113
This batch time : update_bounds func: 0.4764	 prepare: 0.0782	 bound: 0.3143	 transfer: 0.0060	 finalize: 0.0762
Accumulated time: update_bounds func: 6.9349	 prepare: 0.5348	 bound: 5.8713	 transfer: 0.0060	 finalize: 0.3966
batch bounding time:  0.477524995803833
Current worst splitting domains [lb, ub] (depth):
[-0.06916,   inf] (49), [-0.06880,   inf] (49), [-0.06733,   inf] (49), [-0.06725,   inf] (49), [-0.06702,   inf] (49), [-0.06691,   inf] (49), [-0.06507,   inf] (49), [-0.06465,   inf] (49), [-0.06331,   inf] (49), [-0.06281,   inf] (49), [-0.06273,   inf] (49), [-0.06272,   inf] (49), [-0.06243,   inf] (49), [-0.06149,   inf] (49), [-0.05901,   inf] (49), [-0.05898,   inf] (49), [-0.05870,   inf] (49), [-0.05869,   inf] (49), [-0.05857,   inf] (49), [-0.05835,   inf] (49), 
length of domains: 412
Total time: 0.7251	 pickout: 0.0493	 decision: 0.1493	 get_bound: 0.4790	 add_domain: 0.0474
Current lb:-0.06916020810604095
4398 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.609267473220825

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([412, 256]) pre split depth:  1
batch:  torch.Size([412, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 253] [1, 253] [1, 253] [1, 253] [1, 253] [1, 253] [0, 177] [1, 177] [1, 177] [0, 177] 
regular batch size: 2*412, diving batch size 1*0
best_l after optimization: -4.073990345001221 with beta sum per layer: [63.123130798339844, 62.235069274902344, 0.0, 145.31396484375]
alpha/beta optimization time: 0.3370959758758545
This batch time : update_bounds func: 0.6005	 prepare: 0.1502	 bound: 0.3376	 transfer: 0.0085	 finalize: 0.1021
Accumulated time: update_bounds func: 7.5354	 prepare: 0.6850	 bound: 6.2089	 transfer: 0.0085	 finalize: 0.4988
batch bounding time:  0.6025350093841553
Current worst splitting domains [lb, ub] (depth):
[-0.06844,   inf] (51), [-0.06786,   inf] (51), [-0.06652,   inf] (51), [-0.06650,   inf] (51), [-0.06640,   inf] (51), [-0.06610,   inf] (51), [-0.06430,   inf] (51), [-0.06296,   inf] (51), [-0.06273,   inf] (51), [-0.06243,   inf] (51), [-0.06214,   inf] (51), [-0.06209,   inf] (51), [-0.06105,   inf] (51), [-0.05956,   inf] (51), [-0.05955,   inf] (51), [-0.05856,   inf] (51), [-0.05837,   inf] (51), [-0.05835,   inf] (51), [-0.05817,   inf] (51), [-0.05791,   inf] (51), 
length of domains: 487
Total time: 0.9743	 pickout: 0.0906	 decision: 0.2178	 get_bound: 0.6047	 add_domain: 0.0612
Current lb:-0.06844127923250198
5222 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.599656105041504

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([487, 256]) pre split depth:  1
batch:  torch.Size([487, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 177] [1, 218] [1, 218] [1, 177] [1, 177] [1, 218] [0, 138] [1, 251] [1, 218] [0, 83] 
regular batch size: 2*487, diving batch size 1*0
best_l after optimization: -5.850225448608398 with beta sum per layer: [84.640380859375, 81.86161041259766, 0.0, 158.30274963378906]
alpha/beta optimization time: 0.29929542541503906
This batch time : update_bounds func: 0.5613	 prepare: 0.1745	 bound: 0.2998	 transfer: 0.0123	 finalize: 0.0722
Accumulated time: update_bounds func: 8.0966	 prepare: 0.8594	 bound: 6.5087	 transfer: 0.0123	 finalize: 0.5709
batch bounding time:  0.5624961853027344
Current worst splitting domains [lb, ub] (depth):
[-0.06805,   inf] (53), [-0.06714,   inf] (53), [-0.06607,   inf] (53), [-0.06605,   inf] (53), [-0.06586,   inf] (53), [-0.06544,   inf] (53), [-0.06429,   inf] (53), [-0.06282,   inf] (53), [-0.06231,   inf] (53), [-0.06178,   inf] (53), [-0.06090,   inf] (53), [-0.05980,   inf] (53), [-0.05948,   inf] (53), [-0.05914,   inf] (53), [-0.05871,   inf] (53), [-0.05840,   inf] (53), [-0.05819,   inf] (53), [-0.05771,   inf] (53), [-0.05762,   inf] (53), [-0.05757,   inf] (53), 
length of domains: 577
Total time: 1.0043	 pickout: 0.1135	 decision: 0.2590	 get_bound: 0.5643	 add_domain: 0.0675
Current lb:-0.06804875284433365
6196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.620606899261475

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 251] [1, 251] [1, 251] [1, 251] [1, 251] [1, 251] [1, 251] [0, 177] [1, 253] [3, 150] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: -7.764915466308594 with beta sum per layer: [100.74224090576172, 100.87895965576172, 0.0, 167.64772033691406]
alpha/beta optimization time: 0.27899885177612305
This batch time : update_bounds func: 0.4846	 prepare: 0.1178	 bound: 0.2794	 transfer: 0.0109	 finalize: 0.0738
Accumulated time: update_bounds func: 8.5812	 prepare: 0.9772	 bound: 6.7881	 transfer: 0.0109	 finalize: 0.6447
batch bounding time:  0.4858105182647705
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (55), [-0.06666,   inf] (55), [-0.06593,   inf] (55), [-0.06592,   inf] (55), [-0.06552,   inf] (55), [-0.06502,   inf] (55), [-0.06418,   inf] (55), [-0.06178,   inf] (55), [-0.06177,   inf] (55), [-0.06085,   inf] (55), [-0.06023,   inf] (55), [-0.05934,   inf] (55), [-0.05915,   inf] (55), [-0.05891,   inf] (55), [-0.05832,   inf] (55), [-0.05742,   inf] (55), [-0.05740,   inf] (55), [-0.05716,   inf] (55), [-0.05640,   inf] (55), [-0.05624,   inf] (55), 
length of domains: 627
Total time: 0.8256	 pickout: 0.0755	 decision: 0.1968	 get_bound: 0.4876	 add_domain: 0.0657
Current lb:-0.06792494654655457
7196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.464209079742432

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [3, 150] [1, 167] [3, 150] [3, 150] [3, 150] [1, 167] [0, 177] [1, 251] [3, 150] [0, 242] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: -15.65472412109375 with beta sum per layer: [101.6897964477539, 100.25675201416016, 0.0, 201.68603515625]
alpha/beta optimization time: 0.2770977020263672
This batch time : update_bounds func: 0.5442	 prepare: 0.1171	 bound: 0.2775	 transfer: 0.0152	 finalize: 0.1318
Accumulated time: update_bounds func: 9.1255	 prepare: 1.0944	 bound: 7.0655	 transfer: 0.0152	 finalize: 0.7765
batch bounding time:  0.5455915927886963
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (57), [-0.06646,   inf] (57), [-0.06592,   inf] (57), [-0.06591,   inf] (57), [-0.06550,   inf] (57), [-0.06481,   inf] (57), [-0.06225,   inf] (57), [-0.06176,   inf] (57), [-0.06167,   inf] (57), [-0.06004,   inf] (57), [-0.05965,   inf] (57), [-0.05873,   inf] (57), [-0.05831,   inf] (57), [-0.05686,   inf] (57), [-0.05676,   inf] (57), [-0.05589,   inf] (57), [-0.05580,   inf] (57), [-0.05531,   inf] (57), [-0.05521,   inf] (57), [-0.05498,   inf] (57), 
length of domains: 657
Total time: 0.8775	 pickout: 0.0753	 decision: 0.1904	 get_bound: 0.5476	 add_domain: 0.0643
Current lb:-0.06792401522397995
8196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.359752416610718

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [3, 129] [3, 150] [3, 129] [3, 129] [3, 129] [3, 150] [0, 242] [3, 129] [3, 129] [0, 83] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: -22.43423080444336 with beta sum per layer: [84.7960205078125, 94.04214477539062, 0.0, 204.23809814453125]
alpha/beta optimization time: 0.27725887298583984
This batch time : update_bounds func: 0.5409	 prepare: 0.1179	 bound: 0.2776	 transfer: 0.0153	 finalize: 0.1274
Accumulated time: update_bounds func: 9.6664	 prepare: 1.2123	 bound: 7.3432	 transfer: 0.0153	 finalize: 0.9039
batch bounding time:  0.5421936511993408
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (59), [-0.06646,   inf] (59), [-0.06592,   inf] (59), [-0.06587,   inf] (59), [-0.06550,   inf] (59), [-0.06481,   inf] (59), [-0.06176,   inf] (59), [-0.06165,   inf] (59), [-0.06138,   inf] (59), [-0.05952,   inf] (59), [-0.05867,   inf] (59), [-0.05865,   inf] (59), [-0.05671,   inf] (59), [-0.05632,   inf] (59), [-0.05626,   inf] (59), [-0.05580,   inf] (59), [-0.05549,   inf] (59), [-0.05505,   inf] (59), [-0.05483,   inf] (59), [-0.05463,   inf] (59), 
length of domains: 677
Total time: 0.8227	 pickout: 0.0753	 decision: 0.1385	 get_bound: 0.5440	 add_domain: 0.0648
Current lb:-0.06792392581701279
9196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.200986862182617

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [3, 106] [3, 129] [3, 106] [3, 106] [3, 106] [3, 129] [3, 106] [3, 106] [0, 83] [3, 129] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: -29.077640533447266 with beta sum per layer: [78.56482696533203, 90.64698028564453, 0.0, 161.507568359375]
alpha/beta optimization time: 0.28022050857543945
This batch time : update_bounds func: 0.4893	 prepare: 0.1171	 bound: 0.2806	 transfer: 0.0147	 finalize: 0.0746
Accumulated time: update_bounds func: 10.1557	 prepare: 1.3294	 bound: 7.6238	 transfer: 0.0147	 finalize: 0.9785
batch bounding time:  0.4905121326446533
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (61), [-0.06646,   inf] (61), [-0.06592,   inf] (61), [-0.06585,   inf] (61), [-0.06550,   inf] (61), [-0.06481,   inf] (61), [-0.06176,   inf] (61), [-0.06165,   inf] (61), [-0.05969,   inf] (61), [-0.05952,   inf] (61), [-0.05865,   inf] (61), [-0.05845,   inf] (61), [-0.05651,   inf] (61), [-0.05632,   inf] (61), [-0.05626,   inf] (61), [-0.05580,   inf] (61), [-0.05508,   inf] (61), [-0.05483,   inf] (61), [-0.05478,   inf] (61), [-0.05463,   inf] (61), 
length of domains: 705
Total time: 0.8266	 pickout: 0.0742	 decision: 0.1931	 get_bound: 0.4923	 add_domain: 0.0669
Current lb:-0.06792392581701279
10196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.045620918273926

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [3, 120] [3, 106] [3, 120] [3, 120] [3, 120] [3, 106] [3, 120] [3, 120] [3, 150] [3, 106] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: -30.496524810791016 with beta sum per layer: [75.50775146484375, 88.9750747680664, 0.0, 169.34849548339844]
alpha/beta optimization time: 0.2825014591217041
This batch time : update_bounds func: 0.4934	 prepare: 0.1164	 bound: 0.2830	 transfer: 0.0152	 finalize: 0.0766
Accumulated time: update_bounds func: 10.6492	 prepare: 1.4458	 bound: 7.9067	 transfer: 0.0152	 finalize: 1.0551
batch bounding time:  0.49466753005981445
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (63), [-0.06646,   inf] (63), [-0.06592,   inf] (63), [-0.06584,   inf] (63), [-0.06550,   inf] (63), [-0.06481,   inf] (63), [-0.06176,   inf] (63), [-0.06165,   inf] (63), [-0.05954,   inf] (63), [-0.05952,   inf] (63), [-0.05865,   inf] (63), [-0.05839,   inf] (63), [-0.05651,   inf] (63), [-0.05632,   inf] (63), [-0.05626,   inf] (63), [-0.05580,   inf] (63), [-0.05483,   inf] (63), [-0.05474,   inf] (63), [-0.05472,   inf] (63), [-0.05463,   inf] (63), 
length of domains: 756
Total time: 0.8377	 pickout: 0.0757	 decision: 0.1945	 get_bound: 0.4965	 add_domain: 0.0710
Current lb:-0.06792392581701279
11196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.90066146850586

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 157] [3, 120] [1, 157] [1, 157] [1, 157] [3, 120] [1, 157] [1, 157] [3, 129] [3, 120] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: -34.638153076171875 with beta sum per layer: [69.88999938964844, 93.80462646484375, 0.0, 162.93702697753906]
alpha/beta optimization time: 0.279987096786499
This batch time : update_bounds func: 0.4977	 prepare: 0.1181	 bound: 0.2804	 transfer: 0.0143	 finalize: 0.0826
Accumulated time: update_bounds func: 11.1469	 prepare: 1.5639	 bound: 8.1871	 transfer: 0.0143	 finalize: 1.1377
batch bounding time:  0.4999516010284424
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (65), [-0.06646,   inf] (65), [-0.06592,   inf] (65), [-0.06590,   inf] (65), [-0.06584,   inf] (65), [-0.06550,   inf] (65), [-0.06481,   inf] (65), [-0.06467,   inf] (65), [-0.06411,   inf] (65), [-0.06382,   inf] (65), [-0.06176,   inf] (65), [-0.06165,   inf] (65), [-0.06018,   inf] (65), [-0.06014,   inf] (65), [-0.05952,   inf] (65), [-0.05946,   inf] (65), [-0.05865,   inf] (65), [-0.05815,   inf] (65), [-0.05636,   inf] (65), [-0.05632,   inf] (65), 
length of domains: 832
Total time: 0.8522	 pickout: 0.0773	 decision: 0.1943	 get_bound: 0.5019	 add_domain: 0.0787
Current lb:-0.06792392581701279
12196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.77600884437561

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 34] [1, 157] [1, 34] [0, 177] [1, 34] [1, 34] [1, 157] [1, 34] [0, 177] [0, 177] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: -26.168128967285156 with beta sum per layer: [73.28734588623047, 107.26264953613281, 0.0, 145.40280151367188]
alpha/beta optimization time: 0.27749133110046387
This batch time : update_bounds func: 0.4885	 prepare: 0.1157	 bound: 0.2779	 transfer: 0.0153	 finalize: 0.0769
Accumulated time: update_bounds func: 11.6354	 prepare: 1.6796	 bound: 8.4650	 transfer: 0.0153	 finalize: 1.2146
batch bounding time:  0.489851713180542
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (67), [-0.06646,   inf] (67), [-0.06592,   inf] (67), [-0.06588,   inf] (67), [-0.06584,   inf] (67), [-0.06550,   inf] (67), [-0.06506,   inf] (67), [-0.06481,   inf] (67), [-0.06401,   inf] (67), [-0.06374,   inf] (67), [-0.06369,   inf] (67), [-0.06327,   inf] (67), [-0.06176,   inf] (67), [-0.06165,   inf] (67), [-0.06005,   inf] (67), [-0.05959,   inf] (67), [-0.05952,   inf] (67), [-0.05946,   inf] (67), [-0.05943,   inf] (67), [-0.05865,   inf] (67), 
length of domains: 970
Total time: 0.9540	 pickout: 0.0807	 decision: 0.2201	 get_bound: 0.4917	 add_domain: 0.1614
Current lb:-0.06792392581701279
13196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.747262716293335

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [0, 214] [1, 34] [0, 56] [0, 177] [0, 56] [0, 214] [1, 34] [1, 34] [0, 177] [1, 34] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: -36.6478271484375 with beta sum per layer: [81.55780029296875, 133.51675415039062, 0.0, 112.39988708496094]
alpha/beta optimization time: 0.27820920944213867
This batch time : update_bounds func: 0.5474	 prepare: 0.1157	 bound: 0.2786	 transfer: 0.0146	 finalize: 0.1358
Accumulated time: update_bounds func: 12.1828	 prepare: 1.7954	 bound: 8.7435	 transfer: 0.0146	 finalize: 1.3505
batch bounding time:  0.5486910343170166
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (69), [-0.06646,   inf] (69), [-0.06592,   inf] (69), [-0.06584,   inf] (69), [-0.06550,   inf] (69), [-0.06513,   inf] (69), [-0.06494,   inf] (69), [-0.06481,   inf] (69), [-0.06398,   inf] (69), [-0.06357,   inf] (69), [-0.06325,   inf] (69), [-0.06315,   inf] (69), [-0.06176,   inf] (69), [-0.06165,   inf] (69), [-0.06005,   inf] (69), [-0.05959,   inf] (69), [-0.05952,   inf] (69), [-0.05929,   inf] (69), [-0.05865,   inf] (69), [-0.05840,   inf] (69), 
length of domains: 1091
Total time: 0.8523	 pickout: 0.0750	 decision: 0.1409	 get_bound: 0.5506	 add_domain: 0.0858
Current lb:-0.06792392581701279
14196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.61713695526123

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [0, 56] [0, 214] [0, 214] [0, 214] [0, 56] [1, 34] [0, 56] [0, 214] [0, 56] [0, 56] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: -25.1048641204834 with beta sum per layer: [89.13906860351562, 128.14056396484375, 0.0, 89.98954772949219]
alpha/beta optimization time: 0.2789900302886963
This batch time : update_bounds func: 0.5462	 prepare: 0.1155	 bound: 0.2795	 transfer: 0.0152	 finalize: 0.0741
Accumulated time: update_bounds func: 12.7290	 prepare: 1.9109	 bound: 9.0230	 transfer: 0.0152	 finalize: 1.4246
batch bounding time:  0.5474822521209717
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (71), [-0.06646,   inf] (71), [-0.06592,   inf] (71), [-0.06584,   inf] (71), [-0.06550,   inf] (71), [-0.06506,   inf] (71), [-0.06487,   inf] (71), [-0.06481,   inf] (71), [-0.06398,   inf] (71), [-0.06343,   inf] (71), [-0.06324,   inf] (71), [-0.06315,   inf] (71), [-0.06176,   inf] (71), [-0.06165,   inf] (71), [-0.06005,   inf] (71), [-0.05959,   inf] (71), [-0.05952,   inf] (71), [-0.05927,   inf] (71), [-0.05865,   inf] (71), [-0.05852,   inf] (71), 
length of domains: 1247
Total time: 0.8580	 pickout: 0.0754	 decision: 0.1409	 get_bound: 0.5494	 add_domain: 0.0923
Current lb:-0.06792392581701279
15196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 19.492921590805054

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 55] [0, 56] [1, 55] [1, 55] [1, 55] [0, 56] [0, 214] [0, 56] [1, 55] [0, 214] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: 3.5442886352539062 with beta sum per layer: [100.22280883789062, 95.71005249023438, 0.0, 89.60787200927734]
alpha/beta optimization time: 0.27780914306640625
This batch time : update_bounds func: 0.4872	 prepare: 0.1157	 bound: 0.2782	 transfer: 0.0153	 finalize: 0.0756
Accumulated time: update_bounds func: 13.2162	 prepare: 2.0266	 bound: 9.3012	 transfer: 0.0153	 finalize: 1.5002
batch bounding time:  0.48839616775512695
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (73), [-0.06646,   inf] (73), [-0.06592,   inf] (73), [-0.06584,   inf] (73), [-0.06550,   inf] (73), [-0.06482,   inf] (73), [-0.06481,   inf] (73), [-0.06467,   inf] (73), [-0.06398,   inf] (73), [-0.06343,   inf] (73), [-0.06323,   inf] (73), [-0.06315,   inf] (73), [-0.06176,   inf] (73), [-0.06165,   inf] (73), [-0.06005,   inf] (73), [-0.06005,   inf] (73), [-0.05959,   inf] (73), [-0.05952,   inf] (73), [-0.05952,   inf] (73), [-0.05927,   inf] (73), 
length of domains: 1520
Total time: 0.8838	 pickout: 0.0751	 decision: 0.2078	 get_bound: 0.4902	 add_domain: 0.1107
Current lb:-0.06792392581701279
16196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 20.393919706344604

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 7] [1, 235] [1, 7] [1, 7] [1, 7] [1, 55] [1, 235] [0, 214] [0, 214] [1, 55] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: 16.303043365478516 with beta sum per layer: [100.32242584228516, 85.8125, 0.0, 94.10272216796875]
alpha/beta optimization time: 0.2799854278564453
This batch time : update_bounds func: 0.4899	 prepare: 0.1170	 bound: 0.2804	 transfer: 0.0153	 finalize: 0.0747
Accumulated time: update_bounds func: 13.7061	 prepare: 2.1436	 bound: 9.5816	 transfer: 0.0153	 finalize: 1.5749
batch bounding time:  0.4910929203033447
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (75), [-0.06791,   inf] (75), [-0.06646,   inf] (75), [-0.06638,   inf] (75), [-0.06592,   inf] (75), [-0.06592,   inf] (75), [-0.06584,   inf] (75), [-0.06584,   inf] (75), [-0.06550,   inf] (75), [-0.06550,   inf] (75), [-0.06481,   inf] (75), [-0.06478,   inf] (75), [-0.06467,   inf] (75), [-0.06429,   inf] (75), [-0.06398,   inf] (75), [-0.06343,   inf] (75), [-0.06322,   inf] (75), [-0.06315,   inf] (75), [-0.06176,   inf] (75), [-0.06176,   inf] (75), 
length of domains: 1860
Total time: 0.9034	 pickout: 0.0761	 decision: 0.2115	 get_bound: 0.4929	 add_domain: 0.1229
Current lb:-0.06792392581701279
17196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 21.313753604888916

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 235] [0, 83] [1, 55] [1, 55] [1, 235] [0, 83] [1, 235] [1, 235] [1, 235] [1, 235] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: 24.929611206054688 with beta sum per layer: [82.25777435302734, 84.38926696777344, 0.0, 104.1147689819336]
alpha/beta optimization time: 0.28015947341918945
This batch time : update_bounds func: 0.4895	 prepare: 0.1172	 bound: 0.2806	 transfer: 0.0153	 finalize: 0.0739
Accumulated time: update_bounds func: 14.1956	 prepare: 2.2608	 bound: 9.8622	 transfer: 0.0153	 finalize: 1.6488
batch bounding time:  0.490816593170166
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (77), [-0.06786,   inf] (77), [-0.06766,   inf] (77), [-0.06646,   inf] (77), [-0.06637,   inf] (77), [-0.06592,   inf] (77), [-0.06589,   inf] (77), [-0.06584,   inf] (77), [-0.06584,   inf] (77), [-0.06563,   inf] (77), [-0.06562,   inf] (77), [-0.06550,   inf] (77), [-0.06550,   inf] (77), [-0.06545,   inf] (77), [-0.06539,   inf] (77), [-0.06531,   inf] (77), [-0.06481,   inf] (77), [-0.06474,   inf] (77), [-0.06473,   inf] (77), [-0.06467,   inf] (77), 
length of domains: 2233
Total time: 1.0018	 pickout: 0.0765	 decision: 0.2154	 get_bound: 0.4927	 add_domain: 0.2172
Current lb:-0.06792392581701279
18196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 22.331565856933594

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 191] [0, 83] [1, 235] [1, 7] [1, 7] [1, 191] [1, 235] [0, 83] [1, 191] [1, 191] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: 23.762985229492188 with beta sum per layer: [76.0740966796875, 94.59759521484375, 0.0, 112.28713989257812]
alpha/beta optimization time: 0.2812786102294922
This batch time : update_bounds func: 0.5804	 prepare: 0.1185	 bound: 0.2817	 transfer: 0.0153	 finalize: 0.1622
Accumulated time: update_bounds func: 14.7760	 prepare: 2.3793	 bound: 10.1438	 transfer: 0.0153	 finalize: 1.8110
batch bounding time:  0.5835332870483398
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (79), [-0.06769,   inf] (79), [-0.06764,   inf] (79), [-0.06762,   inf] (79), [-0.06646,   inf] (79), [-0.06645,   inf] (79), [-0.06637,   inf] (79), [-0.06633,   inf] (79), [-0.06592,   inf] (79), [-0.06588,   inf] (79), [-0.06584,   inf] (79), [-0.06563,   inf] (79), [-0.06562,   inf] (79), [-0.06554,   inf] (79), [-0.06550,   inf] (79), [-0.06550,   inf] (79), [-0.06546,   inf] (79), [-0.06545,   inf] (79), [-0.06530,   inf] (79), [-0.06512,   inf] (79), 
length of domains: 2560
Total time: 0.9310	 pickout: 0.0776	 decision: 0.1413	 get_bound: 0.5854	 add_domain: 0.1266
Current lb:-0.06792392581701279
19196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 23.279478311538696

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 22] [1, 191] [1, 191] [1, 191] [1, 191] [1, 191] [0, 177] [1, 191] [1, 22] [1, 191] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: 16.56810760498047 with beta sum per layer: [68.79203796386719, 107.80399322509766, 0.0, 120.13578033447266]
alpha/beta optimization time: 0.2808084487915039
This batch time : update_bounds func: 0.4929	 prepare: 0.1178	 bound: 0.2812	 transfer: 0.0171	 finalize: 0.0743
Accumulated time: update_bounds func: 15.2688	 prepare: 2.4971	 bound: 10.4250	 transfer: 0.0171	 finalize: 1.8853
batch bounding time:  0.4942739009857178
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (81), [-0.06767,   inf] (81), [-0.06763,   inf] (81), [-0.06761,   inf] (81), [-0.06646,   inf] (81), [-0.06645,   inf] (81), [-0.06637,   inf] (81), [-0.06631,   inf] (81), [-0.06592,   inf] (81), [-0.06588,   inf] (81), [-0.06584,   inf] (81), [-0.06562,   inf] (81), [-0.06552,   inf] (81), [-0.06550,   inf] (81), [-0.06550,   inf] (81), [-0.06549,   inf] (81), [-0.06546,   inf] (81), [-0.06536,   inf] (81), [-0.06521,   inf] (81), [-0.06512,   inf] (81), 
length of domains: 2798
Total time: 0.9329	 pickout: 0.0782	 decision: 0.2417	 get_bound: 0.4963	 add_domain: 0.1168
Current lb:-0.06792392581701279
20196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 24.230712175369263

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 165] [1, 22] [1, 22] [1, 22] [1, 22] [1, 22] [1, 191] [0, 83] [1, 165] [1, 22] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: 12.772760391235352 with beta sum per layer: [68.39550018310547, 112.58277893066406, 0.0, 129.65432739257812]
alpha/beta optimization time: 0.29075002670288086
This batch time : update_bounds func: 0.5115	 prepare: 0.1178	 bound: 0.2912	 transfer: 0.0156	 finalize: 0.0845
Accumulated time: update_bounds func: 15.7803	 prepare: 2.6149	 bound: 10.7162	 transfer: 0.0156	 finalize: 1.9698
batch bounding time:  0.5128567218780518
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (83), [-0.06767,   inf] (83), [-0.06761,   inf] (83), [-0.06761,   inf] (83), [-0.06646,   inf] (83), [-0.06645,   inf] (83), [-0.06637,   inf] (83), [-0.06629,   inf] (83), [-0.06592,   inf] (83), [-0.06588,   inf] (83), [-0.06584,   inf] (83), [-0.06562,   inf] (83), [-0.06550,   inf] (83), [-0.06550,   inf] (83), [-0.06548,   inf] (83), [-0.06546,   inf] (83), [-0.06540,   inf] (83), [-0.06536,   inf] (83), [-0.06512,   inf] (83), [-0.06502,   inf] (83), 
length of domains: 2996
Total time: 0.9652	 pickout: 0.0778	 decision: 0.2571	 get_bound: 0.5148	 add_domain: 0.1155
Current lb:-0.06792392581701279
21196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 25.217637538909912

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 99] [1, 165] [1, 165] [1, 165] [1, 165] [1, 165] [1, 22] [1, 22] [1, 99] [1, 165] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: 11.614020347595215 with beta sum per layer: [65.92681884765625, 118.36677551269531, 0.0, 146.11727905273438]
alpha/beta optimization time: 0.2974545955657959
This batch time : update_bounds func: 0.5107	 prepare: 0.1180	 bound: 0.2978	 transfer: 0.0153	 finalize: 0.0769
Accumulated time: update_bounds func: 16.2910	 prepare: 2.7329	 bound: 11.0140	 transfer: 0.0153	 finalize: 2.0467
batch bounding time:  0.5119595527648926
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (85), [-0.06766,   inf] (85), [-0.06761,   inf] (85), [-0.06760,   inf] (85), [-0.06646,   inf] (85), [-0.06645,   inf] (85), [-0.06637,   inf] (85), [-0.06625,   inf] (85), [-0.06592,   inf] (85), [-0.06588,   inf] (85), [-0.06584,   inf] (85), [-0.06562,   inf] (85), [-0.06550,   inf] (85), [-0.06550,   inf] (85), [-0.06548,   inf] (85), [-0.06546,   inf] (85), [-0.06536,   inf] (85), [-0.06535,   inf] (85), [-0.06512,   inf] (85), [-0.06489,   inf] (85), 
length of domains: 3155
Total time: 0.9789	 pickout: 0.0807	 decision: 0.2738	 get_bound: 0.5139	 add_domain: 0.1106
Current lb:-0.06792392581701279
22196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 26.216970682144165

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 148] [1, 99] [1, 99] [1, 99] [1, 99] [1, 99] [1, 165] [1, 165] [1, 148] [1, 99] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: 8.652995109558105 with beta sum per layer: [61.946266174316406, 120.31835174560547, 0.0, 150.76223754882812]
alpha/beta optimization time: 0.29994940757751465
This batch time : update_bounds func: 0.5127	 prepare: 0.1174	 bound: 0.3004	 transfer: 0.0153	 finalize: 0.0769
Accumulated time: update_bounds func: 16.8037	 prepare: 2.8503	 bound: 11.3144	 transfer: 0.0153	 finalize: 2.1236
batch bounding time:  0.5141067504882812
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (87), [-0.06766,   inf] (87), [-0.06761,   inf] (87), [-0.06760,   inf] (87), [-0.06646,   inf] (87), [-0.06645,   inf] (87), [-0.06637,   inf] (87), [-0.06625,   inf] (87), [-0.06592,   inf] (87), [-0.06588,   inf] (87), [-0.06584,   inf] (87), [-0.06562,   inf] (87), [-0.06550,   inf] (87), [-0.06550,   inf] (87), [-0.06548,   inf] (87), [-0.06546,   inf] (87), [-0.06536,   inf] (87), [-0.06535,   inf] (87), [-0.06512,   inf] (87), [-0.06489,   inf] (87), 
length of domains: 3290
Total time: 1.0799	 pickout: 0.0791	 decision: 0.2590	 get_bound: 0.5161	 add_domain: 0.2256
Current lb:-0.06792392581701279
23196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 27.31744909286499

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [0, 71] [1, 148] [1, 148] [1, 148] [0, 71] [0, 71] [1, 99] [0, 177] [1, 78] [1, 148] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: 7.790497779846191 with beta sum per layer: [56.49888610839844, 110.74346923828125, 0.0, 144.2379150390625]
alpha/beta optimization time: 0.3007235527038574
This batch time : update_bounds func: 0.5148	 prepare: 0.1180	 bound: 0.3011	 transfer: 0.0153	 finalize: 0.0777
Accumulated time: update_bounds func: 17.3185	 prepare: 2.9683	 bound: 11.6155	 transfer: 0.0153	 finalize: 2.2013
batch bounding time:  0.5162057876586914
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (89), [-0.06766,   inf] (89), [-0.06761,   inf] (89), [-0.06760,   inf] (89), [-0.06646,   inf] (89), [-0.06645,   inf] (89), [-0.06637,   inf] (89), [-0.06625,   inf] (89), [-0.06592,   inf] (89), [-0.06588,   inf] (89), [-0.06584,   inf] (89), [-0.06567,   inf] (89), [-0.06562,   inf] (89), [-0.06550,   inf] (89), [-0.06550,   inf] (89), [-0.06548,   inf] (89), [-0.06546,   inf] (89), [-0.06542,   inf] (89), [-0.06536,   inf] (89), [-0.06535,   inf] (89), 
length of domains: 3462
Total time: 0.9888	 pickout: 0.0778	 decision: 0.1461	 get_bound: 0.5183	 add_domain: 0.2466
Current lb:-0.06792392581701279
24196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 28.32718515396118

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 78] [1, 78] [1, 78] [1, 78] [1, 148] [1, 148] [0, 71] [1, 99] [0, 71] [1, 78] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: 17.560657501220703 with beta sum per layer: [54.94419860839844, 100.65956115722656, 0.0, 122.53349304199219]
alpha/beta optimization time: 0.29654455184936523
This batch time : update_bounds func: 0.6485	 prepare: 0.1189	 bound: 0.2969	 transfer: 0.0153	 finalize: 0.2149
Accumulated time: update_bounds func: 17.9670	 prepare: 3.0872	 bound: 11.9124	 transfer: 0.0153	 finalize: 2.4162
batch bounding time:  0.6499495506286621
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (91), [-0.06766,   inf] (91), [-0.06761,   inf] (91), [-0.06760,   inf] (91), [-0.06721,   inf] (91), [-0.06688,   inf] (91), [-0.06687,   inf] (91), [-0.06682,   inf] (91), [-0.06646,   inf] (91), [-0.06645,   inf] (91), [-0.06637,   inf] (91), [-0.06625,   inf] (91), [-0.06592,   inf] (91), [-0.06588,   inf] (91), [-0.06584,   inf] (91), [-0.06567,   inf] (91), [-0.06566,   inf] (91), [-0.06566,   inf] (91), [-0.06559,   inf] (91), [-0.06559,   inf] (91), 
length of domains: 3664
Total time: 0.9942	 pickout: 0.0768	 decision: 0.1460	 get_bound: 0.6520	 add_domain: 0.1194
Current lb:-0.06792392581701279
25196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 29.34176802635193

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 242] [0, 71] [0, 71] [0, 71] [0, 83] [0, 71] [0, 71] [1, 242] [1, 242] [1, 242] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: 21.55727767944336 with beta sum per layer: [56.95188903808594, 88.32965087890625, 0.0, 114.08297729492188]
alpha/beta optimization time: 0.29789257049560547
This batch time : update_bounds func: 0.6505	 prepare: 0.1187	 bound: 0.2983	 transfer: 0.0154	 finalize: 0.2152
Accumulated time: update_bounds func: 18.6175	 prepare: 3.2059	 bound: 12.2107	 transfer: 0.0154	 finalize: 2.6313
batch bounding time:  0.6519296169281006
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (93), [-0.06792,   inf] (93), [-0.06766,   inf] (93), [-0.06761,   inf] (93), [-0.06760,   inf] (93), [-0.06689,   inf] (93), [-0.06688,   inf] (93), [-0.06687,   inf] (93), [-0.06681,   inf] (93), [-0.06680,   inf] (93), [-0.06646,   inf] (93), [-0.06646,   inf] (93), [-0.06645,   inf] (93), [-0.06645,   inf] (93), [-0.06637,   inf] (93), [-0.06636,   inf] (93), [-0.06625,   inf] (93), [-0.06592,   inf] (93), [-0.06588,   inf] (93), [-0.06584,   inf] (93), 
length of domains: 3907
Total time: 1.0070	 pickout: 0.0793	 decision: 0.1458	 get_bound: 0.6539	 add_domain: 0.1279
Current lb:-0.067922443151474
26196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 30.368985652923584

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 102] [1, 102] [1, 242] [1, 242] [1, 242] [1, 242] [1, 242] [1, 242] [0, 242] [0, 71] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: 19.68998908996582 with beta sum per layer: [70.81167602539062, 76.33881378173828, 0.0, 110.00888061523438]
alpha/beta optimization time: 0.2965359687805176
This batch time : update_bounds func: 0.6502	 prepare: 0.1177	 bound: 0.2969	 transfer: 0.0147	 finalize: 0.2183
Accumulated time: update_bounds func: 19.2677	 prepare: 3.3235	 bound: 12.5077	 transfer: 0.0147	 finalize: 2.8496
batch bounding time:  0.6516330242156982
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (95), [-0.06792,   inf] (95), [-0.06765,   inf] (95), [-0.06764,   inf] (95), [-0.06761,   inf] (95), [-0.06761,   inf] (95), [-0.06760,   inf] (95), [-0.06760,   inf] (95), [-0.06688,   inf] (95), [-0.06687,   inf] (95), [-0.06686,   inf] (95), [-0.06681,   inf] (95), [-0.06680,   inf] (95), [-0.06680,   inf] (95), [-0.06679,   inf] (95), [-0.06677,   inf] (95), [-0.06646,   inf] (95), [-0.06646,   inf] (95), [-0.06646,   inf] (95), [-0.06645,   inf] (95), 
length of domains: 4154
Total time: 1.0167	 pickout: 0.0789	 decision: 0.1488	 get_bound: 0.6537	 add_domain: 0.1354
Current lb:-0.06791942566633224
27196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 31.405335664749146

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [0, 29] [0, 29] [0, 29] [0, 29] [1, 102] [1, 102] [0, 29] [0, 29] [0, 29] [0, 177] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: 21.24556541442871 with beta sum per layer: [82.41210174560547, 73.63027954101562, 0.0, 130.79306030273438]
alpha/beta optimization time: 0.2972443103790283
This batch time : update_bounds func: 0.6602	 prepare: 0.1186	 bound: 0.2976	 transfer: 0.0153	 finalize: 0.2262
Accumulated time: update_bounds func: 19.9279	 prepare: 3.4421	 bound: 12.8053	 transfer: 0.0153	 finalize: 3.0759
batch bounding time:  0.6614704132080078
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (97), [-0.06792,   inf] (97), [-0.06765,   inf] (97), [-0.06764,   inf] (97), [-0.06761,   inf] (97), [-0.06761,   inf] (97), [-0.06760,   inf] (97), [-0.06760,   inf] (97), [-0.06687,   inf] (97), [-0.06684,   inf] (97), [-0.06681,   inf] (97), [-0.06680,   inf] (97), [-0.06680,   inf] (97), [-0.06679,   inf] (97), [-0.06678,   inf] (97), [-0.06677,   inf] (97), [-0.06646,   inf] (97), [-0.06645,   inf] (97), [-0.06645,   inf] (97), [-0.06645,   inf] (97), 
length of domains: 4417
Total time: 1.0335	 pickout: 0.0785	 decision: 0.1557	 get_bound: 0.6633	 add_domain: 0.1360
Current lb:-0.06791897863149643
28196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 32.45879769325256

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 108] [0, 53] [0, 53] [1, 102] [0, 29] [0, 29] [0, 53] [0, 53] [1, 102] [0, 53] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: 17.520267486572266 with beta sum per layer: [66.98577880859375, 82.51654052734375, 0.0, 122.41710662841797]
alpha/beta optimization time: 0.29767656326293945
This batch time : update_bounds func: 0.6683	 prepare: 0.1188	 bound: 0.2981	 transfer: 0.0166	 finalize: 0.2321
Accumulated time: update_bounds func: 20.5962	 prepare: 3.5609	 bound: 13.1034	 transfer: 0.0166	 finalize: 3.3079
batch bounding time:  0.669823408126831
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (99), [-0.06792,   inf] (99), [-0.06764,   inf] (99), [-0.06761,   inf] (99), [-0.06761,   inf] (99), [-0.06761,   inf] (99), [-0.06760,   inf] (99), [-0.06760,   inf] (99), [-0.06687,   inf] (99), [-0.06684,   inf] (99), [-0.06681,   inf] (99), [-0.06680,   inf] (99), [-0.06679,   inf] (99), [-0.06678,   inf] (99), [-0.06677,   inf] (99), [-0.06676,   inf] (99), [-0.06646,   inf] (99), [-0.06645,   inf] (99), [-0.06645,   inf] (99), [-0.06644,   inf] (99), 
length of domains: 4622
Total time: 1.0426	 pickout: 0.0790	 decision: 0.1640	 get_bound: 0.6719	 add_domain: 0.1278
Current lb:-0.06791897863149643
29196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 33.52221727371216

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 123] [1, 108] [1, 108] [0, 54] [0, 53] [0, 53] [0, 54] [1, 102] [0, 29] [0, 54] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: 13.965282440185547 with beta sum per layer: [58.10737991333008, 94.5703125, 0.0, 111.04783630371094]
alpha/beta optimization time: 0.30034589767456055
This batch time : update_bounds func: 0.6817	 prepare: 0.1184	 bound: 0.3008	 transfer: 0.0154	 finalize: 0.2443
Accumulated time: update_bounds func: 21.2779	 prepare: 3.6793	 bound: 13.4041	 transfer: 0.0154	 finalize: 3.5523
batch bounding time:  0.6831948757171631
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (101), [-0.06792,   inf] (101), [-0.06792,   inf] (101), [-0.06764,   inf] (101), [-0.06761,   inf] (101), [-0.06761,   inf] (101), [-0.06761,   inf] (101), [-0.06760,   inf] (101), [-0.06760,   inf] (101), [-0.06687,   inf] (101), [-0.06684,   inf] (101), [-0.06681,   inf] (101), [-0.06680,   inf] (101), [-0.06679,   inf] (101), [-0.06678,   inf] (101), [-0.06677,   inf] (101), [-0.06676,   inf] (101), [-0.06646,   inf] (101), [-0.06645,   inf] (101), [-0.06645,   inf] (101), 
length of domains: 4789
Total time: 1.0586	 pickout: 0.0798	 decision: 0.1707	 get_bound: 0.6854	 add_domain: 0.1227
Current lb:-0.06791897863149643
30196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 34.60214114189148

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 136] [0, 83] [1, 123] [1, 123] [0, 76] [1, 108] [1, 108] [1, 102] [1, 108] [1, 108] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: 16.69614601135254 with beta sum per layer: [56.79872131347656, 88.32978057861328, 0.0, 113.71549987792969]
alpha/beta optimization time: 0.3024270534515381
This batch time : update_bounds func: 0.5172	 prepare: 0.1182	 bound: 0.3028	 transfer: 0.0147	 finalize: 0.0789
Accumulated time: update_bounds func: 21.7950	 prepare: 3.7975	 bound: 13.7070	 transfer: 0.0147	 finalize: 3.6311
batch bounding time:  0.5184881687164307
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (103), [-0.06792,   inf] (103), [-0.06792,   inf] (103), [-0.06764,   inf] (103), [-0.06761,   inf] (103), [-0.06761,   inf] (103), [-0.06761,   inf] (103), [-0.06760,   inf] (103), [-0.06760,   inf] (103), [-0.06687,   inf] (103), [-0.06684,   inf] (103), [-0.06683,   inf] (103), [-0.06681,   inf] (103), [-0.06680,   inf] (103), [-0.06679,   inf] (103), [-0.06678,   inf] (103), [-0.06677,   inf] (103), [-0.06676,   inf] (103), [-0.06669,   inf] (103), [-0.06646,   inf] (103), 
length of domains: 4978
Total time: 1.0911	 pickout: 0.0791	 decision: 0.1829	 get_bound: 0.5204	 add_domain: 0.3087
Current lb:-0.06791897863149643
31196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 35.714804887771606

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 142] [1, 136] [0, 54] [0, 53] [1, 102] [0, 54] [0, 54] [0, 76] [1, 123] [0, 53] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: 26.202341079711914 with beta sum per layer: [54.77119445800781, 70.99880981445312, 0.0, 103.44413757324219]
alpha/beta optimization time: 0.3086848258972168
This batch time : update_bounds func: 0.5244	 prepare: 0.1186	 bound: 0.3091	 transfer: 0.0155	 finalize: 0.0783
Accumulated time: update_bounds func: 22.3195	 prepare: 3.9161	 bound: 14.0161	 transfer: 0.0155	 finalize: 3.7094
batch bounding time:  0.5257737636566162
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (105), [-0.06792,   inf] (105), [-0.06792,   inf] (105), [-0.06764,   inf] (105), [-0.06761,   inf] (105), [-0.06761,   inf] (105), [-0.06761,   inf] (105), [-0.06760,   inf] (105), [-0.06760,   inf] (105), [-0.06687,   inf] (105), [-0.06684,   inf] (105), [-0.06683,   inf] (105), [-0.06681,   inf] (105), [-0.06680,   inf] (105), [-0.06680,   inf] (105), [-0.06679,   inf] (105), [-0.06677,   inf] (105), [-0.06677,   inf] (105), [-0.06676,   inf] (105), [-0.06669,   inf] (105), 
length of domains: 5230
Total time: 0.9559	 pickout: 0.0922	 decision: 0.1898	 get_bound: 0.5277	 add_domain: 0.1461
Current lb:-0.06791897863149643
32196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 36.70151162147522

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [0, 53] [0, 54] [0, 76] [0, 54] [1, 108] [1, 123] [1, 123] [1, 108] [0, 54] [1, 123] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: 35.74066162109375 with beta sum per layer: [55.32040023803711, 59.11089324951172, 0.0, 107.18275451660156]
alpha/beta optimization time: 0.3070249557495117
This batch time : update_bounds func: 0.5318	 prepare: 0.1193	 bound: 0.3075	 transfer: 0.0157	 finalize: 0.0866
Accumulated time: update_bounds func: 22.8512	 prepare: 4.0353	 bound: 14.3236	 transfer: 0.0157	 finalize: 3.7960
batch bounding time:  0.5331158638000488
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (107), [-0.06792,   inf] (107), [-0.06792,   inf] (107), [-0.06764,   inf] (107), [-0.06761,   inf] (107), [-0.06761,   inf] (107), [-0.06761,   inf] (107), [-0.06760,   inf] (107), [-0.06760,   inf] (107), [-0.06687,   inf] (107), [-0.06684,   inf] (107), [-0.06681,   inf] (107), [-0.06680,   inf] (107), [-0.06679,   inf] (107), [-0.06677,   inf] (107), [-0.06677,   inf] (107), [-0.06677,   inf] (107), [-0.06676,   inf] (107), [-0.06676,   inf] (107), [-0.06674,   inf] (107), 
length of domains: 5540
Total time: 1.1493	 pickout: 0.0832	 decision: 0.3716	 get_bound: 0.5352	 add_domain: 0.1594
Current lb:-0.06791897863149643
33196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 37.873069524765015

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [0, 54] [1, 142] [0, 83] [0, 76] [0, 177] [0, 76] [0, 76] [0, 177] [0, 76] [0, 54] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: 41.77369689941406 with beta sum per layer: [55.15544891357422, 47.70762634277344, 0.0, 108.91522216796875]
alpha/beta optimization time: 0.28511524200439453
This batch time : update_bounds func: 0.5011	 prepare: 0.1193	 bound: 0.2856	 transfer: 0.0156	 finalize: 0.0778
Accumulated time: update_bounds func: 23.3523	 prepare: 4.1546	 bound: 14.6091	 transfer: 0.0156	 finalize: 3.8738
batch bounding time:  0.5024657249450684
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (109), [-0.06792,   inf] (109), [-0.06764,   inf] (109), [-0.06761,   inf] (109), [-0.06761,   inf] (109), [-0.06760,   inf] (109), [-0.06760,   inf] (109), [-0.06759,   inf] (109), [-0.06687,   inf] (109), [-0.06684,   inf] (109), [-0.06681,   inf] (109), [-0.06680,   inf] (109), [-0.06679,   inf] (109), [-0.06677,   inf] (109), [-0.06677,   inf] (109), [-0.06676,   inf] (109), [-0.06670,   inf] (109), [-0.06670,   inf] (109), [-0.06669,   inf] (109), [-0.06669,   inf] (109), 
length of domains: 5898
Total time: 1.1628	 pickout: 0.0810	 decision: 0.4116	 get_bound: 0.5044	 add_domain: 0.1657
Current lb:-0.06791897863149643
34196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 39.05583167076111

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [0, 76] [0, 76] [1, 136] [1, 136] [0, 177] [0, 242] [1, 136] [0, 242] [1, 136] [1, 142] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: 40.860538482666016 with beta sum per layer: [49.46115493774414, 53.79371643066406, 0.0, 108.52886199951172]
alpha/beta optimization time: 0.2838723659515381
This batch time : update_bounds func: 0.5017	 prepare: 0.1196	 bound: 0.2843	 transfer: 0.0155	 finalize: 0.0797
Accumulated time: update_bounds func: 23.8540	 prepare: 4.2743	 bound: 14.8934	 transfer: 0.0155	 finalize: 3.9535
batch bounding time:  0.503129243850708
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (111), [-0.06792,   inf] (111), [-0.06764,   inf] (111), [-0.06761,   inf] (111), [-0.06761,   inf] (111), [-0.06760,   inf] (111), [-0.06760,   inf] (111), [-0.06759,   inf] (111), [-0.06687,   inf] (111), [-0.06684,   inf] (111), [-0.06681,   inf] (111), [-0.06680,   inf] (111), [-0.06679,   inf] (111), [-0.06677,   inf] (111), [-0.06677,   inf] (111), [-0.06676,   inf] (111), [-0.06670,   inf] (111), [-0.06669,   inf] (111), [-0.06667,   inf] (111), [-0.06667,   inf] (111), 
length of domains: 6251
Total time: 1.1462	 pickout: 0.0817	 decision: 0.3940	 get_bound: 0.5051	 add_domain: 0.1654
Current lb:-0.06791897863149643
35196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 40.22222018241882

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 152] [0, 83] [0, 177] [1, 142] [0, 242] [1, 123] [1, 142] [1, 123] [0, 76] [0, 76] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: 36.67122268676758 with beta sum per layer: [49.6622314453125, 56.257713317871094, 0.0, 110.45393371582031]
alpha/beta optimization time: 0.28466081619262695
This batch time : update_bounds func: 0.5014	 prepare: 0.1203	 bound: 0.2851	 transfer: 0.0153	 finalize: 0.0780
Accumulated time: update_bounds func: 24.3554	 prepare: 4.3946	 bound: 15.1785	 transfer: 0.0153	 finalize: 4.0315
batch bounding time:  0.5026841163635254
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (113), [-0.06762,   inf] (113), [-0.06761,   inf] (113), [-0.06761,   inf] (113), [-0.06761,   inf] (113), [-0.06760,   inf] (113), [-0.06760,   inf] (113), [-0.06759,   inf] (113), [-0.06687,   inf] (113), [-0.06684,   inf] (113), [-0.06681,   inf] (113), [-0.06680,   inf] (113), [-0.06679,   inf] (113), [-0.06677,   inf] (113), [-0.06677,   inf] (113), [-0.06676,   inf] (113), [-0.06670,   inf] (113), [-0.06667,   inf] (113), [-0.06667,   inf] (113), [-0.06666,   inf] (113), 
length of domains: 6588
Total time: 1.1675	 pickout: 0.0806	 decision: 0.4199	 get_bound: 0.5047	 add_domain: 0.1623
Current lb:-0.06791897863149643
36196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 41.41011595726013

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 161] [1, 142] [1, 152] [0, 177] [1, 136] [0, 249] [1, 152] [0, 249] [1, 142] [0, 177] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: 29.222240447998047 with beta sum per layer: [49.612709045410156, 65.52059936523438, 0.0, 106.8868179321289]
alpha/beta optimization time: 0.3002605438232422
This batch time : update_bounds func: 0.7354	 prepare: 0.1201	 bound: 0.3008	 transfer: 0.0154	 finalize: 0.0773
Accumulated time: update_bounds func: 25.0908	 prepare: 4.5146	 bound: 15.4793	 transfer: 0.0154	 finalize: 4.1088
batch bounding time:  0.7368786334991455
Current worst splitting domains [lb, ub] (depth):
[-0.06792,   inf] (115), [-0.06762,   inf] (115), [-0.06761,   inf] (115), [-0.06761,   inf] (115), [-0.06761,   inf] (115), [-0.06760,   inf] (115), [-0.06760,   inf] (115), [-0.06759,   inf] (115), [-0.06687,   inf] (115), [-0.06684,   inf] (115), [-0.06681,   inf] (115), [-0.06680,   inf] (115), [-0.06679,   inf] (115), [-0.06677,   inf] (115), [-0.06677,   inf] (115), [-0.06676,   inf] (115), [-0.06668,   inf] (115), [-0.06667,   inf] (115), [-0.06667,   inf] (115), [-0.06666,   inf] (115), 
length of domains: 6894
Total time: 1.1880	 pickout: 0.0816	 decision: 0.2072	 get_bound: 0.7389	 add_domain: 0.1603
Current lb:-0.06791897863149643
37196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 42.61862277984619

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [0, 83] [0, 242] [1, 161] [0, 242] [0, 249] [1, 136] [1, 161] [1, 136] [1, 152] [1, 152] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: 25.462308883666992 with beta sum per layer: [50.227699279785156, 71.78514862060547, 0.0, 104.74134826660156]
alpha/beta optimization time: 0.2954115867614746
This batch time : update_bounds func: 0.7526	 prepare: 0.1196	 bound: 0.2958	 transfer: 0.0154	 finalize: 0.3191
Accumulated time: update_bounds func: 25.8435	 prepare: 4.6342	 bound: 15.7751	 transfer: 0.0154	 finalize: 4.4279
batch bounding time:  0.7539501190185547
Current worst splitting domains [lb, ub] (depth):
[-0.06766,   inf] (117), [-0.06762,   inf] (117), [-0.06761,   inf] (117), [-0.06761,   inf] (117), [-0.06761,   inf] (117), [-0.06760,   inf] (117), [-0.06760,   inf] (117), [-0.06759,   inf] (117), [-0.06687,   inf] (117), [-0.06684,   inf] (117), [-0.06681,   inf] (117), [-0.06680,   inf] (117), [-0.06679,   inf] (117), [-0.06677,   inf] (117), [-0.06677,   inf] (117), [-0.06676,   inf] (117), [-0.06668,   inf] (117), [-0.06667,   inf] (117), [-0.06666,   inf] (117), [-0.06666,   inf] (117), 
length of domains: 7174
Total time: 1.2058	 pickout: 0.0822	 decision: 0.2129	 get_bound: 0.7559	 add_domain: 0.1548
Current lb:-0.06766252964735031
38196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 43.84435296058655

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 167] [1, 152] [0, 177] [0, 249] [1, 142] [1, 142] [1, 167] [1, 142] [0, 242] [1, 161] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: 18.177825927734375 with beta sum per layer: [50.77448272705078, 82.58067321777344, 0.0, 98.70470428466797]
alpha/beta optimization time: 0.2815399169921875
This batch time : update_bounds func: 0.4968	 prepare: 0.1189	 bound: 0.2819	 transfer: 0.0153	 finalize: 0.0777
Accumulated time: update_bounds func: 26.3402	 prepare: 4.7532	 bound: 16.0570	 transfer: 0.0153	 finalize: 4.5056
batch bounding time:  0.4982004165649414
Current worst splitting domains [lb, ub] (depth):
[-0.06764,   inf] (119), [-0.06762,   inf] (119), [-0.06761,   inf] (119), [-0.06761,   inf] (119), [-0.06761,   inf] (119), [-0.06760,   inf] (119), [-0.06760,   inf] (119), [-0.06759,   inf] (119), [-0.06687,   inf] (119), [-0.06684,   inf] (119), [-0.06681,   inf] (119), [-0.06680,   inf] (119), [-0.06679,   inf] (119), [-0.06677,   inf] (119), [-0.06677,   inf] (119), [-0.06676,   inf] (119), [-0.06667,   inf] (119), [-0.06666,   inf] (119), [-0.06666,   inf] (119), [-0.06664,   inf] (119), 
length of domains: 7416
Total time: 0.9462	 pickout: 0.0827	 decision: 0.2135	 get_bound: 0.5002	 add_domain: 0.1497
Current lb:-0.06763890385627747
39196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 44.81223154067993

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [0, 177] [0, 249] [0, 242] [1, 152] [1, 152] [1, 152] [0, 177] [1, 152] [0, 249] [0, 242] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: -5.571296691894531 with beta sum per layer: [42.18622970581055, 110.55133056640625, 0.0, 104.0673599243164]
alpha/beta optimization time: 0.28244686126708984
This batch time : update_bounds func: 0.4990	 prepare: 0.1187	 bound: 0.2829	 transfer: 0.0153	 finalize: 0.0795
Accumulated time: update_bounds func: 26.8392	 prepare: 4.8719	 bound: 16.3399	 transfer: 0.0153	 finalize: 4.5851
batch bounding time:  0.500335693359375
Current worst splitting domains [lb, ub] (depth):
[-0.06762,   inf] (121), [-0.06762,   inf] (121), [-0.06761,   inf] (121), [-0.06761,   inf] (121), [-0.06761,   inf] (121), [-0.06760,   inf] (121), [-0.06760,   inf] (121), [-0.06759,   inf] (121), [-0.06687,   inf] (121), [-0.06684,   inf] (121), [-0.06681,   inf] (121), [-0.06680,   inf] (121), [-0.06679,   inf] (121), [-0.06677,   inf] (121), [-0.06677,   inf] (121), [-0.06676,   inf] (121), [-0.06667,   inf] (121), [-0.06666,   inf] (121), [-0.06665,   inf] (121), [-0.06664,   inf] (121), 
length of domains: 7583
Total time: 1.1791	 pickout: 0.0804	 decision: 0.4613	 get_bound: 0.5023	 add_domain: 0.1351
Current lb:-0.06762183457612991
40196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 46.01435136795044

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 161] [0, 242] [0, 249] [1, 161] [1, 161] [1, 161] [0, 242] [1, 161] [1, 161] [0, 249] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: -15.412125587463379 with beta sum per layer: [53.337554931640625, 127.1866226196289, 0.0, 105.09387969970703]
alpha/beta optimization time: 0.28788113594055176
This batch time : update_bounds func: 0.5017	 prepare: 0.1185	 bound: 0.2883	 transfer: 0.0146	 finalize: 0.0773
Accumulated time: update_bounds func: 27.3410	 prepare: 4.9904	 bound: 16.6282	 transfer: 0.0146	 finalize: 4.6623
batch bounding time:  0.5031478404998779
Current worst splitting domains [lb, ub] (depth):
[-0.06762,   inf] (123), [-0.06761,   inf] (123), [-0.06761,   inf] (123), [-0.06761,   inf] (123), [-0.06761,   inf] (123), [-0.06760,   inf] (123), [-0.06759,   inf] (123), [-0.06759,   inf] (123), [-0.06687,   inf] (123), [-0.06684,   inf] (123), [-0.06681,   inf] (123), [-0.06679,   inf] (123), [-0.06679,   inf] (123), [-0.06677,   inf] (123), [-0.06677,   inf] (123), [-0.06676,   inf] (123), [-0.06667,   inf] (123), [-0.06666,   inf] (123), [-0.06664,   inf] (123), [-0.06664,   inf] (123), 
length of domains: 7657
Total time: 1.1843	 pickout: 0.0809	 decision: 0.4824	 get_bound: 0.5052	 add_domain: 0.1158
Current lb:-0.06762183457612991
41196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 47.223175048828125

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  1
splitting decisions: 
split level 0: [1, 167] [0, 249] [1, 167] [1, 167] [1, 167] [1, 167] [0, 249] [1, 167] [1, 167] [1, 167] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: -20.760425567626953 with beta sum per layer: [48.267940521240234, 156.06024169921875, 0.0, 111.10958862304688]
alpha/beta optimization time: 0.2886202335357666
This batch time : update_bounds func: 0.5017	 prepare: 0.1175	 bound: 0.2890	 transfer: 0.0154	 finalize: 0.0771
Accumulated time: update_bounds func: 27.8427	 prepare: 5.1079	 bound: 16.9172	 transfer: 0.0154	 finalize: 4.7394
batch bounding time:  0.5032134056091309
Current worst splitting domains [lb, ub] (depth):
[-0.06762,   inf] (125), [-0.06761,   inf] (125), [-0.06761,   inf] (125), [-0.06761,   inf] (125), [-0.06760,   inf] (125), [-0.06760,   inf] (125), [-0.06759,   inf] (125), [-0.06759,   inf] (125), [-0.06687,   inf] (125), [-0.06684,   inf] (125), [-0.06681,   inf] (125), [-0.06679,   inf] (125), [-0.06679,   inf] (125), [-0.06677,   inf] (125), [-0.06677,   inf] (125), [-0.06676,   inf] (125), [-0.06667,   inf] (125), [-0.06666,   inf] (125), [-0.06664,   inf] (125), [-0.06664,   inf] (125), 
length of domains: 7660
Total time: 1.1845	 pickout: 0.0821	 decision: 0.2279	 get_bound: 0.5054	 add_domain: 0.3691
Current lb:-0.06762183457612991
42196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 48.4333176612854

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 256]) pre split depth:  1
batch:  torch.Size([500, 256]) post split depth:  0
all nodes are split!!
Global ub: inf, batch ub: inf
Image 0 against label 7 verification end, Time cost: 48.961724519729614
Result: unknown in 92.1136 seconds


[[    0.             0.07438698     0.             0.00033474
      1.        ]
 [    0.             0.082162       0.             0.0003283
      2.        ]
 [    0.             0.11101714     0.             0.00033212
      3.        ]
 [    0.             0.12702762     0.             0.0003264
      4.        ]
 [    0.             0.07650559     0.             0.00032401
      5.        ]
 [    0.             0.0000001     32.             1.29912782
      6.        ]
 [    0.            -0.06762183 42196.            48.96172452
      7.        ]]
############# Summary #############
Final verified acc: 0.0% [total 1 examples]
Total verification count: 1 , total verified safe: 0 , verified unsafe: 0 , timeout: 1
mean time [total:1]: 50.262497901916504
mean time [cnt:1]: 50.262497901916504
max time 92.11362099647522
unknown (total 1): [0]
