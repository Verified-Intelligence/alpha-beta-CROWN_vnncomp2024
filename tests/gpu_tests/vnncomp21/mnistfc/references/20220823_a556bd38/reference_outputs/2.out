Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  sparse_alpha: true
  save_adv_example: false
  precompile_jit: false
  mode: verified-acc
  complete_verifier: bab-refine
  enable_incomplete_verification: true
  get_crown_verified_acc: false
  csv_name: mnistfc_instances.csv
  results_file: null
  root_path: ../../vnncomp2021/benchmarks/mnistfc
model:
  path: null
  cache_onnx_conversion: false
  onnx_quirks: null
  name: mnist_9_200
  onnx_path: null
  onnx_path_prefix: ''
  onnx_optimization_flags: none
data:
  start: 73
  end: 74
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: MNIST
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: null
  vnnlib_path: null
  vnnlib_path_prefix: ''
solver:
  batch_size: 500
  no_float64_last_iter: true
  no_amp: false
  early_stop_patience: 10
  start_save_best: 2
  bound_prop_method: alpha-crown
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
    full_conv_alpha: true
  beta-crown:
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  multi_class:
    multi_class_method: allclass_domain
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: 16
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
bab:
  initial_max_domains: 1
  max_domains: 200000
  decision_thresh: 0
  timeout: 360
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_intermediate_layers: ''
  interm_transfer: true
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 100
    batch_size_primal: 100
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    max_num: 1000000000
    fixed_cuts: false
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
    lr: 0.01
  branching:
    method: kfsb
    candidates: 5
    reduceop: max
    sb_coeff_thresh: 0.001
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      sort_domain_interval: -1
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  attack_mode: PGD
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 5000000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
  enable_mip_attack: false
  cex_path: ./test_cex.txt
debug:
  lp_test: null

Experiments at Tue Aug 23 12:45:38 2022 on diablo.cs.ucla.edu
saving results to a-b-crown_[mnistfc_instances]_start=73_end=74_iter=20_b=500_timeout=360_branching=kfsb-max-5_lra-init=0.1_lra=0.01_lrb=0.03_PGD=before_cplex_cuts=False_initial_max_domains=1.npz
customized start/end sample from 73 to 74

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 73 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx mnist-net_256x6.onnx
Using vnnlib prop_13_0.03.vnnlib
Precompiled vnnlib file found at ../../vnncomp2021/benchmarks/mnistfc/prop_13_0.03.vnnlib.compiled
Loading onnx ../../vnncomp2021/benchmarks/mnistfc/mnist-net_256x6.onnx wih quirks {}
ConvertModel(
  (Flatten_15): Flatten()
  (Gemm_16): Linear(in_features=784, out_features=256, bias=True)
  (Relu_17): ReLU(inplace=True)
  (Gemm_18): Linear(in_features=256, out_features=256, bias=True)
  (Relu_19): ReLU(inplace=True)
  (Gemm_20): Linear(in_features=256, out_features=256, bias=True)
  (Relu_21): ReLU(inplace=True)
  (Gemm_22): Linear(in_features=256, out_features=256, bias=True)
  (Relu_23): ReLU(inplace=True)
  (Gemm_24): Linear(in_features=256, out_features=256, bias=True)
  (Relu_25): ReLU(inplace=True)
  (Gemm_26): Linear(in_features=256, out_features=256, bias=True)
  (Relu_27): ReLU(inplace=True)
  (Gemm_28): Linear(in_features=256, out_features=10, bias=True)
)
Unexpected input shape in onnx: (784, 1), given (1, 28, 28)
Attack parameters: initialization=uniform, steps=100, restarts=30, alpha=0.007500000298023224, initialization=uniform, GAMA=False
model output: tensor([[ 3.41790915e-03,  1.96613371e-04, -1.11312941e-02,  8.65552574e-04,
          1.19767822e-02,  1.04162022e-02, -9.40588117e-03,  1.77533403e-02,
          7.31473640e-02,  9.06666577e-01]], device='cuda:0')
pgd prediction: tensor([[[ 0.00460951, -0.00202645, -0.01558051, -0.00429894,  0.01645090,
           0.01692517, -0.02018678,  0.02343428,  0.09444303,  0.89343125],
         [ 0.00460951, -0.00202645, -0.01558051, -0.00429894,  0.01645090,
           0.01692517, -0.02018678,  0.02343428,  0.09444303,  0.89343125]]],
       device='cuda:0')
pgd attack margin tensor([[[0.88882172, 0.89545768, 0.90901172, 0.89773017, 0.87698036,
          0.87650609, 0.91361803, 0.86999696, 0.79898822]]], device='cuda:0')
number of violation:  0
Attack finished in 1.1788 seconds.
pgd attack failed
Model prediction is: tensor([[ 3.41790915e-03,  1.96613371e-04, -1.11312941e-02,  8.65552574e-04,
          1.19767822e-02,  1.04162022e-02, -9.40588117e-03,  1.77533403e-02,
          7.31473640e-02,  9.06666577e-01]], device='cuda:0')
layer /17 using sparse-features alpha with shape [40]; unstable size 40; total size 256 (torch.Size([1, 256]))
layer /17 start_node /input.3 using sparse-spec alpha with unstable size 64 total_size 256 output_shape torch.Size([256])
layer /17 start_node /input.7 using sparse-spec alpha with unstable size 49 total_size 256 output_shape torch.Size([256])
layer /17 start_node /input.11 using sparse-spec alpha with unstable size 209 total_size 256 output_shape torch.Size([256])
layer /17 start_node /input.15 using full alpha with unstable size 256 total_size 256 output_shape torch.Size([256])
layer /17 start_node /input.19 using full alpha with unstable size 256 total_size 256 output_shape torch.Size([256])
layer /17 start_node /28 using full alpha with unstable size None total_size 9 output_shape 9
layer /19 using sparse-features alpha with shape [64]; unstable size 64; total size 256 (torch.Size([1, 256]))
layer /19 start_node /input.7 using sparse-spec alpha with unstable size 49 total_size 256 output_shape torch.Size([256])
layer /19 start_node /input.11 using sparse-spec alpha with unstable size 209 total_size 256 output_shape torch.Size([256])
layer /19 start_node /input.15 using full alpha with unstable size 256 total_size 256 output_shape torch.Size([256])
layer /19 start_node /input.19 using full alpha with unstable size 256 total_size 256 output_shape torch.Size([256])
layer /19 start_node /28 using full alpha with unstable size None total_size 9 output_shape 9
layer /21 using sparse-features alpha with shape [49]; unstable size 49; total size 256 (torch.Size([1, 256]))
layer /21 start_node /input.11 using sparse-spec alpha with unstable size 209 total_size 256 output_shape torch.Size([256])
layer /21 start_node /input.15 using full alpha with unstable size 256 total_size 256 output_shape torch.Size([256])
layer /21 start_node /input.19 using full alpha with unstable size 256 total_size 256 output_shape torch.Size([256])
layer /21 start_node /28 using full alpha with unstable size None total_size 9 output_shape 9
layer /23 using sparse-features alpha with shape [209]; unstable size 209; total size 256 (torch.Size([1, 256]))
layer /23 start_node /input.15 using full alpha with unstable size 256 total_size 256 output_shape torch.Size([256])
layer /23 start_node /input.19 using full alpha with unstable size 256 total_size 256 output_shape torch.Size([256])
layer /23 start_node /28 using full alpha with unstable size None total_size 9 output_shape 9
layer /25 using full alpha with shape torch.Size([256]); unstable size 256; total size 256 (torch.Size([1, 256]))
layer /25 start_node /input.19 using full alpha with unstable size 256 total_size 256 output_shape torch.Size([256])
layer /25 start_node /28 using full alpha with unstable size None total_size 9 output_shape 9
layer /27 using full alpha with shape torch.Size([256]); unstable size 256; total size 256 (torch.Size([1, 256]))
layer /27 start_node /28 using full alpha with unstable size None total_size 9 output_shape 9
Optimizable variables initialized.
initial CROWN bounds: tensor([[-467.02023315, -593.48925781, -561.15936279, -573.99987793,
         -435.07839966, -517.71832275, -576.18212891, -495.29193115,
         -529.78527832]], device='cuda:0') None
best_l after optimization: -703.5863037109375 with beta sum per layer: []
alpha/beta optimization time: 8.116896390914917
initial alpha-CROWN bounds: tensor([[-69.33707428, -87.57156372, -83.06550598, -85.53059387, -64.09634399,
         -76.38113403, -85.65188599, -73.60639191, -78.34578705]],
       device='cuda:0')
Worst class: (+ rhs) -87.57156372070312
Start solving intermediate bounds with MIP...
layer /17 using sparse-features alpha with shape [40]; unstable size 40; total size 256 (torch.Size([1, 256]))
layer /17 start_node /input.3 using sparse-spec alpha with unstable size 64 total_size 256 output_shape torch.Size([256])
layer /17 start_node /input.7 using sparse-spec alpha with unstable size 49 total_size 256 output_shape torch.Size([256])
layer /17 start_node /input.11 using sparse-spec alpha with unstable size 206 total_size 256 output_shape torch.Size([256])
layer /17 start_node /input.15 using full alpha with unstable size 256 total_size 256 output_shape torch.Size([256])
layer /17 start_node /input.19 using full alpha with unstable size 256 total_size 256 output_shape torch.Size([256])
layer /17 start_node /28 using full alpha with unstable size None total_size 9 output_shape 9
layer /19 using sparse-features alpha with shape [64]; unstable size 64; total size 256 (torch.Size([1, 256]))
layer /19 start_node /input.7 using sparse-spec alpha with unstable size 49 total_size 256 output_shape torch.Size([256])
layer /19 start_node /input.11 using sparse-spec alpha with unstable size 206 total_size 256 output_shape torch.Size([256])
layer /19 start_node /input.15 using full alpha with unstable size 256 total_size 256 output_shape torch.Size([256])
layer /19 start_node /input.19 using full alpha with unstable size 256 total_size 256 output_shape torch.Size([256])
layer /19 start_node /28 using full alpha with unstable size None total_size 9 output_shape 9
layer /21 using sparse-features alpha with shape [49]; unstable size 49; total size 256 (torch.Size([1, 256]))
layer /21 start_node /input.11 using sparse-spec alpha with unstable size 206 total_size 256 output_shape torch.Size([256])
layer /21 start_node /input.15 using full alpha with unstable size 256 total_size 256 output_shape torch.Size([256])
layer /21 start_node /input.19 using full alpha with unstable size 256 total_size 256 output_shape torch.Size([256])
layer /21 start_node /28 using full alpha with unstable size None total_size 9 output_shape 9
layer /23 using sparse-features alpha with shape [206]; unstable size 206; total size 256 (torch.Size([1, 256]))
layer /23 start_node /input.15 using full alpha with unstable size 256 total_size 256 output_shape torch.Size([256])
layer /23 start_node /input.19 using full alpha with unstable size 256 total_size 256 output_shape torch.Size([256])
layer /23 start_node /28 using full alpha with unstable size None total_size 9 output_shape 9
layer /25 using full alpha with shape torch.Size([256]); unstable size 256; total size 256 (torch.Size([1, 256]))
layer /25 start_node /input.19 using full alpha with unstable size 256 total_size 256 output_shape torch.Size([256])
layer /25 start_node /28 using full alpha with unstable size None total_size 9 output_shape 9
layer /27 using full alpha with shape torch.Size([256]); unstable size 256; total size 256 (torch.Size([1, 256]))
layer /27 start_node /28 using full alpha with unstable size None total_size 9 output_shape 9
Optimizable variables initialized.
Set parameter Username
Academic license - for non-commercial use only - expires 2023-08-09
mip_multi_proc: 16, mip_threads: 1,total threads used: 16, mip_perneuron_refine_timeout: 15
[total time budget for MIP: 240.0]

Linear(in_features=784, out_features=256, bias=True) 0 2 torch.Size([256])
Linear(in_features=256, out_features=256, bias=True) 1 4 torch.Size([256])
sorted candidates ['lay4_63', 'lay4_78', 'lay4_85', 'lay4_130', 'lay4_71', 'lay4_69', 'lay4_190', 'lay4_102', 'lay4_175', 'lay4_39', 'lay4_206', 'lay4_120', 'lay4_31', 'lay4_87', 'lay4_8', 'lay4_77', 'lay4_103', 'lay4_119', 'lay4_46', 'lay4_37', 'lay4_252', 'lay4_99', 'lay4_255', 'lay4_0', 'lay4_90', 'lay4_145', 'lay4_239', 'lay4_174', 'lay4_195', 'lay4_136', 'lay4_227', 'lay4_158', 'lay4_40', 'lay4_110', 'lay4_104', 'lay4_246', 'lay4_49', 'lay4_62', 'lay4_56', 'lay4_198', 'lay4_20', 'lay4_205', 'lay4_117', 'lay4_114', 'lay4_144', 'lay4_89', 'lay4_47', 'lay4_143', 'lay4_142', 'lay4_163', 'lay4_6', 'lay4_126', 'lay4_10', 'lay4_181', 'lay4_139', 'lay4_18', 'lay4_22', 'lay4_236', 'lay4_203', 'lay4_24', 'lay4_55', 'lay4_222', 'lay4_32'] filter: 1.0
PGD done for relu layer 1
/home/zhouxingshi/onnx2pytorch/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)
  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))
/home/zhouxingshi/onnx2pytorch/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  "Using experimental implementation that allows 'batch_size > 1'."
/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/abcrown.py:95: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_new.cpp:210.)
  arguments.Config["bab"]["decision_thresh"] = torch.tensor([item[1] for item in vnnlib[1]]).to(data)
Solving MIP for lay4_87, [-inf,inf]=>[-inf,-1e-05] (-1,-1; 15,-1), time: 0.3785s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_69, [-inf,inf]=>[-inf,-1e-05] (-1,-1; 15,-1), time: 2.1234s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_206, [-inf,inf]=>[-2.8476011984283907,2.6390139392616763] (2,-1; 2,-1), time: 2.3311s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_77, [-inf,inf]=>[-4.234402842182662,1.1682063816739536] (2,-1; 2,-1), time: 2.7449s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_63, [-inf,inf]=>[-6.110327258792156,0.7055313533709786] (2,-1; 2,-1), time: 2.8210s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_8, [-inf,inf]=>[-3.4667853628598704,0.8558497717606247] (2,-1; 2,-1), time: 2.9819s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_85, [-inf,inf]=>[-3.4575744187576634,3.54761023787214] (2,-1; 2,-1), time: 3.2632s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_103, [-inf,inf]=>[-4.102567347772474,0.3868100833107828] (2,-1; 2,-1), time: 3.0009s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_120, [-inf,inf]=>[-5.613811317551243,0.6862473105014135] (2,-1; 2,-1), time: 3.4682s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_39, [-inf,inf]=>[-1.6450645199652432,3.070500049191628] (2,-1; 2,-1), time: 3.5703s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_78, [-inf,inf]=>[-5.07853249492532,0.7753489895465788] (2,-1; 2,-1), time: 3.6050s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_190, [-inf,inf]=>[-2.088919623552485,3.610802601233988] (2,-1; 2,-1), time: 3.6446s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_102, [-inf,inf]=>[-3.044329628958794,1.3721077485619075] (2,-1; 2,-1), time: 3.6939s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_130, [-inf,inf]=>[-2.492247986660694,3.1772840635485076] (2,-1; 2,-1), time: 3.7647s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_175, [-inf,inf]=>[-4.659525446621932,1.0808420802183483] (2,-1; 2,-1), time: 3.8201s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_71, [-inf,inf]=>[-1.3107580063112232,1.9363947045828656] (2,-1; 2,-1), time: 3.8847s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_239, [-inf,inf]=>[-inf,-1e-05] (-1,-1; 15,-1), time: 0.3421s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_31, [-inf,inf]=>[-2.9841865707702073,3.043388934565017] (2,-1; 2,-1), time: 3.9632s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_227, [-inf,inf]=>[-inf,-1e-05] (-1,-1; 15,-1), time: 0.3982s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_37, [-inf,inf]=>[-6.044141899620148,0.07771766286870027] (2,-1; 2,-1), time: 1.8392s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_104, [-inf,inf]=>[-inf,-1e-05] (-1,-1; 15,-1), time: 0.3101s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_145, [-inf,inf]=>[-4.991540483710975,0.3302763931401334] (2,-1; 2,-1), time: 1.3812s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_49, [-inf,inf]=>[-inf,-1e-05] (-1,-1; 15,-1), time: 0.3430s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_174, [-inf,inf]=>[-1.798012856812545,3.965950932589393] (2,-1; 2,-1), time: 1.7448s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_246, [-inf,inf]=>[1e-05,6.945543518055386] (15,-1; 2,-1), time: 1.0602s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_0, [-inf,inf]=>[-6.311105268313244,0.2380657808874836] (2,-1; 2,-1), time: 2.1261s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_119, [-inf,inf]=>[-3.6777176306899118,0.6141834200919538] (2,-1; 2,-1), time: 3.7650s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_46, [-inf,inf]=>[-2.2789380659239113,1.6183277816875459] (2,-1; 2,-1), time: 3.5947s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_90, [-inf,inf]=>[-2.559141828224333,1.2945830313481907] (2,-1; 2,-1), time: 2.6998s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_20, [-inf,inf]=>[-inf,-1e-05] (-1,-1; 15,-1), time: 0.3516s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_62, [-inf,inf]=>[1e-05,6.588042994023542] (15,-1; 2,-1), time: 1.1080s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_136, [-inf,inf]=>[-2.6822060870639515,1.4718068074456896] (2,-1; 2,-1), time: 2.5757s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_255, [-inf,inf]=>[-4.19441546658577,1.3916450821376478] (2,-1; 2,-1), time: 3.1627s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_47, [-inf,inf]=>[-inf,-1e-05] (-1,-1; 15,-1), time: 0.2928s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_252, [-inf,inf]=>[-2.1208073802893748,2.5532204326963917] (2,-1; 2,-1), time: 3.8716s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_198, [-inf,inf]=>[-4.950889975959291,0.5085794053444925] (2,-1; 2,-1), time: 1.4850s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_195, [-inf,inf]=>[-6.522376021411654,0.21871171427247016] (2,-1; 2,-1), time: 3.3013s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_99, [-inf,inf]=>[-1.7133768985181894,4.048034797748119] (2,-1; 2,-1), time: 4.2263s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_143, [-inf,inf]=>[1e-05,6.348919793755841] (15,-1; 2,-1), time: 0.9399s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_56, [-inf,inf]=>[-2.51034865885898,2.9794692025565053] (2,-1; 2,-1), time: 2.5231s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_110, [-inf,inf]=>[-3.8067267253628887,1.947285913676336] (2,-1; 2,-1), time: 3.6805s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_117, [-inf,inf]=>[-1.3429751639355914,3.485861203311705] (2,-1; 2,-1), time: 1.7614s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_158, [-inf,inf]=>[-1.7239911725762316,2.5791479711525542] (2,-1; 2,-1), time: 4.2537s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_89, [-inf,inf]=>[-2.1320665991487604,2.0399718811588476] (2,-1; 2,-1), time: 2.3765s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_40, [-inf,inf]=>[-3.4708581169548283,0.6147656059094406] (2,-1; 2,-1), time: 4.5191s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_205, [-inf,inf]=>[-1.8935790392622174,2.7759456668462663] (2,-1; 2,-1), time: 2.8307s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_22, [-inf,inf]=>[-inf,-1e-05] (-1,-1; 15,-1), time: 0.9529s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_144, [-inf,inf]=>[-3.7732443194937,0.778616887632062] (2,-1; 2,-1), time: 2.3174s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_55, [-inf,inf]=>[-inf,-1e-05] (-1,-1; 15,-1), time: 0.2837s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_139, [-inf,inf]=>[-inf,-1e-05] (-1,-1; 15,-1), time: 1.5328s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_32, [-inf,inf]=>[-inf,-1e-05] (-1,-1; 15,-1), time: 0.3098s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_142, [-inf,inf]=>[-1.124378490313539,3.6531703714642667] (2,-1; 2,-1), time: 2.5484s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_181, [-inf,inf]=>[-0.4709398825272313,4.620343845550588] (2,-1; 2,-1), time: 2.6710s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_114, [-inf,inf]=>[-3.1744756026563525,0.48890960221861857] (2,-1; 2,-1), time: 3.6427s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_10, [-inf,inf]=>[-3.1927119966914534,0.0487172867554059] (2,-1; 2,-1), time: 3.0970s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_6, [-inf,inf]=>[-1.7784701266078495,2.267644264619225] (2,-1; 2,-1), time: 3.5629s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_18, [-inf,inf]=>[-5.450792218980636,0.04956391979317744] (2,-1; 2,-1), time: 3.0869s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_222, [-inf,inf]=>[-4.544697278930309,0.3736489450363953] (2,-1; 2,-1), time: 2.0852s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_236, [-inf,inf]=>[-2.1829117533275886,3.9826910110902354] (2,-1; 2,-1), time: 3.2841s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_126, [-inf,inf]=>[-3.935790621133867,0.08032021482544835] (2,-1; 2,-1), time: 4.0561s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_163, [-inf,inf]=>[-1.2845230741116427,1.6049167968936078] (2,-1; 2,-1), time: 4.5469s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_203, [-inf,inf]=>[-3.870576806494313,1.2181119827059024] (2,-1; 2,-1), time: 3.8345s, #vars: 1377, #constrs: 632, improved: True
Solving MIP for lay4_24, [-inf,inf]=>[-4.876871353950099,0.2112599879056183] (2,-1; 2,-1), time: 4.5641s, #vars: 1377, #constrs: 632, improved: True
PGD done for relu layer 2
MIP improved 63 nodes out of 63 unstable nodes, lb improved 81.4669189453125, ub improved 64.7379150390625, time 15.4023
maximum relu layer improved by MIP so far 1 last_relu_layer_refined: True
Linear(in_features=256, out_features=256, bias=True) 2 6 torch.Size([256])
sorted candidates ['lay6_245', 'lay6_69', 'lay6_166', 'lay6_9', 'lay6_75', 'lay6_4', 'lay6_177', 'lay6_201', 'lay6_42', 'lay6_220', 'lay6_212', 'lay6_179', 'lay6_160', 'lay6_107', 'lay6_90', 'lay6_33', 'lay6_183', 'lay6_67', 'lay6_244', 'lay6_35', 'lay6_164', 'lay6_247', 'lay6_99', 'lay6_119', 'lay6_246', 'lay6_16', 'lay6_124', 'lay6_241', 'lay6_108', 'lay6_24', 'lay6_120', 'lay6_193', 'lay6_38', 'lay6_236', 'lay6_123', 'lay6_182', 'lay6_251'] filter: 1.0
Solving MIP for lay6_220, [-inf,inf]=>[-inf,-1e-05] (-1,-1; 15,-1), time: 0.4141s, #vars: 1729, #constrs: 1032, improved: True
Solving MIP for lay6_90, [-inf,inf]=>[-inf,-1e-05] (-1,-1; 15,-1), time: 0.4723s, #vars: 1729, #constrs: 1032, improved: True
Solving MIP for lay6_107, [-inf,inf]=>[-inf,-1e-05] (-1,-1; 15,-1), time: 0.5274s, #vars: 1729, #constrs: 1032, improved: True
Solving MIP for lay6_179, [-inf,inf]=>[-inf,-1e-05] (-1,-1; 15,-1), time: 0.5445s, #vars: 1729, #constrs: 1032, improved: True
Solving MIP for lay6_33, [-inf,inf]=>[-inf,-1e-05] (-1,-1; 15,-1), time: 0.5627s, #vars: 1729, #constrs: 1032, improved: True
Solving MIP for lay6_183, [-inf,inf]=>[-inf,-1e-05] (-1,-1; 15,-1), time: 0.3547s, #vars: 1729, #constrs: 1032, improved: True
Solving MIP for lay6_67, [-inf,inf]=>[-inf,-1e-05] (-1,-1; 15,-1), time: 0.4243s, #vars: 1729, #constrs: 1032, improved: True
Solving MIP for lay6_69, [-inf,inf]=>[-inf,-1e-05] (-1,-1; 15,-1), time: 0.9569s, #vars: 1729, #constrs: 1032, improved: True
Solving MIP for lay6_212, [-inf,inf]=>[-inf,-1e-05] (-1,-1; 15,-1), time: 1.0920s, #vars: 1729, #constrs: 1032, improved: True
Solving MIP for lay6_247, [-inf,inf]=>[-inf,-1e-05] (-1,-1; 15,-1), time: 0.3949s, #vars: 1729, #constrs: 1032, improved: True
Solving MIP for lay6_4, [-inf,inf]=>[-inf,-1e-05] (-1,-1; 15,-1), time: 1.2397s, #vars: 1729, #constrs: 1032, improved: True
Solving MIP for lay6_166, [-inf,inf]=>[-inf,-1e-05] (-1,-1; 15,-1), time: 1.5033s, #vars: 1729, #constrs: 1032, improved: True
Solving MIP for lay6_16, [-inf,inf]=>[-inf,-1e-05] (-1,-1; 15,-1), time: 0.8595s, #vars: 1729, #constrs: 1032, improved: True
Solving MIP for lay6_99, [-inf,inf]=>[-inf,-1e-05] (-1,-1; 15,-1), time: 1.6023s, #vars: 1729, #constrs: 1032, improved: True
Solving MIP for lay6_75, [-inf,inf]=>[1e-05,14.279469261367836] (15,-1; 2,-1), time: 4.7823s, #vars: 1729, #constrs: 1032, improved: True
Solving MIP for lay6_124, [-inf,inf]=>[1e-05,15.24700853946641] (15,-1; 2,-1), time: 3.8461s, #vars: 1729, #constrs: 1032, improved: True
PGD done for relu layer 3
Run alpha-CROWN after refining layer 4 and relu idx 1
0 /input torch.Size([1, 256])
1 /input.3 torch.Size([1, 256])
2 /input.7 torch.Size([1, 256])
3 /input.11 torch.Size([1, 256])
4 /input.15 torch.Size([1, 256])
5 /input.19 torch.Size([1, 256])
relu layer: 1 has unstable to stable neurons: [(69, -1), (87, -1), (239, -1), (227, -1), (104, -1), (246, 1), (49, -1), (62, 1), (20, -1), (47, -1), (143, 1), (139, -1), (22, -1), (55, -1), (32, -1)]

all verified at 32th iter
best_l after optimization: 2.012089729309082 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 2.6638379096984863
alpha-CROWN with intermediate bounds by MIP: tensor([[2.59975493e-01, 1.93570435e-01, 3.29017133e-01, 2.11709261e-01,
         3.16851139e-01, 2.99641907e-01, 1.82125062e-01, 2.06828117e-04,
         2.18992412e-01]], device='cuda:0') None
min of alpha-CROWN bounds 0.00020682811737060547>=0, verified!
MIP finished with 25.30916118621826s
Run final alpha-CROWN after MIP solving on layer 5 and relu idx 2
0 /input torch.Size([1, 256])
1 /input.3 torch.Size([1, 256])
2 /input.7 torch.Size([1, 256])
3 /input.11 torch.Size([1, 256])
4 /input.15 torch.Size([1, 256])
5 /input.19 torch.Size([1, 256])

all verified at 0th iter
best_l after optimization: 2.012089729309082 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.04282259941101074
alpha-CROWN with intermediate bounds improved by MIP: tensor([[2.59975493e-01, 1.93570435e-01, 3.29017133e-01, 2.11709261e-01,
         3.16851139e-01, 2.99641907e-01, 1.82125062e-01, 2.06828117e-04,
         2.18992412e-01]], device='cuda:0') None
refined global lb: tensor([[2.59975493e-01],
        [1.93570435e-01],
        [3.29017133e-01],
        [2.11709261e-01],
        [3.16851139e-01],
        [2.99641907e-01],
        [1.82125062e-01],
        [2.06828117e-04],
        [2.18992412e-01]], device='cuda:0') min: tensor(0.00020683, device='cuda:0')
Verified safe using alpha-CROWN with MIP improved bounds!
Result: safe-incomplete-refine in 37.7047 seconds
############# Summary #############
Final verified acc: 100.0% [total 1 examples]
Total verification count: 1 , total verified safe: 1 , verified unsafe: 0 , timeout: 0
mean time [1] 37.7046959400177 max time 37.7046959400177
safe-incomplete-refine (total 1): [0]
