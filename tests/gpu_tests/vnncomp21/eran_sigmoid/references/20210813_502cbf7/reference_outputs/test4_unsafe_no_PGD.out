/home/zhouxingshi/conda/miniconda3/lib/python3.9/site-packages/onnx2pytorch/convert/operations.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)
  op = value_wrapper(torch.from_numpy(extract_attributes(node)["constant"]))
/home/zhouxingshi/conda/miniconda3/lib/python3.9/site-packages/torch/nn/functional.py:2113: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if size_prods == 1:
/home/zhouxingshi/conda/miniconda3/lib/python3.9/site-packages/torch/onnx/symbolic_helper.py:677: UserWarning: ONNX export mode is set to inference mode, but operator batch_norm is set to training  mode. The model will be exported in inference, as specified by the export mode.
  warnings.warn("ONNX export mode is set to " + training_mode +
Experiments at Thu Nov  4 13:05:34 2021 on ubuntu
Namespace(solve_slope=True, load='../../vnncomp2021/benchmarks/eran', device='cuda', seed=100, norm=inf, batch_size=64, refinement_batch_size=-1, no_warm=False, no_beta=False, max_subproblems_list=200000, decision_thresh=0, timeout=360, start=54, end=55, branching_method='kfsb', branching_candidates=3, branching_reduceop='min', lr_init_alpha=0.1, init_iteration=100, lr_alpha=0.01, lr_beta=0.05, lr_decay=0.98, optimizer='adam', iteration=50, beta_warmup=True, opt_coeffs=False, opt_bias=False, opt_intermediate_beta=False, lr_intermediate_beta=0.05, intermediate_refinement_layers=[-1], max_refinement_domains=1000, conv_mode='patches', deterministic=False, double_fp=False, share_slopes=False, loss_reduction_func='min', mip_multi_proc=None, mip_threads=1, mip_refine_timeout=0.8, mip_perneuron_refine_timeout=15, record_lb=False, no_joint_opt=False, csv_name='eran_instances.csv', onnx_path=None, vnnlib_path=None, results_file=None, data='MNIST', model='cresnet5_16_avg_bn', increase_TO=False, pgd_order='skip', complete_verifier='skip', incomplete=True)
saving results to vnn-comp_[eran_instances]_start=54_end=55_iter=50_b=64_int-beta=False_timeout=360_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npz
customized start/end sample from 54 to 55

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
args.loss_reduction_func change: min -> min
args.init_iteration change: 100 -> 1000
args.lr_decay change: 0.98 -> 0.999
args.complete_verifier change: skip -> skip
Model prediction is: tensor([[-11.0175, -15.1377, -11.6329,  -9.0605, -12.7798, -11.2975, -15.4098,
         -15.2713,  -0.2064,  -7.5857]], device='cuda:0',
       grad_fn=<AddBackward0>)
alpha-CROWN optimizable variables initialized.
best_l after optimization: 12.578566551208496 with beta sum per layer: []
optimal alpha/beta time: 162.86112117767334
initial alpha-CROWN bounds: tensor([[-11.6266, -12.0010, -11.5686, -12.5552, -12.5786, -11.4898, -12.4764,
         -12.5674, -12.5511]], device='cuda:0', grad_fn=<AsStridedBackward>) None
Result: unknown in 167.0483 seconds


[]
############# Summary #############
Final verified acc: 0.0% [total 1 examples]
Total verification count: 1 , total verified safe: 0 , verified unsafe: 0 , timeout: 1
max time 167.0482988357544
unknown (total 1): [0]
