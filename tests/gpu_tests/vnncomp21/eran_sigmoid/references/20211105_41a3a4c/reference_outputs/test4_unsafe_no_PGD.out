/home/zhouxingshi/conda/miniconda3/lib/python3.9/site-packages/onnx2pytorch/convert/operations.py:70: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)
  op = value_wrapper(torch.from_numpy(extract_attributes(node)["constant"]))
/home/zhouxingshi/conda/miniconda3/lib/python3.9/site-packages/torch/nn/functional.py:2113: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if size_prods == 1:
/home/zhouxingshi/conda/miniconda3/lib/python3.9/site-packages/torch/onnx/symbolic_helper.py:677: UserWarning: ONNX export mode is set to inference mode, but operator batch_norm is set to training  mode. The model will be exported in inference, as specified by the export mode.
  warnings.warn("ONNX export mode is set to " + training_mode +
Experiments at Wed Nov  3 20:58:17 2021 on ubuntu
saving results to vnn-comp_[eran_instances]_start=54_end=55_iter=50_b=64_int-beta=False_timeout=360_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npz
customized start/end sample from 54 to 55

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
arguments.Config["general"]["loss_reduction_func"] change: sum -> min
arguments.Config["solver"]["alpha-crown"]["iteration"] change: 100 -> 1000
arguments.Config["solver"]["beta-crown"]["lr_decay"] change: 0.98 -> 0.999
arguments.Config["general"]["complete_verifier"] change: bab -> skip
Model prediction is: tensor([[-11.0175, -15.1377, -11.6329,  -9.0605, -12.7798, -11.2975, -15.4098,
         -15.2713,  -0.2064,  -7.5857]], device='cuda:0',
       grad_fn=<AddBackward0>)
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ -80.2355,  -80.3708,  -63.4185, -108.3354,  -86.1833,  -53.9634,
          -98.1512,  -92.7644,  -75.0146]], device='cuda:0') None
best_l after optimization: 12.578566551208496 with beta sum per layer: []
optimal alpha/beta time: 155.44423127174377
initial alpha-CROWN bounds: tensor([[-11.6266, -12.0010, -11.5686, -12.5552, -12.5786, -11.4898, -12.4764,
         -12.5674, -12.5511]], device='cuda:0', grad_fn=<AsStridedBackward>) None
Result: unknown in 159.4703 seconds


[]
############# Summary #############
Final verified acc: 0.0% [total 1 examples]
Total verification count: 1 , total verified safe: 0 , verified unsafe: 0 , timeout: 1
max time 159.4703311920166
unknown (total 1): [0]
