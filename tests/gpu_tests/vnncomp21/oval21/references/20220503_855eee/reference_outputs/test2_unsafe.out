Building native CUDA modules...
/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
  csv_name: oval21_instances.csv
  onnx_path: null
  vnnlib_path: null
  results_file: null
  root_path: ../../../../../vnncomp2021/benchmarks/oval21
model:
  path: null
  name: mnist_9_200
data:
  start: 7
  end: 8
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR
  data_filter_path: null
specification:
  type: lp
  norm: .inf
  epsilon: null
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 2000
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.01
    lr_decay: 0.98
    optimizer: adam
    iteration: 50
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 360
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 10
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:03:33 2022 on ubuntu
saving results to vnn-comp_[oval21_instances]_start=7_end=8_iter=50_b=2000_timeout=360_branching=kfsb-max-10_lra-init=0.1_lra=0.01_lrb=0.01_PGD=skip.npz
customized start/end sample from 7 to 8

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Model prediction is: tensor([[-2.4467, -1.6589,  1.4179,  1.5205,  1.4902,  1.5877,  1.1525,  0.9255,
         -2.5830, -1.4059]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 3.9091e+00,  3.0479e+00,  8.4788e-02,  2.7038e-02, -3.6204e-03,
          3.4312e-01,  5.5045e-01,  4.0414e+00,  2.8461e+00]], device='cuda:0') None
best_l after optimization: -14.851221084594727 with beta sum per layer: []
alpha/beta optimization time: 8.019831418991089
initial alpha-CROWN bounds: tensor([[ 3.9096e+00,  3.0496e+00,  8.5046e-02,  2.7067e-02, -3.5040e-03,
          3.4338e-01,  5.5056e-01,  4.0415e+00,  2.8479e+00]], device='cuda:0',
       grad_fn=<AsStridedBackward>)
worst class: tensor(-0.0035, device='cuda:0', grad_fn=<MinBackward1>)
##### [0] True label: 5, Tested against: 0, onnx_path: nets/cifar_base_kw.onnx, vnnlib_path: vnnlib/cifar_base_kw-img1598-eps0.0026143790849673205.vnnlib ######
init opt crown verified for label 0 with bound 3.9096264839172363
Image 0 against label 0 verification end, Time cost: 0.00035834312438964844
##### [0] True label: 5, Tested against: 1, onnx_path: nets/cifar_base_kw.onnx, vnnlib_path: vnnlib/cifar_base_kw-img1598-eps0.0026143790849673205.vnnlib ######
init opt crown verified for label 1 with bound 3.049588680267334
Image 0 against label 1 verification end, Time cost: 0.0003833770751953125
##### [0] True label: 5, Tested against: 2, onnx_path: nets/cifar_base_kw.onnx, vnnlib_path: vnnlib/cifar_base_kw-img1598-eps0.0026143790849673205.vnnlib ######
init opt crown verified for label 2 with bound 0.08504581451416016
Image 0 against label 2 verification end, Time cost: 0.0003876686096191406
##### [0] True label: 5, Tested against: 3, onnx_path: nets/cifar_base_kw.onnx, vnnlib_path: vnnlib/cifar_base_kw-img1598-eps0.0026143790849673205.vnnlib ######
init opt crown verified for label 3 with bound 0.02706684172153473
Image 0 against label 3 verification end, Time cost: 0.0003628730773925781
##### [0] True label: 5, Tested against: 4, onnx_path: nets/cifar_base_kw.onnx, vnnlib_path: vnnlib/cifar_base_kw-img1598-eps0.0026143790849673205.vnnlib ######
Model prediction is: tensor([[-2.4467, -1.6589,  1.4179,  1.5205,  1.4902,  1.5877,  1.1525,  0.9255,
         -2.5830, -1.4059]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 8, 16, 16]) != torch.Size([2, 9, 1, 8, 16, 16]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 16, 8, 8]) != torch.Size([2, 9, 1, 16, 8, 8]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 8, 16, 16])
1 /11 torch.Size([1, 16, 8, 8])
2 /14 torch.Size([1, 100])
best_l after optimization: 0.0035033226013183594 with beta sum per layer: []
alpha/beta optimization time: 1.334024429321289
alpha-CROWN with fixed intermediate bounds: tensor([[-0.0035]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.0035033226013183594
layer 0 size torch.Size([2048]) unstable 31
layer 1 size torch.Size([1024]) unstable 26
layer 2 size torch.Size([100]) unstable 1
-----------------
# of unstable neurons: 58
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 8, 16, 16]) pre split depth:  7
batch:  torch.Size([1, 8, 16, 16]) post split depth:  7
splitting decisions: 
split level 0: [2, 97] 
split level 1: [1, 286] 
split level 2: [1, 817] 
split level 3: [1, 172] 
split level 4: [1, 140] 
split level 5: [1, 147] 
split level 6: [1, 158] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.35745537281036377 with beta sum per layer: [0.0, 1.241929292678833, 0.0]
alpha/beta optimization time: 0.6529438495635986
This batch time : update_bounds func: 0.6825	 prepare: 0.0147	 bound: 0.6533	 transfer: 0.0037	 finalize: 0.0104
Accumulated time: update_bounds func: 0.6825	 prepare: 0.0147	 bound: 0.6533	 transfer: 0.0037	 finalize: 0.0104
batch bounding time:  0.682828426361084
Current worst splitting domains [lb, ub] (depth):
[-0.00093,   inf] (8), [-0.00083,   inf] (8), [-0.00051,   inf] (8), [-0.00042,   inf] (8), 
length of domains: 4
Total time: 0.7654	 pickout: 0.0010	 decision: 0.0607	 get_bound: 0.7034	 add_domain: 0.0003
Current lb:-0.0009257793426513672
128 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.5810365676879883

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 8, 16, 16]) pre split depth:  5
batch:  torch.Size([4, 8, 16, 16]) post split depth:  5
splitting decisions: 
split level 0: [1, 994] [1, 994] [1, 994] [1, 994] 
split level 1: [1, 776] [1, 776] [1, 776] [1, 776] 
split level 2: [0, 653] [0, 653] [0, 357] [0, 357] 
split level 3: [1, 271] [1, 271] [0, 653] [0, 653] 
split level 4: [0, 357] [0, 357] [1, 271] [1, 271] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.042925767600536346 with beta sum per layer: [0.0, 11.531734466552734, 0.0]
alpha/beta optimization time: 0.587822675704956
This batch time : update_bounds func: 0.6235	 prepare: 0.0190	 bound: 0.5882	 transfer: 0.0057	 finalize: 0.0103
Accumulated time: update_bounds func: 1.3060	 prepare: 0.0337	 bound: 1.2415	 transfer: 0.0057	 finalize: 0.0207
batch bounding time:  0.6238853931427002
Current worst splitting domains [lb, ub] (depth):
[-0.00040,   inf] (14), [-0.00039,   inf] (14), [-0.00032,   inf] (14), [-0.00031,   inf] (14), [-0.00031,   inf] (14), [-0.00029,   inf] (14), [-0.00026,   inf] (14), [-0.00024,   inf] (14), [-0.00021,   inf] (14), [-0.00020,   inf] (14), [-0.00018,   inf] (14), [-0.00017,   inf] (14), [-0.00016,   inf] (14), [-0.00015,   inf] (14), [-0.00008,   inf] (14), [-0.00007,   inf] (14), [-0.00007,   inf] (14), [-0.00006,   inf] (14), [-0.00000,   inf] (14), 
length of domains: 19
Total time: 0.7114	 pickout: 0.0015	 decision: 0.0642	 get_bound: 0.6444	 add_domain: 0.0013
Current lb:-0.0003986358642578125
256 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.2933096885681152

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([19, 8, 16, 16]) pre split depth:  3
batch:  torch.Size([19, 8, 16, 16]) post split depth:  3
splitting decisions: 
split level 0: [1, 856] [1, 856] [1, 856] [1, 856] [1, 856] [1, 856] [1, 856] [1, 856] [1, 856] [1, 856] 
split level 1: [1, 766] [1, 766] [0, 1703] [1, 766] [1, 766] [0, 1703] [1, 766] [1, 766] [1, 766] [1, 766] 
split level 2: [1, 913] [1, 913] [1, 913] [1, 913] [1, 913] [1, 766] [1, 913] [1, 913] [1, 913] [1, 913] 
regular batch size: 2*76, diving batch size 1*0
best_l after optimization: -0.037143465131521225 with beta sum per layer: [0.13915111124515533, 7.784475326538086, 0.0]
alpha/beta optimization time: 0.6576228141784668
This batch time : update_bounds func: 0.6997	 prepare: 0.0236	 bound: 0.6580	 transfer: 0.0044	 finalize: 0.0132
Accumulated time: update_bounds func: 2.0058	 prepare: 0.0573	 bound: 1.8995	 transfer: 0.0044	 finalize: 0.0339
batch bounding time:  0.7000546455383301
Current worst splitting domains [lb, ub] (depth):
[-0.00031,   inf] (18), [-0.00030,   inf] (18), [-0.00023,   inf] (18), [-0.00022,   inf] (18), [-0.00022,   inf] (18), [-0.00021,   inf] (18), [-0.00017,   inf] (18), [-0.00016,   inf] (18), [-0.00013,   inf] (18), [-0.00011,   inf] (18), [-0.00009,   inf] (18), [-0.00008,   inf] (18), [-0.00008,   inf] (18), [-0.00006,   inf] (18), 
length of domains: 14
Total time: 0.7993	 pickout: 0.0043	 decision: 0.0737	 get_bound: 0.7202	 add_domain: 0.0011
Current lb:-0.0003113746643066406
408 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.0937957763671875

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([14, 8, 16, 16]) pre split depth:  3
batch:  torch.Size([14, 8, 16, 16]) post split depth:  3
splitting decisions: 
split level 0: [0, 636] [0, 636] [1, 581] [0, 636] [0, 1126] [0, 636] [0, 636] [0, 636] [1, 552] [0, 1126] 
split level 1: [1, 581] [1, 581] [1, 746] [1, 581] [1, 581] [1, 746] [1, 581] [1, 581] [0, 1822] [1, 581] 
split level 2: [1, 746] [1, 746] [1, 766] [1, 746] [1, 746] [1, 913] [1, 746] [1, 746] [0, 1126] [1, 746] 
regular batch size: 2*56, diving batch size 1*0
best_l after optimization: -0.020066553726792336 with beta sum per layer: [2.152850389480591, 6.309491157531738, 0.0]
alpha/beta optimization time: 0.6500558853149414
This batch time : update_bounds func: 0.6805	 prepare: 0.0179	 bound: 0.6504	 transfer: 0.0024	 finalize: 0.0093
Accumulated time: update_bounds func: 2.6863	 prepare: 0.0753	 bound: 2.5500	 transfer: 0.0024	 finalize: 0.0432
batch bounding time:  0.6807608604431152
Current worst splitting domains [lb, ub] (depth):
[-0.00027,   inf] (22), [-0.00025,   inf] (22), [-0.00025,   inf] (22), [-0.00023,   inf] (22), [-0.00023,   inf] (22), [-0.00022,   inf] (22), [-0.00021,   inf] (22), [-0.00020,   inf] (22), [-0.00017,   inf] (22), [-0.00016,   inf] (22), [-0.00015,   inf] (22), [-0.00014,   inf] (22), [-0.00013,   inf] (22), [-0.00013,   inf] (22), [-0.00013,   inf] (22), [-0.00011,   inf] (22), [-0.00011,   inf] (22), [-0.00010,   inf] (22), [-0.00009,   inf] (22), [-0.00009,   inf] (22), 
length of domains: 30
Total time: 0.7712	 pickout: 0.0033	 decision: 0.0693	 get_bound: 0.6961	 add_domain: 0.0025
Current lb:-0.0002658367156982422
520 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.8659608364105225

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([30, 8, 16, 16]) pre split depth:  2
batch:  torch.Size([30, 8, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [1, 665] [1, 665] [1, 665] [0, 636] [1, 665] [0, 636] [0, 636] [0, 636] [1, 665] [1, 665] 
split level 1: [0, 1126] [0, 1126] [0, 1126] [1, 665] [0, 1126] [1, 665] [1, 665] [1, 665] [0, 1126] [1, 581] 
regular batch size: 2*60, diving batch size 1*0
best_l after optimization: -0.008860020898282528 with beta sum per layer: [1.4314075708389282, 5.249993324279785, 0.0]
alpha/beta optimization time: 0.6651012897491455
This batch time : update_bounds func: 0.6976	 prepare: 0.0192	 bound: 0.6655	 transfer: 0.0026	 finalize: 0.0100
Accumulated time: update_bounds func: 3.3838	 prepare: 0.0945	 bound: 3.2154	 transfer: 0.0026	 finalize: 0.0532
batch bounding time:  0.697852611541748
Current worst splitting domains [lb, ub] (depth):
[-0.00020,   inf] (25), [-0.00019,   inf] (25), [-0.00018,   inf] (25), [-0.00017,   inf] (25), [-0.00014,   inf] (25), [-0.00012,   inf] (25), [-0.00012,   inf] (25), [-0.00011,   inf] (25), [-0.00010,   inf] (25), [-0.00009,   inf] (25), [-0.00009,   inf] (25), [-0.00009,   inf] (25), [-0.00008,   inf] (25), [-0.00007,   inf] (25), [-0.00007,   inf] (25), [-0.00006,   inf] (25), [-0.00006,   inf] (25), [-0.00005,   inf] (25), [-0.00004,   inf] (25), [-0.00003,   inf] (25), 
length of domains: 26
Total time: 0.7972	 pickout: 0.0062	 decision: 0.0793	 get_bound: 0.7093	 add_domain: 0.0024
Current lb:-0.000202178955078125
640 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.664384603500366

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([26, 8, 16, 16]) pre split depth:  2
batch:  torch.Size([26, 8, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [1, 298] [1, 298] [1, 298] [1, 298] [1, 298] [1, 298] [1, 298] [1, 298] [1, 298] [1, 298] 
split level 1: [0, 1703] [0, 1703] [0, 1703] [0, 1703] [0, 1126] [0, 1703] [0, 1126] [0, 1703] [0, 1703] [0, 1126] 
regular batch size: 2*52, diving batch size 1*0
best_l after optimization: -0.0827009454369545 with beta sum per layer: [1.027324914932251, 3.462531089782715, 0.0]
alpha/beta optimization time: 0.6626365184783936
This batch time : update_bounds func: 0.6911	 prepare: 0.0169	 bound: 0.6630	 transfer: 0.0023	 finalize: 0.0085
Accumulated time: update_bounds func: 4.0749	 prepare: 0.1114	 bound: 3.8784	 transfer: 0.0023	 finalize: 0.0617
batch bounding time:  0.6913256645202637
Current worst splitting domains [lb, ub] (depth):
[-0.00019,   inf] (28), [-0.00018,   inf] (28), [-0.00017,   inf] (28), [-0.00016,   inf] (28), [-0.00013,   inf] (28), [-0.00011,   inf] (28), [-0.00010,   inf] (28), [-0.00010,   inf] (28), [-0.00009,   inf] (28), [-0.00008,   inf] (28), [-0.00008,   inf] (28), [-0.00008,   inf] (28), [-0.00007,   inf] (28), [-0.00006,   inf] (28), [-0.00006,   inf] (28), [-0.00005,   inf] (28), [-0.00005,   inf] (28), [-0.00004,   inf] (28), [-0.00003,   inf] (28), [-0.00002,   inf] (28), 
length of domains: 25
Total time: 0.7857	 pickout: 0.0056	 decision: 0.0763	 get_bound: 0.7015	 add_domain: 0.0023
Current lb:-0.0001918886846397072
744 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.451174736022949

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([25, 8, 16, 16]) pre split depth:  3
batch:  torch.Size([25, 8, 16, 16]) post split depth:  3
splitting decisions: 
split level 0: [1, 847] [1, 847] [1, 847] [1, 847] [1, 847] [1, 847] [1, 847] [1, 847] [1, 847] [1, 847] 
split level 1: [0, 1822] [0, 1822] [0, 1822] [0, 1822] [0, 1822] [0, 1822] [0, 1822] [0, 1822] [0, 1822] [0, 1822] 
split level 2: [0, 1084] [0, 1084] [0, 1084] [0, 1084] [0, 1084] [0, 1084] [0, 1084] [0, 1084] [0, 1084] [0, 1084] 
regular batch size: 2*100, diving batch size 1*0
best_l after optimization: -0.013329967856407166 with beta sum per layer: [0.46781957149505615, 6.389014720916748, 0.0]
alpha/beta optimization time: 0.6938838958740234
This batch time : update_bounds func: 0.7472	 prepare: 0.0312	 bound: 0.6943	 transfer: 0.0041	 finalize: 0.0170
Accumulated time: update_bounds func: 4.8221	 prepare: 0.1426	 bound: 4.5728	 transfer: 0.0041	 finalize: 0.0787
batch bounding time:  0.7476356029510498
Current worst splitting domains [lb, ub] (depth):
[-0.00018,   inf] (32), [-0.00018,   inf] (32), [-0.00016,   inf] (32), [-0.00016,   inf] (32), [-0.00016,   inf] (32), [-0.00016,   inf] (32), [-0.00014,   inf] (32), [-0.00014,   inf] (32), [-0.00012,   inf] (32), [-0.00012,   inf] (32), [-0.00011,   inf] (32), [-0.00011,   inf] (32), [-0.00010,   inf] (32), [-0.00010,   inf] (32), [-0.00010,   inf] (32), [-0.00010,   inf] (32), [-0.00010,   inf] (32), [-0.00010,   inf] (32), [-0.00009,   inf] (32), [-0.00009,   inf] (32), 
length of domains: 68
Total time: 0.8669	 pickout: 0.0053	 decision: 0.0783	 get_bound: 0.7765	 add_domain: 0.0068
Current lb:-0.0001785755157470703
944 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.319820165634155

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([68, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([68, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 552] [1, 552] [1, 552] [1, 552] [1, 552] [1, 552] [1, 552] [1, 552] [1, 552] [1, 552] 
regular batch size: 2*68, diving batch size 1*0
best_l after optimization: -0.06155451387166977 with beta sum per layer: [2.121861457824707, 7.615891456604004, 0.0]
alpha/beta optimization time: 0.6498494148254395
This batch time : update_bounds func: 0.6864	 prepare: 0.0221	 bound: 0.6503	 transfer: 0.0056	 finalize: 0.0081
Accumulated time: update_bounds func: 5.5084	 prepare: 0.1646	 bound: 5.2230	 transfer: 0.0056	 finalize: 0.0868
batch bounding time:  0.6867470741271973
Current worst splitting domains [lb, ub] (depth):
[-0.00018,   inf] (34), [-0.00018,   inf] (34), [-0.00016,   inf] (34), [-0.00016,   inf] (34), [-0.00016,   inf] (34), [-0.00016,   inf] (34), [-0.00014,   inf] (34), [-0.00014,   inf] (34), [-0.00012,   inf] (34), [-0.00012,   inf] (34), [-0.00011,   inf] (34), [-0.00011,   inf] (34), [-0.00010,   inf] (34), [-0.00010,   inf] (34), [-0.00010,   inf] (34), [-0.00010,   inf] (34), [-0.00010,   inf] (34), [-0.00010,   inf] (34), [-0.00009,   inf] (34), [-0.00009,   inf] (34), 
length of domains: 72
Total time: 0.8085	 pickout: 0.0138	 decision: 0.1003	 get_bound: 0.6870	 add_domain: 0.0074
Current lb:-0.00017833709716796875
1080 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.130492210388184

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([72, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([72, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 193] [0, 193] [0, 193] [0, 193] [0, 193] [0, 193] [0, 193] [0, 193] [0, 193] [0, 193] 
regular batch size: 2*72, diving batch size 1*0
best_l after optimization: -0.004968023858964443 with beta sum per layer: [0.4957435429096222, 4.013509750366211, 0.0]
alpha/beta optimization time: 0.5367617607116699
This batch time : update_bounds func: 0.5650	 prepare: 0.0147	 bound: 0.5371	 transfer: 0.0048	 finalize: 0.0080
Accumulated time: update_bounds func: 6.0734	 prepare: 0.1793	 bound: 5.7601	 transfer: 0.0048	 finalize: 0.0947
batch bounding time:  0.5652697086334229
Current worst splitting domains [lb, ub] (depth):
[-0.00018,   inf] (36), [-0.00018,   inf] (36), [-0.00016,   inf] (36), [-0.00016,   inf] (36), [-0.00015,   inf] (36), [-0.00015,   inf] (36), [-0.00014,   inf] (36), [-0.00014,   inf] (36), [-0.00011,   inf] (36), [-0.00011,   inf] (36), [-0.00011,   inf] (36), [-0.00011,   inf] (36), [-0.00010,   inf] (36), [-0.00010,   inf] (36), [-0.00010,   inf] (36), [-0.00010,   inf] (36), [-0.00009,   inf] (36), [-0.00009,   inf] (36), [-0.00009,   inf] (36), [-0.00009,   inf] (36), 
length of domains: 66
Total time: 0.6641	 pickout: 0.0103	 decision: 0.0810	 get_bound: 0.5655	 add_domain: 0.0072
Current lb:-0.00017571449279785156
1224 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.796525955200195

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([66, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([66, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 106] [0, 106] [0, 106] [0, 106] [0, 106] [0, 106] [0, 106] [0, 106] [0, 106] [0, 106] 
regular batch size: 2*66, diving batch size 1*0
best_l after optimization: -0.013673080131411552 with beta sum per layer: [2.2396697998046875, 3.6894993782043457, 0.0]
alpha/beta optimization time: 0.5735440254211426
This batch time : update_bounds func: 0.6589	 prepare: 0.0137	 bound: 0.5738	 transfer: 0.0031	 finalize: 0.0678
Accumulated time: update_bounds func: 6.7323	 prepare: 0.1931	 bound: 6.3339	 transfer: 0.0031	 finalize: 0.1625
batch bounding time:  0.659210205078125
Current worst splitting domains [lb, ub] (depth):
[-0.00016,   inf] (38), [-0.00016,   inf] (38), [-0.00015,   inf] (38), [-0.00015,   inf] (38), [-0.00014,   inf] (38), [-0.00014,   inf] (38), [-0.00013,   inf] (38), [-0.00013,   inf] (38), [-0.00010,   inf] (38), [-0.00010,   inf] (38), [-0.00010,   inf] (38), [-0.00010,   inf] (38), [-0.00009,   inf] (38), [-0.00009,   inf] (38), [-0.00008,   inf] (38), [-0.00008,   inf] (38), [-0.00008,   inf] (38), [-0.00008,   inf] (38), [-0.00008,   inf] (38), [-0.00008,   inf] (38), 
length of domains: 59
Total time: 0.7528	 pickout: 0.0094	 decision: 0.0781	 get_bound: 0.6594	 add_domain: 0.0059
Current lb:-0.0001633167266845703
1356 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.551221132278442

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([59, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([59, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 742] [0, 742] [0, 742] [0, 742] [0, 742] [0, 742] [0, 742] [0, 742] [0, 742] [0, 742] 
regular batch size: 2*59, diving batch size 1*0
best_l after optimization: -0.010676955804228783 with beta sum per layer: [1.9049311876296997, 3.2833054065704346, 0.0]
alpha/beta optimization time: 0.5585930347442627
This batch time : update_bounds func: 0.5806	 prepare: 0.0123	 bound: 0.5589	 transfer: 0.0026	 finalize: 0.0066
Accumulated time: update_bounds func: 7.3129	 prepare: 0.2053	 bound: 6.8928	 transfer: 0.0026	 finalize: 0.1691
batch bounding time:  0.5808494091033936
Current worst splitting domains [lb, ub] (depth):
[-0.00016,   inf] (40), [-0.00016,   inf] (40), [-0.00015,   inf] (40), [-0.00015,   inf] (40), [-0.00014,   inf] (40), [-0.00014,   inf] (40), [-0.00013,   inf] (40), [-0.00013,   inf] (40), [-0.00010,   inf] (40), [-0.00010,   inf] (40), [-0.00010,   inf] (40), [-0.00010,   inf] (40), [-0.00009,   inf] (40), [-0.00009,   inf] (40), [-0.00008,   inf] (40), [-0.00008,   inf] (40), [-0.00008,   inf] (40), [-0.00008,   inf] (40), [-0.00008,   inf] (40), [-0.00008,   inf] (40), 
length of domains: 57
Total time: 0.6702	 pickout: 0.0086	 decision: 0.0746	 get_bound: 0.5810	 add_domain: 0.0060
Current lb:-0.00016297594993375242
1474 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.223046064376831

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([57, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([57, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 300] [1, 300] [1, 300] [1, 300] [1, 300] [1, 300] [1, 300] [1, 300] [1, 300] [1, 300] 
regular batch size: 2*57, diving batch size 1*0
best_l after optimization: -0.04222835600376129 with beta sum per layer: [0.17171183228492737, 3.1093344688415527, 0.0]
alpha/beta optimization time: 0.46092844009399414
This batch time : update_bounds func: 0.4824	 prepare: 0.0120	 bound: 0.4613	 transfer: 0.0024	 finalize: 0.0065
Accumulated time: update_bounds func: 7.7953	 prepare: 0.2174	 bound: 7.3541	 transfer: 0.0024	 finalize: 0.1755
batch bounding time:  0.48278260231018066
Current worst splitting domains [lb, ub] (depth):
[-0.00016,   inf] (42), [-0.00016,   inf] (42), [-0.00015,   inf] (42), [-0.00015,   inf] (42), [-0.00014,   inf] (42), [-0.00014,   inf] (42), [-0.00013,   inf] (42), [-0.00013,   inf] (42), [-0.00010,   inf] (42), [-0.00010,   inf] (42), [-0.00010,   inf] (42), [-0.00010,   inf] (42), [-0.00009,   inf] (42), [-0.00008,   inf] (42), [-0.00008,   inf] (42), [-0.00008,   inf] (42), [-0.00008,   inf] (42), [-0.00008,   inf] (42), [-0.00008,   inf] (42), [-0.00007,   inf] (42), 
length of domains: 55
Total time: 0.5704	 pickout: 0.0078	 decision: 0.0736	 get_bound: 0.4830	 add_domain: 0.0059
Current lb:-0.0001614093780517578
1588 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.795002222061157

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([55, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([55, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 30] [1, 30] [1, 30] [1, 723] [1, 30] [1, 30] [1, 30] [0, 1112] [1, 30] [1, 30] 
regular batch size: 2*55, diving batch size 1*0
best_l after optimization: -0.0353718176484108 with beta sum per layer: [1.2084951400756836, 6.252666473388672, 0.0]
alpha/beta optimization time: 0.5687074661254883
This batch time : update_bounds func: 0.5895	 prepare: 0.0117	 bound: 0.5690	 transfer: 0.0023	 finalize: 0.0063
Accumulated time: update_bounds func: 8.3848	 prepare: 0.2291	 bound: 7.9231	 transfer: 0.0023	 finalize: 0.1818
batch bounding time:  0.5897650718688965
Current worst splitting domains [lb, ub] (depth):
[-0.00016,   inf] (44), [-0.00016,   inf] (44), [-0.00015,   inf] (44), [-0.00015,   inf] (44), [-0.00014,   inf] (44), [-0.00014,   inf] (44), [-0.00013,   inf] (44), [-0.00013,   inf] (44), [-0.00013,   inf] (44), [-0.00010,   inf] (44), [-0.00010,   inf] (44), [-0.00010,   inf] (44), [-0.00010,   inf] (44), [-0.00009,   inf] (44), [-0.00008,   inf] (44), [-0.00008,   inf] (44), [-0.00008,   inf] (44), [-0.00008,   inf] (44), [-0.00008,   inf] (44), [-0.00008,   inf] (44), 
length of domains: 56
Total time: 0.6755	 pickout: 0.0077	 decision: 0.0717	 get_bound: 0.5900	 add_domain: 0.0061
Current lb:-0.0001614093780517578
1698 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.472129821777344

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([56, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([56, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 1112] [0, 1112] [0, 1112] [1, 30] [0, 1112] [0, 1112] [0, 1112] [1, 30] [0, 71] [0, 1112] 
regular batch size: 2*56, diving batch size 1*0
best_l after optimization: -0.0006982713821344078 with beta sum per layer: [0.6531294584274292, 3.6598615646362305, 0.0]
alpha/beta optimization time: 0.5647690296173096
This batch time : update_bounds func: 0.5862	 prepare: 0.0120	 bound: 0.5651	 transfer: 0.0022	 finalize: 0.0066
Accumulated time: update_bounds func: 8.9710	 prepare: 0.2411	 bound: 8.4882	 transfer: 0.0022	 finalize: 0.1884
batch bounding time:  0.5864200592041016
Current worst splitting domains [lb, ub] (depth):
[-0.00016,   inf] (46), [-0.00016,   inf] (46), [-0.00016,   inf] (46), [-0.00016,   inf] (46), [-0.00015,   inf] (46), [-0.00015,   inf] (46), [-0.00015,   inf] (46), [-0.00014,   inf] (46), [-0.00014,   inf] (46), [-0.00014,   inf] (46), [-0.00014,   inf] (46), [-0.00013,   inf] (46), [-0.00013,   inf] (46), [-0.00013,   inf] (46), [-0.00013,   inf] (46), [-0.00010,   inf] (46), [-0.00010,   inf] (46), [-0.00010,   inf] (46), [-0.00010,   inf] (46), [-0.00010,   inf] (46), 
length of domains: 97
Total time: 0.6781	 pickout: 0.0080	 decision: 0.0728	 get_bound: 0.5866	 add_domain: 0.0107
Current lb:-0.0001614093780517578
1810 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.151541948318481

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([97, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([97, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 133] [0, 133] [0, 133] [0, 133] [0, 133] [0, 133] [0, 133] [0, 133] [0, 133] [0, 133] 
regular batch size: 2*97, diving batch size 1*0
best_l after optimization: 0.005123664624989033 with beta sum per layer: [0.3039632737636566, 5.2259087562561035, 0.0]
alpha/beta optimization time: 0.5293383598327637
This batch time : update_bounds func: 0.5645	 prepare: 0.0198	 bound: 0.5297	 transfer: 0.0036	 finalize: 0.0110
Accumulated time: update_bounds func: 9.5355	 prepare: 0.2608	 bound: 9.0178	 transfer: 0.0036	 finalize: 0.1994
batch bounding time:  0.5648665428161621
Current worst splitting domains [lb, ub] (depth):
[-0.00015,   inf] (48), [-0.00015,   inf] (48), [-0.00015,   inf] (48), [-0.00015,   inf] (48), [-0.00014,   inf] (48), [-0.00014,   inf] (48), [-0.00014,   inf] (48), [-0.00013,   inf] (48), [-0.00013,   inf] (48), [-0.00013,   inf] (48), [-0.00013,   inf] (48), [-0.00012,   inf] (48), [-0.00012,   inf] (48), [-0.00012,   inf] (48), [-0.00012,   inf] (48), [-0.00010,   inf] (48), [-0.00010,   inf] (48), [-0.00010,   inf] (48), [-0.00010,   inf] (48), [-0.00009,   inf] (48), 
length of domains: 133
Total time: 0.6900	 pickout: 0.0133	 decision: 0.0959	 get_bound: 0.5652	 add_domain: 0.0156
Current lb:-0.0001518726348876953
2004 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.844074487686157

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([133, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([133, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 180] [0, 180] [0, 180] [0, 180] [0, 180] [0, 180] [0, 180] [0, 180] [0, 180] [0, 180] 
regular batch size: 2*133, diving batch size 1*0
best_l after optimization: -0.0010867201490327716 with beta sum per layer: [3.161482572555542, 6.977050304412842, 0.0]
alpha/beta optimization time: 0.5897889137268066
This batch time : update_bounds func: 0.6413	 prepare: 0.0267	 bound: 0.5901	 transfer: 0.0091	 finalize: 0.0148
Accumulated time: update_bounds func: 10.1768	 prepare: 0.2875	 bound: 9.6079	 transfer: 0.0091	 finalize: 0.2143
batch bounding time:  0.6417584419250488
Current worst splitting domains [lb, ub] (depth):
[-0.00015,   inf] (50), [-0.00015,   inf] (50), [-0.00015,   inf] (50), [-0.00015,   inf] (50), [-0.00013,   inf] (50), [-0.00013,   inf] (50), [-0.00013,   inf] (50), [-0.00013,   inf] (50), [-0.00013,   inf] (50), [-0.00013,   inf] (50), [-0.00013,   inf] (50), [-0.00011,   inf] (50), [-0.00011,   inf] (50), [-0.00011,   inf] (50), [-0.00011,   inf] (50), [-0.00009,   inf] (50), [-0.00009,   inf] (50), [-0.00009,   inf] (50), [-0.00009,   inf] (50), [-0.00009,   inf] (50), 
length of domains: 123
Total time: 0.8349	 pickout: 0.0179	 decision: 0.1589	 get_bound: 0.6422	 add_domain: 0.0159
Current lb:-0.00014853477478027344
2270 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.682587385177612

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([123, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([123, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 71] [0, 71] [0, 71] [0, 71] [0, 71] [0, 71] [0, 1112] [0, 71] [0, 71] [0, 71] 
regular batch size: 2*123, diving batch size 1*0
best_l after optimization: -0.002875634003430605 with beta sum per layer: [6.070321083068848, 5.446623802185059, 0.0]
alpha/beta optimization time: 0.5810942649841309
This batch time : update_bounds func: 0.6258	 prepare: 0.0247	 bound: 0.5814	 transfer: 0.0053	 finalize: 0.0137
Accumulated time: update_bounds func: 10.8026	 prepare: 0.3122	 bound: 10.1893	 transfer: 0.0053	 finalize: 0.2280
batch bounding time:  0.6261603832244873
Current worst splitting domains [lb, ub] (depth):
[-0.00015,   inf] (52), [-0.00015,   inf] (52), [-0.00015,   inf] (52), [-0.00015,   inf] (52), [-0.00013,   inf] (52), [-0.00013,   inf] (52), [-0.00013,   inf] (52), [-0.00013,   inf] (52), [-0.00013,   inf] (52), [-0.00013,   inf] (52), [-0.00013,   inf] (52), [-0.00013,   inf] (52), [-0.00011,   inf] (52), [-0.00011,   inf] (52), [-0.00011,   inf] (52), [-0.00011,   inf] (52), [-0.00009,   inf] (52), [-0.00009,   inf] (52), [-0.00009,   inf] (52), [-0.00009,   inf] (52), 
length of domains: 132
Total time: 0.7630	 pickout: 0.0163	 decision: 0.1044	 get_bound: 0.6266	 add_domain: 0.0157
Current lb:-0.00014853477478027344
2516 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.448908805847168

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([132, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([132, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 268] [1, 268] [1, 268] [1, 268] [1, 268] [1, 268] [0, 71] [0, 71] [1, 268] [1, 268] 
regular batch size: 2*132, diving batch size 1*0
best_l after optimization: -0.1038271114230156 with beta sum per layer: [4.029653549194336, 14.019445419311523, 0.0]
alpha/beta optimization time: 0.5831811428070068
This batch time : update_bounds func: 0.6291	 prepare: 0.0263	 bound: 0.5835	 transfer: 0.0043	 finalize: 0.0144
Accumulated time: update_bounds func: 11.4316	 prepare: 0.3385	 bound: 10.7728	 transfer: 0.0043	 finalize: 0.2424
batch bounding time:  0.6294782161712646
Current worst splitting domains [lb, ub] (depth):
[-0.00015,   inf] (54), [-0.00015,   inf] (54), [-0.00015,   inf] (54), [-0.00015,   inf] (54), [-0.00013,   inf] (54), [-0.00013,   inf] (54), [-0.00013,   inf] (54), [-0.00013,   inf] (54), [-0.00013,   inf] (54), [-0.00013,   inf] (54), [-0.00013,   inf] (54), [-0.00013,   inf] (54), [-0.00011,   inf] (54), [-0.00011,   inf] (54), [-0.00011,   inf] (54), [-0.00011,   inf] (54), [-0.00009,   inf] (54), [-0.00009,   inf] (54), [-0.00009,   inf] (54), [-0.00009,   inf] (54), 
length of domains: 132
Total time: 0.7723	 pickout: 0.0176	 decision: 0.1088	 get_bound: 0.6299	 add_domain: 0.0160
Current lb:-0.00014853477478027344
2780 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.224922180175781

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([132, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([132, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 1228] [0, 1228] [0, 1228] [0, 1228] [0, 1228] [0, 1228] [1, 268] [1, 268] [0, 1228] [0, 1228] 
regular batch size: 2*132, diving batch size 1*0
best_l after optimization: -0.03692946583032608 with beta sum per layer: [9.046058654785156, 6.635734558105469, 0.0]
alpha/beta optimization time: 0.6475362777709961
This batch time : update_bounds func: 0.7021	 prepare: 0.0265	 bound: 0.6479	 transfer: 0.0053	 finalize: 0.0218
Accumulated time: update_bounds func: 12.1338	 prepare: 0.3650	 bound: 11.4207	 transfer: 0.0053	 finalize: 0.2643
batch bounding time:  0.7025809288024902
Current worst splitting domains [lb, ub] (depth):
[-0.00015,   inf] (56), [-0.00015,   inf] (56), [-0.00015,   inf] (56), [-0.00015,   inf] (56), [-0.00013,   inf] (56), [-0.00013,   inf] (56), [-0.00013,   inf] (56), [-0.00013,   inf] (56), [-0.00013,   inf] (56), [-0.00013,   inf] (56), [-0.00013,   inf] (56), [-0.00013,   inf] (56), [-0.00011,   inf] (56), [-0.00011,   inf] (56), [-0.00011,   inf] (56), [-0.00011,   inf] (56), [-0.00009,   inf] (56), [-0.00009,   inf] (56), [-0.00009,   inf] (56), [-0.00009,   inf] (56), 
length of domains: 132
Total time: 0.8903	 pickout: 0.0177	 decision: 0.1513	 get_bound: 0.7031	 add_domain: 0.0182
Current lb:-0.00014853477478027344
3044 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.118690729141235

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([132, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([132, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 723] [1, 723] [1, 723] [1, 723] [1, 723] [1, 723] [0, 1228] [0, 1228] [1, 723] [1, 723] 
regular batch size: 2*132, diving batch size 1*0
best_l after optimization: -0.14227326214313507 with beta sum per layer: [5.445962429046631, 15.118309020996094, 0.0]
alpha/beta optimization time: 0.6729061603546143
This batch time : update_bounds func: 0.7428	 prepare: 0.0406	 bound: 0.6733	 transfer: 0.0059	 finalize: 0.0224
Accumulated time: update_bounds func: 12.8765	 prepare: 0.4055	 bound: 12.0940	 transfer: 0.0059	 finalize: 0.2866
batch bounding time:  0.7432422637939453
Current worst splitting domains [lb, ub] (depth):
[-0.00015,   inf] (58), [-0.00015,   inf] (58), [-0.00015,   inf] (58), [-0.00015,   inf] (58), [-0.00013,   inf] (58), [-0.00013,   inf] (58), [-0.00013,   inf] (58), [-0.00013,   inf] (58), [-0.00013,   inf] (58), [-0.00013,   inf] (58), [-0.00013,   inf] (58), [-0.00013,   inf] (58), [-0.00011,   inf] (58), [-0.00011,   inf] (58), [-0.00011,   inf] (58), [-0.00011,   inf] (58), [-0.00009,   inf] (58), [-0.00009,   inf] (58), [-0.00009,   inf] (58), [-0.00009,   inf] (58), 
length of domains: 132
Total time: 0.9168	 pickout: 0.0247	 decision: 0.1307	 get_bound: 0.7438	 add_domain: 0.0176
Current lb:-0.00014853477478027344
3308 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.03909921646118

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([132, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([132, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 1235] [0, 1235] [0, 1235] [0, 1235] [0, 1235] [0, 1235] [0, 1235] [0, 1235] [0, 1235] [0, 1235] 
regular batch size: 2*132, diving batch size 1*0
best_l after optimization: -0.0036044656299054623 with beta sum per layer: [3.4341440200805664, 6.127763271331787, 0.0]
alpha/beta optimization time: 0.677943229675293
This batch time : update_bounds func: 0.7450	 prepare: 0.0401	 bound: 0.6784	 transfer: 0.0044	 finalize: 0.0215
Accumulated time: update_bounds func: 13.6216	 prepare: 0.4456	 bound: 12.7723	 transfer: 0.0044	 finalize: 0.3081
batch bounding time:  0.7454872131347656
Current worst splitting domains [lb, ub] (depth):
[-0.00015,   inf] (60), [-0.00015,   inf] (60), [-0.00015,   inf] (60), [-0.00015,   inf] (60), [-0.00013,   inf] (60), [-0.00013,   inf] (60), [-0.00013,   inf] (60), [-0.00013,   inf] (60), [-0.00013,   inf] (60), [-0.00013,   inf] (60), [-0.00013,   inf] (60), [-0.00013,   inf] (60), [-0.00011,   inf] (60), [-0.00011,   inf] (60), [-0.00011,   inf] (60), [-0.00011,   inf] (60), [-0.00009,   inf] (60), [-0.00009,   inf] (60), [-0.00009,   inf] (60), [-0.00009,   inf] (60), 
length of domains: 144
Total time: 0.9637	 pickout: 0.0250	 decision: 0.1735	 get_bound: 0.7460	 add_domain: 0.0192
Current lb:-0.00014853477478027344
3572 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.006503343582153

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([144, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([144, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 1205] [0, 1205] [0, 1205] [0, 1205] [0, 1205] [0, 1205] [0, 1205] [0, 1205] [0, 1205] [0, 1205] 
regular batch size: 2*144, diving batch size 1*0
best_l after optimization: -0.00043125986121594906 with beta sum per layer: [2.5530753135681152, 5.59182071685791, 0.0]
alpha/beta optimization time: 0.6786844730377197
This batch time : update_bounds func: 0.7555	 prepare: 0.0455	 bound: 0.6791	 transfer: 0.0057	 finalize: 0.0246
Accumulated time: update_bounds func: 14.3771	 prepare: 0.4911	 bound: 13.4514	 transfer: 0.0057	 finalize: 0.3327
batch bounding time:  0.7560062408447266
Current worst splitting domains [lb, ub] (depth):
[-0.00015,   inf] (62), [-0.00015,   inf] (62), [-0.00015,   inf] (62), [-0.00015,   inf] (62), [-0.00013,   inf] (62), [-0.00013,   inf] (62), [-0.00013,   inf] (62), [-0.00013,   inf] (62), [-0.00013,   inf] (62), [-0.00013,   inf] (62), [-0.00013,   inf] (62), [-0.00013,   inf] (62), [-0.00011,   inf] (62), [-0.00011,   inf] (62), [-0.00011,   inf] (62), [-0.00011,   inf] (62), [-0.00009,   inf] (62), [-0.00009,   inf] (62), [-0.00009,   inf] (62), [-0.00009,   inf] (62), 
length of domains: 156
Total time: 0.9437	 pickout: 0.0271	 decision: 0.1388	 get_bound: 0.7565	 add_domain: 0.0212
Current lb:-0.00014853477478027344
3860 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.954347133636475

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([156, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([156, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 1157] [0, 1157] [0, 1157] [0, 1157] [0, 1157] [0, 1157] [0, 1157] [0, 1157] [0, 1157] [0, 1157] 
regular batch size: 2*156, diving batch size 1*0
best_l after optimization: 0.009678288362920284 with beta sum per layer: [1.659981608390808, 6.636795997619629, 0.0]
alpha/beta optimization time: 0.6844222545623779
This batch time : update_bounds func: 0.7662	 prepare: 0.0471	 bound: 0.6848	 transfer: 0.0077	 finalize: 0.0259
Accumulated time: update_bounds func: 15.1433	 prepare: 0.5382	 bound: 14.1362	 transfer: 0.0077	 finalize: 0.3586
batch bounding time:  0.7667562961578369
Current worst splitting domains [lb, ub] (depth):
[-0.00015,   inf] (64), [-0.00015,   inf] (64), [-0.00015,   inf] (64), [-0.00015,   inf] (64), [-0.00013,   inf] (64), [-0.00013,   inf] (64), [-0.00013,   inf] (64), [-0.00013,   inf] (64), [-0.00013,   inf] (64), [-0.00013,   inf] (64), [-0.00013,   inf] (64), [-0.00013,   inf] (64), [-0.00013,   inf] (64), [-0.00013,   inf] (64), [-0.00013,   inf] (64), [-0.00013,   inf] (64), [-0.00012,   inf] (64), [-0.00011,   inf] (64), [-0.00011,   inf] (64), [-0.00011,   inf] (64), 
length of domains: 249
Total time: 1.0200	 pickout: 0.0291	 decision: 0.1885	 get_bound: 0.7673	 add_domain: 0.0350
Current lb:-0.00014853477478027344
4172 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 19.978282690048218

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([249, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([249, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 683] [0, 683] [0, 683] [0, 683] [0, 683] [0, 683] [0, 683] [0, 683] [0, 683] [0, 683] 
regular batch size: 2*249, diving batch size 1*0
best_l after optimization: -0.0004307888448238373 with beta sum per layer: [4.505063533782959, 10.212251663208008, 0.0]
alpha/beta optimization time: 0.7441751956939697
This batch time : update_bounds func: 0.8771	 prepare: 0.0741	 bound: 0.7446	 transfer: 0.0161	 finalize: 0.0412
Accumulated time: update_bounds func: 16.0204	 prepare: 0.6123	 bound: 14.8808	 transfer: 0.0161	 finalize: 0.3998
batch bounding time:  0.8778719902038574
Current worst splitting domains [lb, ub] (depth):
[-0.00013,   inf] (66), [-0.00013,   inf] (66), [-0.00013,   inf] (66), [-0.00013,   inf] (66), [-0.00012,   inf] (66), [-0.00011,   inf] (66), [-0.00011,   inf] (66), [-0.00011,   inf] (66), [-0.00011,   inf] (66), [-0.00011,   inf] (66), [-0.00011,   inf] (66), [-0.00011,   inf] (66), [-0.00011,   inf] (66), [-0.00011,   inf] (66), [-0.00011,   inf] (66), [-0.00011,   inf] (66), [-0.00009,   inf] (66), [-0.00009,   inf] (66), [-0.00009,   inf] (66), [-0.00009,   inf] (66), 
length of domains: 174
Total time: 1.1972	 pickout: 0.0464	 decision: 0.1992	 get_bound: 0.8788	 add_domain: 0.0728
Current lb:-0.00012874603271484375
4670 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 21.182552337646484

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([174, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([174, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 748] [0, 748] [0, 748] [0, 748] [0, 748] [0, 748] [0, 748] [0, 748] [0, 748] [0, 748] 
regular batch size: 2*174, diving batch size 1*0
best_l after optimization: 0.005069834180176258 with beta sum per layer: [3.0122270584106445, 6.384012222290039, 0.0]
alpha/beta optimization time: 0.6850337982177734
This batch time : update_bounds func: 0.7733	 prepare: 0.0525	 bound: 0.6854	 transfer: 0.0056	 finalize: 0.0289
Accumulated time: update_bounds func: 16.7937	 prepare: 0.6648	 bound: 15.5662	 transfer: 0.0056	 finalize: 0.4287
batch bounding time:  0.7738087177276611
Current worst splitting domains [lb, ub] (depth):
[-0.00012,   inf] (68), [-0.00012,   inf] (68), [-0.00012,   inf] (68), [-0.00012,   inf] (68), [-0.00010,   inf] (68), [-0.00010,   inf] (68), [-0.00010,   inf] (68), [-0.00010,   inf] (68), [-0.00010,   inf] (68), [-0.00010,   inf] (68), [-0.00010,   inf] (68), [-0.00010,   inf] (68), [-0.00010,   inf] (68), [-0.00010,   inf] (68), [-0.00010,   inf] (68), [-0.00010,   inf] (68), [-0.00008,   inf] (68), [-0.00008,   inf] (68), [-0.00008,   inf] (68), [-0.00008,   inf] (68), 
length of domains: 176
Total time: 0.9874	 pickout: 0.0327	 decision: 0.1549	 get_bound: 0.7745	 add_domain: 0.0253
Current lb:-0.00011777877807617188
5018 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 22.17484998703003

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([176, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([176, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 1272] [0, 1272] [0, 1272] [0, 1272] [0, 1272] [0, 1272] [0, 1272] [0, 1272] [0, 1272] [0, 1272] 
regular batch size: 2*176, diving batch size 1*0
best_l after optimization: -0.00631167134270072 with beta sum per layer: [5.416069030761719, 5.151627540588379, 0.0]
alpha/beta optimization time: 0.6878814697265625
This batch time : update_bounds func: 0.8183	 prepare: 0.0530	 bound: 0.6883	 transfer: 0.0055	 finalize: 0.0707
Accumulated time: update_bounds func: 17.6119	 prepare: 0.7178	 bound: 16.2545	 transfer: 0.0055	 finalize: 0.4994
batch bounding time:  0.8188729286193848
Current worst splitting domains [lb, ub] (depth):
[-0.00012,   inf] (70), [-0.00012,   inf] (70), [-0.00012,   inf] (70), [-0.00012,   inf] (70), [-0.00010,   inf] (70), [-0.00010,   inf] (70), [-0.00010,   inf] (70), [-0.00010,   inf] (70), [-0.00010,   inf] (70), [-0.00010,   inf] (70), [-0.00010,   inf] (70), [-0.00010,   inf] (70), [-0.00010,   inf] (70), [-0.00010,   inf] (70), [-0.00010,   inf] (70), [-0.00010,   inf] (70), [-0.00008,   inf] (70), [-0.00008,   inf] (70), [-0.00008,   inf] (70), [-0.00008,   inf] (70), 
length of domains: 176
Total time: 1.0328	 pickout: 0.0332	 decision: 0.1545	 get_bound: 0.8195	 add_domain: 0.0256
Current lb:-0.00011777877807617188
5370 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 23.212506532669067

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([176, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([176, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 703] [0, 703] [0, 703] [0, 703] [0, 703] [0, 703] [0, 703] [0, 703] [0, 703] [0, 703] 
regular batch size: 2*176, diving batch size 1*0
best_l after optimization: -0.00711407233029604 with beta sum per layer: [6.221746444702148, 5.270221710205078, 0.0]
alpha/beta optimization time: 0.6840400695800781
This batch time : update_bounds func: 0.7735	 prepare: 0.0529	 bound: 0.6844	 transfer: 0.0056	 finalize: 0.0297
Accumulated time: update_bounds func: 18.3855	 prepare: 0.7707	 bound: 16.9389	 transfer: 0.0056	 finalize: 0.5291
batch bounding time:  0.7740433216094971
Current worst splitting domains [lb, ub] (depth):
[-0.00012,   inf] (72), [-0.00012,   inf] (72), [-0.00012,   inf] (72), [-0.00012,   inf] (72), [-0.00010,   inf] (72), [-0.00010,   inf] (72), [-0.00010,   inf] (72), [-0.00010,   inf] (72), [-0.00010,   inf] (72), [-0.00010,   inf] (72), [-0.00010,   inf] (72), [-0.00010,   inf] (72), [-0.00010,   inf] (72), [-0.00010,   inf] (72), [-0.00010,   inf] (72), [-0.00010,   inf] (72), [-0.00008,   inf] (72), [-0.00008,   inf] (72), [-0.00008,   inf] (72), [-0.00008,   inf] (72), 
length of domains: 176
Total time: 0.9907	 pickout: 0.0327	 decision: 0.1573	 get_bound: 0.7747	 add_domain: 0.0260
Current lb:-0.00011777877807617188
5722 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 24.207942485809326

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([176, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([176, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 1246] [0, 1246] [0, 1246] [0, 1246] [0, 1246] [0, 1246] [0, 1246] [0, 1246] [0, 1246] [0, 1246] 
regular batch size: 2*176, diving batch size 1*0
best_l after optimization: -0.0001542549580335617 with beta sum per layer: [3.989182233810425, 5.233788967132568, 0.0]
alpha/beta optimization time: 0.6878354549407959
This batch time : update_bounds func: 0.7765	 prepare: 0.0528	 bound: 0.6882	 transfer: 0.0055	 finalize: 0.0292
Accumulated time: update_bounds func: 19.1620	 prepare: 0.8235	 bound: 17.6271	 transfer: 0.0055	 finalize: 0.5583
batch bounding time:  0.7770891189575195
Current worst splitting domains [lb, ub] (depth):
[-0.00012,   inf] (74), [-0.00012,   inf] (74), [-0.00012,   inf] (74), [-0.00012,   inf] (74), [-0.00010,   inf] (74), [-0.00010,   inf] (74), [-0.00010,   inf] (74), [-0.00010,   inf] (74), [-0.00010,   inf] (74), [-0.00010,   inf] (74), [-0.00010,   inf] (74), [-0.00010,   inf] (74), [-0.00010,   inf] (74), [-0.00010,   inf] (74), [-0.00010,   inf] (74), [-0.00010,   inf] (74), [-0.00008,   inf] (74), [-0.00008,   inf] (74), [-0.00008,   inf] (74), [-0.00008,   inf] (74), 
length of domains: 184
Total time: 1.0373	 pickout: 0.0323	 decision: 0.1981	 get_bound: 0.7777	 add_domain: 0.0292
Current lb:-0.00011777877807617188
6074 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 25.250512838363647

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([184, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([184, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 719] [0, 719] [0, 719] [0, 719] [0, 719] [0, 719] [0, 719] [0, 719] [0, 719] [0, 719] 
regular batch size: 2*184, diving batch size 1*0
best_l after optimization: -0.00931565836071968 with beta sum per layer: [6.544693946838379, 4.990781784057617, 0.0]
alpha/beta optimization time: 0.6901512145996094
This batch time : update_bounds func: 0.7824	 prepare: 0.0552	 bound: 0.6905	 transfer: 0.0057	 finalize: 0.0301
Accumulated time: update_bounds func: 19.9444	 prepare: 0.8787	 bound: 18.3177	 transfer: 0.0057	 finalize: 0.5884
batch bounding time:  0.7829756736755371
Current worst splitting domains [lb, ub] (depth):
[-0.00012,   inf] (76), [-0.00012,   inf] (76), [-0.00012,   inf] (76), [-0.00012,   inf] (76), [-0.00010,   inf] (76), [-0.00010,   inf] (76), [-0.00010,   inf] (76), [-0.00010,   inf] (76), [-0.00010,   inf] (76), [-0.00010,   inf] (76), [-0.00010,   inf] (76), [-0.00010,   inf] (76), [-0.00010,   inf] (76), [-0.00010,   inf] (76), [-0.00010,   inf] (76), [-0.00010,   inf] (76), [-0.00008,   inf] (76), [-0.00008,   inf] (76), [-0.00008,   inf] (76), [-0.00008,   inf] (76), 
length of domains: 184
Total time: 1.0099	 pickout: 0.0342	 decision: 0.1627	 get_bound: 0.7837	 add_domain: 0.0293
Current lb:-0.00011777877807617188
6442 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 26.26569628715515

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([184, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([184, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 1052] [0, 1052] [0, 1052] [0, 1052] [0, 1052] [0, 1052] [0, 1052] [0, 1052] [0, 1052] [0, 1052] 
regular batch size: 2*184, diving batch size 1*0
best_l after optimization: 0.014023303985595703 with beta sum per layer: [2.035212993621826, 6.1942548751831055, 0.0]
alpha/beta optimization time: 0.5617740154266357
This batch time : update_bounds func: 0.6546	 prepare: 0.0552	 bound: 0.5622	 transfer: 0.0057	 finalize: 0.0307
Accumulated time: update_bounds func: 20.5990	 prepare: 0.9340	 bound: 18.8799	 transfer: 0.0057	 finalize: 0.6191
batch bounding time:  0.6551969051361084
Current worst splitting domains [lb, ub] (depth):
[-0.00012,   inf] (78), [-0.00012,   inf] (78), [-0.00012,   inf] (78), [-0.00012,   inf] (78), [-0.00012,   inf] (78), [-0.00012,   inf] (78), [-0.00012,   inf] (78), [-0.00012,   inf] (78), [-0.00010,   inf] (78), [-0.00010,   inf] (78), [-0.00010,   inf] (78), [-0.00010,   inf] (78), [-0.00010,   inf] (78), [-0.00010,   inf] (78), [-0.00010,   inf] (78), [-0.00010,   inf] (78), [-0.00010,   inf] (78), [-0.00010,   inf] (78), [-0.00010,   inf] (78), [-0.00010,   inf] (78), 
length of domains: 368
Total time: 0.9494	 pickout: 0.0338	 decision: 0.2021	 get_bound: 0.6559	 add_domain: 0.0576
Current lb:-0.00011777877807617188
6810 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 27.219223260879517

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([368, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([368, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 702] [0, 702] [0, 702] [0, 702] [0, 702] [0, 702] [0, 702] [0, 702] [0, 702] [0, 702] 
regular batch size: 2*368, diving batch size 1*0
best_l after optimization: -0.0411764532327652 with beta sum per layer: [18.704519271850586, 10.158238410949707, 0.0]
alpha/beta optimization time: 0.8400380611419678
This batch time : update_bounds func: 1.0315	 prepare: 0.1089	 bound: 0.8404	 transfer: 0.0190	 finalize: 0.0614
Accumulated time: update_bounds func: 21.6306	 prepare: 1.0428	 bound: 19.7203	 transfer: 0.0190	 finalize: 0.6805
batch bounding time:  1.032512903213501
Current worst splitting domains [lb, ub] (depth):
[-0.00012,   inf] (80), [-0.00012,   inf] (80), [-0.00012,   inf] (80), [-0.00012,   inf] (80), [-0.00012,   inf] (80), [-0.00012,   inf] (80), [-0.00012,   inf] (80), [-0.00012,   inf] (80), [-0.00010,   inf] (80), [-0.00010,   inf] (80), [-0.00010,   inf] (80), [-0.00010,   inf] (80), [-0.00010,   inf] (80), [-0.00010,   inf] (80), [-0.00010,   inf] (80), [-0.00010,   inf] (80), [-0.00010,   inf] (80), [-0.00010,   inf] (80), [-0.00010,   inf] (80), [-0.00010,   inf] (80), 
length of domains: 368
Total time: 1.4741	 pickout: 0.0672	 decision: 0.3155	 get_bound: 1.0339	 add_domain: 0.0575
Current lb:-0.00011777877807617188
7546 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 28.703686475753784

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([368, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([368, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 566] [0, 566] [0, 566] [0, 566] [0, 566] [0, 566] [0, 566] [0, 566] [0, 566] [0, 566] 
regular batch size: 2*368, diving batch size 1*0
best_l after optimization: 0.009633161127567291 with beta sum per layer: [14.80555248260498, 11.509784698486328, 0.0]
alpha/beta optimization time: 0.8411905765533447
This batch time : update_bounds func: 1.0303	 prepare: 0.1084	 bound: 0.8416	 transfer: 0.0173	 finalize: 0.0611
Accumulated time: update_bounds func: 22.6608	 prepare: 1.1512	 bound: 20.5619	 transfer: 0.0173	 finalize: 0.7416
batch bounding time:  1.0312235355377197
Current worst splitting domains [lb, ub] (depth):
[-0.00012,   inf] (82), [-0.00012,   inf] (82), [-0.00012,   inf] (82), [-0.00012,   inf] (82), [-0.00012,   inf] (82), [-0.00012,   inf] (82), [-0.00012,   inf] (82), [-0.00012,   inf] (82), [-0.00010,   inf] (82), [-0.00010,   inf] (82), [-0.00010,   inf] (82), [-0.00010,   inf] (82), [-0.00010,   inf] (82), [-0.00010,   inf] (82), [-0.00010,   inf] (82), [-0.00010,   inf] (82), [-0.00010,   inf] (82), [-0.00010,   inf] (82), [-0.00010,   inf] (82), [-0.00010,   inf] (82), 
length of domains: 443
Total time: 1.4829	 pickout: 0.0676	 decision: 0.3107	 get_bound: 1.0327	 add_domain: 0.0719
Current lb:-0.00011777877807617188
8282 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 30.19667625427246

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([443, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([443, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 116] [1, 116] [1, 116] [1, 116] [1, 116] [1, 116] [1, 116] [1, 116] [1, 116] [1, 116] 
regular batch size: 2*443, diving batch size 1*0
best_l after optimization: -0.6216928958892822 with beta sum per layer: [40.806968688964844, 41.92280960083008, 0.0]
alpha/beta optimization time: 0.9230926036834717
This batch time : update_bounds func: 1.1481	 prepare: 0.1307	 bound: 0.9235	 transfer: 0.0195	 finalize: 0.0723
Accumulated time: update_bounds func: 23.8090	 prepare: 1.2819	 bound: 21.4854	 transfer: 0.0195	 finalize: 0.8139
batch bounding time:  1.149416208267212
Current worst splitting domains [lb, ub] (depth):
[-0.00012,   inf] (84), [-0.00012,   inf] (84), [-0.00012,   inf] (84), [-0.00012,   inf] (84), [-0.00012,   inf] (84), [-0.00012,   inf] (84), [-0.00012,   inf] (84), [-0.00012,   inf] (84), [-0.00010,   inf] (84), [-0.00010,   inf] (84), [-0.00010,   inf] (84), [-0.00010,   inf] (84), [-0.00010,   inf] (84), [-0.00010,   inf] (84), [-0.00010,   inf] (84), [-0.00010,   inf] (84), [-0.00010,   inf] (84), [-0.00010,   inf] (84), [-0.00010,   inf] (84), [-0.00010,   inf] (84), 
length of domains: 440
Total time: 1.7091	 pickout: 0.0817	 decision: 0.4013	 get_bound: 1.1512	 add_domain: 0.0750
Current lb:-0.00011777877807617188
9168 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 31.91896390914917

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([440, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([440, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 661] [0, 661] [0, 661] [0, 661] [0, 661] [0, 661] [0, 661] [0, 661] [0, 661] [0, 661] 
regular batch size: 2*440, diving batch size 1*0
best_l after optimization: 0.032211191952228546 with beta sum per layer: [8.780961990356445, 13.08654499053955, 0.0]
alpha/beta optimization time: 0.8420774936676025
This batch time : update_bounds func: 1.1451	 prepare: 0.1318	 bound: 0.8425	 transfer: 0.0274	 finalize: 0.1411
Accumulated time: update_bounds func: 24.9541	 prepare: 1.4137	 bound: 22.3279	 transfer: 0.0274	 finalize: 0.9550
batch bounding time:  1.1462490558624268
Current worst splitting domains [lb, ub] (depth):
[-0.00012,   inf] (86), [-0.00012,   inf] (86), [-0.00012,   inf] (86), [-0.00012,   inf] (86), [-0.00012,   inf] (86), [-0.00012,   inf] (86), [-0.00012,   inf] (86), [-0.00012,   inf] (86), [-0.00012,   inf] (86), [-0.00012,   inf] (86), [-0.00012,   inf] (86), [-0.00012,   inf] (86), [-0.00012,   inf] (86), [-0.00012,   inf] (86), [-0.00012,   inf] (86), [-0.00012,   inf] (86), [-0.00010,   inf] (86), [-0.00010,   inf] (86), [-0.00010,   inf] (86), [-0.00010,   inf] (86), 
length of domains: 880
Total time: 1.7361	 pickout: 0.0808	 decision: 0.3595	 get_bound: 1.1481	 add_domain: 0.1478
Current lb:-0.00011777877807617188
10048 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 33.6649374961853

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([880, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([880, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 256] [1, 256] [1, 256] [0, 105] [1, 256] [1, 256] [0, 105] [1, 256] [1, 256] [1, 256] 
regular batch size: 2*880, diving batch size 1*0
best_l after optimization: -0.1061965748667717 with beta sum per layer: [45.408355712890625, 23.83173370361328, 0.0]
alpha/beta optimization time: 1.3939166069030762
This batch time : update_bounds func: 1.9248	 prepare: 0.2618	 bound: 1.3943	 transfer: 0.0608	 finalize: 0.2038
Accumulated time: update_bounds func: 26.8789	 prepare: 1.6755	 bound: 23.7222	 transfer: 0.0608	 finalize: 1.1588
batch bounding time:  1.926858901977539
Current worst splitting domains [lb, ub] (depth):
[-0.00012,   inf] (88), [-0.00012,   inf] (88), [-0.00012,   inf] (88), [-0.00012,   inf] (88), [-0.00012,   inf] (88), [-0.00010,   inf] (88), [-0.00010,   inf] (88), [-0.00010,   inf] (88), [-0.00010,   inf] (88), [-0.00010,   inf] (88), [-0.00010,   inf] (88), [-0.00010,   inf] (88), [-0.00010,   inf] (88), [-0.00010,   inf] (88), [-0.00010,   inf] (88), [-0.00010,   inf] (88), [-0.00010,   inf] (88), [-0.00010,   inf] (88), [-0.00010,   inf] (88), [-0.00010,   inf] (88), 
length of domains: 646
Total time: 2.9994	 pickout: 0.1626	 decision: 0.7904	 get_bound: 1.9302	 add_domain: 0.1161
Current lb:-0.00011777877807617188
11808 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 36.69145750999451

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([646, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([646, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 745] [0, 745] [0, 745] [1, 256] [1, 256] [1, 256] [1, 256] [1, 256] [0, 745] [0, 745] 
regular batch size: 2*646, diving batch size 1*0
best_l after optimization: -0.05099846422672272 with beta sum per layer: [22.532894134521484, 22.8162899017334, 0.0]
alpha/beta optimization time: 1.1490964889526367
This batch time : update_bounds func: 1.4839	 prepare: 0.1936	 bound: 1.1495	 transfer: 0.0268	 finalize: 0.1110
Accumulated time: update_bounds func: 28.3628	 prepare: 1.8691	 bound: 24.8718	 transfer: 0.0268	 finalize: 1.2698
batch bounding time:  1.48561429977417
Current worst splitting domains [lb, ub] (depth):
[-0.00011,   inf] (90), [-0.00011,   inf] (90), [-0.00011,   inf] (90), [-0.00009,   inf] (90), [-0.00009,   inf] (90), [-0.00009,   inf] (90), [-0.00009,   inf] (90), [-0.00009,   inf] (90), [-0.00009,   inf] (90), [-0.00009,   inf] (90), [-0.00009,   inf] (90), [-0.00009,   inf] (90), [-0.00009,   inf] (90), [-0.00009,   inf] (90), [-0.00009,   inf] (90), [-0.00009,   inf] (90), [-0.00009,   inf] (90), [-0.00009,   inf] (90), [-0.00009,   inf] (90), [-0.00009,   inf] (90), 
length of domains: 503
Total time: 2.3199	 pickout: 0.1208	 decision: 0.6207	 get_bound: 1.4883	 add_domain: 0.0901
Current lb:-0.00010752677917480469
13100 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 39.03302502632141

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([503, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([503, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 1189] [0, 1189] [0, 1189] [1, 256] [0, 1189] [0, 1189] [0, 1189] [1, 256] [1, 256] [1, 256] 
regular batch size: 2*503, diving batch size 1*0
best_l after optimization: -0.03735722601413727 with beta sum per layer: [15.254903793334961, 21.705078125, 0.0]
alpha/beta optimization time: 1.0120182037353516
This batch time : update_bounds func: 1.2692	 prepare: 0.1525	 bound: 1.0125	 transfer: 0.0134	 finalize: 0.0886
Accumulated time: update_bounds func: 29.6320	 prepare: 2.0215	 bound: 25.8843	 transfer: 0.0134	 finalize: 1.3584
batch bounding time:  1.2707252502441406
Current worst splitting domains [lb, ub] (depth):
[-0.00010,   inf] (92), [-0.00010,   inf] (92), [-0.00010,   inf] (92), [-0.00009,   inf] (92), [-0.00009,   inf] (92), [-0.00009,   inf] (92), [-0.00009,   inf] (92), [-0.00009,   inf] (92), [-0.00009,   inf] (92), [-0.00009,   inf] (92), [-0.00009,   inf] (92), [-0.00009,   inf] (92), [-0.00009,   inf] (92), [-0.00009,   inf] (92), [-0.00009,   inf] (92), [-0.00009,   inf] (92), [-0.00008,   inf] (92), [-0.00008,   inf] (92), [-0.00008,   inf] (92), [-0.00008,   inf] (92), 
length of domains: 408
Total time: 1.9709	 pickout: 0.0961	 decision: 0.5282	 get_bound: 1.2729	 add_domain: 0.0738
Current lb:-0.00010466575622558594
14106 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 41.02095341682434

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([408, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([408, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 256] [1, 256] [1, 256] [1, 256] [1, 256] [1, 256] [0, 745] [0, 105] [1, 470] [0, 105] 
regular batch size: 2*408, diving batch size 1*0
best_l after optimization: -0.035616256296634674 with beta sum per layer: [11.541669845581055, 17.214454650878906, 0.0]
alpha/beta optimization time: 0.8327651023864746
This batch time : update_bounds func: 1.0166	 prepare: 0.1237	 bound: 0.8332	 transfer: 0.0106	 finalize: 0.0471
Accumulated time: update_bounds func: 30.6486	 prepare: 2.1452	 bound: 26.7174	 transfer: 0.0106	 finalize: 1.4056
batch bounding time:  1.0176284313201904
Current worst splitting domains [lb, ub] (depth):
[-0.00009,   inf] (94), [-0.00009,   inf] (94), [-0.00009,   inf] (94), [-0.00009,   inf] (94), [-0.00009,   inf] (94), [-0.00008,   inf] (94), [-0.00008,   inf] (94)/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:25: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1627336316785/work/torch/csrc/utils/tensor_numpy.cpp:143.)
  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))
, [-0.00008,   inf] (94), [-0.00007,   inf] (94), [-0.00007,   inf] (94), [-0.00007,   inf] (94), [-0.00007,   inf] (94), [-0.00007,   inf] (94), [-0.00007,   inf] (94), [-0.00007,   inf] (94), [-0.00007,   inf] (94), [-0.00007,   inf] (94), [-0.00007,   inf] (94), [-0.00007,   inf] (94), [-0.00007,   inf] (94), 
length of domains: 321
Total time: 1.5667	 pickout: 0.0786	 decision: 0.4136	 get_bound: 1.0191	 add_domain: 0.0555
Current lb:-8.606910705566406e-05
14922 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 42.60301208496094

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([321, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([321, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 745] [0, 745] [0, 745] [0, 745] [0, 745] [1, 470] [0, 1189] [0, 1189] [0, 1189] [0, 1189] 
regular batch size: 2*321, diving batch size 1*0
best_l after optimization: -0.017677951604127884 with beta sum per layer: [6.732580184936523, 15.211370468139648, 0.0]
alpha/beta optimization time: 0.7349197864532471
This batch time : update_bounds func: 0.8928	 prepare: 0.0628	 bound: 0.7352	 transfer: 0.0085	 finalize: 0.0846
Accumulated time: update_bounds func: 31.5414	 prepare: 2.2081	 bound: 27.4527	 transfer: 0.0085	 finalize: 1.4902
batch bounding time:  0.8936972618103027
Current worst splitting domains [lb, ub] (depth):
[-0.00008,   inf] (96), [-0.00008,   inf] (96), [-0.00008,   inf] (96), [-0.00008,   inf] (96), [-0.00008,   inf] (96), [-0.00008,   inf] (96), [-0.00007,   inf] (96), [-0.00007,   inf] (96), [-0.00007,   inf] (96), [-0.00007,   inf] (96), [-0.00007,   inf] (96), [-0.00007,   inf] (96), [-0.00007,   inf] (96), [-0.00007,   inf] (96), [-0.00007,   inf] (96), [-0.00007,   inf] (96), [-0.00006,   inf] (96), [-0.00006,   inf] (96), [-0.00006,   inf] (96), [-0.00006,   inf] (96), 
length of domains: 275
Total time: 1.2731	 pickout: 0.0437	 decision: 0.2871	 get_bound: 0.8948	 add_domain: 0.0474
Current lb:-7.581710815429688e-05
15564 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 43.88624811172485

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([275, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([275, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 1189] [0, 1189] [0, 1189] [0, 1189] [0, 1189] [0, 1189] [1, 470] [1, 470] [1, 470] [1, 470] 
regular batch size: 2*275, diving batch size 1*0
best_l after optimization: -0.019414467737078667 with beta sum per layer: [5.166016578674316, 14.769795417785645, 0.0]
alpha/beta optimization time: 0.6914234161376953
This batch time : update_bounds func: 0.7846	 prepare: 0.0535	 bound: 0.6917	 transfer: 0.0076	 finalize: 0.0304
Accumulated time: update_bounds func: 32.3260	 prepare: 2.2616	 bound: 28.1444	 transfer: 0.0076	 finalize: 1.5206
batch bounding time:  0.7853610515594482
Current worst splitting domains [lb, ub] (depth):
[-0.00007,   inf] (98), [-0.00007,   inf] (98), [-0.00007,   inf] (98), [-0.00007,   inf] (98), [-0.00007,   inf] (98), [-0.00007,   inf] (98), [-0.00007,   inf] (98), [-0.00007,   inf] (98), [-0.00007,   inf] (98), [-0.00007,   inf] (98), [-0.00007,   inf] (98), [-0.00007,   inf] (98), [-0.00007,   inf] (98), [-0.00007,   inf] (98), [-0.00007,   inf] (98), [-0.00007,   inf] (98), [-0.00006,   inf] (98), [-0.00006,   inf] (98), [-0.00006,   inf] (98), [-0.00006,   inf] (98), 
length of domains: 268
Total time: 1.1338	 pickout: 0.0373	 decision: 0.2139	 get_bound: 0.7863	 add_domain: 0.0963
Current lb:-7.271766662597656e-05
16114 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 45.028544425964355

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([268, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([268, 8, 16, 16]) post split depth:  0
all nodes are split!!
Global ub: inf, batch ub: inf
Image 0 against label 4 verification end, Time cost: 45.31989240646362
Result: unknown in 58.4056 seconds


[[    0.             3.90962648     0.             0.00035834
      0.        ]
 [    0.             3.04958868     0.             0.00038338
      1.        ]
 [    0.             0.08504581     0.             0.00038767
      2.        ]
 [    0.             0.02706684     0.             0.00036287
      3.        ]
 [    0.            -0.00007272 16114.            45.31989241
      4.        ]]
############# Summary #############
Final verified acc: 0.0% [total 1 examples]
Total verification count: 1 , total verified safe: 0 , verified unsafe: 0 , timeout: 1
mean time [total:1]: 45.32138466835022
mean time [cnt:1]: 45.32138466835022
max time 58.405625104904175
unknown (total 1): [0]
