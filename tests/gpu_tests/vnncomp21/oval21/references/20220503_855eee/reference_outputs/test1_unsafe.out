Building native CUDA modules...
/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
  csv_name: oval21_instances.csv
  onnx_path: null
  vnnlib_path: null
  results_file: null
  root_path: ../../../../../vnncomp2021/benchmarks/oval21
model:
  path: null
  name: mnist_9_200
data:
  start: 3
  end: 4
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR
  data_filter_path: null
specification:
  type: lp
  norm: .inf
  epsilon: null
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 2000
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.01
    lr_decay: 0.98
    optimizer: adam
    iteration: 50
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 360
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 10
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 20:59:38 2022 on ubuntu
saving results to vnn-comp_[oval21_instances]_start=3_end=4_iter=50_b=2000_timeout=360_branching=kfsb-max-10_lra-init=0.1_lra=0.01_lrb=0.01_PGD=skip.npz
customized start/end sample from 3 to 4

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Model prediction is: tensor([[-0.5306,  2.9060, -1.1293, -0.7552, -0.8061, -0.7158, -1.5924,  0.0188,
         -0.3641,  2.9689]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 3.4105, -0.0126,  3.9755,  3.5976,  3.6533,  3.5618,  4.4220,  2.8357,
          3.2323]], device='cuda:0') None
best_l after optimization: -28.677427291870117 with beta sum per layer: []
alpha/beta optimization time: 8.042440176010132
initial alpha-CROWN bounds: tensor([[ 3.4106, -0.0115,  3.9755,  3.5976,  3.6533,  3.5618,  4.4220,  2.8357,
          3.2324]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.0115, device='cuda:0', grad_fn=<MinBackward1>)
##### [0] True label: 9, Tested against: 0, onnx_path: nets/cifar_base_kw.onnx, vnnlib_path: vnnlib/cifar_base_kw-img1697-eps0.0014379084967320263.vnnlib ######
init opt crown verified for label 0 with bound 3.410606861114502
Image 0 against label 0 verification end, Time cost: 0.00032210350036621094
##### [0] True label: 9, Tested against: 1, onnx_path: nets/cifar_base_kw.onnx, vnnlib_path: vnnlib/cifar_base_kw-img1697-eps0.0014379084967320263.vnnlib ######
Model prediction is: tensor([[-0.5306,  2.9060, -1.1293, -0.7552, -0.8061, -0.7158, -1.5924,  0.0188,
         -0.3641,  2.9689]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 8, 16, 16]) != torch.Size([2, 9, 1, 8, 16, 16]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 16, 8, 8]) != torch.Size([2, 9, 1, 16, 8, 8]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 8, 16, 16])
1 /11 torch.Size([1, 16, 8, 8])
2 /14 torch.Size([1, 100])
best_l after optimization: 0.011521011590957642 with beta sum per layer: []
alpha/beta optimization time: 1.3540246486663818
alpha-CROWN with fixed intermediate bounds: tensor([[-0.0115]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.011521011590957642
layer 0 size torch.Size([2048]) unstable 25
layer 1 size torch.Size([1024]) unstable 17
layer 2 size torch.Size([100]) unstable 1
-----------------
# of unstable neurons: 43
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 8, 16, 16]) pre split depth:  7
batch:  torch.Size([1, 8, 16, 16]) post split depth:  7
splitting decisions: 
split level 0: [1, 308] 
split level 1: [1, 354] 
split level 2: [1, 906] 
split level 3: [0, 997] 
split level 4: [1, 174] 
split level 5: [0, 420] 
split level 6: [0, 86] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.9833635687828064 with beta sum per layer: [12.359588623046875, 33.891761779785156, 0.0]
alpha/beta optimization time: 0.624943733215332
This batch time : update_bounds func: 0.6451	 prepare: 0.0096	 bound: 0.6256	 transfer: 0.0026	 finalize: 0.0069
Accumulated time: update_bounds func: 0.6451	 prepare: 0.0096	 bound: 0.6256	 transfer: 0.0026	 finalize: 0.0069
batch bounding time:  0.6454219818115234
Current worst splitting domains [lb, ub] (depth):
[-0.01050,   inf] (8), [-0.01009,   inf] (8), [-0.01008,   inf] (8), [-0.00996,   inf] (8), [-0.00979,   inf] (8), [-0.00967,   inf] (8), [-0.00962,   inf] (8), [-0.00955,   inf] (8), [-0.00954,   inf] (8), [-0.00953,   inf] (8), [-0.00938,   inf] (8), [-0.00925,   inf] (8), [-0.00922,   inf] (8), [-0.00920,   inf] (8), [-0.00919,   inf] (8), [-0.00913,   inf] (8), [-0.00912,   inf] (8), [-0.00908,   inf] (8), [-0.00904,   inf] (8), [-0.00899,   inf] (8), 
length of domains: 128
Total time: 0.7193	 pickout: 0.0008	 decision: 0.0523	 get_bound: 0.6600	 add_domain: 0.0062
Current lb:-0.010503917932510376
128 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.5467605590820312

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([128, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([128, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 178] [1, 178] [1, 178] [0, 998] [1, 178] [1, 178] [1, 178] [0, 998] [0, 998] [1, 178] 
regular batch size: 2*128, diving batch size 1*0
best_l after optimization: 1.9247804880142212 with beta sum per layer: [26.095399856567383, 70.75707244873047, 0.0]
alpha/beta optimization time: 0.6322216987609863
This batch time : update_bounds func: 0.6825	 prepare: 0.0240	 bound: 0.6326	 transfer: 0.0114	 finalize: 0.0139
Accumulated time: update_bounds func: 1.3276	 prepare: 0.0336	 bound: 1.2582	 transfer: 0.0114	 finalize: 0.0208
batch bounding time:  0.6829617023468018
Current worst splitting domains [lb, ub] (depth):
[-0.01044,   inf] (10), [-0.01022,   inf] (10), [-0.01003,   inf] (10), [-0.01002,   inf] (10), [-0.00988,   inf] (10), [-0.00981,   inf] (10), [-0.00981,   inf] (10), [-0.00978,   inf] (10), [-0.00973,   inf] (10), [-0.00961,   inf] (10), [-0.00955,   inf] (10), [-0.00947,   inf] (10), [-0.00947,   inf] (10), [-0.00946,   inf] (10), [-0.00944,   inf] (10), [-0.00940,   inf] (10), [-0.00939,   inf] (10), [-0.00937,   inf] (10), [-0.00933,   inf] (10), [-0.00931,   inf] (10), 
length of domains: 256
Total time: 0.8213	 pickout: 0.0171	 decision: 0.1094	 get_bound: 0.6834	 add_domain: 0.0114
Current lb:-0.010437846183776855
384 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.3703808784484863

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 998] [0, 998] [0, 998] [0, 998] [1, 178] [1, 178] [0, 998] [0, 998] [0, 998] [0, 998] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 3.783010721206665 with beta sum per layer: [52.705204010009766, 150.71617126464844, 0.0]
alpha/beta optimization time: 0.7140872478485107
This batch time : update_bounds func: 0.8084	 prepare: 0.0454	 bound: 0.7144	 transfer: 0.0208	 finalize: 0.0266
Accumulated time: update_bounds func: 2.1359	 prepare: 0.0789	 bound: 1.9726	 transfer: 0.0208	 finalize: 0.0474
batch bounding time:  0.8091127872467041
Current worst splitting domains [lb, ub] (depth):
[-0.01037,   inf] (12), [-0.01035,   inf] (12), [-0.01015,   inf] (12), [-0.01014,   inf] (12), [-0.00996,   inf] (12), [-0.00995,   inf] (12), [-0.00994,   inf] (12), [-0.00993,   inf] (12), [-0.00981,   inf] (12), [-0.00975,   inf] (12), [-0.00974,   inf] (12), [-0.00972,   inf] (12), [-0.00972,   inf] (12), [-0.00970,   inf] (12), [-0.00966,   inf] (12), [-0.00964,   inf] (12), [-0.00962,   inf] (12), [-0.00954,   inf] (12), [-0.00954,   inf] (12), [-0.00952,   inf] (12), 
length of domains: 512
Total time: 1.0922	 pickout: 0.0330	 decision: 0.2230	 get_bound: 0.8100	 add_domain: 0.0261
Current lb:-0.010368555784225464
896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.466845750808716

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([512, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 122] [0, 122] [0, 122] [0, 122] [0, 122] [0, 122] [0, 122] [0, 122] [0, 122] [0, 122] 
regular batch size: 2*512, diving batch size 1*0
best_l after optimization: 7.486100673675537 with beta sum per layer: [105.24447631835938, 301.6418151855469, 0.0]
alpha/beta optimization time: 0.9383077621459961
This batch time : update_bounds func: 1.1691	 prepare: 0.0889	 bound: 0.9387	 transfer: 0.0374	 finalize: 0.1016
Accumulated time: update_bounds func: 3.3050	 prepare: 0.1678	 bound: 2.9113	 transfer: 0.0374	 finalize: 0.1490
batch bounding time:  1.1703839302062988
Current worst splitting domains [lb, ub] (depth):
[-0.01030,   inf] (14), [-0.01029,   inf] (14), [-0.01028,   inf] (14), [-0.01027,   inf] (14), [-0.01008,   inf] (14), [-0.01007,   inf] (14), [-0.01006,   inf] (14), [-0.01005,   inf] (14), [-0.00988,   inf] (14), [-0.00988,   inf] (14), [-0.00987,   inf] (14), [-0.00987,   inf] (14), [-0.00986,   inf] (14), [-0.00986,   inf] (14), [-0.00985,   inf] (14), [-0.00985,   inf] (14), [-0.00974,   inf] (14), [-0.00973,   inf] (14), [-0.00968,   inf] (14), [-0.00967,   inf] (14), 
length of domains: 1024
Total time: 1.6247	 pickout: 0.0657	 decision: 0.3322	 get_bound: 1.1723	 add_domain: 0.0544
Current lb:-0.010296016931533813
1920 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.099797964096069

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 938] [1, 938] [1, 938] [1, 938] [1, 938] [1, 938] [1, 938] [1, 938] [1, 938] [1, 938] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 13.77858829498291 with beta sum per layer: [200.2852783203125, 836.2205810546875, 0.0]
alpha/beta optimization time: 1.5680997371673584
This batch time : update_bounds func: 1.9318	 prepare: 0.1765	 bound: 1.5685	 transfer: 0.0740	 finalize: 0.1079
Accumulated time: update_bounds func: 5.2368	 prepare: 0.3444	 bound: 4.4797	 transfer: 0.0740	 finalize: 0.2569
batch bounding time:  1.93400239944458
Current worst splitting domains [lb, ub] (depth):
[-0.01030,   inf] (16), [-0.01029,   inf] (16), [-0.01028,   inf] (16), [-0.01027,   inf] (16), [-0.01008,   inf] (16), [-0.01007,   inf] (16), [-0.01006,   inf] (16), [-0.01005,   inf] (16), [-0.00988,   inf] (16), [-0.00988,   inf] (16), [-0.00987,   inf] (16), [-0.00987,   inf] (16), [-0.00986,   inf] (16), [-0.00986,   inf] (16), [-0.00985,   inf] (16), [-0.00985,   inf] (16), [-0.00974,   inf] (16), [-0.00973,   inf] (16), [-0.00968,   inf] (16), [-0.00967,   inf] (16), 
length of domains: 2048
Total time: 2.9509	 pickout: 0.1298	 decision: 0.7028	 get_bound: 1.9377	 add_domain: 0.1806
Current lb:-0.010296016931533813
3968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.067322969436646

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 922] [1, 922] [1, 922] [1, 922] [1, 922] [1, 922] [1, 922] [1, 922] [1, 922] [1, 922] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 26.750694274902344 with beta sum per layer: [369.6407470703125, 1970.227294921875, 0.0]
alpha/beta optimization time: 2.783778190612793
This batch time : update_bounds func: 3.7268	 prepare: 0.3624	 bound: 2.7843	 transfer: 0.1653	 finalize: 0.3424
Accumulated time: update_bounds func: 8.9636	 prepare: 0.7068	 bound: 7.2640	 transfer: 0.1653	 finalize: 0.5993
batch bounding time:  3.7312207221984863
Current worst splitting domains [lb, ub] (depth):
[-0.01030,   inf] (18), [-0.01029,   inf] (18), [-0.01028,   inf] (18), [-0.01027,   inf] (18), [-0.01008,   inf] (18), [-0.01007,   inf] (18), [-0.01006,   inf] (18), [-0.01005,   inf] (18), [-0.01005,   inf] (18), [-0.01004,   inf] (18), [-0.01003,   inf] (18), [-0.01002,   inf] (18), [-0.00988,   inf] (18), [-0.00988,   inf] (18), [-0.00987,   inf] (18), [-0.00987,   inf] (18), [-0.00986,   inf] (18), [-0.00986,   inf] (18), [-0.00985,   inf] (18), [-0.00985,   inf] (18), 
length of domains: 4048
Total time: 5.6166	 pickout: 0.2619	 decision: 1.3702	 get_bound: 3.7391	 add_domain: 0.2454
Current lb:-0.010296016931533813
7968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.720174312591553

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 1402] [0, 1402] [0, 1402] [0, 1402] [0, 1492] [0, 1492] [0, 1402] [0, 1402] [0, 1635] [0, 1635] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 30.626876831054688 with beta sum per layer: [343.92291259765625, 1461.562744140625, 0.0]
alpha/beta optimization time: 2.748290777206421
This batch time : update_bounds func: 3.6052	 prepare: 0.3475	 bound: 2.7487	 transfer: 0.1485	 finalize: 0.3509
Accumulated time: update_bounds func: 12.5689	 prepare: 1.0542	 bound: 10.0127	 transfer: 0.1485	 finalize: 0.9502
batch bounding time:  3.6094040870666504
Current worst splitting domains [lb, ub] (depth):
[-0.01030,   inf] (20), [-0.01029,   inf] (20), [-0.01028,   inf] (20), [-0.01027,   inf] (20), [-0.01019,   inf] (20), [-0.01019,   inf] (20), [-0.01017,   inf] (20), [-0.01017,   inf] (20), [-0.01006,   inf] (20), [-0.01005,   inf] (20), [-0.01002,   inf] (20), [-0.01001,   inf] (20), [-0.01000,   inf] (20), [-0.00999,   inf] (20), [-0.00998,   inf] (20), [-0.00997,   inf] (20), [-0.00996,   inf] (20), [-0.00996,   inf] (20), [-0.00995,   inf] (20), [-0.00995,   inf] (20), 
length of domains: 6048
Total time: 5.8505	 pickout: 0.2760	 decision: 1.5540	 get_bound: 3.6171	 add_domain: 0.4033
Current lb:-0.010296016931533813
11968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 20.603839874267578

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 1635] [0, 1635] [0, 1635] [0, 1635] [0, 1635] [0, 1635] [0, 1635] [0, 1635] [0, 1492] [0, 1492] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 32.88672637939453 with beta sum per layer: [350.1068115234375, 1119.928466796875, 0.0]
alpha/beta optimization time: 2.7534477710723877
This batch time : update_bounds func: 3.6309	 prepare: 0.3467	 bound: 2.7539	 transfer: 0.1532	 finalize: 0.3674
Accumulated time: update_bounds func: 16.1997	 prepare: 1.4009	 bound: 12.7666	 transfer: 0.1532	 finalize: 1.3176
batch bounding time:  3.6357078552246094
Current worst splitting domains [lb, ub] (depth):
[-0.01028,   inf] (22), [-0.01027,   inf] (22), [-0.01026,   inf] (22), [-0.01025,   inf] (22), [-0.01021,   inf] (22), [-0.01019,   inf] (22), [-0.01019,   inf] (22), [-0.01018,   inf] (22), [-0.01018,   inf] (22), [-0.01017,   inf] (22), [-0.01015,   inf] (22), [-0.01015,   inf] (22), [-0.01010,   inf] (22), [-0.01010,   inf] (22), [-0.01008,   inf] (22), [-0.01008,   inf] (22), [-0.01002,   inf] (22), [-0.01001,   inf] (22), [-0.01001,   inf] (22), [-0.01000,   inf] (22), 
length of domains: 8048
Total time: 5.7426	 pickout: 0.2724	 decision: 1.5506	 get_bound: 3.6448	 add_domain: 0.2748
Current lb:-0.010279804468154907
15968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 26.3803973197937

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 1486] [0, 1486] [0, 1486] [0, 1486] [0, 1486] [0, 1486] [0, 1486] [0, 1486] [0, 1486] [0, 1486] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 34.57857894897461 with beta sum per layer: [333.98114013671875, 871.02392578125, 0.0]
alpha/beta optimization time: 2.753535270690918
This batch time : update_bounds func: 3.5075	 prepare: 0.3476	 bound: 2.7540	 transfer: 0.1642	 finalize: 0.2318
Accumulated time: update_bounds func: 19.7072	 prepare: 1.7485	 bound: 15.5205	 transfer: 0.1642	 finalize: 1.5494
batch bounding time:  3.5121920108795166
Current worst splitting domains [lb, ub] (depth):
[-0.01027,   inf] (24), [-0.01026,   inf] (24), [-0.01025,   inf] (24), [-0.01024,   inf] (24), [-0.01020,   inf] (24), [-0.01019,   inf] (24), [-0.01019,   inf] (24), [-0.01018,   inf] (24), [-0.01018,   inf] (24), [-0.01017,   inf] (24), [-0.01017,   inf] (24), [-0.01017,   inf] (24), [-0.01017,   inf] (24), [-0.01016,   inf] (24), [-0.01015,   inf] (24), [-0.01015,   inf] (24), [-0.01012,   inf] (24), [-0.01011,   inf] (24), [-0.01010,   inf] (24), [-0.01010,   inf] (24), 
length of domains: 10048
Total time: 6.0425	 pickout: 0.2744	 decision: 1.7337	 get_bound: 3.5207	 add_domain: 0.5136
Current lb:-0.010273277759552002
19968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 32.45772099494934

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 1232] [0, 1232] [0, 1232] [0, 1232] [0, 1232] [0, 1232] [0, 1232] [0, 1232] [0, 1232] [0, 1232] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 35.780479431152344 with beta sum per layer: [337.527099609375, 641.6610107421875, 0.0]
alpha/beta optimization time: 2.76283597946167
This batch time : update_bounds func: 3.5120	 prepare: 0.3604	 bound: 2.7633	 transfer: 0.1572	 finalize: 0.2211
Accumulated time: update_bounds func: 23.2192	 prepare: 2.1089	 bound: 18.2838	 transfer: 0.1572	 finalize: 1.7705
batch bounding time:  3.5166239738464355
Current worst splitting domains [lb, ub] (depth):
[-0.01024,   inf] (26), [-0.01023,   inf] (26), [-0.01022,   inf] (26), [-0.01021,   inf] (26), [-0.01017,   inf] (26), [-0.01016,   inf] (26), [-0.01016,   inf] (26), [-0.01015,   inf] (26), [-0.01015,   inf] (26), [-0.01014,   inf] (26), [-0.01014,   inf] (26), [-0.01014,   inf] (26), [-0.01014,   inf] (26), [-0.01013,   inf] (26), [-0.01012,   inf] (26), [-0.01012,   inf] (26), [-0.01012,   inf] (26), [-0.01011,   inf] (26), [-0.01010,   inf] (26), [-0.01009,   inf] (26), 
length of domains: 12048
Total time: 5.9844	 pickout: 0.2781	 decision: 1.6483	 get_bound: 3.5249	 add_domain: 0.5331
Current lb:-0.010243237018585205
23968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 38.476123332977295

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1001] [1, 1001] [1, 1001] [1, 1001] [1, 1001] [1, 1001] [1, 1001] [1, 1001] [1, 1001] [1, 1001] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 35.819156646728516 with beta sum per layer: [274.28411865234375, 684.3385620117188, 0.0]
alpha/beta optimization time: 2.7792861461639404
This batch time : update_bounds func: 3.7745	 prepare: 0.3574	 bound: 2.7797	 transfer: 0.1563	 finalize: 0.2240
Accumulated time: update_bounds func: 26.9937	 prepare: 2.4663	 bound: 21.0635	 transfer: 0.1563	 finalize: 1.9945
batch bounding time:  3.779078722000122
Current worst splitting domains [lb, ub] (depth):
[-0.01024,   inf] (28), [-0.01023,   inf] (28), [-0.01022,   inf] (28), [-0.01021,   inf] (28), [-0.01017,   inf] (28), [-0.01016,   inf] (28), [-0.01016,   inf] (28), [-0.01015,   inf] (28), [-0.01015,   inf] (28), [-0.01014,   inf] (28), [-0.01014,   inf] (28), [-0.01014,   inf] (28), [-0.01014,   inf] (28), [-0.01013,   inf] (28), [-0.01012,   inf] (28), [-0.01012,   inf] (28), [-0.01012,   inf] (28), [-0.01011,   inf] (28), [-0.01010,   inf] (28), [-0.01009,   inf] (28), 
length of domains: 14048
Total time: 5.9373	 pickout: 0.2755	 decision: 1.5624	 get_bound: 3.7880	 add_domain: 0.3113
Current lb:-0.010243237018585205
27968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 44.45006465911865

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 109] [1, 109] [1, 109] [1, 109] [1, 109] [1, 109] [1, 109] [1, 109] [1, 109] [1, 109] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 36.44995880126953 with beta sum per layer: [224.71774291992188, 661.6080322265625, 0.0]
alpha/beta optimization time: 2.768235921859741
This batch time : update_bounds func: 3.5119	 prepare: 0.3553	 bound: 2.7686	 transfer: 0.1561	 finalize: 0.2214
Accumulated time: update_bounds func: 30.5056	 prepare: 2.8216	 bound: 23.8321	 transfer: 0.1561	 finalize: 2.2159
batch bounding time:  3.5165364742279053
Current worst splitting domains [lb, ub] (depth):
[-0.01024,   inf] (30), [-0.01024,   inf] (30), [-0.01023,   inf] (30), [-0.01023,   inf] (30), [-0.01022,   inf] (30), [-0.01022,   inf] (30), [-0.01021,   inf] (30), [-0.01021,   inf] (30), [-0.01017,   inf] (30), [-0.01017,   inf] (30), [-0.01016,   inf] (30), [-0.01016,   inf] (30), [-0.01016,   inf] (30), [-0.01016,   inf] (30), [-0.01015,   inf] (30), [-0.01015,   inf] (30), [-0.01015,   inf] (30), [-0.01015,   inf] (30), [-0.01014,   inf] (30), [-0.01014,   inf] (30), 
length of domains: 16048
Total time: 6.3654	 pickout: 0.2784	 decision: 1.8987	 get_bound: 3.5248	 add_domain: 0.6635
Current lb:-0.010243237018585205
31968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 50.85515332221985

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 813] [0, 813] [0, 813] [0, 813] [0, 813] [0, 813] [0, 813] [0, 813] [0, 813] [0, 813] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 37.5702018737793 with beta sum per layer: [246.6845703125, 419.595947265625, 0.0]
alpha/beta optimization time: 2.7596094608306885
This batch time : update_bounds func: 3.4921	 prepare: 0.3490	 bound: 2.7602	 transfer: 0.1510	 finalize: 0.2214
Accumulated time: update_bounds func: 33.9977	 prepare: 3.1707	 bound: 26.5924	 transfer: 0.1510	 finalize: 2.4373
batch bounding time:  3.4970059394836426
Current worst splitting domains [lb, ub] (depth):
[-0.01024,   inf] (32), [-0.01024,   inf] (32), [-0.01023,   inf] (32), [-0.01023,   inf] (32), [-0.01022,   inf] (32), [-0.01022,   inf] (32), [-0.01021,   inf] (32), [-0.01021,   inf] (32), [-0.01017,   inf] (32), [-0.01017,   inf] (32), [-0.01016,   inf] (32), [-0.01016,   inf] (32), [-0.01016,   inf] (32), [-0.01016,   inf] (32), [-0.01015,   inf] (32), [-0.01015,   inf] (32), [-0.01015,   inf] (32), [-0.01015,   inf] (32), [-0.01014,   inf] (32), [-0.01014,   inf] (32), 
length of domains: 18048
Total time: 6.2114	 pickout: 0.2818	 decision: 1.7270	 get_bound: 3.5061	 add_domain: 0.6965
Current lb:-0.010243237018585205
35968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 57.104565143585205

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 862] [1, 862] [1, 862] [1, 862] [1, 862] [1, 862] [1, 862] [1, 862] [1, 862] [1, 862] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 38.186004638671875 with beta sum per layer: [204.23660278320312, 413.8807373046875, 0.0]
alpha/beta optimization time: 2.750645637512207
This batch time : update_bounds func: 3.8509	 prepare: 0.3608	 bound: 2.7511	 transfer: 0.1506	 finalize: 0.2213
Accumulated time: update_bounds func: 37.8486	 prepare: 3.5315	 bound: 29.3434	 transfer: 0.1506	 finalize: 2.6586
batch bounding time:  3.8550877571105957
Current worst splitting domains [lb, ub] (depth):
[-0.01024,   inf] (34), [-0.01024,   inf] (34), [-0.01024,   inf] (34), [-0.01024,   inf] (34), [-0.01023,   inf] (34), [-0.01023,   inf] (34), [-0.01023,   inf] (34), [-0.01023,   inf] (34), [-0.01022,   inf] (34), [-0.01022,   inf] (34), [-0.01022,   inf] (34), [-0.01022,   inf] (34), [-0.01021,   inf] (34), [-0.01021,   inf] (34), [-0.01021,   inf] (34), [-0.01021,   inf] (34), [-0.01017,   inf] (34), [-0.01017,   inf] (34), [-0.01017,   inf] (34), [-0.01017,   inf] (34), 
length of domains: 20048
Total time: 5.9042	 pickout: 0.2833	 decision: 1.4207	 get_bound: 3.8626	 add_domain: 0.3376
Current lb:-0.010243237018585205
39968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 63.04910397529602

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 22] [0, 22] [0, 22] [0, 22] [0, 22] [0, 22] [0, 22] [0, 22] [0, 22] [0, 22] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 38.88573455810547 with beta sum per layer: [151.02999877929688, 309.75189208984375, 0.0]
alpha/beta optimization time: 2.665525197982788
This batch time : update_bounds func: 3.8448	 prepare: 0.3481	 bound: 2.6660	 transfer: 0.1531	 finalize: 0.6671
Accumulated time: update_bounds func: 41.6934	 prepare: 3.8795	 bound: 32.0094	 transfer: 0.1531	 finalize: 3.3257
batch bounding time:  3.84920597076416
Current worst splitting domains [lb, ub] (depth):
[-0.01024,   inf] (36), [-0.01024,   inf] (36), [-0.01024,   inf] (36), [-0.01024,   inf] (36), [-0.01024,   inf] (36), [-0.01024,   inf] (36), [-0.01024,   inf] (36), [-0.01024,   inf] (36), [-0.01023,   inf] (36), [-0.01023,   inf] (36), [-0.01023,   inf] (36), [-0.01023,   inf] (36), [-0.01023,   inf] (36), [-0.01023,   inf] (36), [-0.01023,   inf] (36), [-0.01023,   inf] (36), [-0.01022,   inf] (36), [-0.01022,   inf] (36), [-0.01022,   inf] (36), [-0.01022,   inf] (36), 
length of domains: 22048
Total time: 6.3156	 pickout: 0.2708	 decision: 1.8401	 get_bound: 3.8571	 add_domain: 0.3476
Current lb:-0.010243237018585205
43968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 69.40210676193237

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 81] [2, 81] [2, 81] [2, 81] [2, 81] [2, 81] [2, 81] [2, 81] [2, 81] [2, 81] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 33.39440155029297 with beta sum per layer: [139.65435791015625, 283.7876892089844, 410.98638916015625]
alpha/beta optimization time: 2.788933277130127
This batch time : update_bounds func: 3.9756	 prepare: 0.3581	 bound: 2.7893	 transfer: 0.1632	 finalize: 0.2341
Accumulated time: update_bounds func: 45.6690	 prepare: 4.2376	 bound: 34.7987	 transfer: 0.1632	 finalize: 3.5598
batch bounding time:  3.9798247814178467
Current worst splitting domains [lb, ub] (depth):
[-0.01024,   inf] (38), [-0.01024,   inf] (38), [-0.01024,   inf] (38), [-0.01024,   inf] (38), [-0.01024,   inf] (38), [-0.01024,   inf] (38), [-0.01024,   inf] (38), [-0.01024,   inf] (38), [-0.01023,   inf] (38), [-0.01023,   inf] (38), [-0.01023,   inf] (38), [-0.01023,   inf] (38), [-0.01023,   inf] (38), [-0.01023,   inf] (38), [-0.01023,   inf] (38), [-0.01023,   inf] (38), [-0.01022,   inf] (38), [-0.01022,   inf] (38), [-0.01022,   inf] (38), [-0.01022,   inf] (38), 
length of domains: 24048
Total time: 6.0670	 pickout: 0.2731	 decision: 1.4443	 get_bound: 3.9874	 add_domain: 0.3623
Current lb:-0.010243237018585205
47968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 75.51248836517334

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 1492] [0, 1492] [0, 1492] [0, 1492] [0, 1492] [0, 1492] [0, 1492] [0, 1492] [0, 1492] [0, 1492] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 36.61054229736328 with beta sum per layer: [140.85818481445312, 255.39109802246094, 189.89959716796875]
alpha/beta optimization time: 2.7567102909088135
This batch time : update_bounds func: 3.5112	 prepare: 0.3706	 bound: 2.7571	 transfer: 0.1548	 finalize: 0.2184
Accumulated time: update_bounds func: 49.1801	 prepare: 4.6082	 bound: 37.5558	 transfer: 0.1548	 finalize: 3.7782
batch bounding time:  3.5153262615203857
Current worst splitting domains [lb, ub] (depth):
[-0.01022,   inf] (40), [-0.01022,   inf] (40), [-0.01022,   inf] (40), [-0.01022,   inf] (40), [-0.01022,   inf] (40), [-0.01022,   inf] (40), [-0.01022,   inf] (40), [-0.01022,   inf] (40), [-0.01021,   inf] (40), [-0.01021,   inf] (40), [-0.01021,   inf] (40), [-0.01021,   inf] (40), [-0.01021,   inf] (40), [-0.01021,   inf] (40), [-0.01021,   inf] (40), [-0.01021,   inf] (40), [-0.01020,   inf] (40), [-0.01020,   inf] (40), [-0.01020,   inf] (40), [-0.01020,   inf] (40), 
length of domains: 26048
Total time: 6.1244	 pickout: 0.2842	 decision: 1.9435	 get_bound: 3.5229	 add_domain: 0.3737
Current lb:-0.010220646858215332
51968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 81.67985701560974

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 814] [0, 814] [0, 814] [0, 814] [0, 814] [0, 814] [0, 814] [0, 814] [0, 814] [0, 814] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 39.601112365722656 with beta sum per layer: [179.20782470703125, 185.7330780029297, 0.0]
alpha/beta optimization time: 2.7828707695007324
This batch time : update_bounds func: 3.5462	 prepare: 0.3831	 bound: 2.7833	 transfer: 0.1509	 finalize: 0.2186
Accumulated time: update_bounds func: 52.7263	 prepare: 4.9914	 bound: 40.3391	 transfer: 0.1509	 finalize: 3.9967
batch bounding time:  3.5509235858917236
Current worst splitting domains [lb, ub] (depth):
[-0.01022,   inf] (42), [-0.01022,   inf] (42), [-0.01022,   inf] (42), [-0.01022,   inf] (42), [-0.01022,   inf] (42), [-0.01022,   inf] (42), [-0.01022,   inf] (42), [-0.01022,   inf] (42), [-0.01021,   inf] (42), [-0.01021,   inf] (42), [-0.01021,   inf] (42), [-0.01021,   inf] (42), [-0.01021,   inf] (42), [-0.01021,   inf] (42), [-0.01021,   inf] (42), [-0.01021,   inf] (42), [-0.01020,   inf] (42), [-0.01020,   inf] (42), [-0.01020,   inf] (42), [-0.01020,   inf] (42), 
length of domains: 28048
Total time: 6.2760	 pickout: 0.2934	 decision: 2.0142	 get_bound: 3.5598	 add_domain: 0.4085
Current lb:-0.010220646858215332
55968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 87.99718570709229

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 1520] [0, 1520] [0, 1520] [0, 1520] [0, 1520] [0, 1520] [0, 1520] [0, 1520] [0, 1520] [0, 1520] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 39.87162399291992 with beta sum per layer: [166.48460388183594, 61.519813537597656, 0.0]
alpha/beta optimization time: 2.7258388996124268
This batch time : update_bounds func: 3.4922	 prepare: 0.3842	 bound: 2.7262	 transfer: 0.1538	 finalize: 0.2179
Accumulated time: update_bounds func: 56.2186	 prepare: 5.3756	 bound: 43.0654	 transfer: 0.1538	 finalize: 4.2147
batch bounding time:  3.496691942214966
Current worst splitting domains [lb, ub] (depth):
[-0.01021,   inf] (44), [-0.01021,   inf] (44), [-0.01021,   inf] (44), [-0.01021,   inf] (44), [-0.01021,   inf] (44), [-0.01021,   inf] (44), [-0.01021,   inf] (44), [-0.01021,   inf] (44), [-0.01020,   inf] (44), [-0.01020,   inf] (44), [-0.01020,   inf] (44), [-0.01020,   inf] (44), [-0.01020,   inf] (44), [-0.01020,   inf] (44), [-0.01020,   inf] (44), [-0.01020,   inf] (44), [-0.01019,   inf] (44), [-0.01019,   inf] (44), [-0.01019,   inf] (44), [-0.01019,   inf] (44), 
length of domains: 30048
Total time: 6.3075	 pickout: 0.2930	 decision: 2.1161	 get_bound: 3.5044	 add_domain: 0.3940
Current lb:-0.010209977626800537
59968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 94.3461480140686

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 418] [0, 418] [0, 418] [0, 418] [0, 418] [0, 418] [0, 418] [0, 418] [0, 418] [0, 418] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 39.71813201904297 with beta sum per layer: [229.58596801757812, 7.54496955871582, 0.0]
alpha/beta optimization time: 2.734790563583374
This batch time : update_bounds func: 3.5034	 prepare: 0.3849	 bound: 2.7352	 transfer: 0.1452	 finalize: 0.2281
Accumulated time: update_bounds func: 59.7219	 prepare: 5.7605	 bound: 45.8005	 transfer: 0.1452	 finalize: 4.4427
batch bounding time:  3.5079429149627686
Current worst splitting domains [lb, ub] (depth):
[-0.01020,   inf] (46), [-0.01020,   inf] (46), [-0.01020,   inf] (46), [-0.01020,   inf] (46), [-0.01020,   inf] (46), [-0.01020,   inf] (46), [-0.01020,   inf] (46), [-0.01020,   inf] (46), [-0.01019,   inf] (46), [-0.01019,   inf] (46), [-0.01019,   inf] (46), [-0.01019,   inf] (46), [-0.01019,   inf] (46), [-0.01019,   inf] (46), [-0.01019,   inf] (46), [-0.01019,   inf] (46), [-0.01018,   inf] (46), [-0.01018,   inf] (46), [-0.01018,   inf] (46), [-0.01018,   inf] (46), 
length of domains: 32048
Total time: 6.3519	 pickout: 0.2887	 decision: 2.1392	 get_bound: 3.5162	 add_domain: 0.4078
Current lb:-0.010202646255493164
63968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 100.73895025253296

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 1181] [0, 1181] [0, 1181] [0, 1181] [0, 1181] [0, 1181] [0, 1181] [0, 1181] [0, 1181] [0, 1181] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 37.79342269897461 with beta sum per layer: [465.58349609375, 14.725553512573242, 0.0]
alpha/beta optimization time: 2.7999298572540283
This batch time : update_bounds func: 4.1647	 prepare: 0.3866	 bound: 2.8003	 transfer: 0.1489	 finalize: 0.8186
Accumulated time: update_bounds func: 63.8866	 prepare: 6.1471	 bound: 48.6008	 transfer: 0.1489	 finalize: 5.2613
batch bounding time:  4.1689465045928955
Current worst splitting domains [lb, ub] (depth):
[-0.01020,   inf] (48), [-0.01020,   inf] (48), [-0.01020,   inf] (48), [-0.01020,   inf] (48), [-0.01020,   inf] (48), [-0.01020,   inf] (48), [-0.01020,   inf] (48), [-0.01020,   inf] (48), [-0.01019,   inf] (48), [-0.01019,   inf] (48), [-0.01019,   inf] (48), [-0.01019,   inf] (48), [-0.01019,   inf] (48), [-0.01019,   inf] (48), [-0.01019,   inf] (48), [-0.01019,   inf] (48), [-0.01018,   inf] (48), [-0.01018,   inf] (48), [-0.01018,   inf] (48), [-0.01018,   inf] (48), 
length of domains: 34048
Total time: 6.5062	 pickout: 0.2862	 decision: 1.6209	 get_bound: 4.1788	 add_domain: 0.4203
Current lb:-0.010202646255493164
67968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 107.29403233528137

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 1091] [0, 1091] [0, 1091] [0, 1091] [0, 1091] [0, 1091] [0, 1091] [0, 1091] [0, 1091] [0, 1091] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 39.68048858642578 with beta sum per layer: [183.4608154296875, 6.42543888092041, 0.0]
alpha/beta optimization time: 2.7356314659118652
This batch time : update_bounds func: 3.5181	 prepare: 0.3825	 bound: 2.7361	 transfer: 0.1524	 finalize: 0.2367
Accumulated time: update_bounds func: 67.4047	 prepare: 6.5296	 bound: 51.3369	 transfer: 0.1524	 finalize: 5.4980
batch bounding time:  3.522930383682251
Current worst splitting domains [lb, ub] (depth):
[-0.01019,   inf] (50), [-0.01019,   inf] (50), [-0.01019,   inf] (50), [-0.01019,   inf] (50), [-0.01019,   inf] (50), [-0.01019,   inf] (50), [-0.01019,   inf] (50), [-0.01019,   inf] (50), [-0.01018,   inf] (50), [-0.01018,   inf] (50), [-0.01018,   inf] (50), [-0.01018,   inf] (50), [-0.01018,   inf] (50), [-0.01018,   inf] (50), [-0.01018,   inf] (50), [-0.01018,   inf] (50), [-0.01017,   inf] (50), [-0.01017,   inf] (50), [-0.01017,   inf] (50), [-0.01017,   inf] (50), 
length of domains: 36048
Total time: 5.9294	 pickout: 0.2819	 decision: 1.6829	 get_bound: 3.5316	 add_domain: 0.4331
Current lb:-0.01019221544265747
71968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 113.2764482498169

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 1323] [0, 1323] [0, 1323] [0, 1323] [0, 1323] [0, 1323] [0, 1323] [0, 1323] [0, 1323] [0, 1323] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 39.9079475402832 with beta sum per layer: [204.17837524414062, 7.19182825088501, 0.0]
alpha/beta optimization time: 2.736473560333252
This batch time : update_bounds func: 4.2066	 prepare: 0.3882	 bound: 2.7369	 transfer: 0.1600	 finalize: 0.2389
Accumulated time: update_bounds func: 71.6113	 prepare: 6.9178	 bound: 54.0738	 transfer: 0.1600	 finalize: 5.7370
batch bounding time:  4.211012125015259
Current worst splitting domains [lb, ub] (depth):
[-0.01019,   inf] (52), [-0.01019,   inf] (52), [-0.01019,   inf] (52), [-0.01019,   inf] (52), [-0.01019,   inf] (52), [-0.01019,   inf] (52), [-0.01019,   inf] (52), [-0.01019,   inf] (52), [-0.01018,   inf] (52), [-0.01018,   inf] (52), [-0.01018,   inf] (52), [-0.01018,   inf] (52), [-0.01018,   inf] (52), [-0.01018,   inf] (52), [-0.01018,   inf] (52), [-0.01018,   inf] (52), [-0.01017,   inf] (52), [-0.01017,   inf] (52), [-0.01017,   inf] (52), [-0.01017,   inf] (52), 
length of domains: 38048
Total time: 6.7182	 pickout: 0.3006	 decision: 1.7510	 get_bound: 4.2190	 add_domain: 0.4476
Current lb:-0.01019221544265747
75968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 120.05494260787964

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 621] [1, 621] [1, 621] [1, 621] [1, 621] [1, 621] [1, 621] [1, 621] [1, 621] [1, 621] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 23.667770385742188 with beta sum per layer: [152.3935089111328, 566.4534912109375, 0.0]
alpha/beta optimization time: 2.8480422496795654
This batch time : update_bounds func: 3.6310	 prepare: 0.3881	 bound: 2.8485	 transfer: 0.1596	 finalize: 0.2244
Accumulated time: update_bounds func: 75.2423	 prepare: 7.3059	 bound: 56.9222	 transfer: 0.1596	 finalize: 5.9614
batch bounding time:  3.635997772216797
Current worst splitting domains [lb, ub] (depth):
[-0.01019,   inf] (54), [-0.01019,   inf] (54), [-0.01019,   inf] (54), [-0.01019,   inf] (54), [-0.01019,   inf] (54), [-0.01019,   inf] (54), [-0.01019,   inf] (54), [-0.01019,   inf] (54), [-0.01018,   inf] (54), [-0.01018,   inf] (54), [-0.01018,   inf] (54), [-0.01018,   inf] (54), [-0.01018,   inf] (54), [-0.01018,   inf] (54), [-0.01018,   inf] (54), [-0.01018,   inf] (54), [-0.01017,   inf] (54), [-0.01017,   inf] (54), [-0.01017,   inf] (54), [-0.01017,   inf] (54), 
length of domains: 40048
Total time: 6.1526	 pickout: 0.2979	 decision: 1.7535	 get_bound: 3.6449	 add_domain: 0.4564
Current lb:-0.01019221544265747
79968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 126.25590586662292

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 1209] [0, 1209] [0, 1209] [0, 1209] [0, 1209] [0, 1209] [0, 1209] [0, 1209] [0, 1209] [0, 1209] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 38.81648254394531 with beta sum per layer: [347.4141845703125, 8.62182331085205, 0.0]
alpha/beta optimization time: 2.746163845062256
This batch time : update_bounds func: 4.2743	 prepare: 0.3930	 bound: 2.7466	 transfer: 0.1535	 finalize: 0.9707
Accumulated time: update_bounds func: 79.5165	 prepare: 7.6989	 bound: 59.6688	 transfer: 0.1535	 finalize: 6.9320
batch bounding time:  4.278611660003662
Current worst splitting domains [lb, ub] (depth):
[-0.01019,   inf] (56), [-0.01019,   inf] (56), [-0.01019,   inf] (56), [-0.01019,   inf] (56), [-0.01019,   inf] (56), [-0.01019,   inf] (56), [-0.01019,   inf] (56), [-0.01019,   inf] (56), [-0.01018,   inf] (56), [-0.01018,   inf] (56), [-0.01018,   inf] (56), [-0.01018,   inf] (56), [-0.01018,   inf] (56), [-0.01018,   inf] (56), [-0.01018,   inf] (56), [-0.01018,   inf] (56), [-0.01017,   inf] (56), [-0.01017,   inf] (56), [-0.01017,   inf] (56), [-0.01017,   inf] (56), 
length of domains: 42048
Total time: 6.8589	 pickout: 0.2885	 decision: 1.8193	 get_bound: 4.2864	 add_domain: 0.4647
Current lb:-0.01019221544265747
83968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 133.1655719280243

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 75] [1, 75] [1, 75] [1, 75] [1, 75] [1, 75] [1, 75] [1, 75] [1, 75] [1, 75] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 37.55847930908203 with beta sum per layer: [157.18182373046875, 185.46142578125, 0.0]
alpha/beta optimization time: 2.757310628890991
This batch time : update_bounds func: 3.5388	 prepare: 0.3898	 bound: 2.7577	 transfer: 0.1489	 finalize: 0.2320
Accumulated time: update_bounds func: 83.0554	 prepare: 8.0887	 bound: 62.4265	 transfer: 0.1489	 finalize: 7.1640
batch bounding time:  3.543565511703491
Current worst splitting domains [lb, ub] (depth):
[-0.01019,   inf] (58), [-0.01019,   inf] (58), [-0.01019,   inf] (58), [-0.01019,   inf] (58), [-0.01019,   inf] (58), [-0.01019,   inf] (58), [-0.01019,   inf] (58), [-0.01019,   inf] (58), [-0.01018,   inf] (58), [-0.01018,   inf] (58), [-0.01018,   inf] (58), [-0.01018,   inf] (58), [-0.01018,   inf] (58), [-0.01018,   inf] (58), [-0.01018,   inf] (58), [-0.01018,   inf] (58), [-0.01017,   inf] (58), [-0.01017,   inf] (58), [-0.01017,   inf] (58), [-0.01017,   inf] (58), 
length of domains: 44048
Total time: 6.1596	 pickout: 0.2962	 decision: 1.8319	 get_bound: 3.5521	 add_domain: 0.4794
Current lb:-0.01019221544265747
87968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 139.37748765945435

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 1188] [0, 1188] [0, 1188] [0, 1188] [0, 1188] [0, 1188] [0, 1188] [0, 1188] [0, 1188] [0, 1188] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 39.70671844482422 with beta sum per layer: [282.63037109375, 8.428889274597168, 0.0]
alpha/beta optimization time: 2.747551679611206
This batch time : update_bounds func: 3.5410	 prepare: 0.3927	 bound: 2.7480	 transfer: 0.1544	 finalize: 0.2358
Accumulated time: update_bounds func: 86.5964	 prepare: 8.4813	 bound: 65.1745	 transfer: 0.1544	 finalize: 7.3998
batch bounding time:  3.545595645904541
Current worst splitting domains [lb, ub] (depth):
[-0.01019,   inf] (60), [-0.01019,   inf] (60), [-0.01019,   inf] (60), [-0.01019,   inf] (60), [-0.01019,   inf] (60), [-0.01019,   inf] (60), [-0.01019,   inf] (60), [-0.01019,   inf] (60), [-0.01018,   inf] (60), [-0.01018,   inf] (60), [-0.01018,   inf] (60), [-0.01018,   inf] (60), [-0.01018,   inf] (60), [-0.01018,   inf] (60), [-0.01018,   inf] (60), [-0.01018,   inf] (60), [-0.01017,   inf] (60), [-0.01017,   inf] (60), [-0.01017,   inf] (60), [-0.01017,   inf] (60), 
length of domains: 46048
Total time: 7.1072	 pickout: 0.2908	 decision: 1.9013	 get_bound: 3.5540	 add_domain: 1.3610
Current lb:-0.01019221544265747
91968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 146.5380642414093

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 1068] [0, 1068] [0, 1068] [0, 1068] [0, 1068] [0, 1068] [0, 1068] [0, 1068] [0, 1068] [0, 1068] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 39.97438049316406 with beta sum per layer: [206.05252075195312, 7.527488708496094, 0.0]
alpha/beta optimization time: 2.739175796508789
This batch time : update_bounds func: 4.4675	 prepare: 0.3893	 bound: 2.7396	 transfer: 0.1491	 finalize: 1.1790
Accumulated time: update_bounds func: 91.0638	 prepare: 8.8706	 bound: 67.9141	 transfer: 0.1491	 finalize: 8.5789
batch bounding time:  4.472387075424194
Current worst splitting domains [lb, ub] (depth):
[-0.01019,   inf] (62), [-0.01019,   inf] (62), [-0.01019,   inf] (62), [-0.01019,   inf] (62), [-0.01019,   inf] (62), [-0.01019,   inf] (62), [-0.01019,   inf] (62), [-0.01019,   inf] (62), [-0.01018,   inf] (62), [-0.01018,   inf] (62), [-0.01018,   inf] (62), [-0.01018,   inf] (62), [-0.01018,   inf] (62), [-0.01018,   inf] (62), [-0.01018,   inf] (62), [-0.01018,   inf] (62), [-0.01017,   inf] (62), [-0.01017,   inf] (62), [-0.01017,   inf] (62), [-0.01017,   inf] (62), 
length of domains: 48048
Total time: 6.3665	 pickout: 0.3086	 decision: 1.0693	 get_bound: 4.4816	 add_domain: 0.5070
Current lb:-0.01019221544265747
95968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 152.96380519866943

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 1269] [0, 1269] [0, 1269] [0, 1269] [0, 1269] [0, 1269] [0, 1269] [0, 1269] [0, 1269] [0, 1269] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 39.64302062988281 with beta sum per layer: [210.61837768554688, 7.7679948806762695, 0.0]
alpha/beta optimization time: 2.797412872314453
This batch time : update_bounds func: 3.6089	 prepare: 0.4000	 bound: 2.7979	 transfer: 0.1511	 finalize: 0.2496
Accumulated time: update_bounds func: 94.6727	 prepare: 9.2706	 bound: 70.7120	 transfer: 0.1511	 finalize: 8.8284
batch bounding time:  3.6138739585876465
Current worst splitting domains [lb, ub] (depth):
[-0.01019,   inf] (64), [-0.01019,   inf] (64), [-0.01019,   inf] (64), [-0.01019,   inf] (64), [-0.01019,   inf] (64), [-0.01019,   inf] (64), [-0.01019,   inf] (64), [-0.01019,   inf] (64), [-0.01018,   inf] (64), [-0.01018,   inf] (64), [-0.01018,   inf] (64), [-0.01018,   inf] (64), [-0.01018,   inf] (64), [-0.01018,   inf] (64), [-0.01018,   inf] (64), [-0.01018,   inf] (64), [-0.01017,   inf] (64), [-0.01017,   inf] (64), [-0.01017,   inf] (64), [-0.01017,   inf] (64), 
length of domains: 50048
Total time: 6.4841	 pickout: 0.3065	 decision: 2.0221	 get_bound: 3.6226	 add_domain: 0.5329
Current lb:-0.01019221544265747
99968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 159.51487755775452

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 806] [1, 806] [1, 806] [1, 806] [1, 806] [1, 806] [1, 806] [1, 806] [1, 806] [1, 806] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 39.88776397705078 with beta sum per layer: [149.56687927246094, 50.18910598754883, 0.0]
alpha/beta optimization time: 2.746203899383545
This batch time : update_bounds func: 3.5693	 prepare: 0.4039	 bound: 2.7466	 transfer: 0.1635	 finalize: 0.2436
Accumulated time: update_bounds func: 98.2421	 prepare: 9.6745	 bound: 73.4586	 transfer: 0.1635	 finalize: 9.0720
batch bounding time:  3.5743463039398193
Current worst splitting domains [lb, ub] (depth):
[-0.01019,   inf] (66), [-0.01019,   inf] (66), [-0.01019,   inf] (66), [-0.01019,   inf] (66), [-0.01019,   inf] (66), [-0.01019,   inf] (66), [-0.01019,   inf] (66), [-0.01019,   inf] (66), [-0.01018,   inf] (66), [-0.01018,   inf] (66), [-0.01018,   inf] (66), [-0.01018,   inf] (66), [-0.01018,   inf] (66), [-0.01018,   inf] (66), [-0.01018,   inf] (66), [-0.01018,   inf] (66), [-0.01017,   inf] (66), [-0.01017,   inf] (66), [-0.01017,   inf] (66), [-0.01017,   inf] (66), 
length of domains: 52048
Total time: 6.5364	 pickout: 0.3105	 decision: 2.0920	 get_bound: 3.5835	 add_domain: 0.5504
Current lb:-0.01019221544265747
103968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 166.11338782310486

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 593] [1, 593] [1, 593] [1, 593] [1, 593] [1, 593] [1, 593] [1, 593] [1, 593] [1, 593] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 40.0361328125 with beta sum per layer: [147.10693359375, 67.50357055664062, 0.0]
alpha/beta optimization time: 2.742954730987549
This batch time : update_bounds func: 3.5433	 prepare: 0.3978	 bound: 2.7434	 transfer: 0.1604	 finalize: 0.2309
Accumulated time: update_bounds func: 101.7853	 prepare: 10.0723	 bound: 76.2020	 transfer: 0.1604	 finalize: 9.3029
batch bounding time:  3.548154830932617
Current worst splitting domains [lb, ub] (depth):
[-0.01019,   inf] (68), [-0.01019,   inf] (68), [-0.01019,   inf] (68), [-0.01019,   inf] (68), [-0.01019,   inf] (68), [-0.01019,   inf] (68), [-0.01019,   inf] (68), [-0.01019,   inf] (68), [-0.01018,   inf] (68), [-0.01018,   inf] (68), [-0.01018,   inf] (68), [-0.01018,   inf] (68), [-0.01018,   inf] (68), [-0.01018,   inf] (68), [-0.01018,   inf] (68), [-0.01018,   inf] (68), [-0.01017,   inf] (68), [-0.01017,   inf] (68), [-0.01017,   inf] (68), [-0.01017,   inf] (68), 
length of domains: 54048
Total time: 6.5299	 pickout: 0.3108	 decision: 2.1051	 get_bound: 3.5574	 add_domain: 0.5567
Current lb:-0.01019221544265747
107968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 172.70053434371948

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 278] [1, 278] [1, 278] [1, 278] [1, 278] [1, 278] [1, 278] [1, 278] [1, 278] [1, 278] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 39.759010314941406 with beta sum per layer: [127.07733154296875, 95.18466186523438, 0.0]
alpha/beta optimization time: 2.7500269412994385
This batch time : update_bounds func: 3.5496	 prepare: 0.4015	 bound: 2.7505	 transfer: 0.1562	 finalize: 0.2309
Accumulated time: update_bounds func: 105.3350	 prepare: 10.4738	 bound: 78.9524	 transfer: 0.1562	 finalize: 9.5338
batch bounding time:  3.554380416870117
Current worst splitting domains [lb, ub] (depth):
[-0.01019,   inf] (70), [-0.01019,   inf] (70), [-0.01019,   inf] (70), [-0.01019,   inf] (70), [-0.01019,   inf] (70), [-0.01019,   inf] (70), [-0.01019,   inf] (70), [-0.01019,   inf] (70), [-0.01018,   inf] (70), [-0.01018,   inf] (70), [-0.01018,   inf] (70), [-0.01018,   inf] (70), [-0.01018,   inf] (70), [-0.01018,   inf] (70), [-0.01018,   inf] (70), [-0.01018,   inf] (70), [-0.01017,   inf] (70), [-0.01017,   inf] (70), [-0.01017,   inf] (70), [-0.01017,   inf] (70), 
length of domains: 56048
Total time: 6.5686	 pickout: 0.3045	 decision: 2.1408	 get_bound: 3.5633	 add_domain: 0.5600
Current lb:-0.01019221544265747
111968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 179.3263077735901

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 571] [1, 571] [1, 571] [0, 130] [1, 571] [1, 571] [0, 130] [1, 571] [1, 571] [1, 571] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 38.43014907836914 with beta sum per layer: [134.737548828125, 266.6628723144531, 0.0]
alpha/beta optimization time: 2.787224531173706
This batch time : update_bounds func: 3.6000	 prepare: 0.4061	 bound: 2.7877	 transfer: 0.1564	 finalize: 0.2392
Accumulated time: update_bounds func: 108.9349	 prepare: 10.8799	 bound: 81.7401	 transfer: 0.1564	 finalize: 9.7730
batch bounding time:  3.6049156188964844
Current worst splitting domains [lb, ub] (depth):
[-0.01019,   inf] (72), [-0.01019,   inf] (72), [-0.01019,   inf] (72), [-0.01019,   inf] (72), [-0.01019,   inf] (72), [-0.01019,   inf] (72), [-0.01019,   inf] (72), [-0.01019,   inf] (72), [-0.01018,   inf] (72), [-0.01018,   inf] (72), [-0.01018,   inf] (72), [-0.01018,   inf] (72), [-0.01018,   inf] (72), [-0.01018,   inf] (72), [-0.01018,   inf] (72), [-0.01018,   inf] (72), [-0.01018,   inf] (72), [-0.01018,   inf] (72), [-0.01017,   inf] (72), [-0.01017,   inf] (72), 
length of domains: 58048
Total time: 6.9401	 pickout: 0.3086	 decision: 2.4342	 get_bound: 3.6141	 add_domain: 0.5833
Current lb:-0.01019221544265747
115968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 186.32402276992798

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 130] [0, 130] [1, 837] [1, 837] [1, 837] [0, 130] [0, 461] [1, 571] [0, 461] [1, 837] 
regular batch size: 2*2000, diving batch size 1*0/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:25: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1627336316785/work/torch/csrc/utils/tensor_numpy.cpp:143.)
  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))

best_l after optimization: 38.94758605957031 with beta sum per layer: [165.746337890625, 181.53436279296875, 0.0]
alpha/beta optimization time: 2.7652125358581543
This batch time : update_bounds func: 3.5712	 prepare: 0.4112	 bound: 2.7656	 transfer: 0.1493	 finalize: 0.2346
Accumulated time: update_bounds func: 112.5061	 prepare: 11.2911	 bound: 84.5057	 transfer: 0.1493	 finalize: 10.0076
batch bounding time:  3.5762710571289062
Current worst splitting domains [lb, ub] (depth):
[-0.01019,   inf] (74), [-0.01019,   inf] (74), [-0.01019,   inf] (74), [-0.01019,   inf] (74), [-0.01019,   inf] (74), [-0.01019,   inf] (74), [-0.01019,   inf] (74), [-0.01019,   inf] (74), [-0.01018,   inf] (74), [-0.01018,   inf] (74), [-0.01018,   inf] (74), [-0.01018,   inf] (74), [-0.01018,   inf] (74), [-0.01018,   inf] (74), [-0.01018,   inf] (74), [-0.01018,   inf] (74), [-0.01018,   inf] (74), [-0.01018,   inf] (74), [-0.01018,   inf] (74), [-0.01018,   inf] (74), 
length of domains: 60048
Total time: 6.9564	 pickout: 0.3172	 decision: 2.4773	 get_bound: 3.5853	 add_domain: 0.5765
Current lb:-0.01019197702407837
119968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 193.34024572372437

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 130] [0, 130] [0, 130] [1, 837] [1, 837] [1, 837] [0, 461] [0, 1229] [1, 837] [0, 461] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 39.763771057128906 with beta sum per layer: [159.90829467773438, 85.25225830078125, 0.0]
alpha/beta optimization time: 2.7446448802948
This batch time : update_bounds func: 3.5595	 prepare: 0.4088	 bound: 2.7451	 transfer: 0.1527	 finalize: 0.2418
Accumulated time: update_bounds func: 116.0657	 prepare: 11.6999	 bound: 87.2508	 transfer: 0.1527	 finalize: 10.2494
batch bounding time:  3.5637128353118896
Current worst splitting domains [lb, ub] (depth):
[-0.01019,   inf] (76), [-0.01019,   inf] (76), [-0.01019,   inf] (76), [-0.01019,   inf] (76), [-0.01019,   inf] (76), [-0.01019,   inf] (76), [-0.01019,   inf] (76), [-0.01019,   inf] (76), [-0.01018,   inf] (76), [-0.01018,   inf] (76), [-0.01018,   inf] (76), [-0.01018,   inf] (76), [-0.01018,   inf] (76), [-0.01018,   inf] (76), [-0.01018,   inf] (76), [-0.01018,   inf] (76), [-0.01018,   inf] (76), [-0.01018,   inf] (76), [-0.01018,   inf] (76), [-0.01018,   inf] (76), 
length of domains: 62048
Total time: 6.9528	 pickout: 0.3022	 decision: 2.4906	 get_bound: 3.5712	 add_domain: 0.5888
Current lb:-0.010191351175308228
123968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 200.36042976379395

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 461] [0, 461] [0, 461] [0, 461] [0, 461] [0, 461] [0, 1229] [1, 571] [0, 461] [0, 461] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 39.643798828125 with beta sum per layer: [189.37225341796875, 81.04824829101562, 0.0]
alpha/beta optimization time: 2.7519454956054688
This batch time : update_bounds func: 3.5668	 prepare: 0.4054	 bound: 2.7524	 transfer: 0.1589	 finalize: 0.2392
Accumulated time: update_bounds func: 119.6325	 prepare: 12.1052	 bound: 90.0032	 transfer: 0.1589	 finalize: 10.4887
batch bounding time:  3.5715250968933105
Current worst splitting domains [lb, ub] (depth):
[-0.01019,   inf] (78), [-0.01019,   inf] (78), [-0.01019,   inf] (78), [-0.01019,   inf] (78), [-0.01019,   inf] (78), [-0.01019,   inf] (78), [-0.01019,   inf] (78), [-0.01019,   inf] (78), [-0.01018,   inf] (78), [-0.01018,   inf] (78), [-0.01018,   inf] (78), [-0.01018,   inf] (78), [-0.01018,   inf] (78), [-0.01018,   inf] (78), [-0.01018,   inf] (78), [-0.01018,   inf] (78), [-0.01018,   inf] (78), [-0.01018,   inf] (78), [-0.01018,   inf] (78), [-0.01018,   inf] (78), 
length of domains: 64048
Total time: 7.0937	 pickout: 0.3162	 decision: 2.6067	 get_bound: 3.5797	 add_domain: 0.5911
Current lb:-0.010189443826675415
127968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 207.53285360336304

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 1229] [0, 1229] [0, 1229] [1, 837] [0, 1229] [0, 1229] [0, 1229] [1, 837] [0, 1229] [1, 837] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 40.225250244140625 with beta sum per layer: [195.6011962890625, 35.03007888793945, 0.0]
alpha/beta optimization time: 2.766637086868286
This batch time : update_bounds func: 3.5879	 prepare: 0.4107	 bound: 2.7671	 transfer: 0.1616	 finalize: 0.2372
Accumulated time: update_bounds func: 123.2205	 prepare: 12.5159	 bound: 92.7702	 transfer: 0.1616	 finalize: 10.7259
batch bounding time:  3.592848062515259
Current worst splitting domains [lb, ub] (depth):
[-0.01019,   inf] (80), [-0.01019,   inf] (80), [-0.01019,   inf] (80), [-0.01019,   inf] (80), [-0.01019,   inf] (80), [-0.01019,   inf] (80), [-0.01019,   inf] (80), [-0.01019,   inf] (80), [-0.01018,   inf] (80), [-0.01018,   inf] (80), [-0.01018,   inf] (80), [-0.01018,   inf] (80), [-0.01018,   inf] (80), [-0.01018,   inf] (80), [-0.01018,   inf] (80), [-0.01018,   inf] (80), [-0.01018,   inf] (80), [-0.01018,   inf] (80), [-0.01018,   inf] (80), [-0.01018,   inf] (80), 
length of domains: 66048
Total time: 7.2067	 pickout: 0.3264	 decision: 2.6811	 get_bound: 3.6018	 add_domain: 0.5974
Current lb:-0.010189443826675415
131968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 214.80756998062134

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 8, 16, 16]) post split depth:  0
all nodes are split!!
Global ub: inf, batch ub: inf
Image 0 against label 1 verification end, Time cost: 219.14242458343506
Result: unknown in 232.1733 seconds


[[     0.              3.41060686      0.              0.0003221
       0.        ]
 [     0.             -0.01018944 131968.            219.14242458
       1.        ]]
############# Summary #############
Final verified acc: 0.0% [total 1 examples]
Total verification count: 1 , total verified safe: 0 , verified unsafe: 0 , timeout: 1
mean time [total:1]: 219.14274668693542
mean time [cnt:1]: 219.14274668693542
max time 232.1733274459839
unknown (total 1): [0]
