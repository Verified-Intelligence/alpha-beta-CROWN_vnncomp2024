Building native CUDA modules...
/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
  csv_name: oval21_instances.csv
  onnx_path: null
  vnnlib_path: null
  results_file: null
  root_path: ../../../../../vnncomp2021/benchmarks/oval21
model:
  path: null
  name: mnist_9_200
data:
  start: 23
  end: 24
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR
  data_filter_path: null
specification:
  type: lp
  norm: .inf
  epsilon: null
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 2000
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.01
    lr_decay: 0.98
    optimizer: adam
    iteration: 50
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 360
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 10
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:09:20 2022 on ubuntu
saving results to vnn-comp_[oval21_instances]_start=23_end=24_iter=50_b=2000_timeout=360_branching=kfsb-max-10_lra-init=0.1_lra=0.01_lrb=0.01_PGD=before.npz
customized start/end sample from 23 to 24

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
##### PGD attack: True label: 2, Tested against: [0, 1, 3, 4, 5, 6, 7, 8, 9] ######
pgd prediction: tensor([ 2.4464, -2.3306,  2.4788,  0.0859,  0.5553, -0.0582, -1.7540,  0.1807,
        -0.2480, -1.3562], device='cuda:0', grad_fn=<SqueezeBackward1>)
attack margin tensor([0.0324, 4.8093,    inf, 2.3929, 1.9234, 2.5370, 4.2328, 2.2980, 2.7268,
        3.8349], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[ 2.1242, -2.5640,  2.5565,  0.2943,  0.6096,  0.2446, -1.6168,  0.2388,
         -0.3803, -1.5068]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-0.1059,  3.9471,  1.6355,  1.4612,  1.5962,  3.4674,  1.3942,  1.9077,
          3.0735]], device='cuda:0') None
best_l after optimization: -18.662105560302734 with beta sum per layer: []
alpha/beta optimization time: 12.815462827682495
initial alpha-CROWN bounds: tensor([[-0.0885,  4.0096,  1.6550,  1.4772,  1.6231,  3.4944,  1.4291,  1.9458,
          3.1165]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.0885, device='cuda:0', grad_fn=<MinBackward1>)
##### [0] True label: 2, Tested against: 0, onnx_path: nets/cifar_deep_kw.onnx, vnnlib_path: vnnlib/cifar_deep_kw-img5533-eps0.014379084967320262.vnnlib ######
Model prediction is: tensor([[ 2.1242, -2.5640,  2.5565,  0.2943,  0.6096,  0.2446, -1.6168,  0.2388,
         -0.3803, -1.5068]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /14 start_node /15
setting alpha for layer /14 start_node /17
setting alpha for layer /14 start_node /19
setting alpha for layer /14 start_node /22
not setting layer /14 start_node /24 because shape mismatch (torch.Size([2, 1, 1, 8, 16, 16]) != torch.Size([2, 9, 1, 8, 16, 16]))
setting alpha for layer /16 start_node /17
setting alpha for layer /16 start_node /19
setting alpha for layer /16 start_node /22
not setting layer /16 start_node /24 because shape mismatch (torch.Size([2, 1, 1, 8, 16, 16]) != torch.Size([2, 9, 1, 8, 16, 16]))
setting alpha for layer /18 start_node /19
setting alpha for layer /18 start_node /22
not setting layer /18 start_node /24 because shape mismatch (torch.Size([2, 1, 1, 8, 16, 16]) != torch.Size([2, 9, 1, 8, 16, 16]))
setting alpha for layer /20 start_node /22
not setting layer /20 start_node /24 because shape mismatch (torch.Size([2, 1, 1, 8, 8, 8]) != torch.Size([2, 9, 1, 8, 8, 8]))
not setting layer /23 start_node /24 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /13 torch.Size([1, 8, 16, 16])
1 /15 torch.Size([1, 8, 16, 16])
2 /17 torch.Size([1, 8, 16, 16])
3 /19 torch.Size([1, 8, 8, 8])
4 /22 torch.Size([1, 100])
best_l after optimization: 0.08844709396362305 with beta sum per layer: []
alpha/beta optimization time: 2.2924227714538574
alpha-CROWN with fixed intermediate bounds: tensor([[-0.0884]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.08844709396362305
layer 0 size torch.Size([2048]) unstable 90
layer 1 size torch.Size([2048]) unstable 126
layer 2 size torch.Size([2048]) unstable 186
layer 3 size torch.Size([512]) unstable 32
layer 4 size torch.Size([100]) unstable 22
-----------------
# of unstable neurons: 456
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 8, 16, 16]) pre split depth:  7
batch:  torch.Size([1, 8, 16, 16]) post split depth:  7
splitting decisions: 
split level 0: [4, 4] 
split level 1: [4, 58] 
split level 2: [4, 0] 
split level 3: [4, 44] 
split level 4: [4, 34] 
split level 5: [4, 99] 
split level 6: [4, 81] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -2.723055124282837 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 2.9136691093444824]
alpha/beta optimization time: 0.9178485870361328
This batch time : update_bounds func: 0.9567	 prepare: 0.0138	 bound: 0.9183	 transfer: 0.0119	 finalize: 0.0124
Accumulated time: update_bounds func: 0.9567	 prepare: 0.0138	 bound: 0.9183	 transfer: 0.0119	 finalize: 0.0124
batch bounding time:  0.957136869430542
Current worst splitting domains [lb, ub] (depth):
[-0.02419,   inf] (8), [-0.00546,   inf] (8), 
length of domains: 2
Total time: 1.0581	 pickout: 0.0012	 decision: 0.0803	 get_bound: 0.9762	 add_domain: 0.0003
Current lb:-0.024186134338378906
128 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.340386867523193

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2, 8, 16, 16]) pre split depth:  6
batch:  torch.Size([2, 8, 16, 16]) post split depth:  6
splitting decisions: 
split level 0: [3, 497] [3, 497] 
split level 1: [4, 33] [4, 33] 
split level 2: [2, 69] [2, 69] 
split level 3: [3, 187] [3, 187] 
split level 4: [4, 8] [4, 8] 
split level 5: [3, 438] [3, 438] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -2.4817309379577637 with beta sum per layer: [0.0, 0.0, 0.727564811706543, 1.4567079544067383, 3.123488664627075]
alpha/beta optimization time: 0.9261231422424316
This batch time : update_bounds func: 0.9677	 prepare: 0.0166	 bound: 0.9266	 transfer: 0.0124	 finalize: 0.0118
Accumulated time: update_bounds func: 1.9245	 prepare: 0.0305	 bound: 1.8448	 transfer: 0.0124	 finalize: 0.0242
batch bounding time:  0.9682385921478271
Current worst splitting domains [lb, ub] (depth):
[-0.01338,   inf] (15), [-0.01153,   inf] (15), [-0.00911,   inf] (15), [-0.00691,   inf] (15), 
length of domains: 4
Total time: 1.0684	 pickout: 0.0014	 decision: 0.0784	 get_bound: 0.9878	 add_domain: 0.0007
Current lb:-0.013378850184381008
256 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.410398483276367

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 8, 16, 16]) pre split depth:  5
batch:  torch.Size([4, 8, 16, 16]) post split depth:  5
splitting decisions: 
split level 0: [0, 1622] [0, 1622] [0, 1622] [0, 1622] 
split level 1: [3, 481] [3, 481] [3, 498] [3, 498] 
split level 2: [3, 498] [3, 498] [2, 1493] [2, 1493] 
split level 3: [2, 1492] [2, 1492] [2, 1492] [2, 1492] 
split level 4: [2, 177] [2, 177] [2, 177] [2, 177] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.4380291700363159 with beta sum per layer: [0.0, 0.0, 0.07244521379470825, 3.5409042835235596, 3.259232521057129]
alpha/beta optimization time: 0.9242994785308838
This batch time : update_bounds func: 0.9643	 prepare: 0.0188	 bound: 0.9247	 transfer: 0.0092	 finalize: 0.0111
Accumulated time: update_bounds func: 2.8888	 prepare: 0.0492	 bound: 2.7696	 transfer: 0.0092	 finalize: 0.0353
batch bounding time:  0.9646713733673096
Current worst splitting domains [lb, ub] (depth):
[-0.00749,   inf] (21), [-0.00733,   inf] (21), [-0.00620,   inf] (21), [-0.00594,   inf] (21), [-0.00573,   inf] (21), [-0.00558,   inf] (21), [-0.00535,   inf] (21), [-0.00534,   inf] (21), [-0.00429,   inf] (21), [-0.00412,   inf] (21), [-0.00398,   inf] (21), [-0.00387,   inf] (21), [-0.00345,   inf] (21), [-0.00335,   inf] (21), [-0.00249,   inf] (21), [-0.00248,   inf] (21), [-0.00184,   inf] (21), [-0.00179,   inf] (21), [-0.00128,   inf] (21), [-0.00121,   inf] (21), 
length of domains: 28
Total time: 1.0693	 pickout: 0.0020	 decision: 0.0784	 get_bound: 0.9863	 add_domain: 0.0025
Current lb:-0.007489681243896484
384 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.481074810028076

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([28, 8, 16, 16]) pre split depth:  2
batch:  torch.Size([28, 8, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [4, 2] [4, 2] [4, 2] [4, 2] [4, 2] [4, 2] [4, 2] [4, 2] [4, 2] [4, 2] 
split level 1: [3, 110] [3, 110] [3, 110] [3, 110] [3, 110] [3, 110] [3, 110] [3, 110] [3, 110] [3, 110] 
regular batch size: 2*56, diving batch size 1*0
best_l after optimization: -1.8872566223144531 with beta sum per layer: [0.0, 0.0, 0.22680309414863586, 2.273693799972534, 2.026291847229004]
alpha/beta optimization time: 0.9265899658203125
This batch time : update_bounds func: 0.9638	 prepare: 0.0175	 bound: 0.9270	 transfer: 0.0084	 finalize: 0.0105
Accumulated time: update_bounds func: 3.8526	 prepare: 0.0667	 bound: 3.6966	 transfer: 0.0084	 finalize: 0.0459
batch bounding time:  0.9642670154571533
Current worst splitting domains [lb, ub] (depth):
[-0.00594,   inf] (24), [-0.00579,   inf] (24), [-0.00460,   inf] (24), [-0.00442,   inf] (24), [-0.00417,   inf] (24), [-0.00404,   inf] (24), [-0.00381,   inf] (24), [-0.00380,   inf] (24), [-0.00267,   inf] (24), [-0.00258,   inf] (24), [-0.00240,   inf] (24), [-0.00234,   inf] (24), [-0.00187,   inf] (24), [-0.00178,   inf] (24), [-0.00083,   inf] (24), [-0.00078,   inf] (24), [-0.00026,   inf] (24), [-0.00025,   inf] (24), 
length of domains: 18
Total time: 1.0757	 pickout: 0.0070	 decision: 0.0925	 get_bound: 0.9742	 add_domain: 0.0020
Current lb:-0.005942821502685547
496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.558856010437012

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([18, 8, 16, 16]) pre split depth:  3
batch:  torch.Size([18, 8, 16, 16]) post split depth:  3
splitting decisions: 
split level 0: [3, 274] [3, 274] [3, 274] [3, 274] [3, 274] [3, 274] [3, 274] [3, 274] [3, 274] [3, 274] 
split level 1: [1, 662] [1, 662] [1, 662] [1, 662] [1, 662] [1, 662] [1, 662] [1, 662] [1, 662] [1, 662] 
split level 2: [3, 386] [3, 386] [3, 386] [3, 386] [3, 386] [3, 386] [3, 386] [3, 386] [3, 386] [3, 386] 
regular batch size: 2*72, diving batch size 1*0
best_l after optimization: -0.34312400221824646 with beta sum per layer: [0.0, 0.11226005852222443, 0.1584293693304062, 1.8800382614135742, 3.282623767852783]
alpha/beta optimization time: 0.9288289546966553
This batch time : update_bounds func: 0.9752	 prepare: 0.0224	 bound: 0.9293	 transfer: 0.0104	 finalize: 0.0127
Accumulated time: update_bounds func: 4.8279	 prepare: 0.0890	 bound: 4.6259	 transfer: 0.0104	 finalize: 0.0586
batch bounding time:  0.9756386280059814
Current worst splitting domains [lb, ub] (depth):
[-0.00407,   inf] (28), [-0.00393,   inf] (28), [-0.00269,   inf] (28), [-0.00256,   inf] (28), [-0.00202,   inf] (28), [-0.00195,   inf] (28), [-0.00194,   inf] (28), [-0.00189,   inf] (28), [-0.00122,   inf] (28), [-0.00109,   inf] (28), [-0.00076,   inf] (28), [-0.00048,   inf] (28), [-0.00045,   inf] (28), [-0.00024,   inf] (28), 
length of domains: 14
Total time: 1.0919	 pickout: 0.0053	 decision: 0.0906	 get_bound: 0.9945	 add_domain: 0.0015
Current lb:-0.004071712493896484
640 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.652881383895874

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([14, 8, 16, 16]) pre split depth:  3
batch:  torch.Size([14, 8, 16, 16]) post split depth:  3
splitting decisions: 
split level 0: [2, 1980] [2, 1980] [2, 1980] [2, 1980] [2, 1493] [2, 1980] [2, 1980] [2, 1493] [2, 1980] [2, 1980] 
split level 1: [2, 1515] [2, 1515] [2, 1515] [2, 1515] [2, 1980] [2, 1515] [2, 1515] [2, 1980] [2, 1515] [2, 1515] 
split level 2: [2, 217] [2, 217] [2, 1514] [2, 217] [2, 1515] [2, 217] [2, 217] [2, 1515] [2, 217] [2, 217] 
regular batch size: 2*56, diving batch size 1*0
best_l after optimization: -0.3329301178455353 with beta sum per layer: [0.0, 0.22456765174865723, 0.07074016332626343, 0.0, 1.624485969543457]
alpha/beta optimization time: 0.8252415657043457
This batch time : update_bounds func: 0.8590	 prepare: 0.0182	 bound: 0.8257	 transfer: 0.0045	 finalize: 0.0104
Accumulated time: update_bounds func: 5.6868	 prepare: 0.1072	 bound: 5.4516	 transfer: 0.0045	 finalize: 0.0689
batch bounding time:  0.8593144416809082
Current worst splitting domains [lb, ub] (depth):
[-0.00059,   inf] (32), [-0.00045,   inf] (32), [-0.00011,   inf] (32), 
length of domains: 3
Total time: 0.9632	 pickout: 0.0042	 decision: 0.0841	 get_bound: 0.8745	 add_domain: 0.0005
Current lb:-0.0005948543548583984
752 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.617793321609497

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3, 8, 16, 16]) pre split depth:  6
batch:  torch.Size([3, 8, 16, 16]) post split depth:  6
splitting decisions: 
split level 0: [2, 1435] [2, 1435] [2, 1435] 
split level 1: [2, 1514] [2, 1514] [2, 1514] 
split level 2: [3, 104] [3, 104] [3, 104] 
split level 3: [2, 1493] [2, 1402] [2, 1493] 
split level 4: [2, 1402] [2, 1493] [2, 1979] 
split level 5: [2, 1979] [2, 1979] [2, 1402] 
regular batch size: 2*96, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -1.551743745803833 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.0134735107421875
This batch time : update_bounds func: 0.0714	 prepare: 0.0306	 bound: 0.0139	 transfer: 0.0092	 finalize: 0.0173
Accumulated time: update_bounds func: 5.7583	 prepare: 0.1378	 bound: 5.4654	 transfer: 0.0092	 finalize: 0.0863
batch bounding time:  0.0717153549194336
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.1840	 pickout: 0.0017	 decision: 0.0766	 get_bound: 0.1056	 add_domain: 0.0001
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 9.804047346115112

Image 0 against label 0 verification end, Time cost: 9.88802719116211
##### [0] True label: 2, Tested against: 1, onnx_path: nets/cifar_deep_kw.onnx, vnnlib_path: vnnlib/cifar_deep_kw-img5533-eps0.014379084967320262.vnnlib ######/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:25: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1627336316785/work/torch/csrc/utils/tensor_numpy.cpp:143.)
  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))

init opt crown verified for label 1 with bound 4.009609699249268
Image 0 against label 1 verification end, Time cost: 0.0003261566162109375
##### [0] True label: 2, Tested against: 3, onnx_path: nets/cifar_deep_kw.onnx, vnnlib_path: vnnlib/cifar_deep_kw-img5533-eps0.014379084967320262.vnnlib ######
init opt crown verified for label 3 with bound 1.6549630165100098
Image 0 against label 3 verification end, Time cost: 0.0002830028533935547
##### [0] True label: 2, Tested against: 4, onnx_path: nets/cifar_deep_kw.onnx, vnnlib_path: vnnlib/cifar_deep_kw-img5533-eps0.014379084967320262.vnnlib ######
init opt crown verified for label 4 with bound 1.4771581888198853
Image 0 against label 4 verification end, Time cost: 0.0002887248992919922
##### [0] True label: 2, Tested against: 5, onnx_path: nets/cifar_deep_kw.onnx, vnnlib_path: vnnlib/cifar_deep_kw-img5533-eps0.014379084967320262.vnnlib ######
init opt crown verified for label 5 with bound 1.6230765581130981
Image 0 against label 5 verification end, Time cost: 0.0002837181091308594
##### [0] True label: 2, Tested against: 6, onnx_path: nets/cifar_deep_kw.onnx, vnnlib_path: vnnlib/cifar_deep_kw-img5533-eps0.014379084967320262.vnnlib ######
init opt crown verified for label 6 with bound 3.4944164752960205
Image 0 against label 6 verification end, Time cost: 0.000293731689453125
##### [0] True label: 2, Tested against: 7, onnx_path: nets/cifar_deep_kw.onnx, vnnlib_path: vnnlib/cifar_deep_kw-img5533-eps0.014379084967320262.vnnlib ######
init opt crown verified for label 7 with bound 1.4291001558303833
Image 0 against label 7 verification end, Time cost: 0.0003135204315185547
##### [0] True label: 2, Tested against: 8, onnx_path: nets/cifar_deep_kw.onnx, vnnlib_path: vnnlib/cifar_deep_kw-img5533-eps0.014379084967320262.vnnlib ######
init opt crown verified for label 8 with bound 1.9457728862762451
Image 0 against label 8 verification end, Time cost: 0.00027871131896972656
##### [0] True label: 2, Tested against: 9, onnx_path: nets/cifar_deep_kw.onnx, vnnlib_path: vnnlib/cifar_deep_kw-img5533-eps0.014379084967320262.vnnlib ######
init opt crown verified for label 9 with bound 3.116469621658325
Image 0 against label 9 verification end, Time cost: 0.00028896331787109375
Result: safe-bab in 28.9514 seconds


[[  0.           0.0000001  944.           9.88802719   0.        ]
 [  0.           4.0096097    0.           0.00032616   1.        ]
 [  0.           1.65496302   0.           0.000283     3.        ]
 [  0.           1.47715819   0.           0.00028872   4.        ]
 [  0.           1.62307656   0.           0.00028372   5.        ]
 [  0.           3.49441648   0.           0.00029373   6.        ]
 [  0.           1.42910016   0.           0.00031352   7.        ]
 [  0.           1.94577289   0.           0.00027871   8.        ]
 [  0.           3.11646962   0.           0.00028896   9.        ]]
############# Summary #############
Final verified acc: 100.0% [total 1 examples]
Total verification count: 1 , total verified safe: 1 , verified unsafe: 0 , timeout: 0
mean time [total:1]: 9.89038372039795
mean time [cnt:1]: 9.89038372039795
max time 28.951387643814087
safe-bab (total 1): [0]
