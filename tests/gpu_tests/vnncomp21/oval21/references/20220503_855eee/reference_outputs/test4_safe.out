Building native CUDA modules...
/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
  csv_name: oval21_instances.csv
  onnx_path: null
  vnnlib_path: null
  results_file: null
  root_path: ../../../../../vnncomp2021/benchmarks/oval21
model:
  path: null
  name: mnist_9_200
data:
  start: 2
  end: 3
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR
  data_filter_path: null
specification:
  type: lp
  norm: .inf
  epsilon: null
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 2000
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.01
    lr_decay: 0.98
    optimizer: adam
    iteration: 50
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 360
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 10
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:06:19 2022 on ubuntu
saving results to vnn-comp_[oval21_instances]_start=2_end=3_iter=50_b=2000_timeout=360_branching=kfsb-max-10_lra-init=0.1_lra=0.01_lrb=0.01_PGD=before.npz
customized start/end sample from 2 to 3

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
##### PGD attack: True label: 5, Tested against: [0, 1, 2, 3, 4, 6, 7, 8, 9] ######
pgd prediction: tensor([-1.8549, -1.7249,  0.8909,  1.7309,  2.1224,  2.1759,  0.6282,  0.4695,
        -1.5537, -2.8844], device='cuda:0', grad_fn=<SqueezeBackward1>)
attack margin tensor([4.0308, 3.9008, 1.2850, 0.4450, 0.0535,    inf, 1.5477, 1.7064, 3.7296,
        5.0603], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[-2.0331, -1.6352,  0.7273,  1.9416,  1.7134,  2.5470,  0.3442,  0.3959,
         -1.2998, -2.7013]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 2.8774,  2.1523,  0.9894,  0.2809, -0.1556,  0.9263,  1.0402,  2.0577,
          3.8459]], device='cuda:0') None
best_l after optimization: -14.512088775634766 with beta sum per layer: []
alpha/beta optimization time: 7.636652946472168
initial alpha-CROWN bounds: tensor([[ 2.9512,  2.2270,  1.0479,  0.2978, -0.1079,  0.9866,  1.0897,  2.1250,
          3.8946]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.1079, device='cuda:0', grad_fn=<MinBackward1>)
##### [0] True label: 5, Tested against: 0, onnx_path: nets/cifar_base_kw.onnx, vnnlib_path: vnnlib/cifar_base_kw-img4631-eps0.016339869281045753.vnnlib ######
init opt crown verified for label 0 with bound 2.951209306716919
Image 0 against label 0 verification end, Time cost: 0.0003104209899902344
##### [0] True label: 5, Tested against: 1, onnx_path: nets/cifar_base_kw.onnx, vnnlib_path: vnnlib/cifar_base_kw-img4631-eps0.016339869281045753.vnnlib ######
init opt crown verified for label 1 with bound 2.226966619491577
Image 0 against label 1 verification end, Time cost: 0.0003178119659423828
##### [0] True label: 5, Tested against: 2, onnx_path: nets/cifar_base_kw.onnx, vnnlib_path: vnnlib/cifar_base_kw-img4631-eps0.016339869281045753.vnnlib ######
init opt crown verified for label 2 with bound 1.0479494333267212
Image 0 against label 2 verification end, Time cost: 0.00033164024353027344
##### [0] True label: 5, Tested against: 3, onnx_path: nets/cifar_base_kw.onnx, vnnlib_path: vnnlib/cifar_base_kw-img4631-eps0.016339869281045753.vnnlib ######
init opt crown verified for label 3 with bound 0.2978476881980896
Image 0 against label 3 verification end, Time cost: 0.0003056526184082031
##### [0] True label: 5, Tested against: 4, onnx_path: nets/cifar_base_kw.onnx, vnnlib_path: vnnlib/cifar_base_kw-img4631-eps0.016339869281045753.vnnlib ######
Model prediction is: tensor([[-2.0331, -1.6352,  0.7273,  1.9416,  1.7134,  2.5470,  0.3442,  0.3959,
         -1.2998, -2.7013]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 8, 16, 16]) != torch.Size([2, 9, 1, 8, 16, 16]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 16, 8, 8]) != torch.Size([2, 9, 1, 16, 8, 8]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 8, 16, 16])
1 /11 torch.Size([1, 16, 8, 8])
2 /14 torch.Size([1, 100])
best_l after optimization: 0.10782317072153091 with beta sum per layer: []
alpha/beta optimization time: 1.856889009475708
alpha-CROWN with fixed intermediate bounds: tensor([[-0.1078]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.10782317072153091
layer 0 size torch.Size([2048]) unstable 273
layer 1 size torch.Size([1024]) unstable 155
layer 2 size torch.Size([100]) unstable 19
-----------------
# of unstable neurons: 447
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 8, 16, 16]) pre split depth:  7
batch:  torch.Size([1, 8, 16, 16]) post split depth:  7
splitting decisions: 
split level 0: [2, 61] 
split level 1: [2, 36] 
split level 2: [2, 86] 
split level 3: [2, 0] 
split level 4: [2, 75] 
split level 5: [1, 987] 
split level 6: [1, 947] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -14.973678588867188 with beta sum per layer: [0.0, 1.9003843069076538, 1.8867015838623047]
alpha/beta optimization time: 0.6517245769500732
This batch time : update_bounds func: 0.6751	 prepare: 0.0100	 bound: 0.6522	 transfer: 0.0052	 finalize: 0.0074
Accumulated time: update_bounds func: 0.6751	 prepare: 0.0100	 bound: 0.6522	 transfer: 0.0052	 finalize: 0.0074
batch bounding time:  0.675633430480957
Current worst splitting domains [lb, ub] (depth):
[-0.06693,   inf] (8), [-0.03823,   inf] (8), [-0.03481,   inf] (8), [-0.03110,   inf] (8), [-0.01166,   inf] (8), [-0.00241,   inf] (8), 
length of domains: 6
Total time: 0.7441	 pickout: 0.0009	 decision: 0.0527	 get_bound: 0.6899	 add_domain: 0.0006
Current lb:-0.0669311061501503
128 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.5493721961975098

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([6, 8, 16, 16]) pre split depth:  5
batch:  torch.Size([6, 8, 16, 16]) post split depth:  5
splitting decisions: 
split level 0: [2, 48] [2, 48] [2, 48] [2, 48] [2, 48] [2, 48] 
split level 1: [1, 282] [1, 282] [1, 282] [1, 282] [1, 282] [1, 282] 
split level 2: [1, 353] [1, 353] [1, 353] [1, 353] [1, 353] [1, 353] 
split level 3: [2, 9] [2, 9] [2, 9] [2, 9] [2, 9] [2, 9] 
split level 4: [1, 821] [1, 821] [1, 996] [1, 821] [1, 996] [1, 821] 
regular batch size: 2*96, diving batch size 1*0
best_l after optimization: -2.5223541259765625 with beta sum per layer: [0.0, 36.918365478515625, 21.56690216064453]
alpha/beta optimization time: 0.6104569435119629
This batch time : update_bounds func: 0.6482	 prepare: 0.0178	 bound: 0.6108	 transfer: 0.0084	 finalize: 0.0104
Accumulated time: update_bounds func: 1.3233	 prepare: 0.0277	 bound: 1.2630	 transfer: 0.0084	 finalize: 0.0178
batch bounding time:  0.6485569477081299
Current worst splitting domains [lb, ub] (depth):
[-0.05204,   inf] (14), [-0.04511,   inf] (14), [-0.04270,   inf] (14), [-0.03994,   inf] (14), [-0.03578,   inf] (14), [-0.03303,   inf] (14), [-0.03244,   inf] (14), [-0.02553,   inf] (14), [-0.02339,   inf] (14), [-0.01919,   inf] (14), [-0.01682,   inf] (14), [-0.01646,   inf] (14), [-0.01405,   inf] (14), [-0.01316,   inf] (14), [-0.01129,   inf] (14), [-0.00787,   inf] (14), [-0.00713,   inf] (14), [-0.00624,   inf] (14), [-0.00584,   inf] (14), [-0.00567,   inf] (14), 
length of domains: 25
Total time: 0.7316	 pickout: 0.0017	 decision: 0.0568	 get_bound: 0.6716	 add_domain: 0.0016
Current lb:-0.05203965678811073
320 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.283212661743164

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([25, 8, 16, 16]) pre split depth:  3
batch:  torch.Size([25, 8, 16, 16]) post split depth:  3
splitting decisions: 
split level 0: [1, 882] [1, 882] [1, 882] [1, 882] [1, 882] [1, 882] [1, 882] [1, 882] [1, 882] [1, 361] 
split level 1: [1, 350] [1, 350] [1, 350] [1, 350] [1, 350] [1, 350] [1, 350] [1, 350] [1, 350] [1, 358] 
split level 2: [1, 996] [1, 996] [1, 996] [1, 996] [1, 996] [1, 996] [1, 996] [1, 996] [1, 996] [1, 350] 
regular batch size: 2*100, diving batch size 1*0
best_l after optimization: 0.4356696903705597 with beta sum per layer: [0.0, 32.035919189453125, 13.664795875549316]
alpha/beta optimization time: 0.6281557083129883
This batch time : update_bounds func: 0.6697	 prepare: 0.0181	 bound: 0.6285	 transfer: 0.0082	 finalize: 0.0143
Accumulated time: update_bounds func: 1.9930	 prepare: 0.0458	 bound: 1.8915	 transfer: 0.0082	 finalize: 0.0321
batch bounding time:  0.6702380180358887
Current worst splitting domains [lb, ub] (depth):
[-0.04359,   inf] (18), [-0.04053,   inf] (18), [-0.03910,   inf] (18), [-0.03666,   inf] (18), [-0.03599,   inf] (18), [-0.03411,   inf] (18), [-0.03360,   inf] (18), [-0.03219,   inf] (18), [-0.03147,   inf] (18), [-0.03104,   inf] (18), [-0.02962,   inf] (18), [-0.02908,   inf] (18), [-0.02861,   inf] (18), [-0.02841,   inf] (18), [-0.02718,   inf] (18), [-0.02699,   inf] (18), [-0.02650,   inf] (18), [-0.02553,   inf] (18), [-0.02455,   inf] (18), [-0.02412,   inf] (18), 
length of domains: 84
Total time: 0.7638	 pickout: 0.0040	 decision: 0.0648	 get_bound: 0.6890	 add_domain: 0.0060
Current lb:-0.043591178953647614
520 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.048589706420898

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([84, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([84, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 358] [1, 358] [1, 358] [1, 358] [1, 358] [1, 358] [1, 358] [1, 358] [1, 358] [1, 358] 
regular batch size: 2*84, diving batch size 1*0
best_l after optimization: 1.5887805223464966 with beta sum per layer: [0.0, 22.314743041992188, 4.399745464324951]
alpha/beta optimization time: 0.6031570434570312
This batch time : update_bounds func: 0.6361	 prepare: 0.0176	 bound: 0.6035	 transfer: 0.0056	 finalize: 0.0090
Accumulated time: update_bounds func: 2.6291	 prepare: 0.0634	 bound: 2.4949	 transfer: 0.0056	 finalize: 0.0411
batch bounding time:  0.6364736557006836
Current worst splitting domains [lb, ub] (depth):
[-0.03765,   inf] (20), [-0.03624,   inf] (20), [-0.03534,   inf] (20), [-0.03394,   inf] (20), [-0.03327,   inf] (20), [-0.03173,   inf] (20), [-0.03074,   inf] (20), [-0.03064,   inf] (20), [-0.02956,   inf] (20), [-0.02931,   inf] (20), [-0.02841,   inf] (20), [-0.02813,   inf] (20), [-0.02704,   inf] (20), [-0.02672,   inf] (20), [-0.02637,   inf] (20), [-0.02582,   inf] (20), [-0.02556,   inf] (20), [-0.02481,   inf] (20), [-0.02442,   inf] (20), [-0.02415,   inf] (20), 
length of domains: 126
Total time: 0.7459	 pickout: 0.0119	 decision: 0.0886	 get_bound: 0.6368	 add_domain: 0.0087
Current lb:-0.03764629364013672
688 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.796479225158691

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([126, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([126, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 826] [1, 826] [1, 826] [1, 826] [1, 826] [1, 826] [1, 826] [1, 932] [1, 826] [1, 826] 
regular batch size: 2*126, diving batch size 1*0
best_l after optimization: 2.1480276584625244 with beta sum per layer: [0.0, 31.620140075683594, 5.9947404861450195]
alpha/beta optimization time: 0.6240265369415283
This batch time : update_bounds func: 0.6718	 prepare: 0.0229	 bound: 0.6244	 transfer: 0.0092	 finalize: 0.0148
Accumulated time: update_bounds func: 3.3008	 prepare: 0.0863	 bound: 3.1193	 transfer: 0.0092	 finalize: 0.0558
batch bounding time:  0.6722686290740967
Current worst splitting domains [lb, ub] (depth):
[-0.03560,   inf] (22), [-0.03419,   inf] (22), [-0.03326,   inf] (22), [-0.03189,   inf] (22), [-0.03122,   inf] (22), [-0.03037,   inf] (22), [-0.02968,   inf] (22), [-0.02913,   inf] (22), [-0.02896,   inf] (22), [-0.02868,   inf] (22), [-0.02803,   inf] (22), [-0.02751,   inf] (22), [-0.02725,   inf] (22), [-0.02666,   inf] (22), [-0.02632,   inf] (22), [-0.02606,   inf] (22), [-0.02599,   inf] (22), [-0.02498,   inf] (22), [-0.02465,   inf] (22), [-0.02446,   inf] (22), 
length of domains: 187
Total time: 0.8110	 pickout: 0.0164	 decision: 0.1081	 get_bound: 0.6727	 add_domain: 0.0139
Current lb:-0.03559732437133789
940 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.610688209533691

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([187, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([187, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 289] [1, 289] [1, 289] [1, 289] [1, 289] [1, 289] [1, 289] [1, 826] [1, 289] [1, 289] 
regular batch size: 2*187, diving batch size 1*0
best_l after optimization: 2.3345348834991455 with beta sum per layer: [0.0, 55.94215393066406, 4.417541027069092]
alpha/beta optimization time: 0.6405432224273682
This batch time : update_bounds func: 0.7112	 prepare: 0.0331	 bound: 0.6409	 transfer: 0.0144	 finalize: 0.0220
Accumulated time: update_bounds func: 4.0120	 prepare: 0.1194	 bound: 3.7602	 transfer: 0.0144	 finalize: 0.0778
batch bounding time:  0.7118611335754395
Current worst splitting domains [lb, ub] (depth):
[-0.03254,   inf] (24), [-0.03113,   inf] (24), [-0.03017,   inf] (24), [-0.02949,   inf] (24), [-0.02883,   inf] (24), [-0.02816,   inf] (24), [-0.02809,   inf] (24), [-0.02730,   inf] (24), [-0.02713,   inf] (24), [-0.02705,   inf] (24), [-0.02662,   inf] (24), [-0.02601,   inf] (24), [-0.02589,   inf] (24), [-0.02579,   inf] (24), [-0.02562,   inf] (24), [-0.02513,   inf] (24), [-0.02493,   inf] (24), [-0.02453,   inf] (24), [-0.02449,   inf] (24), [-0.02427,   inf] (24), 
length of domains: 241
Total time: 0.9632	 pickout: 0.0248	 decision: 0.2073	 get_bound: 0.7125	 add_domain: 0.0186
Current lb:-0.032539252191782
1314 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.578861713409424

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([241, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([241, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 286] [1, 286] [1, 286] [1, 286] [1, 286] [1, 286] [1, 286] [1, 286] [1, 286] [1, 289] 
regular batch size: 2*241, diving batch size 1*0
best_l after optimization: 2.0401535034179688 with beta sum per layer: [0.0, 72.14118957519531, 3.8663265705108643]
alpha/beta optimization time: 0.6751620769500732
This batch time : update_bounds func: 0.7618	 prepare: 0.0424	 bound: 0.6755	 transfer: 0.0157	 finalize: 0.0270
Accumulated time: update_bounds func: 4.7739	 prepare: 0.1618	 bound: 4.4357	 transfer: 0.0157	 finalize: 0.1048
batch bounding time:  0.7625102996826172
Current worst splitting domains [lb, ub] (depth):
[-0.03128,   inf] (26), [-0.02943,   inf] (26), [-0.02855,   inf] (26), [-0.02821,   inf] (26), [-0.02749,   inf] (26), [-0.02690,   inf] (26), [-0.02636,   inf] (26), [-0.02605,   inf] (26), [-0.02549,   inf] (26), [-0.02490,   inf] (26), [-0.02442,   inf] (26), [-0.02437,   inf] (26), [-0.02420,   inf] (26), [-0.02398,   inf] (26), [-0.02384,   inf] (26), [-0.02332,   inf] (26), [-0.02298,   inf] (26), [-0.02296,   inf] (26), [-0.02272,   inf] (26), [-0.02249,   inf] (26), 
length of domains: 279
Total time: 1.0491	 pickout: 0.0341	 decision: 0.2297	 get_bound: 0.7633	 add_domain: 0.0220
Current lb:-0.03128194808959961
1796 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.63427186012268

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([279, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([279, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 361] [1, 361] [1, 361] [1, 361] [1, 361] [1, 361] [1, 361] [1, 361] [1, 361] [1, 361] 
regular batch size: 2*279, diving batch size 1*0
best_l after optimization: 0.9091535210609436 with beta sum per layer: [0.0, 76.15550994873047, 2.834364414215088]
alpha/beta optimization time: 0.714963436126709
This batch time : update_bounds func: 0.8201	 prepare: 0.0489	 bound: 0.7153	 transfer: 0.0203	 finalize: 0.0343
Accumulated time: update_bounds func: 5.5940	 prepare: 0.2106	 bound: 5.1510	 transfer: 0.0203	 finalize: 0.1391
batch bounding time:  0.8208231925964355
Current worst splitting domains [lb, ub] (depth):
[-0.03052,   inf] (28), [-0.02866,   inf] (28), [-0.02779,   inf] (28), [-0.02691,   inf] (28), [-0.02672,   inf] (28), [-0.02614,   inf] (28), [-0.02529,   inf] (28), [-0.02505,   inf] (28), [-0.02419,   inf] (28), [-0.02414,   inf] (28), [-0.02361,   inf] (28), [-0.02343,   inf] (28), [-0.02312,   inf] (28), [-0.02256,   inf] (28), [-0.02255,   inf] (28), [-0.02237,   inf] (28), [-0.02173,   inf] (28), [-0.02168,   inf] (28), [-0.02161,   inf] (28), [-0.02149,   inf] (28), 
length of domains: 257
Total time: 1.1118	 pickout: 0.0357	 decision: 0.2329	 get_bound: 0.8218	 add_domain: 0.0215
Current lb:-0.0305178165435791
2354 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.753998756408691

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([257, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([257, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 277] [1, 932] [1, 932] [1, 277] [1, 277] [1, 932] [1, 277] [1, 932] [1, 932] [1, 932] 
regular batch size: 2*257, diving batch size 1*0
best_l after optimization: 1.0348212718963623 with beta sum per layer: [0.0, 71.6075668334961, 0.0]
alpha/beta optimization time: 0.6917130947113037
This batch time : update_bounds func: 0.8500	 prepare: 0.0451	 bound: 0.6921	 transfer: 0.0140	 finalize: 0.0285
Accumulated time: update_bounds func: 6.4440	 prepare: 0.2557	 bound: 5.8431	 transfer: 0.0140	 finalize: 0.1676
batch bounding time:  0.8507537841796875
Current worst splitting domains [lb, ub] (depth):
[-0.02872,   inf] (30), [-0.02715,   inf] (30), [-0.02628,   inf] (30), [-0.02510,   inf] (30), [-0.02493,   inf] (30), [-0.02465,   inf] (30), [-0.02353,   inf] (30), [-0.02349,   inf] (30), [-0.02267,   inf] (30), [-0.02265,   inf] (30), [-0.02192,   inf] (30), [-0.02181,   inf] (30), [-0.02161,   inf] (30), [-0.02132,   inf] (30), [-0.02105,   inf] (30), [-0.02103,   inf] (30), [-0.02085,   inf] (30), [-0.02022,   inf] (30), [-0.02016,   inf] (30), [-0.02012,   inf] (30), 
length of domains: 262
Total time: 1.0768	 pickout: 0.0374	 decision: 0.1663	 get_bound: 0.8516	 add_domain: 0.0215
Current lb:-0.02871870994567871
2868 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.837815999984741

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([262, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([262, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 932] [1, 277] [1, 277] [1, 932] [1, 932] [1, 277] [1, 277] [1, 932] [1, 277] [1, 277] 
regular batch size: 2*262, diving batch size 1*0
best_l after optimization: 1.2459526062011719 with beta sum per layer: [0.0, 77.18357849121094, 0.0]
alpha/beta optimization time: 0.7063922882080078
This batch time : update_bounds func: 0.8987	 prepare: 0.0738	 bound: 0.7069	 transfer: 0.0166	 finalize: 0.0999
Accumulated time: update_bounds func: 7.3426	 prepare: 0.3295	 bound: 6.5500	 transfer: 0.0166	 finalize: 0.2676
batch bounding time:  0.8994531631469727
Current worst splitting domains [lb, ub] (depth):
[-0.02720,   inf] (32), [-0.02535,   inf] (32), [-0.02449,   inf] (32), [-0.02358,   inf] (32), [-0.02341,   inf] (32), [-0.02286,   inf] (32), [-0.02197,   inf] (32), [-0.02173,   inf] (32), [-0.02087,   inf] (32), [-0.02085,   inf] (32), [-0.02029,   inf] (32), [-0.02012,   inf] (32), [-0.01982,   inf] (32), [-0.01979,   inf] (32), [-0.01926,   inf] (32), [-0.01924,   inf] (32), [-0.01906,   inf] (32), [-0.01841,   inf] (32), [-0.01835,   inf] (32), [-0.01818,   inf] (32), 
length of domains: 272
Total time: 1.1666	 pickout: 0.0345	 decision: 0.2083	 get_bound: 0.9003	 add_domain: 0.0235
Current lb:-0.027201075106859207
3392 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.011909246444702

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([272, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([272, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 601] [1, 601] [1, 601] [1, 601] [1, 601] [1, 601] [1, 601] [1, 601] [1, 601] [1, 601] 
regular batch size: 2*272, diving batch size 1*0
best_l after optimization: 1.6569842100143433 with beta sum per layer: [0.0, 68.97962188720703, 0.0]
alpha/beta optimization time: 0.7050209045410156
This batch time : update_bounds func: 0.8006	 prepare: 0.0497	 bound: 0.7054	 transfer: 0.0144	 finalize: 0.0297
Accumulated time: update_bounds func: 8.1433	 prepare: 0.3792	 bound: 7.2553	 transfer: 0.0144	 finalize: 0.2973
batch bounding time:  0.8013677597045898
Current worst splitting domains [lb, ub] (depth):
[-0.02599,   inf] (34), [-0.02414,   inf] (34), [-0.02328,   inf] (34), [-0.02220,   inf] (34), [-0.02217,   inf] (34), [-0.02164,   inf] (34), [-0.02076,   inf] (34), [-0.02033,   inf] (34), [-0.01964,   inf] (34), [-0.01946,   inf] (34), [-0.01908,   inf] (34), [-0.01891,   inf] (34), [-0.01861,   inf] (34), [-0.01839,   inf] (34), [-0.01837,   inf] (34), [-0.01805,   inf] (34), [-0.01786,   inf] (34), [-0.01783,   inf] (34), [-0.01721,   inf] (34), [-0.01697,   inf] (34), 
length of domains: 315
Total time: 1.1028	 pickout: 0.0367	 decision: 0.1782	 get_bound: 0.8023	 add_domain: 0.0856
Current lb:-0.02599019557237625
3936 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.121774673461914

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([315, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([315, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 772] [1, 772] [1, 772] [1, 772] [1, 772] [1, 772] [1, 772] [1, 772] [1, 772] [1, 772] 
regular batch size: 2*315, diving batch size 1*0
best_l after optimization: 1.720871925354004 with beta sum per layer: [0.0, 66.11186218261719, 0.0]
alpha/beta optimization time: 0.7508928775787354
This batch time : update_bounds func: 0.9345	 prepare: 0.0552	 bound: 0.7513	 transfer: 0.0208	 finalize: 0.1057
Accumulated time: update_bounds func: 9.0778	 prepare: 0.4344	 bound: 8.0066	 transfer: 0.0208	 finalize: 0.4030
batch bounding time:  0.9354071617126465
Current worst splitting domains [lb, ub] (depth):
[-0.02472,   inf] (36), [-0.02287,   inf] (36), [-0.02201,   inf] (36), [-0.02093,   inf] (36), [-0.02090,   inf] (36), [-0.02036,   inf] (36), [-0.01948,   inf] (36), [-0.01905,   inf] (36), [-0.01836,   inf] (36), [-0.01828,   inf] (36), [-0.01819,   inf] (36), [-0.01780,   inf] (36), [-0.01764,   inf] (36), [-0.01711,   inf] (36), [-0.01677,   inf] (36), [-0.01657,   inf] (36), [-0.01655,   inf] (36), [-0.01631,   inf] (36), [-0.01593,   inf] (36), [-0.01566,   inf] (36), 
length of domains: 370
Total time: 1.2078	 pickout: 0.0409	 decision: 0.1939	 get_bound: 0.9367	 add_domain: 0.0364
Current lb:-0.024715760722756386
4566 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.33779788017273

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([370, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([370, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 281] [1, 281] [1, 281] [1, 281] [1, 281] [1, 281] [1, 281] [1, 281] [1, 281] [1, 281] 
regular batch size: 2*370, diving batch size 1*0
best_l after optimization: 1.4979004859924316 with beta sum per layer: [0.0, 65.03936767578125, 0.0]
alpha/beta optimization time: 0.7905275821685791
This batch time : update_bounds func: 0.9252	 prepare: 0.0668	 bound: 0.7909	 transfer: 0.0243	 finalize: 0.0412
Accumulated time: update_bounds func: 10.0030	 prepare: 0.5012	 bound: 8.7974	 transfer: 0.0243	 finalize: 0.4443
batch bounding time:  0.926093339920044
Current worst splitting domains [lb, ub] (depth):
[-0.02137,   inf] (38), [-0.01953,   inf] (38), [-0.01915,   inf] (38), [-0.01866,   inf] (38), [-0.01758,   inf] (38), [-0.01730,   inf] (38), [-0.01702,   inf] (38), [-0.01692,   inf] (38), [-0.01645,   inf] (38), [-0.01627,   inf] (38), [-0.01614,   inf] (38), [-0.01537,   inf] (38), [-0.01508,   inf] (38), [-0.01502,   inf] (38), [-0.01481,   inf] (38), [-0.01458,   inf] (38), [-0.01447,   inf] (38), [-0.01442,   inf] (38), [-0.01429,   inf] (38), [-0.01421,   inf] (38), 
length of domains: 411
Total time: 1.2887	 pickout: 0.0492	 decision: 0.2727	 get_bound: 0.9273	 add_domain: 0.0395
Current lb:-0.02137123793363571
5306 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.636301279067993

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([411, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([411, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1003] [1, 1003] [1, 1003] [1, 1003] [1, 1003] [1, 1003] [1, 1003] [1, 1003] [1, 1003] [1, 1003] 
regular batch size: 2*411, diving batch size 1*0
best_l after optimization: 1.2045323848724365 with beta sum per layer: [0.0, 59.27775955200195, 0.0]
alpha/beta optimization time: 0.8628323078155518
This batch time : update_bounds func: 1.0015	 prepare: 0.0716	 bound: 0.8632	 transfer: 0.0188	 finalize: 0.0459
Accumulated time: update_bounds func: 11.0044	 prepare: 0.5728	 bound: 9.6606	 transfer: 0.0188	 finalize: 0.4902
batch bounding time:  1.0023889541625977
Current worst splitting domains [lb, ub] (depth):
[-0.01923,   inf] (40), [-0.01739,   inf] (40), [-0.01696,   inf] (40), [-0.01653,   inf] (40), [-0.01545,   inf] (40), [-0.01518,   inf] (40), [-0.01512,   inf] (40), [-0.01501,   inf] (40), [-0.01480,   inf] (40), [-0.01426,   inf] (40), [-0.01414,   inf] (40), [-0.01400,   inf] (40), [-0.01334,   inf] (40), [-0.01317,   inf] (40), [-0.01301,   inf] (40), [-0.01294,   inf] (40), [-0.01291,   inf] (40), [-0.01274,   inf] (40), [-0.01248,   inf] (40), [-0.01243,   inf] (40), 
length of domains: 428
Total time: 1.3872	 pickout: 0.0534	 decision: 0.2887	 get_bound: 1.0037	 add_domain: 0.0414
Current lb:-0.019231319427490234
6128 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.034178495407104

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([428, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([428, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 352] [1, 352] [1, 295] [1, 352] [1, 352] [1, 352] [1, 295] [1, 995] [1, 295] [1, 295] 
regular batch size: 2*428, diving batch size 1*0
best_l after optimization: 0.8499441146850586 with beta sum per layer: [0.0, 58.80706787109375, 0.0]
alpha/beta optimization time: 0.859736442565918
This batch time : update_bounds func: 1.0136	 prepare: 0.0779	 bound: 0.8601	 transfer: 0.0258	 finalize: 0.0477
Accumulated time: update_bounds func: 12.0180	 prepare: 0.6507	 bound: 10.5207	 transfer: 0.0258	 finalize: 0.5379
batch bounding time:  1.01472806930542
Current worst splitting domains [lb, ub] (depth):
[-0.01737,   inf] (42), [-0.01552,   inf] (42), [-0.01523,   inf] (42), [-0.01466,   inf] (42), [-0.01391,   inf] (42), [-0.01358,   inf] (42), [-0.01332,   inf] (42), [-0.01332,   inf] (42), [-0.01330,   inf] (42), [-0.01307,   inf] (42), [-0.01246,   inf] (42), [-0.01240,   inf] (42), [-0.01214,   inf] (42), [-0.01206,   inf] (42), [-0.01147,   inf] (42), [-0.01131,   inf] (42), [-0.01120,   inf] (42), [-0.01118,   inf] (42), [-0.01116,   inf] (42), [-0.01103,   inf] (42), 
length of domains: 411
Total time: 1.4874	 pickout: 0.0546	 decision: 0.3693	 get_bound: 1.0162	 add_domain: 0.0472
Current lb:-0.01737046241760254
6984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.53917932510376

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([411, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([411, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 827] [1, 827] [1, 827] [1, 827] [1, 827] [1, 827] [1, 827] [1, 827] [1, 827] [1, 827] 
regular batch size: 2*411, diving batch size 1*0
best_l after optimization: -0.7336195707321167 with beta sum per layer: [0.0, 49.30121612548828, 0.0]
alpha/beta optimization time: 0.8409249782562256
This batch time : update_bounds func: 0.9834	 prepare: 0.0717	 bound: 0.8413	 transfer: 0.0222	 finalize: 0.0462
Accumulated time: update_bounds func: 13.0014	 prepare: 0.7224	 bound: 11.3620	 transfer: 0.0222	 finalize: 0.5841
batch bounding time:  0.9844491481781006
Current worst splitting domains [lb, ub] (depth):
[-0.01623,   inf] (44), [-0.01438,   inf] (44), [-0.01410,   inf] (44), [-0.01352,   inf] (44), [-0.01265,   inf] (44), [-0.01244,   inf] (44), [-0.01218,   inf] (44), [-0.01218,   inf] (44), [-0.01216,   inf] (44), [-0.01193,   inf] (44), [-0.01132,   inf] (44), [-0.01125,   inf] (44), [-0.01084,   inf] (44), [-0.01080,   inf] (44), [-0.01033,   inf] (44), [-0.01017,   inf] (44), [-0.01004,   inf] (44), [-0.01002,   inf] (44), [-0.00994,   inf] (44), [-0.00989,   inf] (44), 
length of domains: 312
Total time: 1.3994	 pickout: 0.0643	 decision: 0.3178	 get_bound: 0.9858	 add_domain: 0.0314
Current lb:-0.016230106353759766
7806 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 19.95034384727478

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([312, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([312, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 884] [1, 884] [1, 884] [1, 884] [1, 884] [1, 884] [1, 884] [1, 884] [1, 884] [1, 884] 
regular batch size: 2*312, diving batch size 1*0
best_l after optimization: -1.9024865627288818 with beta sum per layer: [0.0, 31.589155197143555, 0.0]
alpha/beta optimization time: 0.7431268692016602
This batch time : update_bounds func: 0.8571	 prepare: 0.0548	 bound: 0.7435	 transfer: 0.0191	 finalize: 0.0382
Accumulated time: update_bounds func: 13.8585	 prepare: 0.7772	 bound: 12.1055	 transfer: 0.0191	 finalize: 0.6223
batch bounding time:  0.8579518795013428
Current worst splitting domains [lb, ub] (depth):
[-0.01505,   inf] (46), [-0.01321,   inf] (46), [-0.01292,   inf] (46), [-0.01235,   inf] (46), [-0.01139,   inf] (46), [-0.01127,   inf] (46), [-0.01101,   inf] (46), [-0.01100,   inf] (46), [-0.01099,   inf] (46), [-0.01076,   inf] (46), [-0.01015,   inf] (46), [-0.01006,   inf] (46), [-0.00965,   inf] (46), [-0.00953,   inf] (46), [-0.00915,   inf] (46), [-0.00900,   inf] (46), [-0.00886,   inf] (46), [-0.00884,   inf] (46), [-0.00872,   inf] (46), [-0.00867,   inf] (46), 
length of domains: 242
Total time: 1.1735	 pickout: 0.0414	 decision: 0.2448	 get_bound: 0.8590	 add_domain: 0.0283
Current lb:-0.015052318572998047
8430 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 21.133591413497925

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([242, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([242, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 36] [1, 36] [1, 36] [1, 36] [1, 36] [1, 36] [1, 36] [1, 36] [1, 36] [1, 36] 
regular batch size: 2*242, diving batch size 1*0
best_l after optimization: -0.006519988179206848 with beta sum per layer: [0.0, 27.167396545410156, 0.0]
alpha/beta optimization time: 0.6719567775726318
This batch time : update_bounds func: 0.7545	 prepare: 0.0427	 bound: 0.6723	 transfer: 0.0120	 finalize: 0.0263
Accumulated time: update_bounds func: 14.6130	 prepare: 0.8199	 bound: 12.7778	 transfer: 0.0120	 finalize: 0.6486
batch bounding time:  0.755164384841919
Current worst splitting domains [lb, ub] (depth):
[-0.01446,   inf] (48), [-0.01262,   inf] (48), [-0.01233,   inf] (48), [-0.01174,   inf] (48), [-0.01076,   inf] (48), [-0.01068,   inf] (48), [-0.01042,   inf] (48), [-0.01042,   inf] (48), [-0.01017,   inf] (48), [-0.00990,   inf] (48), [-0.00955,   inf] (48), [-0.00947,   inf] (48), [-0.00906,   inf] (48), [-0.00891,   inf] (48), [-0.00858,   inf] (48), [-0.00829,   inf] (48), [-0.00826,   inf] (48), [-0.00804,   inf] (48), [-0.00791,   inf] (48), [-0.00772,   inf] (48), 
length of domains: 207
Total time: 1.0403	 pickout: 0.0323	 decision: 0.2284	 get_bound: 0.7560	 add_domain: 0.0236
Current lb:-0.014463186264038086
8914 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 22.1821928024292

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([207, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([207, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 344] [1, 344] [1, 344] [1, 344] [1, 344] [1, 344] [1, 344] [1, 344] [1, 344] [1, 344] 
regular batch size: 2*207, diving batch size 1*0
best_l after optimization: -0.2572968602180481 with beta sum per layer: [0.0, 20.140644073486328, 0.0]
alpha/beta optimization time: 0.643831729888916
This batch time : update_bounds func: 0.7148	 prepare: 0.0370	 bound: 0.6442	 transfer: 0.0094	 finalize: 0.0231
Accumulated time: update_bounds func: 15.3278	 prepare: 0.8568	 bound: 13.4220	 transfer: 0.0094	 finalize: 0.6717
batch bounding time:  0.7154145240783691
Current worst splitting domains [lb, ub] (depth):
[-0.01422,   inf] (50), [-0.01237,   inf] (50), [-0.01191,   inf] (50), [-0.01150,   inf] (50), [-0.01043,   inf] (50), [-0.01018,   inf] (50), [-0.01000,   inf] (50), [-0.00991,   inf] (50), [-0.00978,   inf] (50), [-0.00956,   inf] (50), [-0.00913,   inf] (50), [-0.00905,   inf] (50), [-0.00882,   inf] (50), [-0.00833,   inf] (50), [-0.00805,   inf] (50), [-0.00788,   inf] (50), [-0.00787,   inf] (50), [-0.00757,   inf] (50), [-0.00746,   inf] (50), [-0.00742,   inf] (50), 
length of domains: 179
Total time: 0.9497	 pickout: 0.0271	 decision: 0.1873	 get_bound: 0.7161	 add_domain: 0.0192
Current lb:-0.014222300611436367
9328 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 23.13795757293701

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([179, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([179, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 940] [1, 940] [1, 940] [1, 940] [1, 940] [1, 940] [1, 940] [1, 940] [1, 352] [1, 940] 
regular batch size: 2*179, diving batch size 1*0
best_l after optimization: -0.04398263618350029 with beta sum per layer: [0.0, 18.16082191467285, 0.0]
alpha/beta optimization time: 0.6234633922576904
This batch time : update_bounds func: 0.6815	 prepare: 0.0320	 bound: 0.6238	 transfer: 0.0054	 finalize: 0.0195
Accumulated time: update_bounds func: 16.0093	 prepare: 0.8888	 bound: 14.0458	 transfer: 0.0054	 finalize: 0.6911
batch bounding time:  0.6820685863494873
Current worst splitting domains [lb, ub] (depth):
[-0.01146,   inf] (52), [-0.00963,   inf] (52), [-0.00952,   inf] (52), [-0.00916,   inf] (52), [-0.00876,   inf] (52), [-0.00820,   inf] (52), [-0.00767,   inf] (52), [-0.00740,   inf] (52), [-0.00739,   inf] (52), [-0.00727,   inf] (52), [-0.00723,   inf] (52), [-0.00717,   inf] (52), [-0.00683,   inf] (52), [-0.00655,   inf] (52), [-0.00640,   inf] (52), [-0.00631,   inf] (52), [-0.00628,   inf] (52), [-0.00606,   inf] (52), [-0.00597,   inf] (52), [-0.00574,   inf] (52), 
length of domains: 139
Total time: 0.8517	 pickout: 0.0240	 decision: 0.1295	 get_bound: 0.6827	 add_domain: 0.0155
Current lb:-0.011460304260253906
9686 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 23.994911432266235

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([139, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([139, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 15] [2, 15] [2, 15] [2, 15] [2, 15] [2, 15] [2, 15] [2, 15] [2, 15] [2, 15] 
regular batch size: 2*139, diving batch size 1*0
best_l after optimization: -13.12222957611084 with beta sum per layer: [0.0, 13.925440788269043, 0.0]
alpha/beta optimization time: 0.6180288791656494
This batch time : update_bounds func: 0.6705	 prepare: 0.0265	 bound: 0.6184	 transfer: 0.0092	 finalize: 0.0157
Accumulated time: update_bounds func: 16.6798	 prepare: 0.9154	 bound: 14.6641	 transfer: 0.0092	 finalize: 0.7068
batch bounding time:  0.6709601879119873
Current worst splitting domains [lb, ub] (depth):
[-0.01079,   inf] (54), [-0.00897,   inf] (54), [-0.00870,   inf] (54), [-0.00849,   inf] (54), [-0.00812,   inf] (54), [-0.00754,   inf] (54), [-0.00703,   inf] (54), [-0.00671,   inf] (54), [-0.00661,   inf] (54), [-0.00655,   inf] (54), [-0.00649,   inf] (54), [-0.00640,   inf] (54), [-0.00616,   inf] (54), [-0.00576,   inf] (54), [-0.00572,   inf] (54), [-0.00565,   inf] (54), [-0.00564,   inf] (54), [-0.00539,   inf] (54), [-0.00521,   inf] (54), [-0.00494,   inf] (54), 
length of domains: 107
Total time: 0.8659	 pickout: 0.0185	 decision: 0.1621	 get_bound: 0.6714	 add_domain: 0.0138
Current lb:-0.010794639587402344
9964 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 24.86467671394348

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([107, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([107, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 295] [1, 295] [1, 295] [1, 352] [1, 295] [1, 940] [1, 295] [1, 295] [1, 352] [1, 295] 
regular batch size: 2*107, diving batch size 1*0
best_l after optimization: -0.16661357879638672 with beta sum per layer: [0.0, 11.777469635009766, 0.0]
alpha/beta optimization time: 0.6039974689483643
This batch time : update_bounds func: 0.6436	 prepare: 0.0198	 bound: 0.6044	 transfer: 0.0069	 finalize: 0.0119
Accumulated time: update_bounds func: 17.3234	 prepare: 0.9352	 bound: 15.2685	 transfer: 0.0069	 finalize: 0.7187
batch bounding time:  0.6440074443817139
Current worst splitting domains [lb, ub] (depth):
[-0.00907,   inf] (56), [-0.00719,   inf] (56), [-0.00685,   inf] (56), [-0.00634,   inf] (56), [-0.00608,   inf] (56), [-0.00530,   inf] (56), [-0.00499,   inf] (56), [-0.00479,   inf] (56), [-0.00477,   inf] (56), [-0.00460,   inf] (56), [-0.00458,   inf] (56), [-0.00440,   inf] (56), [-0.00419,   inf] (56), [-0.00386,   inf] (56), [-0.00375,   inf] (56), [-0.00372,   inf] (56), [-0.00367,   inf] (56), [-0.00365,   inf] (56), [-0.00343,   inf] (56), [-0.00335,   inf] (56), 
length of domains: 75
Total time: 0.7638	 pickout: 0.0147	 decision: 0.0959	 get_bound: 0.6443	 add_domain: 0.0089
Current lb:-0.009073531255126
10178 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 25.63189935684204

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([75, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([75, 8, 16, 16])/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:25: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1627336316785/work/torch/csrc/utils/tensor_numpy.cpp:143.)
  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))
 post split depth:  1
splitting decisions: 
split level 0: [1, 359] [1, 359] [1, 359] [1, 813] [1, 359] [1, 359] [1, 359] [1, 359] [1, 359] [1, 359] 
regular batch size: 2*75, diving batch size 1*0
best_l after optimization: -0.16911935806274414 with beta sum per layer: [0.0, 8.162667274475098, 0.0]
alpha/beta optimization time: 0.5941300392150879
This batch time : update_bounds func: 0.6203	 prepare: 0.0143	 bound: 0.5945	 transfer: 0.0029	 finalize: 0.0081
Accumulated time: update_bounds func: 17.9437	 prepare: 0.9495	 bound: 15.8630	 transfer: 0.0029	 finalize: 0.7268
batch bounding time:  0.6206378936767578
Current worst splitting domains [lb, ub] (depth):
[-0.00802,   inf] (58), [-0.00609,   inf] (58), [-0.00576,   inf] (58), [-0.00503,   inf] (58), [-0.00498,   inf] (58), [-0.00428,   inf] (58), [-0.00394,   inf] (58), [-0.00374,   inf] (58), [-0.00372,   inf] (58), [-0.00345,   inf] (58), [-0.00336,   inf] (58), [-0.00310,   inf] (58), [-0.00283,   inf] (58), [-0.00277,   inf] (58), [-0.00267,   inf] (58), [-0.00262,   inf] (58), [-0.00255,   inf] (58), [-0.00237,   inf] (58), [-0.00235,   inf] (58), [-0.00204,   inf] (58), 
length of domains: 47
Total time: 0.7201	 pickout: 0.0107	 decision: 0.0826	 get_bound: 0.6209	 add_domain: 0.0058
Current lb:-0.008019424974918365
10328 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 26.354399919509888

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([47, 8, 16, 16]) pre split depth:  2
batch:  torch.Size([47, 8, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [1, 890] [1, 813] [1, 890] [1, 890] [1, 359] [1, 890] [1, 890] [1, 890] [1, 890] [1, 813] 
split level 1: [1, 995] [1, 890] [1, 813] [1, 813] [1, 890] [1, 995] [1, 813] [1, 995] [1, 813] [1, 890] 
regular batch size: 2*94, diving batch size 1*0
best_l after optimization: -0.6420074105262756 with beta sum per layer: [0.0, 9.456275939941406, 0.0]
alpha/beta optimization time: 0.5962035655975342
This batch time : update_bounds func: 0.6296	 prepare: 0.0173	 bound: 0.5965	 transfer: 0.0045	 finalize: 0.0107
Accumulated time: update_bounds func: 18.5733	 prepare: 0.9668	 bound: 16.4596	 transfer: 0.0045	 finalize: 0.7375
batch bounding time:  0.6299726963043213
Current worst splitting domains [lb, ub] (depth):
[-0.00492,   inf] (61), [-0.00366,   inf] (61), [-0.00318,   inf] (61), [-0.00275,   inf] (61), [-0.00246,   inf] (61), [-0.00170,   inf] (61), [-0.00137,   inf] (61), [-0.00117,   inf] (61), [-0.00115,   inf] (61), [-0.00101,   inf] (61), [-0.00067,   inf] (61), [-0.00065,   inf] (61), [-0.00055,   inf] (61), [-0.00019,   inf] (61), [-0.00013,   inf] (61), 
length of domains: 15
Total time: 0.7931	 pickout: 0.0067	 decision: 0.1392	 get_bound: 0.6450	 add_domain: 0.0022
Current lb:-0.004917621612548828
10516 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 27.149625301361084

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([15, 8, 16, 16]) pre split depth:  3
batch:  torch.Size([15, 8, 16, 16]) post split depth:  3
splitting decisions: 
split level 0: [1, 593] [1, 593] [1, 593] [1, 593] [1, 593] [1, 593] [1, 995] [1, 593] [1, 593] [1, 593] 
split level 1: [1, 813] [1, 995] [1, 995] [1, 995] [1, 995] [1, 813] [0, 1864] [1, 813] [1, 995] [1, 995] 
split level 2: [0, 1864] [0, 1864] [0, 1864] [1, 351] [0, 1864] [0, 1864] [1, 288] [1, 351] [1, 288] [0, 1864] 
regular batch size: 2*60, diving batch size 1*0
best_l after optimization: -0.7193906307220459 with beta sum per layer: [0.0, 5.021230697631836, 0.0]
alpha/beta optimization time: 0.5662603378295898
This batch time : update_bounds func: 0.5912	 prepare: 0.0120	 bound: 0.5666	 transfer: 0.0053	 finalize: 0.0068
Accumulated time: update_bounds func: 19.1645	 prepare: 0.9788	 bound: 17.0262	 transfer: 0.0053	 finalize: 0.7443
batch bounding time:  0.5915267467498779
Current worst splitting domains [lb, ub] (depth):
[-0.00255,   inf] (65), [-0.00077,   inf] (65), [-0.00007,   inf] (65), 
length of domains: 3
Total time: 0.6702	 pickout: 0.0041	 decision: 0.0595	 get_bound: 0.6060	 add_domain: 0.0006
Current lb:-0.002554843667894602
10636 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 27.821229696273804

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3, 8, 16, 16]) pre split depth:  6
batch:  torch.Size([3, 8, 16, 16]) post split depth:  6
splitting decisions: 
split level 0: [1, 288] [1, 288] [1, 311] 
split level 1: [2, 78] [2, 78] [1, 288] 
split level 2: [1, 280] [1, 280] [2, 78] 
split level 3: [1, 930] [1, 351] [1, 280] 
split level 4: [1, 351] [1, 930] [1, 930] 
split level 5: [1, 972] [1, 972] [1, 351] 
regular batch size: 2*96, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -2.5428054332733154 with beta sum per layer: [0.0, 7.602015495300293, 0.0]
alpha/beta optimization time: 0.008592605590820312
This batch time : update_bounds func: 0.0443	 prepare: 0.0195	 bound: 0.0089	 transfer: 0.0048	 finalize: 0.0106
Accumulated time: update_bounds func: 19.2089	 prepare: 0.9983	 bound: 17.0351	 transfer: 0.0048	 finalize: 0.7549
batch bounding time:  0.0445706844329834
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.1299	 pickout: 0.0011	 decision: 0.0537	 get_bound: 0.0750	 add_domain: 0.0001
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 27.95280623435974

Image 0 against label 4 verification end, Time cost: 28.00618004798889
##### [0] True label: 5, Tested against: 6, onnx_path: nets/cifar_base_kw.onnx, vnnlib_path: vnnlib/cifar_base_kw-img4631-eps0.016339869281045753.vnnlib ######
init opt crown verified for label 6 with bound 0.9866040945053101
Image 0 against label 6 verification end, Time cost: 0.00029158592224121094
##### [0] True label: 5, Tested against: 7, onnx_path: nets/cifar_base_kw.onnx, vnnlib_path: vnnlib/cifar_base_kw-img4631-eps0.016339869281045753.vnnlib ######
init opt crown verified for label 7 with bound 1.0897454023361206
Image 0 against label 7 verification end, Time cost: 0.0002911090850830078
##### [0] True label: 5, Tested against: 8, onnx_path: nets/cifar_base_kw.onnx, vnnlib_path: vnnlib/cifar_base_kw-img4631-eps0.016339869281045753.vnnlib ######
init opt crown verified for label 8 with bound 2.1250362396240234
Image 0 against label 8 verification end, Time cost: 0.0002841949462890625
##### [0] True label: 5, Tested against: 9, onnx_path: nets/cifar_base_kw.onnx, vnnlib_path: vnnlib/cifar_base_kw-img4631-eps0.016339869281045753.vnnlib ######
init opt crown verified for label 9 with bound 3.894582748413086
Image 0 against label 9 verification end, Time cost: 0.00027871131896972656
Result: safe-bab in 41.6937 seconds


[[    0.             2.95120931     0.             0.00031042
      0.        ]
 [    0.             2.22696662     0.             0.00031781
      1.        ]
 [    0.             1.04794943     0.             0.00033164
      2.        ]
 [    0.             0.29784769     0.             0.00030565
      3.        ]
 [    0.             0.0000001  10828.            28.00618005
      4.        ]
 [    0.             0.98660409     0.             0.00029159
      6.        ]
 [    0.             1.0897454      0.             0.00029111
      7.        ]
 [    0.             2.12503624     0.             0.00028419
      8.        ]
 [    0.             3.89458275     0.             0.00027871
      9.        ]]
############# Summary #############
Final verified acc: 100.0% [total 1 examples]
Total verification count: 1 , total verified safe: 1 , verified unsafe: 0 , timeout: 0
mean time [total:1]: 28.008591175079346
mean time [cnt:1]: 28.008591175079346
max time 41.69367051124573
safe-bab (total 1): [0]
