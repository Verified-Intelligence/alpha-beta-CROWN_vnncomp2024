Building native CUDA modules...
/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
  csv_name: oval21_instances.csv
  onnx_path: null
  vnnlib_path: null
  results_file: null
  root_path: ../../../../../vnncomp2021/benchmarks/oval21
model:
  path: null
  name: mnist_9_200
data:
  start: 13
  end: 14
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR
  data_filter_path: null
specification:
  type: lp
  norm: .inf
  epsilon: null
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 2000
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.01
    lr_decay: 0.98
    optimizer: adam
    iteration: 50
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 360
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 10
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:07:03 2022 on ubuntu
saving results to vnn-comp_[oval21_instances]_start=13_end=14_iter=50_b=2000_timeout=360_branching=kfsb-max-10_lra-init=0.1_lra=0.01_lrb=0.01_PGD=before.npz
customized start/end sample from 13 to 14

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
##### PGD attack: True label: 7, Tested against: [0, 1, 2, 3, 4, 5, 6, 8, 9] ######
pgd prediction: tensor([-2.3125, -2.8326,  1.3337,  1.5642,  1.0289,  1.8712,  0.4670,  1.9487,
        -2.3807, -0.6878], device='cuda:0', grad_fn=<SqueezeBackward1>)
attack margin tensor([4.2611, 4.7813, 0.6150, 0.3844, 0.9197, 0.0774, 1.4817,    inf, 4.3294,
        2.6365], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[-2.2024, -2.6508,  1.2148,  1.4181,  0.9993,  1.5446,  0.3752,  2.1426,
         -2.4388, -0.4027]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 3.0998,  2.2408, -0.1334, -0.2494,  0.1988, -0.2802, -0.0621,  2.6781,
          0.3316]], device='cuda:0') None
best_l after optimization: -9.472267150878906 with beta sum per layer: []
alpha/beta optimization time: 7.969431638717651
initial alpha-CROWN bounds: tensor([[ 3.1965e+00,  2.5253e+00, -2.9324e-03, -1.7383e-02,  3.1136e-01,
         -1.3824e-01,  1.6904e-01,  2.9049e+00,  5.2369e-01]], device='cuda:0',
       grad_fn=<AsStridedBackward>)
worst class: tensor(-0.1382, device='cuda:0', grad_fn=<MinBackward1>)
##### [0] True label: 7, Tested against: 0, onnx_path: nets/cifar_wide_kw.onnx, vnnlib_path: vnnlib/cifar_wide_kw-img6762-eps0.017908496732026144.vnnlib ######
init opt crown verified for label 0 with bound 3.196528196334839
Image 0 against label 0 verification end, Time cost: 0.00032639503479003906
##### [0] True label: 7, Tested against: 1, onnx_path: nets/cifar_wide_kw.onnx, vnnlib_path: vnnlib/cifar_wide_kw-img6762-eps0.017908496732026144.vnnlib ######
init opt crown verified for label 1 with bound 2.5253183841705322
Image 0 against label 1 verification end, Time cost: 0.0003228187561035156
##### [0] True label: 7, Tested against: 2, onnx_path: nets/cifar_wide_kw.onnx, vnnlib_path: vnnlib/cifar_wide_kw-img6762-eps0.017908496732026144.vnnlib ######
Model prediction is: tensor([[-2.2024, -2.6508,  1.2148,  1.4181,  0.9993,  1.5446,  0.3752,  2.1426,
         -2.4388, -0.4027]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 16, 16, 16]) != torch.Size([2, 9, 1, 16, 16, 16]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 8, 8]) != torch.Size([2, 9, 1, 32, 8, 8]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 16, 16])
1 /11 torch.Size([1, 32, 8, 8])
2 /14 torch.Size([1, 100])
best_l after optimization: 0.0029195963870733976 with beta sum per layer: []
alpha/beta optimization time: 1.9402494430541992
alpha-CROWN with fixed intermediate bounds: tensor([[-0.0029]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.0029195963870733976
layer 0 size torch.Size([4096]) unstable 825
layer 1 size torch.Size([2048]) unstable 300
layer 2 size torch.Size([100]) unstable 24
-----------------
# of unstable neurons: 1149
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 16, 16]) pre split depth:  7
batch:  torch.Size([1, 16, 16, 16]) post split depth:  7
splitting decisions: 
split level 0: [2, 56] 
split level 1: [2, 40] 
split level 2: [2, 6] 
split level 3: [2, 97] 
split level 4: [2, 78] 
split level 5: [2, 71] 
split level 6: [2, 75] 
regular batch size: 2*64, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -48.020328521728516 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.010089397430419922
This batch time : update_bounds func: 0.0360	 prepare: 0.0090	 bound: 0.0103	 transfer: 0.0094	 finalize: 0.0068
Accumulated time: update_bounds func: 0.0360	 prepare: 0.0090	 bound: 0.0103	 transfer: 0.0094	 finalize: 0.0068
batch bounding time:  0.03620195388793945
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.1024	 pickout: 0.0009	 decision: 0.0512	 get_bound: 0.0503	 add_domain: 0.0001
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 2.9931564331054688

Image 0 against label 2 verification end, Time cost: 3.048859119415283
##### [0] True label: 7, Tested against: 3, onnx_path: nets/cifar_wide_kw.onnx, vnnlib_path: vnnlib/cifar_wide_kw-img6762-eps0.017908496732026144.vnnlib ######
Model prediction is: tensor([[-2.2024, -2.6508,  1.2148,  1.4181,  0.9993,  1.5446,  0.3752,  2.1426,
         -2.4388, -0.4027]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 16, 16, 16]) != torch.Size([2, 9, 1, 16, 16, 16]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 8, 8]) != torch.Size([2, 9, 1, 32, 8, 8]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 16, 16])
1 /11 torch.Size([1, 32, 8, 8])
2 /14 torch.Size([1, 100])
best_l after optimization: 0.01734747365117073 with beta sum per layer: []
alpha/beta optimization time: 1.0060327053070068
alpha-CROWN with fixed intermediate bounds: tensor([[-0.0173]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.01734747365117073
layer 0 size torch.Size([4096]) unstable 825
layer 1 size torch.Size([2048]) unstable 300
layer 2 size torch.Size([100]) unstable 24
-----------------
# of unstable neurons: 1149
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 16, 16]) pre split depth:  7
batch:  torch.Size([1, 16, 16, 16]) post split depth:  7
splitting decisions: 
split level 0: [2, 71] 
split level 1: [2, 97] 
split level 2: [2, 28] 
split level 3: [2, 59] 
split level 4: [2, 75] 
split level 5: [2, 18] 
split level 6: [2, 56] 
regular batch size: 2*64, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -21.611000061035156 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.009922266006469727
This batch time : update_bounds func: 0.0302	 prepare: 0.0091	 bound: 0.0102	 transfer: 0.0038	 finalize: 0.0067
Accumulated time: update_bounds func: 0.0662	 prepare: 0.0181	 bound: 0.0205	 transfer: 0.0038	 finalize: 0.0135
batch bounding time:  0.03039693832397461
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0956	 pickout: 0.0008	 decision: 0.0504	 get_bound: 0.0443	 add_domain: 0.0001
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.1166491508483887

Image 0 against label 3 verification end, Time cost: 1.1779932975769043
##### [0] True label: 7, Tested against: 4, onnx_path: nets/cifar_wide_kw.onnx, vnnlib_path: vnnlib/cifar_wide_kw-img6762-eps0.017908496732026144.vnnlib ######
init opt crown verified for label 4 with bound 0.3113642632961273
Image 0 against label 4 verification end, Time cost: 0.00031447410583496094
##### [0] True label: 7, Tested against: 5, onnx_path: nets/cifar_wide_kw.onnx, vnnlib_path: vnnlib/cifar_wide_kw-img6762-eps0.017908496732026144.vnnlib ######
Model prediction is: tensor([[-2.2024, -2.6508,  1.2148,  1.4181,  0.9993,  1.5446,  0.3752,  2.1426,
         -2.4388, -0.4027]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 16, 16, 16]) != torch.Size([2, 9, 1, 16, 16, 16]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 8, 8]) != torch.Size([2, 9, 1, 32, 8, 8]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 16, 16])
1 /11 torch.Size([1, 32, 8, 8])
2 /14 torch.Size([1, 100])
best_l after optimization: 0.13821345567703247 with beta sum per layer: []
alpha/beta optimization time: 0.999159574508667
alpha-CROWN with fixed intermediate bounds: tensor([[-0.1382]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.13821345567703247
layer 0 size torch.Size([4096]) unstable 825
layer 1 size torch.Size([2048]) unstable 300
layer 2 size torch.Size([100]) unstable 24
-----------------
# of unstable neurons: 1149
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 16, 16]) pre split depth:  7
batch:  torch.Size([1, 16, 16, 16]) post split depth:  7
splitting decisions: 
split level 0: [2, 97] 
split level 1: [2, 71] 
split level 2: [2, 75] 
split level 3: [2, 56] 
split level 4: [2, 18] 
split level 5: [2, 28] 
split level 6: [2, 20] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -5.532548904418945 with beta sum per layer: [0.0, 0.0, 7.767711162567139]
alpha/beta optimization time: 0.6282331943511963
This batch time : update_bounds func: 0.6491	 prepare: 0.0095	 bound: 0.6285	 transfer: 0.0039	 finalize: 0.0068
Accumulated time: update_bounds func: 0.7153	 prepare: 0.0276	 bound: 0.6491	 transfer: 0.0039	 finalize: 0.0203
batch bounding time:  0.6494143009185791
Current worst splitting domains [lb, ub] (depth):
[-0.05644,   inf] (8), [-0.04398,   inf] (8), 
length of domains: 2
Total time: 0.7170	 pickout: 0.0008	 decision: 0.0526	 get_bound: 0.6633	 add_domain: 0.0002
Current lb:-0.0564434789121151
128 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.7311789989471436

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2, 16, 16, 16]) pre split depth:  6
batch:  torch.Size([2, 16, 16, 16]) post split depth:  6
splitting decisions: 
split level 0: [1, 1773] [1, 1773] 
split level 1: [1, 622] [1, 622] 
split level 2: [1, 630] [1, 630] 
split level 3: [1, 1297] [1, 1297] 
split level 4: [1, 1454] [1, 1289] 
split level 5: [1, 1289] [1, 1454] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 2.2925496101379395 with beta sum per layer: [0.0, 11.22199535369873, 4.849513530731201]
alpha/beta optimization time: 0.6192183494567871
This batch time : update_bounds func: 0.6501	 prepare: 0.0111	 bound: 0.6196	 transfer: 0.0112	 finalize: 0.0078
Accumulated time: update_bounds func: 1.3654	 prepare: 0.0387	 bound: 1.2686	 transfer: 0.0112	 finalize: 0.0281
batch bounding time:  0.650454044342041
Current worst splitting domains [lb, ub] (depth):
[-0.03773,   inf] (15), [-0.03770,   inf] (15), [-0.03541,   inf] (15), [-0.03511,   inf] (15), [-0.03509,   inf] (15), [-0.03462,   inf] (15), [-0.03459,   inf] (15), [-0.03382,   inf] (15), [-0.03380,   inf] (15), [-0.03292,   inf] (15), [-0.03281,   inf] (15), [-0.03231,   inf] (15), [-0.03231,   inf] (15), [-0.03188,   inf] (15), [-0.03152,   inf] (15), [-0.03032,   inf] (15), [-0.02983,   inf] (15), [-0.02967,   inf] (15), [-0.02923,   inf] (15), [-0.02917,   inf] (15), 
length of domains: 124
Total time: 0.7267	 pickout: 0.0009	 decision: 0.0528	 get_bound: 0.6653	 add_domain: 0.0077
Current lb:-0.03773142769932747
256 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.4582901000976562

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([124, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([124, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1314] [1, 1314] [1, 1314] [1, 1314] [1, 1314] [1, 1314] [1, 1314] [1, 1314] [1, 1314] [1, 1314] 
regular batch size: 2*124, diving batch size 1*0
best_l after optimization: 3.239140748977661 with beta sum per layer: [0.0, 25.87549591064453, 9.268891334533691]
alpha/beta optimization time: 0.6709644794464111
This batch time : update_bounds func: 0.7289	 prepare: 0.0251	 bound: 0.6714	 transfer: 0.0184	 finalize: 0.0134
Accumulated time: update_bounds func: 2.0943	 prepare: 0.0638	 bound: 1.9400	 transfer: 0.0184	 finalize: 0.0415
batch bounding time:  0.7293689250946045
Current worst splitting domains [lb, ub] (depth):
[-0.03615,   inf] (17), [-0.03613,   inf] (17), [-0.03374,   inf] (17), [-0.03362,   inf] (17), [-0.03359,   inf] (17), [-0.03302,   inf] (17), [-0.03299,   inf] (17), [-0.03231,   inf] (17), [-0.03228,   inf] (17), [-0.03121,   inf] (17), [-0.03109,   inf] (17), [-0.03072,   inf] (17), [-0.03062,   inf] (17), [-0.03029,   inf] (17), [-0.02991,   inf] (17), [-0.02957,   inf] (17), [-0.02954,   inf] (17), [-0.02857,   inf] (17), [-0.02816,   inf] (17), [-0.02798,   inf] (17), 
length of domains: 217
Total time: 0.8840	 pickout: 0.0201	 decision: 0.1203	 get_bound: 0.7298	 add_domain: 0.0138
Current lb:-0.036149583756923676
504 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.344923973083496

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([217, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([217, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 606] [1, 606] [1, 606] [1, 606] [1, 606] [1, 606] [1, 606] [1, 606] [1, 606] [1, 606] 
regular batch size: 2*217, diving batch size 1*0
best_l after optimization: 4.020226955413818 with beta sum per layer: [0.0, 57.35227966308594, 14.232909202575684]
alpha/beta optimization time: 0.809546947479248
This batch time : update_bounds func: 0.9029	 prepare: 0.0403	 bound: 0.8099	 transfer: 0.0274	 finalize: 0.0239
Accumulated time: update_bounds func: 2.9972	 prepare: 0.1041	 bound: 2.7499	 transfer: 0.0274	 finalize: 0.0653
batch bounding time:  0.9035758972167969
Current worst splitting domains [lb, ub] (depth):
[-0.03464,   inf] (19), [-0.03462,   inf] (19), [-0.03220,   inf] (19), [-0.03215,   inf] (19), [-0.03212,   inf] (19), [-0.03151,   inf] (19), [-0.03148,   inf] (19), [-0.03085,   inf] (19), [-0.03083,   inf] (19), [-0.02971,   inf] (19), [-0.02944,   inf] (19), [-0.02922,   inf] (19), [-0.02908,   inf] (19), [-0.02880,   inf] (19), [-0.02858,   inf] (19), [-0.02856,   inf] (19), [-0.02843,   inf] (19), [-0.02696,   inf] (19), [-0.02670,   inf] (19), [-0.02632,   inf] (19), 
length of domains: 351
Total time: 1.2194	 pickout: 0.0333	 decision: 0.2588	 get_bound: 0.9044	 add_domain: 0.0229
Current lb:-0.03464489430189133
938 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.5688323974609375

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([351, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([351, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 846] [1, 846] [1, 846] [1, 846] [1, 846] [1, 846] [1, 846] [1, 846] [1, 846] [1, 846] 
regular batch size: 2*351, diving batch size 1*0
best_l after optimization: 4.364568710327148 with beta sum per layer: [0.0, 101.01688385009766, 18.725950241088867]
alpha/beta optimization time: 1.0447323322296143
This batch time : update_bounds func: 1.1875	 prepare: 0.0601	 bound: 1.0451	 transfer: 0.0418	 finalize: 0.0388
Accumulated time: update_bounds func: 4.1847	 prepare: 0.1642	 bound: 3.7950	 transfer: 0.0418	 finalize: 0.1042
batch bounding time:  1.1883437633514404
Current worst splitting domains [lb, ub] (depth):
[-0.03382,   inf] (21), [-0.03380,   inf] (21), [-0.03137,   inf] (21), [-0.03133,   inf] (21), [-0.03131,   inf] (21), [-0.03068,   inf] (21), [-0.03065,   inf] (21), [-0.03005,   inf] (21), [-0.03002,   inf] (21), [-0.02888,   inf] (21), [-0.02860,   inf] (21), [-0.02839,   inf] (21), [-0.02823,   inf] (21), [-0.02800,   inf] (21), [-0.02761,   inf] (21), [-0.02709,   inf] (21), [-0.02707,   inf] (21), [-0.02612,   inf] (21), [-0.02588,   inf] (21), [-0.02548,   inf] (21), 
length of domains: 492
Total time: 1.5693	 pickout: 0.0534	 decision: 0.2927	 get_bound: 1.1895	 add_domain: 0.0337
Current lb:-0.033822838217020035
1640 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.145931959152222

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([492, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([492, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1719] [1, 1719] [1, 1719] [1, 1719] [1, 1719] [1, 1719] [1, 1719] [1, 1719] [1, 1719] [1, 1719] 
regular batch size: 2*492, diving batch size 1*0
best_l after optimization: 4.406594276428223 with beta sum per layer: [0.0, 139.14306640625, 25.43044662475586]
alpha/beta optimization time: 1.3589894771575928
This batch time : update_bounds func: 1.7134	 prepare: 0.1368	 bound: 1.3595	 transfer: 0.0727	 finalize: 0.1418
Accumulated time: update_bounds func: 5.8981	 prepare: 0.3010	 bound: 5.1545	 transfer: 0.0727	 finalize: 0.2460
batch bounding time:  1.7147421836853027
Current worst splitting domains [lb, ub] (depth):
[-0.03346,   inf] (23), [-0.03342,   inf] (23), [-0.03098,   inf] (23), [-0.03092,   inf] (23), [-0.03087,   inf] (23), [-0.03031,   inf] (23), [-0.03026,   inf] (23), [-0.02969,   inf] (23), [-0.02964,   inf] (23), [-0.02838,   inf] (23), [-0.02808,   inf] (23), [-0.02786,   inf] (23), [-0.02773,   inf] (23), [-0.02746,   inf] (23), [-0.02711,   inf] (23), [-0.02672,   inf] (23), [-0.02667,   inf] (23), [-0.02559,   inf] (23), [-0.02534,   inf] (23), [-0.02494,   inf] (23), 
length of domains: 622
Total time: 2.2356	 pickout: 0.0755	 decision: 0.3966	 get_bound: 1.7166	 add_domain: 0.0468
Current lb:-0.03346472978591919
2624 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.39400315284729

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([622, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([622, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1782] [1, 1782] [1, 1782] [1, 1782] [1, 1782] [1, 1782] [1, 1782] [1, 1782] [1, 1782] [1, 1782] 
regular batch size: 2*622, diving batch size 1*0
best_l after optimization: 5.699976921081543 with beta sum per layer: [0.0, 161.56491088867188, 23.70024871826172]
alpha/beta optimization time: 1.5583438873291016
This batch time : update_bounds func: 1.8216	 prepare: 0.1072	 bound: 1.5587	 transfer: 0.0843	 finalize: 0.0681
Accumulated time: update_bounds func: 7.7197	 prepare: 0.4082	 bound: 6.7132	 transfer: 0.0843	 finalize: 0.3141
batch bounding time:  1.8230667114257812
Current worst splitting domains [lb, ub] (depth):
[-0.03012,   inf] (25), [-0.02990,   inf] (25), [-0.02844,   inf] (25), [-0.02805,   inf] (25), [-0.02763,   inf] (25), [-0.02748,   inf] (25), [-0.02740,   inf] (25), [-0.02696,   inf] (25), [-0.02673,   inf] (25), [-0.02633,   inf] (25), [-0.02610,   inf] (25), [-0.02592,   inf] (25), [-0.02563,   inf] (25), [-0.02550,   inf] (25), [-0.02523,   inf] (25), [-0.02499,   inf] (25), [-0.02489,   inf] (25), [-0.02482,   inf] (25), [-0.02460,   inf] (25), [-0.02433,   inf] (25), 
length of domains: 806
Total time: 2.4935	 pickout: 0.1009	 decision: 0.5051	 get_bound: 1.8254	 add_domain: 0.0621
Current lb:-0.030124833807349205
3868 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.90243673324585

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([806, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([806, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1765] [1, 1765] [1, 1291] [1, 1765] [1, 1765] [1, 1765] [1, 1765] [1, 1765] [1, 1765] [1, 1765] 
regular batch size: 2*806, diving batch size 1*0
best_l after optimization: 6.622461795806885 with beta sum per layer: [0.0, 200.07948303222656, 26.6955623626709]
alpha/beta optimization time: 1.9708609580993652
This batch time : update_bounds func: 2.4969	 prepare: 0.2278	 bound: 1.9714	 transfer: 0.1165	 finalize: 0.1768
Accumulated time: update_bounds func: 10.2166	 prepare: 0.6359	 bound: 8.6846	 transfer: 0.1165	 finalize: 0.4908
batch bounding time:  2.498837471008301
Current worst splitting domains [lb, ub] (depth):
[-0.02907,   inf] (27), [-0.02890,   inf] (27), [-0.02695,   inf] (27), [-0.02658,   inf] (27), [-0.02653,   inf] (27), [-0.02640,   inf] (27), [-0.02591,   inf] (27), [-0.02580,   inf] (27), [-0.02574,   inf] (27), [-0.02529,   inf] (27), [-0.02511,   inf] (27), [-0.02469,   inf] (27), [-0.02403,   inf] (27), [-0.02403,   inf] (27), [-0.02373,   inf] (27), [-0.02368,   inf] (27), [-0.02337,   inf] (27), [-0.02326,   inf] (27), [-0.02311,   inf] (27), [-0.02282,   inf] (27), 
length of domains: 1070
Total time: 3.3792	 pickout: 0.1266	 decision: 0.6652	 get_bound: 2.5019	 add_domain: 0.0855
Current lb:-0.02907407470047474
5480 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.303054571151733

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1070, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1070, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 614] [1, 618] [1, 1291] [1, 1291] [1, 618] [1, 1291] [1, 1291] [1, 1765] [1, 618] [1, 618] 
regular batch size: 2*1070, diving batch size 1*0
best_l after optimization: 5.879457473754883 with beta sum per layer: [0.0, 263.6939392089844, 28.23134994506836]
alpha/beta optimization time: 2.4252638816833496
This batch time : update_bounds func: 3.0771	 prepare: 0.3083	 bound: 2.4258	 transfer: 0.1510	 finalize: 0.1855
Accumulated time: update_bounds func: 13.2937	 prepare: 0.9442	 bound: 11.1104	 transfer: 0.1510	 finalize: 0.6763
batch bounding time:  3.0797369480133057
Current worst splitting domains [lb, ub] (depth):
[-0.02800,   inf] (29), [-0.02586,   inf] (29), [-0.02563,   inf] (29), [-0.02502,   inf] (29), [-0.02484,   inf] (29), [-0.02481,   inf] (29), [-0.02442,   inf] (29), [-0.02430,   inf] (29), [-0.02422,   inf] (29), [-0.02401,   inf] (29), [-0.02382,   inf] (29), [-0.02376,   inf] (29), [-0.02323,   inf] (29), [-0.02302,   inf] (29), [-0.02269,   inf] (29), [-0.02253,   inf] (29), [-0.02249,   inf] (29), [-0.02227,   inf] (29), [-0.02227,   inf] (29), [-0.02219,   inf] (29), 
length of domains: 1257
Total time: 4.2710	 pickout: 0.1742	 decision: 0.9045	 get_bound: 3.0843	 add_domain: 0.1080
Current lb:-0.028002427890896797
7620 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.60678195953369

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1257, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1257, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1291] [1, 618] [1, 1291] [1, 618] [1, 1291] [1, 618] [1, 614] [1, 618] [1, 1291] [1, 618] 
regular batch size: 2*1257, diving batch size 1*0
best_l after optimization: 5.540478706359863 with beta sum per layer: [0.36321502923965454, 286.5734558105469, 31.37115478515625]
alpha/beta optimization time: 2.7786686420440674
This batch time : update_bounds func: 3.3541	 prepare: 0.2264	 bound: 2.7791	 transfer: 0.1910	 finalize: 0.1508
Accumulated time: update_bounds func: 16.6477	 prepare: 1.1706	 bound: 13.8895	 transfer: 0.1910	 finalize: 0.8272
batch bounding time:  3.356895923614502
Current worst splitting domains [lb, ub] (depth):
[-0.02542,   inf] (31), [-0.02499,   inf] (31), [-0.02412,   inf] (31), [-0.02389,   inf] (31), [-0.02366,   inf] (31), [-0.02339,   inf] (31), [-0.02313,   inf] (31), [-0.02308,   inf] (31), [-0.02290,   inf] (31), [-0.02235,   inf] (31), [-0.02213,   inf] (31), [-0.02210,   inf] (31), [-0.02161,   inf] (31), [-0.02156,   inf] (31), [-0.02137,   inf] (31), [-0.02135,   inf] (31), [-0.02133,   inf] (31), [-0.02123,   inf] (31), [-0.02115,   inf] (31), [-0.02115,   inf] (31), 
length of domains: 1396
Total time: 4.9545	 pickout: 0.2029	 decision: 1.1877	 get_bound: 3.3616	 add_domain: 0.2023
Current lb:-0.025415420532226562
10134 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 23.59719491004944

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1396, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1396, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 614] [1, 1718] [1, 1718] [1, 614] [1, 614] [1, 614] [1, 614] [1, 614] [1, 614] [1, 614] 
regular batch size: 2*1396, diving batch size 1*0
best_l after optimization: 6.585397720336914 with beta sum per layer: [0.8632448315620422, 287.6407470703125, 32.398685455322266]
alpha/beta optimization time: 3.059652328491211
This batch time : update_bounds func: 3.7122	 prepare: 0.2559	 bound: 3.0603	 transfer: 0.2096	 finalize: 0.1785
Accumulated time: update_bounds func: 20.3599	 prepare: 1.4264	 bound: 16.9498	 transfer: 0.2096	 finalize: 1.0057
batch bounding time:  3.715799331665039
Current worst splitting domains [lb, ub] (depth):
[-0.02465,   inf] (33), [-0.02377,   inf] (33), [-0.02209,   inf] (33), [-0.02140,   inf] (33), [-0.02088,   inf] (33), [-0.02056,   inf] (33), [-0.02032,   inf] (33), [-0.02021,   inf] (33), [-0.02001,   inf] (33), [-0.01994,   inf] (33), [-0.01989,   inf] (33), [-0.01963,   inf] (33), [-0.01957,   inf] (33), [-0.01946,   inf] (33), [-0.01934,   inf] (33), [-0.01917,   inf] (33), [-0.01912,   inf] (33), [-0.01907,   inf] (33), [-0.01889,   inf] (33), [-0.01882,   inf] (33), 
length of domains: 1617
Total time: 5.5045	 pickout: 0.2300	 decision: 1.2909	 get_bound: 3.7216	 add_domain: 0.2620
Current lb:-0.024645628407597542
12926 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 29.14425492286682

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1617, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1617, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1756] [1, 1291] [1, 1718] [1, 1718] [1, 1756] [1, 1718] [1, 1718] [1, 1718] [2, 46] [1, 1718] 
regular batch size: 2*1617, diving batch size 1*0
best_l after optimization: 2.4133081436157227 with beta sum per layer: [1.4587630033493042, 309.7180480957031, 43.04467010498047]
alpha/beta optimization time: 3.4741971492767334
This batch time : update_bounds func: 4.3347	 prepare: 0.3238	 bound: 3.4748	 transfer: 0.2532	 finalize: 0.1982
Accumulated time: update_bounds func: 24.6946	 prepare: 1.7502	 bound: 20.4245	 transfer: 0.2532	 finalize: 1.2039
batch bounding time:  4.338450908660889
Current worst splitting domains [lb, ub] (depth):
[-0.02400,   inf] (35), [-0.02172,   inf] (35), [-0.02121,   inf] (35), [-0.02102,   inf] (35), [-0.02026,   inf] (35), [-0.02023,   inf] (35), [-0.01996,   inf] (35), [-0.01994,   inf] (35), [-0.01959,   inf] (35), [-0.01958,   inf] (35), [-0.01945,   inf] (35), [-0.01924,   inf] (35), [-0.01921,   inf] (35), [-0.01908,   inf] (35), [-0.01907,   inf] (35), [-0.01882,   inf] (35), [-0.01873,   inf] (35), [-0.01871,   inf] (35), [-0.01851,   inf] (35), [-0.01846,   inf] (35), 
length of domains: 1452
Total time: 6.2040	 pickout: 0.2910	 decision: 1.3118	 get_bound: 4.3448	 add_domain: 0.2564
Current lb:-0.023998215794563293
16160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 35.40111422538757

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1452, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1452, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1291] [1, 1756] [1, 1756] [1, 1756] [1, 1756] [2, 46] [1, 1756] [1, 1756] [1, 1756] [1, 1756] 
regular batch size: 2*1452, diving batch size 1*0
best_l after optimization: 1.0031442642211914 with beta sum per layer: [1.7133042812347412, 265.64324951171875, 40.02849578857422]
alpha/beta optimization time: 3.163076162338257
This batch time : update_bounds func: 4.1317	 prepare: 0.4179	 bound: 3.1637	 transfer: 0.2288	 finalize: 0.3127
Accumulated time: update_bounds func: 28.8263	 prepare: 2.1681	 bound: 23.5882	 transfer: 0.2288	 finalize: 1.5166
batch bounding time:  4.135100364685059
Current worst splitting domains [lb, ub] (depth):
[-0.02146,   inf] (37), [-0.02109,   inf] (37), [-0.02057,   inf] (37), [-0.02038,   inf] (37), [-0.01970,   inf] (37), [-0.01963,   inf] (37), [-0.01932,   inf] (37), [-0.01930,   inf] (37), [-0.01895,   inf] (37), [-0.01894,   inf] (37), [-0.01880,   inf] (37), [-0.01860,   inf] (37), [-0.01858,   inf] (37), [-0.01844,   inf] (37), [-0.01843,   inf] (37), [-0.01818,   inf] (37), [-0.01808,   inf] (37), [-0.01807,   inf] (37), [-0.01787,   inf] (37), [-0.01782,   inf] (37), 
length of domains: 1325
Total time: 5.9173	 pickout: 0.2426	 decision: 1.4057	 get_bound: 4.1411	 add_domain: 0.1280
Current lb:-0.02146304026246071
19064 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 41.36840105056763

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1325, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1325, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 46] [2, 46] [2, 46] [2, 46] [2, 46] [2, 46] [2, 46] [2, 46] [2, 46] [2, 46] 
regular batch size: 2*1325, diving batch size 1*0
best_l after optimization: 3.5297787189483643 with beta sum per layer: [1.4294805526733398, 211.4346923828125, 42.733299255371094]
alpha/beta optimization time: 2.9064464569091797
This batch time : update_bounds func: 3.6775	 prepare: 0.2399	 bound: 2.9069	 transfer: 0.1963	 finalize: 0.3269
Accumulated time: update_bounds func: 32.5037	 prepare: 2.4080	 bound: 26.4952	 transfer: 0.1963	 finalize: 1.8435
batch bounding time:  3.6819474697113037
Current worst splitting domains [lb, ub] (depth):
[-0.01779,   inf] (39), [-0.01740,   inf] (39), [-0.01732,   inf] (39), [-0.01711,   inf] (39), [-0.01690,   inf] (39), [-0.01670,   inf] (39), [-0.01640,   inf] (39), [-0.01636,   inf] (39), [-0.01601,   inf] (39), [-0.01593,   inf] (39), [-0.01564,   inf] (39), [-0.01562,   inf] (39), [-0.01562,   inf] (39), [-0.01547,   inf] (39), [-0.01530,   inf] (39), [-0.01525,   inf] (39), [-0.01525,   inf] (39), [-0.01517,   inf] (39), [-0.01512,   inf] (39), [-0.01492,   inf] (39), 
length of domains: 1482
Total time: 5.2575	 pickout: 0.2203	 decision: 1.1983	 get_bound: 3.6894	 add_domain: 0.1495
Current lb:-0.017787674441933632
21714 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 46.67557096481323

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1482, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1482, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1417] [1, 1417] [1, 738] [1, 738] [1, 1417] [1, 1417] [1, 738] [1, 738] [1, 1417] [1, 1392] 
regular batch size: 2*1482, diving batch size 1*0
best_l after optimization: 4.725186824798584 with beta sum per layer: [1.5331847667694092, 220.59219360351562, 48.49209976196289]
alpha/beta optimization time: 3.2224390506744385
This batch time : update_bounds func: 3.9607	 prepare: 0.2628	 bound: 3.2229	 transfer: 0.2176	 finalize: 0.1826
Accumulated time: update_bounds func: 36.4644	 prepare: 2.6708	 bound: 29.7181	 transfer: 0.2176	 finalize: 2.0261
batch bounding time:  3.9641201496124268
Current worst splitting domains [lb, ub] (depth):
[-0.01708,   inf] (41), [-0.01669,   inf] (41), [-0.01663,   inf] (41), [-0.01643,   inf] (41), [-0.01620,   inf] (41), [-0.01599,   inf] (41), [-0.01569,   inf] (41), [-0.01566,   inf] (41), [-0.01527,   inf] (41), [-0.01511,   inf] (41), [-0.01481,   inf] (41), [-0.01480,   inf] (41), [-0.01477,   inf] (41), [-0.01461,   inf] (41), [-0.01457,   inf] (41), [-0.01443,   inf] (41), [-0.01441,   inf] (41), [-0.01439,   inf] (41), [-0.01431,   inf] (41), [-0.01411,   inf] (41), 
length of domains: 1702
Total time: 5.7114	 pickout: 0.2498	 decision: 1.3209	 get_bound: 3.9701	 add_domain: 0.1707
Current lb:-0.01708376593887806
24678 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 52.43490242958069

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1702, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1702, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1392] [1, 1392] [1, 1392] [1, 1392] [1, 1392] [1, 1392] [1, 1392] [1, 1392] [1, 1392] [1, 1417] 
regular batch size: 2*1702, diving batch size 1*0
best_l after optimization: 3.0924453735351562 with beta sum per layer: [1.1990598440170288, 235.8004913330078, 58.468807220458984]
alpha/beta optimization time: 3.6237735748291016
This batch time : update_bounds func: 4.7049	 prepare: 0.4129	 bound: 3.6244	 transfer: 0.2575	 finalize: 0.3228
Accumulated time: update_bounds func: 41.1693	 prepare: 3.0837	 bound: 33.3425	 transfer: 0.2575	 finalize: 2.3489
batch bounding time:  4.709083795547485
Current worst splitting domains [lb, ub] (depth):
[-0.01628,   inf] (43), [-0.01588,   inf] (43), [-0.01578,   inf] (43), [-0.01559,   inf] (43), [-0.01540,   inf] (43), [-0.01519,   inf] (43), [-0.01485,   inf] (43), [-0.01482,   inf] (43), [-0.01447,   inf] (43), [-0.01442,   inf] (43), [-0.01413,   inf] (43), [-0.01407,   inf] (43), [-0.01407,   inf] (43), [-0.01391,   inf] (43), [-0.01376,   inf] (43), [-0.01374,   inf] (43), [-0.01372,   inf] (43), [-0.01359,   inf] (43), [-0.01359,   inf] (43), [-0.01338,   inf] (43), 
length of domains: 1769
Total time: 6.8977	 pickout: 0.2997	 decision: 1.6965	 get_bound: 4.7165	 add_domain: 0.1850
Current lb:-0.016280949115753174
28082 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 59.388692140579224

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1769, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1769, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 12] [1, 12] [1, 1000] [1, 1000] [1, 12] [1, 12] [1, 1000] [1, 1000] [1, 1000] [1, 12] 
regular batch size: 2*1769, diving batch size 1*0
best_l after optimization: 3.591193199157715 with beta sum per layer: [1.412619709968567, 233.4248504638672, 66.3426513671875]
alpha/beta optimization time: 3.758808135986328
This batch time : update_bounds func: 4.7030	 prepare: 0.3181	 bound: 3.7593	 transfer: 0.2815	 finalize: 0.3343
Accumulated time: update_bounds func: 45.8723	 prepare: 3.4018	 bound: 37.1018	 transfer: 0.2815	 finalize: 2.6832
batch bounding time:  4.70746636390686
Current worst splitting domains [lb, ub] (depth):
[-0.01506,   inf] (45), [-0.01486,   inf] (45), [-0.01486,   inf] (45), [-0.01444,   inf] (45), [-0.01412,   inf] (45), [-0.01409,   inf] (45), [-0.01398,   inf] (45), [-0.01375,   inf] (45), [-0.01374,   inf] (45), [-0.01335,   inf] (45), [-0.01318,   inf] (45), [-0.01307,   inf] (45), [-0.01299,   inf] (45), [-0.01299,   inf] (45), [-0.01292,   inf] (45), [-0.01286,   inf] (45), [-0.01266,   inf] (45), [-0.01251,   inf] (45), [-0.01230,   inf] (45), [-0.01229,   inf] (45), 
length of domains: 1900
Total time: 6.7041	 pickout: 0.2949	 decision: 1.4935	 get_bound: 4.7152	 add_domain: 0.2006
Current lb:-0.015060262754559517
31620 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 66.1506073474884

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1900, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1900, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1369] [1, 1417] [1, 1000] [1, 1000] [1, 1369] [1, 1417] [1, 1000] [1, 1000] [1, 12] [1, 12] 
regular batch size: 2*1900, diving batch size 1*0
best_l after optimization: 2.8870553970336914 with beta sum per layer: [2.076319456100464, 238.97576904296875, 66.92599487304688]
alpha/beta optimization time: 4.1297852993011475
This batch time : update_bounds func: 5.1405	 prepare: 0.3488	 bound: 4.1303	 transfer: 0.2967	 finalize: 0.3544
Accumulated time: update_bounds func: 51.0128	 prepare: 3.7506	 bound: 41.2321	 transfer: 0.2967	 finalize: 3.0376
batch bounding time:  5.145036220550537
Current worst splitting domains [lb, ub] (depth):
[-0.01432,   inf] (47), [-0.01417,   inf] (47), [-0.01413,   inf] (47), [-0.01371,   inf] (47), [-0.01340,   inf] (47), [-0.01338,   inf] (47), [-0.01325,   inf] (47), [-0.01302,   inf] (47), [-0.01244,   inf] (47), [-0.01237,   inf] (47), [-0.01227,   inf] (47), [-0.01217,   inf] (47), [-0.01206,   inf] (47), [-0.01184,   inf] (47), [-0.01178,   inf] (47), [-0.01177,   inf] (47), [-0.01161,   inf] (47), [-0.01150,   inf] (47), [-0.01150,   inf] (47), [-0.01150,   inf] (47), 
length of domains: 1950
Total time: 7.5834	 pickout: 0.3215	 decision: 1.8965	 get_bound: 5.1529	 add_domain: 0.2125
Current lb:-0.01431584358215332
35420 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 73.80395150184631

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1950, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1950, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1417] [1, 1369] [2, 79] [1, 1790] [1, 1369] [1, 1417] [2, 79] [1, 1790] [1, 1417] [1, 12] 
regular batch size: 2*1950, diving batch size 1*0
best_l after optimization: 0.8098443746566772 with beta sum per layer: [2.5341649055480957, 228.10159301757812, 64.62400817871094]
alpha/beta optimization time: 4.2380921840667725
This batch time : update_bounds func: 5.2712	 prepare: 0.3602	 bound: 4.2386	 transfer: 0.3026	 finalize: 0.3591
Accumulated time: update_bounds func: 56.2840	 prepare: 4.1107	 bound: 45.4707	 transfer: 0.3026	 finalize: 3.3967
batch bounding time:  5.275958299636841
Current worst splitting domains [lb, ub] (depth):
[-0.01362,   inf] (49), [-0.01343,   inf] (49), [-0.01331,   inf] (49), [-0.01268,   inf] (49), [-0.01266,   inf] (49), [-0.01263,   inf] (49), [-0.01243,   inf] (49), [-0.01194,   inf] (49), [-0.01172,   inf] (49), [-0.01154,   inf] (49), [-0.01137,   inf] (49), [-0.01136,   inf] (49), [-0.01110,   inf] (49), [-0.01106,   inf] (49), [-0.01094,   inf] (49), [-0.01078,   inf] (49), [-0.01077,   inf] (49), [-0.01076,   inf] (49), [-0.01076,   inf] (49), [-0.01070,   inf] (49), 
length of domains: 1832
Total time: 7.6515	 pickout: 0.3301	 decision: 1.7192	 get_bound: 5.2848	 add_domain: 0.3175
Current lb:-0.013616099022328854
39320 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 81.52371001243591

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1832, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1832, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 12] [1, 12] [1, 1790] [1, 12] [1, 12] [2, 79] [1, 1790] [2, 79] [1, 12] [1, 12] 
regular batch size: 2*1832, diving batch size 1*0
best_l after optimization: -2.2839787006378174 with beta sum per layer: [1.597296953201294, 194.61004638671875, 57.80760192871094]
alpha/beta optimization time: 3.9589788913726807
This batch time : update_bounds func: 4.9583	 prepare: 0.3616	 bound: 3.9595	 transfer: 0.2959	 finalize: 0.3308
Accumulated time: update_bounds func: 61.2423	 prepare: 4.4724	 bound: 49.4302	 transfer: 0.2959	 finalize: 3.7275
batch bounding time:  4.962511301040649
Current worst splitting domains [lb, ub] (depth):
[-0.01225,   inf] (51), [-0.01224,   inf] (51), [-0.01204,   inf] (51), [-0.01181,   inf] (51), [-0.01137,   inf] (51), [-0.01132,   inf] (51), [-0.01127,   inf] (51), [-0.01112,   inf] (51), [-0.01062,   inf] (51), [-0.01031,   inf] (51), [-0.01027,   inf] (51), [-0.01022,   inf] (51), [-0.01020,   inf] (51), [-0.01002,   inf] (51), [-0.00999,   inf] (51), [-0.00993,   inf] (51), [-0.00989,   inf] (51), [-0.00974,   inf] (51), [-0.00968,   inf] (51), [-0.00967,   inf] (51), 
length of domains: 1533
Total time: 7.0670	 pickout: 0.3257	 decision: 1.5907	 get_bound: 4.9702	 add_domain: 0.1804
Current lb:-0.012250026687979698
42984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 88.67889213562012

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1533, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1533, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 79] [1, 738] [1, 1790] [1, 738] [1, 738] [2, 79] [1, 1790] [1, 738] [1, 12] [1, 738] 
regular batch size: 2*1533, diving batch size 1*0
best_l after optimization: -0.4856429994106293 with beta sum per layer: [0.9235741496086121, 152.51980590820312, 44.93140411376953]
alpha/beta optimization time: 3.2684919834136963
This batch time : update_bounds func: 4.0383	 prepare: 0.2799	 bound: 3.2689	 transfer: 0.2077	 finalize: 0.2733
Accumulated time: update_bounds func: 65.2806	 prepare: 4.7523	 bound: 52.6991	 transfer: 0.2077	 finalize: 4.0008
batch bounding time:  4.043303728103638
Current worst splitting domains [lb, ub] (depth):
[-0.01165,   inf] (53), [-0.01145,   inf] (53), [-0.01121,   inf] (53), [-0.01098,   inf] (53), [-0.01077,   inf] (53), [-0.01052,   inf] (53), [-0.01052,   inf] (53), [-0.01021,   inf] (53), [-0.00971,   inf] (53), [-0.00967,   inf] (53), [-0.00948,   inf] (53), [-0.00934,   inf] (53), [-0.00929,   inf] (53), [-0.00926,   inf] (53), [-0.00918,   inf] (53), [-0.00917,   inf] (53), [-0.00908,   inf] (53), [-0.00899,   inf] (53), [-0.00897,   inf] (53), [-0.00893,   inf] (53), 
length of domains: 1374
Total time: 5.9213	 pickout: 0.3355	 decision: 1.3741	 get_bound: 4.0504	 add_domain: 0.1612
Current lb:-0.011647820472717285
46050 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 94.66369104385376

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1374, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1374, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1369] [1, 1790] [1, 1369] [2, 79] [1, 1369] [1, 1790] [1, 1369] [2, 79] [1, 1369] [1, 1369] 
regular batch size: 2*1374, diving batch size 1*0
best_l after optimization: -1.3879913091659546 with beta sum per layer: [0.4492597281932831, 128.06163024902344, 35.436195373535156]
alpha/beta optimization time: 2.9550747871398926
This batch time : update_bounds func: 3.6494	 prepare: 0.2507	 bound: 2.9555	 transfer: 0.1907	 finalize: 0.2448
Accumulated time: update_bounds func: 68.9300	 prepare: 5.0030	 bound: 55.6546	 transfer: 0.1907	 finalize: 4.2457
batch bounding time:  3.6524806022644043
Current worst splitting domains [lb, ub] (depth):
[-0.01094,   inf] (55), [-0.01050,   inf] (55), [-0.01040,   inf] (55), [-0.01016,   inf] (55), [-0.01006,   inf] (55), [-0.00981,   inf] (55), [-0.00946,   inf] (55), [-0.00939,   inf] (55), [-0.00900,   inf] (55), [-0.00897,   inf] (55), [-0.00865,   inf] (55), [-0.00863,   inf] (55), [-0.00859,   inf] (55), [-0.00859,   inf] (55), [-0.00845,   inf] (55), [-0.00836,   inf] (55), [-0.00829,   inf] (55), [-0.00822,   inf] (55), [-0.00815,   inf] (55), [-0.00813,   inf] (55), 
length of domains: 1115
Total time: 5.2795	 pickout: 0.3040	 decision: 1.1816	 get_bound: 3.6579	 add_domain: 0.1360
Current lb:-0.010936141014099121
48798 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 99.99544405937195

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1115, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1115, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 589] [1, 589] [1, 589] [1, 589] [1, 589] [1, 589] [1, 589] [1, 589] [1, 589] [1, 589] 
regular batch size: 2*1115, diving batch size 1*0
best_l after optimization: -0.49079108238220215 with beta sum per layer: [0.11900806427001953, 97.12997436523438, 26.708959579467773]
alpha/beta optimization time: 2.4661142826080322
This batch time : update_bounds func: 3.0559	 prepare: 0.2037	 bound: 2.4665	 transfer: 0.1584	 finalize: 0.2210
Accumulated time: update_bounds func: 71.9859	 prepare: 5.2067	 bound: 58.1211	 transfer: 0.1584	 finalize: 4.4666
batch bounding time:  3.058734178543091
Current worst splitting domains [lb, ub] (depth):
[-0.00964,   inf] (57), [-0.00919,   inf] (57), [-0.00905,   inf] (57), [-0.00880,   inf] (57), [-0.00876,   inf] (57), [-0.00850,   inf] (57), [-0.00810,   inf] (57), [-0.00802,   inf] (57), [-0.00769,   inf] (57), [-0.00766,   inf] (57), [-0.00734,   inf] (57), [-0.00731,   inf] (57), [-0.00726,   inf] (57), [-0.00717,   inf] (57), [-0.00713,   inf] (57), [-0.00698,   inf] (57), [-0.00698,   inf] (57), [-0.00692,   inf] (57), [-0.00681,   inf] (57), [-0.00677,   inf] (57), 
length of domains: 834
Total time: 4.3085	 pickout: 0.1931	 decision: 0.9482	 get_bound: 3.0634	 add_domain: 0.1037
Current lb:-0.00964421033859253
51028 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 104.34382438659668

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([834, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([834, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 801] [1, 1772] [0, 3278] [1, 1772] [1, 1772] [1, 1772] [0, 3278] [1, 1772] [1, 801] [1, 801] 
regular batch size: 2*834, diving batch size 1*0
best_l after optimization: -0.857973039150238 with beta sum per layer: [0.40473848581314087, 63.43303298950195, 18.733667373657227]
alpha/beta optimization time: 1.9373602867126465
This batch time : update_bounds func: 2.3044	 prepare: 0.1521	 bound: 1.9378	 transfer: 0.1009	 finalize: 0.1089
Accumulated time: update_bounds func: 74.2903	 prepare: 5.3588	 bound: 60.0589	 transfer: 0.1009	 finalize: 4.5755
batch bounding time:  2.3067102432250977
Current worst splitting domains [lb, ub] (depth):
[-0.00904,   inf] (59), [-0.00888,   inf] (59), [-0.00809,   inf] (59), [-0.00703,   inf] (59), [-0.00697,   inf] (59), [-0.00693,   inf] (59), [-0.00688,   inf] (59), [-0.00663,   inf] (59), [-0.00657,   inf] (59), [-0.00649,   inf] (59), [-0.00643,   inf] (59), [-0.00634,   inf] (59), [-0.00631,   inf] (59), [-0.00620,   inf] (59), [-0.00606,   inf] (59), [-0.00604,   inf] (59), [-0.00580,   inf] (59), [-0.00577,   inf] (59), [-0.00575,   inf] (59), [-0.00567,   inf] (59), 
length of domains: 586
Total time: 3.2388	 pickout: 0.1477	 decision: 0.7054	 get_bound: 2.3101	 add_domain: 0.0756
Current lb:-0.009035468101501465
52696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 107.61385321617126

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([586, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([586, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1772] [0, 3278] [1, 1772] [0, 3278] [1, 1772] [0, 3278] [1, 1772] [0, 3278] [1, 1772] [1, 1772] 
regular batch size: 2*586, diving batch size 1*0
best_l after optimization: -0.49953168630599976 with beta sum per layer: [0.8832122087478638, 37.87879943847656, 13.211299896240234]
alpha/beta optimization time: 1.4597620964050293
This batch time : update_bounds func: 1.7014	 prepare: 0.1087	 bound: 1.4601	 transfer: 0.0630	 finalize: 0.0666
Accumulated time: update_bounds func: 75.9917	 prepare: 5.4675	 bound: 61.5190	 transfer: 0.0630	 finalize: 4.6421
batch bounding time:  1.70294189453125
Current worst splitting domains [lb, ub] (depth):
[-0.00886,   inf] (61), [-0.00702,   inf] (61), [-0.00692,   inf] (61), [-0.00666,   inf] (61), [-0.00661,   inf] (61), [-0.00642,   inf] (61), [-0.00633,   inf] (61), [-0.00595,   inf] (61), [-0.00591,   inf] (61), [-0.00579,   inf] (61), [-0.00574,   inf] (61), [-0.00566,   inf] (61), [-0.00558,   inf] (61), [-0.00551,   inf] (61), [-0.00547,   inf] (61), [-0.00524,   inf] (61), [-0.00505,   inf] (61), [-0.00494,   inf] (61), [-0.00475,   inf] (61), [-0.00472,   inf] (61), 
length of domains: 421
Total time: 2.3896	 pickout: 0.1019	 decision: 0.5282	 get_bound: 1.7053	 add_domain: 0.0542
Current lb:-0.008864879608154297
53868 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 110.02381157875061

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([421, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([421, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1772] [1, 801] [1, 1772] [1, 801] [1, 801] [1, 801] [1, 801] [1, 801] [1, 801] [1, 1772] 
regular batch size: 2*421, diving batch size 1*0
best_l after optimization: -0.466635525226593 with beta sum per layer: [0.3989482522010803, 25.706134796142578, 9.311834335327148]
alpha/beta optimization time: 1.1549866199493408
This batch time : update_bounds func: 1.3584	 prepare: 0.0797	 bound: 1.1554	 transfer: 0.0216	 finalize: 0.0995
Accumulated time: update_bounds func: 77.3500	 prepare: 5.5472	 bound: 62.6744	 transfer: 0.0216	 finalize: 4.7417
batch bounding time:  1.3595025539398193
Current worst splitting domains [lb, ub] (depth):
[-0.00672,   inf] (63), [-0.00624,   inf] (63), [-0.00583,   inf] (63), [-0.00582,   inf] (63), [-0.00580,   inf] (63), [-0.00559,   inf] (63), [-0.00554,   inf] (63), [-0.00514,   inf] (63), [-0.00504,   inf] (63), [-0.00490,   inf] (63), [-0.00482,   inf] (63), [-0.00482,   inf] (63), [-0.00479,   inf] (63), [-0.00474,   inf] (63), [-0.00467,   inf] (63), [-0.00442,   inf] (63), [-0.00442,   inf] (63), [-0.00434,   inf] (63), [-0.00426,   inf] (63), [-0.00406,   inf] (63), 
length of domains: 270
Total time: 1.8087	 pickout: 0.0715	 decision: 0.3418	 get_bound: 1.3611	 add_domain: 0.0343
Current lb:-0.006719570606946945
54710 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 111.84740495681763

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([270, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([270, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1781] [1, 1781] [1, 1781] [1, 1781] [1, 1781] [1, 1781] [1, 1781] [1, 1781] [1, 1781] [1, 1781] 
regular batch size: 2*270, diving batch size 1*0
best_l after optimization: -0.46545740962028503 with beta sum per layer: [0.05113070458173752, 13.183490753173828, 6.005246162414551]
alpha/beta optimization time: 0.8907120227813721
This batch time : update_bounds func: 1.0361	 prepare: 0.0523	 bound: 0.8911	 transfer: 0.0131	 finalize: 0.0783
Accumulated time: update_bounds func: 78.3861	 prepare: 5.5995	 bound: 63.5654	 transfer: 0.0131	 finalize: 4.8199
batch bounding time:  1.0368669033050537
Current worst splitting domains [lb, ub] (depth):
[-0.00434,   inf] (65), [-0.00405,   inf] (65), [-0.00388,   inf] (65), [-0.00353,   inf] (65), [-0.00344,   inf] (65), [-0.00338,   inf] (65), [-0.00337,   inf] (65), [-0.00319,   inf] (65), [-0.00316,   inf] (65), [-0.00316,   inf] (65), [-0.00312,   inf] (65), [-0.00310,   inf] (65), [-0.00284,   inf] (65), [-0.00280,   inf] (65), [-0.00279,   inf] (65), [-0.00260,   inf] (65), [-0.00245,   inf] (65), [-0.00245,   inf] (65), [-0.00244,   inf] (65), [-0.00244,   inf] (65), 
length of domains: 124
Total time: 1.3038	 pickout: 0.0465	 decision: 0.2035	 get_bound: 1.0378	 add_domain: 0.0160
Current lb:-0.004335447680205107
55250 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 113.16042566299438

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([124, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([124, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 44] [1, 44] [1, 44] [1, 44] [1, 44] [1, 1311] [1, 44] [1, 44] [1, 44] [1, 1455] 
regular batch size: 2*124, diving batch size 1*0
best_l after optimization: -0.20361173152923584 with beta sum per layer: [0.0, 4.522948265075684, 2.6587629318237305]
alpha/beta optimization time: 0.6837649345397949
This batch time : update_bounds func: 0.7327	 prepare: 0.0256	 bound: 0.6841	 transfer: 0.0085	 finalize: 0.0138
Accumulated time: update_bounds func: 79.1188	 prepare: 5.6251	 bound: 64.2495	 transfer: 0.0085	 finalize: 4.8337
batch bounding time:  0.7331676483154297
Current worst splitting domains [lb, ub] (depth):
[-0.00350,   inf] (67), [-0.00323,   inf] (67), [-0.00305,   inf] (67), [-0.00272,   inf] (67), [-0.00261,   inf] (67), [-0.00250,   inf] (67), [-0.00235,   inf] (67), [-0.00234,   inf] (67), [-0.00228,   inf] (67), [-0.00227,   inf] (67), [-0.00204,   inf] (67), [-0.00202,   inf] (67), [-0.00201,   inf] (67), [-0.00196,   inf] (67), [-0.00194,   inf] (67), [-0.00162,   inf] (67), [-0.00161,   inf] (67), [-0.00160,   inf] (67), [-0.00159,   inf] (67), [-0.00157,   inf] (67), 
length of domains: 69
Total time: 0.8836	 pickout: 0.0210	 decision: 0.1199	 get_bound: 0.7336	 add_domain: 0.0091
Current lb:-0.00350344181060791
55498 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 114.0482165813446

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([69, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([69, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1455] [1, 1311] [1, 1455] [1, 1455] [1, 1311] [1, 1311] [1, 1311] [1, 1311] [1, 1311] [1, 1305] 
regular batch size: 2*69, diving batch size 1*0
best_l after optimization: -0.14375951886177063 with beta sum per layer: [0.0, 1.5272107124328613, 1.3935285806655884]
alpha/beta optimization time: 0.6004254817962646
This batch time : update_bounds func: 0.6337	 prepare: 0.0152	 bound: 0.6008	 transfer: 0.0089	 finalize: 0.0082
Accumulated time: update_bounds func: 79.7524	 prepare: 5.6403	 bound: 64.8504	 transfer: 0.0089	 finalize: 4.8419
batch bounding time:  0.6341488361358643
Current worst splitting domains [lb, ub] (depth):
[-0.00230,   inf] (69), [-0.00217,   inf] (69), [-0.00187,   inf] (69), [-0.00174,   inf] (69), [-0.00154,   inf] (69), [-0.00153,   inf] (69), [-0.00149,   inf] (69), [-0.00144,   inf] (69), [-0.00144,   inf] (69), [-0.00128,   inf] (69), [-0.00127,   inf] (69), [-0.00122,   inf] (69), [-0.00110,   inf] (69), [-0.00096,   inf] (69), [-0.00095,   inf] (69), [-0.00081,   inf] (69), [-0.00077,   inf] (69), [-0.00077,   inf] (69), [-0.00076,   inf] (69), [-0.00056,   inf] (69), 
length of domains: 36
Total time: 0.7420	 pickout: 0.0123	 decision: 0.0901	 get_bound: 0.6344	 add_domain: 0.0052
Current lb:-0.002296626567840576
55636 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 114.79323410987854

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([36, 16, 16, 16]) pre split depth:  2
batch:  torch.Size([36, 16, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [1, 1311] [1, 1455] [1, 1311] [1, 1455] [1, 1455] [1, 1311] [1, 1455] [1, 1311] [1, 1455] [1, 1455] 
split level 1: [2, 70] [2, 70] [1, 1160] [2, 70] [1, 1160] [1, 1160] [2, 70] [1, 1160] [1, 1160] [1, 1160] 
regular batch size: 2*72, diving batch size 1*0/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:25: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1627336316785/work/torch/csrc/utils/tensor_numpy.cpp:143.)
  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))

best_l after optimization: -0.32682913541793823 with beta sum per layer: [0.0, 0.9356153011322021, 1.5666781663894653]
alpha/beta optimization time: 0.5715749263763428
This batch time : update_bounds func: 0.6045	 prepare: 0.0155	 bound: 0.5719	 transfer: 0.0082	 finalize: 0.0083
Accumulated time: update_bounds func: 80.3570	 prepare: 5.6558	 bound: 65.4223	 transfer: 0.0082	 finalize: 4.8502
batch bounding time:  0.6049149036407471
Current worst splitting domains [lb, ub] (depth):
[-0.00027,   inf] (72), 
length of domains: 1
Total time: 0.6955	 pickout: 0.0071	 decision: 0.0712	 get_bound: 0.6169	 add_domain: 0.0003
Current lb:-0.000265657901763916
55780 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 115.49113488197327

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 16, 16]) pre split depth:  7
batch:  torch.Size([1, 16, 16, 16]) post split depth:  7
splitting decisions: 
split level 0: [1, 1305] 
split level 1: [1, 1160] 
split level 2: [1, 759] 
split level 3: [1, 701] 
split level 4: [1, 1278] 
split level 5: [2, 5] 
split level 6: [1, 693] 
regular batch size: 2*64, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -1.368668794631958 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.008859395980834961
This batch time : update_bounds func: 0.0370	 prepare: 0.0134	 bound: 0.0092	 transfer: 0.0069	 finalize: 0.0070
Accumulated time: update_bounds func: 80.3940	 prepare: 5.6692	 bound: 65.4314	 transfer: 0.0069	 finalize: 4.8572
batch bounding time:  0.03719019889831543
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.1106	 pickout: 0.0010	 decision: 0.0511	 get_bound: 0.0584	 add_domain: 0.0001
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 115.60327649116516

Image 0 against label 5 verification end, Time cost: 115.65641832351685
##### [0] True label: 7, Tested against: 6, onnx_path: nets/cifar_wide_kw.onnx, vnnlib_path: vnnlib/cifar_wide_kw-img6762-eps0.017908496732026144.vnnlib ######
init opt crown verified for label 6 with bound 0.16904188692569733
Image 0 against label 6 verification end, Time cost: 0.00031280517578125
##### [0] True label: 7, Tested against: 8, onnx_path: nets/cifar_wide_kw.onnx, vnnlib_path: vnnlib/cifar_wide_kw-img6762-eps0.017908496732026144.vnnlib ######
init opt crown verified for label 8 with bound 2.9048871994018555
Image 0 against label 8 verification end, Time cost: 0.00029087066650390625
##### [0] True label: 7, Tested against: 9, onnx_path: nets/cifar_wide_kw.onnx, vnnlib_path: vnnlib/cifar_wide_kw-img6762-eps0.017908496732026144.vnnlib ######
init opt crown verified for label 9 with bound 0.5236866474151611
Image 0 against label 9 verification end, Time cost: 0.0002903938293457031
Result: safe-bab in 134.2584 seconds


[[    0.             3.1965282      0.             0.0003264
      0.        ]
 [    0.             2.52531838     0.             0.00032282
      1.        ]
 [    0.             0.0000001    128.             3.04885912
      2.        ]
 [    0.             0.0000001    128.             1.1779933
      3.        ]
 [    0.             0.31136426     0.             0.00031447
      4.        ]
 [    0.             0.0000001  55908.           115.65641832
      5.        ]
 [    0.             0.16904189     0.             0.00031281
      6.        ]
 [    0.             2.9048872      0.             0.00029087
      8.        ]
 [    0.             0.52368665     0.             0.00029039
      9.        ]]
############# Summary #############
Final verified acc: 100.0% [total 1 examples]
Total verification count: 1 , total verified safe: 1 , verified unsafe: 0 , timeout: 0
mean time [total:1]: 119.88512849807739
mean time [cnt:1]: 119.88512849807739
max time 134.25840425491333
safe-bab (total 1): [0]
