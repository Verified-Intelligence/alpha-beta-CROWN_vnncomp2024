Building native CUDA modules...
/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
  csv_name: oval21_instances.csv
  onnx_path: null
  vnnlib_path: null
  results_file: null
  root_path: ../../../../../vnncomp2021/benchmarks/oval21
model:
  path: null
  name: mnist_9_200
data:
  start: 16
  end: 17
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR
  data_filter_path: null
specification:
  type: lp
  norm: .inf
  epsilon: null
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 2000
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.01
    lr_decay: 0.98
    optimizer: adam
    iteration: 50
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 360
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 10
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:04:34 2022 on ubuntu
saving results to vnn-comp_[oval21_instances]_start=16_end=17_iter=50_b=2000_timeout=360_branching=kfsb-max-10_lra-init=0.1_lra=0.01_lrb=0.01_PGD=skip.npz
customized start/end sample from 16 to 17

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Model prediction is: tensor([[ 0.7236, -1.3898,  1.0589,  0.0449,  0.8483,  0.3391,  1.6390,  1.6379,
         -2.5766, -2.3253]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 0.8922,  3.0038,  0.5678,  1.5811,  0.7775,  1.2876, -0.0189,  4.1907,
          3.9427]], device='cuda:0') None
best_l after optimization: -16.224651336669922 with beta sum per layer: []
alpha/beta optimization time: 5.105391025543213
initial alpha-CROWN bounds: tensor([[ 0.8922,  3.0039,  0.5678,  1.5811,  0.7775,  1.2876, -0.0189,  4.1908,
          3.9427]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.0189, device='cuda:0', grad_fn=<MinBackward1>)
##### [0] True label: 6, Tested against: 0, onnx_path: nets/cifar_wide_kw.onnx, vnnlib_path: vnnlib/cifar_wide_kw-img4386-eps0.00026143790849673205.vnnlib ######
init opt crown verified for label 0 with bound 0.8921997547149658
Image 0 against label 0 verification end, Time cost: 0.0003170967102050781
##### [0] True label: 6, Tested against: 1, onnx_path: nets/cifar_wide_kw.onnx, vnnlib_path: vnnlib/cifar_wide_kw-img4386-eps0.00026143790849673205.vnnlib ######
init opt crown verified for label 1 with bound 3.003851890563965
Image 0 against label 1 verification end, Time cost: 0.0003032684326171875
##### [0] True label: 6, Tested against: 2, onnx_path: nets/cifar_wide_kw.onnx, vnnlib_path: vnnlib/cifar_wide_kw-img4386-eps0.00026143790849673205.vnnlib ######
init opt crown verified for label 2 with bound 0.5678403377532959
Image 0 against label 2 verification end, Time cost: 0.00029921531677246094
##### [0] True label: 6, Tested against: 3, onnx_path: nets/cifar_wide_kw.onnx, vnnlib_path: vnnlib/cifar_wide_kw-img4386-eps0.00026143790849673205.vnnlib ######
init opt crown verified for label 3 with bound 1.58107590675354
Image 0 against label 3 verification end, Time cost: 0.00028967857360839844
##### [0] True label: 6, Tested against: 4, onnx_path: nets/cifar_wide_kw.onnx, vnnlib_path: vnnlib/cifar_wide_kw-img4386-eps0.00026143790849673205.vnnlib ######
init opt crown verified for label 4 with bound 0.7774796485900879
Image 0 against label 4 verification end, Time cost: 0.0002930164337158203
##### [0] True label: 6, Tested against: 5, onnx_path: nets/cifar_wide_kw.onnx, vnnlib_path: vnnlib/cifar_wide_kw-img4386-eps0.00026143790849673205.vnnlib ######
init opt crown verified for label 5 with bound 1.2875759601593018
Image 0 against label 5 verification end, Time cost: 0.00029277801513671875
##### [0] True label: 6, Tested against: 7, onnx_path: nets/cifar_wide_kw.onnx, vnnlib_path: vnnlib/cifar_wide_kw-img4386-eps0.00026143790849673205.vnnlib ######
Model prediction is: tensor([[ 0.7236, -1.3898,  1.0589,  0.0449,  0.8483,  0.3391,  1.6390,  1.6379,
         -2.5766, -2.3253]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 16, 16, 16]) != torch.Size([2, 9, 1, 16, 16, 16]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 8, 8]) != torch.Size([2, 9, 1, 32, 8, 8]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 16, 16])
1 /11 torch.Size([1, 32, 8, 8])
2 /14 torch.Size([1, 100])
best_l after optimization: 0.018868684768676758 with beta sum per layer: []
alpha/beta optimization time: 1.7523717880249023
alpha-CROWN with fixed intermediate bounds: tensor([[-0.0189]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.018868684768676758
layer 0 size torch.Size([4096]) unstable 14
layer 1 size torch.Size([2048]) unstable 6
layer 2 size torch.Size([100]) unstable 0
-----------------
# of unstable neurons: 20
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 16, 16]) pre split depth:  7
batch:  torch.Size([1, 16, 16, 16]) post split depth:  7
splitting decisions: 
split level 0: [1, 1204] 
split level 1: [1, 531] 
split level 2: [1, 62] 
split level 3: [0, 710] 
split level 4: [0, 2626] 
split level 5: [1, 1054] 
split level 6: [0, 2133] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 2.3446364402770996 with beta sum per layer: [13.603582382202148, 28.79181671142578, 0.0]
alpha/beta optimization time: 0.613804817199707
This batch time : update_bounds func: 0.6403	 prepare: 0.0098	 bound: 0.6141	 transfer: 0.0090	 finalize: 0.0070
Accumulated time: update_bounds func: 0.6403	 prepare: 0.0098	 bound: 0.6141	 transfer: 0.0090	 finalize: 0.0070
batch bounding time:  0.6406497955322266
Current worst splitting domains [lb, ub] (depth):
[-0.01875,   inf] (8), [-0.01875,   inf] (8), [-0.01874,   inf] (8), [-0.01874,   inf] (8), [-0.01870,   inf] (8), [-0.01870,   inf] (8), [-0.01869,   inf] (8), [-0.01869,   inf] (8), [-0.01867,   inf] (8), [-0.01867,   inf] (8), [-0.01867,   inf] (8), [-0.01867,   inf] (8), [-0.01865,   inf] (8), [-0.01865,   inf] (8), [-0.01864,   inf] (8), [-0.01864,   inf] (8), [-0.01861,   inf] (8), [-0.01861,   inf] (8), [-0.01861,   inf] (8), [-0.01861,   inf] (8), 
length of domains: 128
Total time: 0.7147	 pickout: 0.0010	 decision: 0.0528	 get_bound: 0.6547	 add_domain: 0.0062
Current lb:-0.01874983310699463
128 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.9380743503570557

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([128, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([128, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 2150] [0, 2150] [0, 2150] [0, 2150] [0, 2150] [0, 2150] [0, 2150] [0, 2150] [0, 2150] [0, 2150] 
regular batch size: 2*128, diving batch size 1*0
best_l after optimization: 4.670747756958008 with beta sum per layer: [45.677974700927734, 79.40681457519531, 0.0]
alpha/beta optimization time: 0.6740379333496094
This batch time : update_bounds func: 0.7319	 prepare: 0.0227	 bound: 0.6744	 transfer: 0.0205	 finalize: 0.0138
Accumulated time: update_bounds func: 1.3723	 prepare: 0.0324	 bound: 1.2885	 transfer: 0.0205	 finalize: 0.0209
batch bounding time:  0.7323944568634033
Current worst splitting domains [lb, ub] (depth):
[-0.01874,   inf] (10), [-0.01874,   inf] (10), [-0.01873,   inf] (10), [-0.01873,   inf] (10), [-0.01869,   inf] (10), [-0.01869,   inf] (10), [-0.01868,   inf] (10), [-0.01868,   inf] (10), [-0.01867,   inf] (10), [-0.01867,   inf] (10), [-0.01866,   inf] (10), [-0.01866,   inf] (10), [-0.01866,   inf] (10), [-0.01866,   inf] (10), [-0.01865,   inf] (10), [-0.01865,   inf] (10), [-0.01864,   inf] (10), [-0.01864,   inf] (10), [-0.01863,   inf] (10), [-0.01863,   inf] (10), 
length of domains: 256
Total time: 0.8899	 pickout: 0.0198	 decision: 0.1259	 get_bound: 0.7328	 add_domain: 0.0114
Current lb:-0.01874375343322754
384 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.8302385807037354

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1018] [1, 306] [1, 1018] [1, 306] [1, 1018] [1, 306] [1, 1018] [1, 306] [1, 1018] [1, 306] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 9.148371696472168 with beta sum per layer: [92.0488510131836, 219.043212890625, 0.0]
alpha/beta optimization time: 0.8988354206085205
This batch time : update_bounds func: 1.0145	 prepare: 0.0435	 bound: 0.8993	 transfer: 0.0410	 finalize: 0.0296
Accumulated time: update_bounds func: 2.3867	 prepare: 0.0759	 bound: 2.1878	 transfer: 0.0410	 finalize: 0.0504
batch bounding time:  1.015383005142212
Current worst splitting domains [lb, ub] (depth):
[-0.01874,   inf] (12), [-0.01874,   inf] (12), [-0.01873,   inf] (12), [-0.01873,   inf] (12), [-0.01868,   inf] (12), [-0.01868,   inf] (12), [-0.01868,   inf] (12), [-0.01867,   inf] (12), [-0.01866,   inf] (12), [-0.01866,   inf] (12), [-0.01866,   inf] (12), [-0.01866,   inf] (12), [-0.01865,   inf] (12), [-0.01865,   inf] (12), [-0.01865,   inf] (12), [-0.01865,   inf] (12), [-0.01865,   inf] (12), [-0.01864,   inf] (12), [-0.01864,   inf] (12), [-0.01864,   inf] (12), 
length of domains: 512
Total time: 1.3515	 pickout: 0.0386	 decision: 0.2699	 get_bound: 1.0163	 add_domain: 0.0266
Current lb:-0.018738865852355957
896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.186994314193726

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([512, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1018] [1, 306] [1, 1018] [1, 306] [1, 1018] [1, 306] [1, 1018] [1, 306] [1, 1018] [1, 306] 
regular batch size: 2*512, diving batch size 1*0
best_l after optimization: 17.834117889404297 with beta sum per layer: [205.52188110351562, 651.6138916015625, 0.0]
alpha/beta optimization time: 1.4265201091766357
This batch time : update_bounds func: 1.6964	 prepare: 0.0856	 bound: 1.4269	 transfer: 0.0693	 finalize: 0.1121
Accumulated time: update_bounds func: 4.0831	 prepare: 0.1615	 bound: 3.6147	 transfer: 0.0693	 finalize: 0.1626
batch bounding time:  1.6976807117462158
Current worst splitting domains [lb, ub] (depth):
[-0.01873,   inf] (14), [-0.01873,   inf] (14), [-0.01872,   inf] (14), [-0.01872,   inf] (14), [-0.01868,   inf] (14), [-0.01868,   inf] (14), [-0.01867,   inf] (14), [-0.01867,   inf] (14), [-0.01866,   inf] (14), [-0.01866,   inf] (14), [-0.01865,   inf] (14), [-0.01865,   inf] (14), [-0.01865,   inf] (14), [-0.01865,   inf] (14), [-0.01865,   inf] (14), [-0.01865,   inf] (14), [-0.01864,   inf] (14), [-0.01864,   inf] (14), [-0.01864,   inf] (14), [-0.01864,   inf] (14), 
length of domains: 1024
Total time: 2.2461	 pickout: 0.0813	 decision: 0.4101	 get_bound: 1.6996	 add_domain: 0.0551
Current lb:-0.018733501434326172
1920 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.442012548446655

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 1576] [0, 1576] [0, 1576] [0, 1576] [0, 1576] [0, 1576] [0, 1576] [0, 1576] [0, 1576] [0, 1576] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 35.257259368896484 with beta sum per layer: [540.4539184570312, 1690.113525390625, 0.0]
alpha/beta optimization time: 2.5104987621307373
This batch time : update_bounds func: 2.9657	 prepare: 0.1715	 bound: 2.5109	 transfer: 0.1572	 finalize: 0.1197
Accumulated time: update_bounds func: 7.0488	 prepare: 0.3330	 bound: 6.1256	 transfer: 0.1572	 finalize: 0.2823
batch bounding time:  2.9679901599884033
Current worst splitting domains [lb, ub] (depth):
[-0.01873,   inf] (16), [-0.01873,   inf] (16), [-0.01872,   inf] (16), [-0.01872,   inf] (16), [-0.01869,   inf] (16), [-0.01869,   inf] (16), [-0.01868,   inf] (16), [-0.01868,   inf] (16), [-0.01868,   inf] (16), [-0.01868,   inf] (16), [-0.01867,   inf] (16), [-0.01867,   inf] (16), [-0.01865,   inf] (16), [-0.01865,   inf] (16), [-0.01865,   inf] (16), [-0.01865,   inf] (16), [-0.01865,   inf] (16), [-0.01865,   inf] (16), [-0.01865,   inf] (16), [-0.01865,   inf] (16), 
length of domains: 2048
Total time: 4.2971	 pickout: 0.1625	 decision: 0.9446	 get_bound: 2.9718	 add_domain: 0.2183
Current lb:-0.018731465563178062
3968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.756261110305786

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 2434] [0, 3708] [0, 2434] [0, 3708] [0, 2434] [0, 3708] [0, 2434] [0, 3708] [0, 2434] [0, 3708] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 68.24823760986328 with beta sum per layer: [1425.5927734375, 3966.31982421875, 0.0]
alpha/beta optimization time: 4.6988205909729
This batch time : update_bounds func: 6.0442	 prepare: 0.5469	 bound: 4.6994	 transfer: 0.3202	 finalize: 0.3644
Accumulated time: update_bounds func: 13.0930	 prepare: 0.8798	 bound: 10.8250	 transfer: 0.3202	 finalize: 0.6466
batch bounding time:  6.049058675765991
Current worst splitting domains [lb, ub] (depth):
[-0.01873,   inf] (18), [-0.01873,   inf] (18), [-0.01872,   inf] (18), [-0.01872,   inf] (18), [-0.01869,   inf] (18), [-0.01869,   inf] (18), [-0.01868,   inf] (18), [-0.01868,   inf] (18), [-0.01868,   inf] (18), [-0.01868,   inf] (18), [-0.01867,   inf] (18), [-0.01867,   inf] (18), [-0.01866,   inf] (18), [-0.01865,   inf] (18), [-0.01865,   inf] (18), [-0.01865,   inf] (18), [-0.01865,   inf] (18), [-0.01865,   inf] (18), [-0.01865,   inf] (18), [-0.01865,   inf] (18), 
length of domains: 4048
Total time: 8.5618	 pickout: 0.3231	 decision: 1.9377	 get_bound: 6.0574	 add_domain: 0.2437
Current lb:-0.018731355667114258
7968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 20.354023456573486

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 1601] [0, 2434] [0, 1601] [0, 2434] [0, 1601] [0, 2434] [0, 1601] [0, 2434] [0, 1601] [0, 2434] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 72.35430145263672 with beta sum per layer: [1159.3760986328125, 1764.6456298828125, 0.0]
alpha/beta optimization time: 4.48482871055603
This batch time : update_bounds func: 5.5978	 prepare: 0.3418	 bound: 4.4853	 transfer: 0.3493	 finalize: 0.4117
Accumulated time: update_bounds func: 18.6908	 prepare: 1.2217	 bound: 15.3103	 transfer: 0.3493	 finalize: 1.0583
batch bounding time:  5.602524995803833
Current worst splitting domains [lb, ub] (depth):
[-0.01873,   inf] (20), [-0.01873,   inf] (20), [-0.01873,   inf] (20), [-0.01872,   inf] (20), [-0.01872,   inf] (20), [-0.01872,   inf] (20), [-0.01869,   inf] (20), [-0.01869,   inf] (20), [-0.01869,   inf] (20), [-0.01868,   inf] (20), [-0.01868,   inf] (20), [-0.01868,   inf] (20), [-0.01868,   inf] (20), [-0.01868,   inf] (20), [-0.01868,   inf] (20), [-0.01867,   inf] (20), [-0.01867,   inf] (20), [-0.01867,   inf] (20), [-0.01866,   inf] (20), [-0.01866,   inf] (20), 
length of domains: 6048
Total time: 8.3214	 pickout: 0.4067	 decision: 1.8413	 get_bound: 5.6108	 add_domain: 0.4626
Current lb:-0.018731355667114258
11968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 28.712310314178467

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 3442] [0, 3442] [0, 1601] [0, 3442] [0, 3442] [0, 1601] [0, 3442] [0, 3442] [0, 1601] [0, 3442] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 73.28923797607422 with beta sum per layer: [1227.616943359375, 894.6798095703125, 0.0]
alpha/beta optimization time: 4.506401062011719
This batch time : update_bounds func: 5.5945	 prepare: 0.3320	 bound: 4.5068	 transfer: 0.3104	 finalize: 0.4360
Accumulated time: update_bounds func: 24.2853	 prepare: 1.5537	 bound: 19.8171	 transfer: 0.3104	 finalize: 1.4944
batch bounding time:  5.599102735519409
Current worst splitting domains [lb, ub] (depth):
[-0.01873,   inf] (22), [-0.01873,   inf] (22), [-0.01873,   inf] (22), [-0.01873,   inf] (22), [-0.01872,   inf] (22), [-0.01872,   inf] (22), [-0.01872,   inf] (22), [-0.01872,   inf] (22), [-0.01869,   inf] (22), [-0.01869,   inf] (22), [-0.01869,   inf] (22), [-0.01869,   inf] (22), [-0.01868,   inf] (22), [-0.01868,   inf] (22), [-0.01868,   inf] (22), [-0.01868,   inf] (22), [-0.01868,   inf] (22), [-0.01868,   inf] (22), [-0.01868,   inf] (22), [-0.01868,   inf] (22), 
length of domains: 8048
Total time: 8.0454	 pickout: 0.4043	 decision: 1.7644	 get_bound: 5.6071	 add_domain: 0.2697
Current lb:-0.018731355667114258
15968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 36.79249429702759

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 69] [0, 69] [0, 3442] [0, 3442] [0, 2345] [0, 2345] [0, 3442] [0, 3442] [0, 69] [0, 69] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 73.65531921386719 with beta sum per layer: [1205.7913818359375, 600.08642578125, 0.0]
alpha/beta optimization time: 4.5281453132629395
This batch time : update_bounds func: 5.4708	 prepare: 0.3331	 bound: 4.5286	 transfer: 0.3364	 finalize: 0.2632
Accumulated time: update_bounds func: 29.7561	 prepare: 1.8868	 bound: 24.3457	 transfer: 0.3364	 finalize: 1.7575
batch bounding time:  5.475423336029053
Current worst splitting domains [lb, ub] (depth):
[-0.01873,   inf] (24), [-0.01873,   inf] (24), [-0.01873,   inf] (24), [-0.01873,   inf] (24), [-0.01873,   inf] (24), [-0.01873,   inf] (24), [-0.01872,   inf] (24), [-0.01872,   inf] (24), [-0.01872,   inf] (24), [-0.01872,   inf] (24), [-0.01869,   inf] (24), [-0.01869,   inf] (24), [-0.01869,   inf] (24), [-0.01869,   inf] (24), [-0.01869,   inf] (24), [-0.01869,   inf] (24), [-0.01868,   inf] (24), [-0.01868,   inf] (24), [-0.01868,   inf] (24), [-0.01868,   inf] (24), 
length of domains: 10048
Total time: 8.4786	 pickout: 0.4165	 decision: 1.9312	 get_bound: 5.4837	 add_domain: 0.6471
Current lb:-0.018731355667114258
19968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 45.31642746925354

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 2345] [0, 2345] [0, 69] [0, 69] [0, 2345] [0, 2345] [0, 596] [0, 596] [0, 2345] [0, 2345] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 73.84928894042969 with beta sum per layer: [1139.267333984375, 450.63427734375, 0.0]
alpha/beta optimization time: 4.531174421310425
This batch time : update_bounds func: 5.4533	 prepare: 0.3428	 bound: 4.5317	 transfer: 0.3214	 finalize: 0.2474
Accumulated time: update_bounds func: 35.2094	 prepare: 2.2296	 bound: 28.8774	 transfer: 0.3214	 finalize: 2.0049
batch bounding time:  5.458183526992798
Current worst splitting domains [lb, ub] (depth):
[-0.01873,   inf] (26), [-0.01873,   inf] (26), [-0.01873,   inf] (26), [-0.01873,   inf] (26), [-0.01873,   inf] (26), [-0.01873,   inf] (26), [-0.01873,   inf] (26), [-0.01873,   inf] (26), [-0.01872,   inf] (26), [-0.01872,   inf] (26), [-0.01872,   inf] (26), [-0.01872,   inf] (26), [-0.01871,   inf] (26), [-0.01871,   inf] (26), [-0.01869,   inf] (26), [-0.01869,   inf] (26), [-0.01869,   inf] (26), [-0.01869,   inf] (26), [-0.01869,   inf] (26), [-0.01869,   inf] (26), 
length of domains: 12048
Total time: 8.5508	 pickout: 0.3454	 decision: 2.0877	 get_bound: 5.4668	 add_domain: 0.6508
Current lb:-0.018731355667114258
23968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 53.90774703025818

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 596] [0, 596] [0, 2345] [0, 2345] [0, 596] [0, 596] [0, 2345] [0, 2345] [0, 2893] [0, 2893] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 74.02645874023438 with beta sum per layer: [1000.2904663085938, 356.2606201171875, 0.0]
alpha/beta optimization time: 4.519876956939697
This batch time : update_bounds func: 5.6658	 prepare: 0.3376	 bound: 4.5203	 transfer: 0.3082	 finalize: 0.2386
Accumulated time: update_bounds func: 40.8752	 prepare: 2.5672	 bound: 33.3978	 transfer: 0.3082	 finalize: 2.2435
batch bounding time:  5.670753002166748
Current worst splitting domains [lb, ub] (depth):
[-0.01873,   inf] (28), [-0.01873,   inf] (28), [-0.01873,   inf] (28), [-0.01873,   inf] (28), [-0.01873,   inf] (28), [-0.01873,   inf] (28), [-0.01873,   inf] (28), [-0.01873,   inf] (28), [-0.01872,   inf] (28), [-0.01872,   inf] (28), [-0.01872,   inf] (28), [-0.01872,   inf] (28), [-0.01872,   inf] (28), [-0.01872,   inf] (28), [-0.01872,   inf] (28), [-0.01872,   inf] (28), [-0.01871,   inf] (28), [-0.01871,   inf] (28), [-0.01871,   inf] (28), [-0.01871,   inf] (28), 
length of domains: 14048
Total time: 8.3226	 pickout: 0.3563	 decision: 1.9726	 get_bound: 5.6793	 add_domain: 0.3145
Current lb:-0.018731355667114258
27968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 62.29088115692139

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 2893] [0, 2893] [0, 596] [0, 596] [0, 2893] [0, 2893] [0, 596] [0, 596] [0, 69] [0, 69] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 74.19023132324219 with beta sum per layer: [830.3709106445312, 293.2682189941406, 0.0]
alpha/beta optimization time: 4.491983652114868
This batch time : update_bounds func: 5.4237	 prepare: 0.3416	 bound: 4.4925	 transfer: 0.3370	 finalize: 0.2421/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:25: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1627336316785/work/torch/csrc/utils/tensor_numpy.cpp:143.)
  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))

Accumulated time: update_bounds func: 46.2990	 prepare: 2.9088	 bound: 37.8902	 transfer: 0.3370	 finalize: 2.4856
batch bounding time:  5.428662538528442
Current worst splitting domains [lb, ub] (depth):
[-0.01873,   inf] (30), [-0.01873,   inf] (30), [-0.01873,   inf] (30), [-0.01873,   inf] (30), [-0.01873,   inf] (30), [-0.01873,   inf] (30), [-0.01873,   inf] (30), [-0.01873,   inf] (30), [-0.01872,   inf] (30), [-0.01872,   inf] (30), [-0.01872,   inf] (30), [-0.01872,   inf] (30), [-0.01872,   inf] (30), [-0.01872,   inf] (30), [-0.01872,   inf] (30), [-0.01872,   inf] (30), [-0.01872,   inf] (30), [-0.01872,   inf] (30), [-0.01872,   inf] (30), [-0.01872,   inf] (30), 
length of domains: 16048
Total time: 8.9779	 pickout: 0.3463	 decision: 2.4339	 get_bound: 5.4374	 add_domain: 0.7604
Current lb:-0.018731355667114258
31968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 71.30747699737549

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 3406] [0, 3406] [0, 2893] [0, 2893] [0, 3406] [0, 3406] [0, 2893] [0, 2893] [0, 3406] [0, 3406] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 74.32267761230469 with beta sum per layer: [694.1649169921875, 237.6876983642578, 0.0]
alpha/beta optimization time: 4.480592966079712
This batch time : update_bounds func: 5.3975	 prepare: 0.3561	 bound: 4.4811	 transfer: 0.3111	 finalize: 0.2379
Accumulated time: update_bounds func: 51.6964	 prepare: 3.2649	 bound: 42.3713	 transfer: 0.3111	 finalize: 2.7235
batch bounding time:  5.402043581008911
Current worst splitting domains [lb, ub] (depth):
[-0.01873,   inf] (32), [-0.01873,   inf] (32), [-0.01873,   inf] (32), [-0.01873,   inf] (32), [-0.01873,   inf] (32), [-0.01873,   inf] (32), [-0.01873,   inf] (32), [-0.01873,   inf] (32), [-0.01873,   inf] (32), [-0.01873,   inf] (32), [-0.01873,   inf] (32), [-0.01873,   inf] (32), [-0.01872,   inf] (32), [-0.01872,   inf] (32), [-0.01872,   inf] (32), [-0.01872,   inf] (32), [-0.01872,   inf] (32), [-0.01872,   inf] (32), [-0.01872,   inf] (32), [-0.01872,   inf] (32), 
length of domains: 18048
Total time: 8.5517	 pickout: 0.3559	 decision: 1.9952	 get_bound: 5.4106	 add_domain: 0.7900
Current lb:-0.018731355667114258
35968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 79.905348777771

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 3708] [0, 3708] [0, 3708] [0, 3708] [0, 3406] [0, 3406] [0, 3708] [0, 3708] [0, 3708] [0, 3708] 
regular batch size: 2*2000, diving batch size 1*0
best_l after optimization: 74.1622314453125 with beta sum per layer: [683.7393188476562, 186.00083923339844, 0.0]
alpha/beta optimization time: 4.506332874298096
This batch time : update_bounds func: 5.7481	 prepare: 0.3393	 bound: 4.5068	 transfer: 0.3098	 finalize: 0.2399
Accumulated time: update_bounds func: 57.4445	 prepare: 3.6042	 bound: 46.8781	 transfer: 0.3098	 finalize: 2.9633
batch bounding time:  5.752591133117676
Current worst splitting domains [lb, ub] (depth):
[-0.01873,   inf] (34), [-0.01873,   inf] (34), [-0.01873,   inf] (34), [-0.01873,   inf] (34), [-0.01873,   inf] (34), [-0.01873,   inf] (34), [-0.01873,   inf] (34), [-0.01873,   inf] (34), [-0.01873,   inf] (34), [-0.01873,   inf] (34), [-0.01873,   inf] (34), [-0.01873,   inf] (34), [-0.01873,   inf] (34), [-0.01873,   inf] (34), [-0.01873,   inf] (34), [-0.01873,   inf] (34), [-0.01872,   inf] (34), [-0.01872,   inf] (34), [-0.01872,   inf] (34), [-0.01872,   inf] (34), 
length of domains: 20048
Total time: 8.5396	 pickout: 0.4295	 decision: 1.9930	 get_bound: 5.7606	 add_domain: 0.3565
Current lb:-0.018731355667114258
39968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 88.49442100524902

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2000, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([2000, 16, 16, 16]) post split depth:  0
all nodes are split!!
Global ub: inf, batch ub: inf
Image 0 against label 7 verification end, Time cost: 91.6737151145935
Result: unknown in 102.1766 seconds


[[    0.             0.89219975     0.             0.0003171
      0.        ]
 [    0.             3.00385189     0.             0.00030327
      1.        ]
 [    0.             0.56784034     0.             0.00029922
      2.        ]
 [    0.             1.58107591     0.             0.00028968
      3.        ]
 [    0.             0.77747965     0.             0.00029302
      4.        ]
 [    0.             1.28757596     0.             0.00029278
      5.        ]
 [    0.            -0.01873136 39968.            91.67371511
      7.        ]]
############# Summary #############
Final verified acc: 0.0% [total 1 examples]
Total verification count: 1 , total verified safe: 0 , verified unsafe: 0 , timeout: 1
mean time [total:1]: 91.67551016807556
mean time [cnt:1]: 91.67551016807556
max time 102.17655873298645
unknown (total 1): [0]
