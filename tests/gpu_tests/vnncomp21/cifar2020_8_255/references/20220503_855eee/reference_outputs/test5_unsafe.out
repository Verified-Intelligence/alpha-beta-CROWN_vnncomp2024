Building native CUDA modules...
/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
  csv_name: cifar2020_instances.csv
  onnx_path: null
  vnnlib_path: null
  results_file: null
  root_path: ../../../../../vnncomp2021/benchmarks/cifar2020
model:
  path: null
  name: mnist_9_200
data:
  start: 103
  end: 104
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR
  data_filter_path: null
specification:
  type: lp
  norm: .inf
  epsilon: null
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 200
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.01
    lr_decay: 0.98
    optimizer: adam
    iteration: 50
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 360
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 10
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:16:50 2022 on ubuntu
saving results to vnn-comp_[cifar2020_instances]_start=103_end=104_iter=50_b=200_timeout=360_branching=kfsb-max-10_lra-init=0.1_lra=0.01_lrb=0.01_PGD=skip.npz
customized start/end sample from 103 to 104

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Model prediction is: tensor([[-0.2036,  1.8989, -1.0091, -0.2755, -0.9596, -0.4610, -1.2620, -0.1781,
          0.7172,  2.3727]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 0.4467, -0.5843,  0.4994,  0.2372,  0.9314,  0.2145,  0.8190, -0.4699,
         -0.3271]], device='cuda:0') None
best_l after optimization: -4.134335517883301 with beta sum per layer: []
alpha/beta optimization time: 8.027122259140015
initial alpha-CROWN bounds: tensor([[ 0.6729, -0.4794,  0.8198,  0.5132,  1.1849,  0.5354,  1.1143, -0.1046,
         -0.1222]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.4794, device='cuda:0', grad_fn=<MinBackward1>)
##### [0] True label: 9, Tested against: 0, onnx_path: nets/cifar10_8_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_38_eps_0.03137_n1.vnnlib ######
init opt crown verified for label 0 with bound 0.6729030609130859
Image 0 against label 0 verification end, Time cost: 0.000324249267578125
##### [0] True label: 9, Tested against: 1, onnx_path: nets/cifar10_8_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_38_eps_0.03137_n1.vnnlib ######
Model prediction is: tensor([[-0.2036,  1.8989, -1.0091, -0.2755, -0.9596, -0.4610, -1.2620, -0.1781,
          0.7172,  2.3727]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /9 torch.Size([1, 32, 16, 16])
1 /11 torch.Size([1, 128, 8, 8])
2 /14 torch.Size([1, 250])
best_l after optimization: 0.4794089198112488 with beta sum per layer: []
alpha/beta optimization time: 1.870161771774292
alpha-CROWN with fixed intermediate bounds: tensor([[-0.4794]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.4794089198112488
layer 0 size torch.Size([8192]) unstable 252
layer 1 size torch.Size([8192]) unstable 793
layer 2 size torch.Size([250]) unstable 107
-----------------
# of unstable neurons: 1152
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 87] 
split level 1: [2, 160] 
split level 2: [2, 9] 
split level 3: [2, 65] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 3.201404571533203 with beta sum per layer: [0.0, 0.0, 6.6909260749816895]
alpha/beta optimization time: 0.5622978210449219
This batch time : update_bounds func: 0.5686	 prepare: 0.0029	 bound: 0.5628	 transfer: 0.0018	 finalize: 0.0010
Accumulated time: update_bounds func: 0.5686	 prepare: 0.0029	 bound: 0.5628	 transfer: 0.0018	 finalize: 0.0010
batch bounding time:  0.5687663555145264
Current worst splitting domains [lb, ub] (depth):
[-0.34833,   inf] (5), [-0.34200,   inf] (5), [-0.28815,   inf] (5), [-0.28300,   inf] (5), [-0.27143,   inf] (5), [-0.26564,   inf] (5), [-0.20068,   inf] (5), [-0.20022,   inf] (5), [-0.19456,   inf] (5), [-0.18520,   inf] (5), [-0.13490,   inf] (5), [-0.13156,   inf] (5), [-0.12891,   inf] (5), [-0.11127,   inf] (5), [-0.06081,   inf] (5), [-0.05474,   inf] (5), 
length of domains: 16
Total time: 0.6250	 pickout: 0.0010	 decision: 0.0526	 get_bound: 0.5707	 add_domain: 0.0008
Current lb:-0.34833306074142456
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.4349167346954346

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([16, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([16, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 180] [2, 180] [2, 180] [2, 180] [2, 180] [2, 180] [2, 180] [2, 180] [2, 180] [2, 180] 
regular batch size: 2*16, diving batch size 1*0
best_l after optimization: 3.662787914276123 with beta sum per layer: [0.0, 0.0, 25.45976448059082]
alpha/beta optimization time: 0.5769689083099365
This batch time : update_bounds func: 0.5885	 prepare: 0.0037	 bound: 0.5772	 transfer: 0.0055	 finalize: 0.0019
Accumulated time: update_bounds func: 1.1571	 prepare: 0.0066	 bound: 1.1400	 transfer: 0.0055	 finalize: 0.0030
batch bounding time:  0.5887289047241211
Current worst splitting domains [lb, ub] (depth):
[-0.34050,   inf] (7), [-0.33512,   inf] (7), [-0.27552,   inf] (7), [-0.26682,   inf] (7), [-0.26149,   inf] (7), [-0.24256,   inf] (7), [-0.22408,   inf] (7), [-0.21982,   inf] (7), [-0.17455,   inf] (7), [-0.17346,   inf] (7), [-0.17214,   inf] (7), [-0.16059,   inf] (7), [-0.14180,   inf] (7), [-0.13535,   inf] (7), [-0.13466,   inf] (7), [-0.11437,   inf] (7), [-0.08872,   inf] (7), [-0.08220,   inf] (7), [-0.06473,   inf] (7), [-0.06270,   inf] (7), 
length of domains: 24
Total time: 0.6548	 pickout: 0.0042	 decision: 0.0608	 get_bound: 0.5888	 add_domain: 0.0010
Current lb:-0.3405037820339203
48 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.0902299880981445

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([24, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([24, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 38] [2, 38] [2, 38] [2, 38] [2, 38] [2, 38] [2, 38] [2, 38] [2, 38] [2, 38] 
regular batch size: 2*24, diving batch size 1*0
best_l after optimization: 4.437726974487305 with beta sum per layer: [0.0, 0.0, 50.75743103027344]
alpha/beta optimization time: 0.5893938541412354
This batch time : update_bounds func: 0.6052	 prepare: 0.0050	 bound: 0.5897	 transfer: 0.0075	 finalize: 0.0028
Accumulated time: update_bounds func: 1.7623	 prepare: 0.0116	 bound: 1.7297	 transfer: 0.0075	 finalize: 0.0058
batch bounding time:  0.6053793430328369
Current worst splitting domains [lb, ub] (depth):
[-0.31038,   inf] (9), [-0.30603,   inf] (9), [-0.27313,   inf] (9), [-0.26473,   inf] (9), [-0.24355,   inf] (9), [-0.22873,   inf] (9), [-0.22722,   inf] (9), [-0.21939,   inf] (9), [-0.20630,   inf] (9), [-0.20077,   inf] (9), [-0.17846,   inf] (9), [-0.17090,   inf] (9), [-0.16793,   inf] (9), [-0.15738,   inf] (9), [-0.13364,   inf] (9), [-0.13269,   inf] (9), [-0.13041,   inf] (9), [-0.12829,   inf] (9), [-0.11949,   inf] (9), [-0.10902,   inf] (9), 
length of domains: 33
Total time: 0.6817	 pickout: 0.0059	 decision: 0.0683	 get_bound: 0.6055	 add_domain: 0.0019
Current lb:-0.3103835880756378
96 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.772421598434448

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([33, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([33, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 125] [2, 125] [2, 125] [2, 125] [2, 125] [2, 125] [2, 125] [2, 125] [2, 125] [2, 125] 
regular batch size: 2*33, diving batch size 1*0
best_l after optimization: 6.298858642578125 with beta sum per layer: [0.0, 0.0, 85.55937194824219]
alpha/beta optimization time: 0.624171257019043
This batch time : update_bounds func: 0.6464	 prepare: 0.0065	 bound: 0.6245	 transfer: 0.0113	 finalize: 0.0039
Accumulated time: update_bounds func: 2.4087	 prepare: 0.0181	 bound: 2.3542	 transfer: 0.0113	 finalize: 0.0097
batch bounding time:  0.6465811729431152
Current worst splitting domains [lb, ub] (depth):
[-0.30344,   inf] (11), [-0.29847,   inf] (11), [-0.26163,   inf] (11), [-0.25248,   inf] (11), [-0.24442,   inf] (11), [-0.24268,   inf] (11), [-0.23546,   inf] (11), [-0.22144,   inf] (11), [-0.21570,   inf] (11), [-0.20972,   inf] (11), [-0.20523,   inf] (11), [-0.20368,   inf] (11), [-0.19632,   inf] (11), [-0.18901,   inf] (11), [-0.18587,   inf] (11), [-0.16543,   inf] (11), [-0.16490,   inf] (11), [-0.15453,   inf] (11), [-0.15191,   inf] (11), [-0.14744,   inf] (11), 
length of domains: 51
Total time: 0.7334	 pickout: 0.0081	 decision: 0.0764	 get_bound: 0.6467	 add_domain: 0.0023
Current lb:-0.3034377098083496
162 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.506558895111084

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([51, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([51, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 173] [2, 173] [2, 173] [2, 173] [2, 173] [2, 173] [2, 173] [2, 173] [2, 173] [2, 173] 
regular batch size: 2*51, diving batch size 1*0
best_l after optimization: 8.777315139770508 with beta sum per layer: [0.0, 0.0, 163.03997802734375]
alpha/beta optimization time: 0.6972470283508301
This batch time : update_bounds func: 0.7297	 prepare: 0.0092	 bound: 0.6975	 transfer: 0.0171	 finalize: 0.0056
Accumulated time: update_bounds func: 3.1384	 prepare: 0.0273	 bound: 3.0517	 transfer: 0.0171	 finalize: 0.0153
batch bounding time:  0.7299656867980957
Current worst splitting domains [lb, ub] (depth):
[-0.28516,   inf] (13), [-0.27775,   inf] (13), [-0.26216,   inf] (13), [-0.26101,   inf] (13), [-0.23910,   inf] (13), [-0.22856,   inf] (13), [-0.22228,   inf] (13), [-0.21866,   inf] (13), [-0.21338,   inf] (13), [-0.20437,   inf] (13), [-0.20372,   inf] (13), [-0.20213,   inf] (13), [-0.20133,   inf] (13), [-0.19300,   inf] (13), [-0.19120,   inf] (13), [-0.18925,   inf] (13), [-0.18486,   inf] (13), [-0.18474,   inf] (13), [-0.17938,   inf] (13), [-0.17653,   inf] (13), 
length of domains: 80
Total time: 0.8583	 pickout: 0.0117	 decision: 0.1127	 get_bound: 0.7301	 add_domain: 0.0037
Current lb:-0.2851635217666626
264 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.365812540054321

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([80, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([80, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 56] [2, 235] [2, 235] [2, 56] [2, 56] [2, 235] [2, 235] [2, 235] [2, 235] [2, 235] 
regular batch size: 2*80, diving batch size 1*0
best_l after optimization: 12.390546798706055 with beta sum per layer: [0.0, 0.0, 285.2976989746094]
alpha/beta optimization time: 0.8175506591796875
This batch time : update_bounds func: 0.8666	 prepare: 0.0137	 bound: 0.8179	 transfer: 0.0261	 finalize: 0.0085
Accumulated time: update_bounds func: 4.0050	 prepare: 0.0410	 bound: 3.8696	 transfer: 0.0261	 finalize: 0.0239
batch bounding time:  0.8669641017913818
Current worst splitting domains [lb, ub] (depth):
[-0.26622,   inf] (15), [-0.25637,   inf] (15), [-0.25465,   inf] (15), [-0.24675,   inf] (15), [-0.24128,   inf] (15), [-0.24028,   inf] (15), [-0.22779,   inf] (15), [-0.22712,   inf] (15), [-0.21857,   inf] (15), [-0.20914,   inf] (15), [-0.20752,   inf] (15), [-0.20051,   inf] (15), [-0.19782,   inf] (15), [-0.19531,   inf] (15), [-0.19190,   inf] (15), [-0.18742,   inf] (15), [-0.18389,   inf] (15), [-0.18353,   inf] (15), [-0.18271,   inf] (15), [-0.18041,   inf] (15), 
length of domains: 122
Total time: 1.0385	 pickout: 0.0180	 decision: 0.1474	 get_bound: 0.8672	 add_domain: 0.0059
Current lb:-0.26622021198272705
424 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.40583610534668

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([122, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([122, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 5] [2, 5] [2, 5] [2, 5] [2, 5] [2, 5] [2, 5] [2, 5] [2, 5] [2, 5] 
regular batch size: 2*122, diving batch size 1*0
best_l after optimization: 15.837879180908203 with beta sum per layer: [0.0, 0.0, 466.91534423828125]
alpha/beta optimization time: 1.141176700592041
This batch time : update_bounds func: 1.2190	 prepare: 0.0205	 bound: 1.1415	 transfer: 0.0427	 finalize: 0.0136
Accumulated time: update_bounds func: 5.2240	 prepare: 0.0615	 bound: 5.0111	 transfer: 0.0427	 finalize: 0.0375
batch bounding time:  1.2193922996520996
Current worst splitting domains [lb, ub] (depth):
[-0.26143,   inf] (17), [-0.25103,   inf] (17), [-0.24919,   inf] (17), [-0.24092,   inf] (17), [-0.23472,   inf] (17), [-0.23394,   inf] (17), [-0.22087,   inf] (17), [-0.22018,   inf] (17), [-0.21363,   inf] (17), [-0.20365,   inf] (17), [-0.20245,   inf] (17), [-0.19455,   inf] (17), [-0.19190,   inf] (17), [-0.18898,   inf] (17), [-0.18693,   inf] (17), [-0.18543,   inf] (17), [-0.18055,   inf] (17), [-0.18032,   inf] (17), [-0.17816,   inf] (17), [-0.17773,   inf] (17), 
length of domains: 181
Total time: 1.4589	 pickout: 0.0274	 decision: 0.2025	 get_bound: 1.2198	 add_domain: 0.0091
Current lb:-0.26143473386764526
668 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.867158651351929

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([181, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([181, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 46] [2, 46] [2, 46] [2, 46] [2, 46] [2, 46] [2, 46] [2, 46] [2, 46] [2, 46] 
regular batch size: 2*181, diving batch size 1*0
best_l after optimization: 4.542562007904053 with beta sum per layer: [0.0, 0.0, 661.3535766601562]
alpha/beta optimization time: 1.4569706916809082
This batch time : update_bounds func: 1.5573	 prepare: 0.0299	 bound: 1.4573	 transfer: 0.0495	 finalize: 0.0197
Accumulated time: update_bounds func: 6.7813	 prepare: 0.0914	 bound: 6.4684	 transfer: 0.0495	 finalize: 0.0572
batch bounding time:  1.5579521656036377
Current worst splitting domains [lb, ub] (depth):
[-0.25804,   inf] (19), [-0.24738,   inf] (19), [-0.24577,   inf] (19), [-0.23708,   inf] (19), [-0.23078,   inf] (19), [-0.22982,   inf] (19), [-0.21678,   inf] (19), [-0.21590,   inf] (19), [-0.20997,   inf] (19), [-0.19999,   inf] (19), [-0.19873,   inf] (19), [-0.19070,   inf] (19), [-0.18793,   inf] (19), [-0.18489,   inf] (19), [-0.18342,   inf] (19), [-0.17639,   inf] (19), [-0.17443,   inf] (19), [-0.17406,   inf] (19), [-0.17255,   inf] (19), [-0.17157,   inf] (19), 
length of domains: 165
Total time: 1.9628	 pickout: 0.0414	 decision: 0.3536	 get_bound: 1.5586	 add_domain: 0.0092
Current lb:-0.25804275274276733
1030 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.83439016342163

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([165, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([165, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 235] [2, 56] [2, 235] [2, 56] [2, 56] [2, 235] [2, 235] [2, 56] [2, 235] [2, 235] 
regular batch size: 2*165, diving batch size 1*0
best_l after optimization: 17.15882682800293 with beta sum per layer: [0.0, 0.0, 618.729736328125]
alpha/beta optimization time: 1.408254623413086
This batch time : update_bounds func: 1.5763	 prepare: 0.0275	 bound: 1.4086	 transfer: 0.0573	 finalize: 0.0820
Accumulated time: update_bounds func: 8.3575	 prepare: 0.1189	 bound: 7.8770	 transfer: 0.0573	 finalize: 0.1392
batch bounding time:  1.5768423080444336
Current worst splitting domains [lb, ub] (depth):
[-0.23679,   inf] (21), [-0.22894,   inf] (21), [-0.22854,   inf] (21), [-0.22339,   inf] (21), [-0.21808,   inf] (21), [-0.21790,   inf] (21), [-0.21728,   inf] (21), [-0.21050,   inf] (21), [-0.20966,   inf] (21), [-0.20795,   inf] (21), [-0.20018,   inf] (21), [-0.19927,   inf] (21), [-0.19572,   inf] (21), [-0.19558,   inf] (21), [-0.18894,   inf] (21), [-0.18718,   inf] (21), [-0.18712,   inf] (21), [-0.17950,   inf] (21), [-0.17863,   inf] (21), [-0.17778,   inf] (21), 
length of domains: 225
Total time: 1.8914	 pickout: 0.0376	 decision: 0.2620	 get_bound: 1.5774	 add_domain: 0.0143
Current lb:-0.23679320514202118
1360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.729361295700073

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 69] [2, 69] [2, 69] [2, 69] [2, 69] [2, 69] [2, 69] [2, 69] [2, 69] [2, 69] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 24.57543182373047 with beta sum per layer: [0.0, 0.0, 717.7442626953125]
alpha/beta optimization time: 1.6182136535644531
This batch time : update_bounds func: 1.7405	 prepare: 0.0332	 bound: 1.6185	 transfer: 0.0650	 finalize: 0.0227
Accumulated time: update_bounds func: 10.0980	 prepare: 0.1521	 bound: 9.4955	 transfer: 0.0650	 finalize: 0.1619
batch bounding time:  1.7411112785339355
Current worst splitting domains [lb, ub] (depth):
[-0.21355,   inf] (23), [-0.21273,   inf] (23), [-0.20554,   inf] (23), [-0.20490,   inf] (23), [-0.20463,   inf] (23), [-0.20440,   inf] (23), [-0.19981,   inf] (23), [-0.19949,   inf] (23), [-0.19529,   inf] (23), [-0.19431,   inf] (23), [-0.19423,   inf] (23), [-0.19404,   inf] (23), [-0.19300,   inf] (23), [-0.19231,   inf] (23), [-0.18959,   inf] (23), [-0.18740,   inf] (23), [-0.18518,   inf] (23), [-0.18496,   inf] (23), [-0.18490,   inf] (23), [-0.18263,   inf] (23), 
length of domains: 354
Total time: 2.1119	 pickout: 0.0493	 decision: 0.3008	 get_bound: 1.7418	 add_domain: 0.0199
Current lb:-0.2135494351387024
1760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.845102310180664

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 4] [2, 4] [2, 4] [2, 4] [2, 4] [2, 4] [2, 4] [2, 4] [2, 4] [2, 4] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 27.423681259155273 with beta sum per layer: [0.0, 0.0, 565.2379150390625]
alpha/beta optimization time: 1.6230180263519287
This batch time : update_bounds func: 1.7659	 prepare: 0.0329	 bound: 1.6234	 transfer: 0.0866	 finalize: 0.0221
Accumulated time: update_bounds func: 11.8640	 prepare: 0.1850	 bound: 11.1189	 transfer: 0.0866	 finalize: 0.1840
batch bounding time:  1.7665860652923584
Current worst splitting domains [lb, ub] (depth):
[-0.20958,   inf] (25), [-0.20856,   inf] (25), [-0.20146,   inf] (25), [-0.20112,   inf] (25), [-0.20060,   inf] (25), [-0.20038,   inf] (25), [-0.19561,   inf] (25), [-0.19537,   inf] (25), [-0.19099,   inf] (25), [-0.19017,   inf] (25), [-0.19007,   inf] (25), [-0.19001,   inf] (25), [-0.18920,   inf] (25), [-0.18811,   inf] (25), [-0.18592,   inf] (25), [-0.18335,   inf] (25), [-0.18121,   inf] (25), [-0.18095,   inf] (25), [-0.18091,   inf] (25), [-0.17871,   inf] (25), 
length of domains: 501
Total time: 2.1911	 pickout: 0.0503	 decision: 0.3498	 get_bound: 1.7673	 add_domain: 0.0237
Current lb:-0.20957759022712708
2160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.040008068084717

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 231] [2, 231] [2, 231] [2, 233] [2, 233] [2, 231] [2, 231] [2, 231] [2, 233] [2, 233] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 34.151161193847656 with beta sum per layer: [0.0, 0.0, 431.73272705078125]
alpha/beta optimization time: 1.6209120750427246
This batch time : update_bounds func: 1.7601	 prepare: 0.0330	 bound: 1.6212	 transfer: 0.0822	 finalize: 0.0228
Accumulated time: update_bounds func: 13.6241	 prepare: 0.2180	 bound: 12.7401	 transfer: 0.0822	 finalize: 0.2067
batch bounding time:  1.7608120441436768
Current worst splitting domains [lb, ub] (depth):
[-0.19156,   inf] (27), [-0.19108,   inf] (27), [-0.19062,   inf] (27), [-0.19021,   inf] (27), [-0.18430,   inf] (27), [-0.18370,   inf] (27), [-0.18311,   inf] (27), [-0.18109,   inf] (27), [-0.17956,   inf] (27), [-0.17873,   inf] (27), [-0.17872,   inf] (27), [-0.17813,   inf] (27), [-0.17793,   inf] (27), [-0.17617,   inf] (27), [-0.17615,   inf] (27), [-0.17588,   inf] (27), [-0.17462,   inf] (27), [-0.17460,   inf] (27), [-0.17323,   inf] (27), [-0.17203,   inf] (27), 
length of domains: 696
Total time: 2.2002	 pickout: 0.0524	 decision: 0.3582	 get_bound: 1.7615	 add_domain: 0.0280
Current lb:-0.19156117737293243
2560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 19.24386501312256

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 233] [2, 231] [2, 231] [2, 233] [2, 233] [2, 233] [2, 233] [2, 233] [2, 231] [2, 231] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 40.58006286621094 with beta sum per layer: [0.0, 0.0, 330.9505615234375]
alpha/beta optimization time: 1.6258413791656494
This batch time : update_bounds func: 1.7700	 prepare: 0.0331	 bound: 1.6262	 transfer: 0.0865	 finalize: 0.0232
Accumulated time: update_bounds func: 15.3941	 prepare: 0.2511	 bound: 14.3663	 transfer: 0.0865	 finalize: 0.2300
batch bounding time:  1.7706923484802246
Current worst splitting domains [lb, ub] (depth):
[-0.18131,   inf] (29), [-0.17982,   inf] (29), [-0.17293,   inf] (29), [-0.17253,   inf] (29), [-0.17226,   inf] (29), [-0.17195,   inf] (29), [-0.17177,   inf] (29), [-0.17020,   inf] (29), [-0.16858,   inf] (29), [-0.16725,   inf] (29), [-0.16660,   inf] (29), [-0.16624,   inf] (29), [-0.16414,   inf] (29), [-0.16358,   inf] (29), [-0.16185,   inf] (29), [-0.16048,   inf] (29), [-0.15989,   inf] (29), [-0.15948,   inf] (29), [-0.15882,   inf] (29), [-0.15860,   inf] (29), 
length of domains: 896
Total time: 2.1597	 pickout: 0.0585	 decision: 0.3018	 get_bound: 1.7714	 add_domain: 0.0279
Current lb:-0.1813143491744995
2960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 21.407142877578735

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 21] [2, 21] [2, 21] [2, 21] [2, 21] [2, 21] [2, 21] [2, 170] [2, 170] [2, 170] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 42.649017333984375 with beta sum per layer: [0.0, 0.0, 312.6072998046875]
alpha/beta optimization time: 1.6279160976409912
This batch time : update_bounds func: 1.7661	 prepare: 0.0334	 bound: 1.6283	 transfer: 0.0796	 finalize: 0.0238
Accumulated time: update_bounds func: 17.1603	 prepare: 0.2846	 bound: 15.9945	 transfer: 0.0796	 finalize: 0.2538
batch bounding time:  1.7667319774627686
Current worst splitting domains [lb, ub] (depth):
[-0.16852,   inf] (31), [-0.16680,   inf] (31), [-0.16535,   inf] (31), [-0.16483,   inf] (31), [-0.16455,   inf] (31), [-0.16367,   inf] (31), [-0.16223,   inf] (31), [-0.16183,   inf] (31), [-0.16052,   inf] (31), [-0.15818,   inf] (31), [-0.15777,   inf] (31), [-0.15716,   inf] (31), [-0.15647,   inf] (31), [-0.15644,   inf] (31), [-0.15535,   inf] (31), [-0.15449,   inf] (31), [-0.15432,   inf] (31), [-0.15385,   inf] (31), [-0.15383,   inf] (31), [-0.15382,   inf] (31), 
length of domains: 1096
Total time: 2.2002	 pickout: 0.0493	 decision: 0.3542	 get_bound: 1.7674	 add_domain: 0.0292
Current lb:-0.16852132976055145
3360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 23.611022233963013

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 37] [2, 21] [2, 21] [2, 213] [2, 37] [2, 213] [2, 37] [2, 170] [2, 170] [2, 21] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 40.31317901611328 with beta sum per layer: [0.0, 0.0, 308.04254150390625]
alpha/beta optimization time: 1.6197783946990967
This batch time : update_bounds func: 1.7617	 prepare: 0.0332	 bound: 1.6201	 transfer: 0.0852	 finalize: 0.0222
Accumulated time: update_bounds func: 18.9220	 prepare: 0.3178	 bound: 17.6146	 transfer: 0.0852	 finalize: 0.2760
batch bounding time:  1.7623202800750732
Current worst splitting domains [lb, ub] (depth):
[-0.16004,   inf] (33), [-0.15888,   inf] (33), [-0.15702,   inf] (33), [-0.15426,   inf] (33), [-0.15333,   inf] (33), [-0.15304,   inf] (33), [-0.15277,   inf] (33), [-0.15207,   inf] (33), [-0.15206,   inf] (33), [-0.15175,   inf] (33), [-0.15174,   inf] (33), [-0.15160,   inf] (33), [-0.15114,   inf] (33), [-0.15099,   inf] (33), [-0.15057,   inf] (33), [-0.14908,   inf] (33), [-0.14899,   inf] (33), [-0.14756,   inf] (33), [-0.14716,   inf] (33), [-0.14592,   inf] (33), 
length of domains: 1296
Total time: 2.2119	 pickout: 0.0575	 decision: 0.3590	 get_bound: 1.7630	 add_domain: 0.0324
Current lb:-0.1600361168384552
3760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 25.82681965827942

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 213] [2, 213] [2, 213] [2, 21] [2, 213] [2, 37] [2, 37] [2, 213] [2, 213] [2, 213] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 39.95756530761719 with beta sum per layer: [0.0, 0.0, 281.4899597167969]
alpha/beta optimization time: 1.6195659637451172
This batch time : update_bounds func: 1.7555	 prepare: 0.0335	 bound: 1.6199	 transfer: 0.0782	 finalize: 0.0228
Accumulated time: update_bounds func: 20.6774	 prepare: 0.3513	 bound: 19.2345	 transfer: 0.0782	 finalize: 0.2987
batch bounding time:  1.7561278343200684
Current worst splitting domains [lb, ub] (depth):
[-0.14931,   inf] (35), [-0.14856,   inf] (35), [-0.14837,   inf] (35), [-0.14667,   inf] (35), [-0.14305,   inf] (35), [-0.14157,   inf] (35), [-0.14150,   inf] (35), [-0.14139,   inf] (35), [-0.14128,   inf] (35), [-0.14105,   inf] (35), [-0.14059,   inf] (35), [-0.14037,   inf] (35), [-0.14006,   inf] (35), [-0.13993,   inf] (35), [-0.13799,   inf] (35), [-0.13619,   inf] (35), [-0.13611,   inf] (35), [-0.13597,   inf] (35), [-0.13558,   inf] (35), [-0.13462,   inf] (35), 
length of domains: 1496
Total time: 2.2130	 pickout: 0.0569	 decision: 0.3041	 get_bound: 1.7569	 add_domain: 0.0951
Current lb:-0.1493101865053177
4160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 28.043607234954834

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 175] [2, 170] [2, 175] [2, 175] [2, 175] [2, 37] [2, 175] [2, 175] [2, 175] [2, 175] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 37.38383483886719 with beta sum per layer: [0.0, 0.0, 265.7946472167969]
alpha/beta optimization time: 1.6293230056762695
This batch time : update_bounds func: 1.7749	 prepare: 0.0335	 bound: 1.6297	 transfer: 0.0862	 finalize: 0.0244
Accumulated time: update_bounds func: 22.4523	 prepare: 0.3848	 bound: 20.8642	 transfer: 0.0862	 finalize: 0.3231
batch bounding time:  1.7755980491638184
Current worst splitting domains [lb, ub] (depth):
[-0.14733,   inf] (37), [-0.14692,   inf] (37), [-0.14633,   inf] (37), [-0.14465,   inf] (37), [-0.14097,   inf] (37), [-0.13950,   inf] (37), [-0.13942,   inf] (37), [-0.13927,   inf] (37), [-0.13896,   inf] (37), [-0.13405,   inf] (37), [-0.13156,   inf] (37), [-0.13024,   inf] (37), [-0.13000,   inf] (37), [-0.12978,   inf] (37), [-0.12961,   inf] (37), [-0.12926,   inf] (37), [-0.12857,   inf] (37), [-0.12825,   inf] (37), [-0.12787,   inf] (37), [-0.12787,   inf] (37), 
length of domains: 1696
Total time: 2.1660	 pickout: 0.0500	 decision: 0.3059	 get_bound: 1.7763	 add_domain: 0.0338
Current lb:-0.14732572436332703
4560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 30.214643716812134

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 37] [2, 213] [2, 37] [2, 21] [2, 21] [2, 37] [2, 170] [2, 213] [2, 37] [2, 37] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 33.480751037597656 with beta sum per layer: [0.0, 0.0, 259.8553466796875]
alpha/beta optimization time: 1.620232105255127
This batch time : update_bounds func: 1.7660	 prepare: 0.0336	 bound: 1.6206	 transfer: 0.0865	 finalize: 0.0242
Accumulated time: update_bounds func: 24.2183	 prepare: 0.4185	 bound: 22.4848	 transfer: 0.0865	 finalize: 0.3473
batch bounding time:  1.7665743827819824
Current worst splitting domains [lb, ub] (depth):
[-0.13777,   inf] (39), [-0.13642,   inf] (39), [-0.13565,   inf] (39), [-0.13465,   inf] (39), [-0.12883,   inf] (39), [-0.12811,   inf] (39), [-0.12809,   inf] (39), [-0.12795,   inf] (39), [-0.12793,   inf] (39), [-0.12720,   inf] (39), [-0.12620,   inf] (39), [-0.12616,   inf] (39), [-0.12582,   inf] (39), [-0.12580,   inf] (39), [-0.12579,   inf] (39), [-0.12543,   inf] (39), [-0.12374,   inf] (39), [-0.12247,   inf] (39), [-0.12245,   inf] (39), [-0.12223,   inf] (39), 
length of domains: 1896
Total time: 2.2376	 pickout: 0.0634	 decision: 0.3723	 get_bound: 1.7673	 add_domain: 0.0346
Current lb:-0.137771874666214
4960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 32.456815242767334

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 49] [2, 49] [2, 49] [2, 49] [2, 49] [2, 49] [2, 49] [2, 49] [2, 49] [2, 49] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 34.50010681152344 with beta sum per layer: [0.0, 0.0, 263.71697998046875]
alpha/beta optimization time: 1.6310486793518066
This batch time : update_bounds func: 1.7687	 prepare: 0.0333	 bound: 1.6314	 transfer: 0.0793	 finalize: 0.0236
Accumulated time: update_bounds func: 25.9870	 prepare: 0.4518	 bound: 24.1161	 transfer: 0.0793	 finalize: 0.3709
batch bounding time:  1.769345760345459
Current worst splitting domains [lb, ub] (depth):
[-0.12976,   inf] (41), [-0.12831,   inf] (41), [-0.12735,   inf] (41), [-0.12629,   inf] (41), [-0.12043,   inf] (41), [-0.12007,   inf] (41), [-0.11961,   inf] (41), [-0.11938,   inf] (41), [-0.11931,   inf] (41), [-0.11820,   inf] (41), [-0.11762,   inf] (41), [-0.11752,   inf] (41), [-0.11691,   inf] (41), [-0.11675,   inf] (41), [-0.11667,   inf] (41), [-0.11640,   inf] (41), [-0.11448,   inf] (41), [-0.11368,   inf] (41), [-0.11367,   inf] (41), [-0.11359,   inf] (41), 
length of domains: 2096
Total time: 2.1739	 pickout: 0.0576	 decision: 0.3035	 get_bound: 1.7701	 add_domain: 0.0427
Current lb:-0.12976278364658356
5360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 34.63776135444641

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 62] [2, 62] [2, 62] [2, 62] [2, 62] [2, 62] [2, 62] [2, 62] [2, 62] [2, 62] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 33.90878677368164 with beta sum per layer: [0.0, 0.3354864716529846, 258.789306640625]
alpha/beta optimization time: 1.615250825881958
This batch time : update_bounds func: 1.7622	 prepare: 0.0345	 bound: 1.6156	 transfer: 0.0868	 finalize: 0.0242
Accumulated time: update_bounds func: 27.7491	 prepare: 0.4863	 bound: 25.7318	 transfer: 0.0868	 finalize: 0.3951
batch bounding time:  1.7627856731414795
Current worst splitting domains [lb, ub] (depth):
[-0.12020,   inf] (43), [-0.11869,   inf] (43), [-0.11786,   inf] (43), [-0.11688,   inf] (43), [-0.11665,   inf] (43), [-0.11649,   inf] (43), [-0.11647,   inf] (43), [-0.11619,   inf] (43), [-0.11553,   inf] (43), [-0.11420,   inf] (43), [-0.11370,   inf] (43), [-0.11286,   inf] (43), [-0.11231,   inf] (43), [-0.11213,   inf] (43), [-0.11130,   inf] (43), [-0.11088,   inf] (43), [-0.11066,   inf] (43), [-0.11048,   inf] (43), [-0.11038,   inf] (43), [-0.10970,   inf] (43), 
length of domains: 2296
Total time: 2.2610	 pickout: 0.0756	 decision: 0.3851	 get_bound: 1.7635	 add_domain: 0.0368
Current lb:-0.12020225822925568
5760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 36.90291738510132

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 5349] [1, 5349] [1, 5349] [1, 5349] [2, 62] [2, 62] [2, 62] [2, 103] [1, 5349] [2, 62] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 33.526912689208984 with beta sum per layer: [0.0, 1.039646863937378, 232.2176971435547]
alpha/beta optimization time: 1.60744047164917
This batch time : update_bounds func: 1.8310	 prepare: 0.0350	 bound: 1.6078	 transfer: 0.0856	 finalize: 0.1015
Accumulated time: update_bounds func: 29.5801	 prepare: 0.5213	 bound: 27.3395	 transfer: 0.0856	 finalize: 0.4966
batch bounding time:  1.8316402435302734
Current worst splitting domains [lb, ub] (depth):
[-0.11994,   inf] (45), [-0.11845,   inf] (45), [-0.11759,   inf] (45), [-0.11661,   inf] (45), [-0.11511,   inf] (45), [-0.11324,   inf] (45), [-0.11220,   inf] (45), [-0.11141,   inf] (45), [-0.11069,   inf] (45), [-0.11025,   inf] (45), [-0.11012,   inf] (45), [-0.10942,   inf] (45), [-0.10919,   inf] (45), [-0.10833,   inf] (45), [-0.10811,   inf] (45), [-0.10785,   inf] (45), [-0.10683,   inf] (45), [-0.10638,   inf] (45), [-0.10636,   inf] (45), [-0.10630,   inf] (45), 
length of domains: 2496
Total time: 2.2398	 pickout: 0.0669	 decision: 0.3042	 get_bound: 1.8324	 add_domain: 0.0363
Current lb:-0.11994323134422302
6160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 39.147584438323975

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 103] [2, 103] [2, 103] [2, 103] [2, 103] [2, 103] [2, 103] [2, 62] [2, 103] [2, 103] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 31.44463348388672 with beta sum per layer: [0.0, 0.6127752065658569, 235.13494873046875]
alpha/beta optimization time: 1.621410846710205
This batch time : update_bounds func: 1.7702	 prepare: 0.0365	 bound: 1.6218	 transfer: 0.0860	 finalize: 0.0248
Accumulated time: update_bounds func: 31.3503	 prepare: 0.5578	 bound: 28.9613	 transfer: 0.0860	 finalize: 0.5213
batch bounding time:  1.7708168029785156
Current worst splitting domains [lb, ub] (depth):
[-0.11526,   inf] (47), [-0.11375,   inf] (47), [-0.11285,   inf] (47), [-0.11179,   inf] (47), [-0.11033,   inf] (47), [-0.10843,   inf] (47), [-0.10730,   inf] (47), [-0.10724,   inf] (47), [-0.10616,   inf] (47), [-0.10581,   inf] (47), [-0.10572,   inf] (47), [-0.10551,   inf] (47), [-0.10471,   inf] (47), [-0.10379,   inf] (47), [-0.10377,   inf] (47), [-0.10347,   inf] (47), [-0.10314,   inf] (47), [-0.10231,   inf] (47), [-0.10187,   inf] (47), [-0.10185,   inf] (47), 
length of domains: 2696
Total time: 2.1802	 pickout: 0.0632	 decision: 0.3077	 get_bound: 1.7715	 add_domain: 0.0377
Current lb:-0.11526075005531311
6560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 41.332783699035645

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 130] [2, 130] [2, 130] [2, 130] [2, 130] [2, 130] [2, 103] [2, 130] [2, 130] [2, 130] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 29.156620025634766 with beta sum per layer: [0.0, 0.6919859647750854, 267.1383056640625]
alpha/beta optimization time: 1.6130647659301758
This batch time : update_bounds func: 1.7519	 prepare: 0.0363	 bound: 1.6134	 transfer: 0.0776	 finalize: 0.0233
Accumulated time: update_bounds func: 33.1022	 prepare: 0.5941	 bound: 30.5747	 transfer: 0.0776	 finalize: 0.5447
batch bounding time:  1.7525322437286377
Current worst splitting domains [lb, ub] (depth):
[-0.11322,   inf] (49), [-0.11167,   inf] (49), [-0.11076,   inf] (49), [-0.10972,   inf] (49), [-0.10836,   inf] (49), [-0.10635,   inf] (49), [-0.10513,   inf] (49), [-0.10394,   inf] (49), [-0.10371,   inf] (49), [-0.10361,   inf] (49), [-0.10328,   inf] (49), [-0.10278,   inf] (49), [-0.10259,   inf] (49), [-0.10160,   inf] (49), [-0.10153,   inf] (49), [-0.10126,   inf] (49), [-0.10110,   inf] (49), [-0.10020,   inf] (49), [-0.09974,   inf] (49), [-0.09945,   inf] (49), 
length of domains: 2896
Total time: 2.2621	 pickout: 0.0587	 decision: 0.4102	 get_bound: 1.7533	 add_domain: 0.0398
Current lb:-0.11321897804737091
6960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 43.59960627555847

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 105] [2, 105] [2, 105] [2, 105] [2, 105] [2, 105] [2, 105] [2, 105] [2, 105] [2, 105] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 29.383495330810547 with beta sum per layer: [0.0, 0.6560356020927429, 269.27410888671875]
alpha/beta optimization time: 1.6180670261383057
This batch time : update_bounds func: 1.7660	 prepare: 0.0367	 bound: 1.6188	 transfer: 0.0853	 finalize: 0.0240
Accumulated time: update_bounds func: 34.8682	 prepare: 0.6308	 bound: 32.1935	 transfer: 0.0853	 finalize: 0.5687
batch bounding time:  1.7666568756103516
Current worst splitting domains [lb, ub] (depth):
[-0.10744,   inf] (51), [-0.10590,   inf] (51), [-0.10514,   inf] (51), [-0.10410,   inf] (51), [-0.10265,   inf] (51), [-0.10077,   inf] (51), [-0.09972,   inf] (51), [-0.09860,   inf] (51), [-0.09830,   inf] (51), [-0.09816,   inf] (51), [-0.09793,   inf] (51), [-0.09748,   inf] (51), [-0.09730,   inf] (51), [-0.09643,   inf] (51), [-0.09615,   inf] (51), [-0.09599,   inf] (51), [-0.09537,   inf] (51), [-0.09493,   inf] (51), [-0.09493,   inf] (51), [-0.09457,   inf] (51), 
length of domains: 3096
Total time: 2.1858	 pickout: 0.0682	 decision: 0.3098	 get_bound: 1.7674	 add_domain: 0.0404
Current lb:-0.10743710398674011
7360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 45.790079832077026

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 51] [2, 51] [2, 51] [2, 51] [2, 51] [2, 51] [2, 51] [2, 51] [2, 51] [2, 51] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 29.627180099487305 with beta sum per layer: [0.0, 0.9557979106903076, 271.1026611328125]
alpha/beta optimization time: 1.6166133880615234
This batch time : update_bounds func: 1.7662	 prepare: 0.0367	 bound: 1.6170	 transfer: 0.0860	 finalize: 0.0252
Accumulated time: update_bounds func: 36.6344	 prepare: 0.6675	 bound: 33.8106	 transfer: 0.0860	 finalize: 0.5939
batch bounding time:  1.7668304443359375
Current worst splitting domains [lb, ub] (depth):
[-0.10087,   inf] (53), [-0.09933,   inf] (53), [-0.09907,   inf] (53), [-0.09865,   inf] (53), [-0.09756,   inf] (53), [-0.09741,   inf] (53), [-0.09607,   inf] (53), [-0.09604,   inf] (53), [-0.09534,   inf] (53), [-0.09422,   inf] (53), [-0.09400,   inf] (53), [-0.09346,   inf] (53), [-0.09336,   inf] (53), [-0.09314,   inf] (53), [-0.09314,   inf] (53), [-0.09228,   inf] (53), [-0.09220,   inf] (53), [-0.09209,   inf] (53), [-0.09191,   inf] (53), [-0.09179,   inf] (53), 
length of domains: 3296
Total time: 2.2864	 pickout: 0.0680	 decision: 0.4122	 get_bound: 1.7676	 add_domain: 0.0387
Current lb:-0.10086610913276672
7760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 48.081408977508545

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 193] [1, 3500] [2, 80] [1, 3500] [1, 3500] [2, 123] [2, 193] [2, 193] [1, 3500] [2, 123] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 29.01647186279297 with beta sum per layer: [0.0, 1.8756968975067139, 274.75482177734375]
alpha/beta optimization time: 1.616443157196045
This batch time : update_bounds func: 1.7624	 prepare: 0.0368	 bound: 1.6168	 transfer: 0.0820	 finalize: 0.0256
Accumulated time: update_bounds func: 38.3968	 prepare: 0.7042	 bound: 35.4274	 transfer: 0.0820	 finalize: 0.6196
batch bounding time:  1.7630722522735596
Current worst splitting domains [lb, ub] (depth):
[-0.09913,   inf] (55), [-0.09840,   inf] (55), [-0.09825,   inf] (55), [-0.09809,   inf] (55), [-0.09733,   inf] (55), [-0.09496,   inf] (55), [-0.09436,   inf] (55), [-0.09429,   inf] (55), [-0.09346,   inf] (55), [-0.09331,   inf] (55), [-0.09316,   inf] (55), [-0.09310,   inf] (55), [-0.09207,   inf] (55), [-0.09193,   inf] (55), [-0.09179,   inf] (55), [-0.09152,   inf] (55), [-0.09138,   inf] (55), [-0.09135,   inf] (55), [-0.09115,   inf] (55), [-0.09114,   inf] (55), 
length of domains: 3496
Total time: 2.1684	 pickout: 0.0538	 decision: 0.3115	 get_bound: 1.7638	 add_domain: 0.0393
Current lb:-0.0991271361708641
8160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 50.255157470703125

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 123] [2, 193] [2, 80] [2, 193] [2, 123] [2, 123] [2, 123] [2, 193] [1, 7261] [1, 3500] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 28.375591278076172 with beta sum per layer: [0.0, 2.567302703857422, 258.26422119140625]
alpha/beta optimization time: 1.6155004501342773
This batch time : update_bounds func: 1.7689	 prepare: 0.0371	 bound: 1.6159	 transfer: 0.0905	 finalize: 0.0242
Accumulated time: update_bounds func: 40.1657	 prepare: 0.7414	 bound: 37.0432	 transfer: 0.0905	 finalize: 0.6438
batch bounding time:  1.769608974456787
Current worst splitting domains [lb, ub] (depth):
[-0.09737,   inf] (57), [-0.09618,   inf] (57), [-0.09571,   inf] (57), [-0.09540,   inf] (57), [-0.09442,   inf] (57), [-0.09304,   inf] (57), [-0.09199,   inf] (57), [-0.09161,   inf] (57), [-0.09152,   inf] (57), [-0.09151,   inf] (57), [-0.09137,   inf] (57), [-0.09117,   inf] (57), [-0.09052,   inf] (57), [-0.09052,   inf] (57), [-0.09029,   inf] (57), [-0.09012,   inf] (57), [-0.08908,   inf] (55), [-0.08900,   inf] (57), [-0.08892,   inf] (57), [-0.08874,   inf] (55), 
length of domains: 3696
Total time: 2.2786	 pickout: 0.0527	 decision: 0.4135	 get_bound: 1.7704	 add_domain: 0.0419
Current lb:-0.0973731279373169
8560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 52.53898859024048

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7261] [2, 80] [2, 80] [2, 123] [2, 193] [2, 123] [2, 80] [2, 80] [2, 80] [2, 123] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 27.543804168701172 with beta sum per layer: [0.0, 0.9256700873374939, 278.3657531738281]
alpha/beta optimization time: 1.6159312725067139
This batch time : update_bounds func: 1.7690	 prepare: 0.0368	 bound: 1.6163	 transfer: 0.0899	 finalize: 0.0248
Accumulated time: update_bounds func: 41.9347	 prepare: 0.7781	 bound: 38.6595	 transfer: 0.0899	 finalize: 0.6686
batch bounding time:  1.7696382999420166
Current worst splitting domains [lb, ub] (depth):
[-0.09554,   inf] (59), [-0.09530,   inf] (59), [-0.09485,   inf] (59), [-0.09238,   inf] (59), [-0.09235,   inf] (59), [-0.09170,   inf] (59), [-0.09109,   inf] (59), [-0.09074,   inf] (59), [-0.09063,   inf] (59), [-0.09047,   inf] (59), [-0.09003,   inf] (59), [-0.08964,   inf] (59), [-0.08941,   inf] (59), [-0.08863,   inf] (59), [-0.08819,   inf] (59), [-0.08812,   inf] (57), [-0.08777,   inf] (59), [-0.08776,   inf] (59), [-0.08768,   inf] (55), [-0.08768,   inf] (57), 
length of domains: 3896
Total time: 2.1745	 pickout: 0.0528	 decision: 0.3094	 get_bound: 1.7704	 add_domain: 0.0419
Current lb:-0.09554097056388855
8960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 54.71842312812805

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 123] [2, 193] [2, 123] [1, 3603] [1, 3500] [2, 80] [2, 193] [2, 123] [1, 3500] [2, 193] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 27.61865234375 with beta sum per layer: [0.0, 2.89760160446167, 262.9372863769531]
alpha/beta optimization time: 1.6179580688476562
This batch time : update_bounds func: 1.7728	 prepare: 0.0378	 bound: 1.6183	 transfer: 0.0900	 finalize: 0.0254
Accumulated time: update_bounds func: 43.7075	 prepare: 0.8159	 bound: 40.2778	 transfer: 0.0900	 finalize: 0.6941
batch bounding time:  1.773484230041504
Current worst splitting domains [lb, ub] (depth):
[-0.09255,   inf] (61), [-0.09254,   inf] (61), [-0.09214,   inf] (61), [-0.09195,   inf] (61), [-0.09166,   inf] (61), [-0.09083,   inf] (61), [-0.09044,   inf] (61), [-0.08917,   inf] (61), [-0.08844,   inf] (61), [-0.08773,   inf] (61), [-0.08768,   inf] (61), [-0.08755,   inf] (61), [-0.08737,   inf] (61), [-0.08673,   inf] (61), [-0.08656,   inf] (61), [-0.08652,   inf] (55), [-0.08642,   inf] (57), [-0.08638,   inf] (61), [-0.08627,   inf] (61), [-0.08622,   inf] (61), 
length of domains: 4096
Total time: 2.2911	 pickout: 0.0533	 decision: 0.4228	 get_bound: 1.7743	 add_domain: 0.0407
Current lb:-0.09254603832960129
9360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 57.014358043670654

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7261] [1, 3500] [2, 123] [1, 7261] [1, 7261] [1, 7261] [1, 7261] [1, 7261] [1, 7261] [1, 7261] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 27.71282958984375 with beta sum per layer: [0.0, 2.0668041706085205, 256.9598083496094]
alpha/beta optimization time: 1.6108002662658691
This batch time : update_bounds func: 1.7672	 prepare: 0.0391	 bound: 1.6114	 transfer: 0.0893	 finalize: 0.0260
Accumulated time: update_bounds func: 45.4747	 prepare: 0.8550	 bound: 41.8893	 transfer: 0.0893	 finalize: 0.7201
batch bounding time:  1.767881155014038
Current worst splitting domains [lb, ub] (depth):
[-0.09236,   inf] (63), [-0.09077,   inf] (63), [-0.09025,   inf] (63), [-0.08999,   inf] (63), [-0.08914,   inf] (63), [-0.08912,   inf] (63), [-0.08865,   inf] (63), [-0.08791,   inf] (63), [-0.08782,   inf] (63), [-0.08749,   inf] (63), [-0.08746,   inf] (63), [-0.08745,   inf] (63), [-0.08678,   inf] (63), [-0.08673,   inf] (63), [-0.08664,   inf] (63), [-0.08598,   inf] (63), [-0.08596,   inf] (63), [-0.08565,   inf] (63), [-0.08561,   inf] (57), [-0.08559,   inf] (63), 
length of domains: 4296
Total time: 2.1742	 pickout: 0.0521	 decision: 0.3121	 get_bound: 1.7686	 add_domain: 0.0414
Current lb:-0.09235727787017822
9760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 59.194051027297974

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7268] [1, 4851] [1, 7268] [1, 3500] [1, 7268] [1, 7268] [1, 7268] [1, 4851] [1, 7268] [1, 7268] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 27.034908294677734 with beta sum per layer: [0.0, 5.107059478759766, 259.39971923828125]
alpha/beta optimization time: 1.6147072315216064
This batch time : update_bounds func: 1.7676	 prepare: 0.0372	 bound: 1.6152	 transfer: 0.0894	 finalize: 0.0246
Accumulated time: update_bounds func: 47.2423	 prepare: 0.8923	 bound: 43.5045	 transfer: 0.0894	 finalize: 0.7446
batch bounding time:  1.7682900428771973
Current worst splitting domains [lb, ub] (depth):
[-0.09092,   inf] (65), [-0.09002,   inf] (65), [-0.08981,   inf] (65), [-0.08887,   inf] (65), [-0.08774,   inf] (65), [-0.08768,   inf] (65), [-0.08716,   inf] (65), [-0.08714,   inf] (65), [-0.08691,   inf] (65), [-0.08659,   inf] (65), [-0.08635,   inf] (65), [-0.08631,   inf] (65), [-0.08607,   inf] (65), [-0.08600,   inf] (65), [-0.08558,   inf] (65), [-0.08527,   inf] (65), [-0.08526,   inf] (65), [-0.08521,   inf] (65), [-0.08506,   inf] (57), [-0.08456,   inf] (59), 
length of domains: 4496
Total time: 2.2996	 pickout: 0.0511	 decision: 0.4361	 get_bound: 1.7690	 add_domain: 0.0434
Current lb:-0.09092482924461365
10160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 61.49867916107178

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7651] [1, 7268] [1, 4851] [1, 7651] [1, 7651] [1, 7651] [1, 4851] [1, 7268] [1, 3108] [1, 7268] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 27.052560806274414 with beta sum per layer: [0.0, 5.344348907470703, 253.11940002441406]
alpha/beta optimization time: 1.6041886806488037
This batch time : update_bounds func: 1.7572	 prepare: 0.0378	 bound: 1.6045	 transfer: 0.0891	 finalize: 0.0245
Accumulated time: update_bounds func: 48.9995	 prepare: 0.9300	 bound: 45.1090	 transfer: 0.0891	 finalize: 0.7691
batch bounding time:  1.757798671722412
Current worst splitting domains [lb, ub] (depth):
[-0.08918,   inf] (67), [-0.08856,   inf] (67), [-0.08813,   inf] (67), [-0.08751,   inf] (67), [-0.08644,   inf] (67), [-0.08607,   inf] (67), [-0.08573,   inf] (67), [-0.08565,   inf] (67), [-0.08563,   inf] (67), [-0.08512,   inf] (67), [-0.08489,   inf] (67), [-0.08488,   inf] (67), [-0.08449,   inf] (67), [-0.08442,   inf] (67), [-0.08425,   inf] (67), [-0.08419,   inf] (59), [-0.08406,   inf] (67), [-0.08387,   inf] (67), [-0.08372,   inf] (67), [-0.08370,   inf] (67), 
length of domains: 4696
Total time: 2.1698	 pickout: 0.0515	 decision: 0.3148	 get_bound: 1.7586	 add_domain: 0.0450
Current lb:-0.089180588722229
10560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 63.67415809631348

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7268] [1, 7651] [1, 3603] [1, 3603] [1, 3108] [1, 7268] [1, 3603] [1, 7651] [1, 3603] [1, 4851] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 27.39838409423828 with beta sum per layer: [0.0, 10.159217834472656, 238.2646026611328]
alpha/beta optimization time: 1.6168434619903564
This batch time : update_bounds func: 1.7684	 prepare: 0.0376	 bound: 1.6172	 transfer: 0.0863	 finalize: 0.0260
Accumulated time: update_bounds func: 50.7679	 prepare: 0.9676	 bound: 46.7262	 transfer: 0.0863	 finalize: 0.7950
batch bounding time:  1.7690997123718262
Current worst splitting domains [lb, ub] (depth):
[-0.08772,   inf] (69), [-0.08744,   inf] (69), [-0.08682,   inf] (69), [-0.08605,   inf] (69), [-0.08564,   inf] (69), [-0.08522,   inf] (69), [-0.08509,   inf] (69), [-0.08501,   inf] (69), [-0.08464,   inf] (69), [-0.08449,   inf] (69), [-0.08428,   inf] (69), [-0.08419,   inf] (69), [-0.08390,   inf] (69), [-0.08385,   inf] (69), [-0.08362,   inf] (69), [-0.08342,   inf] (69), [-0.08336,   inf] (69), [-0.08306,   inf] (69), [-0.08290,   inf] (69), [-0.08287,   inf] (55), 
length of domains: 4896
Total time: 2.3347	 pickout: 0.0680	 decision: 0.4526	 get_bound: 1.7699	 add_domain: 0.0442
Current lb:-0.0877196341753006
10960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 66.0146541595459

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3108] [1, 4851] [1, 4851] [1, 3620] [1, 7651] [1, 3620] [1, 3108] [1, 3108] [1, 7651] [1, 3108] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 27.113739013671875 with beta sum per layer: [0.0, 12.79681396484375, 230.23597717285156]
alpha/beta optimization time: 1.601583480834961
This batch time : update_bounds func: 1.7523	 prepare: 0.0375	 bound: 1.6019	 transfer: 0.0856	 finalize: 0.0260
Accumulated time: update_bounds func: 52.5202	 prepare: 1.0051	 bound: 48.3282	 transfer: 0.0856	 finalize: 0.8211
batch bounding time:  1.7529630661010742
Current worst splitting domains [lb, ub] (depth):
[-0.08690,   inf] (71), [-0.08677,   inf] (71), [-0.08619,   inf] (71), [-0.08505,   inf] (71), [-0.08435,   inf] (71), [-0.08423,   inf] (71), [-0.08422,   inf] (71), [-0.08370,   inf] (71), [-0.08363,   inf] (71), [-0.08354,   inf] (71), [-0.08352,   inf] (71), [-0.08339,   inf] (71), [-0.08310,   inf] (71), [-0.08295,   inf] (71), [-0.08259,   inf] (71), [-0.08255,   inf] (71), [-0.08234,   inf] (59), [-0.08230,   inf] (53), [-0.08230,   inf] (71), [-0.08220,   inf] (67), 
length of domains: 5096
Total time: 2.1770	 pickout: 0.0607	 decision: 0.3183	 get_bound: 1.7537	 add_domain: 0.0443
Current lb:-0.08689957857131958
11360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 68.1972975730896

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7651] [1, 4902] [1, 4902] [1, 3108] [1, 4902] [1, 4902] [1, 3108] [1, 7651] [1, 7651] [1, 3620] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 26.584409713745117 with beta sum per layer: [0.0, 10.250804901123047, 227.2771759033203]
alpha/beta optimization time: 1.5990917682647705
This batch time : update_bounds func: 1.7444	 prepare: 0.0374	 bound: 1.5995	 transfer: 0.0815	 finalize: 0.0249
Accumulated time: update_bounds func: 54.2647	 prepare: 1.0425	 bound: 49.9276	 transfer: 0.0815	 finalize: 0.8459
batch bounding time:  1.7451727390289307
Current worst splitting domains [lb, ub] (depth):
[-0.08654,   inf] (73), [-0.08595,   inf] (73), [-0.08433,   inf] (73), [-0.08420,   inf] (73), [-0.08415,   inf] (73), [-0.08401,   inf] (73), [-0.08372,   inf] (73), [-0.08352,   inf] (73), [-0.08344,   inf] (73), [-0.08329,   inf] (73), [-0.08315,   inf] (73), [-0.08314,   inf] (73), [-0.08287,   inf] (73), [-0.08271,   inf] (73), [-0.08228,   inf] (73), [-0.08216,   inf] (59), [-0.08212,   inf] (73), [-0.08201,   inf] (55), [-0.08191,   inf] (73), [-0.08172,   inf] (57), 
length of domains: 5295
Total time: 2.3185	 pickout: 0.0552	 decision: 0.3158	 get_bound: 1.7460	 add_domain: 0.2015
Current lb:-0.08654379844665527
11760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 70.52144932746887

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3620] [1, 3108] [1, 4902] [1, 4902] [2, 244] [2, 244] [1, 3620] [1, 4902] [1, 2547] [1, 3620] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 27.158870697021484 with beta sum per layer: [0.0, 12.780590057373047, 205.10189819335938]
alpha/beta optimization time: 1.6085712909698486
This batch time : update_bounds func: 1.7581	 prepare: 0.0378	 bound: 1.6089	 transfer: 0.0853	 finalize: 0.0250
Accumulated time: update_bounds func: 56.0228	 prepare: 1.0803	 bound: 51.5366	 transfer: 0.0853	 finalize: 0.8709
batch bounding time:  1.7588427066802979
Current worst splitting domains [lb, ub] (depth):
[-0.08568,   inf] (75), [-0.08520,   inf] (75), [-0.08406,   inf] (75), [-0.08395,   inf] (75), [-0.08328,   inf] (75), [-0.08322,   inf] (75), [-0.08303,   inf] (75), [-0.08288,   inf] (75), [-0.08286,   inf] (75), [-0.08244,   inf] (75), [-0.08238,   inf] (75), [-0.08226,   inf] (75), [-0.08204,   inf] (75), [-0.08194,   inf] (75), [-0.08158,   inf] (75), [-0.08124,   inf] (75), [-0.08123,   inf] (75), [-0.08121,   inf] (75), [-0.08110,   inf] (55), [-0.08109,   inf] (57), 
length of domains: 5495
Total time: 2.1921	 pickout: 0.0719	 decision: 0.3123	 get_bound: 1.7596	 add_domain: 0.0484
Current lb:-0.0856751948595047
12160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 72.71902537345886

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3108] [2, 244] [1, 2547] [2, 244] [2, 244] [1, 4902] [1, 5357] [1, 5357] [1, 3108] [1, 3108] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 26.562463760375977 with beta sum per layer: [0.0, 13.075141906738281, 217.5511932373047]
alpha/beta optimization time: 1.6084871292114258
This batch time : update_bounds func: 1.7621	 prepare: 0.0380	 bound: 1.6088	 transfer: 0.0881	 finalize: 0.0259
Accumulated time: update_bounds func: 57.7850	 prepare: 1.1183	 bound: 53.1454	 transfer: 0.0881	 finalize: 0.8968
batch bounding time:  1.7628247737884521
Current worst splitting domains [lb, ub] (depth):
[-0.08496,   inf] (77), [-0.08403,   inf] (77), [-0.08383,   inf] (77), [-0.08295,   inf] (77), [-0.08277,   inf] (77), [-0.08277,   inf] (77), [-0.08263,   inf] (77), [-0.08215,   inf] (77), [-0.08209,   inf] (77), [-0.08199,   inf] (77), [-0.08183,   inf] (77), [-0.08173,   inf] (77), [-0.08137,   inf] (77), [-0.08121,   inf] (77), [-0.08099,   inf] (77), [-0.08098,   inf] (77), [-0.08086,   inf] (77), [-0.08077,   inf] (77), [-0.08050,   inf] (55), [-0.08047,   inf] (53), 
length of domains: 5695
Total time: 2.1898	 pickout: 0.0690	 decision: 0.3116	 get_bound: 1.7636	 add_domain: 0.0456
Current lb:-0.08496344089508057
12560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 74.91417169570923

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 244] [1, 3620] [2, 244] [2, 244] [1, 4851] [1, 3620] [1, 4851] [2, 244] [1, 3620] [2, 244] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 26.539751052856445 with beta sum per layer: [0.0, 15.277953147888184, 205.5635986328125]
alpha/beta optimization time: 1.6037793159484863
This batch time : update_bounds func: 1.7513	 prepare: 0.0380	 bound: 1.6041	 transfer: 0.0814	 finalize: 0.0265
Accumulated time: update_bounds func: 59.5362	 prepare: 1.1563	 bound: 54.7495	 transfer: 0.0814	 finalize: 0.9233
batch bounding time:  1.7519052028656006
Current worst splitting domains [lb, ub] (depth):
[-0.08378,   inf] (79), [-0.08302,   inf] (79), [-0.08266,   inf] (79), [-0.08224,   inf] (79), [-0.08210,   inf] (79), [-0.08203,   inf] (79), [-0.08179,   inf] (79), [-0.08132,   inf] (79), [-0.08097,   inf] (79), [-0.08079,   inf] (79), [-0.08073,   inf] (79), [-0.08055,   inf] (79), [-0.08039,   inf] (55), [-0.08024,   inf] (79), [-0.08022,   inf] (79), [-0.08016,   inf] (55), [-0.08007,   inf] (61), [-0.08004,   inf] (43), [-0.08002,   inf] (55), [-0.08002,   inf] (77), 
length of domains: 5895
Total time: 2.3464	 pickout: 0.0658	 decision: 0.4805	 get_bound: 1.7526	 add_domain: 0.0474
Current lb:-0.08377726376056671
12960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 77.26601815223694

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3110] [1, 3110] [1, 2546] [1, 668] [1, 668] [1, 3110] [1, 5357] [1, 3110] [1, 3110] [1, 2546] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 26.98322296142578 with beta sum per layer: [0.0, 18.73134994506836, 192.48907470703125]
alpha/beta optimization time: 1.612534761428833
This batch time : update_bounds func: 1.7688	 prepare: 0.0377	 bound: 1.6129	 transfer: 0.0878	 finalize: 0.0291
Accumulated time: update_bounds func: 61.3050	 prepare: 1.1940	 bound: 56.3625	 transfer: 0.0878	 finalize: 0.9524
batch bounding time:  1.769557237625122
Current worst splitting domains [lb, ub] (depth):
[-0.08252,   inf] (81), [-0.08168,   inf] (81), [-0.08155,   inf] (81), [-0.08152,   inf] (81), [-0.08146,   inf] (81), [-0.08096,   inf] (81), [-0.08068,   inf] (81), [-0.08068,   inf] (81), [-0.08059,   inf] (81), [-0.08022,   inf] (81), [-0.08011,   inf] (81), [-0.07981,   inf] (81), [-0.07975,   inf] (57), [-0.07970,   inf] (81), [-0.07959,   inf] (79), [-0.07959,   inf] (71), [-0.07957,   inf] (57), [-0.07957,   inf] (81), [-0.07955,   inf] (77), [-0.07954,   inf] (81), 
length of domains: 6095
Total time: 2.2032	 pickout: 0.0647	 decision: 0.3137	 get_bound: 1.7705	 add_domain: 0.0543
Current lb:-0.0825241208076477
13360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 79.47689914703369

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 5357] [1, 2547] [1, 2547] [1, 2546] [1, 2547] [1, 2547] [1, 2547] [1, 5357] [1, 5357] [1, 2547] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 27.089324951171875 with beta sum per layer: [0.0, 22.31460952758789, 169.43692016601562]
alpha/beta optimization time: 1.6050105094909668
This batch time : update_bounds func: 1.7560	 prepare: 0.0386	 bound: 1.6054	 transfer: 0.0857	 finalize: 0.0251
Accumulated time: update_bounds func: 63.0610	 prepare: 1.2327	 bound: 57.9678	 transfer: 0.0857	 finalize: 0.9774
batch bounding time:  1.7566924095153809
Current worst splitting domains [lb, ub] (depth):
[-0.08226,   inf] (83), [-0.08145,   inf] (83), [-0.08139,   inf] (83), [-0.08132,   inf] (83), [-0.08123,   inf] (83), [-0.08073,   inf] (83), [-0.08045,   inf] (83), [-0.08041,   inf] (83), [-0.08033,   inf] (83), [-0.08004,   inf] (83), [-0.07999,   inf] (83), [-0.07984,   inf] (83), [-0.07957,   inf] (83), [-0.07944,   inf] (83), [-0.07930,   inf] (83), [-0.07926,   inf] (69), [-0.07925,   inf] (83), [-0.07918,   inf] (83), [-0.07917,   inf] (67), [-0.07914,   inf] (83), 
length of domains: 6295
Total time: 2.3948	 pickout: 0.0817	 decision: 0.3116	 get_bound: 1.7575	 add_domain: 0.2441
Current lb:-0.0822577103972435
13760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 81.87842893600464

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3110] [1, 3620] [1, 3110] [1, 3620] [1, 668] [1, 668] [1, 668] [1, 3110] [1, 3494] [1, 3110] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 27.18115234375 with beta sum per layer: [0.0, 20.56791877746582, 165.3478240966797]
alpha/beta optimization time: 1.597792387008667
This batch time : update_bounds func: 1.7495	 prepare: 0.0385	 bound: 1.5982	 transfer: 0.0860	 finalize: 0.0255
Accumulated time: update_bounds func: 64.8105	 prepare: 1.2711	 bound: 59.5660	 transfer: 0.0860	 finalize: 1.0030
batch bounding time:  1.7502024173736572
Current worst splitting domains [lb, ub] (depth):
[-0.08070,   inf] (85), [-0.08032,   inf] (85), [-0.08020,   inf] (85), [-0.08013,   inf] (85), [-0.08006,   inf] (85), [-0.07997,   inf] (85), [-0.07992,   inf] (85), [-0.07972,   inf] (85), [-0.07959,   inf] (85), [-0.07947,   inf] (85), [-0.07914,   inf] (85), [-0.07910,   inf] (85), [-0.07908,   inf] (85), [-0.07885,   inf] (85), [-0.07879,   inf] (55), [-0.07877,   inf] (83), [-0.07877,   inf] (65), [-0.07875,   inf] (55), [-0.07872,   inf] (81), [-0.07871,   inf] (47), 
length of domains: 6495
Total time: 2.1900	 pickout: 0.0714	 decision: 0.3177	 get_bound: 1.7510	 add_domain: 0.0499
Current lb:-0.08069814741611481
14160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 84.07409238815308

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2546] [1, 2546] [1, 2546] [1, 2546] [1, 7650] [1, 7650] [1, 6106] [1, 7650] [1, 7650] [1, 2546] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 27.340072631835938 with beta sum per layer: [0.0, 26.052146911621094, 143.52085876464844]
alpha/beta optimization time: 1.597628116607666
This batch time : update_bounds func: 1.7249	 prepare: 0.0386	 bound: 1.5980	 transfer: 0.0611	 finalize: 0.0259
Accumulated time: update_bounds func: 66.5354	 prepare: 1.3097	 bound: 61.1640	 transfer: 0.0611	 finalize: 1.0289
batch bounding time:  1.7255277633666992
Current worst splitting domains [lb, ub] (depth):
[-0.08054,   inf] (87), [-0.08017,   inf] (87), [-0.08005,   inf] (87), [-0.07999,   inf] (87), [-0.07933,   inf] (87), [-0.07932,   inf] (87), [-0.07931,   inf] (87), [-0.07921,   inf] (87), [-0.07894,   inf] (87), [-0.07894,   inf] (87), [-0.07889,   inf] (87), [-0.07859,   inf] (83), [-0.07854,   inf] (87), [-0.07846,   inf] (77), [-0.07846,   inf] (83), [-0.07843,   inf] (77), [-0.07841,   inf] (87), [-0.07839,   inf] (77), [-0.07838,   inf] (87), [-0.07837,   inf] (55), 
length of domains: 6695
Total time: 2.1643	 pickout: 0.0695	 decision: 0.3183	 get_bound: 1.7263	 add_domain: 0.0503
Current lb:-0.0805421769618988
14560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 86.2440812587738

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6106] [1, 6106] [1, 6106] [1, 6106] [1, 6106] [1, 6106] [1, 2546] [1, 3494] [1, 3494] [1, 6106] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 26.381258010864258 with beta sum per layer: [0.0, 23.97182846069336, 169.27664184570312]
alpha/beta optimization time: 1.6025500297546387
This batch time : update_bounds func: 1.7453	 prepare: 0.0385	 bound: 1.6029	 transfer: 0.0782	 finalize: 0.0244
Accumulated time: update_bounds func: 68.2808	 prepare: 1.3482	 bound: 62.7669	 transfer: 0.0782	 finalize: 1.0533
batch bounding time:  1.7460365295410156
Current worst splitting domains [lb, ub] (depth):
[-0.07996,   inf] (89), [-0.07967,   inf] (89), [-0.07949,   inf] (89), [-0.07948,   inf] (89), [-0.07917,   inf] (89), [-0.07898,   inf] (89), [-0.07883,   inf] (89), [-0.07872,   inf] (89), [-0.07853,   inf] (89), [-0.07841,   inf] (89), [-0.07835,   inf] (89), [-0.07833,   inf] (79), [-0.07817,   inf] (55), [-0.07817,   inf] (89), [-0.07814,   inf] (55), [-0.07811,   inf] (77), [-0.07800,   inf] (83), [-0.07799,   inf] (83), [-0.07798,   inf] (45), [-0.07798,   inf] (73), 
length of domains: 6895
Total time: 2.4062	 pickout: 0.0779	 decision: 0.3189	 get_bound: 1.7469	 add_domain: 0.2625
Current lb:-0.07995674014091492
14960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 88.656081199646

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7650] [1, 7650] [1, 7650] [1, 7650] [1, 7650] [1, 7262] [1, 3110] [1, 7650] [1, 7262] [1, 3110] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 26.090417861938477 with beta sum per layer: [0.0, 21.202880859375, 189.44711303710938]
alpha/beta optimization time: 1.6016619205474854
This batch time : update_bounds func: 1.7477	 prepare: 0.0380	 bound: 1.6020	 transfer: 0.0811	 finalize: 0.0253
Accumulated time: update_bounds func: 70.0285	 prepare: 1.3862	 bound: 64.3689	 transfer: 0.0811	 finalize: 1.0786
batch bounding time:  1.7483978271484375
Current worst splitting domains [lb, ub] (depth):
[-0.07919,   inf] (91), [-0.07894,   inf] (91), [-0.07878,   inf] (91), [-0.07873,   inf] (91), [-0.07853,   inf] (91), [-0.07844,   inf] (91), [-0.07811,   inf] (91), [-0.07799,   inf] (91), [-0.07788,   inf] (57), [-0.07785,   inf] (59), [-0.07783,   inf] (53), [-0.07780,   inf] (81), [-0.07779,   inf] (81), [-0.07773,   inf] (87), [-0.07770,   inf] (91), [-0.07770,   inf] (77), [-0.07769,   inf] (73), [-0.07768,   inf] (83), [-0.07768,   inf] (67), [-0.07767,   inf] (77), 
length of domains: 7094
Total time: 2.1941	 pickout: 0.0775	 decision: 0.3153	 get_bound: 1.7492	 add_domain: 0.0521
Current lb:-0.07919448614120483
15360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 90.85580921173096

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3494] [1, 3110] [1, 3110] [1, 5357] [1, 6106] [1, 3494] [1, 6106] [1, 5357] [2, 123] [2, 193] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 27.005205154418945 with beta sum per layer: [0.0, 23.95461082458496, 160.77633666992188]
alpha/beta optimization time: 1.5998942852020264
This batch time : update_bounds func: 1.7473	 prepare: 0.0381	 bound: 1.6003	 transfer: 0.0814	 finalize: 0.0262
Accumulated time: update_bounds func: 71.7758	 prepare: 1.4243	 bound: 65.9692	 transfer: 0.0814	 finalize: 1.1048
batch bounding time:  1.7480394840240479
Current worst splitting domains [lb, ub] (depth):
[-0.07896,   inf] (93), [-0.07849,   inf] (93), [-0.07820,   inf] (93), [-0.07806,   inf] (93), [-0.07775,   inf] (93), [-0.07765,   inf] (93), [-0.07753,   inf] (83), [-0.07753,   inf] (55), [-0.07750,   inf] (83), [-0.07746,   inf] (87), [-0.07744,   inf] (69), [-0.07744,   inf] (83), [-0.07741,   inf] (55), [-0.07740,   inf] (69), [-0.07740,   inf] (87), [-0.07738,   inf] (65), [-0.07737,   inf] (85), [-0.07737,   inf] (87), [-0.07736,   inf] (69), [-0.07736,   inf] (77), 
length of domains: 7294
Total time: 2.1740	 pickout: 0.0586	 decision: 0.3149	 get_bound: 1.7488	 add_domain: 0.0517
Current lb:-0.0789596438407898
15760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 93.03554058074951

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 5357] [1, 3494] [1, 5357] [1, 6053] [1, 3494] [1, 6053] [1, 3110] [2, 51] [1, 3110] [1, 6106] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 26.68609619140625 with beta sum per layer: [0.0, 27.830678939819336, 156.60360717773438]
alpha/beta optimization time: 1.608112096786499
This batch time : update_bounds func: 1.7597	 prepare: 0.0382	 bound: 1.6085	 transfer: 0.0853	 finalize: 0.0265
Accumulated time: update_bounds func: 73.5355	 prepare: 1.4625	 bound: 67.5777	 transfer: 0.0853	 finalize: 1.1312
batch bounding time:  1.7604913711547852
Current worst splitting domains [lb, ub] (depth):
[-0.07872,   inf] (95), [-0.07814,   inf] (95), [-0.07796,   inf] (95), [-0.07739,   inf] (95), [-0.07729,   inf] (53), [-0.07720,   inf] (55), [-0.07718,   inf] (87), [-0.07717,   inf] (63), [-0.07716,   inf] (87), [-0.07714,   inf] (85), [-0.07714,   inf] (79), [-0.07714,   inf] (81), [-0.07713,   inf] (81), [-0.07709,   inf] (95), [-0.07708,   inf] (69), [-0.07708,   inf] (49), [-0.07708,   inf] (61), [-0.07708,   inf] (75), [-0.07707,   inf] (43), [-0.07707,   inf] (65), 
length of domains: 7493
Total time: 2.4120	 pickout: 0.0691	 decision: 0.3161	 get_bound: 1.7612	 add_domain: 0.2656
Current lb:-0.07872433215379715
16160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 95.45332074165344

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3635] [1, 3635] [1, 3635] [1, 3635] [1, 3500] [2, 51] [1, 6106] [1, 5357] [1, 6106] [1, 7650] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 26.683351516723633 with beta sum per layer: [0.0, 32.48069763183594, 146.4600830078125]
alpha/beta optimization time: 1.6060545444488525
This batch time : update_bounds func: 1.7519	 prepare: 0.0382	 bound: 1.6064	 transfer: 0.0810	 finalize: 0.0251
Accumulated time: update_bounds func: 75.2874	 prepare: 1.5006	 bound: 69.1841	 transfer: 0.0810	 finalize: 1.1563
batch bounding time:  1.7527101039886475
Current worst splitting domains [lb, ub] (depth):
[-0.07813,   inf] (97), [-0.07755,   inf] (97), [-0.07742,   inf] (97), [-0.07697,   inf] (55), [-0.07691,   inf] (87), [-0.07687,   inf] (83), [-0.07687,   inf] (83), [-0.07685,   inf] (97), [-0.07684,   inf] (65), [-0.07682,   inf] (41), [-0.07682,   inf] (73), [-0.07681,   inf] (59), [-0.07681,   inf] (55), [-0.07681,   inf] (87), [-0.07681,   inf] (47), [-0.07681,   inf] (37), [-0.07681,   inf] (77), [-0.07681,   inf] (59), [-0.07681,   inf] (45), [-0.07680,   inf] (49), 
length of domains: 7692
Total time: 2.1839	 pickout: 0.0584	 decision: 0.3166	 get_bound: 1.7535	 add_domain: 0.0554
Current lb:-0.07812882959842682
16560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 97.64444470405579

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6053] [1, 6053] [1, 6053] [2, 51] [1, 6106] [1, 3494] [1, 3494] [1, 6053] [1, 4902] [2, 103] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 26.402212142944336 with beta sum per layer: [0.0, 27.82589340209961, 166.07801818847656]
alpha/beta optimization time: 1.6011247634887695
This batch time : update_bounds func: 1.7514	 prepare: 0.0386	 bound: 1.6015	 transfer: 0.0848	 finalize: 0.0253
Accumulated time: update_bounds func: 77.0389	 prepare: 1.5392	 bound: 70.7856	 transfer: 0.0848	 finalize: 1.1816
batch bounding time:  1.752098560333252
Current worst splitting domains [lb, ub] (depth):
[-0.07709,   inf] (99), [-0.07674,   inf] (55), [-0.07665,   inf] (83), [-0.07663,   inf] (85), [-0.07659,   inf] (85), [-0.07659,   inf] (71), [-0.07658,   inf] (75), [-0.07658,   inf] (79), [-0.07658,   inf] (57), [-0.07658,   inf] (63), [-0.07658,   inf] (73), [-0.07658,   inf] (79), [-0.07658,   inf] (85), [-0.07658,   inf] (87), [-0.07657,   inf] (53), [-0.07657,   inf] (57), [-0.07657,   inf] (81), [-0.07657,   inf] (75), [-0.07657,   inf] (71), [-0.07657,   inf] (45), 
length of domains: 7892
Total time: 2.1890	 pickout: 0.0644	 decision: 0.3167	 get_bound: 1.7529	 add_domain: 0.0550
Current lb:-0.07709337770938873
16960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 99.83947682380676

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 667] [1, 3500] [1, 3494] [1, 7650] [1, 7650] [1, 3108] [1, 4902] [1, 2547] [2, 193] [1, 5357] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 26.257474899291992 with beta sum per layer: [0.0, 33.4151611328125, 153.34271240234375]
alpha/beta optimization time: 1.6049292087554932
This batch time : update_bounds func: 1.7497	 prepare: 0.0386	 bound: 1.6053	 transfer: 0.0781	 finalize: 0.0264
Accumulated time: update_bounds func: 78.7886	 prepare: 1.5778	 bound: 72.3909	 transfer: 0.0781	 finalize: 1.2081
batch bounding time:  1.7504642009735107
Current worst splitting domains [lb, ub] (depth):
[-0.07665,   inf] (101), [-0.07646,   inf] (57), [-0.07643,   inf] (69), [-0.07639,   inf] (81), [-0.07638,   inf] (85), [-0.07637,   inf] (89), [-0.07636,   inf] (85), [-0.07635,   inf] (57), [-0.07634,   inf] (69), [-0.07634,   inf] (71), [-0.07634,   inf] (83), [-0.07634,   inf] (93), [-0.07634,   inf] (99), [-0.07634,   inf] (77), [-0.07633,   inf] (71), [-0.07633,   inf] (75), [-0.07633,   inf] (79), [-0.07633,   inf] (77), [-0.07633,   inf] (85), [-0.07633,   inf] (83), 
length of domains: 8090
Total time: 2.1906	 pickout: 0.0701	 decision: 0.3164	 get_bound: 1.7513	 add_domain: 0.0529
Current lb:-0.07665102928876877
17360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 102.03755617141724

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7262] [2, 193] [1, 5087] [1, 4851] [1, 7650] [1, 7650] [1, 7650] [2, 123] [1, 5087] [1, 3108] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 26.507814407348633 with beta sum per layer: [0.0, 27.196826934814453, 146.51736450195312]
alpha/beta optimization time: 1.6017277240753174
This batch time : update_bounds func: 1.7544	 prepare: 0.0381	 bound: 1.6021	 transfer: 0.0855	 finalize: 0.0274
Accumulated time: update_bounds func: 80.5430	 prepare: 1.6159	 bound: 73.9930	 transfer: 0.0855	 finalize: 1.2355
batch bounding time:  1.755202054977417
Current worst splitting domains [lb, ub] (depth):
[-0.07626,   inf] (53), [-0.07621,   inf] (71), [-0.07617,   inf] (87), [-0.07615,   inf] (103), [-0.07613,   inf] (83), [-0.07613,   inf] (63), [-0.07613,   inf] (73), [-0.07613,   inf] (81), [-0.07613,   inf] (93), [-0.07613,   inf] (79), [-0.07612,   inf] (77), [-0.07612,   inf] (71), [-0.07612,   inf] (75), [-0.07612,   inf] (35), [-0.07612,   inf] (77), [-0.07612,   inf] (85), [-0.07611,   inf] (75), [-0.07611,   inf] (49), [-0.07611,   inf] (47), [-0.07611,   inf] (85), 
length of domains: 8290
Total time: 2.4492	 pickout: 0.0727	 decision: 0.5677	 get_bound: 1.7560	 add_domain: 0.0528
Current lb:-0.07626405358314514
17760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 104.49295210838318

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3500] [2, 244] [1, 6106] [1, 2548] [1, 3620] [1, 7268] [2, 244] [1, 4851] [1, 5357] [2, 244] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 26.034786224365234 with beta sum per layer: [0.0, 29.654769897460938, 147.03933715820312]
alpha/beta optimization time: 1.6055476665496826
This batch time : update_bounds func: 1.7517	 prepare: 0.0383	 bound: 1.6059	 transfer: 0.0806	 finalize: 0.0256
Accumulated time: update_bounds func: 82.2947	 prepare: 1.6541	 bound: 75.5990	 transfer: 0.0806	 finalize: 1.2611
batch bounding time:  1.752424716949463
Current worst splitting domains [lb, ub] (depth):
[-0.07598,   inf] (77), [-0.07598,   inf] (79), [-0.07597,   inf] (55), [-0.07597,   inf] (81), [-0.07596,   inf] (87), [-0.07595,   inf] (73), [-0.07593,   inf] (55), [-0.07593,   inf] (83), [-0.07589,   inf] (69), [-0.07589,   inf] (55), [-0.07589,   inf] (89), [-0.07589,   inf] (67), [-0.07589,   inf] (87), [-0.07589,   inf] (65), [-0.07589,   inf] (67), [-0.07589,   inf] (95), [-0.07589,   inf] (75), [-0.07589,   inf] (43), [-0.07589,   inf] (85), [-0.07589,   inf] (83), 
length of domains: 8489
Total time: 2.1849	 pickout: 0.0578	 decision: 0.3167	 get_bound: 1.7533	 add_domain: 0.0571
Current lb:-0.07598067820072174
18160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 106.68472957611084

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3620] [2, 244] [2, 51] [1, 3620] [1, 6106] [2, 244] [2, 51] [1, 2546] [1, 7651] [1, 1555] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 26.041183471679688 with beta sum per layer: [0.0, 30.836360931396484, 176.1990509033203]
alpha/beta optimization time: 1.605494737625122
This batch time : update_bounds func: 1.7563	 prepare: 0.0387	 bound: 1.6059	 transfer: 0.0847	 finalize: 0.0257
Accumulated time: update_bounds func: 84.0510	 prepare: 1.6928	 bound: 77.2048	 transfer: 0.0847	 finalize: 1.2868
batch bounding time:  1.757035255432129
Current worst splitting domains [lb, ub] (depth):
[-0.07583,   inf] (55), [-0.07580,   inf] (85), [-0.07577,   inf] (67), [-0.07573,   inf] (87), [-0.07571,   inf] (57), [-0.07570,   inf] (87), [-0.07569,   inf] (77), [-0.07569,   inf] (57), [-0.07569,   inf] (65), [-0.07569,   inf] (47), [-0.07568,   inf] (83), [-0.07568,   inf] (43), [-0.07568,   inf] (59), [-0.07568,   inf] (49), [-0.07568,   inf] (57), [-0.07568,   inf] (75), [-0.07568,   inf] (83), [-0.07568,   inf] (93), [-0.07568,   inf] (39), [-0.07568,   inf] (37), 
length of domains: 8689
Total time: 2.1998	 pickout: 0.0688	 decision: 0.3181	 get_bound: 1.7579	 add_domain: 0.0550
Current lb:-0.07583039999008179
18560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 108.89065623283386

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 51] [2, 244] [1, 4902] [1, 6106] [2, 123] [1, 6106] [2, 244] [1, 422] [1, 7651] [2, 105] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 26.4840030670166 with beta sum per layer: [0.0, 31.231399536132812, 148.0408172607422]
alpha/beta optimization time: 1.6103732585906982
This batch time : update_bounds func: 1.7622	 prepare: 0.0384	 bound: 1.6108	 transfer: 0.0852	 finalize: 0.0265
Accumulated time: update_bounds func: 85.8132	 prepare: 1.7312	 bound: 78.8156	 transfer: 0.0852	 finalize: 1.3133
batch bounding time:  1.7628540992736816
Current worst splitting domains [lb, ub] (depth):
[-0.07565,   inf] (59), [-0.07561,   inf] (57), [-0.07550,   inf] (43), [-0.07550,   inf] (55), [-0.07550,   inf] (39), [-0.07550,   inf] (65), [-0.07550,   inf] (73), [-0.07550,   inf] (81), [-0.07550,   inf] (37), [-0.07550,   inf] (83), [-0.07550,   inf] (37), [-0.07550,   inf] (45), [-0.07550,   inf] (49), [-0.07549,   inf] (37), [-0.07549,   inf] (43), [-0.07549,   inf] (63), [-0.07549,   inf] (103), [-0.07549,   inf] (67), [-0.07549,   inf] (57), [-0.07549,   inf] (69), 
length of domains: 8889
Total time: 2.4585	 pickout: 0.0679	 decision: 0.5739	 get_bound: 1.7636	 add_domain: 0.0531
Current lb:-0.07564520835876465
18960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 111.35552835464478

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 80] [2, 123] [2, 103] [2, 123] [2, 49] [1, 7268] [1, 3108] [1, 2548] [2, 213] [1, 3620] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.941919326782227 with beta sum per layer: [0.0, 33.65692138671875, 142.841796875]
alpha/beta optimization time: 1.6021742820739746
This batch time : update_bounds func: 1.7606	 prepare: 0.0386	 bound: 1.6026	 transfer: 0.0871	 finalize: 0.0311
Accumulated time: update_bounds func: 87.5738	 prepare: 1.7698	 bound: 80.4182	 transfer: 0.0871	 finalize: 1.3444
batch bounding time:  1.761387825012207
Current worst splitting domains [lb, ub] (depth):
[-0.07542,   inf] (55), [-0.07536,   inf] (81), [-0.07534,   inf] (53), [-0.07533,   inf] (53), [-0.07532,   inf] (87), [-0.07531,   inf] (65), [-0.07531,   inf] (59), [-0.07531,   inf] (73), [-0.07531,   inf] (71), [-0.07531,   inf] (51), [-0.07531,   inf] (71), [-0.07531,   inf] (79), [-0.07530,   inf] (65), [-0.07530,   inf] (47), [-0.07530,   inf] (51), [-0.07530,   inf] (85), [-0.07530,   inf] (83), [-0.07530,   inf] (87), [-0.07530,   inf] (59), [-0.07530,   inf] (85), 
length of domains: 9089
Total time: 2.2161	 pickout: 0.0739	 decision: 0.3196	 get_bound: 1.7624	 add_domain: 0.0602
Current lb:-0.07542338967323303
19360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 113.5808482170105

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 80] [1, 5357] [1, 3500] [1, 3500] [1, 6106] [1, 3603] [2, 80] [1, 3620] [1, 4851] [2, 51] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.8541202545166 with beta sum per layer: [0.0, 34.428627014160156, 145.38983154296875]
alpha/beta optimization time: 1.599858283996582
This batch time : update_bounds func: 1.7498	 prepare: 0.0389	 bound: 1.6003	 transfer: 0.0849	 finalize: 0.0244
Accumulated time: update_bounds func: 89.3236	 prepare: 1.8087	 bound: 82.0184	 transfer: 0.0849	 finalize: 1.3689
batch bounding time:  1.7505693435668945
Current worst splitting domains [lb, ub] (depth):
[-0.07520,   inf] (79), [-0.07516,   inf] (87), [-0.07514,   inf] (83), [-0.07514,   inf] (81), [-0.07511,   inf] (81), [-0.07511,   inf] (65), [-0.07511,   inf] (77), [-0.07511,   inf] (67), [-0.07511,   inf] (67), [-0.07511,   inf] (79), [-0.07511,   inf] (31), [-0.07511,   inf] (45), [-0.07510,   inf] (47), [-0.07510,   inf] (63), [-0.07510,   inf] (57), [-0.07510,   inf] (49), [-0.07510,   inf] (37), [-0.07510,   inf] (45), [-0.07510,   inf] (83), [-0.07510,   inf] (77), 
length of domains: 9288
Total time: 2.2044	 pickout: 0.0805	 decision: 0.3160	 get_bound: 1.7514	 add_domain: 0.0565
Current lb:-0.07520468533039093
19760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 115.79136085510254

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 668] [1, 6106] [1, 3494] [1, 5357] [2, 244] [1, 4902] [2, 244] [1, 4902] [1, 3108] [1, 2546] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 26.189876556396484 with beta sum per layer: [0.0, 34.282508850097656, 153.7083740234375]
alpha/beta optimization time: 1.5916218757629395
This batch time : update_bounds func: 2.0327	 prepare: 0.0384	 bound: 1.5920	 transfer: 0.0847	 finalize: 0.3163
Accumulated time: update_bounds func: 91.3563	 prepare: 1.8471	 bound: 83.6104	 transfer: 0.0847	 finalize: 1.6852
batch bounding time:  2.0334372520446777
Current worst splitting domains [lb, ub] (depth):
[-0.07499,   inf] (85), [-0.07497,   inf] (81), [-0.07494,   inf] (39), [-0.07494,   inf] (47), [-0.07494,   inf] (97), [-0.07494,   inf] (83), [-0.07494,   inf] (53), [-0.07494,   inf] (77), [-0.07494,   inf] (95), [-0.07494,   inf] (73), [-0.07494,   inf] (53), [-0.07494,   inf] (33), [-0.07494,   inf] (75), [-0.07494,   inf] (67), [-0.07494,   inf] (75), [-0.07493,   inf] (97), [-0.07493,   inf] (67), [-0.07493,   inf] (61), [-0.07493,   inf] (75), [-0.07493,   inf] (85), 
length of domains: 9487
Total time: 2.4843	 pickout: 0.0793	 decision: 0.3147	 get_bound: 2.0343	 add_domain: 0.0560
Current lb:-0.07498517632484436
20160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 118.28173732757568

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7650] [1, 5357] [2, 49] [2, 130] [1, 6053] [1, 2547] [1, 3500] [1, 3620] [1, 2548] [1, 4902] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 26.298118591308594 with beta sum per layer: [0.0, 37.535675048828125, 143.89068603515625]
alpha/beta optimization time: 1.5919713973999023
This batch time : update_bounds func: 1.7269	 prepare: 0.0385	 bound: 1.5923	 transfer: 0.0690	 finalize: 0.0259
Accumulated time: update_bounds func: 93.0832	 prepare: 1.8856	 bound: 85.2028	 transfer: 0.0690	 finalize: 1.7111
batch bounding time:  1.7276239395141602
Current worst splitting domains [lb, ub] (depth):
[-0.07491,   inf] (77), [-0.07477,   inf] (95), [-0.07477,   inf] (43), [-0.07477,   inf] (83), [-0.07477,   inf] (59), [-0.07476,   inf] (81), [-0.07476,   inf] (61), [-0.07476,   inf] (87), [-0.07476,   inf] (55), [-0.07476,   inf] (85), [-0.07476,   inf] (75), [-0.07476,   inf] (83), [-0.07476,   inf] (83), [-0.07476,   inf] (59), [-0.07476,   inf] (85), [-0.07476,   inf] (45), [-0.07476,   inf] (53), [-0.07476,   inf] (73), [-0.07476,   inf] (71), [-0.07476,   inf] (47), 
length of domains: 9686
Total time: 2.1794	 pickout: 0.0807	 decision: 0.3157	 get_bound: 1.7284	 add_domain: 0.0546
Current lb:-0.07490751147270203
20560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 120.46717381477356

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2547] [1, 3635] [1, 5349] [1, 7650] [2, 193] [1, 2547] [2, 193] [1, 6106] [2, 123] [1, 7650] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 26.32802963256836 with beta sum per layer: [0.0, 35.310306549072266, 134.62982177734375]
alpha/beta optimization time: 1.5937941074371338
This batch time : update_bounds func: 1.7444	 prepare: 0.0386	 bound: 1.5942	 transfer: 0.0835	 finalize: 0.0268
Accumulated time: update_bounds func: 94.8276	 prepare: 1.9242	 bound: 86.7969	 transfer: 0.0835	 finalize: 1.7379
batch bounding time:  1.745124101638794
Current worst splitting domains [lb, ub] (depth):
[-0.07469,   inf] (79), [-0.07468,   inf] (57), [-0.07462,   inf] (87), [-0.07462,   inf] (81), [-0.07462,   inf] (81), [-0.07461,   inf] (39), [-0.07461,   inf] (87), [-0.07461,   inf] (97), [-0.07461,   inf] (57), [-0.07461,   inf] (61), [-0.07461,   inf] (91), [-0.07460,   inf] (99), [-0.07460,   inf] (39), [-0.07460,   inf] (85), [-0.07460,   inf] (89), [-0.07460,   inf] (65), [-0.07460,   inf] (91), [-0.07460,   inf] (65), [-0.07460,   inf] (45), [-0.07460,   inf] (77), 
length of domains: 9886
Total time: 2.1876	 pickout: 0.0679	 decision: 0.3182	 get_bound: 1.7459	 add_domain: 0.0555
Current lb:-0.07469020783901215
20960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 122.66253304481506

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 668] [2, 80] [1, 6106] [1, 5357] [1, 5357] [2, 49] [1, 2546] [1, 6053] [2, 123] [1, 7261] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 26.891124725341797 with beta sum per layer: [0.0, 43.958824157714844, 118.86297607421875]
alpha/beta optimization time: 1.5867912769317627
This batch time : update_bounds func: 1.7359	 prepare: 0.0386	 bound: 1.5872	 transfer: 0.0841	 finalize: 0.0247
Accumulated time: update_bounds func: 96.5635	 prepare: 1.9628	 bound: 88.3841	 transfer: 0.0841	 finalize: 1.7626
batch bounding time:  1.7366869449615479
Current worst splitting domains [lb, ub] (depth):
[-0.07451,   inf] (53), [-0.07449,   inf] (67), [-0.07447,   inf] (89), [-0.07445,   inf] (67), [-0.07445,   inf] (75), [-0.07445,   inf] (91), [-0.07445,   inf] (83), [-0.07445,   inf] (75), [-0.07445,   inf] (71), [-0.07445,   inf] (65), [-0.07445,   inf] (87), [-0.07445,   inf] (77), [-0.07445,   inf] (97), [-0.07444,   inf] (83), [-0.07444,   inf] (69), [-0.07444,   inf] (99), [-0.07444,   inf] (83), [-0.07444,   inf] (45), [-0.07444,   inf] (57), [-0.07444,   inf] (93), 
length of domains: 10086
Total time: 2.1774	 pickout: 0.0644	 decision: 0.3164	 get_bound: 1.7375	 add_domain: 0.0591
Current lb:-0.07450637221336365
21360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 124.84654450416565

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 51] [1, 5087] [1, 7650] [1, 3620] [1, 6842] [1, 3603] [1, 668] [1, 2547] [1, 3108] [1, 4851] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 26.426923751831055 with beta sum per layer: [0.0, 41.35276412963867, 123.93492889404297]
alpha/beta optimization time: 1.595165729522705
This batch time : update_bounds func: 1.7461	 prepare: 0.0389	 bound: 1.5955	 transfer: 0.0842	 finalize: 0.0261
Accumulated time: update_bounds func: 98.3096	 prepare: 2.0017	 bound: 89.9797	 transfer: 0.0842	 finalize: 1.7886
batch bounding time:  1.7468786239624023
Current worst splitting domains [lb, ub] (depth):
[-0.07434,   inf] (57), [-0.07431,   inf] (83), [-0.07431,   inf] (81), [-0.07431,   inf] (85), [-0.07431,   inf] (95), [-0.07430,   inf] (79), [-0.07430,   inf] (81), [-0.07430,   inf] (95), [-0.07430,   inf] (69), [-0.07430,   inf] (89), [-0.07430,   inf] (87), [-0.07430,   inf] (83), [-0.07430,   inf] (77), [-0.07430,   inf] (35), [-0.07430,   inf] (39), [-0.07430,   inf] (69), [-0.07429,   inf] (71), [-0.07429,   inf] (43), [-0.07429,   inf] (63), [-0.07429,   inf] (91), 
length of domains: 10286
Total time: 2.4829	 pickout: 0.0657	 decision: 0.6113	 get_bound: 1.7477	 add_domain: 0.0582
Current lb:-0.07433738559484482
21760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 127.33705759048462

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 123] [1, 7650] [1, 2547] [1, 7650] [1, 3110] [1, 2547] [1, 5357] [1, 3635] [1, 3620] [1, 6106] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 26.251426696777344 with beta sum per layer: [0.0, 46.682029724121094, 109.37431335449219]
alpha/beta optimization time: 1.5924787521362305
This batch time : update_bounds func: 1.7468	 prepare: 0.0388	 bound: 1.5928	 transfer: 0.0845	 finalize: 0.0293
Accumulated time: update_bounds func: 100.0564	 prepare: 2.0405	 bound: 91.5725	 transfer: 0.0845	 finalize: 1.8179
batch bounding time:  1.7475731372833252
Current worst splitting domains [lb, ub] (depth):
[-0.07424,   inf] (57), [-0.07416,   inf] (85), [-0.07416,   inf] (51), [-0.07416,   inf] (87), [-0.07416,   inf] (81), [-0.07416,   inf] (87), [-0.07416,   inf] (53), [-0.07416,   inf] (73), [-0.07416,   inf] (81), [-0.07416,   inf] (43), [-0.07416,   inf] (103), [-0.07416,   inf] (77), [-0.07416,   inf] (49), [-0.07416,   inf] (91), [-0.07416,   inf] (81), [-0.07416,   inf] (81), [-0.07416,   inf] (45), [-0.07416,   inf] (31), [-0.07416,   inf] (89), [-0.07416,   inf] (69), 
length of domains: 10482
Total time: 2.1860	 pickout: 0.0633	 decision: 0.3163	 get_bound: 1.7483	 add_domain: 0.0580
Current lb:-0.0742357149720192
22160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 129.53120231628418

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 123] [1, 3494] [2, 51] [1, 3494] [1, 6106] [1, 2546] [1, 3500] [1, 4851] [1, 668] [2, 62] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 26.25198745727539 with beta sum per layer: [0.0, 39.02678680419922, 120.39179992675781]
alpha/beta optimization time: 1.5901870727539062
This batch time : update_bounds func: 1.7407	 prepare: 0.0384	 bound: 1.5905	 transfer: 0.0840	 finalize: 0.0264
Accumulated time: update_bounds func: 101.7971	 prepare: 2.0790	 bound: 93.1630	 transfer: 0.0840	 finalize: 1.8444
batch bounding time:  1.7413651943206787
Current worst splitting domains [lb, ub] (depth):
[-0.07405,   inf] (65), [-0.07404,   inf] (83), [-0.07404,   inf] (43), [-0.07404,   inf] (71), [-0.07404,   inf] (71), [-0.07404,   inf] (89), [-0.07404,   inf] (47), [-0.07404,   inf] (81), [-0.07404,   inf] (61), [-0.07404,   inf] (83), [-0.07404,   inf] (73), [-0.07404,   inf] (67), [-0.07404,   inf] (83), [-0.07404,   inf] (55), [-0.07403,   inf] (45), [-0.07403,   inf] (97), [-0.07403,   inf] (33), [-0.07403,   inf] (81), [-0.07403,   inf] (57), [-0.07403,   inf] (79), 
length of domains: 10682
Total time: 2.1857	 pickout: 0.0703	 decision: 0.3169	 get_bound: 1.7421	 add_domain: 0.0564
Current lb:-0.07404962182044983
22560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 131.72297763824463

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 4851] [1, 3494] [1, 5349] [1, 4902] [1, 7651] [1, 7262] [2, 105] [1, 2546] [1, 7261] [1, 3494] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 26.188268661499023 with beta sum per layer: [0.0, 38.56973648071289, 118.51153564453125]
alpha/beta optimization time: 1.6013343334197998
This batch time : update_bounds func: 1.7428	 prepare: 0.0389	 bound: 1.6017	 transfer: 0.0764	 finalize: 0.0245
Accumulated time: update_bounds func: 103.5399	 prepare: 2.1179	 bound: 94.7647	 transfer: 0.0764	 finalize: 1.8689
batch bounding time:  1.743420124053955
Current worst splitting domains [lb, ub] (depth):
[-0.07398,   inf] (57), [-0.07398,   inf] (57), [-0.07393,   inf] (83), [-0.07392,   inf] (93), [-0.07392,   inf] (71), [-0.07392,   inf] (67), [-0.07392,   inf] (75), [-0.07392,   inf] (73), [-0.07392,   inf] (87), [-0.07392,   inf] (63), [-0.07392,   inf] (41), [-0.07392,   inf] (61), [-0.07392,   inf] (91), [-0.07391,   inf] (89), [-0.07391,   inf] (63), [-0.07391,   inf] (79), [-0.07391,   inf] (89), [-0.07391,   inf] (87), [-0.07391,   inf] (35), [-0.07391,   inf] (75), 
length of domains: 10881
Total time: 2.1868	 pickout: 0.0684	 decision: 0.3157	 get_bound: 1.7442	 add_domain: 0.0585
Current lb:-0.07398132234811783
22960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 133.91578197479248

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 193] [2, 123] [1, 6106] [1, 3635] [1, 7651] [2, 244] [1, 2547] [1, 2547] [1, 3494] [1, 3603] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 26.628454208374023 with beta sum per layer: [0.0, 45.617218017578125, 103.84513854980469]
alpha/beta optimization time: 1.596998691558838
This batch time : update_bounds func: 1.7481	 prepare: 0.0392	 bound: 1.5974	 transfer: 0.0846	 finalize: 0.0257
Accumulated time: update_bounds func: 105.2880	 prepare: 2.1571	 bound: 96.3621	 transfer: 0.0846	 finalize: 1.8946
batch bounding time:  1.748793601989746
Current worst splitting domains [lb, ub] (depth):
[-0.07383,   inf] (53), [-0.07379,   inf] (67), [-0.07379,   inf] (73), [-0.07379,   inf] (59), [-0.07379,   inf] (79), [-0.07378,   inf] (87), [-0.07378,   inf] (71), [-0.07378,   inf] (95), [-0.07378,   inf] (93), [-0.07378,   inf] (93), [-0.07378,   inf] (73), [-0.07378,   inf] (71), [-0.07378,   inf] (47), [-0.07378,   inf] (91), [-0.07378,   inf] (85), [-0.07378,   inf] (73), [-0.07378,   inf] (45), [-0.07377,   inf] (73), [-0.07377,   inf] (73), [-0.07377,   inf] (67), 
length of domains: 11081
Total time: 2.5013	 pickout: 0.0705	 decision: 0.6210	 get_bound: 1.7496	 add_domain: 0.0602
Current lb:-0.0738275945186615
23360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 136.42325162887573

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3500] [1, 5087] [1, 4902] [2, 80] [1, 2546] [1, 6106] [1, 3620] [1, 3635] [1, 3635] [1, 6053] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 26.63356590270996 with beta sum per layer: [0.0, 41.444252014160156, 122.28932189941406]
alpha/beta optimization time: 1.5971999168395996
This batch time : update_bounds func: 1.7400	 prepare: 0.0386	 bound: 1.5976	 transfer: 0.0768	 finalize: 0.0258
Accumulated time: update_bounds func: 107.0280	 prepare: 2.1957	 bound: 97.9597	 transfer: 0.0768	 finalize: 1.9204
batch bounding time:  1.7406902313232422
Current worst splitting domains [lb, ub] (depth):
[-0.07367,   inf] (45), [-0.07367,   inf] (63), [-0.07367,   inf] (67), [-0.07366,   inf] (85), [-0.07366,   inf] (51), [-0.07366,   inf] (91), [-0.07366,   inf] (93), [-0.07366,   inf] (45), [-0.07366,   inf] (93), [-0.07366,   inf] (69), [-0.07366,   inf] (47), [-0.07366,   inf] (59), [-0.07366,   inf] (95), [-0.07366,   inf] (77), [-0.07366,   inf] (95), [-0.07366,   inf] (53), [-0.07366,   inf] (37), [-0.07366,   inf] (89), [-0.07366,   inf] (63), [-0.07365,   inf] (71), 
length of domains: 11281
Total time: 2.1826	 pickout: 0.0653	 decision: 0.3187	 get_bound: 1.7415	 add_domain: 0.0572
Current lb:-0.0736655592918396
23760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 138.6120433807373

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 5349] [1, 7268] [1, 3603] [1, 2546] [2, 51] [1, 6106] [1, 6053] [2, 62] [1, 3494] [1, 7651] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.83041000366211 with beta sum per layer: [0.0, 40.15190505981445, 140.71119689941406]
alpha/beta optimization time: 1.5846693515777588
This batch time : update_bounds func: 1.7357	 prepare: 0.0384	 bound: 1.5850	 transfer: 0.0843	 finalize: 0.0267
Accumulated time: update_bounds func: 108.7637	 prepare: 2.2341	 bound: 99.5447	 transfer: 0.0843	 finalize: 1.9470
batch bounding time:  1.7362785339355469
Current worst splitting domains [lb, ub] (depth):
[-0.07354,   inf] (41), [-0.07353,   inf] (43), [-0.07353,   inf] (43), [-0.07353,   inf] (39), [-0.07353,   inf] (65), [-0.07353,   inf] (81), [-0.07353,   inf] (53), [-0.07353,   inf] (73), [-0.07353,   inf] (73), [-0.07353,   inf] (99), [-0.07353,   inf] (65), [-0.07353,   inf] (57), [-0.07353,   inf] (43), [-0.07353,   inf] (45), [-0.07353,   inf] (87), [-0.07353,   inf] (77), [-0.07353,   inf] (45), [-0.07352,   inf] (65), [-0.07352,   inf] (83), [-0.07352,   inf] (65), 
length of domains: 11479
Total time: 2.1692	 pickout: 0.0645	 decision: 0.3112	 get_bound: 1.7370	 add_domain: 0.0565
Current lb:-0.07353534549474716
24160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 140.78801822662354

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 103] [2, 103] [2, 103] [2, 175] [1, 3603] [1, 4851] [1, 1555] [1, 2549] [1, 5357] [1, 3635] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 26.299293518066406 with beta sum per layer: [0.0, 39.58697509765625, 118.59136962890625]
alpha/beta optimization time: 1.582169771194458
This batch time : update_bounds func: 1.7320	 prepare: 0.0385	 bound: 1.5825	 transfer: 0.0847	 finalize: 0.0250
Accumulated time: update_bounds func: 110.4956	 prepare: 2.2726	 bound: 101.1272	 transfer: 0.0847	 finalize: 1.9720
batch bounding time:  1.7326531410217285
Current worst splitting domains [lb, ub] (depth):
[-0.07350,   inf] (55), [-0.07342,   inf] (75), [-0.07342,   inf] (87), [-0.07342,   inf] (47), [-0.07342,   inf] (47), [-0.07341,   inf] (69), [-0.07341,   inf] (69), [-0.07341,   inf] (41), [-0.07341,   inf] (87), [-0.07341,   inf] (45), [-0.07341,   inf] (99), [-0.07341,   inf] (31), [-0.07341,   inf] (65), [-0.07341,   inf] (75), [-0.07341,   inf] (81), [-0.07341,   inf] (79), [-0.07341,   inf] (93), [-0.07341,   inf] (77), [-0.07341,   inf] (53), [-0.07341,   inf] (93), 
length of domains: 11679
Total time: 2.1669	 pickout: 0.0620	 decision: 0.3117	 get_bound: 1.7335	 add_domain: 0.0598
Current lb:-0.07350099086761475
24560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 142.96123886108398

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3500] [1, 3620] [1, 3110] [2, 130] [2, 103] [1, 7651] [1, 3620] [2, 62] [1, 6106] [2, 103] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.938610076904297 with beta sum per layer: [0.0, 36.600982666015625, 115.61314392089844]
alpha/beta optimization time: 1.5808227062225342
This batch time : update_bounds func: 1.7318	 prepare: 0.0387	 bound: 1.5812	 transfer: 0.0849	 finalize: 0.0258
Accumulated time: update_bounds func: 112.2274	 prepare: 2.3113	 bound: 102.7084	 transfer: 0.0849	 finalize: 1.9978
batch bounding time:  1.7325057983398438
Current worst splitting domains [lb, ub] (depth):
[-0.07333,   inf] (61), [-0.07330,   inf] (33), [-0.07330,   inf] (83), [-0.07329,   inf] (83), [-0.07329,   inf] (67), [-0.07329,   inf] (67), [-0.07329,   inf] (85), [-0.07329,   inf] (65), [-0.07329,   inf] (85), [-0.07329,   inf] (69), [-0.07329,   inf] (97), [-0.07329,   inf] (43), [-0.07329,   inf] (65), [-0.07329,   inf] (57), [-0.07329,   inf] (41), [-0.07328,   inf] (89), [-0.07328,   inf] (97), [-0.07328,   inf] (49), [-0.07328,   inf] (93), [-0.07328,   inf] (73), 
length of domains: 11876
Total time: 2.4945	 pickout: 0.0628	 decision: 0.6390	 get_bound: 1.7333	 add_domain: 0.0594
Current lb:-0.07332880049943924
24960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 145.4621081352234

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 80] [2, 170] [1, 4851] [2, 244] [1, 3108] [1, 4851] [1, 2546] [1, 4902] [1, 2546] [1, 3108] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 26.043663024902344 with beta sum per layer: [0.0, 39.0741081237793, 118.23797607421875]
alpha/beta optimization time: 1.5787675380706787
This batch time : update_bounds func: 1.7300	 prepare: 0.0382	 bound: 1.5791	 transfer: 0.0849	 finalize: 0.0265
Accumulated time: update_bounds func: 113.9574	 prepare: 2.3495	 bound: 104.2875	 transfer: 0.0849	 finalize: 2.0244
batch bounding time:  1.7306678295135498
Current worst splitting domains [lb, ub] (depth):
[-0.07320,   inf] (55), [-0.07317,   inf] (91), [-0.07317,   inf] (93), [-0.07317,   inf] (87), [-0.07317,   inf] (93), [-0.07317,   inf] (35), [-0.07317,   inf] (99), [-0.07317,   inf] (71), [-0.07317,   inf] (71), [-0.07317,   inf] (89), [-0.07317,   inf] (75), [-0.07317,   inf] (57), [-0.07317,   inf] (77), [-0.07317,   inf] (89), [-0.07316,   inf] (95), [-0.07316,   inf] (37), [-0.07316,   inf] (81), [-0.07316,   inf] (91), [-0.07316,   inf] (61), [-0.07316,   inf] (91), 
length of domains: 12076
Total time: 2.1610	 pickout: 0.0619	 decision: 0.3104	 get_bound: 1.7315	 add_domain: 0.0571
Current lb:-0.0732041597366333
25360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 147.6296694278717

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 80] [1, 3110] [1, 3635] [1, 7650] [1, 3494] [2, 37] [1, 3603] [1, 3108] [2, 244] [1, 7650] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.934383392333984 with beta sum per layer: [0.0, 40.95458221435547, 113.5843505859375]
alpha/beta optimization time: 1.5729329586029053
This batch time : update_bounds func: 1.7237	 prepare: 0.0385	 bound: 1.5733	 transfer: 0.0843	 finalize: 0.0264
Accumulated time: update_bounds func: 115.6811	 prepare: 2.3880	 bound: 105.8608	 transfer: 0.0843	 finalize: 2.0507
batch bounding time:  1.7243585586547852
Current worst splitting domains [lb, ub] (depth):
[-0.07305,   inf] (71), [-0.07305,   inf] (103), [-0.07305,   inf] (69), [-0.07305,   inf] (105), [-0.07305,   inf] (93), [-0.07305,   inf] (71), [-0.07305,   inf] (49), [-0.07305,   inf] (63), [-0.07305,   inf] (91), [-0.07304,   inf] (101), [-0.07304,   inf] (75), [-0.07304,   inf] (95), [-0.07304,   inf] (53), [-0.07304,   inf] (65), [-0.07304,   inf] (97), [-0.07304,   inf] (71), [-0.07304,   inf] (73), [-0.07304,   inf] (91), [-0.07304,   inf] (65), [-0.07304,   inf] (95), 
length of domains: 12275
Total time: 2.1632	 pickout: 0.0699	 decision: 0.3102	 get_bound: 1.7251	 add_domain: 0.0580
Current lb:-0.07305401563644409
25760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 149.79899787902832

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3108] [2, 151] [1, 4851] [2, 151] [1, 3494] [2, 244] [2, 105] [1, 7268] [1, 7262] [1, 3635] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.718597412109375 with beta sum per layer: [0.0, 41.9963264465332, 110.73788452148438]
alpha/beta optimization time: 1.57633376121521
This batch time : update_bounds func: 1.7264	 prepare: 0.0388	 bound: 1.5768	 transfer: 0.0846	 finalize: 0.0249
Accumulated time: update_bounds func: 117.4075	 prepare: 2.4268	 bound: 107.4376	 transfer: 0.0846	 finalize: 2.0757
batch bounding time:  1.7271215915679932
Current worst splitting domains [lb, ub] (depth):
[-0.07301,   inf] (77), [-0.07300,   inf] (87), [-0.07298,   inf] (57), [-0.07295,   inf] (77), [-0.07294,   inf] (83), [-0.07294,   inf] (45), [-0.07294,   inf] (77), [-0.07294,   inf] (45), [-0.07294,   inf] (83), [-0.07294,   inf] (91), [-0.07294,   inf] (83), [-0.07294,   inf] (99), [-0.07294,   inf] (43), [-0.07294,   inf] (77), [-0.07293,   inf] (65), [-0.07293,   inf] (83), [-0.07293,   inf] (71), [-0.07293,   inf] (55), [-0.07293,   inf] (57), [-0.07293,   inf] (69), 
length of domains: 12471
Total time: 2.1655	 pickout: 0.0667	 decision: 0.3108	 get_bound: 1.7279	 add_domain: 0.0602
Current lb:-0.07301101833581924
26160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 151.97089433670044

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 668] [1, 3110] [2, 193] [1, 3620] [1, 2546] [2, 103] [1, 2546] [2, 103] [1, 3494] [1, 6106] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.783504486083984 with beta sum per layer: [0.0, 39.389156341552734, 126.97900390625]
alpha/beta optimization time: 1.5765132904052734
This batch time : update_bounds func: 1.7193	 prepare: 0.0384	 bound: 1.5769	 transfer: 0.0766	 finalize: 0.0262
Accumulated time: update_bounds func: 119.1269	 prepare: 2.4652	 bound: 109.0145	 transfer: 0.0766	 finalize: 2.1019
batch bounding time:  1.7200133800506592
Current worst splitting domains [lb, ub] (depth):
[-0.07285,   inf] (83), [-0.07282,   inf] (49), [-0.07282,   inf] (67), [-0.07282,   inf] (93), [-0.07282,   inf] (77), [-0.07282,   inf] (77), [-0.07282,   inf] (41), [-0.07282,   inf] (85), [-0.07282,   inf] (97), [-0.07282,   inf] (53), [-0.07282,   inf] (47), [-0.07282,   inf] (107), [-0.07282,   inf] (77), [-0.07282,   inf] (79), [-0.07282,   inf] (87), [-0.07282,   inf] (95), [-0.07282,   inf] (85), [-0.07282,   inf] (81), [-0.07282,   inf] (49), [-0.07282,   inf] (69), 
length of domains: 12670
Total time: 2.5254	 pickout: 0.0685	 decision: 0.6767	 get_bound: 1.7208	 add_domain: 0.0594
Current lb:-0.07285099476575851
26560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 154.50252199172974

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6106] [2, 130] [1, 4851] [1, 6106] [2, 244] [1, 2549] [1, 5349] [1, 3110] [1, 7262] [1, 3500] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 26.065204620361328 with beta sum per layer: [0.0, 41.368553161621094, 111.603271484375]
alpha/beta optimization time: 1.568835735321045
This batch time : update_bounds func: 1.7130	 prepare: 0.0384	 bound: 1.5692	 transfer: 0.0777	 finalize: 0.0264
Accumulated time: update_bounds func: 120.8398	 prepare: 2.5036	 bound: 110.5836	 transfer: 0.0777	 finalize: 2.1283
batch bounding time:  1.713629961013794
Current worst splitting domains [lb, ub] (depth):
[-0.07274,   inf] (53), [-0.07272,   inf] (77), [-0.07272,   inf] (79), [-0.07272,   inf] (85), [-0.07272,   inf] (57), [-0.07272,   inf] (55), [-0.07272,   inf] (81), [-0.07272,   inf] (85), [-0.07272,   inf] (59), [-0.07272,   inf] (91), [-0.07272,   inf] (73), [-0.07272,   inf] (95), [-0.07272,   inf] (81), [-0.07272,   inf] (97), [-0.07272,   inf] (91), [-0.07272,   inf] (95), [-0.07272,   inf] (79), [-0.07272,   inf] (73), [-0.07272,   inf] (85), [-0.07272,   inf] (85), 
length of domains: 12869
Total time: 2.1514	 pickout: 0.0674	 decision: 0.3115	 get_bound: 1.7144	 add_domain: 0.0580
Current lb:-0.07273852825164795
26960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 156.6603388786316

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3500] [1, 668] [1, 2546] [1, 2546] [2, 80] [2, 123] [1, 5357] [1, 7650] [2, 193] [1, 6106] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.886085510253906 with beta sum per layer: [0.0, 41.64616012573242, 104.57038879394531]
alpha/beta optimization time: 1.575204610824585
This batch time : update_bounds func: 1.7200	 prepare: 0.0387	 bound: 1.5755	 transfer: 0.0777	 finalize: 0.0268
Accumulated time: update_bounds func: 122.5598	 prepare: 2.5422	 bound: 112.1592	 transfer: 0.0777	 finalize: 2.1552
batch bounding time:  1.7206318378448486
Current worst splitting domains [lb, ub] (depth):
[-0.07267,   inf] (113), [-0.07262,   inf] (83), [-0.07262,   inf] (99), [-0.07262,   inf] (63), [-0.07262,   inf] (39), [-0.07262,   inf] (39), [-0.07262,   inf] (75), [-0.07262,   inf] (89), [-0.07262,   inf] (69), [-0.07262,   inf] (65), [-0.07262,   inf] (85), [-0.07261,   inf] (65), [-0.07261,   inf] (73), [-0.07261,   inf] (53), [-0.07261,   inf] (61), [-0.07261,   inf] (41), [-0.07261,   inf] (75), [-0.07261,   inf] (45), [-0.07261,   inf] (95), [-0.07261,   inf] (65), 
length of domains: 13066
Total time: 2.1688	 pickout: 0.0787	 decision: 0.3108	 get_bound: 1.7214	 add_domain: 0.0579
Current lb:-0.07267307490110397
27360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 158.83513045310974

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3636] [1, 7650] [1, 667] [1, 3108] [2, 175] [2, 49] [1, 2547] [1, 6106] [1, 3108] [1, 7651] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 26.094390869140625 with beta sum per layer: [0.0, 47.74672317504883, 107.81871032714844]
alpha/beta optimization time: 1.5862741470336914
This batch time : update_bounds func: 1.7378	 prepare: 0.0391	 bound: 1.5866	 transfer: 0.0854	 finalize: 0.0254
Accumulated time: update_bounds func: 124.2977	 prepare: 2.5814	 bound: 113.7458	 transfer: 0.0854	 finalize: 2.1806
batch bounding time:  1.7385540008544922
Current worst splitting domains [lb, ub] (depth):
[-0.07259,   inf] (55), [-0.07256,   inf] (55), [-0.07252,   inf] (57), [-0.07251,   inf] (77), [-0.07251,   inf] (65), [-0.07251,   inf] (83), [-0.07251,   inf] (75), [-0.07251,   inf] (93), [-0.07251,   inf] (81), [-0.07251,   inf] (41), [-0.07251,   inf] (47), [-0.07251,   inf] (95), [-0.07251,   inf] (91), [-0.07251,   inf] (73), [-0.07251,   inf] (49), [-0.07251,   inf] (87), [-0.07251,   inf] (79), [-0.07251,   inf] (65), [-0.07251,   inf] (75), [-0.07251,   inf] (77), 
length of domains: 13264
Total time: 2.1917	 pickout: 0.0771	 decision: 0.3137	 get_bound: 1.7394	 add_domain: 0.0614
Current lb:-0.07258810102939606
27760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 161.03345942497253

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3500] [2, 51] [2, 193] [1, 2547] [1, 3603] [1, 7261] [1, 668] [1, 3494] [1, 2546] [1, 5349] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.759502410888672 with beta sum per layer: [0.0, 43.73456573486328, 105.81167602539062]
alpha/beta optimization time: 1.5706732273101807
This batch time : update_bounds func: 1.7217	 prepare: 0.0388	 bound: 1.5710	 transfer: 0.0850	 finalize: 0.0255
Accumulated time: update_bounds func: 126.0193	 prepare: 2.6202	 bound: 115.3169	 transfer: 0.0850	 finalize: 2.2061
batch bounding time:  1.7223422527313232
Current worst splitting domains [lb, ub] (depth):
[-0.07245,   inf] (59), [-0.07244,   inf] (65), [-0.07240,   inf] (95), [-0.07240,   inf] (73), [-0.07240,   inf] (73), [-0.07240,   inf] (37), [-0.07240,   inf] (57), [-0.07240,   inf] (77), [-0.07240,   inf] (63), [-0.07240,   inf] (91), [-0.07240,   inf] (71), [-0.07240,   inf] (67), [-0.07240,   inf] (87), [-0.07240,   inf] (77), [-0.07240,   inf] (75), [-0.07240,   inf] (89), [-0.07240,   inf] (85), [-0.07240,   inf] (85), [-0.07240,   inf] (93), [-0.07240,   inf] (81), 
length of domains: 13460
Total time: 2.5846	 pickout: 0.0854	 decision: 0.3135	 get_bound: 1.7231	 add_domain: 0.4626
Current lb:-0.07244808971881866
28160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 163.62431168556213

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 123] [1, 5357] [1, 3635] [1, 668] [2, 244] [2, 49] [2, 80] [2, 244] [1, 7268] [1, 2548] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.807422637939453 with beta sum per layer: [0.0, 46.26795196533203, 111.26547241210938]
alpha/beta optimization time: 1.5736339092254639
This batch time : update_bounds func: 1.7194	 prepare: 0.0387	 bound: 1.5740	 transfer: 0.0789	 finalize: 0.0265
Accumulated time: update_bounds func: 127.7387	 prepare: 2.6589	 bound: 116.8908	 transfer: 0.0789	 finalize: 2.2326
batch bounding time:  1.7200767993927002
Current worst splitting domains [lb, ub] (depth):
[-0.07235,   inf] (113), [-0.07231,   inf] (81), [-0.07230,   inf] (95), [-0.07230,   inf] (81), [-0.07230,   inf] (83), [-0.07230,   inf] (57), [-0.07230,   inf] (103), [-0.07230,   inf] (79), [-0.07230,   inf] (59), [-0.07230,   inf] (91), [-0.07230,   inf] (99), [-0.07230,   inf] (75), [-0.07230,   inf] (99), [-0.07230,   inf] (81), [-0.07230,   inf] (43), [-0.07230,   inf] (33), [-0.07230,   inf] (81), [-0.07230,   inf] (49), [-0.07230,   inf] (81), [-0.07230,   inf] (43), 
length of domains: 13658
Total time: 2.1690	 pickout: 0.0812	 decision: 0.3091	 get_bound: 1.7209	 add_domain: 0.0578
Current lb:-0.07234708219766617
28560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 165.79932856559753

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 4629] [1, 668] [1, 3635] [1, 5357] [1, 2546] [2, 123] [1, 7262] [1, 2547] [1, 3500] [1, 3620] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.8293399810791 with beta sum per layer: [0.0, 48.6905517578125, 113.82215881347656]
alpha/beta optimization time: 1.5672900676727295
This batch time : update_bounds func: 1.7188	 prepare: 0.0390	 bound: 1.5676	 transfer: 0.0846	 finalize: 0.0263
Accumulated time: update_bounds func: 129.4575	 prepare: 2.6979	 bound: 118.4585	 transfer: 0.0846	 finalize: 2.2589
batch bounding time:  1.7194228172302246
Current worst splitting domains [lb, ub] (depth):
[-0.07227,   inf] (81), [-0.07225,   inf] (77), [-0.07222,   inf] (81), [-0.07222,   inf] (81), [-0.07222,   inf] (87), [-0.07222,   inf] (95), [-0.07222,   inf] (95), [-0.07222,   inf] (53), [-0.07222,   inf] (47), [-0.07222,   inf] (97), [-0.07222,   inf] (99), [-0.07221,   inf] (81), [-0.07221,   inf] (45), [-0.07221,   inf] (45), [-0.07221,   inf] (67), [-0.07221,   inf] (67), [-0.07221,   inf] (55), [-0.07221,   inf] (73), [-0.07221,   inf] (85), [-0.07221,   inf] (69), 
length of domains: 13856
Total time: 2.1848	 pickout: 0.0868	 decision: 0.3183	 get_bound: 1.7202	 add_domain: 0.0595
Current lb:-0.07226841896772385
28960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 167.99059438705444

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2546] [1, 3620] [2, 244] [1, 3620] [1, 3494] [1, 668] [1, 3635] [1, 3500] [2, 105] [1, 668] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.75082778930664 with beta sum per layer: [0.0, 49.98750686645508, 96.27349853515625]
alpha/beta optimization time: 1.570908546447754
This batch time : update_bounds func: 1.7133	 prepare: 0.0390	 bound: 1.5713	 transfer: 0.0770	 finalize: 0.0248
Accumulated time: update_bounds func: 131.1708	 prepare: 2.7369	 bound: 120.0298	 transfer: 0.0770	 finalize: 2.2838
batch bounding time:  1.7140438556671143
Current worst splitting domains [lb, ub] (depth):
[-0.07219,   inf] (111), [-0.07216,   inf] (83), [-0.07212,   inf] (57), [-0.07212,   inf] (29), [-0.07212,   inf] (75), [-0.07212,   inf] (71), [-0.07212,   inf] (89), [-0.07212,   inf] (57), [-0.07212,   inf] (67), [-0.07212,   inf] (75), [-0.07212,   inf] (83), [-0.07212,   inf] (77), [-0.07212,   inf] (77), [-0.07212,   inf] (71), [-0.07212,   inf] (67), [-0.07212,   inf] (73), [-0.07212,   inf] (73), [-0.07212,   inf] (65), [-0.07212,   inf] (61), [-0.07212,   inf] (69), 
length of domains: 14051
Total time: 2.1626	 pickout: 0.0756	 decision: 0.3103	 get_bound: 1.7148	 add_domain: 0.0618
Current lb:-0.07218532264232635
29360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 170.15970253944397

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 21] [1, 6106] [1, 1555] [2, 170] [1, 6842] [1, 7268] [1, 2546] [2, 80] [1, 4851] [1, 4902] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.778226852416992 with beta sum per layer: [0.0, 48.31308364868164, 98.0186767578125]
alpha/beta optimization time: 1.5691144466400146
This batch time : update_bounds func: 1.7197	 prepare: 0.0388	 bound: 1.5695	 transfer: 0.0846	 finalize: 0.0255
Accumulated time: update_bounds func: 132.8905	 prepare: 2.7757	 bound: 121.5992	 transfer: 0.0846	 finalize: 2.3093
batch bounding time:  1.7203316688537598
Current worst splitting domains [lb, ub] (depth):
[-0.07211,   inf] (59), [-0.07208,   inf] (79), [-0.07204,   inf] (83), [-0.07204,   inf] (111), [-0.07204,   inf] (91), [-0.07204,   inf] (89), [-0.07204,   inf] (103), [-0.07204,   inf] (81), [-0.07204,   inf] (101), [-0.07204,   inf] (45), [-0.07204,   inf] (105), [-0.07204,   inf] (45), [-0.07204,   inf] (105), [-0.07204,   inf] (55), [-0.07204,   inf] (81), [-0.07204,   inf] (85), [-0.07204,   inf] (93), [-0.07204,   inf] (81), [-0.07204,   inf] (75), [-0.07204,   inf] (71), 
length of domains: 14247
Total time: 2.1699	 pickout: 0.0764	 decision: 0.3109	 get_bound: 1.7211	 add_domain: 0.0615
Current lb:-0.07210852205753326
29760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 172.33605980873108

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 123] [1, 668] [1, 4851] [1, 422] [1, 5357] [1, 2546] [1, 4629] [1, 2547] [2, 151] [2, 103] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.753604888916016 with beta sum per layer: [0.0, 48.024147033691406, 109.6776123046875]
alpha/beta optimization time: 1.574697732925415
This batch time : update_bounds func: 2.1965	 prepare: 0.0390	 bound: 1.5751	 transfer: 0.0840	 finalize: 0.4971
Accumulated time: update_bounds func: 135.0870	 prepare: 2.8147	 bound: 123.1743	 transfer: 0.0840	 finalize: 2.8064
batch bounding time:  2.1972503662109375
Current worst splitting domains [lb, ub] (depth):
[-0.07203,   inf] (113), [-0.07202,   inf] (113), [-0.07196,   inf] (75), [-0.07196,   inf] (67), [-0.07196,   inf] (73), [-0.07196,   inf] (95), [-0.07196,   inf] (67), [-0.07196,   inf] (63), [-0.07196,   inf] (81), [-0.07196,   inf] (77), [-0.07196,   inf] (87), [-0.07196,   inf] (67), [-0.07196,   inf] (81), [-0.07195,   inf] (69), [-0.07195,   inf] (81), [-0.07195,   inf] (45), [-0.07195,   inf] (91), [-0.07195,   inf] (47), [-0.07195,   inf] (33), [-0.07195,   inf] (57), 
length of domains: 14446
Total time: 2.6438	 pickout: 0.0733	 decision: 0.3125	 get_bound: 2.1981	 add_domain: 0.0599
Current lb:-0.07202547043561935
30160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 174.98614811897278

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3636] [1, 3636] [1, 4851] [1, 4851] [1, 5533] [1, 3635] [1, 3108] [1, 5357] [1, 3620] [2, 244] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.290504455566406 with beta sum per layer: [0.0, 47.61420822143555, 111.13992309570312]
alpha/beta optimization time: 1.582338809967041
This batch time : update_bounds func: 1.7334	 prepare: 0.0390	 bound: 1.5827	 transfer: 0.0836	 finalize: 0.0268
Accumulated time: update_bounds func: 136.8204	 prepare: 2.8537	 bound: 124.7570	 transfer: 0.0836	 finalize: 2.8332
batch bounding time:  1.734057903289795
Current worst splitting domains [lb, ub] (depth):
[-0.07189,   inf] (111), [-0.07187,   inf] (69), [-0.07187,   inf] (97), [-0.07187,   inf] (91), [-0.07187,   inf] (81), [-0.07187,   inf] (85), [-0.07187,   inf] (95), [-0.07187,   inf] (79), [-0.07187,   inf] (87), [-0.07187,   inf] (45), [-0.07187,   inf] (89), [-0.07187,   inf] (81), [-0.07187,   inf] (83), [-0.07187,   inf] (59), [-0.07187,   inf] (101), [-0.07187,   inf] (79), [-0.07187,   inf] (41), [-0.07187,   inf] (99), [-0.07187,   inf] (93), [-0.07187,   inf] (79), 
length of domains: 14639
Total time: 2.1805	 pickout: 0.0712	 decision: 0.3158	 get_bound: 1.7348	 add_domain: 0.0587
Current lb:-0.07188943028450012
30560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 177.172993183136

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 21] [1, 4902] [1, 6053] [1, 5357] [2, 244] [1, 7650] [1, 2548] [1, 3620] [1, 6106] [2, 103] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.690048217773438 with beta sum per layer: [0.0, 46.60145568847656, 113.17689514160156]
alpha/beta optimization time: 1.5697581768035889
This batch time : update_bounds func: 1.7194	 prepare: 0.0386	 bound: 1.5701	 transfer: 0.0844	 finalize: 0.0250
Accumulated time: update_bounds func: 138.5398	 prepare: 2.8924	 bound: 126.3271	 transfer: 0.0844	 finalize: 2.8582
batch bounding time:  1.7200427055358887
Current worst splitting domains [lb, ub] (depth):
[-0.07181,   inf] (53), [-0.07180,   inf] (91), [-0.07180,   inf] (99), [-0.07180,   inf] (95), [-0.07180,   inf] (77), [-0.07180,   inf] (105), [-0.07180,   inf] (63), [-0.07180,   inf] (37), [-0.07180,   inf] (69), [-0.07180,   inf] (73), [-0.07180,   inf] (57), [-0.07180,   inf] (89), [-0.07179,   inf] (69), [-0.07179,   inf] (93), [-0.07179,   inf] (85), [-0.07179,   inf] (71), [-0.07179,   inf] (81), [-0.07179,   inf] (91), [-0.07179,   inf] (93), [-0.07179,   inf] (43), 
length of domains: 14837
Total time: 2.1644	 pickout: 0.0681	 decision: 0.3142	 get_bound: 1.7208	 add_domain: 0.0613
Current lb:-0.07180875539779663
30960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 179.34357905387878

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3500] [1, 3494] [1, 667] [1, 3635] [1, 668] [2, 151] [1, 4902] [2, 49] [1, 3108] [1, 2547] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.567928314208984 with beta sum per layer: [0.0, 50.77956771850586, 103.25760650634766]
alpha/beta optimization time: 1.571526050567627
This batch time : update_bounds func: 1.7231	 prepare: 0.0393	 bound: 1.5719	 transfer: 0.0846	 finalize: 0.0260
Accumulated time: update_bounds func: 140.2628	 prepare: 2.9317	 bound: 127.8990	 transfer: 0.0846	 finalize: 2.8842
batch bounding time:  1.7237765789031982
Current worst splitting domains [lb, ub] (depth):
[-0.07172,   inf] (91), [-0.07172,   inf] (83), [-0.07172,   inf] (85), [-0.07172,   inf] (55), [-0.07172,   inf] (111), [-0.07172,   inf] (83), [-0.07171,   inf] (89), [-0.07171,   inf] (55), [-0.07171,   inf] (101), [-0.07171,   inf] (85), [-0.07171,   inf] (75), [-0.07171,   inf] (55), [-0.07171,   inf] (71), [-0.07171,   inf] (77), [-0.07171,   inf] (89), [-0.07171,   inf] (57), [-0.07171,   inf] (107), [-0.07171,   inf] (67), [-0.07171,   inf] (45), [-0.07171,   inf] (43), 
length of domains: 15032
Total time: 2.1779	 pickout: 0.0772	 decision: 0.3139	 get_bound: 1.7246	 add_domain: 0.0622
Current lb:-0.07171623408794403
31360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 181.5286898612976

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7262] [1, 2547] [1, 2546] [1, 3500] [1, 422] [1, 7650] [1, 6106] [2, 123] [1, 38] [1, 2546] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.778627395629883 with beta sum per layer: [0.0, 49.595794677734375, 101.81964111328125]
alpha/beta optimization time: 1.5708203315734863
This batch time : update_bounds func: 1.7141	 prepare: 0.0386	 bound: 1.5712	 transfer: 0.0766	 finalize: 0.0264
Accumulated time: update_bounds func: 141.9769	 prepare: 2.9702	 bound: 129.4701	 transfer: 0.0766	 finalize: 2.9106
batch bounding time:  1.7148199081420898
Current worst splitting domains [lb, ub] (depth):
[-0.07169,   inf] (113), [-0.07166,   inf] (77), [-0.07164,   inf] (75), [-0.07164,   inf] (99), [-0.07163,   inf] (83), [-0.07163,   inf] (93), [-0.07163,   inf] (67), [-0.07163,   inf] (97), [-0.07163,   inf] (95), [-0.07163,   inf] (81), [-0.07163,   inf] (69), [-0.07163,   inf] (51), [-0.07163,   inf] (75), [-0.07163,   inf] (69), [-0.07163,   inf] (43), [-0.07163,   inf] (81), [-0.07163,   inf] (97), [-0.07163,   inf] (45), [-0.07163,   inf] (85), [-0.07163,   inf] (71), 
length of domains: 15229
Total time: 2.1539	 pickout: 0.0663	 decision: 0.3116	 get_bound: 1.7156	 add_domain: 0.0604
Current lb:-0.07169473171234131
31760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 183.68994808197021

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 4629] [1, 2547] [1, 2547] [1, 668] [1, 7650] [1, 3494] [1, 3108] [1, 1118] [1, 668] [1, 3620] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.864513397216797 with beta sum per layer: [0.0, 51.63135528564453, 83.28382110595703]
alpha/beta optimization time: 1.5676133632659912
This batch time : update_bounds func: 1.7191	 prepare: 0.0388	 bound: 1.5680	 transfer: 0.0842	 finalize: 0.0270
Accumulated time: update_bounds func: 143.6961	 prepare: 3.0090	 bound: 131.0381	 transfer: 0.0842	 finalize: 2.9376
batch bounding time:  1.7198460102081299
Current worst splitting domains [lb, ub] (depth):
[-0.07159,   inf] (95), [-0.07156,   inf] (101), [-0.07156,   inf] (85), [-0.07156,   inf] (81), [-0.07156,   inf] (79), [-0.07156,   inf] (67), [-0.07156,   inf] (87), [-0.07156,   inf] (97), [-0.07156,   inf] (55), [-0.07156,   inf] (63), [-0.07156,   inf] (31), [-0.07156,   inf] (61), [-0.07156,   inf] (101), [-0.07156,   inf] (79), [-0.07156,   inf] (41), [-0.07156,   inf] (83), [-0.07156,   inf] (45), [-0.07156,   inf] (95), [-0.07156,   inf] (95), [-0.07155,   inf] (99), 
length of domains: 15427
Total time: 2.6072	 pickout: 0.0747	 decision: 0.3122	 get_bound: 1.7206	 add_domain: 0.4998
Current lb:-0.07158748805522919
32160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 186.30351161956787

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7262] [1, 3635] [1, 668] [2, 244] [1, 6106] [2, 244] [1, 7650] [1, 668] [2, 123] [1, 7268] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.393428802490234 with beta sum per layer: [0.0, 47.22588348388672, 92.27738189697266]
alpha/beta optimization time: 1.5653541088104248
This batch time : update_bounds func: 1.7069	 prepare: 0.0387	 bound: 1.5657	 transfer: 0.0762	 finalize: 0.0250
Accumulated time: update_bounds func: 145.4030	 prepare: 3.0477	 bound: 132.6038	 transfer: 0.0762	 finalize: 2.9626
batch bounding time:  1.7076194286346436
Current worst splitting domains [lb, ub] (depth):
[-0.07154,   inf] (67), [-0.07153,   inf] (111), [-0.07149,   inf] (73), [-0.07149,   inf] (47), [-0.07149,   inf] (91), [-0.07149,   inf] (75), [-0.07149,   inf] (89), [-0.07149,   inf] (81), [-0.07149,   inf] (89), [-0.07149,   inf] (97), [-0.07149,   inf] (97), [-0.07149,   inf] (83), [-0.07149,   inf] (77), [-0.07149,   inf] (81), [-0.07149,   inf] (89), [-0.07149,   inf] (91), [-0.07149,   inf] (87), [-0.07149,   inf] (81), [-0.07149,   inf] (67), [-0.07149,   inf] (113), 
length of domains: 15620
Total time: 2.1498	 pickout: 0.0649	 decision: 0.3146	 get_bound: 1.7084	 add_domain: 0.0618
Current lb:-0.07154026627540588
32560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 188.45976519584656

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 4902] [1, 21] [2, 244] [2, 105] [1, 6106] [1, 2547] [1, 3110] [1, 2546] [1, 7650] [1, 2548] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.825828552246094 with beta sum per layer: [0.0, 57.381752014160156, 87.04678344726562]
alpha/beta optimization time: 1.5674912929534912
This batch time : update_bounds func: 1.7177	 prepare: 0.0388	 bound: 1.5678	 transfer: 0.0836	 finalize: 0.0262
Accumulated time: update_bounds func: 147.1207	 prepare: 3.0865	 bound: 134.1716	 transfer: 0.0836	 finalize: 2.9889
batch bounding time:  1.7184593677520752
Current worst splitting domains [lb, ub] (depth):
[-0.07143,   inf] (59), [-0.07143,   inf] (87), [-0.07143,   inf] (63), [-0.07143,   inf] (99), [-0.07143,   inf] (107), [-0.07143,   inf] (81), [-0.07143,   inf] (81), [-0.07143,   inf] (83), [-0.07143,   inf] (103), [-0.07143,   inf] (95), [-0.07143,   inf] (69), [-0.07143,   inf] (91), [-0.07142,   inf] (79), [-0.07142,   inf] (75), [-0.07142,   inf] (95), [-0.07142,   inf] (101), [-0.07142,   inf] (83), [-0.07142,   inf] (97), [-0.07142,   inf] (69), [-0.07142,   inf] (77), 
length of domains: 15817
Total time: 2.1697	 pickout: 0.0719	 decision: 0.3147	 get_bound: 1.7192	 add_domain: 0.0638
Current lb:-0.07142958045005798
32960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 190.6367893218994

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 193] [1, 3110] [1, 7651] [1, 667] [1, 3094] [2, 244] [1, 5357] [1, 3110] [1, 4629] [1, 2548] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.90949249267578 with beta sum per layer: [0.0, 55.89929962158203, 87.377197265625]
alpha/beta optimization time: 1.5671966075897217
This batch time : update_bounds func: 1.7171	 prepare: 0.0386	 bound: 1.5675	 transfer: 0.0837	 finalize: 0.0260
Accumulated time: update_bounds func: 148.8378	 prepare: 3.1251	 bound: 135.7392	 transfer: 0.0837	 finalize: 3.0149
batch bounding time:  1.7177674770355225
Current worst splitting domains [lb, ub] (depth):
[-0.07136,   inf] (89), [-0.07136,   inf] (75), [-0.07136,   inf] (55), [-0.07136,   inf] (39), [-0.07136,   inf] (93), [-0.07136,   inf] (83), [-0.07136,   inf] (73), [-0.07136,   inf] (81), [-0.07136,   inf] (81), [-0.07136,   inf] (93), [-0.07136,   inf] (71), [-0.07136,   inf] (73), [-0.07136,   inf] (101), [-0.07136,   inf] (73), [-0.07136,   inf] (51), [-0.07136,   inf] (53), [-0.07136,   inf] (47), [-0.07136,   inf] (55), [-0.07136,   inf] (55), [-0.07136,   inf] (69), 
length of domains: 16014
Total time: 2.1608	 pickout: 0.0695	 decision: 0.3116	 get_bound: 1.7185	 add_domain: 0.0611
Current lb:-0.07136014103889465
33360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 192.80413627624512

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3635] [1, 2549] [2, 51] [2, 49] [1, 2548] [1, 3110] [1, 2547] [1, 2547] [1, 2547] [1, 3110] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.71596908569336 with beta sum per layer: [0.10503707081079483, 52.23625183105469, 84.56797790527344]
alpha/beta optimization time: 1.5728950500488281
This batch time : update_bounds func: 1.7167	 prepare: 0.0395	 bound: 1.5733	 transfer: 0.0755	 finalize: 0.0271
Accumulated time: update_bounds func: 150.5545	 prepare: 3.1647	 bound: 137.3124	 transfer: 0.0755	 finalize: 3.0420
batch bounding time:  1.7173328399658203
Current worst splitting domains [lb, ub] (depth):
[-0.07135,   inf] (113), [-0.07133,   inf] (57), [-0.07133,   inf] (111), [-0.07129,   inf] (95), [-0.07129,   inf] (85), [-0.07129,   inf] (87), [-0.07129,   inf] (77), [-0.07129,   inf] (97), [-0.07129,   inf] (85), [-0.07129,   inf] (93), [-0.07129,   inf] (71), [-0.07129,   inf] (81), [-0.07129,   inf] (79), [-0.07129,   inf] (89), [-0.07129,   inf] (89), [-0.07129,   inf] (75), [-0.07129,   inf] (87), [-0.07129,   inf] (73), [-0.07129,   inf] (67), [-0.07129,   inf] (91), 
length of domains: 16209
Total time: 2.1538	 pickout: 0.0629	 decision: 0.3117	 get_bound: 1.7181	 add_domain: 0.0611
Current lb:-0.07135246694087982
33760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 194.96414637565613

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6842] [2, 193] [1, 21] [1, 2548] [1, 3110] [1, 3494] [1, 2546] [1, 6053] [1, 3494] [1, 6053] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.607017517089844 with beta sum per layer: [0.0, 52.53120422363281, 82.22006225585938]
alpha/beta optimization time: 1.575929880142212
This batch time : update_bounds func: 1.7262	 prepare: 0.0396	 bound: 1.5763	 transfer: 0.0838	 finalize: 0.0254
Accumulated time: update_bounds func: 152.2807	 prepare: 3.2042	 bound: 138.8887	 transfer: 0.0838	 finalize: 3.0674
batch bounding time:  1.726928472518921
Current worst splitting domains [lb, ub] (depth):
[-0.07126,   inf] (77), [-0.07125,   inf] (61), [-0.07123,   inf] (85), [-0.07123,   inf] (85), [-0.07123,   inf] (85), [-0.07123,   inf] (83), [-0.07123,   inf] (97), [-0.07123,   inf] (95), [-0.07123,   inf] (79), [-0.07123,   inf] (101), [-0.07123,   inf] (61), [-0.07123,   inf] (79), [-0.07123,   inf] (97), [-0.07122,   inf] (71), [-0.07122,   inf] (103), [-0.07122,   inf] (87), [-0.07122,   inf] (79), [-0.07122,   inf] (93), [-0.07122,   inf] (97), [-0.07122,   inf] (57), 
length of domains: 16401
Total time: 2.6388	 pickout: 0.0704	 decision: 0.3106	 get_bound: 1.7277	 add_domain: 0.5300
Current lb:-0.07125687599182129
34160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 197.60932445526123

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2547] [2, 193] [1, 4851] [1, 3110] [1, 3110] [1, 2547] [1, 668] [1, 3635] [1, 668] [1, 3635] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.591808319091797 with beta sum per layer: [0.0, 51.7193489074707, 95.47579956054688]
alpha/beta optimization time: 1.5874371528625488
This batch time : update_bounds func: 1.7348	 prepare: 0.0395	 bound: 1.5878	 transfer: 0.0803	 finalize: 0.0258
Accumulated time: update_bounds func: 154.0155	 prepare: 3.2438	 bound: 140.4765	 transfer: 0.0803	 finalize: 3.0931
batch bounding time:  1.7354419231414795
Current worst splitting domains [lb, ub] (depth):
[-0.07116,   inf] (89), [-0.07116,   inf] (57), [-0.07116,   inf] (95), [-0.07116,   inf] (71), [-0.07116,   inf] (85), [-0.07116,   inf] (45), [-0.07116,   inf] (99), [-0.07116,   inf] (97), [-0.07116,   inf] (103), [-0.07116,   inf] (65), [-0.07116,   inf] (89), [-0.07116,   inf] (93), [-0.07116,   inf] (85), [-0.07116,   inf] (47), [-0.07116,   inf] (71), [-0.07116,   inf] (115), [-0.07116,   inf] (83), [-0.07116,   inf] (87), [-0.07116,   inf] (85), [-0.07116,   inf] (81), 
length of domains: 16596
Total time: 2.1798	 pickout: 0.0598	 decision: 0.3182	 get_bound: 1.7362	 add_domain: 0.0655
Current lb:-0.07116296887397766
34560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 199.79687547683716

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7262] [2, 123] [1, 3635] [1, 4902] [1, 7650] [2, 103] [1, 668] [1, 6053] [1, 2548] [1, 3108] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.523365020751953 with beta sum per layer: [0.0, 56.36163330078125, 87.20919799804688]
alpha/beta optimization time: 1.5830764770507812
This batch time : update_bounds func: 1.7389	 prepare: 0.0393	 bound: 1.5834	 transfer: 0.0881	 finalize: 0.0268
Accumulated time: update_bounds func: 155.7544	 prepare: 3.2830	 bound: 142.0599	 transfer: 0.0881	 finalize: 3.1200
batch bounding time:  1.7395505905151367
Current worst splitting domains [lb, ub] (depth):
[-0.07110,   inf] (55), [-0.07110,   inf] (93), [-0.07110,   inf] (85), [-0.07110,   inf] (43), [-0.07110,   inf] (81), [-0.07110,   inf] (73), [-0.07110,   inf] (87), [-0.07110,   inf] (85), [-0.07110,   inf] (95), [-0.07110,   inf] (85), [-0.07110,   inf] (101), [-0.07110,   inf] (97), [-0.07110,   inf] (85), [-0.07110,   inf] (57), [-0.07109,   inf] (81), [-0.07109,   inf] (93), [-0.07109,   inf] (45), [-0.07109,   inf] (67), [-0.07109,   inf] (59), [-0.07109,   inf] (99), 
length of domains: 16793
Total time: 2.1755	 pickout: 0.0621	 decision: 0.3123	 get_bound: 1.7403	 add_domain: 0.0609
Current lb:-0.07110026478767395
34960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 201.97888588905334

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 422] [1, 2548] [1, 7650] [2, 103] [2, 244] [1, 2547] [1, 3110] [1, 7650] [1, 6053] [1, 7650] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.724136352539062 with beta sum per layer: [0.0, 52.4083137512207, 74.19864654541016]
alpha/beta optimization time: 1.5933418273925781
This batch time : update_bounds func: 1.7459	 prepare: 0.0396	 bound: 1.5937	 transfer: 0.0843	 finalize: 0.0271
Accumulated time: update_bounds func: 157.5003	 prepare: 3.3226	 bound: 143.6537	 transfer: 0.0843	 finalize: 3.1470
batch bounding time:  1.7465996742248535
Current worst splitting domains [lb, ub] (depth):
[-0.07106,   inf] (111), [-0.07106,   inf] (57), [-0.07105,   inf] (59), [-0.07103,   inf] (95), [-0.07103,   inf] (71), [-0.07103,   inf] (109), [-0.07103,   inf] (77), [-0.07103,   inf] (83), [-0.07103,   inf] (89), [-0.07103,   inf] (75), [-0.07103,   inf] (77), [-0.07103,   inf] (73), [-0.07103,   inf] (91), [-0.07103,   inf] (49), [-0.07103,   inf] (39), [-0.07103,   inf] (95), [-0.07103,   inf] (95), [-0.07103,   inf] (75), [-0.07103,   inf] (91), [-0.07103,   inf] (35), 
length of domains: 16993
Total time: 2.1945	 pickout: 0.0686	 decision: 0.3166	 get_bound: 1.7474	 add_domain: 0.0619
Current lb:-0.07106170058250427
35360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 204.18023324012756

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 21] [2, 123] [2, 80] [1, 668] [1, 7268] [1, 6053] [1, 668] [2, 244] [1, 7262] [1, 2547] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.284576416015625 with beta sum per layer: [0.0, 49.40453338623047, 94.70990753173828]
alpha/beta optimization time: 1.5714261531829834
This batch time : update_bounds func: 1.7203	 prepare: 0.0388	 bound: 1.5718	 transfer: 0.0836	 finalize: 0.0250
Accumulated time: update_bounds func: 159.2206	 prepare: 3.3614	 bound: 145.2254	 transfer: 0.0836	 finalize: 3.1720
batch bounding time:  1.7210421562194824
Current worst splitting domains [lb, ub] (depth):
[-0.07099,   inf] (83), [-0.07097,   inf] (77), [-0.07097,   inf] (93), [-0.07097,   inf] (79), [-0.07097,   inf] (43), [-0.07097,   inf] (97), [-0.07097,   inf] (75), [-0.07097,   inf] (37), [-0.07097,   inf] (107), [-0.07097,   inf] (87), [-0.07097,   inf] (59), [-0.07097,   inf] (93), [-0.07097,   inf] (93), [-0.07097,   inf] (67), [-0.07097,   inf] (91), [-0.07097,   inf] (103), [-0.07097,   inf] (45), [-0.07097,   inf] (85), [-0.07097,   inf] (87), [-0.07097,   inf] (75), 
length of domains: 17188
Total time: 2.1640	 pickout: 0.0643	 decision: 0.3144	 get_bound: 1.7219	 add_domain: 0.0634
Current lb:-0.07098796218633652
35760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 206.3508539199829

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6106] [1, 3620] [1, 7262] [1, 2547] [1, 5349] [1, 7262] [1, 6842] [2, 213] [1, 3094] [1, 3110] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.42920684814453 with beta sum per layer: [0.0, 49.567726135253906, 93.11929321289062]
alpha/beta optimization time: 1.5723795890808105
This batch time : update_bounds func: 1.7188	 prepare: 0.0389	 bound: 1.5727	 transfer: 0.0800	 finalize: 0.0259
Accumulated time: update_bounds func: 160.9394	 prepare: 3.4003	 bound: 146.7981	 transfer: 0.0800	 finalize: 3.1979
batch bounding time:  1.719444751739502
Current worst splitting domains [lb, ub] (depth):
[-0.07091,   inf] (51), [-0.07091,   inf] (101), [-0.07091,   inf] (69), [-0.07091,   inf] (55), [-0.07091,   inf] (87), [-0.07091,   inf] (83), [-0.07091,   inf] (95), [-0.07091,   inf] (73), [-0.07091,   inf] (87), [-0.07091,   inf] (111), [-0.07091,   inf] (69), [-0.07091,   inf] (83), [-0.07091,   inf] (97), [-0.07091,   inf] (81), [-0.07091,   inf] (43), [-0.07091,   inf] (107), [-0.07090,   inf] (97), [-0.07090,   inf] (93), [-0.07090,   inf] (45), [-0.07090,   inf] (57), 
length of domains: 17382
Total time: 2.1547	 pickout: 0.0601	 decision: 0.3109	 get_bound: 1.7202	 add_domain: 0.0635
Current lb:-0.07091023772954941
36160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 208.5124535560608

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3500] [1, 3635] [1, 3108] [2, 123] [1, 6106] [1, 2546] [1, 3635] [2, 244] [1, 7650] [0, 13] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.480270385742188 with beta sum per layer: [0.10503704845905304, 52.30510330200195, 83.83895111083984]
alpha/beta optimization time: 1.5738449096679688
This batch time : update_bounds func: 1.7301	 prepare: 0.0397	 bound: 1.5742	 transfer: 0.0879	 finalize: 0.0269
Accumulated time: update_bounds func: 162.6694	 prepare: 3.4401	 bound: 148.3724	 transfer: 0.0879	 finalize: 3.2248
batch bounding time:  1.7308235168457031
Current worst splitting domains [lb, ub] (depth):
[-0.07090,   inf] (113), [-0.07088,   inf] (109), [-0.07085,   inf] (79), [-0.07085,   inf] (97), [-0.07085,   inf] (45), [-0.07085,   inf] (81), [-0.07085,   inf] (83), [-0.07085,   inf] (103), [-0.07085,   inf] (33), [-0.07085,   inf] (83), [-0.07085,   inf] (95), [-0.07085,   inf] (49), [-0.07085,   inf] (51), [-0.07085,   inf] (53), [-0.07085,   inf] (93), [-0.07085,   inf] (33), [-0.07085,   inf] (87), [-0.07085,   inf] (103), [-0.07085,   inf] (71), [-0.07085,   inf] (69), 
length of domains: 17579
Total time: 2.6763	 pickout: 0.0614	 decision: 0.8214	 get_bound: 1.7316	 add_domain: 0.0618
Current lb:-0.07090061902999878
36560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 211.1952064037323

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 5086] [1, 6053] [1, 2546] [1, 668] [2, 103] [1, 3620] [1, 2547] [2, 151] [2, 213] [1, 3620] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.384689331054688 with beta sum per layer: [0.0, 47.171329498291016, 82.16294860839844]
alpha/beta optimization time: 1.5718357563018799
This batch time : update_bounds func: 1.7282	 prepare: 0.0398	 bound: 1.5722	 transfer: 0.0880	 finalize: 0.0269
Accumulated time: update_bounds func: 164.3976	 prepare: 3.4799	 bound: 149.9446	 transfer: 0.0880	 finalize: 3.2517
batch bounding time:  1.7288475036621094
Current worst splitting domains [lb, ub] (depth):
[-0.07079,   inf] (97), [-0.07079,   inf] (101), [-0.07079,   inf] (89), [-0.07079,   inf] (75), [-0.07079,   inf] (97), [-0.07079,   inf] (97), [-0.07079,   inf] (45), [-0.07079,   inf] (37), [-0.07079,   inf] (73), [-0.07079,   inf] (51), [-0.07079,   inf] (71), [-0.07078,   inf] (103), [-0.07078,   inf] (97), [-0.07078,   inf] (101), [-0.07078,   inf] (99), [-0.07078,   inf] (49), [-0.07078,   inf] (95), [-0.07078,   inf] (77), [-0.07078,   inf] (45), [-0.07078,   inf] (89), 
length of domains: 17773
Total time: 2.1648	 pickout: 0.0607	 decision: 0.3131	 get_bound: 1.7296	 add_domain: 0.0614
Current lb:-0.07078967988491058
36960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 213.36649560928345

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 668] [2, 151] [1, 7650] [1, 2549] [1, 6053] [1, 2548] [2, 130] [2, 49] [1, 3494] [2, 51] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.544479370117188 with beta sum per layer: [0.0, 51.539554595947266, 91.93356323242188]
alpha/beta optimization time: 1.5737895965576172
This batch time : update_bounds func: 1.7233	 prepare: 0.0388	 bound: 1.5741	 transfer: 0.0842	 finalize: 0.0251
Accumulated time: update_bounds func: 166.1209	 prepare: 3.5186	 bound: 151.5187	 transfer: 0.0842	 finalize: 3.2768
batch bounding time:  1.7240066528320312
Current worst splitting domains [lb, ub] (depth):
[-0.07074,   inf] (57), [-0.07074,   inf] (91), [-0.07073,   inf] (69), [-0.07073,   inf] (77), [-0.07073,   inf] (91), [-0.07073,   inf] (93), [-0.07073,   inf] (101), [-0.07073,   inf] (93), [-0.07073,   inf] (101), [-0.07073,   inf] (89), [-0.07073,   inf] (81), [-0.07073,   inf] (77), [-0.07073,   inf] (87), [-0.07073,   inf] (91), [-0.07073,   inf] (95), [-0.07073,   inf] (69), [-0.07073,   inf] (85), [-0.07073,   inf] (97), [-0.07073,   inf] (75), [-0.07073,   inf] (97), 
length of domains: 17967
Total time: 2.1666	 pickout: 0.0637	 decision: 0.3136	 get_bound: 1.7248	 add_domain: 0.0644
Current lb:-0.07074155658483505
37360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 215.53991651535034

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 123] [1, 3494] [1, 4902] [1, 3494] [1, 3494] [1, 6053] [1, 6053] [1, 3635] [1, 2548] [1, 7650] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.7459716796875 with beta sum per layer: [0.0, 47.909358978271484, 87.92555236816406]
alpha/beta optimization time: 1.566499948501587
This batch time : update_bounds func: 1.7213	 prepare: 0.0388	 bound: 1.5668	 transfer: 0.0888	 finalize: 0.0256
Accumulated time: update_bounds func: 167.8422	 prepare: 3.5574	 bound: 153.0855	 transfer: 0.0888	 finalize: 3.3023
batch bounding time:  1.7219796180725098
Current worst splitting domains [lb, ub] (depth):
[-0.07068,   inf] (85), [-0.07067,   inf] (103), [-0.07067,   inf] (71), [-0.07067,   inf] (93), [-0.07067,   inf] (81), [-0.07067,   inf] (73), [-0.07067,   inf] (51), [-0.07067,   inf] (87), [-0.07067,   inf] (73), [-0.07066,   inf] (73), [-0.07066,   inf] (97), [-0.07066,   inf] (61), [-0.07066,   inf] (61), [-0.07066,   inf] (55), [-0.07066,   inf] (103), [-0.07066,   inf] (71), [-0.07066,   inf] (45), [-0.07066,   inf] (37), [-0.07066,   inf] (63), [-0.07066,   inf] (69), 
length of domains: 18163
Total time: 2.1565	 pickout: 0.0588	 decision: 0.3102	 get_bound: 1.7228	 add_domain: 0.0647
Current lb:-0.07068300247192383
37760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 217.70314407348633

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3494] [1, 6053] [1, 3603] [1, 3494] [1, 3620] [1, 3108] [2, 51] [1, 3494] [1, 3108] [2, 244] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.384737014770508 with beta sum per layer: [0.0, 53.00849914550781, 92.93948364257812]
alpha/beta optimization time: 1.576310634613037
This batch time : update_bounds func: 1.7328	 prepare: 0.0397	 bound: 1.5767	 transfer: 0.0883	 finalize: 0.0269
Accumulated time: update_bounds func: 169.5750	 prepare: 3.5971	 bound: 154.6622	 transfer: 0.0883	 finalize: 3.3292
batch bounding time:  1.7334511280059814
Current worst splitting domains [lb, ub] (depth):
[-0.07062,   inf] (79), [-0.07062,   inf] (81), [-0.07062,   inf] (81), [-0.07061,   inf] (97), [-0.07061,   inf] (71), [-0.07061,   inf] (57), [-0.07061,   inf] (59), [-0.07061,   inf] (75), [-0.07061,   inf] (75), [-0.07061,   inf] (87), [-0.07061,   inf] (91), [-0.07061,   inf] (111), [-0.07061,   inf] (89), [-0.07061,   inf] (101), [-0.07061,   inf] (91), [-0.07061,   inf] (93), [-0.07061,   inf] (91), [-0.07061,   inf] (77), [-0.07061,   inf] (89), [-0.07061,   inf] (103), 
length of domains: 18356
Total time: 2.1658	 pickout: 0.0601	 decision: 0.3103	 get_bound: 1.7342	 add_domain: 0.0612
Current lb:-0.07061760127544403
38160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 219.87562084197998

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3110] [1, 3494] [2, 244] [1, 668] [1, 3108] [2, 123] [2, 80] [2, 244] [2, 244] [1, 6106] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.059694290161133 with beta sum per layer: [0.0, 47.40481948852539, 105.6834716796875]
alpha/beta optimization time: 1.5702900886535645
This batch time : update_bounds func: 1.7217	 prepare: 0.0388	 bound: 1.5706	 transfer: 0.0841	 finalize: 0.0270
Accumulated time: update_bounds func: 171.2967	 prepare: 3.6359	 bound: 156.2328	 transfer: 0.0841	 finalize: 3.3562
batch bounding time:  1.7223939895629883
Current worst splitting domains [lb, ub] (depth):
[-0.07060,   inf] (113), [-0.07059,   inf] (63), [-0.07058,   inf] (113), [-0.07057,   inf] (113), [-0.07056,   inf] (75), [-0.07056,   inf] (77), [-0.07056,   inf] (97), [-0.07056,   inf] (79), [-0.07056,   inf] (95), [-0.07056,   inf] (105), [-0.07056,   inf] (95), [-0.07056,   inf] (109), [-0.07056,   inf] (61), [-0.07056,   inf] (47), [-0.07056,   inf] (55), [-0.07056,   inf] (87), [-0.07056,   inf] (43), [-0.07056,   inf] (97), [-0.07056,   inf] (71), [-0.07056,   inf] (103), 
length of domains: 18546
Total time: 2.1617	 pickout: 0.0642	 decision: 0.3142	 get_bound: 1.7232	 add_domain: 0.0602
Current lb:-0.07059585303068161
38560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 222.04403972625732

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3636] [1, 7261] [1, 3636] [1, 3636] [1, 3620] [1, 2547] [1, 3636] [1, 3494] [1, 3494] [2, 151] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.509737014770508 with beta sum per layer: [0.10747314989566803, 50.91382598876953, 88.9808120727539]
alpha/beta optimization time: 1.5731713771820068
This batch time : update_bounds func: 1.7245	 prepare: 0.0399	 bound: 1.5736	 transfer: 0.0838	 finalize: 0.0260
Accumulated time: update_bounds func: 173.0212	 prepare: 3.6757	 bound: 157.8064	 transfer: 0.0838	 finalize: 3.3822
batch bounding time:  1.725208044052124
Current worst splitting domains [lb, ub] (depth):
[-0.07053,   inf] (93), [-0.07050,   inf] (93), [-0.07050,   inf] (113), [-0.07050,   inf] (59), [-0.07050,   inf] (81), [-0.07050,   inf] (95), [-0.07050,   inf] (93), [-0.07050,   inf] (37), [-0.07050,   inf] (79), [-0.07050,   inf] (103), [-0.07050,   inf] (75), [-0.07050,   inf] (53), [-0.07050,   inf] (77), [-0.07050,   inf] (53), [-0.07050,   inf] (73), [-0.07050,   inf] (67), [-0.07050,   inf] (71), [-0.07050,   inf] (59), [-0.07050,   inf] (59), [-0.07050,   inf] (65), 
length of domains: 18742
Total time: 2.7134	 pickout: 0.0638	 decision: 0.8588	 get_bound: 1.7260	 add_domain: 0.0647
Current lb:-0.07053272426128387
38960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 224.76396989822388

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6106] [1, 3494] [1, 422] [1, 7261] [1, 2547] [1, 668] [1, 2548] [2, 175] [2, 244] [1, 3603] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 24.863292694091797 with beta sum per layer: [0.0, 44.01862335205078, 112.55901336669922]
alpha/beta optimization time: 1.5962367057800293
This batch time : update_bounds func: 1.7479	 prepare: 0.0397	 bound: 1.5966	 transfer: 0.0844	 finalize: 0.0260
Accumulated time: update_bounds func: 174.7691	 prepare: 3.7155	 bound: 159.4030	 transfer: 0.0844	 finalize: 3.4082
batch bounding time:  1.748591661453247
Current worst splitting domains [lb, ub] (depth):
[-0.07049,   inf] (115), [-0.07049,   inf] (63), [-0.07045,   inf] (79), [-0.07044,   inf] (31), [-0.07044,   inf] (89), [-0.07044,   inf] (71), [-0.07044,   inf] (71), [-0.07044,   inf] (55), [-0.07044,   inf] (73), [-0.07044,   inf] (93), [-0.07044,   inf] (99), [-0.07044,   inf] (93), [-0.07044,   inf] (75), [-0.07044,   inf] (95), [-0.07044,   inf] (97), [-0.07044,   inf] (99), [-0.07044,   inf] (95), [-0.07044,   inf] (87), [-0.07044,   inf] (47), [-0.07044,   inf] (85), 
length of domains: 18936
Total time: 2.1930	 pickout: 0.0641	 decision: 0.3166	 get_bound: 1.7494	 add_domain: 0.0629
Current lb:-0.07048813998699188
39360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 226.963543176651

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6842] [1, 5357] [1, 5357] [2, 37] [1, 2548] [1, 4902] [1, 3620] [2, 123] [1, 2547] [1, 3603] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.164913177490234 with beta sum per layer: [0.0, 49.58644485473633, 86.8769760131836]
alpha/beta optimization time: 1.5773718357086182
This batch time : update_bounds func: 1.7327	 prepare: 0.0415	 bound: 1.5779	 transfer: 0.0844	 finalize: 0.0275
Accumulated time: update_bounds func: 176.5018	 prepare: 3.7570	 bound: 160.9809	 transfer: 0.0844	 finalize: 3.4356
batch bounding time:  1.733393907546997
Current worst splitting domains [lb, ub] (depth):
[-0.07040,   inf] (109), [-0.07038,   inf] (99), [-0.07038,   inf] (97), [-0.07038,   inf] (91), [-0.07038,   inf] (93), [-0.07038,   inf] (97), [-0.07038,   inf] (101), [-0.07038,   inf] (97), [-0.07038,   inf] (97), [-0.07038,   inf] (97), [-0.07038,   inf] (75), [-0.07038,   inf] (75), [-0.07038,   inf] (105), [-0.07038,   inf] (83), [-0.07038,   inf] (39), [-0.07038,   inf] (67), [-0.07038,   inf] (107), [-0.07038,   inf] (83), [-0.07038,   inf] (71), [-0.07038,   inf] (109), 
length of domains: 19130
Total time: 2.1856	 pickout: 0.0699	 decision: 0.3197	 get_bound: 1.7342	 add_domain: 0.0618
Current lb:-0.07039817422628403
39760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 229.15595078468323

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 5533] [1, 7262] [1, 7262] [1, 3620] [1, 3110] [1, 3636] [1, 3635] [1, 2548] [1, 668] [1, 6053] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.556819915771484 with beta sum per layer: [0.0, 52.37408447265625, 84.6668701171875]
alpha/beta optimization time: 1.5741298198699951
This batch time : update_bounds func: 1.7299	 prepare: 0.0398	 bound: 1.5745	 transfer: 0.0845	 finalize: 0.0298
Accumulated time: update_bounds func: 178.2317	 prepare: 3.7968	 bound: 162.5554	 transfer: 0.0845	 finalize: 3.4654
batch bounding time:  1.7305614948272705
Current worst splitting domains [lb, ub] (depth):
[-0.07033,   inf] (107), [-0.07033,   inf] (85), [-0.07032,   inf] (107), [-0.07032,   inf] (57), [-0.07032,   inf] (93), [-0.07032,   inf] (77), [-0.07032,   inf] (77), [-0.07032,   inf] (97), [-0.07032,   inf] (47), [-0.07032,   inf] (73), [-0.07032,   inf] (101), [-0.07032,   inf] (71), [-0.07032,   inf] (77), [-0.07032,   inf] (83), [-0.07032,   inf] (99), [-0.07032,   inf] (43), [-0.07032,   inf] (67), [-0.07032,   inf] (105), [-0.07032,   inf] (89), [-0.07032,   inf] (91), 
length of domains: 19327
Total time: 2.1808	 pickout: 0.0721	 decision: 0.3139	 get_bound: 1.7313	 add_domain: 0.0635
Current lb:-0.07032555341720581
40160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 231.34380269050598

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 21] [1, 3110] [1, 3094] [2, 123] [1, 2548] [2, 244] [1, 4902] [1, 6053] [2, 105] [2, 244] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 24.723461151123047 with beta sum per layer: [0.0, 50.564178466796875, 105.56227111816406]
alpha/beta optimization time: 1.579253911972046
This batch time : update_bounds func: 1.7350	 prepare: 0.0398	 bound: 1.5796	 transfer: 0.0887	 finalize: 0.0256
Accumulated time: update_bounds func: 179.9667	 prepare: 3.8366	 bound: 164.1350	 transfer: 0.0887	 finalize: 3.4910
batch bounding time:  1.7356915473937988
Current worst splitting domains [lb, ub] (depth):
[-0.07029,   inf] (113), [-0.07029,   inf] (75), [-0.07028,   inf] (113), [-0.07027,   inf] (85), [-0.07027,   inf] (87), [-0.07027,   inf] (97), [-0.07027,   inf] (79), [-0.07027,   inf] (87), [-0.07027,   inf] (65), [-0.07027,   inf] (83), [-0.07027,   inf] (31), [-0.07027,   inf] (95), [-0.07027,   inf] (85), [-0.07027,   inf] (75), [-0.07027,   inf] (73), [-0.07027,   inf] (79), [-0.07027,   inf] (81), [-0.07027,   inf] (85), [-0.07027,   inf] (97), [-0.07027,   inf] (95), 
length of domains: 19517
Total time: 2.1754	 pickout: 0.0597	 decision: 0.3154	 get_bound: 1.7365	 add_domain: 0.0638
Current lb:-0.07028831541538239
40560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 233.52601742744446

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 4629] [1, 3108] [1, 4629] [1, 6106] [1, 6106] [1, 2548] [1, 5357] [1, 3494] [1, 4851] [1, 3494] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.048681259155273 with beta sum per layer: [0.0, 52.580101013183594, 86.33528137207031]
alpha/beta optimization time: 1.5801455974578857
This batch time : update_bounds func: 1.7266	 prepare: 0.0386	 bound: 1.5805	 transfer: 0.0802	 finalize: 0.0260
Accumulated time: update_bounds func: 181.6932	 prepare: 3.8752	 bound: 165.7155	 transfer: 0.0802	 finalize: 3.5170
batch bounding time:  1.7272284030914307
Current worst splitting domains [lb, ub] (depth):
[-0.07023,   inf] (113), [-0.07022,   inf] (75), [-0.07022,   inf] (101), [-0.07022,   inf] (69), [-0.07022,   inf] (77), [-0.07022,   inf] (87), [-0.07022,   inf] (83), [-0.07022,   inf] (103), [-0.07022,   inf] (83), [-0.07022,   inf] (71), [-0.07022,   inf] (87), [-0.07022,   inf] (91), [-0.07022,   inf] (69), [-0.07022,   inf] (65), [-0.07022,   inf] (93), [-0.07022,   inf] (105), [-0.07022,   inf] (75), [-0.07022,   inf] (57), [-0.07022,   inf] (93), [-0.07022,   inf] (69), 
length of domains: 19709
Total time: 2.7270	 pickout: 0.0606	 decision: 0.3115	 get_bound: 1.7280	 add_domain: 0.6269
Current lb:-0.07022539526224136
40960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 236.25957083702087

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2548] [1, 5533] [1, 3635] [1, 5087] [1, 2546] [1, 6106] [1, 3494] [1, 7262] [1, 3494] [2, 244] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.18229103088379 with beta sum per layer: [0.0, 57.17882537841797, 87.0543212890625]
alpha/beta optimization time: 1.573378324508667
This batch time : update_bounds func: 1.7219	 prepare: 0.0402	 bound: 1.5737	 transfer: 0.0798	 finalize: 0.0268
Accumulated time: update_bounds func: 183.4151	 prepare: 3.9154	 bound: 167.2893	 transfer: 0.0798	 finalize: 3.5438
batch bounding time:  1.7225534915924072
Current worst splitting domains [lb, ub] (depth):
[-0.07016,   inf] (91), [-0.07016,   inf] (89), [-0.07016,   inf] (77), [-0.07016,   inf] (97), [-0.07016,   inf] (103), [-0.07016,   inf] (101), [-0.07016,   inf] (99), [-0.07016,   inf] (31), [-0.07016,   inf] (89), [-0.07016,   inf] (67), [-0.07016,   inf] (87), [-0.07016,   inf] (89), [-0.07016,   inf] (89), [-0.07016,   inf] (81), [-0.07016,   inf] (71), [-0.07016,   inf] (61), [-0.07016,   inf] (97), [-0.07016,   inf] (43), [-0.07016,   inf] (75), [-0.07016,   inf] (105), 
length of domains: 19904
Total time: 2.1654	 pickout: 0.0607	 decision: 0.3203	 get_bound: 1.7233	 add_domain: 0.0610
Current lb:-0.07016481459140778
41360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 238.43154740333557

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6106] [1, 7650] [1, 3620] [1, 668] [1, 3635] [1, 2548] [1, 667] [2, 21] [1, 7650] [1, 3620] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.37970733642578 with beta sum per layer: [0.11506975442171097, 50.84709548950195, 83.04146575927734]
alpha/beta optimization time: 1.5729339122772217
This batch time : update_bounds func: 1.7270	 prepare: 0.0401	 bound: 1.5733	 transfer: 0.0852	 finalize: 0.0272
Accumulated time: update_bounds func: 185.1421	 prepare: 3.9555	 bound: 168.8626	 transfer: 0.0852	 finalize: 3.5710
batch bounding time:  1.7276673316955566
Current worst splitting domains [lb, ub] (depth):
[-0.07015,   inf] (109), [-0.07012,   inf] (79), [-0.07011,   inf] (111), [-0.07011,   inf] (99), [-0.07011,   inf] (87), [-0.07011,   inf] (83), [-0.07011,   inf] (49), [-0.07011,   inf] (111), [-0.07011,   inf] (81), [-0.07011,   inf] (97), [-0.07011,   inf] (97), [-0.07011,   inf] (105), [-0.07011,   inf] (93), [-0.07011,   inf] (99), [-0.07011,   inf] (117), [-0.07011,   inf] (77), [-0.07011,   inf] (71), [-0.07011,   inf] (77), [-0.07011,   inf] (89), [-0.07011,   inf] (107), 
length of domains: 20100
Total time: 2.1699	 pickout: 0.0633	 decision: 0.3157	 get_bound: 1.7284	 add_domain: 0.0624
Current lb:-0.07014679163694382
41760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 240.6081509590149

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 38] [1, 2547] [1, 21] [1, 668] [1, 3110] [1, 7650] [2, 105] [1, 21] [1, 5357] [1, 668] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 24.72966766357422 with beta sum per layer: [0.0, 55.47798156738281, 76.09988403320312]
alpha/beta optimization time: 1.5724728107452393
This batch time : update_bounds func: 1.7239	 prepare: 0.0402	 bound: 1.5729	 transfer: 0.0840	 finalize: 0.0255
Accumulated time: update_bounds func: 186.8661	 prepare: 3.9958	 bound: 170.4354	 transfer: 0.0840	 finalize: 3.5965
batch bounding time:  1.7245943546295166
Current worst splitting domains [lb, ub] (depth):
[-0.07008,   inf] (111), [-0.07007,   inf] (37), [-0.07007,   inf] (97), [-0.07007,   inf] (75), [-0.07007,   inf] (87), [-0.07007,   inf] (45), [-0.07007,   inf] (99), [-0.07007,   inf] (81), [-0.07006,   inf] (45), [-0.07006,   inf] (71), [-0.07006,   inf] (107), [-0.07006,   inf] (95), [-0.07006,   inf] (73), [-0.07006,   inf] (49), [-0.07006,   inf] (99), [-0.07006,   inf] (65), [-0.07006,   inf] (87), [-0.07006,   inf] (83), [-0.07006,   inf] (77), [-0.07006,   inf] (85), 
length of domains: 20287
Total time: 2.1716	 pickout: 0.0698	 decision: 0.3112	 get_bound: 1.7254	 add_domain: 0.0651
Current lb:-0.07007758319377899
42160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 242.786518573761

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 21] [2, 175] [1, 668] [2, 244] [1, 7650] [1, 5349] [1, 1118] [1, 2547] [1, 5349] [1, 7651] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.357295989990234 with beta sum per layer: [0.10752028971910477, 49.54733657836914, 97.41705322265625]
alpha/beta optimization time: 1.5701675415039062
This batch time : update_bounds func: 1.7216	 prepare: 0.0397	 bound: 1.5705	 transfer: 0.0838	 finalize: 0.0263
Accumulated time: update_bounds func: 188.5876	 prepare: 4.0355	 bound: 172.0059	 transfer: 0.0838	 finalize: 3.6228
batch bounding time:  1.7222967147827148
Current worst splitting domains [lb, ub] (depth):
[-0.07003,   inf] (113), [-0.07001,   inf] (89), [-0.07001,   inf] (55), [-0.07001,   inf] (83), [-0.07001,   inf] (97), [-0.07001,   inf] (81), [-0.07001,   inf] (59), [-0.07001,   inf] (77), [-0.07001,   inf] (99), [-0.07001,   inf] (97), [-0.07001,   inf] (67), [-0.07001,   inf] (99), [-0.07001,   inf] (101), [-0.07001,   inf] (59), [-0.07001,   inf] (101), [-0.07001,   inf] (71), [-0.07001,   inf] (75), [-0.07001,   inf] (35), [-0.07001,   inf] (79), [-0.07001,   inf] (93), 
length of domains: 20482
Total time: 2.1745	 pickout: 0.0733	 decision: 0.3135	 get_bound: 1.7231	 add_domain: 0.0646
Current lb:-0.07003484666347504
42560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 244.96767902374268

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 422] [1, 7650] [1, 1555] [1, 3620] [1, 6053] [1, 2547] [2, 80] [1, 2546] [1, 3636] [1, 668] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.440608978271484 with beta sum per layer: [0.1051916554570198, 61.14961242675781, 67.25700378417969]
alpha/beta optimization time: 1.5735502243041992
This batch time : update_bounds func: 1.7185	 prepare: 0.0397	 bound: 1.5739	 transfer: 0.0766	 finalize: 0.0271
Accumulated time: update_bounds func: 190.3061	 prepare: 4.0751	 bound: 173.5799	 transfer: 0.0766	 finalize: 3.6499
batch bounding time:  1.7192127704620361
Current worst splitting domains [lb, ub] (depth):
[-0.07001,   inf] (115), [-0.06998,   inf] (113), [-0.06996,   inf] (63), [-0.06996,   inf] (85), [-0.06996,   inf] (77), [-0.06996,   inf] (73), [-0.06996,   inf] (45), [-0.06996,   inf] (75), [-0.06996,   inf] (71), [-0.06995,   inf] (73), [-0.06995,   inf] (107), [-0.06995,   inf] (61), [-0.06995,   inf] (79), [-0.06995,   inf] (95), [-0.06995,   inf] (81), [-0.06995,   inf] (73), [-0.06995,   inf] (95), [-0.06995,   inf] (89), [-0.06995,   inf] (69), [-0.06995,   inf] (95), 
length of domains: 20677
Total time: 2.1625	 pickout: 0.0677	 decision: 0.3106	 get_bound: 1.7200	 add_domain: 0.0641
Current lb:-0.07001322507858276
42960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 247.13820028305054

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 5086] [1, 422] [1, 5357] [1, 6106] [2, 244] [1, 3494] [1, 5349] [1, 3108] [2, 244] [1, 3108] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 24.72864532470703 with beta sum per layer: [0.0, 51.473106384277344, 92.1065902709961]
alpha/beta optimization time: 1.5730664730072021
This batch time : update_bounds func: 1.7253	 prepare: 0.0397	 bound: 1.5734	 transfer: 0.0838	 finalize: 0.0270
Accumulated time: update_bounds func: 192.0314	 prepare: 4.1149	 bound: 175.1533	 transfer: 0.0838	 finalize: 3.6769
batch bounding time:  1.725905418395996
Current worst splitting domains [lb, ub] (depth):
[-0.06996,   inf] (115), [-0.06993,   inf] (113), [-0.06992,   inf] (79), [-0.06991,   inf] (113), [-0.06991,   inf] (63), [-0.06991,   inf] (83), [-0.06991,   inf] (73), [-0.06991,   inf] (31), [-0.06991,   inf] (79), [-0.06991,   inf] (67), [-0.06991,   inf] (75), [-0.06991,   inf] (97), [-0.06991,   inf] (63), [-0.06991,   inf] (75), [-0.06991,   inf] (91), [-0.06991,   inf] (91), [-0.06991,   inf] (77), [-0.06991,   inf] (89), [-0.06991,   inf] (99), [-0.06991,   inf] (105), 
length of domains: 20869
Total time: 2.1774	 pickout: 0.0772	 decision: 0.3124	 get_bound: 1.7267	 add_domain: 0.0611
Current lb:-0.06996268033981323
43360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 249.32245421409607

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6842] [1, 3636] [1, 2547] [1, 3636] [1, 7268] [1, 2546] [1, 3620] [2, 170] [1, 2547] [1, 4851] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 24.799036026000977 with beta sum per layer: [0.1127055436372757, 55.92790603637695, 85.28164672851562]
alpha/beta optimization time: 1.575556755065918
This batch time : update_bounds func: 1.7236	 prepare: 0.0398	 bound: 1.5759	 transfer: 0.0806	 finalize: 0.0260
Accumulated time: update_bounds func: 193.7550	 prepare: 4.1547	 bound: 176.7292	 transfer: 0.0806	 finalize: 3.7029
batch bounding time:  1.7242543697357178
Current worst splitting domains [lb, ub] (depth):
[-0.06990,   inf] (109), [-0.06987,   inf] (65), [-0.06987,   inf] (87), [-0.06986,   inf] (121), [-0.06986,   inf] (97), [-0.06986,   inf] (107), [-0.06986,   inf] (67), [-0.06986,   inf] (99), [-0.06986,   inf] (69), [-0.06986,   inf] (81), [-0.06986,   inf] (91), [-0.06986,   inf] (87), [-0.06986,   inf] (93), [-0.06986,   inf] (89), [-0.06986,   inf] (55), [-0.06986,   inf] (93), [-0.06986,   inf] (97), [-0.06986,   inf] (73), [-0.06986,   inf] (63), [-0.06986,   inf] (103), 
length of domains: 21058
Total time: 2.8098	 pickout: 0.0704	 decision: 0.9495	 get_bound: 1.7251	 add_domain: 0.0648
Current lb:-0.0698973760008812
43760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 252.13886618614197

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 5533] [1, 4902] [1, 3110] [1, 38] [1, 6053] [1, 3094] [1, 5087] [1, 3635] [1, 4851] [1, 5357] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.22368812561035 with beta sum per layer: [0.10519164800643921, 52.609840393066406, 91.34042358398438]
alpha/beta optimization time: 1.5695314407348633
This batch time : update_bounds func: 1.7131	 prepare: 0.0398	 bound: 1.5699	 transfer: 0.0758	 finalize: 0.0264
Accumulated time: update_bounds func: 195.4681	 prepare: 4.1944	 bound: 178.2991	 transfer: 0.0758	 finalize: 3.7293
batch bounding time:  1.7137959003448486
Current worst splitting domains [lb, ub] (depth):
[-0.06981,   inf] (105), [-0.06981,   inf] (83), [-0.06981,   inf] (93), [-0.06981,   inf] (91), [-0.06981,   inf] (83), [-0.06981,   inf] (97), [-0.06981,   inf] (85), [-0.06981,   inf] (91), [-0.06981,   inf] (113), [-0.06981,   inf] (97), [-0.06981,   inf] (79), [-0.06981,   inf] (61), [-0.06981,   inf] (99), [-0.06981,   inf] (93), [-0.06981,   inf] (95), [-0.06981,   inf] (95), [-0.06981,   inf] (83), [-0.06981,   inf] (95), [-0.06981,   inf] (101), [-0.06981,   inf] (97), 
length of domains: 21254
Total time: 2.1654	 pickout: 0.0747	 decision: 0.3110	 get_bound: 1.7146	 add_domain: 0.0651
Current lb:-0.06981217861175537
44160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 254.3109631538391

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3603] [1, 668] [1, 7650] [1, 2548] [1, 6106] [1, 6053] [1, 3110] [1, 6106] [1, 5533] [1, 2548] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.087055206298828 with beta sum per layer: [0.22777530550956726, 56.95684051513672, 93.38043212890625]
alpha/beta optimization time: 1.5742197036743164
This batch time : update_bounds func: 1.7197	 prepare: 0.0398	 bound: 1.5746	 transfer: 0.0764	 finalize: 0.0276
Accumulated time: update_bounds func: 197.1878	 prepare: 4.2343	 bound: 179.8737	 transfer: 0.0764	 finalize: 3.7569
batch bounding time:  1.7203905582427979
Current worst splitting domains [lb, ub] (depth):
[-0.06979,   inf] (109), [-0.06978,   inf] (109), [-0.06977,   inf] (99), [-0.06977,   inf] (85), [-0.06977,   inf] (105), [-0.06977,   inf] (91), [-0.06977,   inf] (79), [-0.06977,   inf] (77), [-0.06977,   inf] (107), [-0.06977,   inf] (77), [-0.06977,   inf] (91), [-0.06977,   inf] (63), [-0.06977,   inf] (75), [-0.06977,   inf] (105), [-0.06977,   inf] (93), [-0.06977,   inf] (75), [-0.06977,   inf] (89), [-0.06977,   inf] (105), [-0.06977,   inf] (47), [-0.06977,   inf] (69), 
length of domains: 21449
Total time: 2.1790	 pickout: 0.0846	 decision: 0.3098	 get_bound: 1.7212	 add_domain: 0.0634
Current lb:-0.06978726387023926
44560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 256.49665212631226

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 5533] [1, 38] [1, 668] [1, 7650] [2, 151] [1, 6106] [1, 3620] [1, 4851] [1, 3094] [1, 2547] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 24.91411018371582 with beta sum per layer: [0.0, 53.89858627319336, 84.14468383789062]
alpha/beta optimization time: 1.6001613140106201
This batch time : update_bounds func: 1.7546	 prepare: 0.0418	 bound: 1.6005	 transfer: 0.0851	 finalize: 0.0259
Accumulated time: update_bounds func: 198.9424	 prepare: 4.2761	 bound: 181.4742	 transfer: 0.0851	 finalize: 3.7828
batch bounding time:  1.7553575038909912
Current worst splitting domains [lb, ub] (depth):
[-0.06973,   inf] (97), [-0.06973,   inf] (57), [-0.06973,   inf] (101), [-0.06973,   inf] (95), [-0.06973,   inf] (95), [-0.06973,   inf] (99), [-0.06973,   inf] (29), [-0.06973,   inf] (77), [-0.06972,   inf] (57), [-0.06972,   inf] (71), [-0.06972,   inf] (87), [-0.06972,   inf] (47), [-0.06972,   inf] (93), [-0.06972,   inf] (77), [-0.06972,   inf] (81), [-0.06972,   inf] (81), [-0.06972,   inf] (95), [-0.06972,   inf] (61), [-0.06972,   inf] (101), [-0.06972,   inf] (83), 
length of domains: 21641
Total time: 2.2183	 pickout: 0.0831	 decision: 0.3136	 get_bound: 1.7562	 add_domain: 0.0654
Current lb:-0.06972645223140717
44960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 258.72197127342224

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3635] [2, 123] [1, 4629] [1, 1118] [1, 2548] [1, 7262] [2, 21] [1, 3620] [2, 80] [1, 7651] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 24.578834533691406 with beta sum per layer: [0.11270510405302048, 51.42861557006836, 92.607177734375]
alpha/beta optimization time: 1.585862398147583
This batch time : update_bounds func: 1.7458	 prepare: 0.0433	 bound: 1.5864	 transfer: 0.0847	 finalize: 0.0302
Accumulated time: update_bounds func: 200.6882	 prepare: 4.3193	 bound: 183.0605	 transfer: 0.0847	 finalize: 3.8130
batch bounding time:  1.7465908527374268
Current worst splitting domains [lb, ub] (depth):
[-0.06970,   inf] (109), [-0.06969,   inf] (63), [-0.06968,   inf] (113), [-0.06968,   inf] (79), [-0.06968,   inf] (75), [-0.06968,   inf] (95), [-0.06968,   inf] (89), [-0.06968,   inf] (49), [-0.06967,   inf] (101), [-0.06967,   inf] (79), [-0.06967,   inf] (101), [-0.06967,   inf] (93), [-0.06967,   inf] (105), [-0.06967,   inf] (93), [-0.06967,   inf] (51), [-0.06967,   inf] (79), [-0.06967,   inf] (69), [-0.06967,   inf] (89), [-0.06967,   inf] (91), [-0.06967,   inf] (99), 
length of domains: 21833
Total time: 2.2234	 pickout: 0.0792	 decision: 0.3237	 get_bound: 1.7477	 add_domain: 0.0728
Current lb:-0.06969597935676575
45360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 260.956205368042

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 4629] [1, 5357] [1, 4629] [1, 2546] [1, 3108] [1, 3603] [1, 6053] [2, 105] [2, 151] [1, 2547] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 24.94549560546875 with beta sum per layer: [0.0, 59.186119079589844, 77.35840606689453]
alpha/beta optimization time: 1.5795602798461914
This batch time : update_bounds func: 1.7335	 prepare: 0.0417	 bound: 1.5799	 transfer: 0.0842	 finalize: 0.0263
Accumulated time: update_bounds func: 202.4216	 prepare: 4.3611	 bound: 184.6405	 transfer: 0.0842	 finalize: 3.8394
batch bounding time:  1.734189510345459
Current worst splitting domains [lb, ub] (depth):
[-0.06965,   inf] (113), [-0.06964,   inf] (113), [-0.06963,   inf] (101), [-0.06963,   inf] (87), [-0.06963,   inf] (85), [-0.06963,   inf] (105), [-0.06963,   inf] (101), [-0.06963,   inf] (103), [-0.06963,   inf] (89), [-0.06963,   inf] (79), [-0.06963,   inf] (105), [-0.06963,   inf] (93), [-0.06963,   inf] (67), [-0.06963,   inf] (95), [-0.06963,   inf] (61), [-0.06963,   inf] (83), [-0.06963,   inf] (95), [-0.06963,   inf] (99), [-0.06963,   inf] (101), [-0.06963,   inf] (95), 
length of domains: 22025
Total time: 2.2077	 pickout: 0.0919	 decision: 0.3144	 get_bound: 1.7350	 add_domain: 0.0663
Current lb:-0.06965179741382599
45760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 263.1709532737732

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2548] [1, 4629] [1, 667] [1, 3110] [1, 3603] [2, 151] [1, 667] [2, 151] [1, 7650] [2, 244] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 24.742549896240234 with beta sum per layer: [0.0, 60.13243865966797, 76.1724624633789]
alpha/beta optimization time: 1.5820322036743164
This batch time : update_bounds func: 1.7318	 prepare: 0.0409	 bound: 1.5824	 transfer: 0.0803	 finalize: 0.0269
Accumulated time: update_bounds func: 204.1534	 prepare: 4.4020	 bound: 186.2229	 transfer: 0.0803	 finalize: 3.8662
batch bounding time:  1.7324855327606201
Current worst splitting domains [lb, ub] (depth):
[-0.06959,   inf] (121), [-0.06959,   inf] (91), [-0.06959,   inf] (81), [-0.06959,   inf] (99), [-0.06959,   inf] (93), [-0.06959,   inf] (81), [-0.06959,   inf] (93), [-0.06959,   inf] (55), [-0.06959,   inf] (67), [-0.06959,   inf] (61), [-0.06959,   inf] (107), [-0.06959,   inf] (95), [-0.06959,   inf] (69), [-0.06959,   inf] (73), [-0.06959,   inf] (53), [-0.06959,   inf] (107), [-0.06959,   inf] (87), [-0.06959,   inf] (89), [-0.06959,   inf] (69), [-0.06959,   inf] (71), 
length of domains: 22214
Total time: 2.1896	 pickout: 0.0786	 decision: 0.3119	 get_bound: 1.7333	 add_domain: 0.0658
Current lb:-0.06959119439125061
46160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 265.36802101135254

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 38] [1, 6106] [1, 2546] [1, 3636] [1, 6106] [2, 244] [1, 6106] [2, 123] [1, 3108] [1, 7261] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.411640167236328 with beta sum per layer: [0.0, 61.35869598388672, 80.63882446289062]
alpha/beta optimization time: 1.5735385417938232
This batch time : update_bounds func: 1.7244	 prepare: 0.0400	 bound: 1.5739	 transfer: 0.0832	 finalize: 0.0261
Accumulated time: update_bounds func: 205.8779	 prepare: 4.4419	 bound: 187.7968	 transfer: 0.0832	 finalize: 3.8923
batch bounding time:  1.7251324653625488
Current worst splitting domains [lb, ub] (depth):
[-0.06956,   inf] (57), [-0.06954,   inf] (103), [-0.06954,   inf] (101), [-0.06954,   inf] (91), [-0.06954,   inf] (109), [-0.06954,   inf] (101), [-0.06954,   inf] (97), [-0.06954,   inf] (75), [-0.06954,   inf] (99), [-0.06954,   inf] (97), [-0.06954,   inf] (85), [-0.06954,   inf] (101), [-0.06954,   inf] (93), [-0.06954,   inf] (93), [-0.06954,   inf] (105), [-0.06954,   inf] (99), [-0.06954,   inf] (81), [-0.06954,   inf] (71), [-0.06954,   inf] (119), [-0.06954,   inf] (61), 
length of domains: 22411
Total time: 2.9070	 pickout: 0.0760	 decision: 1.0385	 get_bound: 1.7259	 add_domain: 0.0666
Current lb:-0.06955879926681519
46560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 268.28158926963806

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 123] [1, 6053] [1, 38] [1, 6106] [1, 5533] [2, 151] [1, 668] [1, 3494] [1, 3635] [1, 3635] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 24.799198150634766 with beta sum per layer: [0.0, 58.79815673828125, 87.55941772460938]
alpha/beta optimization time: 1.5763447284698486
This batch time : update_bounds func: 1.7275	 prepare: 0.0397	 bound: 1.5767	 transfer: 0.0834	 finalize: 0.0265
Accumulated time: update_bounds func: 207.6054	 prepare: 4.4817	 bound: 189.3735	 transfer: 0.0834	 finalize: 3.9188
batch bounding time:  1.7283005714416504
Current worst splitting domains [lb, ub] (depth):
[-0.06951,   inf] (111), [-0.06950,   inf] (91), [-0.06950,   inf] (89), [-0.06950,   inf] (79), [-0.06950,   inf] (83), [-0.06950,   inf] (69), [-0.06950,   inf] (95), [-0.06950,   inf] (87), [-0.06950,   inf] (83), [-0.06950,   inf] (49), [-0.06950,   inf] (89), [-0.06950,   inf] (83), [-0.06950,   inf] (83), [-0.06950,   inf] (65), [-0.06950,   inf] (81), [-0.06950,   inf] (83), [-0.06950,   inf] (99), [-0.06950,   inf] (101), [-0.06950,   inf] (43), [-0.06950,   inf] (73), 
length of domains: 22600
Total time: 2.1922	 pickout: 0.0803	 decision: 0.3162	 get_bound: 1.7291	 add_domain: 0.0665
Current lb:-0.06951463222503662
46960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 270.48043155670166

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 21] [1, 2548] [1, 7262] [1, 3494] [1, 7650] [1, 4902] [1, 3635] [1, 3110] [1, 3110] [2, 105] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 24.927898406982422 with beta sum per layer: [0.11293242871761322, 56.48431396484375, 85.0221939086914]
alpha/beta optimization time: 1.5741808414459229
This batch time : update_bounds func: 1.7178	 prepare: 0.0394	 bound: 1.5746	 transfer: 0.0759	 finalize: 0.0266
Accumulated time: update_bounds func: 209.3232	 prepare: 4.5211	 bound: 190.9480	 transfer: 0.0759	 finalize: 3.9454
batch bounding time:  1.7185449600219727
Current worst splitting domains [lb, ub] (depth):
[-0.06947,   inf] (109), [-0.06947,   inf] (81), [-0.06946,   inf] (51), [-0.06946,   inf] (87), [-0.06946,   inf] (95), [-0.06946,   inf] (91), [-0.06946,   inf] (105), [-0.06946,   inf] (89), [-0.06946,   inf] (77), [-0.06946,   inf] (97), [-0.06946,   inf] (69), [-0.06946,   inf] (75), [-0.06946,   inf] (47), [-0.06946,   inf] (71), [-0.06946,   inf] (95), [-0.06946,   inf] (67), [-0.06946,   inf] (103), [-0.06946,   inf] (83), [-0.06946,   inf] (93), [-0.06946,   inf] (103), 
length of domains: 22794
Total time: 2.1800	 pickout: 0.0817	 decision: 0.3140	 get_bound: 1.7194	 add_domain: 0.0650
Current lb:-0.06946678459644318
47360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 272.6682996749878

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 5533] [1, 3620] [1, 3500] [1, 3494] [1, 2548] [1, 6053] [1, 3636] [1, 2548] [1, 3108] [1, 6053] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.368274688720703 with beta sum per layer: [0.11270539462566376, 59.159244537353516, 74.3238754272461]
alpha/beta optimization time: 1.5755670070648193
This batch time : update_bounds func: 1.7280	 prepare: 0.0397	 bound: 1.5759	 transfer: 0.0838	 finalize: 0.0273
Accumulated time: update_bounds func: 211.0512	 prepare: 4.5608	 bound: 192.5240	 transfer: 0.0838	 finalize: 3.9726
batch bounding time:  1.7287304401397705
Current worst splitting domains [lb, ub] (depth):
[-0.06945,   inf] (63), [-0.06944,   inf] (113), [-0.06943,   inf] (109), [-0.06942,   inf] (99), [-0.06942,   inf] (47), [-0.06942,   inf] (61), [-0.06942,   inf] (77), [-0.06942,   inf] (99), [-0.06942,   inf] (105), [-0.06942,   inf] (99), [-0.06942,   inf] (87), [-0.06942,   inf] (93), [-0.06942,   inf] (87), [-0.06942,   inf] (73), [-0.06942,   inf] (65), [-0.06942,   inf] (83), [-0.06942,   inf] (85), [-0.06942,   inf] (59), [-0.06942,   inf] (79), [-0.06942,   inf] (77), 
length of domains: 22988
Total time: 2.1807	 pickout: 0.0734	 decision: 0.3133	 get_bound: 1.7295	 add_domain: 0.0645
Current lb:-0.06945294886827469
47760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 274.8567740917206

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7261] [1, 2548] [1, 5533] [1, 3635] [2, 105] [2, 193] [1, 5357] [1, 3636] [1, 3603] [1, 7262] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.23862075805664 with beta sum per layer: [0.0, 60.75422668457031, 70.01991271972656]
alpha/beta optimization time: 1.5774283409118652
This batch time : update_bounds func: 1.7278	 prepare: 0.0398	 bound: 1.5778	 transfer: 0.0838	 finalize: 0.0252
Accumulated time: update_bounds func: 212.7790	 prepare: 4.6006	 bound: 194.1018	 transfer: 0.0838	 finalize: 3.9978
batch bounding time:  1.728546142578125
Current worst splitting domains [lb, ub] (depth):
[-0.06938,   inf] (93), [-0.06938,   inf] (99), [-0.06938,   inf] (87), [-0.06938,   inf] (67), [-0.06938,   inf] (97), [-0.06938,   inf] (79), [-0.06938,   inf] (79), [-0.06938,   inf] (69), [-0.06938,   inf] (99), [-0.06938,   inf] (101), [-0.06938,   inf] (89), [-0.06938,   inf] (47), [-0.06938,   inf] (71), [-0.06938,   inf] (83), [-0.06938,   inf] (95), [-0.06938,   inf] (101), [-0.06938,   inf] (89), [-0.06938,   inf] (87), [-0.06938,   inf] (85), [-0.06938,   inf] (87), 
length of domains: 23185
Total time: 2.1907	 pickout: 0.0791	 decision: 0.3151	 get_bound: 1.7294	 add_domain: 0.0671
Current lb:-0.0693809986114502
48160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 277.05484557151794

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6106] [1, 7262] [1, 3494] [1, 7651] [1, 667] [1, 2546] [2, 244] [1, 4902] [1, 3636] [1, 3603] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 24.87885284423828 with beta sum per layer: [0.10278739780187607, 58.87590789794922, 83.38642120361328]
alpha/beta optimization time: 1.5709819793701172
This batch time : update_bounds func: 1.7145	 prepare: 0.0399	 bound: 1.5714	 transfer: 0.0761	 finalize: 0.0259
Accumulated time: update_bounds func: 214.4935	 prepare: 4.6405	 bound: 195.6731	 transfer: 0.0761	 finalize: 4.0237
batch bounding time:  1.7152252197265625
Current worst splitting domains [lb, ub] (depth):
[-0.06936,   inf] (119), [-0.06935,   inf] (113), [-0.06935,   inf] (113), [-0.06934,   inf] (69), [-0.06934,   inf] (97), [-0.06934,   inf] (59), [-0.06934,   inf] (101), [-0.06934,   inf] (99), [-0.06934,   inf] (65), [-0.06934,   inf] (71), [-0.06934,   inf] (109), [-0.06934,   inf] (83), [-0.06934,   inf] (103), [-0.06934,   inf] (79), [-0.06934,   inf] (87), [-0.06934,   inf] (105), [-0.06934,   inf] (73), [-0.06934,   inf] (91), [-0.06934,   inf] (77), [-0.06934,   inf] (99), 
length of domains: 23379
Total time: 2.1690	 pickout: 0.0743	 decision: 0.3121	 get_bound: 1.7160	 add_domain: 0.0666
Current lb:-0.06936325132846832
48560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 279.23096084594727

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 422] [1, 2548] [1, 3636] [1, 5087] [1, 6053] [1, 3108] [2, 151] [1, 3635] [1, 7651] [1, 3108] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.11727523803711 with beta sum per layer: [0.0, 59.37615966796875, 72.79478454589844]
alpha/beta optimization time: 1.5714433193206787
This batch time : update_bounds func: 1.7255	 prepare: 0.0422	 bound: 1.5718	 transfer: 0.0838	 finalize: 0.0265
Accumulated time: update_bounds func: 216.2190	 prepare: 4.6827	 bound: 197.2449	 transfer: 0.0838	 finalize: 4.0502
batch bounding time:  1.726222038269043
Current worst splitting domains [lb, ub] (depth):
[-0.06935,   inf] (121), [-0.06930,   inf] (83), [-0.06930,   inf] (105), [-0.06930,   inf] (93), [-0.06930,   inf] (55), [-0.06930,   inf] (61), [-0.06930,   inf] (91), [-0.06930,   inf] (69), [-0.06930,   inf] (99), [-0.06930,   inf] (115), [-0.06930,   inf] (105), [-0.06930,   inf] (97), [-0.06930,   inf] (29), [-0.06930,   inf] (73), [-0.06930,   inf] (67), [-0.06930,   inf] (89), [-0.06930,   inf] (79), [-0.06930,   inf] (73), [-0.06930,   inf] (67), [-0.06930,   inf] (101), 
length of domains: 23572
Total time: 2.1769	 pickout: 0.0712	 decision: 0.3120	 get_bound: 1.7270	 add_domain: 0.0667
Current lb:-0.06934818625450134
48960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 281.41528487205505

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3636] [1, 3110] [2, 151] [1, 6106] [2, 51] [2, 80] [1, 7262] [1, 7651] [1, 6053] [1, 3636] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 24.650066375732422 with beta sum per layer: [0.11059513688087463, 61.152687072753906, 73.19649505615234]
alpha/beta optimization time: 1.571471929550171
This batch time : update_bounds func: 1.7239	 prepare: 0.0399	 bound: 1.5718	 transfer: 0.0834	 finalize: 0.0274
Accumulated time: update_bounds func: 217.9429	 prepare: 4.7226	 bound: 198.8168	 transfer: 0.0834	 finalize: 4.0776
batch bounding time:  1.7245736122131348
Current worst splitting domains [lb, ub] (depth):
[-0.06928,   inf] (109), [-0.06927,   inf] (67), [-0.06927,   inf] (47), [-0.06927,   inf] (91), [-0.06927,   inf] (91), [-0.06927,   inf] (89), [-0.06927,   inf] (81), [-0.06927,   inf] (73), [-0.06927,   inf] (99), [-0.06927,   inf] (93), [-0.06927,   inf] (99), [-0.06927,   inf] (103), [-0.06927,   inf] (83), [-0.06927,   inf] (93), [-0.06927,   inf] (81), [-0.06926,   inf] (103), [-0.06926,   inf] (81), [-0.06926,   inf] (91), [-0.06926,   inf] (73), [-0.06926,   inf] (55), 
length of domains: 23758
Total time: 2.8938	 pickout: 0.0707	 decision: 1.0352	 get_bound: 1.7254	 add_domain: 0.0626
Current lb:-0.06928284466266632
49360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 284.31610560417175

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 4629] [1, 4851] [2, 130] [1, 6106] [1, 5357] [1, 3635] [2, 244] [1, 3620] [1, 3635] [1, 7262] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 24.887123107910156 with beta sum per layer: [0.2041369378566742, 60.10138702392578, 88.62806701660156]
alpha/beta optimization time: 1.5788979530334473
This batch time : update_bounds func: 1.7234	 prepare: 0.0417	 bound: 1.5793	 transfer: 0.0756	 finalize: 0.0256
Accumulated time: update_bounds func: 219.6663	 prepare: 4.7642	 bound: 200.3961	 transfer: 0.0756	 finalize: 4.1032
batch bounding time:  1.7241792678833008
Current worst splitting domains [lb, ub] (depth):
[-0.06925,   inf] (113), [-0.06925,   inf] (115), [-0.06923,   inf] (113), [-0.06923,   inf] (95), [-0.06923,   inf] (77), [-0.06923,   inf] (49), [-0.06923,   inf] (75), [-0.06923,   inf] (75), [-0.06923,   inf] (53), [-0.06923,   inf] (91), [-0.06923,   inf] (101), [-0.06923,   inf] (95), [-0.06923,   inf] (83), [-0.06923,   inf] (89), [-0.06923,   inf] (105), [-0.06922,   inf] (107), [-0.06922,   inf] (79), [-0.06922,   inf] (55), [-0.06922,   inf] (73), [-0.06922,   inf] (103), 
length of domains: 23955
Total time: 2.1791	 pickout: 0.0744	 decision: 0.3136	 get_bound: 1.7250	 add_domain: 0.0661
Current lb:-0.06924974918365479
49760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 286.5027642250061

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6842] [1, 422] [1, 3636] [1, 3635] [1, 2547] [2, 105] [1, 2547] [1, 3108] [1, 422] [1, 5357] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 24.888887405395508 with beta sum per layer: [0.10503687709569931, 60.92997741699219, 64.29820251464844]
alpha/beta optimization time: 1.600114107131958
This batch time : update_bounds func: 1.7450	 prepare: 0.0408	 bound: 1.6005	 transfer: 0.0763	 finalize: 0.0260
Accumulated time: update_bounds func: 221.4113	 prepare: 4.8050	 bound: 201.9966	 transfer: 0.0763	 finalize: 4.1292
batch bounding time:  1.7457401752471924
Current worst splitting domains [lb, ub] (depth):
[-0.06923,   inf] (117), [-0.06921,   inf] (113), [-0.06920,   inf] (83), [-0.06919,   inf] (115), [-0.06919,   inf] (89), [-0.06919,   inf] (81), [-0.06919,   inf] (105), [-0.06919,   inf] (105), [-0.06919,   inf] (97), [-0.06919,   inf] (77), [-0.06919,   inf] (105), [-0.06919,   inf] (75), [-0.06919,   inf] (69), [-0.06919,   inf] (87), [-0.06919,   inf] (113), [-0.06919,   inf] (85), [-0.06919,   inf] (95), [-0.06919,   inf] (87), [-0.06919,   inf] (87), [-0.06919,   inf] (121), 
length of domains: 24146
Total time: 2.2123	 pickout: 0.0804	 decision: 0.3174	 get_bound: 1.7465	 add_domain: 0.0679
Current lb:-0.06923405826091766
50160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 288.722131729126

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6842] [1, 3636] [1, 6106] [1, 3636] [1, 6106] [1, 2546] [2, 151] [2, 151] [1, 6053] [1, 2547] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 24.87601089477539 with beta sum per layer: [0.0, 58.992496490478516, 76.68934631347656]
alpha/beta optimization time: 1.5886616706848145
This batch time : update_bounds func: 1.7431	 prepare: 0.0405	 bound: 1.5891	 transfer: 0.0847	 finalize: 0.0275
Accumulated time: update_bounds func: 223.1545	 prepare: 4.8455	 bound: 203.5856	 transfer: 0.0847	 finalize: 4.1567
batch bounding time:  1.7439045906066895
Current worst splitting domains [lb, ub] (depth):
[-0.06916,   inf] (113), [-0.06916,   inf] (113), [-0.06916,   inf] (83), [-0.06916,   inf] (87), [-0.06916,   inf] (71), [-0.06915,   inf] (97), [-0.06915,   inf] (89), [-0.06915,   inf] (57), [-0.06915,   inf] (99), [-0.06915,   inf] (91), [-0.06915,   inf] (95), [-0.06915,   inf] (83), [-0.06915,   inf] (29), [-0.06915,   inf] (55), [-0.06915,   inf] (63), [-0.06915,   inf] (95), [-0.06915,   inf] (71), [-0.06915,   inf] (63), [-0.06915,   inf] (99), [-0.06915,   inf] (67), 
length of domains: 24336
Total time: 2.1991	 pickout: 0.0662	 decision: 0.3236	 get_bound: 1.7448	 add_domain: 0.0646
Current lb:-0.06916199624538422
50560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 290.9286096096039

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2548] [1, 4629] [1, 3494] [1, 1126] [1, 5357] [1, 6053] [1, 3110] [2, 80] [1, 2548] [1, 6053] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 24.212635040283203 with beta sum per layer: [0.0, 62.034549713134766, 78.24214935302734]
alpha/beta optimization time: 1.5809886455535889
This batch time : update_bounds func: 1.7349	 prepare: 0.0401	 bound: 1.5814	 transfer: 0.0847	 finalize: 0.0273
Accumulated time: update_bounds func: 224.8893	 prepare: 4.8856	 bound: 205.1670	 transfer: 0.0847	 finalize: 4.1841
batch bounding time:  1.7355470657348633
Current worst splitting domains [lb, ub] (depth):
[-0.06912,   inf] (81), [-0.06912,   inf] (109), [-0.06912,   inf] (95), [-0.06912,   inf] (97), [-0.06912,   inf] (71), [-0.06912,   inf] (87), [-0.06912,   inf] (83), [-0.06912,   inf] (109), [-0.06912,   inf] (49), [-0.06912,   inf] (59), [-0.06912,   inf] (93), [-0.06912,   inf] (65), [-0.06912,   inf] (83)/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:25: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1627336316785/work/torch/csrc/utils/tensor_numpy.cpp:143.)
  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))
, [-0.06912,   inf] (65), [-0.06912,   inf] (49), [-0.06912,   inf] (99), [-0.06912,   inf] (91), [-0.06912,   inf] (71), [-0.06912,   inf] (61), [-0.06912,   inf] (77), 
length of domains: 24520
Total time: 2.1857	 pickout: 0.0687	 decision: 0.3167	 get_bound: 1.7363	 add_domain: 0.0640
Current lb:-0.06912407279014587
50960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 293.1222231388092

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2546] [1, 6053] [1, 3635] [1, 668] [1, 4902] [1, 3603] [1, 3620] [1, 6842] [2, 105] [2, 80] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.122711181640625 with beta sum per layer: [0.0, 52.162353515625, 76.97430419921875]
alpha/beta optimization time: 1.5726184844970703
This batch time : update_bounds func: 1.7207	 prepare: 0.0401	 bound: 1.5730	 transfer: 0.0807	 finalize: 0.0256
Accumulated time: update_bounds func: 226.6100	 prepare: 4.9257	 bound: 206.7400	 transfer: 0.0807	 finalize: 4.2097
batch bounding time:  1.721452236175537
Current worst splitting domains [lb, ub] (depth):
[-0.06908,   inf] (95), [-0.06908,   inf] (79), [-0.06908,   inf] (67), [-0.06908,   inf] (71), [-0.06908,   inf] (69), [-0.06908,   inf] (103), [-0.06908,   inf] (99), [-0.06908,   inf] (89), [-0.06908,   inf] (77), [-0.06908,   inf] (97), [-0.06908,   inf] (91), [-0.06908,   inf] (95), [-0.06908,   inf] (75), [-0.06908,   inf] (91), [-0.06908,   inf] (51), [-0.06908,   inf] (83), [-0.06908,   inf] (89), [-0.06908,   inf] (57), [-0.06908,   inf] (89), [-0.06908,   inf] (91), 
length of domains: 24714
Total time: 2.1686	 pickout: 0.0644	 decision: 0.3152	 get_bound: 1.7223	 add_domain: 0.0668
Current lb:-0.06908309459686279
51360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 295.2979383468628

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2548] [1, 668] [1, 7268] [1, 7268] [1, 7651] [1, 3603] [1, 7262] [1, 7650] [1, 2547] [1, 667] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.273277282714844 with beta sum per layer: [0.0, 59.752750396728516, 66.46904754638672]
alpha/beta optimization time: 1.5731534957885742
This batch time : update_bounds func: 1.7265	 prepare: 0.0403	 bound: 1.5735	 transfer: 0.0851	 finalize: 0.0263
Accumulated time: update_bounds func: 228.3365	 prepare: 4.9660	 bound: 208.3135	 transfer: 0.0851	 finalize: 4.2359
batch bounding time:  1.7272212505340576
Current worst splitting domains [lb, ub] (depth):
[-0.06905,   inf] (97), [-0.06905,   inf] (81), [-0.06905,   inf] (77), [-0.06905,   inf] (45), [-0.06905,   inf] (75), [-0.06905,   inf] (83), [-0.06904,   inf] (101), [-0.06904,   inf] (87), [-0.06904,   inf] (91), [-0.06904,   inf] (93), [-0.06904,   inf] (97), [-0.06904,   inf] (77), [-0.06904,   inf] (91), [-0.06904,   inf] (69), [-0.06904,   inf] (87), [-0.06904,   inf] (47), [-0.06904,   inf] (83), [-0.06904,   inf] (77), [-0.06904,   inf] (93), [-0.06904,   inf] (81), 
length of domains: 24908
Total time: 2.1780	 pickout: 0.0685	 decision: 0.3144	 get_bound: 1.7280	 add_domain: 0.0671
Current lb:-0.06905298680067062
51760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 297.4834156036377

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6053] [1, 2546] [1, 2549] [2, 130] [2, 244] [1, 3110] [1, 7262] [1, 3110] [1, 6106] [1, 2548] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 25.216510772705078 with beta sum per layer: [0.0, 66.67558288574219, 67.61587524414062]
alpha/beta optimization time: 1.5693769454956055
This batch time : update_bounds func: 1.7228	 prepare: 0.0400	 bound: 1.5698	 transfer: 0.0846	 finalize: 0.0271
Accumulated time: update_bounds func: 230.0593	 prepare: 5.0060	 bound: 209.8833	 transfer: 0.0846	 finalize: 4.2631
batch bounding time:  1.7235047817230225
Current worst splitting domains [lb, ub] (depth):
[-0.06901,   inf] (109), [-0.06901,   inf] (83), [-0.06901,   inf] (81), [-0.06901,   inf] (117), [-0.06901,   inf] (81), [-0.06901,   inf] (75), [-0.06901,   inf] (93), [-0.06901,   inf] (51), [-0.06901,   inf] (93), [-0.06901,   inf] (77), [-0.06901,   inf] (87), [-0.06901,   inf] (103), [-0.06901,   inf] (103), [-0.06901,   inf] (97), [-0.06901,   inf] (101), [-0.06901,   inf] (39), [-0.06901,   inf] (63), [-0.06901,   inf] (97), [-0.06901,   inf] (105), [-0.06901,   inf] (113), 
length of domains: 25104
Total time: 2.9277	 pickout: 0.0734	 decision: 1.0662	 get_bound: 1.7243	 add_domain: 0.0638
Current lb:-0.0690121278166771
52160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Time out!!!!!!!!
Image 0 against label 1 verification end, Time cost: 301.1177020072937
Result: unknown in 314.2269 seconds


[[    0.             0.67290306     0.             0.00032425
      0.        ]
 [    0.            -0.06901213 52160.           301.11770201
      1.        ]]
############# Summary #############
Final verified acc: 0.0% [total 1 examples]
Total verification count: 1 , total verified safe: 0 , verified unsafe: 0 , timeout: 1
mean time [total:1]: 301.1180262565613
mean time [cnt:1]: 301.1180262565613
max time 314.22686672210693
unknown (total 1): [0]
