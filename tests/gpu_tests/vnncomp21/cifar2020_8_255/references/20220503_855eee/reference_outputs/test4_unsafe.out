Building native CUDA modules...
/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
  csv_name: cifar2020_instances.csv
  onnx_path: null
  vnnlib_path: null
  results_file: null
  root_path: ../../../../../vnncomp2021/benchmarks/cifar2020
model:
  path: null
  name: mnist_9_200
data:
  start: 84
  end: 85
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR
  data_filter_path: null
specification:
  type: lp
  norm: .inf
  epsilon: null
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 200
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.01
    lr_decay: 0.98
    optimizer: adam
    iteration: 50
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 360
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 10
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:11:32 2022 on ubuntu
saving results to vnn-comp_[cifar2020_instances]_start=84_end=85_iter=50_b=200_timeout=360_branching=kfsb-max-10_lra-init=0.1_lra=0.01_lrb=0.01_PGD=skip.npz
customized start/end sample from 84 to 85

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Model prediction is: tensor([[-1.1870, -1.9637,  0.9364,  0.8253,  1.3488,  0.7688,  1.6074,  0.1347,
         -1.4134, -2.2176]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 0.8903,  0.6462, -0.1247, -0.2174, -0.5931, -0.3933, -0.2175,  0.1378,
          1.5990]], device='cuda:0') None
best_l after optimization: -3.4514567852020264 with beta sum per layer: []
alpha/beta optimization time: 7.983880996704102
initial alpha-CROWN bounds: tensor([[ 1.1261,  0.9133, -0.0186, -0.1048, -0.4745, -0.2509,  0.0087,  0.4305,
          1.8215]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.4745, device='cuda:0', grad_fn=<MinBackward1>)
##### [0] True label: 6, Tested against: 0, onnx_path: nets/cifar10_8_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_4_eps_0.03137_n1.vnnlib ######
init opt crown verified for label 0 with bound 1.1261144876480103
Image 0 against label 0 verification end, Time cost: 0.0003228187561035156
##### [0] True label: 6, Tested against: 1, onnx_path: nets/cifar10_8_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_4_eps_0.03137_n1.vnnlib ######
init opt crown verified for label 1 with bound 0.913333535194397
Image 0 against label 1 verification end, Time cost: 0.0003314018249511719
##### [0] True label: 6, Tested against: 2, onnx_path: nets/cifar10_8_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_4_eps_0.03137_n1.vnnlib ######
Model prediction is: tensor([[-1.1870, -1.9637,  0.9364,  0.8253,  1.3488,  0.7688,  1.6074,  0.1347,
         -1.4134, -2.2176]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /9 torch.Size([1, 32, 16, 16])
1 /11 torch.Size([1, 128, 8, 8])
2 /14 torch.Size([1, 250])
best_l after optimization: 0.018533766269683838 with beta sum per layer: []
alpha/beta optimization time: 1.8432118892669678
alpha-CROWN with fixed intermediate bounds: tensor([[-0.0185]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.018533766269683838
layer 0 size torch.Size([8192]) unstable 300
layer 1 size torch.Size([8192]) unstable 945
layer 2 size torch.Size([250]) unstable 120
-----------------
# of unstable neurons: 1365
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 214] 
split level 1: [2, 34] 
split level 2: [2, 21] 
split level 3: [2, 229] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -1.2271168231964111 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.008977651596069336
This batch time : update_bounds func: 0.0160	 prepare: 0.0035	 bound: 0.0094	 transfer: 0.0019	 finalize: 0.0011
Accumulated time: update_bounds func: 0.0160	 prepare: 0.0035	 bound: 0.0094	 transfer: 0.0019	 finalize: 0.0011
batch bounding time:  0.01611018180847168
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0708	 pickout: 0.0010	 decision: 0.0517	 get_bound: 0.0180	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 2.8478710651397705

Image 0 against label 2 verification end, Time cost: 2.9139022827148438
##### [0] True label: 6, Tested against: 3, onnx_path: nets/cifar10_8_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_4_eps_0.03137_n1.vnnlib ######
Model prediction is: tensor([[-1.1870, -1.9637,  0.9364,  0.8253,  1.3488,  0.7688,  1.6074,  0.1347,
         -1.4134, -2.2176]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /9 torch.Size([1, 32, 16, 16])
1 /11 torch.Size([1, 128, 8, 8])
2 /14 torch.Size([1, 250])
best_l after optimization: 0.10472685098648071 with beta sum per layer: []
alpha/beta optimization time: 0.8574786186218262
alpha-CROWN with fixed intermediate bounds: tensor([[-0.1047]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.10472685098648071
layer 0 size torch.Size([8192]) unstable 300
layer 1 size torch.Size([8192]) unstable 945
layer 2 size torch.Size([250]) unstable 120
-----------------
# of unstable neurons: 1365
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 87] 
split level 1: [2, 58] 
split level 2: [2, 196] 
split level 3: [2, 171] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.07279348373413086 with beta sum per layer: [0.0, 0.0, 2.092499256134033]
alpha/beta optimization time: 0.5424442291259766
This batch time : update_bounds func: 0.5484	 prepare: 0.0027	 bound: 0.5429	 transfer: 0.0014	 finalize: 0.0012
Accumulated time: update_bounds func: 0.5645	 prepare: 0.0062	 bound: 0.5524	 transfer: 0.0014	 finalize: 0.0024
batch bounding time:  0.5486729145050049
Current worst splitting domains [lb, ub] (depth):
[-0.04401,   inf] (5), [-0.03559,   inf] (5), [-0.03364,   inf] (5), [-0.01496,   inf] (5), [-0.01190,   inf] (5), [-0.00676,   inf] (5), [-0.00049,   inf] (5), 
length of domains: 7
Total time: 0.6014	 pickout: 0.0008	 decision: 0.0497	 get_bound: 0.5505	 add_domain: 0.0004
Current lb:-0.04401451349258423
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.479363203048706

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([7, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([7, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 214] [2, 214] [2, 214] [2, 214] [2, 214] [2, 214] [2, 214] 
regular batch size: 2*7, diving batch size 1*0
best_l after optimization: -0.05323917418718338 with beta sum per layer: [0.0, 0.0, 4.1634063720703125]
alpha/beta optimization time: 0.6295051574707031
This batch time : update_bounds func: 0.6362	 prepare: 0.0033	 bound: 0.6299	 transfer: 0.0017	 finalize: 0.0013
Accumulated time: update_bounds func: 1.2007	 prepare: 0.0095	 bound: 1.1823	 transfer: 0.0017	 finalize: 0.0037
batch bounding time:  0.6363952159881592
Current worst splitting domains [lb, ub] (depth):
[-0.03317,   inf] (7), [-0.02395,   inf] (7), [-0.02209,   inf] (7), [-0.00068,   inf] (7), 
length of domains: 4
Total time: 0.7043	 pickout: 0.0028	 decision: 0.0648	 get_bound: 0.6364	 add_domain: 0.0003
Current lb:-0.03317089378833771
30 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.1839284896850586

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 32, 16, 16]) pre split depth:  2
batch:  torch.Size([4, 32, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [2, 117] [2, 117] [2, 96] [2, 96] 
split level 1: [2, 96] [2, 96] [2, 117] [2, 117] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.41778236627578735 with beta sum per layer: [0.0, 0.0, 4.729360103607178]
alpha/beta optimization time: 0.6304166316986084
This batch time : update_bounds func: 0.6377	 prepare: 0.0035	 bound: 0.6307	 transfer: 0.0019	 finalize: 0.0015
Accumulated time: update_bounds func: 1.8384	 prepare: 0.0130	 bound: 1.8131	 transfer: 0.0019	 finalize: 0.0052
batch bounding time:  0.6378879547119141
Current worst splitting domains [lb, ub] (depth):
[-0.01056,   inf] (10), 
length of domains: 1
Total time: 0.7039	 pickout: 0.0019	 decision: 0.0622	 get_bound: 0.6397	 add_domain: 0.0001
Current lb:-0.01055868063122034
46 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.888103723526001

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 139] 
split level 1: [2, 95] 
split level 2: [2, 12] 
split level 3: [2, 229] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -1.298037052154541 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.009322404861450195
This batch time : update_bounds func: 0.0166	 prepare: 0.0035	 bound: 0.0096	 transfer: 0.0019	 finalize: 0.0015
Accumulated time: update_bounds func: 1.8551	 prepare: 0.0165	 bound: 1.8227	 transfer: 0.0019	 finalize: 0.0067
batch bounding time:  0.01669931411743164
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0812	 pickout: 0.0011	 decision: 0.0606	 get_bound: 0.0195	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 2.969555377960205

Image 0 against label 3 verification end, Time cost: 3.0322957038879395
##### [0] True label: 6, Tested against: 4, onnx_path: nets/cifar10_8_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_4_eps_0.03137_n1.vnnlib ######
Model prediction is: tensor([[-1.1870, -1.9637,  0.9364,  0.8253,  1.3488,  0.7688,  1.6074,  0.1347,
         -1.4134, -2.2176]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /9 torch.Size([1, 32, 16, 16])
1 /11 torch.Size([1, 128, 8, 8])
2 /14 torch.Size([1, 250])
best_l after optimization: 0.4744327664375305 with beta sum per layer: []
alpha/beta optimization time: 1.047314167022705
alpha-CROWN with fixed intermediate bounds: tensor([[-0.4744]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.4744327664375305
layer 0 size torch.Size([8192]) unstable 300
layer 1 size torch.Size([8192]) unstable 945
layer 2 size torch.Size([250]) unstable 120
-----------------
# of unstable neurons: 1365
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 58] 
split level 1: [2, 87] 
split level 2: [2, 73] 
split level 3: [2, 28] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 4.602119445800781 with beta sum per layer: [0.0, 0.0, 6.732370376586914]
alpha/beta optimization time: 0.5602197647094727
This batch time : update_bounds func: 0.5678	 prepare: 0.0027	 bound: 0.5607	 transfer: 0.0033	 finalize: 0.0010
Accumulated time: update_bounds func: 2.4229	 prepare: 0.0192	 bound: 2.3834	 transfer: 0.0033	 finalize: 0.0078
batch bounding time:  0.5680022239685059
Current worst splitting domains [lb, ub] (depth):
[-0.42047,   inf] (5), [-0.37670,   inf] (5), [-0.35462,   inf] (5), [-0.34602,   inf] (5), [-0.31253,   inf] (5), [-0.30238,   inf] (5), [-0.30067,   inf] (5), [-0.29051,   inf] (5), [-0.26315,   inf] (5), [-0.25950,   inf] (5), [-0.25801,   inf] (5), [-0.24745,   inf] (5), [-0.22842,   inf] (5), [-0.22813,   inf] (5), [-0.21889,   inf] (5), [-0.19465,   inf] (5), 
length of domains: 16
Total time: 0.6207	 pickout: 0.0008	 decision: 0.0493	 get_bound: 0.5698	 add_domain: 0.0008
Current lb:-0.4204723536968231
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.6908280849456787

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([16, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([16, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 244] [2, 244] [2, 12] [2, 12] [2, 21] [2, 12] [2, 244] [2, 12] [2, 12] [2, 244] 
regular batch size: 2*16, diving batch size 1*0
best_l after optimization: 8.001605033874512 with beta sum per layer: [0.0, 0.0, 25.839126586914062]
alpha/beta optimization time: 0.5619692802429199
This batch time : update_bounds func: 0.5740	 prepare: 0.0037	 bound: 0.5623	 transfer: 0.0060	 finalize: 0.0019
Accumulated time: update_bounds func: 2.9968	 prepare: 0.0229	 bound: 2.9457	 transfer: 0.0060	 finalize: 0.0097
batch bounding time:  0.5741786956787109
Current worst splitting domains [lb, ub] (depth):
[-0.40648,   inf] (7), [-0.37684,   inf] (7), [-0.35347,   inf] (7), [-0.33470,   inf] (7), [-0.33285,   inf] (7), [-0.32755,   inf] (7), [-0.31653,   inf] (7), [-0.30065,   inf] (7), [-0.28667,   inf] (7), [-0.27844,   inf] (7), [-0.27225,   inf] (7), [-0.26312,   inf] (7), [-0.25856,   inf] (7), [-0.25793,   inf] (7), [-0.25218,   inf] (7), [-0.24491,   inf] (7), [-0.23454,   inf] (7), [-0.22442,   inf] (7), [-0.22201,   inf] (7), [-0.21605,   inf] (7), 
length of domains: 32
Total time: 0.6403	 pickout: 0.0049	 decision: 0.0598	 get_bound: 0.5742	 add_domain: 0.0014
Current lb:-0.4064849615097046
48 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.3314974308013916

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([32, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([32, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 21] [2, 12] [2, 21] [2, 21] [2, 244] [2, 21] [2, 21] [2, 244] [2, 244] [2, 21] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: 13.998106956481934 with beta sum per layer: [0.0, 0.0, 74.66368865966797]
alpha/beta optimization time: 0.6011896133422852
This batch time : update_bounds func: 0.6233	 prepare: 0.0060	 bound: 0.6015	 transfer: 0.0120	 finalize: 0.0037
Accumulated time: update_bounds func: 3.6201	 prepare: 0.0289	 bound: 3.5471	 transfer: 0.0120	 finalize: 0.0134
batch bounding time:  0.6234819889068604
Current worst splitting domains [lb, ub] (depth):
[-0.39728,   inf] (9), [-0.36216,   inf] (9), [-0.35337,   inf] (9), [-0.33939,   inf] (9), [-0.33009,   inf] (9), [-0.31849,   inf] (9), [-0.31818,   inf] (9), [-0.31053,   inf] (9), [-0.29855,   inf] (9), [-0.29603,   inf] (9), [-0.29298,   inf] (9), [-0.29243,   inf] (9), [-0.28190,   inf] (9), [-0.27555,   inf] (9), [-0.26946,   inf] (9), [-0.26564,   inf] (9), [-0.26174,   inf] (9), [-0.25580,   inf] (9), [-0.25565,   inf] (9), [-0.24878,   inf] (9), 
length of domains: 64
Total time: 0.7098	 pickout: 0.0076	 decision: 0.0759	 get_bound: 0.6236	 add_domain: 0.0026
Current lb:-0.3972756564617157
112 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.0418264865875244

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([64, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 96] [2, 96] [2, 96] [2, 96] [2, 96] [2, 96] [2, 96] [2, 96] [2, 96] [2, 96] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 23.535030364990234 with beta sum per layer: [0.0, 0.0, 193.89840698242188]
alpha/beta optimization time: 0.7293877601623535
This batch time : update_bounds func: 0.7760	 prepare: 0.0108	 bound: 0.7297	 transfer: 0.0281	 finalize: 0.0071
Accumulated time: update_bounds func: 4.3961	 prepare: 0.0396	 bound: 4.2768	 transfer: 0.0281	 finalize: 0.0205
batch bounding time:  0.7762510776519775
Current worst splitting domains [lb, ub] (depth):
[-0.38821,   inf] (11), [-0.35277,   inf] (11), [-0.34017,   inf] (11), [-0.33465,   inf] (11), [-0.32706,   inf] (11), [-0.31450,   inf] (11), [-0.31024,   inf] (11), [-0.30885,   inf] (11), [-0.29937,   inf] (11), [-0.29215,   inf] (11), [-0.29078,   inf] (11), [-0.28813,   inf] (11), [-0.28735,   inf] (11), [-0.28317,   inf] (11), [-0.28283,   inf] (11), [-0.27459,   inf] (11), [-0.27153,   inf] (11), [-0.26147,   inf] (11), [-0.26005,   inf] (11), [-0.25845,   inf] (11), 
length of domains: 128
Total time: 0.9223	 pickout: 0.0145	 decision: 0.1256	 get_bound: 0.7765	 add_domain: 0.0058
Current lb:-0.388208270072937
240 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.9652063846588135

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([128, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([128, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 12] [2, 21] [2, 12] [2, 12] [2, 101] [2, 21] [2, 21] [2, 244] [2, 12] [2, 21] 
regular batch size: 2*128, diving batch size 1*0
best_l after optimization: 39.29134750366211 with beta sum per layer: [0.0, 0.0, 479.863037109375]
alpha/beta optimization time: 1.1474812030792236
This batch time : update_bounds func: 1.2352	 prepare: 0.0233	 bound: 1.1478	 transfer: 0.0492	 finalize: 0.0143
Accumulated time: update_bounds func: 5.6313	 prepare: 0.0629	 bound: 5.4246	 transfer: 0.0492	 finalize: 0.0347
batch bounding time:  1.2355983257293701
Current worst splitting domains [lb, ub] (depth):
[-0.37668,   inf] (13), [-0.34635,   inf] (13), [-0.34005,   inf] (13), [-0.32144,   inf] (13), [-0.31855,   inf] (13), [-0.31430,   inf] (13), [-0.31278,   inf] (13), [-0.29903,   inf] (13), [-0.29873,   inf] (13), [-0.29251,   inf] (13), [-0.28890,   inf] (13), [-0.28588,   inf] (13), [-0.28557,   inf] (13), [-0.28066,   inf] (13), [-0.27632,   inf] (13), [-0.27510,   inf] (13), [-0.27166,   inf] (13), [-0.27094,   inf] (13), [-0.26829,   inf] (13), [-0.26677,   inf] (13), 
length of domains: 249
Total time: 1.4849	 pickout: 0.0293	 decision: 0.2084	 get_bound: 1.2360	 add_domain: 0.0112
Current lb:-0.3766779899597168
496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.452873706817627

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 101] [2, 101] [2, 229] [2, 101] [2, 12] [2, 101] [2, 101] [2, 101] [2, 229] [2, 229] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 61.666282653808594 with beta sum per layer: [0.0, 0.0, 783.501953125]
alpha/beta optimization time: 1.6218950748443604
This batch time : update_bounds func: 1.7589	 prepare: 0.0314	 bound: 1.6222	 transfer: 0.0825	 finalize: 0.0219
Accumulated time: update_bounds func: 7.3902	 prepare: 0.0943	 bound: 7.0468	 transfer: 0.0825	 finalize: 0.0566
batch bounding time:  1.7595338821411133
Current worst splitting domains [lb, ub] (depth):
[-0.36842,   inf] (15), [-0.32984,   inf] (15), [-0.32837,   inf] (15), [-0.32800,   inf] (15), [-0.30955,   inf] (15), [-0.30501,   inf] (15), [-0.30486,   inf] (15), [-0.29648,   inf] (15), [-0.29629,   inf] (15), [-0.29370,   inf] (15), [-0.28890,   inf] (15), [-0.28669,   inf] (15), [-0.28438,   inf] (15), [-0.28264,   inf] (15), [-0.28190,   inf] (15), [-0.27688,   inf] (15), [-0.26900,   inf] (15), [-0.26739,   inf] (15), [-0.26688,   inf] (15), [-0.26537,   inf] (15), 
length of domains: 449
Total time: 2.1940	 pickout: 0.0463	 decision: 0.3670	 get_bound: 1.7602	 add_domain: 0.0205
Current lb:-0.3684239089488983
896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.650026559829712

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 163] [2, 163] [2, 163] [2, 163] [2, 163] [2, 163] [2, 163] [2, 163] [2, 163] [2, 163] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 65.43199157714844 with beta sum per layer: [0.0, 0.0, 772.0908203125]
alpha/beta optimization time: 1.6175591945648193
This batch time : update_bounds func: 1.7537	 prepare: 0.0340	 bound: 1.6179	 transfer: 0.0782	 finalize: 0.0226
Accumulated time: update_bounds func: 9.1439	 prepare: 0.1283	 bound: 8.6647	 transfer: 0.0782	 finalize: 0.0792
batch bounding time:  1.7543437480926514
Current worst splitting domains [lb, ub] (depth):
[-0.36064,   inf] (17), [-0.32200,   inf] (17), [-0.31740,   inf] (17), [-0.30999,   inf] (17), [-0.30340,   inf] (17), [-0.30203,   inf] (17), [-0.29604,   inf] (17), [-0.29346,   inf] (17), [-0.28855,   inf] (17), [-0.28523,   inf] (17), [-0.28328,   inf] (17), [-0.27880,   inf] (17), [-0.27725,   inf] (17), [-0.27548,   inf] (17), [-0.27398,   inf] (17), [-0.27181,   inf] (17), [-0.27075,   inf] (17), [-0.26968,   inf] (17), [-0.25947,   inf] (17), [-0.25699,   inf] (17), 
length of domains: 649
Total time: 2.2260	 pickout: 0.0752	 decision: 0.3736	 get_bound: 1.7551	 add_domain: 0.0221
Current lb:-0.3606392443180084
1296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.879318475723267

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 117] [2, 117] [2, 117] [2, 117] [2, 7] [2, 229] [2, 117] [2, 101] [2, 117] [2, 117] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 70.23876190185547 with beta sum per layer: [0.0, 0.0, 787.4234619140625]
alpha/beta optimization time: 1.5993692874908447
This batch time : update_bounds func: 1.7394	 prepare: 0.0314	 bound: 1.5997	 transfer: 0.0849	 finalize: 0.0225
Accumulated time: update_bounds func: 10.8833	 prepare: 0.1597	 bound: 10.2644	 transfer: 0.0849	 finalize: 0.1017
batch bounding time:  1.7399258613586426
Current worst splitting domains [lb, ub] (depth):
[-0.35394,   inf] (19), [-0.31491,   inf] (19), [-0.30969,   inf] (19), [-0.30691,   inf] (19), [-0.29799,   inf] (19), [-0.28914,   inf] (19), [-0.28744,   inf] (19), [-0.28058,   inf] (19), [-0.28034,   inf] (19), [-0.27934,   inf] (19), [-0.27809,   inf] (19), [-0.27697,   inf] (19), [-0.27621,   inf] (19), [-0.27515,   inf] (19), [-0.26956,   inf] (19), [-0.26939,   inf] (19), [-0.26778,   inf] (19), [-0.26762,   inf] (19), [-0.26679,   inf] (19), [-0.26303,   inf] (19), 
length of domains: 849
Total time: 2.1112	 pickout: 0.0562	 decision: 0.2921	 get_bound: 1.7406	 add_domain: 0.0222
Current lb:-0.35393697023391724
1696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.993806838989258

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 234] [2, 234] [2, 234] [2, 234] [2, 234] [2, 234] [2, 234] [2, 234] [2, 234] [2, 234] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 70.25867462158203 with beta sum per layer: [0.0, 0.0, 751.7490234375]
alpha/beta optimization time: 1.6048049926757812
This batch time : update_bounds func: 1.7474	 prepare: 0.0315	 bound: 1.6051	 transfer: 0.0864	 finalize: 0.0234
Accumulated time: update_bounds func: 12.6307	 prepare: 0.1912	 bound: 11.8695	 transfer: 0.0864	 finalize: 0.1251
batch bounding time:  1.747969150543213
Current worst splitting domains [lb, ub] (depth):
[-0.34698,   inf] (21), [-0.30781,   inf] (21), [-0.30321,   inf] (21), [-0.29053,   inf] (21), [-0.28491,   inf] (21), [-0.28182,   inf] (21), [-0.28097,   inf] (21), [-0.27890,   inf] (21), [-0.27193,   inf] (21), [-0.27172,   inf] (21), [-0.27129,   inf] (21), [-0.27038,   inf] (21), [-0.26890,   inf] (21), [-0.26276,   inf] (21), [-0.26237,   inf] (21), [-0.26136,   inf] (21), [-0.26064,   inf] (21), [-0.25964,   inf] (21), [-0.25500,   inf] (21), [-0.25367,   inf] (21), 
length of domains: 1049
Total time: 2.1690	 pickout: 0.0476	 decision: 0.3490	 get_bound: 1.7486	 add_domain: 0.0237
Current lb:-0.34697625041007996
2096 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.166237831115723

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 229] [2, 101] [2, 229] [2, 229] [2, 229] [2, 229] [2, 229] [2, 117] [2, 117] [2, 229] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 71.89322662353516 with beta sum per layer: [0.0, 0.0, 754.548583984375]
alpha/beta optimization time: 1.6312594413757324
This batch time : update_bounds func: 1.7759	 prepare: 0.0324	 bound: 1.6316	 transfer: 0.0875	 finalize: 0.0234
Accumulated time: update_bounds func: 14.4066	 prepare: 0.2237	 bound: 13.5011	 transfer: 0.0875	 finalize: 0.1485
batch bounding time:  1.7766072750091553
Current worst splitting domains [lb, ub] (depth):
[-0.33703,   inf] (23), [-0.30649,   inf] (23), [-0.29872,   inf] (23), [-0.29182,   inf] (23), [-0.27759,   inf] (23), [-0.27194,   inf] (23), [-0.26952,   inf] (23), [-0.26643,   inf] (23), [-0.26472,   inf] (23), [-0.26331,   inf] (23), [-0.26237,   inf] (23), [-0.26228,   inf] (23), [-0.25936,   inf] (23), [-0.25819,   inf] (23), [-0.25676,   inf] (23), [-0.25666,   inf] (23), [-0.25274,   inf] (23), [-0.25138,   inf] (23), [-0.25035,   inf] (23), [-0.24762,   inf] (23), 
length of domains: 1249
Total time: 2.2205	 pickout: 0.0576	 decision: 0.3580	 get_bound: 1.7774	 add_domain: 0.0275
Current lb:-0.3370293378829956
2496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.391170263290405

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 7] [2, 7] [2, 7] [2, 7] [2, 7] [2, 7] [2, 7] [2, 7] [2, 7] [2, 7] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 72.4477767944336 with beta sum per layer: [0.0, 0.0, 748.1064453125]
alpha/beta optimization time: 1.6162185668945312
This batch time : update_bounds func: 1.7554	 prepare: 0.0319	 bound: 1.6165	 transfer: 0.0832	 finalize: 0.0228
Accumulated time: update_bounds func: 16.1620	 prepare: 0.2556	 bound: 15.1176	 transfer: 0.0832	 finalize: 0.1713
batch bounding time:  1.7560162544250488
Current worst splitting domains [lb, ub] (depth):
[-0.32433,   inf] (25), [-0.30418,   inf] (25), [-0.28634,   inf] (25), [-0.28476,   inf] (25), [-0.27933,   inf] (25), [-0.27371,   inf] (25), [-0.26460,   inf] (25), [-0.26067,   inf] (25), [-0.25896,   inf] (25), [-0.25869,   inf] (25), [-0.25709,   inf] (25), [-0.25192,   inf] (25), [-0.25189,   inf] (25), [-0.25104,   inf] (25), [-0.25040,   inf] (25), [-0.24877,   inf] (25), [-0.24744,   inf] (25), [-0.24656,   inf] (25), [-0.24324,   inf] (25), [-0.24317,   inf] (25), 
length of domains: 1449
Total time: 2.2132	 pickout: 0.0493	 decision: 0.2970	 get_bound: 1.7567	 add_domain: 0.1102
Current lb:-0.32433202862739563
2896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.60776114463806

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 34] [2, 34] [2, 34] [2, 34] [2, 34] [2, 131] [2, 34] [2, 34] [2, 131] [2, 131] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 72.08734130859375 with beta sum per layer: [0.0, 0.0, 724.844970703125]
alpha/beta optimization time: 1.6088573932647705
This batch time : update_bounds func: 1.7540	 prepare: 0.0358	 bound: 1.6092	 transfer: 0.0848	 finalize: 0.0232
Accumulated time: update_bounds func: 17.9161	 prepare: 0.2914	 bound: 16.7268	 transfer: 0.0848	 finalize: 0.1944
batch bounding time:  1.7546143531799316
Current worst splitting domains [lb, ub] (depth):
[-0.30944,   inf] (27), [-0.29417,   inf] (27), [-0.28698,   inf] (27), [-0.27360,   inf] (27), [-0.27035,   inf] (27), [-0.26653,   inf] (27), [-0.26270,   inf] (27), [-0.26259,   inf] (27), [-0.25407,   inf] (27), [-0.25335,   inf] (27), [-0.25169,   inf] (27), [-0.25007,   inf] (27), [-0.24871,   inf] (27), [-0.24540,   inf] (27), [-0.24235,   inf] (27), [-0.23931,   inf] (27), [-0.23592,   inf] (27), [-0.23579,   inf] (27), [-0.23556,   inf] (27), [-0.23533,   inf] (27), 
length of domains: 1649
Total time: 2.1279	 pickout: 0.0486	 decision: 0.2963	 get_bound: 1.7553	 add_domain: 0.0277
Current lb:-0.3094416856765747
3296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 20.739493370056152

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 131] [2, 131] [2, 131] [2, 131] [2, 131] [2, 131] [2, 34] [2, 131] [2, 131] [2, 131] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 71.23910522460938 with beta sum per layer: [0.0, 0.0, 706.1226806640625]
alpha/beta optimization time: 1.6077122688293457
This batch time : update_bounds func: 1.7513	 prepare: 0.0320	 bound: 1.6080	 transfer: 0.0870	 finalize: 0.0233
Accumulated time: update_bounds func: 19.6673	 prepare: 0.3234	 bound: 18.3348	 transfer: 0.0870	 finalize: 0.2177
batch bounding time:  1.751837968826294
Current worst splitting domains [lb, ub] (depth):
[-0.29905,   inf] (29), [-0.28250,   inf] (29), [-0.27543,   inf] (29), [-0.27270,   inf] (29), [-0.26193,   inf] (29), [-0.26018,   inf] (29), [-0.25397,   inf] (29), [-0.25114,   inf] (29), [-0.24895,   inf] (29), [-0.24732,   inf] (29), [-0.24675,   inf] (29), [-0.24152,   inf] (29), [-0.24082,   inf] (29), [-0.23953,   inf] (29), [-0.23685,   inf] (29), [-0.23494,   inf] (29), [-0.23412,   inf] (29), [-0.23289,   inf] (29), [-0.23057,   inf] (29), [-0.23048,   inf] (29), 
length of domains: 1849
Total time: 2.2133	 pickout: 0.0600	 decision: 0.3718	 get_bound: 1.7525	 add_domain: 0.0290
Current lb:-0.2990468442440033
3696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 22.95673680305481

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 128] [2, 50] [2, 128] [2, 139] [2, 50] [2, 128] [2, 50] [2, 139] [2, 128] [2, 50] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 69.33451843261719 with beta sum per layer: [0.0, 0.0, 696.493408203125]
alpha/beta optimization time: 1.6052119731903076
This batch time : update_bounds func: 1.7424	 prepare: 0.0360	 bound: 1.6056	 transfer: 0.0767	 finalize: 0.0231
Accumulated time: update_bounds func: 21.4097	 prepare: 0.3594	 bound: 19.9404	 transfer: 0.0767	 finalize: 0.2408
batch bounding time:  1.7429933547973633
Current worst splitting domains [lb, ub] (depth):
[-0.28229,   inf] (31), [-0.27697,   inf] (31), [-0.27371,   inf] (31), [-0.25796,   inf] (31), [-0.25492,   inf] (31), [-0.25403,   inf] (31), [-0.25344,   inf] (31), [-0.24773,   inf] (31), [-0.24526,   inf] (31), [-0.24324,   inf] (31), [-0.24019,   inf] (31), [-0.23871,   inf] (31), [-0.23655,   inf] (31), [-0.23127,   inf] (31), [-0.22671,   inf] (31), [-0.22571,   inf] (31), [-0.22489,   inf] (31), [-0.22382,   inf] (31), [-0.22347,   inf] (31), [-0.22189,   inf] (31), 
length of domains: 2049
Total time: 2.1267	 pickout: 0.0502	 decision: 0.3003	 get_bound: 1.7437	 add_domain: 0.0324
Current lb:-0.2822871506214142
4096 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 25.08865451812744

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 95] [2, 95] [2, 95] [2, 95] [2, 95] [2, 95] [2, 95] [2, 95] [2, 95] [2, 95] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 65.76995849609375 with beta sum per layer: [0.0, 0.0, 659.7615356445312]
alpha/beta optimization time: 1.6036791801452637
This batch time : update_bounds func: 1.7446	 prepare: 0.0322	 bound: 1.6040	 transfer: 0.0833	 finalize: 0.0237
Accumulated time: update_bounds func: 23.1544	 prepare: 0.3916	 bound: 21.5444	 transfer: 0.0833	 finalize: 0.2646
batch bounding time:  1.7453064918518066
Current worst splitting domains [lb, ub] (depth):
[-0.27645,   inf] (33), [-0.27079,   inf] (33), [-0.26751,   inf] (33), [-0.25227,   inf] (33), [-0.24785,   inf] (33), [-0.24778,   inf] (33), [-0.24704,   inf] (33), [-0.24061,   inf] (33), [-0.23667,   inf] (33), [-0.23380,   inf] (33), [-0.23357,   inf] (33), [-0.23205,   inf] (33), [-0.23140,   inf] (33), [-0.22128,   inf] (33), [-0.21931,   inf] (33), [-0.21911,   inf] (33), [-0.21791,   inf] (33), [-0.21774,   inf] (33), [-0.21740,   inf] (33), [-0.21649,   inf] (33), 
length of domains: 2249
Total time: 2.2171	 pickout: 0.0713	 decision: 0.3661	 get_bound: 1.7460	 add_domain: 0.0336
Current lb:-0.27645206451416016
4496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 27.31083393096924

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 50] [2, 50] [2, 128] [2, 50] [2, 128] [2, 50] [2, 128] [2, 139] [2, 139] [2, 128] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 66.01885986328125 with beta sum per layer: [0.0, 0.0, 645.3289794921875]
alpha/beta optimization time: 1.606837511062622
This batch time : update_bounds func: 1.8556	 prepare: 0.0321	 bound: 1.6072	 transfer: 0.0843	 finalize: 0.1310
Accumulated time: update_bounds func: 25.0100	 prepare: 0.4237	 bound: 23.1515	 transfer: 0.0843	 finalize: 0.3956
batch bounding time:  1.856320858001709
Current worst splitting domains [lb, ub] (depth):
[-0.26898,   inf] (35), [-0.26345,   inf] (35), [-0.25103,   inf] (35), [-0.24559,   inf] (35), [-0.24481,   inf] (35), [-0.24170,   inf] (35), [-0.24054,   inf] (35), [-0.23215,   inf] (35), [-0.22991,   inf] (35), [-0.22950,   inf] (35), [-0.22682,   inf] (35), [-0.22672,   inf] (35), [-0.22550,   inf] (35), [-0.22300,   inf] (35), [-0.21846,   inf] (35), [-0.21764,   inf] (35), [-0.21686,   inf] (35), [-0.21493,   inf] (35), [-0.21478,   inf] (35), [-0.21244,   inf] (35), 
length of domains: 2449
Total time: 2.2477	 pickout: 0.0616	 decision: 0.2969	 get_bound: 1.8570	 add_domain: 0.0321
Current lb:-0.2689836323261261
4896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 29.562579870224

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 139] [2, 139] [2, 11] [2, 139] [2, 139] [2, 139] [2, 139] [2, 139] [2, 139] [2, 50] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 65.1197738647461 with beta sum per layer: [0.0, 0.0, 652.06640625]
alpha/beta optimization time: 1.6182386875152588
This batch time : update_bounds func: 1.7613	 prepare: 0.0324	 bound: 1.6186	 transfer: 0.0855	 finalize: 0.0238
Accumulated time: update_bounds func: 26.7713	 prepare: 0.4561	 bound: 24.7701	 transfer: 0.0855	 finalize: 0.4194
batch bounding time:  1.7618415355682373
Current worst splitting domains [lb, ub] (depth):
[-0.25380,   inf] (37), [-0.24837,   inf] (37), [-0.24743,   inf] (37), [-0.24095,   inf] (37), [-0.23319,   inf] (37), [-0.23249,   inf] (37), [-0.22982,   inf] (37), [-0.22896,   inf] (37), [-0.22701,   inf] (37), [-0.22586,   inf] (37), [-0.22316,   inf] (37), [-0.22133,   inf] (37), [-0.21867,   inf] (37), [-0.21818,   inf] (37), [-0.21793,   inf] (37), [-0.21581,   inf] (37), [-0.21299,   inf] (37), [-0.21176,   inf] (37), [-0.21169,   inf] (37), [-0.21161,   inf] (37), 
length of domains: 2649
Total time: 2.1546	 pickout: 0.0577	 decision: 0.3020	 get_bound: 1.7625	 add_domain: 0.0323
Current lb:-0.25380462408065796
5296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 31.721105813980103

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 11] [2, 11] [2, 11] [2, 11] [2, 139] [2, 139] [2, 11] [2, 11] [2, 11] [2, 11] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 64.37113952636719 with beta sum per layer: [0.0, 0.0, 617.555419921875]
alpha/beta optimization time: 1.608996868133545
This batch time : update_bounds func: 1.7495	 prepare: 0.0322	 bound: 1.6093	 transfer: 0.0842	 finalize: 0.0227
Accumulated time: update_bounds func: 28.5207	 prepare: 0.4883	 bound: 26.3794	 transfer: 0.0842	 finalize: 0.4421
batch bounding time:  1.7500858306884766
Current worst splitting domains [lb, ub] (depth):
[-0.23873,   inf] (39), [-0.23259,   inf] (39), [-0.23170,   inf] (39), [-0.23105,   inf] (39), [-0.22941,   inf] (39), [-0.22653,   inf] (39), [-0.22327,   inf] (39), [-0.22164,   inf] (39), [-0.21645,   inf] (39), [-0.21561,   inf] (39), [-0.21505,   inf] (39), [-0.21436,   inf] (39), [-0.21273,   inf] (39), [-0.21168,   inf] (39), [-0.21079,   inf] (39), [-0.20948,   inf] (39), [-0.20942,   inf] (39), [-0.20772,   inf] (39), [-0.20742,   inf] (39), [-0.20721,   inf] (39), 
length of domains: 2849
Total time: 2.2287	 pickout: 0.0614	 decision: 0.3817	 get_bound: 1.7508	 add_domain: 0.0349
Current lb:-0.23873408138751984
5696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 33.954325675964355

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 149] [2, 149] [2, 149] [2, 149] [2, 149] [2, 149] [2, 149] [2, 149] [2, 149] [2, 149] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 60.587738037109375 with beta sum per layer: [0.0, 0.0, 615.8638305664062]
alpha/beta optimization time: 1.6098284721374512
This batch time : update_bounds func: 1.7500	 prepare: 0.0322	 bound: 1.6102	 transfer: 0.0834	 finalize: 0.0231
Accumulated time: update_bounds func: 30.2707	 prepare: 0.5205	 bound: 27.9895	 transfer: 0.0834	 finalize: 0.4653
batch bounding time:  1.7506053447723389
Current worst splitting domains [lb, ub] (depth):
[-0.23169,   inf] (41), [-0.22572,   inf] (41), [-0.22464,   inf] (41), [-0.22373,   inf] (41), [-0.22247,   inf] (41), [-0.21924,   inf] (41), [-0.21576,   inf] (41), [-0.21429,   inf] (41), [-0.20956,   inf] (41), [-0.20864,   inf] (41), [-0.20789,   inf] (41), [-0.20705,   inf] (41), [-0.20655,   inf] (41), [-0.20484,   inf] (41), [-0.20462,   inf] (41), [-0.20247,   inf] (41), [-0.20238,   inf] (41), [-0.20147,   inf] (41), [-0.20121,   inf] (41), [-0.19995,   inf] (41), 
length of domains: 3049
Total time: 2.1453	 pickout: 0.0563	 decision: 0.3014	 get_bound: 1.7513	 add_domain: 0.0362
Current lb:-0.2316884994506836
6096 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 36.10405492782593

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 196] [2, 196] [2, 196] [2, 196] [2, 196] [2, 196] [2, 196] [2, 196] [2, 196] [2, 196] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 61.277767181396484 with beta sum per layer: [0.0, 0.0, 641.2008056640625]
alpha/beta optimization time: 1.6281962394714355
This batch time : update_bounds func: 1.7716	 prepare: 0.0322	 bound: 1.6285	 transfer: 0.0852	 finalize: 0.0245
Accumulated time: update_bounds func: 32.0423	 prepare: 0.5527	 bound: 29.6181	 transfer: 0.0852	 finalize: 0.4898
batch bounding time:  1.7723383903503418
Current worst splitting domains [lb, ub] (depth):
[-0.22229,   inf] (43), [-0.21653,   inf] (43), [-0.21519,   inf] (43), [-0.21426,   inf] (43), [-0.21321,   inf] (43), [-0.21102,   inf] (43), [-0.21009,   inf] (43), [-0.20618,   inf] (43), [-0.20484,   inf] (43), [-0.20463,   inf] (43), [-0.20190,   inf] (43), [-0.20173,   inf] (43), [-0.20025,   inf] (43), [-0.19924,   inf] (43), [-0.19857,   inf] (43), [-0.19842,   inf] (43), [-0.19758,   inf] (43), [-0.19737,   inf] (43), [-0.19561,   inf] (43), [-0.19560,   inf] (43), 
length of domains: 3249
Total time: 2.2514	 pickout: 0.0560	 decision: 0.3879	 get_bound: 1.7731	 add_domain: 0.0344
Current lb:-0.2222909927368164
6496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 38.361021518707275

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 83] [2, 83] [2, 83] [2, 83] [2, 83] [2, 75] [2, 92] [2, 83] [2, 92] [2, 83] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 61.099395751953125 with beta sum per layer: [0.0, 0.0, 603.498779296875]
alpha/beta optimization time: 1.603795051574707
This batch time : update_bounds func: 1.7480	 prepare: 0.0332	 bound: 1.6041	 transfer: 0.0855	 finalize: 0.0240
Accumulated time: update_bounds func: 33.7903	 prepare: 0.5859	 bound: 31.2222	 transfer: 0.0855	 finalize: 0.5138
batch bounding time:  1.7485616207122803
Current worst splitting domains [lb, ub] (depth):
[-0.21574,   inf] (45), [-0.20993,   inf] (45), [-0.20923,   inf] (45), [-0.20776,   inf] (45), [-0.20711,   inf] (45), [-0.20201,   inf] (45), [-0.20075,   inf] (45), [-0.19999,   inf] (45), [-0.19830,   inf] (45), [-0.19724,   inf] (45), [-0.19696,   inf] (45), [-0.19428,   inf] (45), [-0.19407,   inf] (45), [-0.19289,   inf] (45), [-0.19185,   inf] (45), [-0.19171,   inf] (45), [-0.19061,   inf] (45), [-0.19043,   inf] (45), [-0.19036,   inf] (45), [-0.18915,   inf] (45), 
length of domains: 3449
Total time: 2.1468	 pickout: 0.0569	 decision: 0.3051	 get_bound: 1.7492	 add_domain: 0.0356
Current lb:-0.21574075520038605
6896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 40.512523889541626

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 75] [2, 92] [2, 27] [2, 92] [2, 92] [2, 83] [2, 83] [2, 92] [2, 92] [2, 27] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 60.49158477783203 with beta sum per layer: [0.0, 0.0, 571.714111328125]
alpha/beta optimization time: 1.6063344478607178
This batch time : update_bounds func: 1.7473	 prepare: 0.0323	 bound: 1.6066	 transfer: 0.0844	 finalize: 0.0229
Accumulated time: update_bounds func: 35.5376	 prepare: 0.6181	 bound: 32.8288	 transfer: 0.0844	 finalize: 0.5367
batch bounding time:  1.7479066848754883
Current worst splitting domains [lb, ub] (depth):
[-0.20651,   inf] (47), [-0.20163,   inf] (47), [-0.19931,   inf] (47), [-0.19907,   inf] (47), [-0.19882,   inf] (47), [-0.19734,   inf] (47), [-0.19564,   inf] (47), [-0.19463,   inf] (47), [-0.19345,   inf] (47), [-0.19187,   inf] (47), [-0.19100,   inf] (47), [-0.18711,   inf] (47), [-0.18655,   inf] (47), [-0.18642,   inf] (47), [-0.18577,   inf] (47), [-0.18436,   inf] (47), [-0.18378,   inf] (47), [-0.18310,   inf] (47), [-0.18299,   inf] (47), [-0.18297,   inf] (47), 
length of domains: 3649
Total time: 2.2407	 pickout: 0.0542	 decision: 0.4004	 get_bound: 1.7486	 add_domain: 0.0374
Current lb:-0.20651023089885712
7296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 42.757795333862305

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 22] [2, 22] [2, 75] [2, 92] [2, 27] [2, 92] [2, 145] [2, 22] [2, 22] [2, 27] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 58.58796691894531 with beta sum per layer: [0.0, 0.0, 600.3682861328125]
alpha/beta optimization time: 1.6041040420532227
This batch time : update_bounds func: 1.7473	 prepare: 0.0329	 bound: 1.6044	 transfer: 0.0846	 finalize: 0.0243
Accumulated time: update_bounds func: 37.2848	 prepare: 0.6511	 bound: 34.4332	 transfer: 0.0846	 finalize: 0.5610
batch bounding time:  1.747901201248169
Current worst splitting domains [lb, ub] (depth):
[-0.20299,   inf] (49), [-0.19805,   inf] (49), [-0.19097,   inf] (49), [-0.19037,   inf] (49), [-0.19013,   inf] (49), [-0.19002,   inf] (49), [-0.18878,   inf] (49), [-0.18662,   inf] (49), [-0.18437,   inf] (49), [-0.18369,   inf] (49), [-0.18289,   inf] (49), [-0.18207,   inf] (49), [-0.18132,   inf] (49), [-0.18116,   inf] (49), [-0.18061,   inf] (49), [-0.18025,   inf] (49), [-0.17969,   inf] (49), [-0.17964,   inf] (49), [-0.17923,   inf] (49), [-0.17859,   inf] (49), 
length of domains: 3849
Total time: 2.2601	 pickout: 0.0617	 decision: 0.3016	 get_bound: 1.7486	 add_domain: 0.1482
Current lb:-0.20299294590950012
7696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 45.02267098426819

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 27] [2, 27] [2, 92] [2, 27] [2, 92] [2, 27] [2, 22] [2, 97] [2, 97] [2, 75] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 57.817054748535156 with beta sum per layer: [0.0, 0.0, 573.3814697265625]
alpha/beta optimization time: 1.5997674465179443
This batch time : update_bounds func: 1.7430	 prepare: 0.0323	 bound: 1.6001	 transfer: 0.0834	 finalize: 0.0262
Accumulated time: update_bounds func: 39.0279	 prepare: 0.6834	 bound: 36.0333	 transfer: 0.0834	 finalize: 0.5871
batch bounding time:  1.7437491416931152
Current worst splitting domains [lb, ub] (depth):
[-0.19103,   inf] (51), [-0.18799,   inf] (51), [-0.18559,   inf] (51), [-0.18501,   inf] (51), [-0.18395,   inf] (51), [-0.18254,   inf] (51), [-0.18087,   inf] (51), [-0.17968,   inf] (51), [-0.17859,   inf] (51), [-0.17777,   inf] (51), [-0.17733,   inf] (51), [-0.17528,   inf] (51), [-0.17526,   inf] (51), [-0.17367,   inf] (51), [-0.17361,   inf] (51), [-0.17309,   inf] (51), [-0.17257,   inf] (51), [-0.17147,   inf] (51), [-0.17112,   inf] (51), [-0.17068,   inf] (51), 
length of domains: 4049
Total time: 2.1427	 pickout: 0.0590	 decision: 0.3004	 get_bound: 1.7446	 add_domain: 0.0387
Current lb:-0.19102852046489716
8096 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 47.17066526412964

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 92] [2, 92] [2, 97] [2, 75] [2, 97] [2, 75] [2, 27] [2, 22] [2, 22] [2, 22] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 56.72208023071289 with beta sum per layer: [0.0, 0.0, 607.072509765625]
alpha/beta optimization time: 1.6024160385131836
This batch time : update_bounds func: 1.7459	 prepare: 0.0327	 bound: 1.6027	 transfer: 0.0845	 finalize: 0.0249
Accumulated time: update_bounds func: 40.7738	 prepare: 0.7160	 bound: 37.6360	 transfer: 0.0845	 finalize: 0.6121
batch bounding time:  1.7465291023254395
Current worst splitting domains [lb, ub] (depth):
[-0.18229,   inf] (53), [-0.17937,   inf] (53), [-0.17867,   inf] (53), [-0.17686,   inf] (53), [-0.17591,   inf] (53), [-0.17546,   inf] (53), [-0.17484,   inf] (53), [-0.17385,   inf] (53), [-0.17370,   inf] (53), [-0.17284,   inf] (53), [-0.17164,   inf] (53), [-0.17136,   inf] (53), [-0.17089,   inf] (53), [-0.17024,   inf] (53), [-0.16793,   inf] (53), [-0.16742,   inf] (53), [-0.16659,   inf] (53), [-0.16654,   inf] (53), [-0.16419,   inf] (53), [-0.16409,   inf] (53), 
length of domains: 4249
Total time: 2.1679	 pickout: 0.0831	 decision: 0.3008	 get_bound: 1.7473	 add_domain: 0.0368
Current lb:-0.18229059875011444
8496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 49.34336280822754

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 97] [2, 97] [2, 75] [2, 75] [2, 166] [2, 97] [2, 97] [2, 145] [2, 166] [2, 145] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 55.41336441040039 with beta sum per layer: [0.0, 0.0, 676.8806762695312]
alpha/beta optimization time: 1.6012427806854248
This batch time : update_bounds func: 1.7427	 prepare: 0.0325	 bound: 1.6016	 transfer: 0.0840	 finalize: 0.0235
Accumulated time: update_bounds func: 42.5165	 prepare: 0.7485	 bound: 39.2376	 transfer: 0.0840	 finalize: 0.6356
batch bounding time:  1.7433826923370361
Current worst splitting domains [lb, ub] (depth):
[-0.17499,   inf] (55), [-0.17203,   inf] (55), [-0.16858,   inf] (55), [-0.16843,   inf] (55), [-0.16764,   inf] (55), [-0.16648,   inf] (55), [-0.16596,   inf] (55), [-0.16497,   inf] (55), [-0.16445,   inf] (55), [-0.16399,   inf] (55), [-0.16321,   inf] (55), [-0.16283,   inf] (55), [-0.16183,   inf] (55), [-0.16171,   inf] (55), [-0.16061,   inf] (55), [-0.16041,   inf] (55), [-0.16033,   inf] (55), [-0.15968,   inf] (55), [-0.15946,   inf] (55), [-0.15918,   inf] (55), 
length of domains: 4449
Total time: 2.2830	 pickout: 0.0677	 decision: 0.4333	 get_bound: 1.7441	 add_domain: 0.0378
Current lb:-0.17499218881130219
8896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 51.630717039108276

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 15] [2, 15] [2, 15] [2, 15] [2, 15] [2, 15] [2, 15] [2, 15] [2, 15] [2, 15] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 53.2287712097168 with beta sum per layer: [0.0, 0.0, 657.8267822265625]
alpha/beta optimization time: 1.5983502864837646
This batch time : update_bounds func: 1.7402	 prepare: 0.0327	 bound: 1.5987	 transfer: 0.0838	 finalize: 0.0239
Accumulated time: update_bounds func: 44.2567	 prepare: 0.7812	 bound: 40.8363	 transfer: 0.0838	 finalize: 0.6595
batch bounding time:  1.740828037261963
Current worst splitting domains [lb, ub] (depth):
[-0.17276,   inf] (57), [-0.16972,   inf] (57), [-0.16626,   inf] (57), [-0.16626,   inf] (57), [-0.16539,   inf] (57), [-0.16432,   inf] (57), [-0.16370,   inf] (57), [-0.16272,   inf] (57), [-0.16220,   inf] (57), [-0.16167,   inf] (57), [-0.16080,   inf] (57), [-0.16058,   inf] (57), [-0.15940,   inf] (57), [-0.15839,   inf] (57), [-0.15814,   inf] (57), [-0.15790,   inf] (57), [-0.15769,   inf] (37), [-0.15768,   inf] (39), [-0.15768,   inf] (31), [-0.15767,   inf] (53), 
length of domains: 4649
Total time: 2.1577	 pickout: 0.0765	 decision: 0.3022	 get_bound: 1.7416	 add_domain: 0.0374
Current lb:-0.172761932015419
9296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 53.79313778877258

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 166] [2, 145] [2, 166] [2, 166] [2, 145] [2, 145] [2, 75] [2, 166] [2, 166] [2, 75] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 54.27492904663086 with beta sum per layer: [0.0, 0.0, 641.054443359375]
alpha/beta optimization time: 1.5997958183288574
This batch time : update_bounds func: 1.7345	 prepare: 0.0326	 bound: 1.6001	 transfer: 0.0757	 finalize: 0.0249
Accumulated time: update_bounds func: 45.9912	 prepare: 0.8138	 bound: 42.4364	 transfer: 0.0757	 finalize: 0.6844
batch bounding time:  1.7351016998291016
Current worst splitting domains [lb, ub] (depth):
[-0.16282,   inf] (59), [-0.15706,   inf] (59), [-0.15676,   inf] (59), [-0.15641,   inf] (59), [-0.15640,   inf] (59), [-0.15638,   inf] (31), [-0.15638,   inf] (21), [-0.15637,   inf] (57), [-0.15637,   inf] (43), [-0.15637,   inf] (43), [-0.15637,   inf] (25), [-0.15637,   inf] (49), [-0.15636,   inf] (37), [-0.15635,   inf] (21), [-0.15635,   inf] (39), [-0.15633,   inf] (37), [-0.15633,   inf] (29), [-0.15633,   inf] (23), [-0.15630,   inf] (41), [-0.15630,   inf] (25), 
length of domains: 4849
Total time: 2.2753	 pickout: 0.0684	 decision: 0.4345	 get_bound: 1.7358	 add_domain: 0.0367
Current lb:-0.16281792521476746
9696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 56.07305979728699

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 145] [2, 166] [2, 145] [2, 145] [2, 145] [2, 95] [2, 101] [2, 97] [2, 196] [2, 83] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 53.41979217529297 with beta sum per layer: [0.0, 0.0, 732.964111328125]
alpha/beta optimization time: 1.6016409397125244
This batch time : update_bounds func: 1.7358	 prepare: 0.0326	 bound: 1.6020	 transfer: 0.0754	 finalize: 0.0248
Accumulated time: update_bounds func: 47.7270	 prepare: 0.8464	 bound: 44.0383	 transfer: 0.0754	 finalize: 0.7091
batch bounding time:  1.7364161014556885
Current worst splitting domains [lb, ub] (depth):
[-0.15520,   inf] (23), [-0.15519,   inf] (45), [-0.15519,   inf] (51), [-0.15519,   inf] (53), [-0.15516,   inf] (49), [-0.15516,   inf] (21), [-0.15516,   inf] (45), [-0.15515,   inf] (19), [-0.15515,   inf] (39), [-0.15514,   inf] (53), [-0.15514,   inf] (29), [-0.15513,   inf] (27), [-0.15513,   inf] (39), [-0.15512,   inf] (35), [-0.15512,   inf] (21), [-0.15512,   inf] (47), [-0.15512,   inf] (31), [-0.15512,   inf] (49), [-0.15510,   inf] (17), [-0.15510,   inf] (29), 
length of domains: 5049
Total time: 2.1409	 pickout: 0.0657	 decision: 0.3025	 get_bound: 1.7371	 add_domain: 0.0356
Current lb:-0.15520188212394714
10096 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 58.2186222076416

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 229] [2, 92] [2, 27] [2, 166] [2, 22] [2, 34] [2, 83] [2, 234] [2, 149] [2, 166] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 52.49991989135742 with beta sum per layer: [0.0, 0.0, 727.023681640625]
alpha/beta optimization time: 1.6042289733886719
This batch time : update_bounds func: 1.8906	 prepare: 0.0326	 bound: 1.6045	 transfer: 0.0835	 finalize: 0.1689
Accumulated time: update_bounds func: 49.6176	 prepare: 0.8790	 bound: 45.6429	 transfer: 0.0835	 finalize: 0.8781
batch bounding time:  1.8913192749023438
Current worst splitting domains [lb, ub] (depth):
[-0.15410,   inf] (41), [-0.15410,   inf] (17), [-0.15409,   inf] (51), [-0.15409,   inf] (45), [-0.15409,   inf] (29), [-0.15409,   inf] (31), [-0.15408,   inf] (45), [-0.15408,   inf] (37), [-0.15407,   inf] (27), [-0.15407,   inf] (49), [-0.15406,   inf] (27), [-0.15406,   inf] (19), [-0.15406,   inf] (39), [-0.15406,   inf] (43), [-0.15406,   inf] (35), [-0.15406,   inf] (17), [-0.15405,   inf] (29), [-0.15400,   inf] (37), [-0.15400,   inf] (35), [-0.15399,   inf] (45), 
length of domains: 5249
Total time: 2.3052	 pickout: 0.0740	 decision: 0.3016	 get_bound: 1.8921	 add_domain: 0.0375
Current lb:-0.15410229563713074
10496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 60.52843880653381

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 83] [2, 117] [2, 145] [2, 27] [2, 128] [2, 95] [2, 92] [2, 11] [2, 34] [2, 27] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 51.839988708496094 with beta sum per layer: [0.0, 0.0, 749.71484375]
alpha/beta optimization time: 1.6189186573028564
This batch time : update_bounds func: 1.7552	 prepare: 0.0327	 bound: 1.6192	 transfer: 0.0771	 finalize: 0.0249
Accumulated time: update_bounds func: 51.3728	 prepare: 0.9117	 bound: 47.2621	 transfer: 0.0771	 finalize: 0.9030
batch bounding time:  1.7558391094207764
Current worst splitting domains [lb, ub] (depth):
[-0.15290,   inf] (23), [-0.15289,   inf] (43), [-0.15289,   inf] (51), [-0.15288,   inf] (27), [-0.15287,   inf] (33), [-0.15286,   inf] (27), [-0.15285,   inf] (25), [-0.15285,   inf] (31), [-0.15285,   inf] (27), [-0.15284,   inf] (35), [-0.15283,   inf] (23), [-0.15283,   inf] (47), [-0.15282,   inf] (45), [-0.15282,   inf] (27), [-0.15281,   inf] (19), [-0.15281,   inf] (35), [-0.15280,   inf] (27), [-0.15280,   inf] (31), [-0.15279,   inf] (51), [-0.15279,   inf] (49), 
length of domains: 5449
Total time: 2.1635	 pickout: 0.0642	 decision: 0.3041	 get_bound: 1.7566	 add_domain: 0.0386
Current lb:-0.1528959423303604
10896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 62.696653604507446

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 7] [2, 83] [2, 145] [2, 131] [2, 128] [2, 34] [2, 139] [2, 95] [2, 34] [2, 50] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 51.847068786621094 with beta sum per layer: [0.0, 0.0, 753.3844604492188]
alpha/beta optimization time: 1.608675241470337
This batch time : update_bounds func: 1.7530	 prepare: 0.0341	 bound: 1.6090	 transfer: 0.0835	 finalize: 0.0252
Accumulated time: update_bounds func: 53.1259	 prepare: 0.9458	 bound: 48.8711	 transfer: 0.0835	 finalize: 0.9282
batch bounding time:  1.7538175582885742
Current worst splitting domains [lb, ub] (depth):
[-0.15169,   inf] (23), [-0.15169,   inf] (25), [-0.15168,   inf] (39), [-0.15168,   inf] (47), [-0.15167,   inf] (17), [-0.15167,   inf] (29), [-0.15167,   inf] (27), [-0.15167,   inf] (33), [-0.15167,   inf] (27), [-0.15166,   inf] (33), [-0.15166,   inf] (21), [-0.15166,   inf] (41), [-0.15165,   inf] (33), [-0.15165,   inf] (39), [-0.15163,   inf] (21), [-0.15163,   inf] (47), [-0.15163,   inf] (33), [-0.15162,   inf] (59), [-0.15162,   inf] (45), [-0.15161,   inf] (33), 
length of domains: 5649
Total time: 2.1772	 pickout: 0.0777	 decision: 0.3091	 get_bound: 1.7546	 add_domain: 0.0358
Current lb:-0.1516905575990677
11296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 64.88008975982666

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 131] [2, 229] [2, 149] [2, 27] [2, 117] [2, 50] [2, 34] [2, 128] [2, 131] [2, 139] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 51.16609191894531 with beta sum per layer: [0.0, 0.0, 700.5606689453125]
alpha/beta optimization time: 1.609246015548706
This batch time : update_bounds func: 1.7488	 prepare: 0.0333	 bound: 1.6096	 transfer: 0.0792	 finalize: 0.0256
Accumulated time: update_bounds func: 54.8747	 prepare: 0.9792	 bound: 50.4807	 transfer: 0.0792	 finalize: 0.9537
batch bounding time:  1.7494292259216309
Current worst splitting domains [lb, ub] (depth):
[-0.15053,   inf] (23), [-0.15053,   inf] (23), [-0.15053,   inf] (29), [-0.15053,   inf] (23), [-0.15053,   inf] (33), [-0.15052,   inf] (49), [-0.15052,   inf] (25), [-0.15050,   inf] (21), [-0.15050,   inf] (41), [-0.15050,   inf] (33), [-0.15049,   inf] (51), [-0.15049,   inf] (41), [-0.15049,   inf] (31), [-0.15047,   inf] (27), [-0.15046,   inf] (35), [-0.15046,   inf] (37), [-0.15046,   inf] (35), [-0.15046,   inf] (33), [-0.15045,   inf] (21), [-0.15045,   inf] (23), 
length of domains: 5849
Total time: 2.3128	 pickout: 0.0592	 decision: 0.4676	 get_bound: 1.7501	 add_domain: 0.0359
Current lb:-0.15053023397922516
11696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 67.19760537147522

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 7] [2, 34] [2, 7] [2, 7] [2, 50] [2, 97] [2, 34] [2, 7] [2, 196] [2, 139] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 50.578086853027344 with beta sum per layer: [0.0, 0.0, 721.0867919921875]
alpha/beta optimization time: 1.6210284233093262
This batch time : update_bounds func: 1.7657	 prepare: 0.0338	 bound: 1.6213	 transfer: 0.0849	 finalize: 0.0245
Accumulated time: update_bounds func: 56.6404	 prepare: 1.0130	 bound: 52.1020	 transfer: 0.0849	 finalize: 0.9782
batch bounding time:  1.7663309574127197
Current worst splitting domains [lb, ub] (depth):
[-0.14957,   inf] (35), [-0.14956,   inf] (35), [-0.14956,   inf] (41), [-0.14956,   inf] (57), [-0.14956,   inf] (41), [-0.14955,   inf] (41), [-0.14954,   inf] (47), [-0.14953,   inf] (41), [-0.14953,   inf] (49), [-0.14953,   inf] (47), [-0.14952,   inf] (31), [-0.14951,   inf] (29), [-0.14951,   inf] (23), [-0.14950,   inf] (41), [-0.14950,   inf] (25), [-0.14950,   inf] (43), [-0.14948,   inf] (41), [-0.14948,   inf] (31), [-0.14947,   inf] (31), [-0.14947,   inf] (37), 
length of domains: 6049
Total time: 2.1717	 pickout: 0.0622	 decision: 0.3042	 get_bound: 1.7671	 add_domain: 0.0382
Current lb:-0.14956757426261902
12096 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 69.37429356575012

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 50] [2, 139] [2, 196] [2, 75] [2, 196] [2, 196] [2, 75] [2, 196] [2, 75] [2, 22] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 50.379661560058594 with beta sum per layer: [0.0, 0.0, 759.0178833007812]
alpha/beta optimization time: 1.6141571998596191
This batch time : update_bounds func: 1.9258	 prepare: 0.0329	 bound: 1.6146	 transfer: 0.0838	 finalize: 0.1932
Accumulated time: update_bounds func: 58.5662	 prepare: 1.0458	 bound: 53.7167	 transfer: 0.0838	 finalize: 1.1715
batch bounding time:  1.9264984130859375
Current worst splitting domains [lb, ub] (depth):
[-0.14861,   inf] (21), [-0.14860,   inf] (35), [-0.14859,   inf] (27), [-0.14859,   inf] (23), [-0.14859,   inf] (33), [-0.14859,   inf] (21), [-0.14858,   inf] (45), [-0.14858,   inf] (21), [-0.14858,   inf] (33), [-0.14858,   inf] (35), [-0.14858,   inf] (45), [-0.14857,   inf] (33), [-0.14857,   inf] (51), [-0.14857,   inf] (45), [-0.14857,   inf] (51), [-0.14856,   inf] (29), [-0.14855,   inf] (23), [-0.14855,   inf] (49), [-0.14854,   inf] (29), [-0.14854,   inf] (17), 
length of domains: 6249
Total time: 2.3433	 pickout: 0.0709	 decision: 0.3076	 get_bound: 1.9273	 add_domain: 0.0375
Current lb:-0.14860771596431732
12496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 71.72235321998596

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 229] [2, 128] [2, 131] [2, 229] [2, 50] [2, 7] [2, 83] [2, 7] [2, 139] [2, 50] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 49.907405853271484 with beta sum per layer: [0.0, 0.0, 746.1329345703125]
alpha/beta optimization time: 1.6082499027252197
This batch time : update_bounds func: 1.7452	 prepare: 0.0339	 bound: 1.6086	 transfer: 0.0762	 finalize: 0.0254
Accumulated time: update_bounds func: 60.3114	 prepare: 1.0797	 bound: 55.3253	 transfer: 0.0762	 finalize: 1.1968
batch bounding time:  1.7459022998809814
Current worst splitting domains [lb, ub] (depth):
[-0.14765,   inf] (23), [-0.14765,   inf] (37), [-0.14764,   inf] (49), [-0.14764,   inf] (47), [-0.14764,   inf] (31), [-0.14763,   inf] (45), [-0.14763,   inf] (39), [-0.14762,   inf] (23), [-0.14762,   inf] (33), [-0.14761,   inf] (31), [-0.14761,   inf] (21), [-0.14760,   inf] (43), [-0.14760,   inf] (41), [-0.14760,   inf] (27), [-0.14760,   inf] (35), [-0.14760,   inf] (31), [-0.14759,   inf] (43), [-0.14759,   inf] (49), [-0.14759,   inf] (55), [-0.14759,   inf] (55), 
length of domains: 6449
Total time: 2.1508	 pickout: 0.0622	 decision: 0.3061	 get_bound: 1.7466	 add_domain: 0.0359
Current lb:-0.14764884114265442
12896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 73.87882113456726

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 7] [2, 11] [2, 97] [2, 27] [2, 95] [2, 97] [2, 149] [2, 131] [2, 50] [2, 95] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 49.47439956665039 with beta sum per layer: [0.0, 0.0, 741.480224609375]
alpha/beta optimization time: 1.6000778675079346
This batch time : update_bounds func: 1.7436	 prepare: 0.0330	 bound: 1.6004	 transfer: 0.0841	 finalize: 0.0250
Accumulated time: update_bounds func: 62.0550	 prepare: 1.1127	 bound: 56.9257	 transfer: 0.0841	 finalize: 1.2218
batch bounding time:  1.744194507598877
Current worst splitting domains [lb, ub] (depth):
[-0.14670,   inf] (41), [-0.14668,   inf] (37), [-0.14668,   inf] (45), [-0.14667,   inf] (35), [-0.14667,   inf] (39), [-0.14666,   inf] (25), [-0.14666,   inf] (39), [-0.14665,   inf] (53), [-0.14664,   inf] (27), [-0.14664,   inf] (33), [-0.14663,   inf] (51), [-0.14663,   inf] (29), [-0.14663,   inf] (21), [-0.14662,   inf] (31), [-0.14662,   inf] (43), [-0.14662,   inf] (35), [-0.14661,   inf] (35), [-0.14661,   inf] (47), [-0.14660,   inf] (37), [-0.14660,   inf] (33), 
length of domains: 6649
Total time: 2.1557	 pickout: 0.0664	 decision: 0.3087	 get_bound: 1.7449	 add_domain: 0.0357
Current lb:-0.14669904112815857
13296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 76.03967142105103

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 196] [2, 11] [2, 92] [2, 139] [2, 149] [2, 131] [2, 149] [2, 97] [2, 131] [2, 139] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 49.20124816894531 with beta sum per layer: [0.0, 0.0, 787.1149291992188]
alpha/beta optimization time: 1.6005291938781738
This batch time : update_bounds func: 1.7424	 prepare: 0.0326	 bound: 1.6008	 transfer: 0.0840	 finalize: 0.0239
Accumulated time: update_bounds func: 63.7975	 prepare: 1.1452	 bound: 58.5265	 transfer: 0.0840	 finalize: 1.2457
batch bounding time:  1.743058681488037
Current worst splitting domains [lb, ub] (depth):
[-0.14587,   inf] (51), [-0.14586,   inf] (35), [-0.14586,   inf] (53), [-0.14586,   inf] (23), [-0.14586,   inf] (57), [-0.14584,   inf] (49), [-0.14584,   inf] (27), [-0.14584,   inf] (47), [-0.14583,   inf] (25), [-0.14583,   inf] (31), [-0.14583,   inf] (35), [-0.14583,   inf] (23), [-0.14583,   inf] (31), [-0.14582,   inf] (25), [-0.14581,   inf] (37), [-0.14581,   inf] (21), [-0.14581,   inf] (61), [-0.14580,   inf] (49), [-0.14580,   inf] (45), [-0.14579,   inf] (33), 
length of domains: 6849
Total time: 2.3498	 pickout: 0.0716	 decision: 0.4958	 get_bound: 1.7438	 add_domain: 0.0386
Current lb:-0.145870640873909
13696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 78.39450097084045

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 97] [2, 128] [2, 97] [2, 131] [2, 75] [2, 75] [2, 34] [2, 97] [2, 7] [2, 95] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 48.74222183227539 with beta sum per layer: [0.0, 0.0, 735.05859375]
alpha/beta optimization time: 1.6047682762145996
This batch time : update_bounds func: 1.7396	 prepare: 0.0328	 bound: 1.6051	 transfer: 0.0764	 finalize: 0.0241
Accumulated time: update_bounds func: 65.5370	 prepare: 1.1781	 bound: 60.1316	 transfer: 0.0764	 finalize: 1.2697
batch bounding time:  1.740187168121338
Current worst splitting domains [lb, ub] (depth):
[-0.14503,   inf] (27), [-0.14503,   inf] (35), [-0.14503,   inf] (19), [-0.14503,   inf] (45), [-0.14502,   inf] (35), [-0.14502,   inf] (53), [-0.14501,   inf] (45), [-0.14500,   inf] (47), [-0.14500,   inf] (29), [-0.14499,   inf] (33), [-0.14499,   inf] (31), [-0.14499,   inf] (47), [-0.14498,   inf] (33), [-0.14498,   inf] (21), [-0.14498,   inf] (35), [-0.14498,   inf] (45), [-0.14497,   inf] (57), [-0.14497,   inf] (29), [-0.14497,   inf] (27), [-0.14497,   inf] (47), 
length of domains: 7049
Total time: 2.1409	 pickout: 0.0581	 decision: 0.3036	 get_bound: 1.7409	 add_domain: 0.0384
Current lb:-0.14503371715545654
14096 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 80.54025721549988

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 34] [2, 128] [2, 234] [2, 92] [2, 128] [2, 27] [2, 75] [2, 27] [2, 50] [2, 139] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 48.867469787597656 with beta sum per layer: [0.0, 0.0, 761.392822265625]
alpha/beta optimization time: 1.602424144744873
This batch time : update_bounds func: 1.7450	 prepare: 0.0327	 bound: 1.6027	 transfer: 0.0834	 finalize: 0.0250
Accumulated time: update_bounds func: 67.2820	 prepare: 1.2107	 bound: 61.7343	 transfer: 0.0834	 finalize: 1.2947
batch bounding time:  1.7456285953521729
Current worst splitting domains [lb, ub] (depth):
[-0.14431,   inf] (21), [-0.14430,   inf] (47), [-0.14428,   inf] (57), [-0.14427,   inf] (29), [-0.14426,   inf] (29), [-0.14426,   inf] (21), [-0.14426,   inf] (17), [-0.14426,   inf] (31), [-0.14425,   inf] (21), [-0.14425,   inf] (43), [-0.14424,   inf] (37), [-0.14424,   inf] (23), [-0.14423,   inf] (35), [-0.14423,   inf] (37), [-0.14422,   inf] (19), [-0.14421,   inf] (29), [-0.14421,   inf] (55), [-0.14420,   inf] (37), [-0.14420,   inf] (19), [-0.14420,   inf] (41), 
length of domains: 7249
Total time: 2.1490	 pickout: 0.0616	 decision: 0.3044	 get_bound: 1.7464	 add_domain: 0.0367
Current lb:-0.14430592954158783
14496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 82.69432020187378

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 139] [2, 97] [2, 27] [2, 128] [2, 128] [2, 229] [2, 117] [2, 95] [2, 7] [2, 83] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 47.835227966308594 with beta sum per layer: [0.0, 0.0, 817.8604736328125]
alpha/beta optimization time: 1.5999841690063477
This batch time : update_bounds func: 1.7356	 prepare: 0.0326	 bound: 1.6003	 transfer: 0.0759	 finalize: 0.0256
Accumulated time: update_bounds func: 69.0176	 prepare: 1.2433	 bound: 63.3346	 transfer: 0.0759	 finalize: 1.3203
batch bounding time:  1.736194372177124
Current worst splitting domains [lb, ub] (depth):
[-0.14345,   inf] (35), [-0.14342,   inf] (23), [-0.14342,   inf] (45), [-0.14342,   inf] (23), [-0.14342,   inf] (47), [-0.14341,   inf] (55), [-0.14341,   inf] (45), [-0.14340,   inf] (37), [-0.14340,   inf] (35), [-0.14339,   inf] (29), [-0.14338,   inf] (49), [-0.14338,   inf] (41), [-0.14338,   inf] (41), [-0.14338,   inf] (27), [-0.14337,   inf] (45), [-0.14337,   inf] (51), [-0.14337,   inf] (39), [-0.14336,   inf] (29), [-0.14335,   inf] (25), [-0.14335,   inf] (57), 
length of domains: 7449
Total time: 2.3558	 pickout: 0.0715	 decision: 0.5117	 get_bound: 1.7369	 add_domain: 0.0357
Current lb:-0.14344839751720428
14896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 85.0552887916565

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 128] [2, 229] [2, 92] [2, 7] [2, 97] [2, 15] [2, 75] [2, 11] [2, 139] [2, 128] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 48.08888244628906 with beta sum per layer: [0.0, 0.0, 739.5052490234375]
alpha/beta optimization time: 1.5992848873138428
This batch time : update_bounds func: 1.7412	 prepare: 0.0328	 bound: 1.5996	 transfer: 0.0839	 finalize: 0.0238
Accumulated time: update_bounds func: 70.7588	 prepare: 1.2761	 bound: 64.9342	 transfer: 0.0839	 finalize: 1.3441
batch bounding time:  1.741894245147705
Current worst splitting domains [lb, ub] (depth):
[-0.14259,   inf] (19), [-0.14257,   inf] (17), [-0.14257,   inf] (25), [-0.14257,   inf] (59), [-0.14256,   inf] (37), [-0.14256,   inf] (29), [-0.14256,   inf] (45), [-0.14255,   inf] (41), [-0.14255,   inf] (39), [-0.14255,   inf] (29), [-0.14255,   inf] (41), [-0.14255,   inf] (35), [-0.14255,   inf] (53), [-0.14255,   inf] (39), [-0.14254,   inf] (31), [-0.14254,   inf] (31), [-0.14254,   inf] (53), [-0.14253,   inf] (29), [-0.14253,   inf] (37), [-0.14253,   inf] (31), 
length of domains: 7649
Total time: 2.1593	 pickout: 0.0718	 decision: 0.3053	 get_bound: 1.7426	 add_domain: 0.0396
Current lb:-0.14258569478988647
15296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 87.21964073181152

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 234] [2, 117] [2, 34] [2, 166] [2, 139] [2, 50] [2, 83] [2, 92] [2, 149] [2, 7] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 47.3849983215332 with beta sum per layer: [0.0, 0.0, 774.7783203125]
alpha/beta optimization time: 1.6067490577697754
This batch time : update_bounds func: 1.7416	 prepare: 0.0328	 bound: 1.6071	 transfer: 0.0760	 finalize: 0.0244
Accumulated time: update_bounds func: 72.5004	 prepare: 1.3090	 bound: 66.5413	 transfer: 0.0760	 finalize: 1.3685
batch bounding time:  1.742239236831665
Current worst splitting domains [lb, ub] (depth):
[-0.14184,   inf] (23), [-0.14184,   inf] (59), [-0.14184,   inf] (33), [-0.14183,   inf] (39), [-0.14182,   inf] (41), [-0.14182,   inf] (53), [-0.14182,   inf] (39), [-0.14181,   inf] (47), [-0.14181,   inf] (23), [-0.14181,   inf] (45), [-0.14181,   inf] (51), [-0.14180,   inf] (21), [-0.14180,   inf] (41), [-0.14180,   inf] (61), [-0.14179,   inf] (43), [-0.14179,   inf] (41), [-0.14179,   inf] (43), [-0.14179,   inf] (53), [-0.14179,   inf] (49), [-0.14179,   inf] (39), 
length of domains: 7849
Total time: 2.1528	 pickout: 0.0670	 decision: 0.3034	 get_bound: 1.7430	 add_domain: 0.0395
Current lb:-0.14184437692165375
15696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 89.37780594825745

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 229] [2, 166] [2, 50] [2, 149] [2, 92] [2, 27] [2, 149] [2, 22] [2, 34] [2, 27] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 47.513633728027344 with beta sum per layer: [0.0, 0.0, 706.2440795898438]
alpha/beta optimization time: 1.6065943241119385
This batch time : update_bounds func: 1.7424	 prepare: 0.0326	 bound: 1.6069	 transfer: 0.0767	 finalize: 0.0250
Accumulated time: update_bounds func: 74.2429	 prepare: 1.3416	 bound: 68.1482	 transfer: 0.0767	 finalize: 1.3935
batch bounding time:  1.7430779933929443
Current worst splitting domains [lb, ub] (depth):
[-0.14111,   inf] (29), [-0.14111,   inf] (43), [-0.14111,   inf] (39), [-0.14110,   inf] (41), [-0.14110,   inf] (37), [-0.14110,   inf] (23), [-0.14109,   inf] (55), [-0.14109,   inf] (55), [-0.14109,   inf] (29), [-0.14107,   inf] (39), [-0.14107,   inf] (27), [-0.14106,   inf] (49), [-0.14106,   inf] (51), [-0.14106,   inf] (25), [-0.14106,   inf] (53), [-0.14106,   inf] (53), [-0.14105,   inf] (31), [-0.14105,   inf] (19), [-0.14105,   inf] (37), [-0.14104,   inf] (51), 
length of domains: 8049
Total time: 2.3813	 pickout: 0.0812	 decision: 0.5183	 get_bound: 1.7438	 add_domain: 0.0379
Current lb:-0.14110562205314636
16096 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 91.76425290107727

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 139] [2, 83] [2, 149] [2, 83] [2, 11] [2, 229] [2, 15] [2, 15] [2, 128] [2, 149] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 46.54033660888672 with beta sum per layer: [0.0, 0.0, 791.8618774414062]
alpha/beta optimization time: 1.6181244850158691
This batch time : update_bounds func: 1.7544	 prepare: 0.0332	 bound: 1.6185	 transfer: 0.0760	 finalize: 0.0255
Accumulated time: update_bounds func: 75.9973	 prepare: 1.3748	 bound: 69.7667	 transfer: 0.0760	 finalize: 1.4190
batch bounding time:  1.7550058364868164
Current worst splitting domains [lb, ub] (depth):
[-0.14036,   inf] (57), [-0.14036,   inf] (31), [-0.14035,   inf] (47), [-0.14035,   inf] (35), [-0.14034,   inf] (25), [-0.14034,   inf] (59), [-0.14034,   inf] (33), [-0.14034,   inf] (53), [-0.14033,   inf] (53), [-0.14033,   inf] (35), [-0.14033,   inf] (15), [-0.14032,   inf] (27), [-0.14032,   inf] (35), [-0.14031,   inf] (49), [-0.14030,   inf] (35), [-0.14030,   inf] (57), [-0.14030,   inf] (53), [-0.14029,   inf] (27), [-0.14029,   inf] (59), [-0.14029,   inf] (37), 
length of domains: 8249
Total time: 2.1824	 pickout: 0.0829	 decision: 0.3067	 get_bound: 1.7557	 add_domain: 0.0372
Current lb:-0.14036309719085693
16496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 93.95169734954834

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 15] [2, 95] [2, 97] [2, 50] [2, 131] [2, 166] [2, 139] [2, 22] [2, 22] [2, 50] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 46.79507827758789 with beta sum per layer: [0.0, 0.0, 711.1048583984375]
alpha/beta optimization time: 1.6090216636657715
This batch time : update_bounds func: 1.7506	 prepare: 0.0330	 bound: 1.6093	 transfer: 0.0833	 finalize: 0.0238
Accumulated time: update_bounds func: 77.7478	 prepare: 1.4077	 bound: 71.3760	 transfer: 0.0833	 finalize: 1.4427
batch bounding time:  1.7512052059173584
Current worst splitting domains [lb, ub] (depth):
[-0.13970,   inf] (39), [-0.13969,   inf] (55), [-0.13969,   inf] (27), [-0.13969,   inf] (49), [-0.13968,   inf] (35), [-0.13968,   inf] (51), [-0.13967,   inf] (27), [-0.13967,   inf] (23), [-0.13966,   inf] (25), [-0.13966,   inf] (53), [-0.13966,   inf] (27), [-0.13966,   inf] (47), [-0.13965,   inf] (31), [-0.13965,   inf] (49), [-0.13965,   inf] (47), [-0.13964,   inf] (21), [-0.13964,   inf] (49), [-0.13963,   inf] (27), [-0.13961,   inf] (41), [-0.13961,   inf] (37), 
length of domains: 8449
Total time: 2.1757	 pickout: 0.0740	 decision: 0.3100	 get_bound: 1.7519	 add_domain: 0.0398
Current lb:-0.1396975964307785
16896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 96.13237142562866

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 149] [2, 145] [2, 131] [2, 75] [2, 128] [2, 22] [2, 34] [2, 229] [2, 34] [2, 145] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 46.41014099121094 with beta sum per layer: [0.0, 0.0, 750.7742309570312]
alpha/beta optimization time: 1.6031787395477295
This batch time : update_bounds func: 1.7458	 prepare: 0.0327	 bound: 1.6035	 transfer: 0.0835	 finalize: 0.0249
Accumulated time: update_bounds func: 79.4936	 prepare: 1.4404	 bound: 72.9795	 transfer: 0.0835	 finalize: 1.4677
batch bounding time:  1.7464189529418945
Current worst splitting domains [lb, ub] (depth):
[-0.13898,   inf] (35), [-0.13897,   inf] (37), [-0.13897,   inf] (49), [-0.13896,   inf] (31), [-0.13896,   inf] (29), [-0.13895,   inf] (47), [-0.13895,   inf] (43), [-0.13894,   inf] (57), [-0.13894,   inf] (23), [-0.13894,   inf] (33), [-0.13894,   inf] (53), [-0.13893,   inf] (45), [-0.13892,   inf] (41), [-0.13892,   inf] (63), [-0.13892,   inf] (17), [-0.13890,   inf] (39), [-0.13890,   inf] (25), [-0.13890,   inf] (45), [-0.13889,   inf] (55), [-0.13889,   inf] (29), 
length of domains: 8649
Total time: 2.3940	 pickout: 0.0738	 decision: 0.5337	 get_bound: 1.7472	 add_domain: 0.0393
Current lb:-0.13897822797298431
17296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 98.53129076957703

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 128] [2, 11] [2, 27] [2, 95] [2, 128] [2, 22] [2, 196] [2, 166] [2, 131] [2, 128] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 45.95999526977539 with beta sum per layer: [0.0, 0.0, 757.2616577148438]
alpha/beta optimization time: 1.597721815109253
This batch time : update_bounds func: 1.7451	 prepare: 0.0330	 bound: 1.5980	 transfer: 0.0881	 finalize: 0.0249
Accumulated time: update_bounds func: 81.2387	 prepare: 1.4734	 bound: 74.5775	 transfer: 0.0881	 finalize: 1.4925
batch bounding time:  1.7457804679870605
Current worst splitting domains [lb, ub] (depth):
[-0.13835,   inf] (35), [-0.13834,   inf] (55), [-0.13833,   inf] (27), [-0.13833,   inf] (51), [-0.13833,   inf] (27), [-0.13833,   inf] (23), [-0.13832,   inf] (35), [-0.13832,   inf] (23), [-0.13832,   inf] (51), [-0.13832,   inf] (37), [-0.13832,   inf] (53), [-0.13831,   inf] (51), [-0.13831,   inf] (47), [-0.13831,   inf] (43), [-0.13829,   inf] (47), [-0.13829,   inf] (55), [-0.13828,   inf] (27), [-0.13827,   inf] (53), [-0.13827,   inf] (31), [-0.13827,   inf] (53), 
length of domains: 8849
Total time: 2.1654	 pickout: 0.0759	 decision: 0.3049	 get_bound: 1.7465	 add_domain: 0.0380
Current lb:-0.138345405459404
17696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 100.70173263549805

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 50] [2, 75] [2, 131] [2, 75] [2, 131] [2, 7] [2, 11] [2, 229] [2, 97] [2, 196] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 45.99334716796875 with beta sum per layer: [0.0, 0.0, 750.8096313476562]
alpha/beta optimization time: 1.600816249847412
This batch time : update_bounds func: 1.7473	 prepare: 0.0328	 bound: 1.6011	 transfer: 0.0861	 finalize: 0.0260
Accumulated time: update_bounds func: 82.9860	 prepare: 1.5062	 bound: 76.1787	 transfer: 0.0861	 finalize: 1.5186
batch bounding time:  1.7478892803192139
Current worst splitting domains [lb, ub] (depth):
[-0.13771,   inf] (47), [-0.13771,   inf] (63), [-0.13771,   inf] (25), [-0.13771,   inf] (39), [-0.13771,   inf] (51), [-0.13771,   inf] (31), [-0.13770,   inf] (51), [-0.13770,   inf] (57), [-0.13770,   inf] (51), [-0.13770,   inf] (29), [-0.13770,   inf] (55), [-0.13770,   inf] (45), [-0.13769,   inf] (33), [-0.13769,   inf] (31), [-0.13769,   inf] (33), [-0.13768,   inf] (33), [-0.13768,   inf] (21), [-0.13768,   inf] (51), [-0.13767,   inf] (45), [-0.13767,   inf] (29), 
length of domains: 9049
Total time: 2.1657	 pickout: 0.0726	 decision: 0.3043	 get_bound: 1.7487	 add_domain: 0.0401
Current lb:-0.13771498203277588
18096 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 102.87299418449402

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 97] [2, 157] [2, 7] [2, 149] [2, 27] [2, 95] [2, 145] [2, 166] [2, 27] [2, 34] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 45.914520263671875 with beta sum per layer: [0.0, 0.0, 739.6263427734375]
alpha/beta optimization time: 1.609623908996582
This batch time : update_bounds func: 1.7564	 prepare: 0.0330	 bound: 1.6100	 transfer: 0.0840	 finalize: 0.0282
Accumulated time: update_bounds func: 84.7424	 prepare: 1.5392	 bound: 77.7886	 transfer: 0.0840	 finalize: 1.5468
batch bounding time:  1.7572486400604248
Current worst splitting domains [lb, ub] (depth):
[-0.13708,   inf] (53), [-0.13708,   inf] (39), [-0.13708,   inf] (23), [-0.13707,   inf] (35), [-0.13706,   inf] (35), [-0.13706,   inf] (39), [-0.13705,   inf] (51), [-0.13704,   inf] (45), [-0.13703,   inf] (57), [-0.13703,   inf] (23), [-0.13703,   inf] (25), [-0.13703,   inf] (29), [-0.13702,   inf] (47), [-0.13702,   inf] (43), [-0.13702,   inf] (27), [-0.13701,   inf] (29), [-0.13701,   inf] (47), [-0.13701,   inf] (31), [-0.13701,   inf] (45), [-0.13701,   inf] (33), 
length of domains: 9249
Total time: 2.4909	 pickout: 0.0754	 decision: 0.3091	 get_bound: 1.7583	 add_domain: 0.3481
Current lb:-0.1370786875486374
18496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 105.368980884552

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 22] [2, 149] [2, 7] [2, 50] [2, 128] [2, 149] [2, 27] [2, 92] [2, 22] [2, 131] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 45.235313415527344 with beta sum per layer: [0.0, 0.0, 748.57568359375]
alpha/beta optimization time: 1.628648281097412
This batch time : update_bounds func: 1.7715	 prepare: 0.0329	 bound: 1.6290	 transfer: 0.0838	 finalize: 0.0246
Accumulated time: update_bounds func: 86.5139	 prepare: 1.5721	 bound: 79.4176	 transfer: 0.0838	 finalize: 1.5714
batch bounding time:  1.7721238136291504
Current worst splitting domains [lb, ub] (depth):
[-0.13643,   inf] (37), [-0.13643,   inf] (53), [-0.13643,   inf] (61), [-0.13642,   inf] (49), [-0.13642,   inf] (55), [-0.13642,   inf] (51), [-0.13642,   inf] (63), [-0.13641,   inf] (35), [-0.13641,   inf] (49), [-0.13641,   inf] (41), [-0.13641,   inf] (57), [-0.13641,   inf] (33), [-0.13641,   inf] (31), [-0.13640,   inf] (35), [-0.13640,   inf] (29), [-0.13640,   inf] (53), [-0.13640,   inf] (39), [-0.13639,   inf] (39), [-0.13639,   inf] (27), [-0.13639,   inf] (37), 
length of domains: 9449
Total time: 2.2029	 pickout: 0.0813	 decision: 0.3092	 get_bound: 1.7729	 add_domain: 0.0394
Current lb:-0.13642852008342743
18896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 107.57700324058533

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 11] [2, 27] [2, 248] [2, 75] [2, 75] [2, 27] [2, 171] [2, 128] [2, 92] [2, 149] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 44.52855682373047 with beta sum per layer: [0.0, 0.0, 777.2601928710938]
alpha/beta optimization time: 1.6061196327209473
This batch time : update_bounds func: 1.7417	 prepare: 0.0330	 bound: 1.6066	 transfer: 0.0759	 finalize: 0.0250
Accumulated time: update_bounds func: 88.2556	 prepare: 1.6051	 bound: 81.0242	 transfer: 0.0759	 finalize: 1.5963
batch bounding time:  1.7423758506774902
Current worst splitting domains [lb, ub] (depth):
[-0.13587,   inf] (39), [-0.13587,   inf] (17), [-0.13587,   inf] (23), [-0.13586,   inf] (21), [-0.13586,   inf] (47), [-0.13586,   inf] (57), [-0.13585,   inf] (29), [-0.13585,   inf] (55), [-0.13585,   inf] (27), [-0.13585,   inf] (45), [-0.13585,   inf] (41), [-0.13584,   inf] (47), [-0.13584,   inf] (49), [-0.13584,   inf] (21), [-0.13584,   inf] (33), [-0.13583,   inf] (25), [-0.13583,   inf] (31), [-0.13582,   inf] (25), [-0.13582,   inf] (29), [-0.13581,   inf] (49), 
length of domains: 9649
Total time: 2.1576	 pickout: 0.0721	 decision: 0.3043	 get_bound: 1.7431	 add_domain: 0.0381
Current lb:-0.13586939871311188
19296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 109.73969078063965

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 149] [2, 117] [2, 7] [2, 229] [2, 22] [2, 145] [2, 50] [2, 15] [2, 131] [2, 83] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 45.14642333984375 with beta sum per layer: [0.0, 0.0, 740.2720947265625]
alpha/beta optimization time: 1.6061160564422607
This batch time : update_bounds func: 1.7491	 prepare: 0.0330	 bound: 1.6064	 transfer: 0.0833	 finalize: 0.0252
Accumulated time: update_bounds func: 90.0047	 prepare: 1.6380	 bound: 82.6307	 transfer: 0.0833	 finalize: 1.6215
batch bounding time:  1.7496707439422607
Current worst splitting domains [lb, ub] (depth):
[-0.13534,   inf] (39), [-0.13534,   inf] (31), [-0.13534,   inf] (43), [-0.13534,   inf] (39), [-0.13534,   inf] (25), [-0.13533,   inf] (25), [-0.13533,   inf] (29), [-0.13532,   inf] (47), [-0.13532,   inf] (17), [-0.13531,   inf] (39), [-0.13531,   inf] (31), [-0.13531,   inf] (55), [-0.13530,   inf] (33), [-0.13530,   inf] (39), [-0.13530,   inf] (15), [-0.13530,   inf] (37), [-0.13529,   inf] (37), [-0.13529,   inf] (53), [-0.13527,   inf] (45), [-0.13527,   inf] (53), 
length of domains: 9849
Total time: 2.1783	 pickout: 0.0808	 decision: 0.3086	 get_bound: 1.7504	 add_domain: 0.0385
Current lb:-0.1353445202112198
19696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 111.92320942878723

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 149] [2, 95] [2, 196] [2, 149] [2, 34] [2, 131] [2, 50] [2, 83] [2, 7] [2, 149] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 44.69972229003906 with beta sum per layer: [0.0, 0.0, 785.664794921875]
alpha/beta optimization time: 1.6025855541229248
This batch time : update_bounds func: 1.7364	 prepare: 0.0329	 bound: 1.6029	 transfer: 0.0753	 finalize: 0.0242
Accumulated time: update_bounds func: 91.7411	 prepare: 1.6709	 bound: 84.2336	 transfer: 0.0753	 finalize: 1.6457
batch bounding time:  1.7370460033416748
Current worst splitting domains [lb, ub] (depth):
[-0.13478,   inf] (19), [-0.13477,   inf] (55), [-0.13477,   inf] (33), [-0.13477,   inf] (39), [-0.13477,   inf] (43), [-0.13477,   inf] (45), [-0.13477,   inf] (31), [-0.13476,   inf] (41), [-0.13476,   inf] (47), [-0.13476,   inf] (31), [-0.13476,   inf] (23), [-0.13475,   inf] (37), [-0.13475,   inf] (29), [-0.13475,   inf] (47), [-0.13474,   inf] (31), [-0.13474,   inf] (65), [-0.13474,   inf] (37), [-0.13474,   inf] (25), [-0.13473,   inf] (31), [-0.13473,   inf] (39), 
length of domains: 10049
Total time: 2.4387	 pickout: 0.0712	 decision: 0.5898	 get_bound: 1.7378	 add_domain: 0.0399
Current lb:-0.13477522134780884
20096 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 114.36689019203186

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 234] [2, 15] [2, 50] [2, 149] [2, 92] [2, 92] [2, 95] [2, 92] [2, 97] [2, 95] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 44.86513900756836 with beta sum per layer: [0.0, 0.0, 757.822021484375]
alpha/beta optimization time: 1.6016132831573486
This batch time : update_bounds func: 1.7363	 prepare: 0.0329	 bound: 1.6019	 transfer: 0.0759	 finalize: 0.0245
Accumulated time: update_bounds func: 93.4774	 prepare: 1.7038	 bound: 85.8355	 transfer: 0.0759	 finalize: 1.6701
batch bounding time:  1.7369952201843262
Current worst splitting domains [lb, ub] (depth):
[-0.13429,   inf] (53), [-0.13429,   inf] (27), [-0.13429,   inf] (15), [-0.13428,   inf] (41), [-0.13428,   inf] (27), [-0.13427,   inf] (17), [-0.13427,   inf] (21), [-0.13427,   inf] (37), [-0.13427,   inf] (51), [-0.13427,   inf] (61), [-0.13426,   inf] (45), [-0.13426,   inf] (61), [-0.13426,   inf] (37), [-0.13426,   inf] (41), [-0.13426,   inf] (49), [-0.13425,   inf] (63), [-0.13425,   inf] (55), [-0.13425,   inf] (51), [-0.13425,   inf] (35), [-0.13425,   inf] (29), 
length of domains: 10249
Total time: 2.1597	 pickout: 0.0757	 decision: 0.3055	 get_bound: 1.7378	 add_domain: 0.0407
Current lb:-0.13429419696331024
20496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 116.53188300132751

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 145] [2, 131] [2, 163] [2, 83] [2, 50] [2, 117] [2, 229] [2, 11] [2, 97] [2, 214] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 44.129051208496094 with beta sum per layer: [0.0, 0.0, 744.0592651367188]
alpha/beta optimization time: 1.6019566059112549
This batch time : update_bounds func: 1.7453	 prepare: 0.0329	 bound: 1.6023	 transfer: 0.0837	 finalize: 0.0252
Accumulated time: update_bounds func: 95.2227	 prepare: 1.7366	 bound: 87.4378	 transfer: 0.0837	 finalize: 1.6953
batch bounding time:  1.7459843158721924
Current worst splitting domains [lb, ub] (depth):
[-0.13378,   inf] (27), [-0.13377,   inf] (27), [-0.13377,   inf] (45), [-0.13377,   inf] (41), [-0.13377,   inf] (29), [-0.13377,   inf] (65), [-0.13376,   inf] (51), [-0.13376,   inf] (31), [-0.13376,   inf] (29), [-0.13375,   inf] (39), [-0.13375,   inf] (29), [-0.13375,   inf] (27), [-0.13374,   inf] (21), [-0.13374,   inf] (27), [-0.13374,   inf] (49), [-0.13373,   inf] (33), [-0.13373,   inf] (23), [-0.13373,   inf] (55), [-0.13373,   inf] (29), [-0.13373,   inf] (51), 
length of domains: 10449
Total time: 2.1582	 pickout: 0.0691	 decision: 0.3045	 get_bound: 1.7468	 add_domain: 0.0378
Current lb:-0.1337779462337494
20896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 118.69519877433777

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 131] [2, 131] [2, 92] [2, 196] [2, 139] [2, 108] [2, 22] [2, 95] [2, 50] [2, 149] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 43.776893615722656 with beta sum per layer: [0.0, 0.0, 795.26123046875]
alpha/beta optimization time: 1.6046478748321533
This batch time : update_bounds func: 1.7485	 prepare: 0.0329	 bound: 1.6050	 transfer: 0.0837	 finalize: 0.0257
Accumulated time: update_bounds func: 96.9712	 prepare: 1.7696	 bound: 89.0427	 transfer: 0.0837	 finalize: 1.7211
batch bounding time:  1.7491188049316406
Current worst splitting domains [lb, ub] (depth):
[-0.13320,   inf] (27), [-0.13320,   inf] (41), [-0.13320,   inf] (53), [-0.13319,   inf] (55), [-0.13319,   inf] (47), [-0.13319,   inf] (27), [-0.13318,   inf] (51), [-0.13318,   inf] (25), [-0.13318,   inf] (53), [-0.13318,   inf] (59), [-0.13317,   inf] (29), [-0.13317,   inf] (29), [-0.13317,   inf] (47), [-0.13316,   inf] (57), [-0.13316,   inf] (53), [-0.13316,   inf] (39), [-0.13316,   inf] (41), [-0.13316,   inf] (15), [-0.13316,   inf] (31), [-0.13316,   inf] (53), 
length of domains: 10649
Total time: 2.1772	 pickout: 0.0840	 decision: 0.3054	 get_bound: 1.7498	 add_domain: 0.0380
Current lb:-0.13320013880729675
21296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 120.87771487236023

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 131] [2, 196] [2, 145] [2, 145] [2, 97] [2, 131] [2, 27] [2, 34] [2, 75] [2, 145] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 43.70718002319336 with beta sum per layer: [0.0, 0.0, 782.1553955078125]
alpha/beta optimization time: 1.5999798774719238
This batch time : update_bounds func: 1.7361	 prepare: 0.0328	 bound: 1.6003	 transfer: 0.0775	 finalize: 0.0243
Accumulated time: update_bounds func: 98.7073	 prepare: 1.8024	 bound: 90.6430	 transfer: 0.0775	 finalize: 1.7454
batch bounding time:  1.7367513179779053
Current worst splitting domains [lb, ub] (depth):
[-0.13271,   inf] (43), [-0.13270,   inf] (45), [-0.13270,   inf] (35), [-0.13270,   inf] (35), [-0.13270,   inf] (45), [-0.13269,   inf] (23), [-0.13269,   inf] (57), [-0.13269,   inf] (33), [-0.13269,   inf] (57), [-0.13269,   inf] (57), [-0.13269,   inf] (39), [-0.13269,   inf] (19), [-0.13268,   inf] (35), [-0.13268,   inf] (45), [-0.13268,   inf] (33), [-0.13267,   inf] (55), [-0.13267,   inf] (47), [-0.13267,   inf] (51), [-0.13267,   inf] (39), [-0.13267,   inf] (43), 
length of domains: 10849
Total time: 2.4637	 pickout: 0.0841	 decision: 0.6011	 get_bound: 1.7375	 add_domain: 0.0410
Current lb:-0.1327054351568222
21696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 123.34669280052185

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 92] [2, 97] [2, 128] [2, 139] [2, 83] [2, 7] [2, 15] [2, 50] [2, 166] [2, 15] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 43.56831741333008 with beta sum per layer: [0.0, 0.0, 770.0528564453125]
alpha/beta optimization time: 1.6183717250823975
This batch time : update_bounds func: 1.7537	 prepare: 0.0332	 bound: 1.6187	 transfer: 0.0761	 finalize: 0.0245
Accumulated time: update_bounds func: 100.4610	 prepare: 1.8356	 bound: 92.2617	 transfer: 0.0761	 finalize: 1.7699
batch bounding time:  1.7543716430664062
Current worst splitting domains [lb, ub] (depth):
[-0.13222,   inf] (29), [-0.13221,   inf] (57), [-0.13221,   inf] (41), [-0.13221,   inf] (27), [-0.13221,   inf] (25), [-0.13221,   inf] (27), [-0.13221,   inf] (47), [-0.13221,   inf] (29), [-0.13220,   inf] (33), [-0.13220,   inf] (23), [-0.13220,   inf] (27), [-0.13220,   inf] (35), [-0.13220,   inf] (39), [-0.13219,   inf] (33), [-0.13219,   inf] (57), [-0.13219,   inf] (39), [-0.13219,   inf] (39), [-0.13218,   inf] (39), [-0.13218,   inf] (23), [-0.13218,   inf] (39), 
length of domains: 11049
Total time: 2.1726	 pickout: 0.0698	 decision: 0.3071	 get_bound: 1.7551	 add_domain: 0.0406
Current lb:-0.13221555948257446
22096 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 125.52454686164856

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 139] [2, 166] [2, 196] [2, 139] [2, 131] [2, 131] [2, 145] [2, 34] [2, 50] [2, 131] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 43.351539611816406 with beta sum per layer: [0.0, 0.0, 755.6385498046875]
alpha/beta optimization time: 1.6190474033355713
This batch time : update_bounds func: 1.7621	 prepare: 0.0329	 bound: 1.6194	 transfer: 0.0834	 finalize: 0.0252
Accumulated time: update_bounds func: 102.2231	 prepare: 1.8685	 bound: 93.8811	 transfer: 0.0834	 finalize: 1.7951
batch bounding time:  1.7628064155578613
Current worst splitting domains [lb, ub] (depth):
[-0.13173,   inf] (37), [-0.13173,   inf] (43), [-0.13173,   inf] (39), [-0.13173,   inf] (29), [-0.13172,   inf] (39), [-0.13172,   inf] (49), [-0.13172,   inf] (55), [-0.13172,   inf] (37), [-0.13172,   inf] (53), [-0.13171,   inf] (23), [-0.13171,   inf] (61), [-0.13171,   inf] (35), [-0.13170,   inf] (27), [-0.13170,   inf] (33), [-0.13170,   inf] (35), [-0.13170,   inf] (27), [-0.13170,   inf] (37), [-0.13169,   inf] (49), [-0.13168,   inf] (67), [-0.13168,   inf] (55), 
length of domains: 11249
Total time: 2.1886	 pickout: 0.0775	 decision: 0.3086	 get_bound: 1.7636	 add_domain: 0.0389
Current lb:-0.13173288106918335
22496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 127.71833229064941

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 11] [2, 196] [2, 149] [2, 128] [2, 149] [2, 97] [2, 97] [2, 11] [2, 27] [2, 7] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 43.14097595214844 with beta sum per layer: [0.0, 0.0, 730.648681640625]
alpha/beta optimization time: 1.603689193725586
This batch time : update_bounds func: 1.7391	 prepare: 0.0329	 bound: 1.6040	 transfer: 0.0755	 finalize: 0.0254
Accumulated time: update_bounds func: 103.9622	 prepare: 1.9014	 bound: 95.4851	 transfer: 0.0755	 finalize: 1.8205
batch bounding time:  1.7396934032440186
Current worst splitting domains [lb, ub] (depth):
[-0.13122,   inf] (45), [-0.13121,   inf] (45), [-0.13121,   inf] (27), [-0.13121,   inf] (27), [-0.13121,   inf] (39), [-0.13121,   inf] (29), [-0.13120,   inf] (25), [-0.13120,   inf] (51), [-0.13120,   inf] (43), [-0.13120,   inf] (27), [-0.13120,   inf] (29), [-0.13120,   inf] (37), [-0.13120,   inf] (41), [-0.13119,   inf] (55), [-0.13119,   inf] (29), [-0.13119,   inf] (29), [-0.13118,   inf] (53), [-0.13118,   inf] (67), [-0.13118,   inf] (29), [-0.13118,   inf] (43), 
length of domains: 11449
Total time: 2.1553	 pickout: 0.0666	 decision: 0.3084	 get_bound: 1.7404	 add_domain: 0.0399
Current lb:-0.13121642172336578
22896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 129.8789849281311

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 83] [2, 92] [2, 139] [2, 131] [2, 149] [2, 128] [2, 34] [2, 145] [2, 196] [2, 34] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 42.89313507080078 with beta sum per layer: [0.0, 0.0, 778.543212890625]
alpha/beta optimization time: 1.6029601097106934
This batch time : update_bounds func: 1.7453	 prepare: 0.0331	 bound: 1.6033	 transfer: 0.0833	 finalize: 0.0244
Accumulated time: update_bounds func: 105.7075	 prepare: 1.9345	 bound: 97.0884	 transfer: 0.0833	 finalize: 1.8449
batch bounding time:  1.746011734008789
Current worst splitting domains [lb, ub] (depth):
[-0.13074,   inf] (53), [-0.13074,   inf] (35), [-0.13074,   inf] (37), [-0.13074,   inf] (35), [-0.13073,   inf] (33), [-0.13073,   inf] (53), [-0.13073,   inf] (31), [-0.13073,   inf] (21), [-0.13073,   inf] (45), [-0.13073,   inf] (29), [-0.13073,   inf] (45), [-0.13073,   inf] (37), [-0.13072,   inf] (49), [-0.13072,   inf] (25), [-0.13072,   inf] (59), [-0.13072,   inf] (55), [-0.13071,   inf] (37), [-0.13071,   inf] (25), [-0.13071,   inf] (33), [-0.13071,   inf] (63), 
length of domains: 11649
Total time: 2.4964	 pickout: 0.0762	 decision: 0.6323	 get_bound: 1.7468	 add_domain: 0.0412
Current lb:-0.1307445466518402
23296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 132.38128328323364

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 145] [2, 128] [2, 11] [2, 139] [2, 139] [2, 145] [2, 95] [2, 101] [2, 92] [2, 50] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 43.04165267944336 with beta sum per layer: [0.0, 0.0, 797.7418212890625]
alpha/beta optimization time: 1.6027421951293945
This batch time : update_bounds func: 1.7455	 prepare: 0.0329	 bound: 1.6031	 transfer: 0.0837	 finalize: 0.0246
Accumulated time: update_bounds func: 107.4530	 prepare: 1.9674	 bound: 98.6914	 transfer: 0.0837	 finalize: 1.8695
batch bounding time:  1.7461199760437012
Current worst splitting domains [lb, ub] (depth):
[-0.13034,   inf] (41), [-0.13034,   inf] (31), [-0.13034,   inf] (35), [-0.13033,   inf] (45), [-0.13033,   inf] (39), [-0.13033,   inf] (29), [-0.13033,   inf] (43), [-0.13033,   inf] (27), [-0.13033,   inf] (71), [-0.13032,   inf] (45), [-0.13032,   inf] (27), [-0.13032,   inf] (57), [-0.13031,   inf] (33), [-0.13031,   inf] (63), [-0.13031,   inf] (59), [-0.13031,   inf] (33), [-0.13031,   inf] (59), [-0.13031,   inf] (31), [-0.13031,   inf] (41), [-0.13030,   inf] (19), 
length of domains: 11849
Total time: 2.1622	 pickout: 0.0678	 decision: 0.3061	 get_bound: 1.7469	 add_domain: 0.0415
Current lb:-0.13034191727638245
23696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 134.54937171936035

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 196] [2, 95] [2, 50] [2, 92] [2, 149] [2, 139] [2, 92] [2, 34] [2, 67] [2, 92] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 42.00010681152344 with beta sum per layer: [0.0, 0.0, 771.7894897460938]
alpha/beta optimization time: 1.6072697639465332
This batch time : update_bounds func: 1.7508	 prepare: 0.0329	 bound: 1.6076	 transfer: 0.0838	 finalize: 0.0253
Accumulated time: update_bounds func: 109.2038	 prepare: 2.0003	 bound: 100.2990	 transfer: 0.0838	 finalize: 1.8948
batch bounding time:  1.7514448165893555
Current worst splitting domains [lb, ub] (depth):
[-0.12992,   inf] (49), [-0.12992,   inf] (33), [-0.12992,   inf] (29), [-0.12991,   inf] (55), [-0.12991,   inf] (29), [-0.12991,   inf] (31), [-0.12991,   inf] (37), [-0.12991,   inf] (23), [-0.12990,   inf] (43), [-0.12989,   inf] (57), [-0.12989,   inf] (35), [-0.12989,   inf] (29), [-0.12989,   inf] (27), [-0.12989,   inf] (49), [-0.12989,   inf] (59), [-0.12989,   inf] (15), [-0.12989,   inf] (67), [-0.12988,   inf] (37), [-0.12988,   inf] (41), [-0.12988,   inf] (23), 
length of domains: 12049
Total time: 2.1649	 pickout: 0.0676	 decision: 0.3060	 get_bound: 1.7522	 add_domain: 0.0391
Current lb:-0.12991896271705627
24096 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 136.72003078460693

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 22] [2, 50] [2, 139] [2, 15] [2, 34] [2, 95] [2, 11] [2, 139] [2, 83] [2, 145] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 43.191314697265625 with beta sum per layer: [0.0, 0.0, 747.8135986328125]
alpha/beta optimization time: 1.6306829452514648
This batch time : update_bounds func: 1.7750	 prepare: 0.0331	 bound: 1.6310	 transfer: 0.0839	 finalize: 0.0257
Accumulated time: update_bounds func: 110.9788	 prepare: 2.0334	 bound: 101.9300	 transfer: 0.0839	 finalize: 1.9205
batch bounding time:  1.7756006717681885
Current worst splitting domains [lb, ub] (depth):
[-0.12947,   inf] (43), [-0.12946,   inf] (53), [-0.12946,   inf] (25), [-0.12946,   inf] (39), [-0.12946,   inf] (55), [-0.12945,   inf] (31), [-0.12945,   inf] (35), [-0.12945,   inf] (57), [-0.12945,   inf] (29), [-0.12945,   inf] (55), [-0.12945,   inf] (41), [-0.12944,   inf] (39), [-0.12944,   inf] (39), [-0.12944,   inf] (59), [-0.12944,   inf] (47), [-0.12944,   inf] (23), [-0.12944,   inf] (51), [-0.12944,   inf] (37), [-0.12944,   inf] (41), [-0.12943,   inf] (23), 
length of domains: 12249
Total time: 2.2018	 pickout: 0.0730	 decision: 0.3131	 get_bound: 1.7763	 add_domain: 0.0393
Current lb:-0.12946704030036926
24496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 138.92721819877625

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 92] [2, 145] [2, 131] [2, 149] [2, 27] [2, 95] [2, 128] [2, 75] [2, 34] [2, 15] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 42.45500183105469 with beta sum per layer: [0.0, 0.0, 777.4320068359375]
alpha/beta optimization time: 1.5998964309692383
This batch time : update_bounds func: 1.7537	 prepare: 0.0514	 bound: 1.6002	 transfer: 0.0756	 finalize: 0.0245
Accumulated time: update_bounds func: 112.7324	 prepare: 2.0848	 bound: 103.5303	 transfer: 0.0756	 finalize: 1.9450
batch bounding time:  1.7543137073516846
Current worst splitting domains [lb, ub] (depth):
[-0.12908,   inf] (33), [-0.12908,   inf] (33), [-0.12908,   inf] (49), [-0.12908,   inf] (35), [-0.12907,   inf] (37), [-0.12907,   inf] (57), [-0.12907,   inf] (37), [-0.12907,   inf] (37), [-0.12907,   inf] (31), [-0.12907,   inf] (41), [-0.12906,   inf] (49), [-0.12906,   inf] (55), [-0.12906,   inf] (39), [-0.12906,   inf] (45), [-0.12906,   inf] (37), [-0.12905,   inf] (39), [-0.12905,   inf] (23), [-0.12905,   inf] (67), [-0.12905,   inf] (55), [-0.12904,   inf] (45), 
length of domains: 12449
Total time: 2.5330	 pickout: 0.0637	 decision: 0.6728	 get_bound: 1.7551	 add_domain: 0.0414
Current lb:-0.1290808469057083
24896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 141.4657461643219

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 50] [2, 50] [2, 145] [2, 128] [2, 11] [2, 166] [2, 11] [2, 11] [2, 128] [2, 196] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 42.03758239746094 with beta sum per layer: [0.0, 0.0, 806.3248291015625]
alpha/beta optimization time: 1.6053214073181152
This batch time : update_bounds func: 1.7481	 prepare: 0.0329	 bound: 1.6056	 transfer: 0.0836	 finalize: 0.0248
Accumulated time: update_bounds func: 114.4805	 prepare: 2.1177	 bound: 105.1359	 transfer: 0.0836	 finalize: 1.9698
batch bounding time:  1.7487189769744873
Current worst splitting domains [lb, ub] (depth):
[-0.12869,   inf] (65), [-0.12869,   inf] (41), [-0.12869,   inf] (59), [-0.12869,   inf] (61), [-0.12869,   inf] (35), [-0.12868,   inf] (35), [-0.12868,   inf] (53), [-0.12867,   inf] (37), [-0.12867,   inf] (15), [-0.12867,   inf] (37), [-0.12867,   inf] (31), [-0.12866,   inf] (31), [-0.12866,   inf] (47), [-0.12866,   inf] (35), [-0.12866,   inf] (35), [-0.12865,   inf] (63), [-0.12865,   inf] (55), [-0.12865,   inf] (33), [-0.12865,   inf] (65), [-0.12865,   inf] (35), 
length of domains: 12649
Total time: 2.1711	 pickout: 0.0740	 decision: 0.3061	 get_bound: 1.7495	 add_domain: 0.0415
Current lb:-0.12869380414485931
25296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 143.6425166130066

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 171] [2, 196] [2, 166] [2, 214] [2, 128] [2, 50] [2, 145] [2, 11] [2, 163] [2, 11] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 42.08845520019531 with beta sum per layer: [0.0, 0.0, 806.7177734375]
alpha/beta optimization time: 1.6046500205993652
This batch time : update_bounds func: 1.7396	 prepare: 0.0329	 bound: 1.6050	 transfer: 0.0753	 finalize: 0.0252
Accumulated time: update_bounds func: 116.2201	 prepare: 2.1505	 bound: 106.7409	 transfer: 0.0753	 finalize: 1.9950
batch bounding time:  1.7402818202972412
Current worst splitting domains [lb, ub] (depth):
[-0.12823,   inf] (63), [-0.12823,   inf] (25), [-0.12823,   inf] (41), [-0.12823,   inf] (31), [-0.12823,   inf] (47), [-0.12823,   inf] (67), [-0.12822,   inf] (31), [-0.12822,   inf] (55), [-0.12822,   inf] (53), [-0.12821,   inf] (23), [-0.12821,   inf] (39), [-0.12821,   inf] (29), [-0.12820,   inf] (53), [-0.12820,   inf] (35), [-0.12820,   inf] (27), [-0.12820,   inf] (45), [-0.12819,   inf] (49), [-0.12819,   inf] (67), [-0.12819,   inf] (31), [-0.12819,   inf] (51), 
length of domains: 12849
Total time: 2.1511	 pickout: 0.0654	 decision: 0.3055	 get_bound: 1.7410	 add_domain: 0.0392
Current lb:-0.12823373079299927
25696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 145.79935097694397

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 214] [2, 229] [2, 196] [2, 95] [2, 97] [2, 108] [2, 95] [2, 75] [2, 27] [2, 229] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 42.1119384765625 with beta sum per layer: [0.0, 0.0, 784.5474243164062]
alpha/beta optimization time: 1.6023752689361572
This batch time : update_bounds func: 1.7466	 prepare: 0.0334	 bound: 1.6027	 transfer: 0.0836	 finalize: 0.0257
Accumulated time: update_bounds func: 117.9667	 prepare: 2.1839	 bound: 108.3436	 transfer: 0.0836	 finalize: 2.0207
batch bounding time:  1.7472445964813232
Current worst splitting domains [lb, ub] (depth):
[-0.12779,   inf] (47), [-0.12779,   inf] (41), [-0.12779,   inf] (25), [-0.12779,   inf] (35), [-0.12779,   inf] (57), [-0.12779,   inf] (41), [-0.12778,   inf] (33), [-0.12778,   inf] (23), [-0.12778,   inf] (53), [-0.12777,   inf] (67), [-0.12777,   inf] (43), [-0.12777,   inf] (47), [-0.12777,   inf] (57), [-0.12777,   inf] (47), [-0.12777,   inf] (39), [-0.12776,   inf] (49), [-0.12776,   inf] (51), [-0.12776,   inf] (39), [-0.12776,   inf] (23), [-0.12775,   inf] (53), 
length of domains: 13049
Total time: 2.1696	 pickout: 0.0746	 decision: 0.3075	 get_bound: 1.7480	 add_domain: 0.0396
Current lb:-0.12779037654399872
26096 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 147.97423124313354

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 22] [2, 196] [2, 7] [2, 50] [2, 145] [2, 196] [2, 128] [2, 229] [2, 145] [2, 171] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 42.21861267089844 with beta sum per layer: [0.0, 0.0, 764.711181640625]
alpha/beta optimization time: 1.6002132892608643
This batch time : update_bounds func: 1.7422	 prepare: 0.0329	 bound: 1.6005	 transfer: 0.0832	 finalize: 0.0244
Accumulated time: update_bounds func: 119.7089	 prepare: 2.2168	 bound: 109.9441	 transfer: 0.0832	 finalize: 2.0451
batch bounding time:  1.7428746223449707
Current worst splitting domains [lb, ub] (depth):
[-0.12741,   inf] (27), [-0.12741,   inf] (63), [-0.12741,   inf] (61), [-0.12741,   inf] (37), [-0.12741,   inf] (35), [-0.12740,   inf] (37), [-0.12740,   inf] (35), [-0.12740,   inf] (27), [-0.12740,   inf] (37), [-0.12740,   inf] (39), [-0.12740,   inf] (37), [-0.12740,   inf] (47), [-0.12740,   inf] (49), [-0.12739,   inf] (19), [-0.12739,   inf] (47), [-0.12739,   inf] (41), [-0.12739,   inf] (51), [-0.12739,   inf] (41), [-0.12739,   inf] (33), [-0.12739,   inf] (41), 
length of domains: 13249
Total time: 2.5348	 pickout: 0.0697	 decision: 0.6798	 get_bound: 1.7437	 add_domain: 0.0417
Current lb:-0.1274142563343048
26496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 150.51431608200073

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 139] [2, 214] [2, 214] [2, 11] [2, 11] [2, 11] [2, 128] [2, 34] [2, 11] [2, 149] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 41.13501739501953 with beta sum per layer: [0.0, 0.0, 795.494873046875]
alpha/beta optimization time: 1.6024408340454102
This batch time : update_bounds func: 1.7224	 prepare: 0.0331	 bound: 1.6027	 transfer: 0.0604	 finalize: 0.0250
Accumulated time: update_bounds func: 121.4314	 prepare: 2.2499	 bound: 111.5469	 transfer: 0.0604	 finalize: 2.0701
batch bounding time:  1.7231006622314453
Current worst splitting domains [lb, ub] (depth):
[-0.12698,   inf] (67), [-0.12698,   inf] (27), [-0.12698,   inf] (49), [-0.12697,   inf] (37), [-0.12697,   inf] (21), [-0.12696,   inf] (55), [-0.12696,   inf] (49), [-0.12696,   inf] (35), [-0.12695,   inf] (33), [-0.12695,   inf] (43), [-0.12695,   inf] (33), [-0.12695,   inf] (55), [-0.12694,   inf] (69), [-0.12694,   inf] (55), [-0.12694,   inf] (45), [-0.12694,   inf] (55), [-0.12693,   inf] (55), [-0.12693,   inf] (49), [-0.12693,   inf] (33), [-0.12693,   inf] (37), 
length of domains: 13449
Total time: 2.1408	 pickout: 0.0691	 decision: 0.3067	 get_bound: 1.7239	 add_domain: 0.0411
Current lb:-0.12697820365428925
26896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 152.66106152534485

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 110] [2, 34] [2, 97] [2, 11] [2, 101] [2, 15] [2, 97] [2, 139] [2, 128] [2, 196] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 41.47643280029297 with beta sum per layer: [0.0, 0.0, 774.0628662109375]
alpha/beta optimization time: 1.6019110679626465
This batch time : update_bounds func: 1.7334	 prepare: 0.0330	 bound: 1.6022	 transfer: 0.0718	 finalize: 0.0252
Accumulated time: update_bounds func: 123.1648	 prepare: 2.2830	 bound: 113.1491	 transfer: 0.0718	 finalize: 2.0953
batch bounding time:  1.7340614795684814
Current worst splitting domains [lb, ub] (depth):
[-0.12651,   inf] (35), [-0.12651,   inf] (19), [-0.12651,   inf] (37), [-0.12651,   inf] (21), [-0.12651,   inf] (57), [-0.12650,   inf] (23), [-0.12650,   inf] (67), [-0.12650,   inf] (39), [-0.12650,   inf] (53), [-0.12649,   inf] (49), [-0.12649,   inf] (59), [-0.12649,   inf] (39), [-0.12649,   inf] (49), [-0.12649,   inf] (35), [-0.12649,   inf] (61), [-0.12648,   inf] (51), [-0.12648,   inf] (39), [-0.12648,   inf] (33), [-0.12648,   inf] (39), [-0.12648,   inf] (43), 
length of domains: 13649
Total time: 2.1468	 pickout: 0.0690	 decision: 0.3032	 get_bound: 1.7348	 add_domain: 0.0398
Current lb:-0.12651391327381134
27296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 154.81494450569153

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 128] [2, 234] [2, 11] [2, 101] [2, 166] [2, 7] [2, 171] [2, 149] [2, 145] [2, 22] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 41.42173767089844 with beta sum per layer: [0.0, 0.0, 789.3291015625]
alpha/beta optimization time: 1.6033051013946533
This batch time : update_bounds func: 1.7475	 prepare: 0.0331	 bound: 1.6036	 transfer: 0.0840	 finalize: 0.0256
Accumulated time: update_bounds func: 124.9123	 prepare: 2.3160	 bound: 114.7527	 transfer: 0.0840	 finalize: 2.1209
batch bounding time:  1.748161792755127
Current worst splitting domains [lb, ub] (depth):
[-0.12613,   inf] (61), [-0.12612,   inf] (55), [-0.12612,   inf] (27), [-0.12612,   inf] (49), [-0.12612,   inf] (27), [-0.12612,   inf] (21), [-0.12612,   inf] (37), [-0.12611,   inf] (29), [-0.12611,   inf] (41), [-0.12611,   inf] (43), [-0.12611,   inf] (29), [-0.12610,   inf] (47), [-0.12610,   inf] (33), [-0.12610,   inf] (27), [-0.12610,   inf] (39), [-0.12609,   inf] (57), [-0.12609,   inf] (47), [-0.12609,   inf] (21), [-0.12609,   inf] (51), [-0.12609,   inf] (61), 
length of domains: 13849
Total time: 2.1639	 pickout: 0.0667	 decision: 0.3085	 get_bound: 1.7489	 add_domain: 0.0397
Current lb:-0.12612608075141907
27696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 156.98418164253235

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 248] [2, 145] [2, 50] [2, 22] [2, 34] [2, 101] [2, 11] [2, 128] [2, 196] [2, 92] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 41.28514099121094 with beta sum per layer: [0.0, 0.0, 759.4297485351562]
alpha/beta optimization time: 1.6225359439849854
This batch time : update_bounds func: 1.7575	 prepare: 0.0333	 bound: 1.6229	 transfer: 0.0760	 finalize: 0.0241
Accumulated time: update_bounds func: 126.6699	 prepare: 2.3493	 bound: 116.3756	 transfer: 0.0760	 finalize: 2.1450
batch bounding time:  1.7582335472106934
Current worst splitting domains [lb, ub] (depth):
[-0.12571,   inf] (25), [-0.12571,   inf] (25), [-0.12571,   inf] (53), [-0.12571,   inf] (51), [-0.12571,   inf] (59), [-0.12571,   inf] (29), [-0.12571,   inf] (41), [-0.12570,   inf] (69), [-0.12570,   inf] (43), [-0.12570,   inf] (43), [-0.12570,   inf] (43), [-0.12569,   inf] (45), [-0.12569,   inf] (51), [-0.12569,   inf] (23), [-0.12569,   inf] (31), [-0.12568,   inf] (31), [-0.12568,   inf] (57), [-0.12568,   inf] (37), [-0.12567,   inf] (29), [-0.12567,   inf] (37), 
length of domains: 14049
Total time: 2.5806	 pickout: 0.0677	 decision: 0.3091	 get_bound: 1.7590	 add_domain: 0.4447
Current lb:-0.12571465969085693
28096 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 159.5702817440033

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 131] [2, 139] [2, 145] [2, 145] [2, 166] [2, 139] [2, 196] [2, 223] [2, 92] [2, 92] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 40.538516998291016 with beta sum per layer: [0.0, 0.0, 761.210205078125]
alpha/beta optimization time: 1.6004226207733154
This batch time : update_bounds func: 1.7437	 prepare: 0.0332	 bound: 1.6007	 transfer: 0.0836	 finalize: 0.0250
Accumulated time: update_bounds func: 128.4136	 prepare: 2.3825	 bound: 117.9763	 transfer: 0.0836	 finalize: 2.1700
batch bounding time:  1.744405746459961
Current worst splitting domains [lb, ub] (depth):
[-0.12536,   inf] (43), [-0.12536,   inf] (51), [-0.12536,   inf] (59), [-0.12535,   inf] (37), [-0.12535,   inf] (45), [-0.12535,   inf] (67), [-0.12535,   inf] (69), [-0.12535,   inf] (43), [-0.12535,   inf] (39), [-0.12535,   inf] (55), [-0.12535,   inf] (43), [-0.12535,   inf] (45), [-0.12535,   inf] (69), [-0.12534,   inf] (53), [-0.12534,   inf] (43), [-0.12534,   inf] (43), [-0.12534,   inf] (45), [-0.12533,   inf] (21), [-0.12533,   inf] (35), [-0.12533,   inf] (33), 
length of domains: 14249
Total time: 2.1633	 pickout: 0.0664	 decision: 0.3095	 get_bound: 1.7452	 add_domain: 0.0423
Current lb:-0.12535999715328217
28496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 161.7391300201416

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 92] [2, 22] [2, 166] [2, 11] [2, 83] [2, 171] [2, 67] [2, 83] [2, 149] [2, 15] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 40.96240234375 with beta sum per layer: [0.0, 0.0, 776.0413818359375]
alpha/beta optimization time: 1.6055567264556885
This batch time : update_bounds func: 1.7492	 prepare: 0.0332	 bound: 1.6059	 transfer: 0.0832	 finalize: 0.0256
Accumulated time: update_bounds func: 130.1628	 prepare: 2.4157	 bound: 119.5822	 transfer: 0.0832	 finalize: 2.1957
batch bounding time:  1.7498672008514404
Current worst splitting domains [lb, ub] (depth):
[-0.12499,   inf] (45), [-0.12499,   inf] (55), [-0.12499,   inf] (37), [-0.12499,   inf] (47), [-0.12499,   inf] (51), [-0.12498,   inf] (55), [-0.12498,   inf] (29), [-0.12498,   inf] (51), [-0.12498,   inf] (47), [-0.12498,   inf] (17), [-0.12497,   inf] (43), [-0.12497,   inf] (43), [-0.12497,   inf] (15), [-0.12497,   inf] (57), [-0.12497,   inf] (47), [-0.12497,   inf] (47), [-0.12496,   inf] (49), [-0.12496,   inf] (31), [-0.12496,   inf] (47), [-0.12496,   inf] (21), 
length of domains: 14449
Total time: 2.1619	 pickout: 0.0657	 decision: 0.3056	 get_bound: 1.7506	 add_domain: 0.0399
Current lb:-0.12499204277992249
28896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 163.90644717216492

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 97] [2, 15] [2, 11] [2, 97] [2, 27] [2, 22] [2, 139] [2, 27] [2, 22] [2, 117] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 41.005638122558594 with beta sum per layer: [0.0, 0.0, 791.130126953125]
alpha/beta optimization time: 1.6008684635162354
This batch time : update_bounds func: 1.7369	 prepare: 0.0331	 bound: 1.6012	 transfer: 0.0758	 finalize: 0.0256
Accumulated time: update_bounds func: 131.8997	 prepare: 2.4488	 bound: 121.1834	 transfer: 0.0758	 finalize: 2.2213
batch bounding time:  1.7375373840332031
Current worst splitting domains [lb, ub] (depth):
[-0.12462,   inf] (53), [-0.12462,   inf] (43), [-0.12461,   inf] (59), [-0.12461,   inf] (47), [-0.12461,   inf] (47), [-0.12461,   inf] (55), [-0.12461,   inf] (31), [-0.12460,   inf] (55), [-0.12460,   inf] (67), [-0.12460,   inf] (23), [-0.12460,   inf] (45), [-0.12460,   inf] (45), [-0.12460,   inf] (69), [-0.12459,   inf] (23), [-0.12459,   inf] (45), [-0.12459,   inf] (37), [-0.12459,   inf] (35), [-0.12459,   inf] (45), [-0.12459,   inf] (47), [-0.12459,   inf] (25), 
length of domains: 14649
Total time: 2.1533	 pickout: 0.0679	 decision: 0.3079	 get_bound: 1.7383	 add_domain: 0.0393
Current lb:-0.12461737543344498
29296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 166.06505513191223

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 166] [2, 92] [2, 145] [2, 22] [2, 97] [2, 27] [2, 95] [2, 15] [2, 157] [2, 229] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 40.159122467041016 with beta sum per layer: [0.0, 0.0, 759.9491577148438]
alpha/beta optimization time: 1.6037311553955078
This batch time : update_bounds func: 1.7467	 prepare: 0.0334	 bound: 1.6041	 transfer: 0.0839	 finalize: 0.0241
Accumulated time: update_bounds func: 133.6465	 prepare: 2.4823	 bound: 122.7875	 transfer: 0.0839	 finalize: 2.2455
batch bounding time:  1.7473783493041992
Current worst splitting domains [lb, ub] (depth):
[-0.12425,   inf] (49), [-0.12425,   inf] (55), [-0.12425,   inf] (27), [-0.12425,   inf] (35), [-0.12425,   inf] (31), [-0.12425,   inf] (29), [-0.12424,   inf] (29), [-0.12424,   inf] (47), [-0.12424,   inf] (33), [-0.12424,   inf] (55), [-0.12424,   inf] (63), [-0.12424,   inf] (61), [-0.12423,   inf] (23), [-0.12423,   inf] (61), [-0.12423,   inf] (59), [-0.12423,   inf] (25), [-0.12423,   inf] (59), [-0.12423,   inf] (39), [-0.12423,   inf] (27), [-0.12423,   inf] (17), 
length of domains: 14849
Total time: 2.1629	 pickout: 0.0645	 decision: 0.3065	 get_bound: 1.7482	 add_domain: 0.0437
Current lb:-0.12425471842288971
29696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 168.23344826698303

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 27] [2, 22] [2, 7] [2, 50] [2, 95] [2, 34] [2, 131] [2, 22] [2, 128] [2, 75] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 40.75542449951172 with beta sum per layer: [0.0, 0.0, 764.8460083007812]
alpha/beta optimization time: 1.5993049144744873
This batch time : update_bounds func: 2.1430	 prepare: 0.0330	 bound: 1.5996	 transfer: 0.0839	 finalize: 0.4253
Accumulated time: update_bounds func: 135.7895	 prepare: 2.5152	 bound: 124.3871	 transfer: 0.0839	 finalize: 2.6708
batch bounding time:  2.143711805343628
Current worst splitting domains [lb, ub] (depth):
[-0.12386,   inf] (37), [-0.12386,   inf] (35), [-0.12386,   inf] (39), [-0.12386,   inf] (31), [-0.12386,   inf] (27), [-0.12386,   inf] (47), [-0.12386,   inf] (57), [-0.12386,   inf] (17), [-0.12386,   inf] (47), [-0.12385,   inf] (43), [-0.12385,   inf] (49), [-0.12385,   inf] (35), [-0.12385,   inf] (55), [-0.12385,   inf] (47), [-0.12385,   inf] (43), [-0.12384,   inf] (45), [-0.12384,   inf] (33), [-0.12384,   inf] (45), [-0.12384,   inf] (55), [-0.12384,   inf] (49), 
length of domains: 15049
Total time: 2.5601	 pickout: 0.0651	 decision: 0.3080	 get_bound: 2.1445	 add_domain: 0.0425
Current lb:-0.12386425584554672
30096 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 170.7989525794983

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 11] [2, 128] [2, 149] [2, 95] [2, 131] [2, 27] [2, 145] [2, 117] [2, 22] [2, 97] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 40.3192138671875 with beta sum per layer: [0.0, 0.0, 776.7421875]
alpha/beta optimization time: 1.6073098182678223
This batch time : update_bounds func: 1.7536	 prepare: 0.0331	 bound: 1.6076	 transfer: 0.0846	 finalize: 0.0270
Accumulated time: update_bounds func: 137.5430	 prepare: 2.5483	 bound: 125.9947	 transfer: 0.0846	 finalize: 2.6978
batch bounding time:  1.7542436122894287
Current worst splitting domains [lb, ub] (depth):
[-0.12354,   inf] (37), [-0.12354,   inf] (27), [-0.12354,   inf] (43), [-0.12354,   inf] (53), [-0.12353,   inf] (41), [-0.12353,   inf] (45), [-0.12353,   inf] (53), [-0.12353,   inf] (37), [-0.12353,   inf] (41), [-0.12352,   inf] (55), [-0.12352,   inf] (67), [-0.12352,   inf] (29), [-0.12352,   inf] (67), [-0.12352,   inf] (31), [-0.12351,   inf] (37), [-0.12351,   inf] (31), [-0.12351,   inf] (53), [-0.12351,   inf] (31), [-0.12350,   inf] (55), [-0.12350,   inf] (37), 
length of domains: 15249
Total time: 2.1694	 pickout: 0.0659	 decision: 0.3075	 get_bound: 1.7550	 add_domain: 0.0409
Current lb:-0.12354329228401184
30496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 172.9741542339325

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 11] [2, 139] [2, 83] [2, 27] [2, 11] [2, 92] [2, 166] [2, 11] [2, 196] [2, 166] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 40.306640625 with beta sum per layer: [0.0, 0.0, 760.589111328125]
alpha/beta optimization time: 1.6247899532318115
This batch time : update_bounds func: 1.7784	 prepare: 0.0331	 bound: 1.6251	 transfer: 0.0809	 finalize: 0.0381
Accumulated time: update_bounds func: 139.3214	 prepare: 2.5814	 bound: 127.6199	 transfer: 0.0809	 finalize: 2.7358
batch bounding time:  1.7790782451629639
Current worst splitting domains [lb, ub] (depth):
[-0.12315,   inf] (57), [-0.12315,   inf] (29), [-0.12315,   inf] (47), [-0.12315,   inf] (59), [-0.12315,   inf] (35), [-0.12315,   inf] (39), [-0.12314,   inf] (35), [-0.12314,   inf] (27), [-0.12314,   inf] (61), [-0.12314,   inf] (49), [-0.12314,   inf] (63), [-0.12314,   inf] (49), [-0.12314,   inf] (57), [-0.12314,   inf] (63), [-0.12313,   inf] (39), [-0.12313,   inf] (71), [-0.12313,   inf] (47), [-0.12313,   inf] (39), [-0.12313,   inf] (47), [-0.12312,   inf] (43), 
length of domains: 15449
Total time: 2.2043	 pickout: 0.0705	 decision: 0.3114	 get_bound: 1.7799	 add_domain: 0.0425
Current lb:-0.12315412610769272
30896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 175.18381762504578

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 27] [2, 34] [2, 27] [2, 75] [2, 139] [2, 149] [2, 128] [2, 131] [2, 248] [2, 97] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 39.683746337890625 with beta sum per layer: [0.0, 0.0, 800.444091796875]
alpha/beta optimization time: 1.6013872623443604
This batch time : update_bounds func: 1.7639	 prepare: 0.0527	 bound: 1.6018	 transfer: 0.0840	 finalize: 0.0243
Accumulated time: update_bounds func: 141.0853	 prepare: 2.6341	 bound: 129.2216	 transfer: 0.0840	 finalize: 2.7601
batch bounding time:  1.7646708488464355
Current worst splitting domains [lb, ub] (depth):
[-0.12284,   inf] (41), [-0.12284,   inf] (43), [-0.12284,   inf] (31), [-0.12283,   inf] (29), [-0.12283,   inf] (39), [-0.12283,   inf] (39), [-0.12282,   inf] (47), [-0.12282,   inf] (33), [-0.12282,   inf] (49), [-0.12282,   inf] (63), [-0.12282,   inf] (41), [-0.12282,   inf] (39), [-0.12281,   inf] (19), [-0.12281,   inf] (55), [-0.12281,   inf] (61), [-0.12280,   inf] (43), [-0.12280,   inf] (31), [-0.12280,   inf] (39), [-0.12279,   inf] (23), [-0.12279,   inf] (51), 
length of domains: 15649
Total time: 2.2331	 pickout: 0.0847	 decision: 0.3391	 get_bound: 1.7655	 add_domain: 0.0438
Current lb:-0.12283900380134583
31296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 177.42266631126404

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 196] [2, 196] [2, 95] [2, 131] [2, 149] [2, 149] [2, 97] [2, 139] [2, 145] [2, 171] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 39.781036376953125 with beta sum per layer: [0.0, 0.0, 805.3638916015625]
alpha/beta optimization time: 1.6035897731781006
This batch time : update_bounds func: 1.7389	 prepare: 0.0332	 bound: 1.6039	 transfer: 0.0758	 finalize: 0.0248
Accumulated time: update_bounds func: 142.8243	 prepare: 2.6673	 bound: 130.8255	 transfer: 0.0758	 finalize: 2.7849
batch bounding time:  1.7395620346069336
Current worst splitting domains [lb, ub] (depth):
[-0.12248,   inf] (53), [-0.12248,   inf] (45), [-0.12248,   inf] (29), [-0.12247,   inf] (51), [-0.12247,   inf] (51), [-0.12247,   inf] (43), [-0.12247,   inf] (45), [-0.12246,   inf] (29), [-0.12246,   inf] (53), [-0.12246,   inf] (41), [-0.12246,   inf] (33), [-0.12245,   inf] (47), [-0.12245,   inf] (31), [-0.12245,   inf] (49), [-0.12245,   inf] (27), [-0.12244,   inf] (37), [-0.12244,   inf] (67), [-0.12244,   inf] (59), [-0.12244,   inf] (43), [-0.12244,   inf] (41), 
length of domains: 15849
Total time: 2.1613	 pickout: 0.0700	 decision: 0.3084	 get_bound: 1.7403	 add_domain: 0.0426
Current lb:-0.12248240411281586
31696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 179.58952140808105

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 75] [2, 97] [2, 128] [2, 75] [2, 97] [2, 196] [2, 97] [2, 139] [2, 145] [2, 149] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 39.82149124145508 with beta sum per layer: [0.0, 0.0, 778.6568603515625]
alpha/beta optimization time: 1.6018428802490234
This batch time : update_bounds func: 2.1936	 prepare: 0.0332	 bound: 1.6022	 transfer: 0.0757	 finalize: 0.4813
Accumulated time: update_bounds func: 145.0179	 prepare: 2.7005	 bound: 132.4277	 transfer: 0.0757	 finalize: 3.2662
batch bounding time:  2.1944031715393066
Current worst splitting domains [lb, ub] (depth):
[-0.12216,   inf] (41), [-0.12216,   inf] (55), [-0.12216,   inf] (29), [-0.12215,   inf] (33), [-0.12215,   inf] (47), [-0.12215,   inf] (45), [-0.12215,   inf] (53), [-0.12215,   inf] (47), [-0.12215,   inf] (21), [-0.12215,   inf] (47), [-0.12215,   inf] (29), [-0.12214,   inf] (31), [-0.12214,   inf] (37), [-0.12214,   inf] (31), [-0.12214,   inf] (57), [-0.12214,   inf] (31), [-0.12214,   inf] (31), [-0.12214,   inf] (31), [-0.12213,   inf] (39), [-0.12213,   inf] (57), 
length of domains: 16049
Total time: 2.6216	 pickout: 0.0798	 decision: 0.3065	 get_bound: 2.1952	 add_domain: 0.0401
Current lb:-0.12215844541788101
32096 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 182.21669268608093

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 196] [2, 75] [2, 139] [2, 139] [2, 22] [2, 92] [2, 97] [2, 97] [2, 34] [2, 22] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 40.05488586425781 with beta sum per layer: [0.0, 0.0, 784.6150512695312]
alpha/beta optimization time: 1.5998899936676025
This batch time : update_bounds func: 1.7444	 prepare: 0.0330	 bound: 1.6002	 transfer: 0.0836	 finalize: 0.0263
Accumulated time: update_bounds func: 146.7623	 prepare: 2.7335	 bound: 134.0279	 transfer: 0.0836	 finalize: 3.2925
batch bounding time:  1.7449870109558105
Current worst splitting domains [lb, ub] (depth):
[-0.12183,   inf] (35), [-0.12183,   inf] (55), [-0.12183,   inf] (41), [-0.12183,   inf] (39), [-0.12182,   inf] (57), [-0.12182,   inf] (27), [-0.12182,   inf] (67), [-0.12182,   inf] (25), [-0.12182,   inf] (37), [-0.12182,   inf] (53), [-0.12182,   inf] (61), [-0.12181,   inf] (43), [-0.12181,   inf] (37), [-0.12181,   inf] (53), [-0.12181,   inf] (41), [-0.12181,   inf] (59), [-0.12181,   inf] (31), [-0.12181,   inf] (31), [-0.12181,   inf] (55), [-0.12181,   inf] (49), 
length of domains: 16249
Total time: 2.1754	 pickout: 0.0794	 decision: 0.3091	 get_bound: 1.7457	 add_domain: 0.0412
Current lb:-0.12183240801095963
32496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 184.39809155464172

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 11] [2, 15] [2, 196] [2, 149] [2, 166] [2, 34] [2, 110] [2, 229] [2, 11] [2, 145] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 39.486122131347656 with beta sum per layer: [0.0, 0.0, 758.6343994140625]
alpha/beta optimization time: 1.6005887985229492
This batch time : update_bounds func: 1.7435	 prepare: 0.0333	 bound: 1.6009	 transfer: 0.0839	 finalize: 0.0242
Accumulated time: update_bounds func: 148.5057	 prepare: 2.7668	 bound: 135.6288	 transfer: 0.0839	 finalize: 3.3167
batch bounding time:  1.744124412536621
Current worst splitting domains [lb, ub] (depth):
[-0.12150,   inf] (27), [-0.12150,   inf] (45), [-0.12150,   inf] (51), [-0.12150,   inf] (57), [-0.12149,   inf] (33), [-0.12149,   inf] (43), [-0.12149,   inf] (39), [-0.12149,   inf] (47), [-0.12148,   inf] (31), [-0.12148,   inf] (55), [-0.12148,   inf] (27), [-0.12148,   inf] (55), [-0.12148,   inf] (33), [-0.12148,   inf] (35), [-0.12148,   inf] (59), [-0.12148,   inf] (23), [-0.12147,   inf] (45), [-0.12147,   inf] (61), [-0.12147,   inf] (35), [-0.12147,   inf] (49), 
length of domains: 16449
Total time: 2.1719	 pickout: 0.0735	 decision: 0.3103	 get_bound: 1.7449	 add_domain: 0.0431
Current lb:-0.12149760127067566
32896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 186.5754907131195

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 131] [2, 83] [2, 145] [2, 27] [2, 50] [2, 83] [2, 149] [2, 22] [2, 95] [2, 15] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 39.642242431640625 with beta sum per layer: [0.0, 0.0, 764.542724609375]
alpha/beta optimization time: 1.6027097702026367
This batch time : update_bounds func: 1.7460	 prepare: 0.0331	 bound: 1.6030	 transfer: 0.0839	 finalize: 0.0248
Accumulated time: update_bounds func: 150.2518	 prepare: 2.7999	 bound: 137.2318	 transfer: 0.0839	 finalize: 3.3415
batch bounding time:  1.746687650680542
Current worst splitting domains [lb, ub] (depth):
[-0.12119,   inf] (35), [-0.12119,   inf] (33), [-0.12119,   inf] (55), [-0.12119,   inf] (25), [-0.12118,   inf] (21), [-0.12118,   inf] (65), [-0.12118,   inf] (43), [-0.12118,   inf] (25), [-0.12118,   inf] (35), [-0.12118,   inf] (23), [-0.12117,   inf] (65), [-0.12117,   inf] (55), [-0.12117,   inf] (49), [-0.12117,   inf] (47), [-0.12117,   inf] (49), [-0.12117,   inf] (49), [-0.12117,   inf] (57), [-0.12116,   inf] (49), [-0.12116,   inf] (23), [-0.12116,   inf] (37), 
length of domains: 16649
Total time: 2.1696	 pickout: 0.0710	 decision: 0.3071	 get_bound: 1.7474	 add_domain: 0.0441
Current lb:-0.12119348347187042
33296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 188.75086569786072

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 128] [2, 50] [2, 15] [2, 131] [2, 229] [2, 171] [2, 196] [2, 7] [2, 139] [2, 139] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 38.9385986328125 with beta sum per layer: [0.0, 0.0, 777.679443359375]
alpha/beta optimization time: 1.6041412353515625
This batch time : update_bounds func: 1.7403	 prepare: 0.0329	 bound: 1.6045	 transfer: 0.0762	 finalize: 0.0256
Accumulated time: update_bounds func: 151.9921	 prepare: 2.8328	 bound: 138.8363	 transfer: 0.0762	 finalize: 3.3671
batch bounding time:  1.7409672737121582
Current worst splitting domains [lb, ub] (depth):
[-0.12087,   inf] (43), [-0.12087,   inf] (47), [-0.12087,   inf] (27), [-0.12087,   inf] (25), [-0.12086,   inf] (71), [-0.12086,   inf] (37), [-0.12086,   inf] (49), [-0.12086,   inf] (45), [-0.12086,   inf] (59), [-0.12086,   inf] (33), [-0.12086,   inf] (33), [-0.12086,   inf] (59), [-0.12085,   inf] (55), [-0.12085,   inf] (41), [-0.12085,   inf] (55), [-0.12085,   inf] (59), [-0.12085,   inf] (29), [-0.12085,   inf] (21), [-0.12085,   inf] (41), [-0.12084,   inf] (29), 
length of domains: 16849
Total time: 2.1592	 pickout: 0.0720	 decision: 0.3052	 get_bound: 1.7417	 add_domain: 0.0402
Current lb:-0.1208694726228714
33696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 190.9157259464264

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 92] [2, 75] [2, 139] [2, 34] [2, 108] [2, 11] [2, 22] [2, 97] [2, 15] [2, 139] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 39.086917877197266 with beta sum per layer: [0.0, 0.0, 794.45361328125]
alpha/beta optimization time: 1.6034002304077148
This batch time : update_bounds func: 1.7479	 prepare: 0.0331	 bound: 1.6037	 transfer: 0.0839	 finalize: 0.0261
Accumulated time: update_bounds func: 153.7400	 prepare: 2.8659	 bound: 140.4400	 transfer: 0.0839	 finalize: 3.3932
batch bounding time:  1.7485599517822266
Current worst splitting domains [lb, ub] (depth):
[-0.12054,   inf] (61), [-0.12054,   inf] (55), [-0.12054,   inf] (41), [-0.12054,   inf] (53), [-0.12053,   inf] (31), [-0.12053,   inf] (45), [-0.12053,   inf] (31), [-0.12053,   inf] (43), [-0.12052,   inf] (45), [-0.12052,   inf] (37), [-0.12052,   inf] (29), [-0.12052,   inf] (49), [-0.12052,   inf] (37), [-0.12052,   inf] (65), [-0.12052,   inf] (33), [-0.12052,   inf] (55), [-0.12051,   inf] (29), [-0.12051,   inf] (65), [-0.12051,   inf] (37), [-0.12051,   inf] (35), 
length of domains: 17049
Total time: 2.1799	 pickout: 0.0813	 decision: 0.3087	 get_bound: 1.7493	 add_domain: 0.0405
Current lb:-0.12054218351840973
34096 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 193.10119438171387

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 214] [2, 22] [2, 196] [2, 145] [2, 95] [2, 83] [2, 95] [2, 83] [2, 97] [2, 11] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 38.51087951660156 with beta sum per layer: [0.0, 0.0, 806.3939819335938]
alpha/beta optimization time: 1.6133990287780762
This batch time : update_bounds func: 1.7489	 prepare: 0.0331	 bound: 1.6137	 transfer: 0.0764	 finalize: 0.0244
Accumulated time: update_bounds func: 155.4889	 prepare: 2.8990	 bound: 142.0537	 transfer: 0.0764	 finalize: 3.4176
batch bounding time:  1.7495322227478027
Current worst splitting domains [lb, ub] (depth):
[-0.12025,   inf] (59), [-0.12025,   inf] (43), [-0.12024,   inf] (53), [-0.12024,   inf] (25), [-0.12024,   inf] (57), [-0.12024,   inf] (59), [-0.12024,   inf] (59), [-0.12024,   inf] (39), [-0.12024,   inf] (29), [-0.12023,   inf] (35), [-0.12023,   inf] (27), [-0.12023,   inf] (53), [-0.12022,   inf] (47), [-0.12022,   inf] (49), [-0.12022,   inf] (31), [-0.12021,   inf] (37), [-0.12021,   inf] (35), [-0.12021,   inf] (33), [-0.12021,   inf] (27), [-0.12021,   inf] (63), 
length of domains: 17249
Total time: 2.6850	 pickout: 0.0728	 decision: 0.8192	 get_bound: 1.7503	 add_domain: 0.0427
Current lb:-0.1202474981546402
34496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 195.79176259040833

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 145] [2, 83] [2, 166] [2, 101] [2, 15] [2, 166] [2, 110] [2, 149] [2, 50] [2, 128] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 38.85060501098633 with beta sum per layer: [0.0, 0.0, 807.56689453125]
alpha/beta optimization time: 1.6165657043457031
This batch time : update_bounds func: 1.7619	 prepare: 0.0336	 bound: 1.6169	 transfer: 0.0847	 finalize: 0.0254
Accumulated time: update_bounds func: 157.2508	 prepare: 2.9326	 bound: 143.6707	 transfer: 0.0847	 finalize: 3.4430
batch bounding time:  1.7626063823699951
Current worst splitting domains [lb, ub] (depth):
[-0.11996,   inf] (41), [-0.11996,   inf] (37), [-0.11996,   inf] (39), [-0.11996,   inf] (41), [-0.11996,   inf] (29), [-0.11996,   inf] (45), [-0.11995,   inf] (55), [-0.11995,   inf] (61), [-0.11995,   inf] (65), [-0.11995,   inf] (27), [-0.11995,   inf] (43), [-0.11995,   inf] (41), [-0.11995,   inf] (23), [-0.11995,   inf] (37), [-0.11995,   inf] (45), [-0.11994,   inf] (51), [-0.11994,   inf] (39), [-0.11994,   inf] (25), [-0.11994,   inf] (51), [-0.11994,   inf] (63), 
length of domains: 17449
Total time: 2.1993	 pickout: 0.0806	 decision: 0.3122	 get_bound: 1.7634	 add_domain: 0.0431
Current lb:-0.11995898187160492
34896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 197.99671077728271

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 92] [2, 11] [2, 149] [2, 92] [2, 139] [2, 27] [2, 15] [2, 248] [2, 171] [2, 7] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 39.080230712890625 with beta sum per layer: [0.0, 0.0, 761.8374633789062]
alpha/beta optimization time: 1.6141061782836914
This batch time : update_bounds func: 1.7332	 prepare: 0.0335	 bound: 1.6145	 transfer: 0.0585	 finalize: 0.0254
Accumulated time: update_bounds func: 158.9839	 prepare: 2.9661	 bound: 145.2851	 transfer: 0.0585	 finalize: 3.4684
batch bounding time:  1.7338173389434814
Current worst splitting domains [lb, ub] (depth):
[-0.11968,   inf] (51), [-0.11968,   inf] (31), [-0.11968,   inf] (39), [-0.11968,   inf] (61), [-0.11967,   inf] (65), [-0.11967,   inf] (55), [-0.11967,   inf] (47), [-0.11967,   inf] (47), [-0.11966,   inf] (27), [-0.11966,   inf] (45), [-0.11966,   inf] (47), [-0.11966,   inf] (45), [-0.11966,   inf] (27), [-0.11966,   inf] (25), [-0.11966,   inf] (43), [-0.11966,   inf] (33), [-0.11966,   inf] (65), [-0.11966,   inf] (51), [-0.11965,   inf] (29), [-0.11965,   inf] (37), 
length of domains: 17649
Total time: 2.1648	 pickout: 0.0748	 decision: 0.3135	 get_bound: 1.7346	 add_domain: 0.0419
Current lb:-0.11968457698822021
35296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 200.1673936843872

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 75] [2, 95] [2, 149] [2, 214] [2, 171] [2, 15] [2, 22] [2, 27] [2, 34] [2, 92] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 38.624755859375 with beta sum per layer: [0.0, 0.0, 793.208251953125]
alpha/beta optimization time: 1.605607509613037
This batch time : update_bounds func: 1.7527	 prepare: 0.0339	 bound: 1.6060	 transfer: 0.0849	 finalize: 0.0267
Accumulated time: update_bounds func: 160.7366	 prepare: 3.0000	 bound: 146.8911	 transfer: 0.0849	 finalize: 3.4951
batch bounding time:  1.7533864974975586
Current worst splitting domains [lb, ub] (depth):
[-0.11936,   inf] (27), [-0.11936,   inf] (41), [-0.11936,   inf] (55), [-0.11935,   inf] (47), [-0.11935,   inf] (35), [-0.11935,   inf] (49), [-0.11935,   inf] (75), [-0.11935,   inf] (39), [-0.11935,   inf] (51), [-0.11934,   inf] (35), [-0.11934,   inf] (43), [-0.11934,   inf] (49), [-0.11934,   inf] (29), [-0.11934,   inf] (43), [-0.11934,   inf] (31), [-0.11934,   inf] (15), [-0.11934,   inf] (61), [-0.11933,   inf] (15), [-0.11933,   inf] (45), [-0.11933,   inf] (55), 
length of domains: 17849
Total time: 2.1939	 pickout: 0.0820	 decision: 0.3162	 get_bound: 1.7541	 add_domain: 0.0416
Current lb:-0.11935936659574509
35696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 202.36704635620117

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 50] [2, 196] [2, 166] [2, 97] [2, 139] [2, 22] [2, 193] [2, 149] [2, 97] [2, 128] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 38.29422378540039 with beta sum per layer: [0.0, 0.0, 776.4640502929688]
alpha/beta optimization time: 1.6174235343933105
This batch time : update_bounds func: 1.7664	 prepare: 0.0333	 bound: 1.6180	 transfer: 0.0835	 finalize: 0.0304
Accumulated time: update_bounds func: 162.5031	 prepare: 3.0333	 bound: 148.5091	 transfer: 0.0835	 finalize: 3.5255
batch bounding time:  1.767277717590332
Current worst splitting domains [lb, ub] (depth):
[-0.11905,   inf] (27), [-0.11905,   inf] (63), [-0.11905,   inf] (39), [-0.11905,   inf] (23), [-0.11905,   inf] (69), [-0.11904,   inf] (49), [-0.11904,   inf] (67), [-0.11904,   inf] (41), [-0.11904,   inf] (15), [-0.11904,   inf] (63), [-0.11904,   inf] (51), [-0.11904,   inf] (41), [-0.11904,   inf] (41), [-0.11904,   inf] (41), [-0.11904,   inf] (29), [-0.11904,   inf] (59), [-0.11904,   inf] (43), [-0.11904,   inf] (33), [-0.11903,   inf] (63), [-0.11903,   inf] (65), 
length of domains: 18049
Total time: 2.2165	 pickout: 0.0825	 decision: 0.3139	 get_bound: 1.7685	 add_domain: 0.0517
Current lb:-0.11905394494533539
36096 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 204.59334993362427

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 139] [2, 171] [2, 149] [2, 229] [2, 108] [2, 22] [2, 171] [2, 196] [2, 163] [2, 248] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 38.431060791015625 with beta sum per layer: [0.0, 0.0, 798.0863647460938]
alpha/beta optimization time: 1.6212663650512695
This batch time : update_bounds func: 2.3183	 prepare: 0.0345	 bound: 1.6216	 transfer: 0.0856	 finalize: 0.5753
Accumulated time: update_bounds func: 164.8214	 prepare: 3.0678	 bound: 150.1307	 transfer: 0.0856	 finalize: 4.1008
batch bounding time:  2.319044589996338
Current worst splitting domains [lb, ub] (depth):
[-0.11881,   inf] (63), [-0.11881,   inf] (37), [-0.11881,   inf] (55), [-0.11881,   inf] (57), [-0.11880,   inf] (45), [-0.11880,   inf] (43), [-0.11880,   inf] (61), [-0.11880,   inf] (53), [-0.11879,   inf] (37), [-0.11879,   inf] (41), [-0.11879,   inf] (53), [-0.11879,   inf] (35), [-0.11879,   inf] (53), [-0.11878,   inf] (51), [-0.11878,   inf] (41), [-0.11878,   inf] (49), [-0.11878,   inf] (49), [-0.11877,   inf] (49), [-0.11877,   inf] (53), [-0.11877,   inf] (25), 
length of domains: 18249
Total time: 2.7577	 pickout: 0.0850	 decision: 0.3089	 get_bound: 2.3198	 add_domain: 0.0440
Current lb:-0.11881069839000702
36496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 207.35703921318054

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 214] [2, 11] [2, 97] [2, 145] [2, 83] [2, 196] [2, 214] [2, 166] [2, 11] [2, 196] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 39.16794204711914 with beta sum per layer: [0.0, 0.0, 797.0004272460938]
alpha/beta optimization time: 1.6182007789611816
This batch time : update_bounds func: 1.7478	 prepare: 0.0332	 bound: 1.6185	 transfer: 0.0682	 finalize: 0.0265
Accumulated time: update_bounds func: 166.5691	 prepare: 3.1010	 bound: 151.7492	 transfer: 0.0682	 finalize: 4.1273
batch bounding time:  1.7484631538391113
Current worst splitting domains [lb, ub] (depth):
[-0.11851,   inf] (27), [-0.11851,   inf] (27), [-0.11850,   inf] (63), [-0.11850,   inf] (61), [-0.11850,   inf] (47), [-0.11849,   inf] (41), [-0.11849,   inf] (41), [-0.11849,   inf] (67), [-0.11849,   inf] (47), [-0.11849,   inf] (65), [-0.11849,   inf] (33), [-0.11849,   inf] (49), [-0.11848,   inf] (57), [-0.11848,   inf] (29), [-0.11848,   inf] (27), [-0.11848,   inf] (45), [-0.11848,   inf] (65), [-0.11848,   inf] (55), [-0.11848,   inf] (29), [-0.11848,   inf] (47), 
length of domains: 18449
Total time: 2.1778	 pickout: 0.0704	 decision: 0.3139	 get_bound: 1.7492	 add_domain: 0.0444
Current lb:-0.11850783973932266
36896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 209.5411434173584

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 139] [2, 50] [2, 157] [2, 214] [2, 22] [2, 196] [2, 83] [2, 108] [2, 22] [2, 157] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 38.11994552612305 with beta sum per layer: [0.0, 0.0, 737.7847900390625]
alpha/beta optimization time: 1.631885051727295
This batch time : update_bounds func: 1.7775	 prepare: 0.0332	 bound: 1.6323	 transfer: 0.0843	 finalize: 0.0266
Accumulated time: update_bounds func: 168.3466	 prepare: 3.1342	 bound: 153.3815	 transfer: 0.0843	 finalize: 4.1539
batch bounding time:  1.7782022953033447
Current worst splitting domains [lb, ub] (depth):
[-0.11823,   inf] (27), [-0.11822,   inf] (43), [-0.11822,   inf] (37), [-0.11822,   inf] (15), [-0.11822,   inf] (65), [-0.11822,   inf] (29), [-0.11822,   inf] (41), [-0.11822,   inf] (35), [-0.11821,   inf] (57), [-0.11821,   inf] (51), [-0.11821,   inf] (53), [-0.11821,   inf] (51), [-0.11820,   inf] (41), [-0.11820,   inf] (51), [-0.11820,   inf] (61), [-0.11820,   inf] (33), [-0.11820,   inf] (61), [-0.11820,   inf] (25), [-0.11820,   inf] (61), [-0.11820,   inf] (61), 
length of domains: 18649
Total time: 2.2103	 pickout: 0.0753	 decision: 0.3137	 get_bound: 1.7790	 add_domain: 0.0423
Current lb:-0.1182258352637291
37296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 211.7571997642517

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 7] [2, 83] [2, 11] [2, 163] [2, 110] [2, 128] [2, 196] [2, 128] [2, 145] [2, 92] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 38.709739685058594 with beta sum per layer: [0.0, 0.0, 791.0759887695312]
alpha/beta optimization time: 1.632204294204712
This batch time : update_bounds func: 1.7768	 prepare: 0.0338	 bound: 1.6325	 transfer: 0.0849	 finalize: 0.0243
Accumulated time: update_bounds func: 170.1234	 prepare: 3.1680	 bound: 155.0141	 transfer: 0.0849	 finalize: 4.1782
batch bounding time:  1.7776029109954834
Current worst splitting domains [lb, ub] (depth):
[-0.11796,   inf] (49), [-0.11796,   inf] (35), [-0.11796,   inf] (63), [-0.11796,   inf] (39), [-0.11795,   inf] (49), [-0.11795,   inf] (23), [-0.11795,   inf] (35), [-0.11795,   inf] (41), [-0.11795,   inf] (59), [-0.11795,   inf] (45), [-0.11795,   inf] (59), [-0.11795,   inf] (35), [-0.11795,   inf] (27), [-0.11795,   inf] (57), [-0.11795,   inf] (31), [-0.11794,   inf] (27), [-0.11794,   inf] (29), [-0.11794,   inf] (51), [-0.11794,   inf] (47), [-0.11794,   inf] (41), 
length of domains: 18849
Total time: 2.2128	 pickout: 0.0751	 decision: 0.3151	 get_bound: 1.7784	 add_domain: 0.0442
Current lb:-0.11796194314956665
37696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 213.97568345069885

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 75] [2, 128] [2, 157] [2, 149] [2, 22] [2, 7] [2, 128] [2, 83] [2, 214] [2, 27] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 37.79712677001953 with beta sum per layer: [0.0, 0.0, 787.335693359375]
alpha/beta optimization time: 1.6269409656524658
This batch time : update_bounds func: 1.7754	 prepare: 0.0339	 bound: 1.6273	 transfer: 0.0879	 finalize: 0.0251
Accumulated time: update_bounds func: 171.8988	 prepare: 3.2018	 bound: 156.6413	 transfer: 0.0879	 finalize: 4.2033
batch bounding time:  1.7761187553405762
Current worst splitting domains [lb, ub] (depth):
[-0.11768,   inf] (35), [-0.11768,   inf] (73), [-0.11768,   inf] (51), [-0.11768,   inf] (51), [-0.11768,   inf] (41), [-0.11768,   inf] (61), [-0.11768,   inf] (67), [-0.11767,   inf] (55), [-0.11767,   inf] (57), [-0.11767,   inf] (35), [-0.11767,   inf] (23), [-0.11767,   inf] (49), [-0.11767,   inf] (27), [-0.11767,   inf] (29), [-0.11767,   inf] (31), [-0.11767,   inf] (41), [-0.11767,   inf] (53), [-0.11766,   inf] (31), [-0.11766,   inf] (51), [-0.11766,   inf] (57), 
length of domains: 19049
Total time: 2.2108	 pickout: 0.0719	 decision: 0.3170	 get_bound: 1.7769	 add_domain: 0.0449
Current lb:-0.11768272519111633
38096 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 216.19243216514587

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 50] [2, 108] [2, 145] [2, 75] [2, 196] [2, 214] [2, 110] [2, 15] [2, 15] [2, 50] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 37.89873123168945 with beta sum per layer: [0.0, 0.0, 806.0191650390625]
alpha/beta optimization time: 1.6288001537322998
This batch time : update_bounds func: 1.7795	 prepare: 0.0339	 bound: 1.6292	 transfer: 0.0893	 finalize: 0.0258
Accumulated time: update_bounds func: 173.6783	 prepare: 3.2358	 bound: 158.2705	 transfer: 0.0893	 finalize: 4.2291
batch bounding time:  1.780179738998413
Current worst splitting domains [lb, ub] (depth):
[-0.11742,   inf] (61), [-0.11742,   inf] (31), [-0.11741,   inf] (19), [-0.11741,   inf] (51), [-0.11741,   inf] (53), [-0.11741,   inf] (29), [-0.11741,   inf] (51), [-0.11741,   inf] (49), [-0.11741,   inf] (21), [-0.11740,   inf] (37), [-0.11740,   inf] (29), [-0.11740,   inf] (45), [-0.11740,   inf] (61), [-0.11740,   inf] (37), [-0.11740,   inf] (65), [-0.11740,   inf] (49), [-0.11740,   inf] (49), [-0.11740,   inf] (61), [-0.11739,   inf] (59), [-0.11739,   inf] (29), 
length of domains: 19249
Total time: 2.2059	 pickout: 0.0692	 decision: 0.3146	 get_bound: 1.7810	 add_domain: 0.0412
Current lb:-0.11741850525140762
38496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 218.4039442539215

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 214] [2, 95] [2, 234] [2, 27] [2, 145] [2, 50] [2, 75] [2, 97] [2, 7] [2, 11] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 38.266212463378906 with beta sum per layer: [0.0, 0.0, 738.9913940429688]
alpha/beta optimization time: 1.6294305324554443
This batch time : update_bounds func: 1.7808	 prepare: 0.0338	 bound: 1.6298	 transfer: 0.0891	 finalize: 0.0268
Accumulated time: update_bounds func: 175.4592	 prepare: 3.2696	 bound: 159.9003	 transfer: 0.0891	 finalize: 4.2559
batch bounding time:  1.781616449356079
Current worst splitting domains [lb, ub] (depth):
[-0.11716,   inf] (53), [-0.11716,   inf] (61), [-0.11716,   inf] (31), [-0.11716,   inf] (35), [-0.11716,   inf] (29), [-0.11716,   inf] (53), [-0.11716,   inf] (53), [-0.11716,   inf] (59), [-0.11715,   inf] (31), [-0.11715,   inf] (43), [-0.11715,   inf] (27), [-0.11715,   inf] (51), [-0.11715,   inf] (53), [-0.11715,   inf] (61), [-0.11714,   inf] (39), [-0.11714,   inf] (29), [-0.11714,   inf] (27), [-0.11714,   inf] (25), [-0.11714,   inf] (39), [-0.11714,   inf] (61), 
length of domains: 19449
Total time: 2.7900	 pickout: 0.0700	 decision: 0.3210	 get_bound: 1.7824	 add_domain: 0.6166
Current lb:-0.11716188490390778
38896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 221.19970178604126

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 166] [2, 214] [2, 95] [2, 128] [2, 139] [2, 145] [2, 166] [2, 75] [2, 95] [2, 83] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 38.185569763183594 with beta sum per layer: [0.0, 0.0, 790.7013549804688]
alpha/beta optimization time: 1.6319427490234375
This batch time : update_bounds func: 1.7822	 prepare: 0.0336	 bound: 1.6323	 transfer: 0.0902	 finalize: 0.0249
Accumulated time: update_bounds func: 177.2414	 prepare: 3.3031	 bound: 161.5326	 transfer: 0.0902	 finalize: 4.2807
batch bounding time:  1.7829444408416748
Current worst splitting domains [lb, ub] (depth):
[-0.11689,   inf] (53), [-0.11689,   inf] (43), [-0.11689,   inf] (55), [-0.11689,   inf] (57), [-0.11689,   inf] (67), [-0.11688,   inf] (35), [-0.11688,   inf] (37), [-0.11688,   inf] (59), [-0.11688,   inf] (61), [-0.11688,   inf] (59), [-0.11688,   inf] (55), [-0.11688,   inf] (57), [-0.11688,   inf] (37), [-0.11688,   inf] (53), [-0.11688,   inf] (21), [-0.11688,   inf] (33), [-0.11688,   inf] (45), [-0.11688,   inf] (37), [-0.11687,   inf] (61), [-0.11687,   inf] (51), 
length of domains: 19649
Total time: 2.2136	 pickout: 0.0707	 decision: 0.3138	 get_bound: 1.7837	 add_domain: 0.0454
Current lb:-0.11689069867134094
39296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 223.41908264160156

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 27] [2, 92] [2, 22] [2, 97] [2, 108] [2, 11] [2, 11] [2, 166] [2, 214] [2, 166] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 37.518699645996094 with beta sum per layer: [0.0, 0.0, 770.2001953125]
alpha/beta optimization time: 1.6281390190124512
This batch time : update_bounds func: 1.7747	 prepare: 0.0335	 bound: 1.6285	 transfer: 0.0851	 finalize: 0.0264
Accumulated time: update_bounds func: 179.0161	 prepare: 3.3366	 bound: 163.1611	 transfer: 0.0851	 finalize: 4.3071
batch bounding time:  1.7755038738250732
Current worst splitting domains [lb, ub] (depth):
[-0.11666,   inf] (53), [-0.11666,   inf] (45), [-0.11666,   inf] (67), [-0.11666,   inf] (25), [-0.11665,   inf] (29), [-0.11665,   inf] (37), [-0.11665,   inf] (51), [-0.11664,   inf] (39), [-0.11664,   inf] (19), [-0.11664,   inf] (65), [-0.11664,   inf] (37), [-0.11664,   inf] (33), [-0.11664,   inf] (57), [-0.11664,   inf] (69), [-0.11664,   inf] (47), [-0.11663,   inf] (39), [-0.11663,   inf] (49), [-0.11663,   inf] (45), [-0.11663,   inf] (45), [-0.11663,   inf] (43), 
length of domains: 19849
Total time: 2.2123	 pickout: 0.0725	 decision: 0.3180	 get_bound: 1.7763	 add_domain: 0.0455
Current lb:-0.11665985733270645
39696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 225.63877058029175

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 145] [2, 92] [2, 157] [2, 34] [2, 50] [2, 11] [2, 97] [2, 149] [2, 234] [2, 110] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 37.59419631958008 with beta sum per layer: [0.0, 0.0, 780.4763793945312]
alpha/beta optimization time: 1.626680612564087
This batch time : update_bounds func: 1.7779	 prepare: 0.0335	 bound: 1.6270	 transfer: 0.0897	 finalize: 0.0264
Accumulated time: update_bounds func: 180.7941	 prepare: 3.3701	 bound: 164.7882	 transfer: 0.0897	 finalize: 4.3335
batch bounding time:  1.7786493301391602
Current worst splitting domains [lb, ub] (depth):
[-0.11636,   inf] (43), [-0.11636,   inf] (43), [-0.11636,   inf] (33), [-0.11636,   inf] (29), [-0.11636,   inf] (25), [-0.11636,   inf] (63), [-0.11635,   inf] (31), [-0.11635,   inf] (49), [-0.11635,   inf] (45), [-0.11635,   inf] (51), [-0.11635,   inf] (71), [-0.11635,   inf] (45), [-0.11635,   inf] (41), [-0.11635,   inf] (43), [-0.11634,   inf] (47), [-0.11634,   inf] (45), [-0.11634,   inf] (67), [-0.11634,   inf] (61), [-0.11634,   inf] (61), [-0.11634,   inf] (55), 
length of domains: 20049
Total time: 2.2188	 pickout: 0.0799	 decision: 0.3164	 get_bound: 1.7794	 add_domain: 0.0430
Current lb:-0.11636386066675186
40096 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 227.8642807006836

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 92] [2, 92] [2, 50] [2, 139] [2, 139] [2, 214] [2, 95] [2, 75] [2, 145] [2, 145] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 37.14348220825195 with beta sum per layer: [0.0, 0.0, 800.4894409179688]
alpha/beta optimization time: 1.6301383972167969
This batch time : update_bounds func: 1.7815	 prepare: 0.0339	 bound: 1.6305	 transfer: 0.0893	 finalize: 0.0265
Accumulated time: update_bounds func: 182.5756	 prepare: 3.4040	 bound: 166.4187	 transfer: 0.0893	 finalize: 4.3600
batch bounding time:  1.7821645736694336
Current worst splitting domains [lb, ub] (depth):
[-0.11611,   inf] (55), [-0.11611,   inf] (27), [-0.11611,   inf] (57), [-0.11611,   inf] (29), [-0.11611,   inf] (49), [-0.11611,   inf] (37), [-0.11611,   inf] (41), [-0.11611,   inf] (33), [-0.11611,   inf] (45), [-0.11611,   inf] (35), [-0.11610,   inf] (45), [-0.11610,   inf] (47), [-0.11610,   inf] (43), [-0.11610,   inf] (39), [-0.11610,   inf] (37), [-0.11610,   inf] (25), [-0.11610,   inf] (31), [-0.11610,   inf] (63), [-0.11610,   inf] (55), [-0.11610,   inf] (47), 
length of domains: 20249
Total time: 2.2137	 pickout: 0.0734	 decision: 0.3145	 get_bound: 1.7829	 add_domain: 0.0429
Current lb:-0.1161143109202385
40496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 230.0838794708252

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 145] [2, 139] [2, 166] [2, 128] [2, 27] [2, 11] [2, 196] [2, 50] [2, 97] [2, 50] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 37.35418701171875 with beta sum per layer: [0.0, 0.0, 794.222412109375]
alpha/beta optimization time: 1.6312744617462158
This batch time : update_bounds func: 1.7765	 prepare: 0.0339	 bound: 1.6317	 transfer: 0.0850	 finalize: 0.0247
Accumulated time: update_bounds func: 184.3520	 prepare: 3.4379	 bound: 168.0503	 transfer: 0.0850	 finalize: 4.3847
batch bounding time:  1.777191162109375
Current worst splitting domains [lb, ub] (depth):
[-0.11587,   inf] (55), [-0.11587,   inf] (61), [-0.11587,   inf] (41), [-0.11587,   inf] (21), [-0.11587,   inf] (49), [-0.11587,   inf] (39), [-0.11587,   inf] (59), [-0.11587,   inf] (29), [-0.11587,   inf] (49), [-0.11586,   inf] (31), [-0.11586,   inf] (49), [-0.11586,   inf] (59), [-0.11586,   inf] (45), [-0.11586,   inf] (55), [-0.11586,   inf] (59), [-0.11586,   inf] (51), [-0.11586,   inf] (31), [-0.11585,   inf] (33), [-0.11585,   inf] (25), [-0.11585,   inf] (47), 
length of domains: 20449
Total time: 2.2123	 pickout: 0.0733	 decision: 0.3166	 get_bound: 1.7780	 add_domain: 0.0444
Current lb:-0.11587479710578918
40896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 232.30242037773132

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 15] [2, 214] [2, 196] [2, 101] [2, 92] [2, 149] [2, 75] [2, 34] [2, 27] [2, 95] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 36.64964294433594 with beta sum per layer: [0.0, 0.0, 768.7803955078125]
alpha/beta optimization time: 1.6252260208129883
This batch time : update_bounds func: 1.7745	 prepare: 0.0341	 bound: 1.6256	 transfer: 0.0883	 finalize: 0.0252
Accumulated time: update_bounds func: 186.1265	 prepare: 3.4720	 bound: 169.6759	 transfer: 0.0883	 finalize: 4.4099
batch bounding time:  1.7751867771148682
Current worst splitting domains [lb, ub] (depth):
[-0.11563,   inf] (27), [-0.11562,   inf] (59), [-0.11562,   inf] (43), [-0.11562,   inf] (57), [-0.11562,   inf] (35), [-0.11562,   inf] (21), [-0.11562,   inf] (63), [-0.11561,   inf] (37), [-0.11561,   inf] (21), [-0.11561,   inf] (43), [-0.11561,   inf] (47), [-0.11561,   inf] (29), [-0.11560,   inf] (43), [-0.11560,   inf] (43), [-0.11560,   inf] (53), [-0.11560,   inf] (35), [-0.11560,   inf] (57), [-0.11559,   inf] (57), [-0.11559,   inf] (57), [-0.11559,   inf] (57), 
length of domains: 20649
Total time: 2.8061	 pickout: 0.0711	 decision: 0.3180	 get_bound: 1.7760	 add_domain: 0.6411
Current lb:-0.11562596261501312
41296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 235.11464500427246

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 50] [2, 15] [2, 196] [2, 15] [2, 11] [2, 117] [2, 214] [2, 11] [2, 229] [2, 83] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 37.609466552734375 with beta sum per layer: [0.0, 0.0, 796.044921875]
alpha/beta optimization time: 1.6293907165527344
This batch time : update_bounds func: 1.7762	 prepare: 0.0336	 bound: 1.6298	 transfer: 0.0850	 finalize: 0.0265
Accumulated time: update_bounds func: 187.9027	 prepare: 3.5055	 bound: 171.3057	 transfer: 0.0850	 finalize: 4.4364
batch bounding time:  1.776909589767456
Current worst splitting domains [lb, ub] (depth):
[-0.11536,   inf] (53), [-0.11535,   inf] (41), [-0.11535,   inf] (33), [-0.11535,   inf] (35), [-0.11535,   inf] (65), [-0.11535,   inf] (17), [-0.11535,   inf] (57), [-0.11535,   inf] (37), [-0.11535,   inf] (63), [-0.11535,   inf] (31), [-0.11534,   inf] (53), [-0.11534,   inf] (53), [-0.11534,   inf] (39), [-0.11534,   inf] (61), [-0.11534,   inf] (63), [-0.11534,   inf] (23), [-0.11534,   inf] (29), [-0.11533,   inf] (57), [-0.11533,   inf] (31), [-0.11533,   inf] (51), 
length of domains: 20849
Total time: 2.2071	 pickout: 0.0735	 decision: 0.3135	 get_bound: 1.7777	 add_domain: 0.0424
Current lb:-0.11535532027482986
41696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 237.32811307907104

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 75] [2, 83] [2, 50] [2, 11] [2, 171] [2, 117] [2, 166] [2, 11] [2, 214] [2, 95] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 36.78977966308594 with beta sum per layer: [0.0, 0.0, 801.0086669921875]
alpha/beta optimization time: 1.631521224975586
This batch time : update_bounds func: 1.7816	 prepare: 0.0347	 bound: 1.6319	 transfer: 0.0853	 finalize: 0.0284
Accumulated time: update_bounds func: 189.6843	 prepare: 3.5402	 bound: 172.9376	 transfer: 0.0853	 finalize: 4.4648
batch bounding time:  1.7823486328125
Current worst splitting domains [lb, ub] (depth):
[-0.11512,   inf] (65), [-0.11512,   inf] (43), [-0.11512,   inf] (51), [-0.11512,   inf] (39), [-0.11512,   inf] (43), [-0.11512,   inf] (37), [-0.11511,   inf] (53), [-0.11511,   inf] (61), [-0.11511,   inf] (25), [-0.11511,   inf] (33), [-0.11511,   inf] (61), [-0.11511,   inf] (17), [-0.11511,   inf] (47), [-0.11511,   inf] (71), [-0.11511,   inf] (33), [-0.11511,   inf] (59), [-0.11511,   inf] (47), [-0.11510,   inf] (41), [-0.11510,   inf] (51), [-0.11510,   inf] (55), 
length of domains: 21049
Total time: 2.2138	 pickout: 0.0738	 decision: 0.3149	 get_bound: 1.7832	 add_domain: 0.0420
Current lb:-0.11512437462806702
42096 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 239.55000042915344

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 108] [2, 83] [2, 22] [2, 149] [2, 92] [2, 11] [2, 166] [2, 248] [2, 7] [2, 50] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 36.75016784667969 with beta sum per layer: [0.0, 0.0, 802.6732788085938]
alpha/beta optimization time: 1.6283738613128662
This batch time : update_bounds func: 1.7571	 prepare: 0.0335	 bound: 1.6287	 transfer: 0.0689	 finalize: 0.0247
Accumulated time: update_bounds func: 191.4414	 prepare: 3.5736	 bound: 174.5663	 transfer: 0.0689	 finalize: 4.4895
batch bounding time:  1.7578701972961426
Current worst splitting domains [lb, ub] (depth):
[-0.11487,   inf] (61), [-0.11487,   inf] (39), [-0.11486,   inf] (43), [-0.11486,   inf] (55), [-0.11486,   inf] (43), [-0.11486,   inf] (43), [-0.11486,   inf] (65), [-0.11486,   inf] (55), [-0.11486,   inf] (49), [-0.11486,   inf] (21), [-0.11486,   inf] (65), [-0.11485,   inf] (61), [-0.11485,   inf] (63), [-0.11485,   inf] (35), [-0.11485,   inf] (53), [-0.11485,   inf] (33), [-0.11485,   inf] (53), [-0.11485,   inf] (39), [-0.11485,   inf] (59), [-0.11485,   inf] (69), 
length of domains: 21249
Total time: 2.2007	 pickout: 0.0835	 decision: 0.3130	 get_bound: 1.7587	 add_domain: 0.0456
Current lb:-0.11486715078353882
42496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 241.75681686401367

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 248] [2, 149] [2, 83] [2, 15] [2, 83] [2, 83] [2, 157] [2, 145] [2, 75] [2, 229] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 37.469276428222656 with beta sum per layer: [0.0, 0.0, 769.227783203125]
alpha/beta optimization time: 1.632416009902954
This batch time : update_bounds func: 1.7790	 prepare: 0.0336	 bound: 1.6328	 transfer: 0.0860	 finalize: 0.0252
Accumulated time: update_bounds func: 193.2204	 prepare: 3.6073	 bound: 176.1991	 transfer: 0.0860	 finalize: 4.5147
batch bounding time:  1.7796828746795654
Current worst splitting domains [lb, ub] (depth):
[-0.11461,   inf] (33), [-0.11461,   inf] (41), [-0.11461,   inf] (45), [-0.11461,   inf] (33), [-0.11460,   inf] (55), [-0.11460,   inf] (61), [-0.11460,   inf] (25), [-0.11460,   inf] (57), [-0.11460,   inf] (31), [-0.11460,   inf] (45), [-0.11460,   inf] (59), [-0.11460,   inf] (49), [-0.11460,   inf] (55), [-0.11459,   inf] (65), [-0.11459,   inf] (35), [-0.11459,   inf] (51), [-0.11459,   inf] (29), [-0.11459,   inf] (59), [-0.11459,   inf] (35), [-0.11459,   inf] (41), 
length of domains: 21449
Total time: 2.2163	 pickout: 0.0796	 decision: 0.3117	 get_bound: 1.7805	 add_domain: 0.0446
Current lb:-0.11461001634597778
42896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 243.9792423248291

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 50] [2, 83] [2, 97] [2, 50] [2, 166] [2, 214] [2, 34] [2, 166] [2, 95] [2, 27] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 36.82421875 with beta sum per layer: [0.0, 0.0, 740.9609375]
alpha/beta optimization time: 1.6314828395843506
This batch time : update_bounds func: 1.7583	 prepare: 0.0339	 bound: 1.6318	 transfer: 0.0652	 finalize: 0.0262
Accumulated time: update_bounds func: 194.9787	 prepare: 3.6411	 bound: 177.8309	 transfer: 0.0652	 finalize: 4.5409
batch bounding time:  1.7590138912200928
Current worst splitting domains [lb, ub] (depth):
[-0.11436,   inf] (41), [-0.11436,   inf] (57), [-0.11436,   inf] (65), [-0.11436,   inf] (57), [-0.11436,   inf] (55), [-0.11436,   inf] (41), [-0.11436,   inf] (39), [-0.11436,   inf] (49), [-0.11436,   inf] (35), [-0.11436,   inf] (59), [-0.11435,   inf] (57), [-0.11435,   inf] (61), [-0.11435,   inf] (37), [-0.11435,   inf] (57), [-0.11435,   inf] (63), [-0.11435,   inf] (57), [-0.11435,   inf] (29), [-0.11435,   inf] (21), [-0.11434,   inf] (41), [-0.11434,   inf] (51), 
length of domains: 21649
Total time: 2.1927	 pickout: 0.0764	 decision: 0.3129	 get_bound: 1.7598	 add_domain: 0.0437
Current lb:-0.1143646165728569
43296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 246.17830681800842

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 196] [2, 145] [2, 110] [2, 15] [2, 15] [2, 139] [2, 149] [2, 27] [2, 50] [2, 166] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 36.88868713378906 with beta sum per layer: [0.0, 0.0, 808.462646484375]
alpha/beta optimization time: 1.643144130706787
This batch time : update_bounds func: 1.7870	 prepare: 0.0337	 bound: 1.6435	 transfer: 0.0815	 finalize: 0.0269
Accumulated time: update_bounds func: 196.7657	 prepare: 3.6748	 bound: 179.4744	 transfer: 0.0815	 finalize: 4.5678
batch bounding time:  1.7876129150390625
Current worst splitting domains [lb, ub] (depth):
[-0.11411,   inf] (29), [-0.11411,   inf] (47), [-0.11410,   inf] (35), [-0.11410,   inf] (39), [-0.11410,   inf] (43), [-0.11410,   inf] (53), [-0.11410,   inf] (33), [-0.11410,   inf] (55), [-0.11410,   inf] (51), [-0.11410,   inf] (67), [-0.11409,   inf] (69), [-0.11409,   inf] (45), [-0.11409,   inf] (57), [-0.11409,   inf] (59), [-0.11409,   inf] (63), [-0.11409,   inf] (35), [-0.11409,   inf] (55), [-0.11409,   inf] (29), [-0.11409,   inf] (33), [-0.11409,   inf] (47), 
length of domains: 21849
Total time: 2.2161	 pickout: 0.0688	 decision: 0.3166	 get_bound: 1.7884	 add_domain: 0.0424
Current lb:-0.11410800367593765
43696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 248.4008810520172

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 131] [2, 97] [2, 50] [2, 149] [2, 92] [2, 27] [2, 139] [2, 27] [2, 145] [2, 110] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 35.586524963378906 with beta sum per layer: [0.0, 0.0, 820.3356323242188]
alpha/beta optimization time: 1.6398193836212158
This batch time : update_bounds func: 2.4508	 prepare: 0.0337	 bound: 1.6403	 transfer: 0.0852	 finalize: 0.6903
Accumulated time: update_bounds func: 199.2165	 prepare: 3.7086	 bound: 181.1147	 transfer: 0.0852	 finalize: 5.2581
batch bounding time:  2.451592445373535
Current worst splitting domains [lb, ub] (depth):
[-0.11386,   inf] (51), [-0.11386,   inf] (69), [-0.11386,   inf] (31), [-0.11385,   inf] (43), [-0.11385,   inf] (55), [-0.11385,   inf] (49), [-0.11385,   inf] (29), [-0.11385,   inf] (57), [-0.11385,   inf] (51), [-0.11385,   inf] (51), [-0.11385,   inf] (55), [-0.11385,   inf] (65), [-0.11385,   inf] (31), [-0.11385,   inf] (31), [-0.11385,   inf] (33), [-0.11384,   inf] (53), [-0.11384,   inf] (53), [-0.11384,   inf] (59), [-0.11384,   inf] (45), [-0.11384,   inf] (53), 
length of domains: 22048
Total time: 2.8848	 pickout: 0.0702	 decision: 0.3174	 get_bound: 2.4524	 add_domain: 0.0448
Current lb:-0.11385845392942429
44096 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 251.29216289520264

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 27] [2, 223] [2, 95] [2, 92] [2, 15] [2, 97] [2, 139] [2, 15] [2, 92] [2, 97] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 35.719459533691406 with beta sum per layer: [0.0, 0.0, 773.2982177734375]
alpha/beta optimization time: 1.63944411277771
This batch time : update_bounds func: 1.7757	 prepare: 0.0336	 bound: 1.6398	 transfer: 0.0751	 finalize: 0.0258
Accumulated time: update_bounds func: 200.9922	 prepare: 3.7422	 bound: 182.7545	 transfer: 0.0751	 finalize: 5.2839
batch bounding time:  1.7764172554016113
Current worst splitting domains [lb, ub] (depth):
[-0.11365,   inf] (31), [-0.11365,   inf] (39), [-0.11365,   inf] (61), [-0.11365,   inf] (47), [-0.11364,   inf] (21), [-0.11364,   inf] (47), [-0.11364,   inf] (57), [-0.11364,   inf] (51), [-0.11364,   inf] (29), [-0.11364,   inf] (45), [-0.11364,   inf] (37), [-0.11364,   inf] (59), [-0.11364,   inf] (59), [-0.11364,   inf] (41), [-0.11364,   inf] (71), [-0.11364,   inf] (37), [-0.11363,   inf] (31), [-0.11363,   inf] (63), [-0.11363,   inf] (37), [-0.11363,   inf] (35), 
length of domains: 22248
Total time: 2.2088	 pickout: 0.0685	 decision: 0.3179	 get_bound: 1.7772	 add_domain: 0.0451
Current lb:-0.11364606767892838
44496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 253.50713849067688

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 95] [2, 149] [2, 214] [2, 22] [2, 101] [2, 97] [2, 75] [2, 145] [2, 128] [2, 196] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 36.553348541259766 with beta sum per layer: [0.0, 0.0, 806.2902221679688]
alpha/beta optimization time: 1.6391091346740723
This batch time : update_bounds func: 1.7906	 prepare: 0.0339	 bound: 1.6395	 transfer: 0.0893	 finalize: 0.0266
Accumulated time: update_bounds func: 202.7828	 prepare: 3.7761	 bound: 184.3940	 transfer: 0.0893	 finalize: 5.3105
batch bounding time:  1.7912864685058594
Current worst splitting domains [lb, ub] (depth):
[-0.11342,   inf] (49), [-0.11342,   inf] (61), [-0.11341,   inf] (57), [-0.11341,   inf] (49), [-0.11341,   inf] (55), [-0.11341,   inf] (55), [-0.11341,   inf] (59), [-0.11340,   inf] (33), [-0.11340,   inf] (27), [-0.11340,   inf] (49), [-0.11340,   inf] (69), [-0.11340,   inf] (55), [-0.11340,   inf] (39), [-0.11340,   inf] (55), [-0.11339,   inf] (43), [-0.11339,   inf] (61), [-0.11339,   inf] (51), [-0.11338,   inf] (35), [-0.11338,   inf] (39), [-0.11338,   inf] (63), 
length of domains: 22448
Total time: 2.2236	 pickout: 0.0687	 decision: 0.3194	 get_bound: 1.7921	 add_domain: 0.0434
Current lb:-0.11341530829668045
44896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 255.73710584640503

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 145] [2, 214] [2, 166] [2, 97] [2, 27] [2, 15] [2, 214] [2, 50] [2, 131] [2, 22] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 35.791996002197266 with beta sum per layer: [0.0, 0.0, 793.5734252929688]
alpha/beta optimization time: 1.6383795738220215
This batch time : update_bounds func: 1.7891	 prepare: 0.0336	 bound: 1.6388	 transfer: 0.0889	 finalize: 0.0265
Accumulated time: update_bounds func: 204.5719	 prepare: 3.8097	 bound: 186.0328	 transfer: 0.0889	 finalize: 5.3371
batch bounding time:  1.7897615432739258
Current worst splitting domains [lb, ub] (depth):
[-0.11319,   inf] (59), [-0.11319,   inf] (43), [-0.11319,   inf] (35), [-0.11319,   inf] (39), [-0.11319,   inf] (53), [-0.11319,   inf] (63), [-0.11319,   inf] (37), [-0.11319,   inf] (31), [-0.11318,   inf] (31), [-0.11318,   inf] (55), [-0.11318,   inf] (73), [-0.11318,   inf] (39), [-0.11318,   inf] (67), [-0.11318,   inf] (45), [-0.11318,   inf] (47), [-0.11318,   inf] (59), [-0.11318,   inf] (45), [-0.11317,   inf] (59), [-0.11317,   inf] (53), [-0.11317,   inf] (27), 
length of domains: 22648
Total time: 2.2223	 pickout: 0.0709	 decision: 0.3184	 get_bound: 1.7905	 add_domain: 0.0426
Current lb:-0.11319172382354736
45296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 257.96556782722473

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 15] [2, 83] [2, 50] [2, 149] [2, 27] [2, 171] [2, 11] [2, 95] [2, 95] [2, 145] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 36.3762321472168 with beta sum per layer: [0.0, 0.0, 777.35205078125]
alpha/beta optimization time: 1.6380743980407715
This batch time : update_bounds func: 1.7901	 prepare: 0.0350	 bound: 1.6384	 transfer: 0.0891	 finalize: 0.0262
Accumulated time: update_bounds func: 206.3620	 prepare: 3.8447	 bound: 187.6712	 transfer: 0.0891	 finalize: 5.3633
batch bounding time:  1.7908482551574707
Current worst splitting domains [lb, ub] (depth):
[-0.11301,   inf] (45), [-0.11301,   inf] (31), [-0.11301,   inf] (65), [-0.11301,   inf] (35), [-0.11300,   inf] (59), [-0.11300,   inf] (49), [-0.11300,   inf] (57), [-0.11300,   inf] (25), [-0.11300,   inf] (65), [-0.11300,   inf] (33), [-0.11300,   inf] (41), [-0.11300,   inf] (39), [-0.11300,   inf] (39), [-0.11299,   inf] (51), [-0.11299,   inf] (67), [-0.11299,   inf] (51), [-0.11299,   inf] (43), [-0.11299,   inf] (55), [-0.11299,   inf] (63), [-0.11299,   inf] (45), 
length of domains: 22848
Total time: 2.2270	 pickout: 0.0724	 decision: 0.3174	 get_bound: 1.7917	 add_domain: 0.0455
Current lb:-0.11300718039274216
45696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 260.19891119003296

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 97] [2, 95] [2, 110] [2, 139] [2, 214] [2, 22] [2, 15] [2, 34] [2, 157] [2, 50] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 35.70320510864258 with beta sum per layer: [0.0, 0.0, 832.65087890625]
alpha/beta optimization time: 1.6420867443084717
This batch time : update_bounds func: 1.7922	 prepare: 0.0335	 bound: 1.6424	 transfer: 0.0895	 finalize: 0.0255
Accumulated time: update_bounds func: 208.1542	 prepare: 3.8782	 bound: 189.3136	 transfer: 0.0895	 finalize: 5.3888
batch bounding time:  1.7929437160491943
Current worst splitting domains [lb, ub] (depth):
[-0.11279,   inf] (51), [-0.11279,   inf] (35), [-0.11278,   inf] (59), [-0.11278,   inf] (29), [-0.11278,   inf] (43), [-0.11278,   inf] (63), [-0.11278,   inf] (57), [-0.11278,   inf] (51), [-0.11278,   inf] (53), [-0.11278,   inf] (55), [-0.11277,   inf] (73), [-0.11277,   inf] (23), [-0.11277,   inf] (69), [-0.11277,   inf] (19), [-0.11277,   inf] (25), [-0.11277,   inf] (75), [-0.11277,   inf] (59), [-0.11277,   inf] (31), [-0.11277,   inf] (29), [-0.11277,   inf] (29), 
length of domains: 23047
Total time: 2.2242	 pickout: 0.0682	 decision: 0.3177	 get_bound: 1.7937	 add_domain: 0.0446
Current lb:-0.1127873957157135
46096 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 262.4292914867401

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 75] [2, 128] [2, 166] [2, 131] [2, 92] [2, 108] [2, 166] [2, 27] [2, 75] [2, 15] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 36.16009521484375 with beta sum per layer: [0.0, 0.0, 788.959228515625]
alpha/beta optimization time: 1.644164800643921
This batch time : update_bounds func: 1.7935	 prepare: 0.0333	 bound: 1.6445	 transfer: 0.0883	 finalize: 0.0261
Accumulated time: update_bounds func: 209.9477	 prepare: 3.9115	 bound: 190.9582	 transfer: 0.0883	 finalize: 5.4149
batch bounding time:  1.79416823387146
Current worst splitting domains [lb, ub] (depth):
[-0.11258,   inf] (41), [-0.11258,   inf] (39), [-0.11258,   inf] (45), [-0.11258,   inf] (49), [-0.11258,   inf] (17), [-0.11257,   inf] (39), [-0.11257,   inf] (51), [-0.11257,   inf] (43), [-0.11257,   inf] (17), [-0.11256,   inf] (19), [-0.11256,   inf] (59), [-0.11256,   inf] (33), [-0.11256,   inf] (63), [-0.11256,   inf] (45), [-0.11256,   inf] (39), [-0.11256,   inf] (53), [-0.11256,   inf] (57), [-0.11256,   inf] (49), [-0.11256,   inf] (37), [-0.11256,   inf] (47), 
length of domains: 23247
Total time: 2.2214	 pickout: 0.0689	 decision: 0.3152	 get_bound: 1.7950	 add_domain: 0.0423
Current lb:-0.11257796734571457
46496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 264.65665793418884

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 196] [2, 149] [2, 97] [2, 145] [2, 117] [2, 149] [2, 75] [2, 196] [2, 117] [2, 234] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 35.504905700683594 with beta sum per layer: [0.0, 0.0, 841.1934814453125]
alpha/beta optimization time: 1.6415467262268066
This batch time : update_bounds func: 1.7942	 prepare: 0.0339	 bound: 1.6419	 transfer: 0.0897	 finalize: 0.0274
Accumulated time: update_bounds func: 211.7419	 prepare: 3.9454	 bound: 192.6001	 transfer: 0.0897	 finalize: 5.4423
batch bounding time:  1.7948904037475586
Current worst splitting domains [lb, ub] (depth):
[-0.11237,   inf] (35), [-0.11237,   inf] (69), [-0.11237,   inf] (55), [-0.11237,   inf] (29), [-0.11236,   inf] (41), [-0.11236,   inf] (43), [-0.11236,   inf] (33), [-0.11236,   inf] (51), [-0.11236,   inf] (59), [-0.11236,   inf] (65), [-0.11236,   inf] (51), [-0.11236,   inf] (59), [-0.11236,   inf] (33), [-0.11236,   inf] (31), [-0.11236,   inf] (53), [-0.11235,   inf] (33), [-0.11235,   inf] (67), [-0.11235,   inf] (19), [-0.11235,   inf] (53), [-0.11235,   inf] (41), 
length of domains: 23447
Total time: 2.9274	 pickout: 0.0651	 decision: 1.0242	 get_bound: 1.7957	 add_domain: 0.0424
Current lb:-0.11236749589443207
46896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 267.59035754203796

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 128] [2, 67] [2, 22] [2, 139] [2, 196] [2, 83] [2, 128] [2, 166] [2, 166] [2, 214] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 35.622257232666016 with beta sum per layer: [0.0, 0.0, 784.9686279296875]
alpha/beta optimization time: 1.6420016288757324
This batch time : update_bounds func: 1.7907	 prepare: 0.0334	 bound: 1.6424	 transfer: 0.0888	 finalize: 0.0248
Accumulated time: update_bounds func: 213.5326	 prepare: 3.9788	 bound: 194.2424	 transfer: 0.0888	 finalize: 5.4671
batch bounding time:  1.7913923263549805
Current worst splitting domains [lb, ub] (depth):
[-0.11214,   inf] (43), [-0.11214,   inf] (53), [-0.11214,   inf] (27), [-0.11214,   inf] (61), [-0.11214,   inf] (49), [-0.11214,   inf] (41), [-0.11214,   inf] (45), [-0.11214,   inf] (41), [-0.11214,   inf] (53), [-0.11214,   inf] (55), [-0.11214,   inf] (41), [-0.11214,   inf] (55), [-0.11213,   inf] (59), [-0.11213,   inf] (53), [-0.11213,   inf] (49), [-0.11213,   inf] (47), [-0.11212,   inf] (61), [-0.11212,   inf] (37), [-0.11212,   inf] (55), [-0.11212,   inf] (63), 
length of domains: 23647
Total time: 2.2213	 pickout: 0.0670	 decision: 0.3160	 get_bound: 1.7922	 add_domain: 0.0461
Current lb:-0.11214423179626465
47296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 269.8182487487793

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 196] [2, 75] [2, 34] [2, 214] [2, 27] [2, 83] [2, 83] [2, 196] [2, 145] [2, 15] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 35.36856460571289 with beta sum per layer: [0.0, 0.0, 800.868408203125]
alpha/beta optimization time: 1.642148733139038
This batch time : update_bounds func: 1.7871	 prepare: 0.0335	 bound: 1.6425	 transfer: 0.0848	 finalize: 0.0250
Accumulated time: update_bounds func: 215.3197	 prepare: 4.0123	 bound: 195.8850	 transfer: 0.0848	 finalize: 5.4921
batch bounding time:  1.7878103256225586
Current worst splitting domains [lb, ub] (depth):
[-0.11192,   inf] (21), [-0.11192,   inf] (33), [-0.11192,   inf] (49), [-0.11192,   inf] (69), [-0.11192,   inf] (37), [-0.11192,   inf] (39), [-0.11192,   inf] (39), [-0.11192,   inf] (69), [-0.11192,   inf] (65), [-0.11192,   inf] (55), [-0.11191,   inf] (61), [-0.11191,   inf] (35), [-0.11191,   inf] (55), [-0.11191,   inf] (33), [-0.11191,   inf] (31), [-0.11191,   inf] (67), [-0.11191,   inf] (31), [-0.11191,   inf] (47), [-0.11191,   inf] (31), [-0.11191,   inf] (63), 
length of domains: 23846
Total time: 2.2145	 pickout: 0.0660	 decision: 0.3149	 get_bound: 1.7886	 add_domain: 0.0450
Current lb:-0.11192256957292557
47696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 272.0389099121094

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 7] [2, 50] [2, 97] [2, 223] [2, 139] [2, 149] [2, 149] [2, 108] [2, 110] [2, 166] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 35.32487106323242 with beta sum per layer: [0.0, 0.0, 806.6109619140625]
alpha/beta optimization time: 1.6418602466583252
This batch time : update_bounds func: 1.7919	 prepare: 0.0338	 bound: 1.6422	 transfer: 0.0880	 finalize: 0.0266
Accumulated time: update_bounds func: 217.1116	 prepare: 4.0461	 bound: 197.5272	 transfer: 0.0880	 finalize: 5.5187
batch bounding time:  1.7925925254821777
Current worst splitting domains [lb, ub] (depth):
[-0.11170,   inf] (33), [-0.11170,   inf] (43), [-0.11170,   inf] (61), [-0.11170,   inf] (39), [-0.11170,   inf] (31), [-0.11170,   inf] (57), [-0.11170,   inf] (39), [-0.11170,   inf] (49), [-0.11170,   inf] (31), [-0.11170,   inf] (27), [-0.11170,   inf] (63), [-0.11169,   inf] (35), [-0.11169,   inf] (63), [-0.11169,   inf] (53), [-0.11169,   inf] (73), [-0.11169,   inf] (45), [-0.11169,   inf] (61), [-0.11169,   inf] (55), [-0.11169,   inf] (63), [-0.11169,   inf] (69), 
length of domains: 24046
Total time: 2.2189	 pickout: 0.0664	 decision: 0.3152	 get_bound: 1.7934	 add_domain: 0.0438
Current lb:-0.11170165240764618
48096 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 274.26405477523804

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 50] [2, 196] [2, 214] [2, 149] [2, 95] [2, 22] [2, 149] [2, 22] [2, 95] [2, 131] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 35.59587860107422 with beta sum per layer: [0.0, 0.0, 779.3907470703125]
alpha/beta optimization time: 1.6320042610168457
This batch time : update_bounds func: 1.7794	 prepare: 0.0340	 bound: 1.6324	 transfer: 0.0855	 finalize: 0.0262
Accumulated time: update_bounds func: 218.8910	 prepare: 4.0801	 bound: 199.1595	 transfer: 0.0855	 finalize: 5.5449
batch bounding time:  1.780045986175537
Current worst splitting domains [lb, ub] (depth):
[-0.11148,   inf] (25), [-0.11148,   inf] (25), [-0.11148,   inf] (49), [-0.11148,   inf] (45), [-0.11148,   inf] (59), [-0.11148,   inf] (51), [-0.11148,   inf] (23), [-0.11147,   inf] (73), [-0.11147,   inf] (51), [-0.11147,   inf] (53), [-0.11147,   inf] (47), [-0.11147,   inf] (63), [-0.11147,   inf] (25), [-0.11147,   inf] (29), [-0.11147,   inf] (51), [-0.11147,   inf] (33), [-0.11147,   inf] (65), [-0.11147,   inf] (47), [-0.11147,   inf] (39), [-0.11147,   inf] (51), 
length of domains: 24245
Total time: 2.2165	 pickout: 0.0719	 decision: 0.3195	 get_bound: 1.7808	 add_domain: 0.0443
Current lb:-0.11148174107074738
48496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 276.486857175827

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 34] [2, 34] [2, 22] [2, 92] [2, 214] [2, 97] [2, 139] [2, 108] [2, 145] [2, 22] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 35.33594512939453 with beta sum per layer: [0.0, 0.0, 791.458251953125]
alpha/beta optimization time: 1.6318531036376953
This batch time : update_bounds func: 1.7835	 prepare: 0.0346	 bound: 1.6322	 transfer: 0.0890	 finalize: 0.0263
Accumulated time: update_bounds func: 220.6745	 prepare: 4.1148	 bound: 200.7918	 transfer: 0.0890	 finalize: 5.5712
batch bounding time:  1.7842953205108643
Current worst splitting domains [lb, ub] (depth):
[-0.11126,   inf] (49), [-0.11126,   inf] (41), [-0.11126,   inf] (41), [-0.11126,   inf] (31), [-0.11125,   inf] (65), [-0.11125,   inf] (31), [-0.11125,   inf] (35), [-0.11125,   inf] (51), [-0.11125,   inf] (37), [-0.11125,   inf] (39), [-0.11125,   inf] (47), [-0.11125,   inf] (39), [-0.11125,   inf] (41), [-0.11125,   inf] (37), [-0.11125,   inf] (43), [-0.11125,   inf] (57), [-0.11125,   inf] (63), [-0.11124,   inf] (59), [-0.11124,   inf] (49), [-0.11124,   inf] (29), 
length of domains: 24444
Total time: 2.2269	 pickout: 0.0695	 decision: 0.3241	 get_bound: 1.7851	 add_domain: 0.0482
Current lb:-0.11125759780406952
48896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 278.72056818008423

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 22] [2, 196] [2, 196] [2, 95] [2, 157] [2, 95] [2, 128] [2, 22] [2, 92] [2, 149] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 35.210723876953125 with beta sum per layer: [0.0, 0.03978601098060608, 814.5570068359375]
alpha/beta optimization time: 1.6377837657928467
This batch time : update_bounds func: 1.7870	 prepare: 0.0346	 bound: 1.6382	 transfer: 0.0867	 finalize: 0.0263
Accumulated time: update_bounds func: 222.4616	 prepare: 4.1493	 bound: 202.4299	 transfer: 0.0867	 finalize: 5.5975
batch bounding time:  1.7878239154815674
Current worst splitting domains [lb, ub] (depth):
[-0.11106,   inf] (53), [-0.11106,   inf] (19), [-0.11106,   inf] (27), [-0.11106,   inf] (37), [-0.11106,   inf] (69), [-0.11106,   inf] (45), [-0.11106,   inf] (33), [-0.11106,   inf] (43), [-0.11106,   inf] (49), [-0.11106,   inf] (39), [-0.11105,   inf] (55), [-0.11105,   inf] (45), [-0.11105,   inf] (25), [-0.11105,   inf] (51), [-0.11105,   inf] (39), [-0.11105,   inf] (37), [-0.11105,   inf] (35), [-0.11105,   inf] (37), [-0.11105,   inf] (55), [-0.11105,   inf] (45), 
length of domains: 24644
Total time: 2.2333	 pickout: 0.0731	 decision: 0.3255	 get_bound: 1.7887	 add_domain: 0.0460
Current lb:-0.1110638827085495
49296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 280.960298538208

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 22] [2, 234] [2, 34] [2, 139] [2, 223] [2, 83] [2, 128] [2, 196] [2, 22] [2, 149] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 35.02537155151367 with beta sum per layer: [0.0, 0.0, 752.2568359375]
alpha/beta optimization time: 1.6398158073425293
This batch time : update_bounds func: 2.5158	 prepare: 0.0340	 bound: 1.6402	 transfer: 0.0859	 finalize: 0.7544
Accumulated time: update_bounds func: 224.9774	 prepare: 4.1834	 bound: 204.0701	 transfer: 0.0859	 finalize: 6.3519
batch bounding time:  2.5165886878967285
Current worst splitting domains [lb, ub] (depth):
[-0.11085,   inf] (21), [-0.11085,   inf] (25), [-0.11085,   inf] (57), [-0.11085,   inf] (37), [-0.11085,   inf] (55), [-0.11085,   inf] (39), [-0.11084,   inf] (71), [-0.11084,   inf] (69), [-0.11084,   inf] (57), [-0.11084,   inf] (47), [-0.11084,   inf] (47), [-0.11084,   inf] (41), [-0.11084,   inf] (75), [-0.11084,   inf] (59), [-0.11084,   inf] (61), [-0.11084,   inf] (75), [-0.11084,   inf] (29), [-0.11084,   inf] (45), [-0.11084,   inf] (25), [-0.11084,   inf] (59), 
length of domains: 24844
Total time: 2.9547	 pickout: 0.0751	 decision: 0.3180	 get_bound: 2.5174	 add_domain: 0.0441
Current lb:-0.11085102707147598
49696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 283.92113518714905

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 229] [2, 7] [2, 166] [2, 11] [2, 166] [2, 149] [2, 108] [2, 108] [2, 166] [2, 22] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 35.89999771118164 with beta sum per layer: [0.0, 0.0, 718.406005859375]
alpha/beta optimization time: 1.6357111930847168
This batch time : update_bounds func: 1.7862	 prepare: 0.0345	 bound: 1.6361	 transfer: 0.0867	 finalize: 0.0276
Accumulated time: update_bounds func: 226.7636	 prepare: 4.2179	 bound: 205.7062	 transfer: 0.0867	 finalize: 6.3795
batch bounding time:  1.7869012355804443
Current worst splitting domains [lb, ub] (depth):
[-0.11065,   inf] (39), [-0.11065,   inf] (39), [-0.11065,   inf] (41), [-0.11065,   inf] (41), [-0.11064,   inf] (61), [-0.11064,   inf] (51), [-0.11064,   inf] (27), [-0.11064,   inf] (33), [-0.11064,   inf] (73), [-0.11064,   inf] (51), [-0.11064,   inf] (55), [-0.11063,   inf] (39), [-0.11063,   inf] (35), [-0.11063,   inf] (51), [-0.11063,   inf] (53), [-0.11063,   inf] (55), [-0.11063,   inf] (47), [-0.11063,   inf] (67), [-0.11063,   inf] (39), [-0.11063,   inf] (53), 
length of domains: 25044
Total time: 2.2295	 pickout: 0.0724	 decision: 0.3235	 get_bound: 1.7877	 add_domain: 0.0459
Current lb:-0.11064910143613815
50096 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 286.15715742111206

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 149] [2, 83] [2, 196] [2, 83] [2, 214] [2, 27] [2, 34] [2, 50] [2, 110] [2, 97] 
regular batch size: 2*200, diving batch size 1*0/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:25: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1627336316785/work/torch/csrc/utils/tensor_numpy.cpp:143.)
  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))

best_l after optimization: 35.23805236816406 with beta sum per layer: [0.0, 0.0, 828.3779907226562]
alpha/beta optimization time: 1.635530710220337
This batch time : update_bounds func: 1.7837	 prepare: 0.0344	 bound: 1.6359	 transfer: 0.0854	 finalize: 0.0266
Accumulated time: update_bounds func: 228.5473	 prepare: 4.2522	 bound: 207.3421	 transfer: 0.0854	 finalize: 6.4061
batch bounding time:  1.7844586372375488
Current worst splitting domains [lb, ub] (depth):
[-0.11046,   inf] (27), [-0.11046,   inf] (59), [-0.11046,   inf] (19), [-0.11046,   inf] (59), [-0.11046,   inf] (45), [-0.11046,   inf] (49), [-0.11046,   inf] (67), [-0.11046,   inf] (33), [-0.11046,   inf] (75), [-0.11046,   inf] (41), [-0.11046,   inf] (55), [-0.11046,   inf] (73), [-0.11045,   inf] (25), [-0.11045,   inf] (57), [-0.11045,   inf] (29), [-0.11045,   inf] (51), [-0.11045,   inf] (47), [-0.11045,   inf] (43), [-0.11045,   inf] (31), [-0.11045,   inf] (47), 
length of domains: 25243
Total time: 2.2341	 pickout: 0.0783	 decision: 0.3223	 get_bound: 1.7853	 add_domain: 0.0482
Current lb:-0.11046478152275085
50496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 288.3975622653961

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 139] [2, 166] [2, 234] [2, 166] [2, 83] [2, 75] [2, 108] [2, 50] [2, 10] [2, 196] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 34.575965881347656 with beta sum per layer: [0.0, 0.0, 861.5596923828125]
alpha/beta optimization time: 1.637697458267212
This batch time : update_bounds func: 1.7851	 prepare: 0.0353	 bound: 1.6381	 transfer: 0.0850	 finalize: 0.0254
Accumulated time: update_bounds func: 230.3324	 prepare: 4.2875	 bound: 208.9801	 transfer: 0.0850	 finalize: 6.4315
batch bounding time:  1.7858500480651855
Current worst splitting domains [lb, ub] (depth):
[-0.11027,   inf] (37), [-0.11027,   inf] (57), [-0.11026,   inf] (51), [-0.11026,   inf] (59), [-0.11026,   inf] (45), [-0.11026,   inf] (29), [-0.11026,   inf] (45), [-0.11026,   inf] (25), [-0.11026,   inf] (43), [-0.11026,   inf] (43), [-0.11026,   inf] (65), [-0.11026,   inf] (65), [-0.11026,   inf] (41), [-0.11026,   inf] (41), [-0.11025,   inf] (45), [-0.11025,   inf] (55), [-0.11025,   inf] (25), [-0.11025,   inf] (39), [-0.11025,   inf] (49), [-0.11025,   inf] (53), 
length of domains: 25442
Total time: 2.2282	 pickout: 0.0752	 decision: 0.3222	 get_bound: 1.7866	 add_domain: 0.0441
Current lb:-0.11026719957590103
50896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 290.6319251060486

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 11] [2, 15] [2, 97] [2, 166] [2, 97] [2, 50] [2, 97] [2, 34] [2, 92] [2, 145] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 35.24981689453125 with beta sum per layer: [0.0, 0.0, 786.6463012695312]
alpha/beta optimization time: 1.6354279518127441
This batch time : update_bounds func: 1.7781	 prepare: 0.0339	 bound: 1.6358	 transfer: 0.0808	 finalize: 0.0263
Accumulated time: update_bounds func: 232.1105	 prepare: 4.3214	 bound: 210.6159	 transfer: 0.0808	 finalize: 6.4578
batch bounding time:  1.7788307666778564
Current worst splitting domains [lb, ub] (depth):
[-0.11007,   inf] (35), [-0.11007,   inf] (31), [-0.11007,   inf] (29), [-0.11007,   inf] (57), [-0.11007,   inf] (39), [-0.11007,   inf] (57), [-0.11007,   inf] (39), [-0.11006,   inf] (43), [-0.11006,   inf] (39), [-0.11006,   inf] (43), [-0.11006,   inf] (31), [-0.11006,   inf] (73), [-0.11006,   inf] (55), [-0.11006,   inf] (49), [-0.11006,   inf] (69), [-0.11006,   inf] (75), [-0.11006,   inf] (17), [-0.11006,   inf] (43), [-0.11006,   inf] (37), [-0.11006,   inf] (45), 
length of domains: 25642
Total time: 2.2227	 pickout: 0.0784	 decision: 0.3192	 get_bound: 1.7796	 add_domain: 0.0455
Current lb:-0.11007486283779144
51296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 292.860857963562

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([200, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 139] [2, 95] [2, 50] [2, 15] [2, 149] [2, 166] [2, 149] [2, 92] [2, 149] [2, 196] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 34.56209945678711 with beta sum per layer: [0.0, 0.0, 786.669189453125]
alpha/beta optimization time: 1.6388707160949707
This batch time : update_bounds func: 1.7892	 prepare: 0.0375	 bound: 1.6392	 transfer: 0.0840	 finalize: 0.0273
Accumulated time: update_bounds func: 233.8998	 prepare: 4.3589	 bound: 212.2551	 transfer: 0.0840	 finalize: 6.4851
batch bounding time:  1.78989577293396
Current worst splitting domains [lb, ub] (depth):
[-0.10988,   inf] (37), [-0.10988,   inf] (35), [-0.10988,   inf] (43), [-0.10988,   inf] (63), [-0.10988,   inf] (49), [-0.10988,   inf] (45), [-0.10988,   inf] (59), [-0.10988,   inf] (57), [-0.10987,   inf] (39), [-0.10987,   inf] (67), [-0.10987,   inf] (49), [-0.10987,   inf] (21), [-0.10987,   inf] (67), [-0.10987,   inf] (15), [-0.10987,   inf] (67), [-0.10987,   inf] (69), [-0.10987,   inf] (41), [-0.10986,   inf] (31), [-0.10986,   inf] (35), [-0.10986,   inf] (67), 
length of domains: 25841
Total time: 2.2319	 pickout: 0.0766	 decision: 0.3208	 get_bound: 1.7907	 add_domain: 0.0438
Current lb:-0.10988160967826843
51696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Time out!!!!!!!!
Image 0 against label 4 verification end, Time cost: 295.7512366771698
Result: unknown in 314.8113 seconds


[[    0.             1.12611449     0.             0.00032282
      0.        ]
 [    0.             0.91333354     0.             0.0003314
      1.        ]
 [    0.             0.0000001     16.             2.91390228
      2.        ]
 [    0.             0.0000001     62.             3.0322957
      3.        ]
 [    0.            -0.10988161 51696.           295.75123668
      4.        ]]
############# Summary #############
Final verified acc: 0.0% [total 1 examples]
Total verification count: 1 , total verified safe: 0 , verified unsafe: 0 , timeout: 1
mean time [total:1]: 301.69808888435364
mean time [cnt:1]: 301.69808888435364
max time 314.81132435798645
unknown (total 1): [0]
