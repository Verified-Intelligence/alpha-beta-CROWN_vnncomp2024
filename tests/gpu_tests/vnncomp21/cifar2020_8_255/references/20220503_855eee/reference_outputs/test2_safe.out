Building native CUDA modules...
/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
  csv_name: cifar2020_instances.csv
  onnx_path: null
  vnnlib_path: null
  results_file: null
  root_path: ../../../../../vnncomp2021/benchmarks/cifar2020
model:
  path: null
  name: mnist_9_200
data:
  start: 121
  end: 122
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR
  data_filter_path: null
specification:
  type: lp
  norm: .inf
  epsilon: null
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 200
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.01
    lr_decay: 0.98
    optimizer: adam
    iteration: 50
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 360
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 10
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:10:35 2022 on ubuntu
saving results to vnn-comp_[cifar2020_instances]_start=121_end=122_iter=50_b=200_timeout=360_branching=kfsb-max-10_lra-init=0.1_lra=0.01_lrb=0.01_PGD=before.npz
customized start/end sample from 121 to 122

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
##### PGD attack: True label: 9, Tested against: [0, 1, 2, 3, 4, 5, 6, 7, 8] ######
pgd prediction: tensor([-0.2849,  0.1348,  0.2000, -0.0128, -0.3974, -0.2700, -0.5843,  0.9304,
        -0.7933,  1.1769], device='cuda:0', grad_fn=<SqueezeBackward1>)
attack margin tensor([1.4618, 1.0421, 0.9769, 1.1897, 1.5743, 1.4469, 1.7612, 0.2465, 1.9702,
           inf], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[-0.2645,  0.8440, -0.0178, -0.0686, -0.6196, -0.4751, -0.6186,  0.1821,
         -0.4023,  1.7282]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 0.2225, -0.3299, -0.3313, -0.0254,  0.5140,  0.1120,  0.1814, -1.0419,
          0.2489]], device='cuda:0') None
best_l after optimization: -1.2983101606369019 with beta sum per layer: []
alpha/beta optimization time: 8.046030044555664
initial alpha-CROWN bounds: tensor([[ 0.3942, -0.2259, -0.1213,  0.1653,  0.6940,  0.3581,  0.3964, -0.7856,
          0.4232]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.7856, device='cuda:0', grad_fn=<MinBackward1>)
##### [0] True label: 9, Tested against: 0, onnx_path: nets/cifar10_8_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_76_eps_0.03137_n1.vnnlib ######
init opt crown verified for label 0 with bound 0.3941802680492401
Image 0 against label 0 verification end, Time cost: 0.0003046989440917969
##### [0] True label: 9, Tested against: 1, onnx_path: nets/cifar10_8_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_76_eps_0.03137_n1.vnnlib ######
Model prediction is: tensor([[-0.2645,  0.8440, -0.0178, -0.0686, -0.6196, -0.4751, -0.6186,  0.1821,
         -0.4023,  1.7282]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /9 torch.Size([1, 32, 16, 16])
1 /11 torch.Size([1, 128, 8, 8])
2 /14 torch.Size([1, 250])
best_l after optimization: 0.22585998475551605 with beta sum per layer: []
alpha/beta optimization time: 1.9046719074249268
alpha-CROWN with fixed intermediate bounds: tensor([[-0.2259]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.22585998475551605
layer 0 size torch.Size([8192]) unstable 215
layer 1 size torch.Size([8192]) unstable 838
layer 2 size torch.Size([250]) unstable 105
-----------------
# of unstable neurons: 1158
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 61] 
split level 1: [2, 211] 
split level 2: [2, 87] 
split level 3: [2, 9] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -1.4396255016326904 with beta sum per layer: [0.0, 0.0, 0.620981752872467]
alpha/beta optimization time: 0.571080207824707
This batch time : update_bounds func: 0.5775	 prepare: 0.0029	 bound: 0.5716	 transfer: 0.0019	 finalize: 0.0010
Accumulated time: update_bounds func: 0.5775	 prepare: 0.0029	 bound: 0.5716	 transfer: 0.0019	 finalize: 0.0010
batch bounding time:  0.5776622295379639
Current worst splitting domains [lb, ub] (depth):
[-0.11948,   inf] (5), [-0.06890,   inf] (5), [-0.01929,   inf] (5), 
length of domains: 3
Total time: 0.6320	 pickout: 0.0010	 decision: 0.0512	 get_bound: 0.5796	 add_domain: 0.0003
Current lb:-0.11947587132453918
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.470130443572998

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3, 32, 16, 16]) pre split depth:  2
batch:  torch.Size([3, 32, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [2, 153] [2, 135] [2, 153] 
split level 1: [2, 135] [2, 153] [2, 135] 
regular batch size: 2*6, diving batch size 1*0
best_l after optimization: -0.6885817646980286 with beta sum per layer: [0.0, 0.0, 1.970658779144287]
alpha/beta optimization time: 0.5640604496002197
This batch time : update_bounds func: 0.5689	 prepare: 0.0021	 bound: 0.5643	 transfer: 0.0016	 finalize: 0.0008
Accumulated time: update_bounds func: 1.1464	 prepare: 0.0050	 bound: 1.1359	 transfer: 0.0016	 finalize: 0.0018
batch bounding time:  0.5690386295318604
Current worst splitting domains [lb, ub] (depth):
[-0.02771,   inf] (8), [-0.00471,   inf] (8), 
length of domains: 2
Total time: 0.6233	 pickout: 0.0013	 decision: 0.0517	 get_bound: 0.5701	 add_domain: 0.0002
Current lb:-0.027713550254702568
28 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.093636751174927

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2, 32, 16, 16]) pre split depth:  3
batch:  torch.Size([2, 32, 16, 16]) post split depth:  3
splitting decisions: 
split level 0: [2, 97] [2, 97] 
split level 1: [2, 160] [2, 160] 
split level 2: [2, 173] [2, 91] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -1.8787814378738403 with beta sum per layer: [0.0, 0.0, 0.5162808299064636]
alpha/beta optimization time: 0.008103132247924805
This batch time : update_bounds func: 0.0136	 prepare: 0.0024	 bound: 0.0083	 transfer: 0.0017	 finalize: 0.0010
Accumulated time: update_bounds func: 1.1599	 prepare: 0.0074	 bound: 1.1442	 transfer: 0.0017	 finalize: 0.0028
batch bounding time:  0.013607025146484375
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0680	 pickout: 0.0011	 decision: 0.0515	 get_bound: 0.0154	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 4.161889553070068

Image 0 against label 1 verification end, Time cost: 4.225315570831299
##### [0] True label: 9, Tested against: 2, onnx_path: nets/cifar10_8_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_76_eps_0.03137_n1.vnnlib ######
Model prediction is: tensor([[-0.2645,  0.8440, -0.0178, -0.0686, -0.6196, -0.4751, -0.6186,  0.1821,
         -0.4023,  1.7282]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /9 torch.Size([1, 32, 16, 16])
1 /11 torch.Size([1, 128, 8, 8])
2 /14 torch.Size([1, 250])
best_l after optimization: 0.12130308151245117 with beta sum per layer: []
alpha/beta optimization time: 0.9653177261352539
alpha-CROWN with fixed intermediate bounds: tensor([[-0.1213]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.12130308151245117
layer 0 size torch.Size([8192]) unstable 215
layer 1 size torch.Size([8192]) unstable 838
layer 2 size torch.Size([250]) unstable 105
-----------------
# of unstable neurons: 1158
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 120] 
split level 1: [2, 210] 
split level 2: [2, 20] 
split level 3: [2, 157] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -2.7328314781188965 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.5669901371002197
This batch time : update_bounds func: 0.5731	 prepare: 0.0028	 bound: 0.5675	 transfer: 0.0017	 finalize: 0.0010
Accumulated time: update_bounds func: 1.7330	 prepare: 0.0102	 bound: 1.7118	 transfer: 0.0017	 finalize: 0.0038
batch bounding time:  0.5732276439666748
Current worst splitting domains [lb, ub] (depth):
[-0.03295,   inf] (5), 
length of domains: 1
Total time: 0.6265	 pickout: 0.0008	 decision: 0.0505	 get_bound: 0.5751	 add_domain: 0.0001
Current lb:-0.03294992446899414
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.613034725189209

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 114] 
split level 1: [2, 37] 
split level 2: [2, 124] 
split level 3: [2, 162] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -4.106719017028809 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.007950544357299805
This batch time : update_bounds func: 0.0134	 prepare: 0.0025	 bound: 0.0082	 transfer: 0.0017	 finalize: 0.0010
Accumulated time: update_bounds func: 1.7464	 prepare: 0.0127	 bound: 1.7199	 transfer: 0.0017	 finalize: 0.0048
batch bounding time:  0.013507366180419922
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0667	 pickout: 0.0008	 decision: 0.0504	 get_bound: 0.0154	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.6799888610839844

Image 0 against label 2 verification end, Time cost: 1.7431018352508545
##### [0] True label: 9, Tested against: 3, onnx_path: nets/cifar10_8_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_76_eps_0.03137_n1.vnnlib ######
init opt crown verified for label 3 with bound 0.16530346870422363
Image 0 against label 3 verification end, Time cost: 0.0003001689910888672
##### [0] True label: 9, Tested against: 4, onnx_path: nets/cifar10_8_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_76_eps_0.03137_n1.vnnlib ######
init opt crown verified for label 4 with bound 0.6940069794654846
Image 0 against label 4 verification end, Time cost: 0.00030350685119628906
##### [0] True label: 9, Tested against: 5, onnx_path: nets/cifar10_8_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_76_eps_0.03137_n1.vnnlib ######
init opt crown verified for label 5 with bound 0.3580732047557831
Image 0 against label 5 verification end, Time cost: 0.0003039836883544922
##### [0] True label: 9, Tested against: 6, onnx_path: nets/cifar10_8_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_76_eps_0.03137_n1.vnnlib ######
init opt crown verified for label 6 with bound 0.39635542035102844
Image 0 against label 6 verification end, Time cost: 0.00031280517578125
##### [0] True label: 9, Tested against: 7, onnx_path: nets/cifar10_8_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_76_eps_0.03137_n1.vnnlib ######
Model prediction is: tensor([[-0.2645,  0.8440, -0.0178, -0.0686, -0.6196, -0.4751, -0.6186,  0.1821,
         -0.4023,  1.7282]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /9 torch.Size([1, 32, 16, 16])
1 /11 torch.Size([1, 128, 8, 8])
2 /14 torch.Size([1, 250])
best_l after optimization: 0.785581111907959 with beta sum per layer: []
alpha/beta optimization time: 1.0051372051239014
alpha-CROWN with fixed intermediate bounds: tensor([[-0.7856]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.785581111907959
layer 0 size torch.Size([8192]) unstable 215
layer 1 size torch.Size([8192]) unstable 838
layer 2 size torch.Size([250]) unstable 105
-----------------
# of unstable neurons: 1158
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 149] 
split level 1: [2, 30] 
split level 2: [2, 193] 
split level 3: [2, 27] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 2.8979501724243164 with beta sum per layer: [0.0, 0.0, 2.5279455184936523]
alpha/beta optimization time: 0.6021692752838135
This batch time : update_bounds func: 0.6083	 prepare: 0.0028	 bound: 0.6026	 transfer: 0.0018	 finalize: 0.0010
Accumulated time: update_bounds func: 2.3547	 prepare: 0.0154	 bound: 2.3226	 transfer: 0.0018	 finalize: 0.0058
batch bounding time:  0.6084184646606445
Current worst splitting domains [lb, ub] (depth):
[-0.50380,   inf] (5), [-0.47790,   inf] (5), [-0.42999,   inf] (5), [-0.42939,   inf] (5), [-0.42799,   inf] (5), [-0.37687,   inf] (5), [-0.32866,   inf] (5), [-0.31449,   inf] (5), 
length of domains: 8
Total time: 0.6623	 pickout: 0.0008	 decision: 0.0509	 get_bound: 0.6103	 add_domain: 0.0004
Current lb:-0.5037959814071655
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.688246726989746

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([8, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 152] [2, 163] [2, 94] [2, 94] [2, 152] [2, 152] [2, 152] [2, 152] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 4.972725868225098 with beta sum per layer: [0.0, 0.0, 9.883218765258789]
alpha/beta optimization time: 0.5719382762908936
This batch time : update_bounds func: 0.5775	 prepare: 0.0025	 bound: 0.5722	 transfer: 0.0018	 finalize: 0.0010
Accumulated time: update_bounds func: 2.9322	 prepare: 0.0179	 bound: 2.8948	 transfer: 0.0018	 finalize: 0.0068
batch bounding time:  0.5777065753936768
Current worst splitting domains [lb, ub] (depth):
[-0.47687,   inf] (7), [-0.44746,   inf] (7), [-0.42525,   inf] (7), [-0.42488,   inf] (7), [-0.39465,   inf] (7), [-0.34923,   inf] (7), [-0.34285,   inf] (7), [-0.32876,   inf] (7), [-0.28433,   inf] (7), [-0.27495,   inf] (7), [-0.25187,   inf] (7), [-0.24670,   inf] (7), [-0.23133,   inf] (7), [-0.19760,   inf] (7), [-0.15036,   inf] (7), [-0.14563,   inf] (7), 
length of domains: 16
Total time: 0.6382	 pickout: 0.0024	 decision: 0.0574	 get_bound: 0.5777	 add_domain: 0.0007
Current lb:-0.476870596408844
32 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.326711416244507

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([16, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([16, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 163] [2, 94] [2, 35] [2, 152] [2, 94] [2, 163] [2, 163] [2, 152] [2, 94] [2, 94] 
regular batch size: 2*16, diving batch size 1*0
best_l after optimization: 6.557463645935059 with beta sum per layer: [0.0, 0.0, 34.45924377441406]
alpha/beta optimization time: 0.5869870185852051
This batch time : update_bounds func: 0.5959	 prepare: 0.0036	 bound: 0.5873	 transfer: 0.0030	 finalize: 0.0019
Accumulated time: update_bounds func: 3.5282	 prepare: 0.0216	 bound: 3.4821	 transfer: 0.0030	 finalize: 0.0087
batch bounding time:  0.5960831642150879
Current worst splitting domains [lb, ub] (depth):
[-0.44672,   inf] (9), [-0.44595,   inf] (9), [-0.41490,   inf] (9), [-0.39482,   inf] (9), [-0.38758,   inf] (9), [-0.32945,   inf] (9), [-0.30348,   inf] (9), [-0.29478,   inf] (9), [-0.28930,   inf] (9), [-0.27833,   inf] (9), [-0.27090,   inf] (9), [-0.26981,   inf] (9), [-0.26264,   inf] (9), [-0.26182,   inf] (9), [-0.21252,   inf] (9), [-0.19941,   inf] (9), [-0.18823,   inf] (9), [-0.18709,   inf] (9), [-0.17314,   inf] (9), [-0.16036,   inf] (9), 
length of domains: 30
Total time: 0.6628	 pickout: 0.0042	 decision: 0.0611	 get_bound: 0.5961	 add_domain: 0.0013
Current lb:-0.44671979546546936
64 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.989896535873413

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([30, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([30, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 94] [2, 152] [2, 163] [2, 35] [2, 163] [2, 94] [2, 94] [2, 94] [2, 35] [2, 94] 
regular batch size: 2*30, diving batch size 1*0
best_l after optimization: 7.196697235107422 with beta sum per layer: [0.0, 0.0, 84.43282318115234]
alpha/beta optimization time: 0.638350248336792
This batch time : update_bounds func: 0.6564	 prepare: 0.0059	 bound: 0.6386	 transfer: 0.0084	 finalize: 0.0034
Accumulated time: update_bounds func: 4.1846	 prepare: 0.0274	 bound: 4.1207	 transfer: 0.0084	 finalize: 0.0121
batch bounding time:  0.6566271781921387
Current worst splitting domains [lb, ub] (depth):
[-0.44535,   inf] (11), [-0.41910,   inf] (11), [-0.38624,   inf] (11), [-0.37913,   inf] (11), [-0.35230,   inf] (11), [-0.30593,   inf] (11), [-0.30378,   inf] (11), [-0.29945,   inf] (11), [-0.28854,   inf] (11), [-0.27167,   inf] (11), [-0.26528,   inf] (11), [-0.25851,   inf] (11), [-0.25648,   inf] (11), [-0.25504,   inf] (11), [-0.24875,   inf] (11), [-0.24628,   inf] (11), [-0.24030,   inf] (11), [-0.19135,   inf] (11), [-0.18866,   inf] (11), [-0.17801,   inf] (11), 
length of domains: 44
Total time: 0.7407	 pickout: 0.0072	 decision: 0.0747	 get_bound: 0.6567	 add_domain: 0.0020
Current lb:-0.4453459680080414
124 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.7312278747558594

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([44, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([44, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 34] [2, 34] [2, 163] [2, 34] [2, 34] [2, 35] [2, 34] [2, 34] [2, 152] [2, 35] 
regular batch size: 2*44, diving batch size 1*0
best_l after optimization: 7.141620635986328 with beta sum per layer: [0.0, 0.0, 142.97320556640625]
alpha/beta optimization time: 0.6719088554382324
This batch time : update_bounds func: 0.7059	 prepare: 0.0081	 bound: 0.6722	 transfer: 0.0200	 finalize: 0.0053
Accumulated time: update_bounds func: 4.8904	 prepare: 0.0355	 bound: 4.7929	 transfer: 0.0200	 finalize: 0.0174
batch bounding time:  0.7062318325042725
Current worst splitting domains [lb, ub] (depth):
[-0.41911,   inf] (13), [-0.39380,   inf] (13), [-0.34979,   inf] (13), [-0.34964,   inf] (13), [-0.31844,   inf] (13), [-0.30855,   inf] (13), [-0.28020,   inf] (13), [-0.27525,   inf] (13), [-0.26435,   inf] (13), [-0.26136,   inf] (13), [-0.25321,   inf] (13), [-0.24707,   inf] (13), [-0.24346,   inf] (13), [-0.24191,   inf] (13), [-0.22736,   inf] (13), [-0.22255,   inf] (13), [-0.21563,   inf] (13), [-0.20742,   inf] (13), [-0.20274,   inf] (13), [-0.19971,   inf] (13), 
length of domains: 53
Total time: 0.8061	 pickout: 0.0102	 decision: 0.0867	 get_bound: 0.7064	 add_domain: 0.0028
Current lb:-0.4191066026687622
212 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.538594484329224

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([53, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([53, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 120] [2, 120] [2, 34] [2, 152] [2, 120] [2, 120] [2, 35] [2, 34] [2, 120] [2, 34] 
regular batch size: 2*53, diving batch size 1*0
best_l after optimization: 6.759975433349609 with beta sum per layer: [0.0, 0.0, 180.02926635742188]
alpha/beta optimization time: 0.7062337398529053
This batch time : update_bounds func: 0.7420	 prepare: 0.0096	 bound: 0.7066	 transfer: 0.0195	 finalize: 0.0060
Accumulated time: update_bounds func: 5.6324	 prepare: 0.0451	 bound: 5.4995	 transfer: 0.0195	 finalize: 0.0234
batch bounding time:  0.7422502040863037
Current worst splitting domains [lb, ub] (depth):
[-0.40570,   inf] (15), [-0.38068,   inf] (15), [-0.32105,   inf] (15), [-0.31928,   inf] (15), [-0.30344,   inf] (15), [-0.28029,   inf] (15), [-0.25530,   inf] (15), [-0.24866,   inf] (15), [-0.24844,   inf] (15), [-0.22391,   inf] (15), [-0.22284,   inf] (15), [-0.22276,   inf] (15), [-0.21841,   inf] (15), [-0.21766,   inf] (15), [-0.20959,   inf] (15), [-0.20238,   inf] (15), [-0.19643,   inf] (15), [-0.19226,   inf] (15), [-0.19222,   inf] (15), [-0.18018,   inf] (15), 
length of domains: 60
Total time: 0.8766	 pickout: 0.0145	 decision: 0.1166	 get_bound: 0.7424	 add_domain: 0.0030
Current lb:-0.4056960642337799
318 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.416428804397583

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([60, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([60, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 17] [2, 35] [2, 120] [2, 120] [2, 17] [2, 35] [2, 120] [2, 35] [2, 17] [2, 120] 
regular batch size: 2*60, diving batch size 1*0
best_l after optimization: 6.181065559387207 with beta sum per layer: [0.0, 0.0, 211.38095092773438]
alpha/beta optimization time: 0.7202720642089844
This batch time : update_bounds func: 0.7527	 prepare: 0.0106	 bound: 0.7206	 transfer: 0.0146	 finalize: 0.0067
Accumulated time: update_bounds func: 6.3851	 prepare: 0.0557	 bound: 6.2200	 transfer: 0.0146	 finalize: 0.0301
batch bounding time:  0.7531962394714355
Current worst splitting domains [lb, ub] (depth):
[-0.38260,   inf] (17), [-0.37230,   inf] (17), [-0.30855,   inf] (17), [-0.30641,   inf] (17), [-0.28041,   inf] (17), [-0.27695,   inf] (17), [-0.26013,   inf] (17), [-0.24019,   inf] (17), [-0.23363,   inf] (17), [-0.23276,   inf] (17), [-0.19103,   inf] (17), [-0.19057,   inf] (17), [-0.18933,   inf] (17), [-0.18619,   inf] (17), [-0.18299,   inf] (17), [-0.18064,   inf] (17), [-0.17869,   inf] (17), [-0.17531,   inf] (17), [-0.17221,   inf] (17), [-0.16293,   inf] (17), 
length of domains: 67
Total time: 0.8950	 pickout: 0.0140	 decision: 0.1240	 get_bound: 0.7534	 add_domain: 0.0036
Current lb:-0.3825959265232086
438 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.312886476516724

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([67, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([67, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 114] [2, 17] [2, 20] [2, 17] [2, 114] [2, 114] [2, 17] [2, 17] [2, 17] [2, 17] 
regular batch size: 2*67, diving batch size 1*0
best_l after optimization: 4.805663108825684 with beta sum per layer: [0.0, 0.0, 244.47793579101562]
alpha/beta optimization time: 0.7485406398773193
This batch time : update_bounds func: 0.7806	 prepare: 0.0115	 bound: 0.7488	 transfer: 0.0127	 finalize: 0.0072
Accumulated time: update_bounds func: 7.1658	 prepare: 0.0672	 bound: 6.9688	 transfer: 0.0127	 finalize: 0.0373
batch bounding time:  0.7809538841247559
Current worst splitting domains [lb, ub] (depth):
[-0.37666,   inf] (19), [-0.34853,   inf] (19), [-0.29594,   inf] (19), [-0.27913,   inf] (19), [-0.27374,   inf] (19), [-0.25152,   inf] (19), [-0.24417,   inf] (19), [-0.22900,   inf] (19), [-0.21535,   inf] (19), [-0.20009,   inf] (19), [-0.19427,   inf] (19), [-0.17274,   inf] (19), [-0.17059,   inf] (19), [-0.15697,   inf] (19), [-0.15174,   inf] (19), [-0.14912,   inf] (19), [-0.14854,   inf] (19), [-0.14798,   inf] (19), [-0.14751,   inf] (19), [-0.14712,   inf] (19), 
length of domains: 67
Total time: 0.9317	 pickout: 0.0158	 decision: 0.1310	 get_bound: 0.7812	 add_domain: 0.0038
Current lb:-0.3766603469848633
572 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.246188163757324

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([67, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([67, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 35] [2, 114] [2, 114] [2, 114] [2, 35] [2, 114] [2, 35] [2, 114] [2, 114] [2, 114] 
regular batch size: 2*67, diving batch size 1*0
best_l after optimization: 0.9882144927978516 with beta sum per layer: [0.0, 0.0, 254.24307250976562]
alpha/beta optimization time: 0.7488498687744141
This batch time : update_bounds func: 0.7801	 prepare: 0.0116	 bound: 0.7491	 transfer: 0.0119	 finalize: 0.0071
Accumulated time: update_bounds func: 7.9459	 prepare: 0.0788	 bound: 7.7180	 transfer: 0.0119	 finalize: 0.0444
batch bounding time:  0.7804231643676758
Current worst splitting domains [lb, ub] (depth):
[-0.36778,   inf] (21), [-0.34294,   inf] (21), [-0.29046,   inf] (21), [-0.27329,   inf] (21), [-0.26456,   inf] (21), [-0.24114,   inf] (21), [-0.22184,   inf] (21), [-0.22091,   inf] (21), [-0.21307,   inf] (21), [-0.20912,   inf] (21), [-0.19253,   inf] (21), [-0.16650,   inf] (21), [-0.14988,   inf] (21), [-0.14244,   inf] (21), [-0.14118,   inf] (21), [-0.14020,   inf] (21), [-0.13896,   inf] (21), [-0.13120,   inf] (21), [-0.13038,   inf] (21), [-0.12760,   inf] (21), 
length of domains: 55
Total time: 0.9302	 pickout: 0.0158	 decision: 0.1306	 get_bound: 0.7806	 add_domain: 0.0032
Current lb:-0.3677835464477539
706 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.178051471710205

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([55, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([55, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 20] [2, 20] [2, 17] [2, 20] [2, 20] [2, 20] [2, 20] [2, 20] [2, 20] [2, 20] 
regular batch size: 2*55, diving batch size 1*0
best_l after optimization: 4.48621940612793 with beta sum per layer: [0.0, 0.0, 215.81092834472656]
alpha/beta optimization time: 0.6968154907226562
This batch time : update_bounds func: 0.7213	 prepare: 0.0097	 bound: 0.6971	 transfer: 0.0079	 finalize: 0.0063
Accumulated time: update_bounds func: 8.6672	 prepare: 0.0886	 bound: 8.4151	 transfer: 0.0079	 finalize: 0.0507
batch bounding time:  0.7215228080749512
Current worst splitting domains [lb, ub] (depth):
[-0.35608,   inf] (23), [-0.33067,   inf] (23), [-0.26212,   inf] (23), [-0.26147,   inf] (23), [-0.25297,   inf] (23), [-0.22243,   inf] (23), [-0.20624,   inf] (23), [-0.20390,   inf] (23), [-0.19700,   inf] (23), [-0.19509,   inf] (23), [-0.18751,   inf] (23), [-0.18305,   inf] (23), [-0.18083,   inf] (23), [-0.17749,   inf] (23), [-0.13673,   inf] (23), [-0.13547,   inf] (23), [-0.12921,   inf] (23), [-0.12532,   inf] (23), [-0.12301,   inf] (23), [-0.12015,   inf] (23), 
length of domains: 57
Total time: 0.8537	 pickout: 0.0129	 decision: 0.1156	 get_bound: 0.7217	 add_domain: 0.0035
Current lb:-0.35608139634132385
816 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.032930850982666

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([57, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([57, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 204] [2, 204] [2, 204] [2, 204] [2, 204] [2, 204] [2, 204] [2, 204] [2, 204] [2, 204] 
regular batch size: 2*57, diving batch size 1*0
best_l after optimization: -0.0939742922782898 with beta sum per layer: [0.0, 0.0, 212.99349975585938]
alpha/beta optimization time: 0.6990909576416016
This batch time : update_bounds func: 0.7241	 prepare: 0.0102	 bound: 0.6994	 transfer: 0.0079	 finalize: 0.0063
Accumulated time: update_bounds func: 9.3913	 prepare: 0.0987	 bound: 9.1145	 transfer: 0.0079	 finalize: 0.0570
batch bounding time:  0.724334716796875
Current worst splitting domains [lb, ub] (depth):
[-0.35041,   inf] (25), [-0.32456,   inf] (25), [-0.25629,   inf] (25), [-0.25578,   inf] (25), [-0.24668,   inf] (25), [-0.20107,   inf] (25), [-0.19020,   inf] (25), [-0.17216,   inf] (25), [-0.16633,   inf] (25), [-0.16534,   inf] (25), [-0.16300,   inf] (25), [-0.15767,   inf] (25), [-0.15514,   inf] (25), [-0.15127,   inf] (25), [-0.13008,   inf] (25), [-0.12015,   inf] (25), [-0.11783,   inf] (25), [-0.11649,   inf] (25), [-0.10775,   inf] (25), [-0.09710,   inf] (25), 
length of domains: 46
Total time: 0.9267	 pickout: 0.0130	 decision: 0.1861	 get_bound: 0.7245	 add_domain: 0.0031
Current lb:-0.3504081964492798
930 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.961037397384644

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([46, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([46, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 21] [2, 21] [2, 21] [2, 21] [2, 21] [2, 21] [2, 21] [2, 21] [2, 21] [2, 21] 
regular batch size: 2*46, diving batch size 1*0
best_l after optimization: 3.604923963546753 with beta sum per layer: [0.0, 0.0, 183.43771362304688]
alpha/beta optimization time: 0.6749081611633301
This batch time : update_bounds func: 0.6959	 prepare: 0.0085	 bound: 0.6752	 transfer: 0.0068	 finalize: 0.0052
Accumulated time: update_bounds func: 10.0872	 prepare: 0.1072	 bound: 9.7897	 transfer: 0.0068	 finalize: 0.0622
batch bounding time:  0.6961731910705566
Current worst splitting domains [lb, ub] (depth):
[-0.32532,   inf] (27), [-0.30135,   inf] (27), [-0.24625,   inf] (27), [-0.23283,   inf] (27), [-0.23150,   inf] (27), [-0.22585,   inf] (27), [-0.21397,   inf] (27), [-0.17732,   inf] (27), [-0.17019,   inf] (27), [-0.14975,   inf] (27), [-0.14874,   inf] (27), [-0.14813,   inf] (27), [-0.12955,   inf] (27), [-0.12861,   inf] (27), [-0.12678,   inf] (27), [-0.11555,   inf] (27), [-0.10839,   inf] (27), [-0.10471,   inf] (27), [-0.09686,   inf] (27), [-0.09482,   inf] (27), 
length of domains: 49
Total time: 0.7969	 pickout: 0.0117	 decision: 0.0854	 get_bound: 0.6963	 add_domain: 0.0035
Current lb:-0.3253187835216522
1022 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.759170770645142

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([49, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([49, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 157] [2, 157] [2, 157] [2, 157] [2, 157] [2, 2] [2, 157] [2, 157] [2, 2] [2, 157] 
regular batch size: 2*49, diving batch size 1*0
best_l after optimization: 2.727851390838623 with beta sum per layer: [0.0, 0.0, 189.00738525390625]
alpha/beta optimization time: 0.6884405612945557
This batch time : update_bounds func: 0.7104	 prepare: 0.0089	 bound: 0.6887	 transfer: 0.0071	 finalize: 0.0054
Accumulated time: update_bounds func: 10.7976	 prepare: 0.1161	 bound: 10.4784	 transfer: 0.0071	 finalize: 0.0676
batch bounding time:  0.7106049060821533
Current worst splitting domains [lb, ub] (depth):
[-0.28743,   inf] (29), [-0.26080,   inf] (29), [-0.23327,   inf] (29), [-0.21086,   inf] (29), [-0.19309,   inf] (29), [-0.19240,   inf] (29), [-0.19238,   inf] (29), [-0.18500,   inf] (29), [-0.14919,   inf] (29), [-0.14120,   inf] (29), [-0.14103,   inf] (29), [-0.13660,   inf] (29), [-0.13567,   inf] (29), [-0.13013,   inf] (29), [-0.12410,   inf] (29), [-0.11297,   inf] (29), [-0.09768,   inf] (29), [-0.08833,   inf] (29), [-0.08553,   inf] (29), [-0.08426,   inf] (29), 
length of domains: 44
Total time: 0.8353	 pickout: 0.0115	 decision: 0.1098	 get_bound: 0.7108	 add_domain: 0.0032
Current lb:-0.28742605447769165
1120 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.595693588256836

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([44, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([44, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 148] [2, 148] [2, 148] [2, 148] [2, 148] [2, 148] [2, 157] [2, 148] [2, 148] [2, 2] 
regular batch size: 2*44, diving batch size 1*0
best_l after optimization: 2.643888235092163 with beta sum per layer: [0.0, 0.0, 143.30291748046875]
alpha/beta optimization time: 0.669600248336792
This batch time : update_bounds func: 0.6897	 prepare: 0.0083	 bound: 0.6699	 transfer: 0.0064	 finalize: 0.0049
Accumulated time: update_bounds func: 11.4873	 prepare: 0.1244	 bound: 11.1483	 transfer: 0.0064	 finalize: 0.0725
batch bounding time:  0.6899938583374023
Current worst splitting domains [lb, ub] (depth):
[-0.28246,   inf] (31), [-0.25557,   inf] (31), [-0.21538,   inf] (31), [-0.19283,   inf] (31), [-0.18759,   inf] (31), [-0.18658,   inf] (31), [-0.15915,   inf] (31), [-0.15316,   inf] (31), [-0.12209,   inf] (31), [-0.12189,   inf] (31), [-0.10817,   inf] (31), [-0.10571,   inf] (31), [-0.10283,   inf] (31), [-0.09394,   inf] (31), [-0.09028,   inf] (31), [-0.08871,   inf] (31), [-0.08467,   inf] (31), [-0.07820,   inf] (31), [-0.07624,   inf] (31), [-0.07097,   inf] (31), 
length of domains: 45
Total time: 0.7880	 pickout: 0.0103	 decision: 0.0842	 get_bound: 0.6901	 add_domain: 0.0033
Current lb:-0.2824598252773285
1208 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.384768724441528

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([45, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([45, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 2] [2, 217] [2, 2] [2, 2] [2, 217] [2, 2] [2, 2] [2, 148] [2, 217] [2, 2] 
regular batch size: 2*45, diving batch size 1*0
best_l after optimization: 2.1704671382904053 with beta sum per layer: [0.0, 0.0, 138.2081298828125]
alpha/beta optimization time: 0.6635773181915283
This batch time : update_bounds func: 0.6930	 prepare: 0.0083	 bound: 0.6639	 transfer: 0.0150	 finalize: 0.0056
Accumulated time: update_bounds func: 12.1803	 prepare: 0.1327	 bound: 11.8122	 transfer: 0.0150	 finalize: 0.0782
batch bounding time:  0.6932971477508545
Current worst splitting domains [lb, ub] (depth):
[-0.24420,   inf] (33), [-0.22950,   inf] (33), [-0.20267,   inf] (33), [-0.17148,   inf] (33), [-0.16483,   inf] (33), [-0.16087,   inf] (33), [-0.14754,   inf] (33), [-0.14666,   inf] (33), [-0.14627,   inf] (33), [-0.12013,   inf] (33), [-0.10996,   inf] (33), [-0.10540,   inf] (33), [-0.09998,   inf] (33), [-0.09975,   inf] (33), [-0.09796,   inf] (33), [-0.09678,   inf] (33), [-0.08723,   inf] (33), [-0.07632,   inf] (33), [-0.07431,   inf] (33), [-0.07124,   inf] (33), 
length of domains: 40
Total time: 0.7930	 pickout: 0.0105	 decision: 0.0858	 get_bound: 0.6935	 add_domain: 0.0033
Current lb:-0.24420152604579926
1298 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.179133653640747

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([40, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([40, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 235] [2, 2] [2, 235] [2, 235] [2, 235] [2, 2] [2, 235] [2, 235] [2, 235] [2, 235] 
regular batch size: 2*40, diving batch size 1*0
best_l after optimization: 2.094015598297119 with beta sum per layer: [0.0, 0.0, 130.7559051513672]
alpha/beta optimization time: 0.6453678607940674
This batch time : update_bounds func: 0.6695	 prepare: 0.0074	 bound: 0.6457	 transfer: 0.0114	 finalize: 0.0048
Accumulated time: update_bounds func: 12.8498	 prepare: 0.1401	 bound: 12.4578	 transfer: 0.0114	 finalize: 0.0830
batch bounding time:  0.6697702407836914
Current worst splitting domains [lb, ub] (depth):
[-0.22142,   inf] (35), [-0.18930,   inf] (35), [-0.17715,   inf] (35), [-0.15771,   inf] (35), [-0.14839,   inf] (35), [-0.14709,   inf] (35), [-0.12478,   inf] (35), [-0.12336,   inf] (35), [-0.12303,   inf] (35), [-0.12193,   inf] (35), [-0.12160,   inf] (35), [-0.10701,   inf] (35), [-0.09024,   inf] (35), [-0.08836,   inf] (35), [-0.08291,   inf] (35), [-0.07589,   inf] (35), [-0.07579,   inf] (35), [-0.07188,   inf] (35), [-0.06475,   inf] (35), [-0.05932,   inf] (35), 
length of domains: 42
Total time: 0.7640	 pickout: 0.0107	 decision: 0.0800	 get_bound: 0.6699	 add_domain: 0.0034
Current lb:-0.22141718864440918
1378 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.944131851196289

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([42, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([42, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 217] [2, 235] [2, 66] [2, 235] [2, 66] [2, 217] [2, 66] [2, 217] [2, 2] [2, 217] 
regular batch size: 2*42, diving batch size 1*0
best_l after optimization: 1.4423421621322632 with beta sum per layer: [0.0, 0.0, 118.06879425048828]
alpha/beta optimization time: 0.6496102809906006
This batch time : update_bounds func: 0.6708	 prepare: 0.0078	 bound: 0.6499	 transfer: 0.0081	 finalize: 0.0047
Accumulated time: update_bounds func: 13.5206	 prepare: 0.1479	 bound: 13.1077	 transfer: 0.0081	 finalize: 0.0877
batch bounding time:  0.6710035800933838
Current worst splitting domains [lb, ub] (depth):
[-0.19253,   inf] (37), [-0.16626,   inf] (37), [-0.14038,   inf] (37), [-0.13083,   inf] (37), [-0.13049,   inf] (37), [-0.10792,   inf] (37), [-0.10778,   inf] (37), [-0.09869,   inf] (37), [-0.09506,   inf] (37), [-0.09497,   inf] (37), [-0.09488,   inf] (37), [-0.09454,   inf] (37), [-0.07920,   inf] (37), [-0.06714,   inf] (37), [-0.06322,   inf] (37), [-0.06300,   inf] (37), [-0.06298,   inf] (37), [-0.05681,   inf] (37), [-0.05366,   inf] (37), [-0.05031,   inf] (37), 
length of domains: 38
Total time: 0.7670	 pickout: 0.0101	 decision: 0.0827	 get_bound: 0.6711	 add_domain: 0.0031
Current lb:-0.19252777099609375
1462 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.712235450744629

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([38, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([38, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 73] [2, 66] [2, 73] [2, 66] [2, 73] [2, 73] [2, 73] [2, 66] [2, 73] [2, 66] 
regular batch size: 2*38, diving batch size 1*0
best_l after optimization: -2.7994251251220703 with beta sum per layer: [0.0, 0.0, 85.08257293701172]
alpha/beta optimization time: 0.6373920440673828
This batch time : update_bounds func: 0.6551	 prepare: 0.0072	 bound: 0.6377	 transfer: 0.0058	 finalize: 0.0042
Accumulated time: update_bounds func: 14.1757	 prepare: 0.1551	 bound: 13.7454	 transfer: 0.0058	 finalize: 0.0919
batch bounding time:  0.6552901268005371
Current worst splitting domains [lb, ub] (depth):
[-0.18751,   inf] (39), [-0.12510,   inf] (39), [-0.11931,   inf] (39), [-0.11767,   inf] (39), [-0.10399,   inf] (39), [-0.10225,   inf] (39), [-0.10026,   inf] (39), [-0.08911,   inf] (39), [-0.08046,   inf] (39), [-0.07435,   inf] (39), [-0.06834,   inf] (39), [-0.06661,   inf] (39), [-0.05401,   inf] (39), [-0.04790,   inf] (39), [-0.04730,   inf] (39), [-0.04579,   inf] (39), [-0.04567,   inf] (39), [-0.04419,   inf] (39), [-0.04251,   inf] (39), [-0.04045,   inf] (39), 
length of domains: 34
Total time: 0.7469	 pickout: 0.0091	 decision: 0.0793	 get_bound: 0.6554	 add_domain: 0.0030
Current lb:-0.18750905990600586
1538 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.460131406784058

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([34, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([34, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 66] [2, 217] [2, 66] [2, 73] [2, 73] [2, 217] [2, 217] [2, 66] [2, 73] [2, 217] 
regular batch size: 2*34, diving batch size 1*0
best_l after optimization: -1.5171083211898804 with beta sum per layer: [0.0, 0.0, 74.0091323852539]
alpha/beta optimization time: 0.6243536472320557
This batch time : update_bounds func: 0.6405	 prepare: 0.0065	 bound: 0.6247	 transfer: 0.0052	 finalize: 0.0039
Accumulated time: update_bounds func: 14.8162	 prepare: 0.1616	 bound: 14.3702	 transfer: 0.0052	 finalize: 0.0958
batch bounding time:  0.6407506465911865
Current worst splitting domains [lb, ub] (depth):
[-0.13871,   inf] (41), [-0.12131,   inf] (41), [-0.11218,   inf] (41), [-0.09796,   inf] (41), [-0.09652,   inf] (41), [-0.07485,   inf] (41), [-0.07288,   inf] (41), [-0.07225,   inf] (41), [-0.06196,   inf] (41), [-0.06041,   inf] (41), [-0.04817,   inf] (41), [-0.04088,   inf] (41), [-0.04082,   inf] (41), [-0.03850,   inf] (41), [-0.03789,   inf] (41), [-0.03436,   inf] (41), [-0.02886,   inf] (41), [-0.02383,   inf] (41), [-0.01462,   inf] (41), [-0.01451,   inf] (41), 
length of domains: 26
Total time: 0.7275	 pickout: 0.0084	 decision: 0.0759	 get_bound: 0.6409	 add_domain: 0.0024
Current lb:-0.1387123167514801
1606 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.18853759765625

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([26, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([26, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 166] [2, 166] [2, 166] [2, 166] [2, 107] [2, 166] [2, 166] [2, 166] [2, 166] [2, 166] 
regular batch size: 2*26, diving batch size 1*0
best_l after optimization: -0.01958276331424713 with beta sum per layer: [0.0, 0.0, 50.55382537841797]
alpha/beta optimization time: 0.599189043045044
This batch time : update_bounds func: 0.6126	 prepare: 0.0053	 bound: 0.5995	 transfer: 0.0044	 finalize: 0.0032
Accumulated time: update_bounds func: 15.4288	 prepare: 0.1670	 bound: 14.9696	 transfer: 0.0044	 finalize: 0.0990
batch bounding time:  0.6127951145172119
Current worst splitting domains [lb, ub] (depth):
[-0.10806,   inf] (43), [-0.08897,   inf] (43), [-0.08793,   inf] (43), [-0.08182,   inf] (43), [-0.06693,   inf] (43), [-0.06486,   inf] (43), [-0.04737,   inf] (43), [-0.04594,   inf] (43), [-0.04249,   inf] (43), [-0.04209,   inf] (43), [-0.03936,   inf] (43), [-0.03026,   inf] (43), [-0.02699,   inf] (43), [-0.02170,   inf] (43), [-0.01833,   inf] (43), [-0.00948,   inf] (43), [-0.00842,   inf] (43), [-0.00723,   inf] (43), [-0.00696,   inf] (43), [-0.00250,   inf] (43), 
length of domains: 20
Total time: 0.6899	 pickout: 0.0065	 decision: 0.0685	 get_bound: 0.6129	 add_domain: 0.0020
Current lb:-0.10805940628051758
1658 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.881603717803955

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([20, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([20, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 101] [2, 101] [2, 107] [2, 107] [2, 107] [2, 101] [2, 101] [2, 107] [2, 107] [2, 107] 
regular batch size: 2*20, diving batch size 1*0
best_l after optimization: 0.01673397421836853 with beta sum per layer: [0.0, 0.0, 27.08646583557129]
alpha/beta optimization time: 0.5861995220184326
This batch time : update_bounds func: 0.5969	 prepare: 0.0044	 bound: 0.5865	 transfer: 0.0036	 finalize: 0.0024
Accumulated time: update_bounds func: 16.0257	 prepare: 0.1713	 bound: 15.5561	 transfer: 0.0036	 finalize: 0.1014
batch bounding time:  0.5970983505249023
Current worst splitting domains [lb, ub] (depth):
[-0.10509,   inf] (45), [-0.08565,   inf] (45), [-0.07904,   inf] (45), [-0.07396,   inf] (45), [-0.05873,   inf] (45), [-0.04873,   inf] (45), [-0.03831,   inf] (45), [-0.03472,   inf] (45), [-0.03409,   inf] (45), [-0.03207,   inf] (45), [-0.02225,   inf] (45), [-0.01924,   inf] (45), [-0.01294,   inf] (45), [-0.01056,   inf] (45), [-0.00654,   inf] (45), [-0.00430,   inf] (45), [-0.00088,   inf] (45), [-0.00036,   inf] (45), 
length of domains: 18
Total time: 0.6682	 pickout: 0.0052	 decision: 0.0640	 get_bound: 0.5972	 add_domain: 0.0018
Current lb:-0.10509490966796875
1698 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.550405502319336

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([18, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([18, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 107] [2, 166] [2, 101] [2, 101] [2, 101] [2, 107] [2, 101] [2, 101] [2, 101] [2, 107] 
regular batch size: 2*18, diving batch size 1*0
best_l after optimization: -0.2522616386413574 with beta sum per layer: [0.0, 0.0, 26.353940963745117]
alpha/beta optimization time: 0.5822575092315674
This batch time : update_bounds func: 0.5922	 prepare: 0.0041	 bound: 0.5825	 transfer: 0.0034	 finalize: 0.0022
Accumulated time: update_bounds func: 16.6179	 prepare: 0.1754	 bound: 16.1386	 transfer: 0.0034	 finalize: 0.1035
batch bounding time:  0.592430591583252
Current worst splitting domains [lb, ub] (depth):
[-0.09705,   inf] (47), [-0.07619,   inf] (47), [-0.07087,   inf] (47), [-0.05603,   inf] (47), [-0.05581,   inf] (47), [-0.03492,   inf] (47), [-0.03186,   inf] (47), [-0.03132,   inf] (47), [-0.03080,   inf] (47), [-0.01896,   inf] (47), [-0.01695,   inf] (47), [-0.00726,   inf] (47), [-0.00640,   inf] (47), [-0.00610,   inf] (47), 
length of domains: 14
Total time: 0.6609	 pickout: 0.0047	 decision: 0.0623	 get_bound: 0.5925	 add_domain: 0.0015
Current lb:-0.09704923629760742
1734 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.21189522743225

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([14, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([14, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 124] [2, 124] [2, 124] [2, 124] [2, 124] [2, 124] [2, 124] [2, 124] [2, 124] [2, 124] 
regular batch size: 2*14, diving batch size 1*0
best_l after optimization: 0.16428720951080322 with beta sum per layer: [0.0, 0.0, 20.614299774169922]
alpha/beta optimization time: 0.578873872756958
This batch time : update_bounds func: 0.5872	 prepare: 0.0035	 bound: 0.5791	 transfer: 0.0028	 finalize: 0.0016
Accumulated time: update_bounds func: 17.2052	 prepare: 0.1790	 bound: 16.7178	 transfer: 0.0028	 finalize: 0.1051
batch bounding time:  0.5873820781707764
Current worst splitting domains [lb, ub] (depth):
[-0.09060,   inf] (49), [-0.06941,   inf] (49), [-0.06435,   inf] (49), [-0.04928,   inf] (49), [-0.04918,   inf] (49), [-0.02826,   inf] (49), [-0.02500,   inf] (49), [-0.02475,   inf] (49), [-0.01978,   inf] (49), [-0.01209,   inf] (49), [-0.00696,   inf] (49), [-0.00099,   inf] (49), [-0.00053,   inf] (49), 
length of domains: 13
Total time: 0.6524	 pickout: 0.0041	 decision: 0.0594	 get_bound: 0.5874	 add_domain: 0.0014
Current lb:-0.09060227125883102
1762 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.86472225189209

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([13, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([13, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 118] [2, 118] [2, 118] [2, 118] [2, 118] [2, 118] [2, 118] [2, 118] [2, 37] [2, 238] 
regular batch size: 2*13, diving batch size 1*0
best_l after optimization: 0.05647999048233032 with beta sum per layer: [0.0, 0.0, 18.511428833007812]
alpha/beta optimization time: 0.5780158042907715
This batch time : update_bounds func: 0.5859	 prepare: 0.0032	 bound: 0.5783	 transfer: 0.0027	 finalize: 0.0015
Accumulated time: update_bounds func: 17.7910	 prepare: 0.1822	 bound: 17.2961	 transfer: 0.0027	 finalize: 0.1067
batch bounding time:  0.5860421657562256
Current worst splitting domains [lb, ub] (depth):
[-0.07365,   inf] (51), [-0.05058,   inf] (51), [-0.04696,   inf] (51), [-0.03104,   inf] (51), [-0.02974,   inf] (51), [-0.02665,   inf] (51), [-0.01184,   inf] (51), [-0.01094,   inf] (51), [-0.00980,   inf] (51), [-0.00841,   inf] (51), [-0.00389,   inf] (51), [-0.00358,   inf] (51), [-0.00137,   inf] (51), 
length of domains: 13
Total time: 0.6497	 pickout: 0.0036	 decision: 0.0586	 get_bound: 0.5861	 add_domain: 0.0014
Current lb:-0.07364672422409058
1788 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 19.51485276222229

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([13, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([13, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 37] [2, 37] [2, 37] [2, 37] [2, 37] [2, 37] [2, 118] [2, 37] [2, 37] [2, 37] 
regular batch size: 2*13, diving batch size 1*0
best_l after optimization: -0.1708294153213501 with beta sum per layer: [0.0, 0.0, 15.99388599395752]
alpha/beta optimization time: 0.5754303932189941
This batch time : update_bounds func: 0.5831	 prepare: 0.0032	 bound: 0.5757	 transfer: 0.0025	 finalize: 0.0015
Accumulated time: update_bounds func: 18.3741	 prepare: 0.1854	 bound: 17.8718	 transfer: 0.0025	 finalize: 0.1082
batch bounding time:  0.5832643508911133
Current worst splitting domains [lb, ub] (depth):
[-0.06746,   inf] (53), [-0.04391,   inf] (53), [-0.04099,   inf] (53), [-0.02569,   inf] (53), [-0.02311,   inf] (53), [-0.00404,   inf] (53), [-0.00286,   inf] (53), [-0.00155,   inf] (53), 
length of domains: 8
Total time: 0.6464	 pickout: 0.0036	 decision: 0.0585	 get_bound: 0.5833	 add_domain: 0.0009
Current lb:-0.06746268272399902
1814 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 20.161683797836304

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([8, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 238] [2, 238] [2, 238] [2, 238] [2, 238] [2, 238] [2, 238] [2, 238] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.021701231598854065 with beta sum per layer: [0.0, 0.0, 7.646383762359619]
alpha/beta optimization time: 0.5720624923706055
This batch time : update_bounds func: 0.5780	 prepare: 0.0025	 bound: 0.5723	 transfer: 0.0018	 finalize: 0.0013
Accumulated time: update_bounds func: 18.9521	 prepare: 0.1879	 bound: 18.4441	 transfer: 0.0018	 finalize: 0.1095
batch bounding time:  0.5781168937683105
Current worst splitting domains [lb, ub] (depth):
[-0.05833,   inf] (55), [-0.03522,   inf] (55), [-0.03183,   inf] (55), [-0.01673,   inf] (55), [-0.01425,   inf] (55), 
length of domains: 5
Total time: 0.6366	 pickout: 0.0025	 decision: 0.0553	 get_bound: 0.5782	 add_domain: 0.0006
Current lb:-0.058330945670604706
1830 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 20.798619508743286

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([5, 32, 16, 16]) pre split depth:  2
batch:  torch.Size([5, 32, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [2, 178] [2, 178] [2, 178] [2, 178] [2, 178] 
split level 1: [2, 179] [2, 179] [2, 179] [2, 179] [2, 179] 
regular batch size: 2*10, diving batch size 1*0
best_l after optimization: -0.2244359403848648 with beta sum per layer: [0.0, 0.0, 6.758199691772461]
alpha/beta optimization time: 0.5722248554229736
This batch time : update_bounds func: 0.5787	 prepare: 0.0028	 bound: 0.5726	 transfer: 0.0020	 finalize: 0.0012
Accumulated time: update_bounds func: 19.5308	 prepare: 0.1907	 bound: 19.0167	 transfer: 0.0020	 finalize: 0.1107
batch bounding time:  0.5788962841033936
Current worst splitting domains [lb, ub] (depth):
[-0.04487,   inf] (58), [-0.02158,   inf] (58), [-0.01887,   inf] (58), [-0.00267,   inf] (58), [-0.00101,   inf] (58), 
length of domains: 5
Total time: 0.6369	 pickout: 0.0019	 decision: 0.0535	 get_bound: 0.5808	 add_domain: 0.0007
Current lb:-0.0448719747364521
1850 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 21.435775756835938

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([5, 32, 16, 16]) pre split depth:  2
batch:  torch.Size([5, 32, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [2, 91] [2, 91] [2, 91] [2, 91] [2, 91] 
split level 1: [2, 162] [2, 162] [2, 162] [2, 162] [2, 162] 
regular batch size: 2*10, diving batch size 1*0
best_l after optimization: -0.522286593914032 with beta sum per layer: [0.0, 0.0, 6.469009876251221]
alpha/beta optimization time: 0.5764374732971191
This batch time : update_bounds func: 0.5849	 prepare: 0.0028	 bound: 0.5767	 transfer: 0.0040	 finalize: 0.0013
Accumulated time: update_bounds func: 20.1156	 prepare: 0.1934	 bound: 19.5934	 transfer: 0.0040	 finalize: 0.1120
batch bounding time:  0.5851342678070068
Current worst splitting domains [lb, ub] (depth):
[-0.01318,   inf] (61), [-0.00995,   inf] (61), 
length of domains: 2
Total time: 0.6429	 pickout: 0.0017	 decision: 0.0536	 get_bound: 0.5870	 add_domain: 0.0005
Current lb:-0.013176202774047852
1870 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 22.07903218269348

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2, 32, 16, 16]) pre split depth:  3
batch:  torch.Size([2, 32, 16, 16]) post split depth:  3
splitting decisions: 
split level 0: [2, 188] [2, 188] 
split level 1: [2, 195] [2, 195] 
split level 2: [2, 171] [2, 171] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -0.5663552284240723 with beta sum per layer: [0.0, 0.0, 0.38674867153167725]
alpha/beta optimization time: 0.007976770401000977
This batch time : update_bounds func: 0.0148	 prepare: 0.0025	 bound: 0.0082	 transfer: 0.0030	 finalize: 0.0010
Accumulated time: update_bounds func: 20.1305	 prepare: 0.1959	 bound: 19.6017	 transfer: 0.0030	 finalize: 0.1130
batch bounding time:  0.014888286590576172
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0698	 pickout: 0.0012	 decision: 0.0514	 get_bound: 0.0171	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 22.149133920669556

Image 0 against label 7 verification end, Time cost: 22.206602811813354
##### [0] True label: 9, Tested against: 8, onnx_path: nets/cifar10_8_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_76_eps_0.03137_n1.vnnlib ######
init opt crown verified for label 8 with bound 0.4232209324836731
Image 0 against label 8 verification end, Time cost: 0.0003170967102050781
Result: safe-bab in 42.7195 seconds


[[   0.            0.39418027    0.            0.0003047     0.        ]
 [   0.            0.0000001    44.            4.22531557    1.        ]
 [   0.            0.0000001    32.            1.74310184    2.        ]
 [   0.            0.16530347    0.            0.00030017    3.        ]
 [   0.            0.69400698    0.            0.00030351    4.        ]
 [   0.            0.3580732     0.            0.00030398    5.        ]
 [   0.            0.39635542    0.            0.00031281    6.        ]
 [   0.            0.0000001  1886.           22.20660281    7.        ]
 [   0.            0.42322093    0.            0.0003171     8.        ]]/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:25: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1627336316785/work/torch/csrc/utils/tensor_numpy.cpp:143.)
  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))

############# Summary #############
Final verified acc: 100.0% [total 1 examples]
Total verification count: 1 , total verified safe: 1 , verified unsafe: 0 , timeout: 0
mean time [total:1]: 28.176862478256226
mean time [cnt:1]: 28.176862478256226
max time 42.71947169303894
safe-bab (total 1): [0]
