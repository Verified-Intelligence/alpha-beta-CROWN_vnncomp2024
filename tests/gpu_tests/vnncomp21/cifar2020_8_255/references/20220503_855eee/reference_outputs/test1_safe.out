Building native CUDA modules...
/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
  csv_name: cifar2020_instances.csv
  onnx_path: null
  vnnlib_path: null
  results_file: null
  root_path: ../../../../../vnncomp2021/benchmarks/cifar2020
model:
  path: null
  name: mnist_9_200
data:
  start: 110
  end: 111
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR
  data_filter_path: null
specification:
  type: lp
  norm: .inf
  epsilon: null
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 200
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.01
    lr_decay: 0.98
    optimizer: adam
    iteration: 50
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 360
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 10
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:09:52 2022 on ubuntu
saving results to vnn-comp_[cifar2020_instances]_start=110_end=111_iter=50_b=200_timeout=360_branching=kfsb-max-10_lra-init=0.1_lra=0.01_lrb=0.01_PGD=before.npz
customized start/end sample from 110 to 111

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
##### PGD attack: True label: 8, Tested against: [0, 1, 2, 3, 4, 5, 6, 7, 9] ######
pgd prediction: tensor([ 0.7470,  0.1024,  0.1625, -0.7112,  0.2084, -0.8857, -0.1704, -0.5451,
         1.1341,  0.1887], device='cuda:0', grad_fn=<SqueezeBackward1>)
attack margin tensor([0.3871, 1.0317, 0.9716, 1.8453, 0.9257, 2.0198, 1.3045, 1.6792,    inf,
        0.9454], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[ 0.7880,  0.0817,  0.1218, -0.7367,  0.1581, -0.9347, -0.2041, -0.7055,
          1.5174,  0.2377]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-0.3684, -0.8451, -0.4958,  0.1201, -0.4134,  0.0862, -0.3073, -0.1249,
         -0.6806]], device='cuda:0') None
best_l after optimization: 0.7773752808570862 with beta sum per layer: []
alpha/beta optimization time: 8.057021379470825
initial alpha-CROWN bounds: tensor([[-0.2191, -0.5870, -0.2474,  0.3907, -0.2054,  0.4169, -0.0293,  0.1348,
         -0.4316]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.5870, device='cuda:0', grad_fn=<MinBackward1>)
##### [0] True label: 8, Tested against: 0, onnx_path: nets/cifar10_8_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_51_eps_0.03137_n1.vnnlib ######
Model prediction is: tensor([[ 0.7880,  0.0817,  0.1218, -0.7367,  0.1581, -0.9347, -0.2041, -0.7055,
          1.5174,  0.2377]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /9 torch.Size([1, 32, 16, 16])
1 /11 torch.Size([1, 128, 8, 8])
2 /14 torch.Size([1, 250])
best_l after optimization: 0.219060480594635 with beta sum per layer: []
alpha/beta optimization time: 1.8544316291809082
alpha-CROWN with fixed intermediate bounds: tensor([[-0.2191]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.219060480594635
layer 0 size torch.Size([8192]) unstable 260
layer 1 size torch.Size([8192]) unstable 1123
layer 2 size torch.Size([250]) unstable 111
-----------------
# of unstable neurons: 1494
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 249] 
split level 1: [2, 208] 
split level 2: [2, 106] 
split level 3: [2, 135] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.42844653129577637 with beta sum per layer: [0.0, 0.0, 0.9423983097076416]
alpha/beta optimization time: 0.5538933277130127
This batch time : update_bounds func: 0.5606	 prepare: 0.0026	 bound: 0.5544	 transfer: 0.0024	 finalize: 0.0011
Accumulated time: update_bounds func: 0.5606	 prepare: 0.0026	 bound: 0.5544	 transfer: 0.0024	 finalize: 0.0011
batch bounding time:  0.5608062744140625
Current worst splitting domains [lb, ub] (depth):
[-0.10946,   inf] (5), [-0.06419,   inf] (5), [-0.00666,   inf] (5), [-0.00336,   inf] (5), [-0.00009,   inf] (5), 
length of domains: 5
Total time: 0.6160	 pickout: 0.0010	 decision: 0.0520	 get_bound: 0.5627	 add_domain: 0.0003
Current lb:-0.10946430265903473
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.4001383781433105

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([5, 32, 16, 16]) pre split depth:  2
batch:  torch.Size([5, 32, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [2, 22] [2, 22] [2, 50] [2, 50] [2, 22] 
split level 1: [2, 53] [2, 50] [2, 22] [2, 22] [2, 50] 
regular batch size: 2*10, diving batch size 1*0
best_l after optimization: -1.062973141670227 with beta sum per layer: [0.0, 0.0, 2.19638729095459]
alpha/beta optimization time: 0.5556788444519043
This batch time : update_bounds func: 0.5636	 prepare: 0.0027	 bound: 0.5560	 transfer: 0.0035	 finalize: 0.0014
Accumulated time: update_bounds func: 1.1243	 prepare: 0.0053	 bound: 1.1104	 transfer: 0.0035	 finalize: 0.0025
batch bounding time:  0.563819169998169
Current worst splitting domains [lb, ub] (depth):
[-0.03743,   inf] (8), [-0.00960,   inf] (8), [-0.00888,   inf] (8), [-0.00483,   inf] (8), 
length of domains: 4
Total time: 0.6208	 pickout: 0.0018	 decision: 0.0534	 get_bound: 0.5653	 add_domain: 0.0003
Current lb:-0.037425510585308075
36 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.021240949630737

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 32, 16, 16]) pre split depth:  2
batch:  torch.Size([4, 32, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [2, 187] [2, 187] [2, 187] [2, 187] 
split level 1: [2, 50] [2, 50] [2, 50] [2, 53] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -1.0454870462417603 with beta sum per layer: [0.0, 0.0, 1.3018088340759277]
alpha/beta optimization time: 0.5849819183349609
This batch time : update_bounds func: 0.5908	 prepare: 0.0024	 bound: 0.5854	 transfer: 0.0018	 finalize: 0.0011
Accumulated time: update_bounds func: 1.7150	 prepare: 0.0077	 bound: 1.6958	 transfer: 0.0018	 finalize: 0.0035
batch bounding time:  0.5909276008605957
Current worst splitting domains [lb, ub] (depth):
[-0.01230,   inf] (11), 
length of domains: 1
Total time: 0.6461	 pickout: 0.0015	 decision: 0.0523	 get_bound: 0.5922	 add_domain: 0.0002
Current lb:-0.012299349531531334
52 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.667637825012207

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 167] 
split level 1: [2, 188] 
split level 2: [2, 127] 
split level 3: [2, 102] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -1.3435486555099487 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.007870912551879883
This batch time : update_bounds func: 0.0132	 prepare: 0.0024	 bound: 0.0081	 transfer: 0.0016	 finalize: 0.0010
Accumulated time: update_bounds func: 1.7283	 prepare: 0.0101	 bound: 1.7039	 transfer: 0.0016	 finalize: 0.0046
batch bounding time:  0.013319015502929688
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0662	 pickout: 0.0009	 decision: 0.0500	 get_bound: 0.0153	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 4.7341225147247314

Image 0 against label 0 verification end, Time cost: 4.8001391887664795
##### [0] True label: 8, Tested against: 1, onnx_path: nets/cifar10_8_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_51_eps_0.03137_n1.vnnlib ######
Model prediction is: tensor([[ 0.7880,  0.0817,  0.1218, -0.7367,  0.1581, -0.9347, -0.2041, -0.7055,
          1.5174,  0.2377]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /9 torch.Size([1, 32, 16, 16])
1 /11 torch.Size([1, 128, 8, 8])
2 /14 torch.Size([1, 250])
best_l after optimization: 0.5869009494781494 with beta sum per layer: []
alpha/beta optimization time: 0.8998959064483643
alpha-CROWN with fixed intermediate bounds: tensor([[-0.5869]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.5869009494781494
layer 0 size torch.Size([8192]) unstable 260
layer 1 size torch.Size([8192]) unstable 1123
layer 2 size torch.Size([250]) unstable 111
-----------------
# of unstable neurons: 1494
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 211] 
split level 1: [2, 215] 
split level 2: [2, 182] 
split level 3: [2, 54] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 3.37434720993042 with beta sum per layer: [0.0, 0.0, 1.497600793838501]
alpha/beta optimization time: 0.5538859367370605
This batch time : update_bounds func: 0.5597	 prepare: 0.0025	 bound: 0.5544	 transfer: 0.0016	 finalize: 0.0010
Accumulated time: update_bounds func: 2.2879	 prepare: 0.0126	 bound: 2.2583	 transfer: 0.0016	 finalize: 0.0056
batch bounding time:  0.5598175525665283
Current worst splitting domains [lb, ub] (depth):
[-0.30302,   inf] (5), [-0.30165,   inf] (5), [-0.26870,   inf] (5), [-0.24901,   inf] (5), [-0.24210,   inf] (5), [-0.24034,   inf] (5), [-0.23802,   inf] (5), [-0.22023,   inf] (5), [-0.20583,   inf] (5), [-0.19016,   inf] (5), [-0.18066,   inf] (5), [-0.17884,   inf] (5), [-0.16457,   inf] (5), [-0.16206,   inf] (5), [-0.12124,   inf] (5), [-0.10793,   inf] (5), 
length of domains: 16
Total time: 0.6142	 pickout: 0.0008	 decision: 0.0511	 get_bound: 0.5617	 add_domain: 0.0007
Current lb:-0.3030241131782532
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.5384409427642822

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([16, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([16, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 38] [2, 38] [2, 135] [2, 38] [2, 38] [2, 38] [2, 135] [2, 135] [2, 135] [2, 38] 
regular batch size: 2*16, diving batch size 1*0
best_l after optimization: 3.9365968704223633 with beta sum per layer: [0.0, 0.0, 7.95412540435791]
alpha/beta optimization time: 0.5719325542449951
This batch time : update_bounds func: 0.5840	 prepare: 0.0037	 bound: 0.5722	 transfer: 0.0059	 finalize: 0.0021
Accumulated time: update_bounds func: 2.8719	 prepare: 0.0163	 bound: 2.8305	 transfer: 0.0059	 finalize: 0.0077
batch bounding time:  0.5842287540435791
Current worst splitting domains [lb, ub] (depth):
[-0.28438,   inf] (7), [-0.28189,   inf] (7), [-0.22774,   inf] (7), [-0.22466,   inf] (7), [-0.22269,   inf] (7), [-0.21924,   inf] (7), [-0.20448,   inf] (7), [-0.18184,   inf] (7), [-0.16501,   inf] (7), [-0.16433,   inf] (7), [-0.16287,   inf] (7), [-0.16100,   inf] (7), [-0.14724,   inf] (7), [-0.14635,   inf] (7), [-0.12736,   inf] (7), [-0.12489,   inf] (7), [-0.12199,   inf] (7), [-0.11306,   inf] (7), [-0.10570,   inf] (7), [-0.10177,   inf] (7), 
length of domains: 30
Total time: 0.6507	 pickout: 0.0041	 decision: 0.0609	 get_bound: 0.5843	 add_domain: 0.0014
Current lb:-0.2843772768974304
48 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.189572811126709

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([30, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([30, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 9] [2, 160] [2, 9] [2, 160] [2, 9] [2, 160] [2, 9] [2, 38] [2, 160] [2, 9] 
regular batch size: 2*30, diving batch size 1*0
best_l after optimization: 2.938610792160034 with beta sum per layer: [0.0, 0.0, 22.075176239013672]
alpha/beta optimization time: 0.6248137950897217
This batch time : update_bounds func: 0.6444	 prepare: 0.0059	 bound: 0.6251	 transfer: 0.0096	 finalize: 0.0037
Accumulated time: update_bounds func: 3.5164	 prepare: 0.0221	 bound: 3.4557	 transfer: 0.0096	 finalize: 0.0113
batch bounding time:  0.6446785926818848
Current worst splitting domains [lb, ub] (depth):
[-0.22587,   inf] (9), [-0.21134,   inf] (9), [-0.18957,   inf] (9), [-0.18476,   inf] (9), [-0.16260,   inf] (9), [-0.16192,   inf] (9), [-0.16183,   inf] (9), [-0.15570,   inf] (9), [-0.14646,   inf] (9), [-0.14345,   inf] (9), [-0.12895,   inf] (9), [-0.12453,   inf] (9), [-0.12220,   inf] (9), [-0.11491,   inf] (9), [-0.10595,   inf] (9), [-0.10385,   inf] (9), [-0.09564,   inf] (9), [-0.09396,   inf] (9), [-0.09324,   inf] (9), [-0.08414,   inf] (9), 
length of domains: 39
Total time: 0.7288	 pickout: 0.0079	 decision: 0.0744	 get_bound: 0.6448	 add_domain: 0.0017
Current lb:-0.2258726805448532
108 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.9191129207611084

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([39, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([39, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 135] [2, 9] [2, 9] [2, 135] [2, 135] [2, 9] [2, 160] [2, 135] [2, 9] [2, 38] 
regular batch size: 2*39, diving batch size 1*0
best_l after optimization: 1.4068634510040283 with beta sum per layer: [0.0, 0.0, 29.38620376586914]
alpha/beta optimization time: 0.6407184600830078
This batch time : update_bounds func: 0.6668	 prepare: 0.0072	 bound: 0.6410	 transfer: 0.0139	 finalize: 0.0045
Accumulated time: update_bounds func: 4.1832	 prepare: 0.0293	 bound: 4.0967	 transfer: 0.0139	 finalize: 0.0158
batch bounding time:  0.6672108173370361
Current worst splitting domains [lb, ub] (depth):
[-0.18487,   inf] (11), [-0.14696,   inf] (11), [-0.14139,   inf] (11), [-0.12368,   inf] (11), [-0.12225,   inf] (11), [-0.12087,   inf] (11), [-0.11478,   inf] (11), [-0.11158,   inf] (11), [-0.10627,   inf] (11), [-0.10151,   inf] (11), [-0.09714,   inf] (11), [-0.09416,   inf] (11), [-0.09394,   inf] (11), [-0.08472,   inf] (11), [-0.08174,   inf] (11), [-0.08094,   inf] (11), [-0.07942,   inf] (11), [-0.07323,   inf] (11), [-0.06952,   inf] (11), [-0.06486,   inf] (11), 
length of domains: 42
Total time: 0.7615	 pickout: 0.0095	 decision: 0.0827	 get_bound: 0.6674	 add_domain: 0.0019
Current lb:-0.1848672330379486
186 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.6815707683563232

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([42, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([42, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 160] [2, 135] [2, 160] [2, 160] [2, 160] [2, 135] [2, 135] [2, 9] [2, 160] [2, 135] 
regular batch size: 2*42, diving batch size 1*0
best_l after optimization: -1.0653389692306519 with beta sum per layer: [0.0, 0.0, 21.24069595336914]
alpha/beta optimization time: 0.6278963088989258
This batch time : update_bounds func: 0.6536	 prepare: 0.0078	 bound: 0.6282	 transfer: 0.0110	 finalize: 0.0064
Accumulated time: update_bounds func: 4.8367	 prepare: 0.0371	 bound: 4.7249	 transfer: 0.0110	 finalize: 0.0223
batch bounding time:  0.6538205146789551
Current worst splitting domains [lb, ub] (depth):
[-0.11219,   inf] (13), [-0.10227,   inf] (13), [-0.09260,   inf] (13), [-0.07577,   inf] (13), [-0.07383,   inf] (13), [-0.06652,   inf] (13), [-0.06279,   inf] (13), [-0.05385,   inf] (13), [-0.05287,   inf] (13), [-0.04820,   inf] (13), [-0.04639,   inf] (13), [-0.04613,   inf] (13), [-0.04174,   inf] (13), [-0.04060,   inf] (13), [-0.03969,   inf] (13), [-0.03856,   inf] (13), [-0.03246,   inf] (13), [-0.02571,   inf] (13), [-0.01892,   inf] (13), [-0.01620,   inf] (13), 
length of domains: 32
Total time: 0.7494	 pickout: 0.0114	 decision: 0.0825	 get_bound: 0.6540	 add_domain: 0.0015
Current lb:-0.1121862381696701
270 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.432308197021484

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([32, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([32, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 180] [2, 173] [2, 180] [2, 173] [2, 180] [2, 173] [2, 180] [2, 180] [2, 173] [2, 180] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: -0.6560481190681458 with beta sum per layer: [0.0, 0.0, 12.801980972290039]
alpha/beta optimization time: 0.6011826992034912
This batch time : update_bounds func: 0.6167	 prepare: 0.0062	 bound: 0.6015	 transfer: 0.0049	 finalize: 0.0040
Accumulated time: update_bounds func: 5.4534	 prepare: 0.0432	 bound: 5.3263	 transfer: 0.0049	 finalize: 0.0262
batch bounding time:  0.6168704032897949
Current worst splitting domains [lb, ub] (depth):
[-0.08962,   inf] (15), [-0.07977,   inf] (15), [-0.06758,   inf] (15), [-0.05365,   inf] (15), [-0.05267,   inf] (15), [-0.04447,   inf] (15), [-0.03825,   inf] (15), [-0.03062,   inf] (15), [-0.02991,   inf] (15), [-0.02535,   inf] (15), [-0.02322,   inf] (15), [-0.02184,   inf] (15), [-0.01890,   inf] (15), [-0.01848,   inf] (15), [-0.01768,   inf] (15), [-0.01310,   inf] (15), [-0.01255,   inf] (15), [-0.01220,   inf] (15), [-0.00675,   inf] (15), [-0.00271,   inf] (15), 
length of domains: 21
Total time: 0.7101	 pickout: 0.0088	 decision: 0.0831	 get_bound: 0.6170	 add_domain: 0.0012
Current lb:-0.08961945027112961
334 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.143218755722046

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([21, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([21, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 173] [2, 180] [2, 173] [2, 173] [2, 180] [2, 180] [2, 173] [2, 180] [2, 173] [2, 173] 
regular batch size: 2*21, diving batch size 1*0
best_l after optimization: -0.5632209181785583 with beta sum per layer: [0.0, 0.0, 7.493385314941406]
alpha/beta optimization time: 0.5786712169647217
This batch time : update_bounds func: 0.5937	 prepare: 0.0044	 bound: 0.5790	 transfer: 0.0075	 finalize: 0.0027
Accumulated time: update_bounds func: 6.0471	 prepare: 0.0477	 bound: 5.9053	 transfer: 0.0075	 finalize: 0.0289
batch bounding time:  0.5940251350402832
Current worst splitting domains [lb, ub] (depth):
[-0.06681,   inf] (17), [-0.05405,   inf] (17), [-0.04421,   inf] (17), [-0.03060,   inf] (17), [-0.02555,   inf] (17), [-0.01744,   inf] (17), [-0.01515,   inf] (17), [-0.00594,   inf] (17), [-0.00441,   inf] (17), [-0.00379,   inf] (17), [-0.00284,   inf] (17), 
length of domains: 11
Total time: 0.6653	 pickout: 0.0052	 decision: 0.0651	 get_bound: 0.5941	 add_domain: 0.0008
Current lb:-0.06680973619222641
376 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.80929160118103

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([11, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([11, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 22] [2, 200] [2, 200] [2, 200] [2, 200] [2, 64] [2, 64] [2, 200] [2, 213] [2, 200] 
regular batch size: 2*11, diving batch size 1*0
best_l after optimization: -0.3521192967891693 with beta sum per layer: [0.0, 0.0, 2.068420648574829]
alpha/beta optimization time: 0.5578939914703369
This batch time : update_bounds func: 0.5663	 prepare: 0.0030	 bound: 0.5582	 transfer: 0.0037	 finalize: 0.0014
Accumulated time: update_bounds func: 6.6135	 prepare: 0.0506	 bound: 6.4634	 transfer: 0.0037	 finalize: 0.0303
batch bounding time:  0.5665061473846436
Current worst splitting domains [lb, ub] (depth):
[-0.03639,   inf] (19), [-0.03130,   inf] (19), [-0.02026,   inf] (19), [-0.00943,   inf] (19), [-0.00632,   inf] (19), [-0.00523,   inf] (19), [-0.00224,   inf] (19), 
length of domains: 7
Total time: 0.6277	 pickout: 0.0035	 decision: 0.0572	 get_bound: 0.5666	 add_domain: 0.0005
Current lb:-0.03639103099703789
398 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.437424898147583

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([7, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([7, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 64] [2, 64] [2, 64] [2, 200] [2, 62] [2, 200] [2, 64] 
regular batch size: 2*7, diving batch size 1*0
best_l after optimization: -0.303955078125 with beta sum per layer: [0.0, 0.0, 0.7807666063308716]
alpha/beta optimization time: 0.547792911529541
This batch time : update_bounds func: 0.5535	 prepare: 0.0023	 bound: 0.5481	 transfer: 0.0019	 finalize: 0.0012
Accumulated time: update_bounds func: 7.1670	 prepare: 0.0529	 bound: 7.0115	 transfer: 0.0019	 finalize: 0.0315
batch bounding time:  0.5536975860595703
Current worst splitting domains [lb, ub] (depth):
[-0.02734,   inf] (21), [-0.02345,   inf] (21), [-0.00937,   inf] (21), 
length of domains: 3
Total time: 0.6104	 pickout: 0.0023	 decision: 0.0540	 get_bound: 0.5537	 add_domain: 0.0003
Current lb:-0.02734479494392872
412 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.048085927963257

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3, 32, 16, 16]) pre split depth:  2
batch:  torch.Size([3, 32, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [2, 153] [2, 153] [2, 153] 
split level 1: [2, 200] [2, 22] [2, 22] 
regular batch size: 2*6, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -1.3047738075256348 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.009216547012329102
This batch time : update_bounds func: 0.0138	 prepare: 0.0021	 bound: 0.0095	 transfer: 0.0014	 finalize: 0.0008
Accumulated time: update_bounds func: 7.1808	 prepare: 0.0550	 bound: 7.0210	 transfer: 0.0014	 finalize: 0.0323
batch bounding time:  0.014004945755004883
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0679	 pickout: 0.0014	 decision: 0.0513	 get_bound: 0.0151	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 7.117638111114502

Image 0 against label 1 verification end, Time cost: 7.181454658508301
##### [0] True label: 8, Tested against: 2, onnx_path: nets/cifar10_8_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_51_eps_0.03137_n1.vnnlib ######
Model prediction is: tensor([[ 0.7880,  0.0817,  0.1218, -0.7367,  0.1581, -0.9347, -0.2041, -0.7055,
          1.5174,  0.2377]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /9 torch.Size([1, 32, 16, 16])
1 /11 torch.Size([1, 128, 8, 8])
2 /14 torch.Size([1, 250])
best_l after optimization: 0.2473747283220291 with beta sum per layer: []
alpha/beta optimization time: 0.9427037239074707
alpha-CROWN with fixed intermediate bounds: tensor([[-0.2474]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.2473747432231903
layer 0 size torch.Size([8192]) unstable 260
layer 1 size torch.Size([8192]) unstable 1123
layer 2 size torch.Size([250]) unstable 111
-----------------
# of unstable neurons: 1494
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 192] 
split level 1: [2, 213] 
split level 2: [2, 162] 
split level 3: [2, 54] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.06478868424892426 with beta sum per layer: [0.0, 0.0, 2.0804905891418457]
alpha/beta optimization time: 0.5456604957580566
This batch time : update_bounds func: 0.5514	 prepare: 0.0025	 bound: 0.5461	 transfer: 0.0017	 finalize: 0.0010
Accumulated time: update_bounds func: 7.7322	 prepare: 0.0574	 bound: 7.5671	 transfer: 0.0017	 finalize: 0.0333
batch bounding time:  0.551530122756958
Current worst splitting domains [lb, ub] (depth):
[-0.11213,   inf] (5), [-0.08731,   inf] (5), [-0.08516,   inf] (5), [-0.05833,   inf] (5), [-0.00808,   inf] (5), 
length of domains: 5
Total time: 0.6040	 pickout: 0.0009	 decision: 0.0495	 get_bound: 0.5533	 add_domain: 0.0003
Current lb:-0.11212790012359619
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.5667552947998047

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([5, 32, 16, 16]) pre split depth:  2
batch:  torch.Size([5, 32, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [2, 208] [2, 208] [2, 208] [2, 208] [2, 208] 
split level 1: [2, 37] [2, 53] [2, 37] [2, 53] [2, 37] 
regular batch size: 2*10, diving batch size 1*0
best_l after optimization: -1.2760361433029175 with beta sum per layer: [0.0, 0.0, 4.266368389129639]
alpha/beta optimization time: 0.5494973659515381
This batch time : update_bounds func: 0.5559	 prepare: 0.0027	 bound: 0.5498	 transfer: 0.0021	 finalize: 0.0012
Accumulated time: update_bounds func: 8.2881	 prepare: 0.0601	 bound: 8.1169	 transfer: 0.0021	 finalize: 0.0346
batch bounding time:  0.5560846328735352
Current worst splitting domains [lb, ub] (depth):
[-0.06036,   inf] (8), [-0.05019,   inf] (8), [-0.04087,   inf] (8), [-0.03352,   inf] (8), [-0.02056,   inf] (8), [-0.00843,   inf] (8), [-0.00057,   inf] (8), 
length of domains: 7
Total time: 0.6118	 pickout: 0.0018	 decision: 0.0521	 get_bound: 0.5575	 add_domain: 0.0004
Current lb:-0.06035752221941948
36 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.1788480281829834

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([7, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([7, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 53] [2, 37] [2, 53] [2, 53] [2, 90] [2, 53] [2, 37] 
regular batch size: 2*7, diving batch size 1*0
best_l after optimization: -0.15929014980793 with beta sum per layer: [0.0, 0.0, 3.5678608417510986]
alpha/beta optimization time: 0.5489280223846436
This batch time : update_bounds func: 0.5543	 prepare: 0.0022	 bound: 0.5492	 transfer: 0.0016	 finalize: 0.0012
Accumulated time: update_bounds func: 8.8424	 prepare: 0.0624	 bound: 8.6661	 transfer: 0.0016	 finalize: 0.0358
batch bounding time:  0.5544900894165039
Current worst splitting domains [lb, ub] (depth):
[-0.03373,   inf] (10), [-0.01394,   inf] (10), [-0.00852,   inf] (10), [-0.00546,   inf] (10), 
length of domains: 4
Total time: 0.6111	 pickout: 0.0022	 decision: 0.0540	 get_bound: 0.5545	 add_domain: 0.0003
Current lb:-0.033727847039699554
50 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.7901551723480225

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 32, 16, 16]) pre split depth:  2
batch:  torch.Size([4, 32, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [2, 90] [2, 90] [2, 90] [2, 90] 
split level 1: [2, 60] [2, 60] [2, 200] [2, 60] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -0.9177137613296509 with beta sum per layer: [0.0, 0.0, 1.850271463394165]
alpha/beta optimization time: 0.007834911346435547
This batch time : update_bounds func: 0.0133	 prepare: 0.0025	 bound: 0.0081	 transfer: 0.0016	 finalize: 0.0010
Accumulated time: update_bounds func: 8.8557	 prepare: 0.0648	 bound: 8.6742	 transfer: 0.0016	 finalize: 0.0368
batch bounding time:  0.013347625732421875
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0689	 pickout: 0.0016	 decision: 0.0527	 get_bound: 0.0146	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 2.8593642711639404

Image 0 against label 2 verification end, Time cost: 2.9273085594177246
##### [0] True label: 8, Tested against: 3, onnx_path: nets/cifar10_8_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_51_eps_0.03137_n1.vnnlib ######
init opt crown verified for label 3 with bound 0.39067453145980835
Image 0 against label 3 verification end, Time cost: 0.0003039836883544922
##### [0] True label: 8, Tested against: 4, onnx_path: nets/cifar10_8_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_51_eps_0.03137_n1.vnnlib ######
Model prediction is: tensor([[ 0.7880,  0.0817,  0.1218, -0.7367,  0.1581, -0.9347, -0.2041, -0.7055,
          1.5174,  0.2377]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /9 torch.Size([1, 32, 16, 16])
1 /11 torch.Size([1, 128, 8, 8])
2 /14 torch.Size([1, 250])
best_l after optimization: 0.2053515911102295 with beta sum per layer: []
alpha/beta optimization time: 1.086702585220337
alpha-CROWN with fixed intermediate bounds: tensor([[-0.2054]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.2053515911102295
layer 0 size torch.Size([8192]) unstable 260
layer 1 size torch.Size([8192]) unstable 1123
layer 2 size torch.Size([250]) unstable 111
-----------------
# of unstable neurons: 1494
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 213] 
split level 1: [2, 119] 
split level 2: [2, 90] 
split level 3: [2, 149] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.5999637842178345 with beta sum per layer: [0.0, 0.0, 0.3266827166080475]
alpha/beta optimization time: 0.5924394130706787
This batch time : update_bounds func: 0.5983	 prepare: 0.0025	 bound: 0.5930	 transfer: 0.0017	 finalize: 0.0011
Accumulated time: update_bounds func: 9.4540	 prepare: 0.0673	 bound: 9.2671	 transfer: 0.0017	 finalize: 0.0379
batch bounding time:  0.5984654426574707
Current worst splitting domains [lb, ub] (depth):
[-0.04365,   inf] (5), [-0.03981,   inf] (5), 
length of domains: 2
Total time: 0.6532	 pickout: 0.0008	 decision: 0.0519	 get_bound: 0.6003	 add_domain: 0.0002
Current lb:-0.043651580810546875
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.760347604751587

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2, 32, 16, 16]) pre split depth:  3
batch:  torch.Size([2, 32, 16, 16]) post split depth:  3
splitting decisions: 
split level 0: [2, 27] [2, 131] 
split level 1: [2, 131] [2, 27] 
split level 2: [2, 54] [2, 54] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -1.2379399538040161 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.007972002029418945
This batch time : update_bounds func: 0.0151	 prepare: 0.0025	 bound: 0.0083	 transfer: 0.0032	 finalize: 0.0011
Accumulated time: update_bounds func: 9.4691	 prepare: 0.0698	 bound: 9.2754	 transfer: 0.0032	 finalize: 0.0390
batch bounding time:  0.015146970748901367
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0835	 pickout: 0.0011	 decision: 0.0654	 get_bound: 0.0169	 add_domain: 0.0001
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.8441178798675537

Image 0 against label 4 verification end, Time cost: 1.9027838706970215
##### [0] True label: 8, Tested against: 5, onnx_path: nets/cifar10_8_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_51_eps_0.03137_n1.vnnlib ######
init opt crown verified for label 5 with bound 0.416911244392395
Image 0 against label 5 verification end, Time cost: 0.00043845176696777344
##### [0] True label: 8, Tested against: 6, onnx_path: nets/cifar10_8_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_51_eps_0.03137_n1.vnnlib ######
Model prediction is: tensor([[ 0.7880,  0.0817,  0.1218, -0.7367,  0.1581, -0.9347, -0.2041, -0.7055,
          1.5174,  0.2377]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /9 torch.Size([1, 32, 16, 16])
1 /11 torch.Size([1, 128, 8, 8])
2 /14 torch.Size([1, 250])
best_l after optimization: 0.02921447530388832 with beta sum per layer: []
alpha/beta optimization time: 0.9755563735961914
alpha-CROWN with fixed intermediate bounds: tensor([[-0.0292]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.02921447530388832
layer 0 size torch.Size([8192]) unstable 260
layer 1 size torch.Size([8192]) unstable 1123
layer 2 size torch.Size([250]) unstable 111
-----------------
# of unstable neurons: 1494
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 208] 
split level 1: [2, 213] 
split level 2: [2, 195] 
split level 3: [2, 54] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -3.7141871452331543 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.010155200958251953
This batch time : update_bounds func: 0.0170	 prepare: 0.0025	 bound: 0.0106	 transfer: 0.0027	 finalize: 0.0010
Accumulated time: update_bounds func: 9.4860	 prepare: 0.0723	 bound: 9.2860	 transfer: 0.0027	 finalize: 0.0400
batch bounding time:  0.01703357696533203
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0697	 pickout: 0.0009	 decision: 0.0499	 get_bound: 0.0189	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.0655221939086914

Image 0 against label 6 verification end, Time cost: 1.130741834640503
##### [0] True label: 8, Tested against: 7, onnx_path: nets/cifar10_8_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_51_eps_0.03137_n1.vnnlib ######
init opt crown verified for label 7 with bound 0.13480030000209808
Image 0 against label 7 verification end, Time cost: 0.0002853870391845703
##### [0] True label: 8, Tested against: 9, onnx_path: nets/cifar10_8_255_simplified.onnx, vnnlib_path: specs/cifar10/cifar10_spec_idx_51_eps_0.03137_n1.vnnlib ######
Model prediction is: tensor([[ 0.7880,  0.0817,  0.1218, -0.7367,  0.1581, -0.9347, -0.2041, -0.7055,
          1.5174,  0.2377]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /9 torch.Size([1, 32, 16, 16])
1 /11 torch.Size([1, 128, 8, 8])
2 /14 torch.Size([1, 250])
best_l after optimization: 0.4315767288208008 with beta sum per layer: []
alpha/beta optimization time: 0.9582593441009521
alpha-CROWN with fixed intermediate bounds: tensor([[-0.4316]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.4315767288208008
layer 0 size torch.Size([8192]) unstable 260
layer 1 size torch.Size([8192]) unstable 1123
layer 2 size torch.Size([250]) unstable 111
-----------------
# of unstable neurons: 1494
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 79] 
split level 1: [2, 54] 
split level 2: [2, 50] 
split level 3: [2, 25] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 1.893212080001831 with beta sum per layer: [0.0, 0.0, 6.264197826385498]
alpha/beta optimization time: 0.5486512184143066
This batch time : update_bounds func: 0.5561	 prepare: 0.0026	 bound: 0.5492	 transfer: 0.0032	 finalize: 0.0011
Accumulated time: update_bounds func: 10.0422	 prepare: 0.0749	 bound: 9.8352	 transfer: 0.0032	 finalize: 0.0411
batch bounding time:  0.5563271045684814
Current worst splitting domains [lb, ub] (depth):
[-0.32584,   inf] (5), [-0.25476,   inf] (5), [-0.24331,   inf] (5), [-0.19649,   inf] (5), [-0.17156,   inf] (5), [-0.16941,   inf] (5), [-0.11484,   inf] (5), [-0.10979,   inf] (5), [-0.10698,   inf] (5), [-0.10299,   inf] (5), [-0.04893,   inf] (5), [-0.04771,   inf] (5), [-0.02395,   inf] (5), 
length of domains: 13
Total time: 0.6101	 pickout: 0.0010	 decision: 0.0503	 get_bound: 0.5582	 add_domain: 0.0006
Current lb:-0.32583504915237427
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.5887200832366943

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([13, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([13, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 189] [2, 189] [2, 243] [2, 189] [2, 189] [2, 189] [2, 189] [2, 189] [2, 189] [2, 189] 
regular batch size: 2*13, diving batch size 1*0
best_l after optimization: 1.305530071258545 with beta sum per layer: [0.0, 0.0, 15.283946990966797]
alpha/beta optimization time: 0.5480554103851318
This batch time : update_bounds func: 0.5581	 prepare: 0.0033	 bound: 0.5483	 transfer: 0.0048	 finalize: 0.0015
Accumulated time: update_bounds func: 10.6003	 prepare: 0.0781	 bound: 10.3836	 transfer: 0.0048	 finalize: 0.0426
batch bounding time:  0.558255672454834
Current worst splitting domains [lb, ub] (depth):
[-0.24498,   inf] (7), [-0.23893,   inf] (7), [-0.20494,   inf] (7), [-0.17234,   inf] (7), [-0.16852,   inf] (7), [-0.12489,   inf] (7), [-0.08082,   inf] (7), [-0.07987,   inf] (7), [-0.07897,   inf] (7), [-0.07594,   inf] (7), [-0.07392,   inf] (7), [-0.02914,   inf] (7), [-0.02013,   inf] (7), [-0.00378,   inf] (7), 
length of domains: 14
Total time: 0.6209	 pickout: 0.0039	 decision: 0.0580	 get_bound: 0.5583	 add_domain: 0.0006
Current lb:-0.2449840009212494
42 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.2100961208343506

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([14, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([14, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 243] [2, 243] [2, 189] [2, 243] [2, 243] [2, 189] [2, 215] [2, 243] [2, 243] [2, 243] 
regular batch size: 2*14, diving batch size 1*0
best_l after optimization: 1.2742613554000854 with beta sum per layer: [0.0, 0.0, 19.71407699584961]
alpha/beta optimization time: 0.5592186450958252
This batch time : update_bounds func: 0.5684	 prepare: 0.0034	 bound: 0.5595	 transfer: 0.0038	 finalize: 0.0017
Accumulated time: update_bounds func: 11.1687	 prepare: 0.0815	 bound: 10.9431	 transfer: 0.0038	 finalize: 0.0443
batch bounding time:  0.5685725212097168
Current worst splitting domains [lb, ub] (depth):
[-0.21996,   inf] (9), [-0.21373,   inf] (9), [-0.14552,   inf] (9), [-0.14163,   inf] (9), [-0.13798,   inf] (9), [-0.13566,   inf] (9), [-0.11529,   inf] (9), [-0.11225,   inf] (9), [-0.08140,   inf] (9), [-0.07914,   inf] (9), [-0.04224,   inf] (9), [-0.03991,   inf] (9), [-0.02842,   inf] (9), [-0.01721,   inf] (9), [-0.01703,   inf] (9), [-0.01536,   inf] (9), [-0.01198,   inf] (9), 
length of domains: 17
Total time: 0.6337	 pickout: 0.0038	 decision: 0.0604	 get_bound: 0.5686	 add_domain: 0.0009
Current lb:-0.21995994448661804
70 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.8441648483276367

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([17, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([17, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 60] [2, 60] [2, 60] [2, 60] [2, 60] [2, 60] [2, 60] [2, 60] [2, 60] [2, 60] 
regular batch size: 2*17, diving batch size 1*0
best_l after optimization: 1.1615525484085083 with beta sum per layer: [0.0, 0.0, 27.91260528564453]
alpha/beta optimization time: 0.5833065509796143
This batch time : update_bounds func: 0.5939	 prepare: 0.0038	 bound: 0.5836	 transfer: 0.0042	 finalize: 0.0022
Accumulated time: update_bounds func: 11.7625	 prepare: 0.0853	 bound: 11.5266	 transfer: 0.0042	 finalize: 0.0465
batch bounding time:  0.5940415859222412
Current worst splitting domains [lb, ub] (depth):
[-0.19615,   inf] (11), [-0.18792,   inf] (11), [-0.13133,   inf] (11), [-0.12276,   inf] (11), [-0.12079,   inf] (11), [-0.11481,   inf] (11), [-0.09854,   inf] (11), [-0.09652,   inf] (11), [-0.08259,   inf] (11), [-0.07698,   inf] (11), [-0.05425,   inf] (11), [-0.04867,   inf] (11), [-0.04736,   inf] (11), [-0.04621,   inf] (11), [-0.03729,   inf] (11), [-0.02832,   inf] (11), [-0.02078,   inf] (11), [-0.01351,   inf] (11), [-0.01179,   inf] (11), [-0.00690,   inf] (11), 
length of domains: 20
Total time: 0.6616	 pickout: 0.0044	 decision: 0.0622	 get_bound: 0.5941	 add_domain: 0.0010
Current lb:-0.19614508748054504
104 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.5062365531921387

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([20, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([20, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 215] [2, 172] [2, 215] [2, 215] [2, 215] [2, 215] [2, 172] [2, 172] [2, 200] [2, 172] 
regular batch size: 2*20, diving batch size 1*0
best_l after optimization: 0.8435169458389282 with beta sum per layer: [0.0, 0.0, 31.988739013671875]
alpha/beta optimization time: 0.5752065181732178
This batch time : update_bounds func: 0.5874	 prepare: 0.0043	 bound: 0.5755	 transfer: 0.0050	 finalize: 0.0025
Accumulated time: update_bounds func: 12.3499	 prepare: 0.0896	 bound: 12.1021	 transfer: 0.0050	 finalize: 0.0490
batch bounding time:  0.5875892639160156
Current worst splitting domains [lb, ub] (depth):
[-0.15557,   inf] (13), [-0.14369,   inf] (13), [-0.12638,   inf] (13), [-0.12567,   inf] (13), [-0.09381,   inf] (13), [-0.08086,   inf] (13), [-0.07721,   inf] (13), [-0.07662,   inf] (13), [-0.05414,   inf] (13), [-0.05079,   inf] (13), [-0.04917,   inf] (13), [-0.04797,   inf] (13), [-0.04536,   inf] (13), [-0.04107,   inf] (13), [-0.03238,   inf] (13), [-0.02725,   inf] (13), [-0.01550,   inf] (13), [-0.01137,   inf] (13), [-0.00877,   inf] (13), [-0.00834,   inf] (13), 
length of domains: 22
Total time: 0.6588	 pickout: 0.0051	 decision: 0.0649	 get_bound: 0.5877	 add_domain: 0.0011
Current lb:-0.155569925904274
144 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.165599584579468

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([22, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([22, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 187] [2, 187] [2, 187] [2, 187] [2, 187] [2, 187] [2, 187] [2, 187] [2, 187] [2, 187] 
regular batch size: 2*22, diving batch size 1*0
best_l after optimization: -0.26094019412994385 with beta sum per layer: [0.0, 0.0, 29.625381469726562]
alpha/beta optimization time: 0.5823028087615967
This batch time : update_bounds func: 0.5978	 prepare: 0.0046	 bound: 0.5826	 transfer: 0.0078	 finalize: 0.0027
Accumulated time: update_bounds func: 12.9477	 prepare: 0.0942	 bound: 12.6847	 transfer: 0.0078	 finalize: 0.0517
batch bounding time:  0.5980973243713379
Current worst splitting domains [lb, ub] (depth):
[-0.14507,   inf] (15), [-0.13417,   inf] (15), [-0.11656,   inf] (15), [-0.11218,   inf] (15), [-0.08235,   inf] (15), [-0.07040,   inf] (15), [-0.06729,   inf] (15), [-0.06494,   inf] (15), [-0.03902,   inf] (15), [-0.03535,   inf] (15), [-0.03529,   inf] (15), [-0.03439,   inf] (15), [-0.03131,   inf] (15), [-0.02319,   inf] (15), [-0.01323,   inf] (15), [-0.01231,   inf] (15), [-0.00522,   inf] (15), 
length of domains: 17
Total time: 0.6706	 pickout: 0.0055	 decision: 0.0658	 get_bound: 0.5982	 add_domain: 0.0011
Current lb:-0.14507441222667694
188 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.836974143981934

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([17, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([17, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 200] [2, 215] [2, 200] [2, 200] [2, 172] [2, 200] [2, 200] [2, 172] [2, 172] [2, 215] 
regular batch size: 2*17, diving batch size 1*0
best_l after optimization: 0.34345337748527527 with beta sum per layer: [0.0, 0.0, 21.865352630615234]
alpha/beta optimization time: 0.6047770977020264
This batch time : update_bounds func: 0.6171	 prepare: 0.0038	 bound: 0.6051	 transfer: 0.0060	 finalize: 0.0021
Accumulated time: update_bounds func: 13.5649	 prepare: 0.0980	 bound: 13.2898	 transfer: 0.0060	 finalize: 0.0538
batch bounding time:  0.6173267364501953
Current worst splitting domains [lb, ub] (depth):
[-0.11973,   inf] (17), [-0.09664,   inf] (17)/home/zhouxingshi/conda/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:25: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1627336316785/work/torch/csrc/utils/tensor_numpy.cpp:143.)
  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))
, [-0.09123,   inf] (17), [-0.08569,   inf] (17), [-0.06906,   inf] (17), [-0.06564,   inf] (17), [-0.04445,   inf] (17), [-0.04427,   inf] (17), [-0.03907,   inf] (17), [-0.03756,   inf] (17), [-0.03439,   inf] (17), [-0.02031,   inf] (17), [-0.01999,   inf] (17), [-0.00671,   inf] (17), [-0.00481,   inf] (17), [-0.00256,   inf] (17), [-0.00039,   inf] (17), 
length of domains: 17
Total time: 0.6871	 pickout: 0.0051	 decision: 0.0635	 get_bound: 0.6174	 add_domain: 0.0011
Current lb:-0.11972626298666
222 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.5245630741119385

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([17, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([17, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 172] [2, 200] [2, 215] [2, 172] [2, 172] [2, 200] [2, 215] [2, 172] [2, 172] [2, 200] 
regular batch size: 2*17, diving batch size 1*0
best_l after optimization: -0.06008695065975189 with beta sum per layer: [0.0, 0.0, 11.327108383178711]
alpha/beta optimization time: 0.5693674087524414
This batch time : update_bounds func: 0.5791	 prepare: 0.0038	 bound: 0.5696	 transfer: 0.0035	 finalize: 0.0021
Accumulated time: update_bounds func: 14.1440	 prepare: 0.1018	 bound: 13.8594	 transfer: 0.0035	 finalize: 0.0559
batch bounding time:  0.5793159008026123
Current worst splitting domains [lb, ub] (depth):
[-0.07515,   inf] (19), [-0.06950,   inf] (19), [-0.05847,   inf] (19), [-0.05271,   inf] (19), [-0.03931,   inf] (19), [-0.03458,   inf] (19), [-0.03005,   inf] (19), [-0.02698,   inf] (19), [-0.02583,   inf] (19), [-0.02151,   inf] (19), [-0.00404,   inf] (19), 
length of domains: 11
Total time: 0.6468	 pickout: 0.0046	 decision: 0.0620	 get_bound: 0.5794	 add_domain: 0.0008
Current lb:-0.07515358924865723
256 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.17188024520874

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([11, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([11, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 62] [2, 62] [2, 62] [2, 62] [2, 62] [2, 62] [2, 62] [2, 160] [2, 160] [2, 62] 
regular batch size: 2*11, diving batch size 1*0
best_l after optimization: 0.05163486674427986 with beta sum per layer: [0.0, 0.0, 4.465888500213623]
alpha/beta optimization time: 0.5542120933532715
This batch time : update_bounds func: 0.5611	 prepare: 0.0030	 bound: 0.5545	 transfer: 0.0022	 finalize: 0.0014
Accumulated time: update_bounds func: 14.7051	 prepare: 0.1048	 bound: 14.4139	 transfer: 0.0022	 finalize: 0.0573
batch bounding time:  0.5613107681274414
Current worst splitting domains [lb, ub] (depth):
[-0.04114,   inf] (21), [-0.03899,   inf] (21), [-0.03123,   inf] (21), [-0.02417,   inf] (21), [-0.02202,   inf] (21), [-0.02021,   inf] (21), [-0.01593,   inf] (21), [-0.00811,   inf] (21), [-0.00010,   inf] (21), 
length of domains: 9
Total time: 0.6217	 pickout: 0.0033	 decision: 0.0564	 get_bound: 0.5614	 add_domain: 0.0006
Current lb:-0.041136108338832855
278 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.79397988319397

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([9, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([9, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 160] [2, 160] [2, 160] [2, 160] [2, 160] [2, 160] [2, 160] [2, 160] [2, 160] 
regular batch size: 2*9, diving batch size 1*0
best_l after optimization: -0.21717919409275055 with beta sum per layer: [0.0, 0.0, 1.368483304977417]
alpha/beta optimization time: 0.5506162643432617
This batch time : update_bounds func: 0.5569	 prepare: 0.0026	 bound: 0.5509	 transfer: 0.0019	 finalize: 0.0014
Accumulated time: update_bounds func: 15.2620	 prepare: 0.1074	 bound: 14.9648	 transfer: 0.0019	 finalize: 0.0587
batch bounding time:  0.5570132732391357
Current worst splitting domains [lb, ub] (depth):
[-0.00849,   inf] (23), [-0.00405,   inf] (23), [-0.00367,   inf] (23), [-0.00264,   inf] (23), 
length of domains: 4
Total time: 0.6153	 pickout: 0.0027	 decision: 0.0552	 get_bound: 0.5571	 add_domain: 0.0004
Current lb:-0.008494782261550426
296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.4095847606658936

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 32, 16, 16]) pre split depth:  2
batch:  torch.Size([4, 32, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [2, 86] [2, 86] [2, 86] [2, 86] 
split level 1: [2, 75] [2, 11] [2, 75] [2, 11] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -0.8551092743873596 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.0081024169921875
This batch time : update_bounds func: 0.0137	 prepare: 0.0025	 bound: 0.0084	 transfer: 0.0017	 finalize: 0.0011
Accumulated time: update_bounds func: 15.2757	 prepare: 0.1099	 bound: 14.9731	 transfer: 0.0017	 finalize: 0.0597
batch bounding time:  0.013816356658935547
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0790	 pickout: 0.0016	 decision: 0.0621	 get_bound: 0.0153	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 7.488953351974487

Image 0 against label 9 verification end, Time cost: 7.5479066371917725
Result: safe-bab in 40.1501 seconds


[[  0.           0.0000001   68.           4.80013919   0.        ]
 [  0.           0.0000001  424.           7.18145466   1.        ]
 [  0.           0.0000001   66.           2.92730856   2.        ]
 [  0.           0.39067453   0.           0.00030398   3.        ]
 [  0.           0.0000001   32.           1.90278387   4.        ]
 [  0.           0.41691124   0.           0.00043845   5.        ]
 [  0.           0.0000001   16.           1.13074183   6.        ]
 [  0.           0.1348003    0.           0.00028539   7.        ]
 [  0.           0.0000001  312.           7.54790664   9.        ]]
############# Summary #############
Final verified acc: 100.0% [total 1 examples]
Total verification count: 1 , total verified safe: 1 , verified unsafe: 0 , timeout: 0
mean time [total:1]: 25.49136257171631
mean time [cnt:1]: 25.49136257171631
max time 40.150099992752075
safe-bab (total 1): [0]
