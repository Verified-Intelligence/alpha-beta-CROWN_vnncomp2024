/home/zhouxingshi/Verifier_Development/complete_verifier/abcrown.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  c = torch.tensor(specs[0][0]).unsqueeze(0).to(data)
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: false
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: false
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: null
  results_file: out.txt
  root_path: ''
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "default_optimizer")'
  buffer_has_batchdim: false
  save_output: true
  output_file: /home/zhouxingshi/Verifier_Development/tests/gpu_tests/gcp_crown/oval_deep_cplex/master_outputs/2.pkl
  return_optimized_model: false
model:
  name: cifar_model_deep
  path: models/oval/cifar_deep.pth
  onnx_path: null
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: default_onnx_and_vnnlib_loader
  onnx_optimization_flags: none
  onnx_vnnlib_joint_optimization_flags: none
  check_optmized: false
  flatten_final_output: false
  optimize_graph: null
  with_jacobian: false
data:
  start: 67
  end: 68
  select_instance: null
  num_outputs: 10
  mean: [0.485, 0.456, 0.406]
  std: [0.225, 0.225, 0.225]
  pkl_path: models/oval/deep_100.pkl
  dataset: CIFAR
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: specify-target
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: null
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 1024
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  optimize_disjuncts_separately: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
    relu_option: adaptive
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    disable_optimization: []
  invprop:
    apply_output_constraints_to: []
    tighten_input_bounds: false
    best_of_oc_and_no_oc: false
    directly_optimize: []
    oc_lr: 0.1
    share_gammas: false
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.03
    lr_decay: 0.96
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
    reset_threshold: 1.0
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: false
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 3600
  timeout_scale: 1
  max_iterations: -1
  override_timeout: null
  get_upper_bound: false
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: true
    implication: false
    bab_cut: true
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 0.8
    iteration: 200
    bab_iteration: 50
    early_stop_patience: -1
    lr_beta: 0.01
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: true
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
    _tmp_cuts: null
    fixed_cuts: false
    add_implied_cuts: false
    add_input_cuts: false
  branching:
    method: kfsb
    candidates: 10
    reduceop: min
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      num_branches: 2
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      use_min: false
      loose_tanh_threshold: null
      dynamic_bbps: false
      dynamic_options: [uniform, three_left, three_right]
      branching_point_node: ''
      branching_point_db: []
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_iters: 1000000000.0
      bf_batch_size: 100000
      bf_zero_crossing_score: false
      touch_zero_score: 0
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
      sb_coeff_thresh: 0.001
      sort_index: null
      sort_descending: true
      show_progress: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 30.0
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  pgd_steps: 100
  pgd_restarts: 30
  pgd_batch_size: 100000000
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_alpha_scale: false
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: default_adv_saver
  early_stop_condition: default_early_stop_condition
  adv_example_finalizer: default_adv_example_finalizer
  pgd_loss: default_pgd_loss
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: attack_with_general_specs
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0
  print_verbose_decisions: false

Experiments at Thu Apr 11 12:40:48 2024 on valla.cs.ucla.edu
Sequential(
  (0): Conv2d(3, 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (3): ReLU()
  (4): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (5): ReLU()
  (6): Conv2d(8, 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (7): ReLU()
  (8): Flatten(start_dim=1, end_dim=-1)
  (9): Linear(in_features=512, out_features=100, bias=True)
  (10): ReLU()
  (11): Linear(in_features=100, out_features=10, bias=True)
)
Parameters:
  0.weight: shape torch.Size([8, 3, 4, 4])
  0.bias: shape torch.Size([8])
  2.weight: shape torch.Size([8, 8, 3, 3])
  2.bias: shape torch.Size([8])
  4.weight: shape torch.Size([8, 8, 3, 3])
  4.bias: shape torch.Size([8])
  6.weight: shape torch.Size([8, 8, 4, 4])
  6.bias: shape torch.Size([8])
  9.weight: shape torch.Size([100, 512])
  9.bias: shape torch.Size([100])
  11.weight: shape torch.Size([10, 100])
  11.bias: shape torch.Size([10])
Files already downloaded and verified
Overwrite epsilon that saved in .pkl file, they should be after normalized!
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 67 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Model: BoundedModule(
  (/input.1): BoundInput(name=/input.1, inputs=[], perturbed=True)
  (/1): BoundParams(name=/1, inputs=[], perturbed=False)
  (/2): BoundParams(name=/2, inputs=[], perturbed=False)
  (/3): BoundParams(name=/3, inputs=[], perturbed=False)
  (/4): BoundParams(name=/4, inputs=[], perturbed=False)
  (/5): BoundParams(name=/5, inputs=[], perturbed=False)
  (/6): BoundParams(name=/6, inputs=[], perturbed=False)
  (/7): BoundParams(name=/7, inputs=[], perturbed=False)
  (/8): BoundParams(name=/8, inputs=[], perturbed=False)
  (/9): BoundParams(name=/9, inputs=[], perturbed=False)
  (/10): BoundParams(name=/10, inputs=[], perturbed=False)
  (/11): BoundParams(name=/11, inputs=[], perturbed=False)
  (/12): BoundParams(name=/12, inputs=[], perturbed=False)
  (/input): BoundConv(name=/input, inputs=[/input.1, /1, /2], perturbed=True)
  (/input.4): BoundRelu(name=/input.4, inputs=[/input], perturbed=True)
  (/input.8): BoundConv(name=/input.8, inputs=[/input.4, /3, /4], perturbed=True)
  (/input.12): BoundRelu(name=/input.12, inputs=[/input.8], perturbed=True)
  (/input.16): BoundConv(name=/input.16, inputs=[/input.12, /5, /6], perturbed=True)
  (/input.20): BoundRelu(name=/input.20, inputs=[/input.16], perturbed=True)
  (/input.24): BoundConv(name=/input.24, inputs=[/input.20, /7, /8], perturbed=True)
  (/20): BoundRelu(name=/20, inputs=[/input.24], perturbed=True)
  (/21): BoundFlatten(name=/21, inputs=[/20], perturbed=True)
  (/input.28): BoundLinear(name=/input.28, inputs=[/21, /9, /10], perturbed=True)
  (/23): BoundRelu(name=/23, inputs=[/input.28], perturbed=True)
  (/24): BoundLinear(name=/24, inputs=[/23, /11, /12], perturbed=True)
)
Original output: tensor([[-2.35039830, -4.53964615,  1.72910023,  2.51990438,  2.08594632,
          2.71009231,  2.03775144,  1.96993172, -3.78473258, -2.37795210]],
       device='cuda:0')
Split layers:
  BoundConv(name=/input, inputs=[/input.1, /1, /2], perturbed=True): [(BoundRelu(name=/input.4, inputs=[/input], perturbed=True), 0)]
  BoundConv(name=/input.8, inputs=[/input.4, /3, /4], perturbed=True): [(BoundRelu(name=/input.12, inputs=[/input.8], perturbed=True), 0)]
  BoundConv(name=/input.16, inputs=[/input.12, /5, /6], perturbed=True): [(BoundRelu(name=/input.20, inputs=[/input.16], perturbed=True), 0)]
  BoundConv(name=/input.24, inputs=[/input.20, /7, /8], perturbed=True): [(BoundRelu(name=/20, inputs=[/input.24], perturbed=True), 0)]
  BoundLinear(name=/input.28, inputs=[/21, /9, /10], perturbed=True): [(BoundRelu(name=/23, inputs=[/input.28], perturbed=True), 0)]
Nonlinear functions:
   BoundRelu(name=/input.4, inputs=[/input], perturbed=True)
   BoundRelu(name=/input.12, inputs=[/input.8], perturbed=True)
   BoundRelu(name=/input.20, inputs=[/input.16], perturbed=True)
   BoundRelu(name=/20, inputs=[/input.24], perturbed=True)
   BoundRelu(name=/23, inputs=[/input.28], perturbed=True)
layer /input.4 using sparse-features alpha with shape [215]; unstable size 215; total size 2048 ([1, 8, 16, 16])
layer /input.4 start_node /input.8 using sparse-spec alpha [2, 429, 1, 215] with unstable size 428 total_size 2048 output_shape (8, 16, 16)
layer /input.4 start_node /input.16 using sparse-spec alpha [2, 326, 1, 215] with unstable size 325 total_size 2048 output_shape (8, 16, 16)
layer /input.4 start_node /input.24 using sparse-spec alpha [2, 85, 1, 215] with unstable size 84 total_size 512 output_shape (8, 8, 8)
layer /input.4 start_node /input.28 using sparse-spec alpha [2, 46, 1, 215] with unstable size 45 total_size 100 output_shape torch.Size([100])
layer /input.4 start_node /24 using full alpha [2, 1, 1, 215] with unstable size None total_size 1 output_shape 1
layer /input.12 using sparse-features alpha with shape [428]; unstable size 428; total size 2048 ([1, 8, 16, 16])
layer /input.12 start_node /input.16 using sparse-spec alpha [2, 326, 1, 428] with unstable size 325 total_size 2048 output_shape (8, 16, 16)
layer /input.12 start_node /input.24 using sparse-spec alpha [2, 85, 1, 428] with unstable size 84 total_size 512 output_shape (8, 8, 8)
layer /input.12 start_node /input.28 using sparse-spec alpha [2, 46, 1, 428] with unstable size 45 total_size 100 output_shape torch.Size([100])
layer /input.12 start_node /24 using full alpha [2, 1, 1, 428] with unstable size None total_size 1 output_shape 1
layer /input.20 using sparse-features alpha with shape [325]; unstable size 325; total size 2048 ([1, 8, 16, 16])
layer /input.20 start_node /input.24 using sparse-spec alpha [2, 85, 1, 325] with unstable size 84 total_size 512 output_shape (8, 8, 8)
layer /input.20 start_node /input.28 using sparse-spec alpha [2, 46, 1, 325] with unstable size 45 total_size 100 output_shape torch.Size([100])
layer /input.20 start_node /24 using full alpha [2, 1, 1, 325] with unstable size None total_size 1 output_shape 1
layer /20 using sparse-features alpha with shape [84]; unstable size 84; total size 512 ([1, 8, 8, 8])
layer /20 start_node /input.28 using sparse-spec alpha [2, 46, 1, 84] with unstable size 45 total_size 100 output_shape torch.Size([100])
layer /20 start_node /24 using full alpha [2, 1, 1, 84] with unstable size None total_size 1 output_shape 1
layer /23 using sparse-features alpha with shape [45]; unstable size 45; total size 100 ([1, 100])
layer /23 start_node /24 using full alpha [2, 1, 1, 45] with unstable size None total_size 1 output_shape 1
Optimizable variables initialized.
initial CROWN bounds: tensor([[-0.51241779]], device='cuda:0') None
best_l after optimization: -0.3435361385345459
alpha/beta optimization time: 13.731139659881592
initial alpha-crown bounds: tensor([[-0.34353614]], device='cuda:0')
Worst class: (+ rhs) -0.3435361385345459
preset mip_multi_proc as default setting: 40
Set parameter WLSAccessID
Set parameter WLSSecret
Set parameter LicenseID to value 2482314
Academic license 2482314 - for non-commercial use only - registered to z.___@g.ucla.edu
mip_multi_proc: 40, mip_threads: 1, total threads used: 40
mip solver model built in 1.6245 seconds.
lower bounds for all target labels: [-0.3435361385345459]
Starting MIP solver for these labels: [0]
start creating model mps for candidates: ['lay/24_0']
Total VNNLIB file length: 1, max property batch size: 1, total number of batches: 1
lA shape: [torch.Size([1, 1, 8, 16, 16]), torch.Size([1, 1, 8, 16, 16]), torch.Size([1, 1, 8, 16, 16]), torch.Size([1, 1, 8, 8, 8]), torch.Size([1, 1, 100])]

Properties batch 0, size 1
Remaining timeout: 3584.042689561844
##### Instance 0 first 10 spec matrices: 
tensor([[[ 0.,  0., -1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.]]])
thresholds: tensor([0.], device='cuda:0') ######
Model prediction is: tensor([-2.35039830, -4.53964615,  1.72910023,  2.51990438,  2.08594632,
         2.71009231,  2.03775144,  1.96993172, -3.78473258, -2.37795210],
       device='cuda:0')
build_with_refined_bounds batch [1/1]
setting alpha for layer /input.4 start_node /24 with alignment adjustment
setting alpha for layer /input.12 start_node /24 with alignment adjustment
setting alpha for layer /input.20 start_node /24 with alignment adjustment
setting alpha for layer /20 start_node /24 with alignment adjustment
setting alpha for layer /23 start_node /24 with alignment adjustment
all alpha initialized
directly get lb and ub from refined bounds
c shape: torch.Size([1, 1, 10])
lA shapes: [torch.Size([1, 1, 8, 16, 16]), torch.Size([1, 1, 8, 16, 16]), torch.Size([1, 1, 8, 16, 16]), torch.Size([1, 1, 8, 8, 8]), torch.Size([1, 1, 100])]
(alpha-)CROWN with fixed intermediate bounds: tensor([[-0.34353614]], device='cuda:0') tensor([[inf]], device='cuda:0')
Intermediate layers: /input,/input.8,/input.16,/input.24,/input.28,/24
Keeping alphas for these layers: ['/24']
Keeping alphas for these layers: ['/24']
Node /input.4 input 0: size torch.Size([8, 16, 16]) unstable 215
Node /input.12 input 0: size torch.Size([8, 16, 16]) unstable 419
Node /input.20 input 0: size torch.Size([8, 16, 16]) unstable 300
Node /20 input 0: size torch.Size([8, 8, 8]) unstable 78
Node /23 input 0: size torch.Size([100]) unstable 42
-----------------
# of unstable neurons: 1054
-----------------

======================Cut verification begins======================
Fetch cut process: mps for current label is not ready yet
Cut time: 0.00092315673828125
======================Cut verification ends======================
BaB round 1
Fetch cut process: mps for current label is not ready yet
batch: 1
splitting decisions: 
split level 0: [/input.28, 11] 
split level 1: [/input.28, 30] 
split level 2: [/input.28, 83] 
split level 3: [/input.28, 22] 
split level 4: [/input.28, 23] 
split level 5: [/input.28, 95] 
pruning_in_iteration open status: True
ratio of positive domain = 48 / 64 = 0.75
pruning-in-iteration extra time: 0.014769554138183594
Time: prepare 0.0066    bound 0.5956    transfer 0.0017    finalize 0.0080    func 0.6120    
Accumulated time: func 0.6120    prepare 0.0079    bound 0.5956    transfer 0.0017    finalize 0.0080    
Current worst splitting domains lb-rhs (depth):
-0.09093 (6), -0.09074 (6), -0.08941 (6), -0.08722 (6), -0.07577 (6), -0.07421 (6), -0.07338 (6), -0.06704 (6), -0.06279 (6), -0.06018 (6), -0.06005 (6), -0.05233 (6), -0.05081 (6), -0.04921 (6), -0.03125 (6), -0.02772 (6), 
Length of domains: 16
Time: pickout 0.0018    decision 0.1665    set_bounds 0.0110    solve 0.6121    add 0.0025    
Accumulated time: pickout 0.0018    decision 0.1665    set_bounds 0.0110    solve 0.6121    add 0.0025    
Current (lb-rhs): -0.0909280776977539
16 domains visited
Cumulative time: 0.8589165210723877

BaB round 2
Fetch cut process: mps for current label is not ready yet
batch: 16
splitting decisions: 
split level 0: [/input.28, 35] [/input.28, 45] [/input.28, 45] [/input.28, 45] [/input.28, 35] [/input.28, 45] [/input.28, 45] [/input.28, 45] [/input.28, 35] [/input.28, 45] 
split level 1: [/input.28, 45] [/input.28, 35] [/input.28, 35] [/input.28, 35] [/input.28, 45] [/input.28, 35] [/input.28, 35] [/input.28, 35] [/input.28, 45] [/input.28, 35] 
pruning_in_iteration open status: True
ratio of positive domain = 56 / 64 = 0.875
pruning-in-iteration extra time: 0.014959573745727539
Time: prepare 0.0089    bound 0.4098    transfer 0.0010    finalize 0.0065    func 0.4262    
Accumulated time: func 1.0382    prepare 0.0180    bound 1.0054    transfer 0.0027    finalize 0.0145    
Current worst splitting domains lb-rhs (depth):
-0.04360 (8), -0.04203 (8), -0.03934 (8), -0.03720 (8), -0.02294 (8), -0.01599 (8), -0.01159 (8), -0.00972 (8), 
Length of domains: 8
Time: pickout 0.0015    decision 0.1005    set_bounds 0.0068    solve 0.4264    add 0.0020    
Accumulated time: pickout 0.0033    decision 0.2670    set_bounds 0.0178    solve 1.0385    add 0.0044    
Current (lb-rhs): -0.04360055923461914
24 domains visited
Cumulative time: 1.3970446586608887

BaB round 3
Fetch cut process: mps for current label is not ready yet
batch: 8
splitting decisions: 
split level 0: [/input.28, 32] [/input.28, 32] [/input.28, 32] [/input.28, 32] [/input.28, 39] [/input.28, 32] [/input.28, 32] [/input.28, 32] 
split level 1: [/input.28, 39] [/input.28, 39] [/input.28, 39] [/input.28, 68] [/input.28, 32] [/input.28, 39] [/input.28, 68] [/input.28, 68] 
split level 2: [/input.28, 20] [/input.28, 20] [/input.28, 68] [/input.28, 20] [/input.28, 68] [/input.28, 68] [/input.28, 39] [/input.28, 39] 

all verified at 0th iter
pruning_in_iteration open status: False
ratio of positive domain = 64 / 64 = 1.0
pruning-in-iteration extra time: 0.00012373924255371094
Time: prepare 0.0088    bound 0.0124    transfer 0.0006    finalize 0.0063    func 0.0282    
Accumulated time: func 1.0664    prepare 0.0280    bound 1.0178    transfer 0.0033    finalize 0.0208    
Length of domains: 0
Time: pickout 0.0015    decision 0.0983    set_bounds 0.0081    solve 0.0282    add 0.0001    
Accumulated time: pickout 0.0048    decision 0.3653    set_bounds 0.0259    solve 1.0667    add 0.0046    
No domains left, verification finished!
Current (lb-rhs): 1.0000000116860974e-07
24 domains visited
Cumulative time: 1.5340156555175781

the mip building process is not terminated yet, kill it
Result: safe in 17.9808 seconds
############# Summary #############
Final verified acc: 100.0% (total 1 examples)
Problem instances count: 1 , total verified (safe/unsat): 1 , total falsified (unsafe/sat): 0 , timeout: 0
mean time for ALL instances (total 1):17.98064561773816, max time: 17.980825424194336
mean time for verified SAFE instances(total 1): 17.980825424194336, max time: 17.980825424194336
safe (total 1), index: [0]
Result dict saved to /home/zhouxingshi/Verifier_Development/tests/gpu_tests/gcp_crown/oval_deep_cplex/master_outputs/2.pkl.
