Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_cnn_b_adv.model
  name: cnn_4layer_b
data:
  start: 70
  end: 71
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR_SDP
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.00784313725
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 256
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 90
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:10:07 2022 on diablo.cs.ucla.edu
Sequential(
  (0): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)
  (1): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2))
  (2): ReLU()
  (3): Conv2d(32, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (4): ReLU()
  (5): Flatten()
  (6): Linear(in_features=8192, out_features=250, bias=True)
  (7): ReLU()
  (8): Linear(in_features=250, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([200, 3, 32, 32]) torch.Size([200]) torch.Size([200])
X range: tensor(2.1256) tensor(-1.9889) tensor(-0.0131)
############################
epsilon after preprocessing: tensor([[[[0.0317]],

         [[0.0322]],

         [[0.0300]]]]), data_max = tensor([[[[2.0587]],

         [[2.1256]],

         [[2.1154]]]]), data_min = tensor([[[[-1.9889]],

         [[-1.9807]],

         [[-1.7076]]]])
Task length: 1
saving results to Verified_ret_[cnn_4layer_b]_start=70_end=71_iter=20_b=256_timeout=90_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 70 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 6, correct label 6, image norm 3166.35595703125, logits tensor([-83.4550, -86.1856, -79.0081, -81.0062, -77.6787, -81.7953, -75.8846,
        -84.0971, -85.2723, -86.8423], device='cuda:0',
       grad_fn=<SelectBackward>)
##### PGD attack: True label: 6, Tested against: ['all'] ######
pgd prediction: tensor([-80.7524, -83.5661, -76.2261, -78.0808, -74.5814, -78.7356, -73.7347,
        -80.8625, -82.6046, -84.1199], device='cuda:0',
       grad_fn=<SqueezeBackward1>)
attack margin tensor([ 7.0177,  9.8314,  2.4914,  4.3461,  0.8467,  5.0009,     inf,  7.1278,
         8.8699, 10.3852], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[-83.4550, -86.1856, -79.0081, -81.0062, -77.6787, -81.7953, -75.8846,
         -84.0971, -85.2723, -86.8423]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 2.6652,  4.5232, -0.7494,  2.1016, -1.4833,  2.0882,  3.2970,  3.9114,
          5.4983]], device='cuda:0') None
best_l after optimization: -24.708677291870117 with beta sum per layer: []
alpha/beta optimization time: 8.376883268356323
initial alpha-CROWN bounds: tensor([[ 3.0270,  4.9417, -0.4893,  2.3059, -1.2307,  2.3243,  3.6332,  4.2790,
          5.9176]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-1.2307, device='cuda:0', grad_fn=<MinBackward1>)
Sorted order for labels to verify: [4, 2, 3, 5, 0, 7, 8, 1, 9, 6]
##### [0:70] Tested against 4 ######
Model prediction is: tensor([[-83.4550, -86.1856, -79.0081, -81.0062, -77.6787, -81.7953, -75.8846,
         -84.0971, -85.2723, -86.8423]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /34 start_node /35
setting alpha for layer /34 start_node /45
not setting layer /34 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /36 start_node /45
not setting layer /36 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /46 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /33 torch.Size([1, 32, 16, 16])
1 /35 torch.Size([1, 128, 8, 8])
2 /45 torch.Size([1, 250])
best_l after optimization: 1.2304496765136719 with beta sum per layer: []
alpha/beta optimization time: 2.0190162658691406
alpha-CROWN with fixed intermediate bounds: tensor([[-1.2304]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-1.2304496765136719
layer 0 size torch.Size([8192]) unstable 1612
layer 1 size torch.Size([8192]) unstable 678
layer 2 size torch.Size([250]) unstable 66
-----------------
# of unstable neurons: 2356
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 124] 
split level 1: [2, 114] 
split level 2: [2, 168] 
split level 3: [2, 129] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 1.8692524433135986 with beta sum per layer: [0.0, 0.0, 2.458946704864502]
alpha/beta optimization time: 0.2769758701324463
This batch time : update_bounds func: 0.2839	 prepare: 0.0029	 bound: 0.2775	 transfer: 0.0022	 finalize: 0.0012
Accumulated time: update_bounds func: 0.2839	 prepare: 0.0029	 bound: 0.2775	 transfer: 0.0022	 finalize: 0.0012
batch bounding time:  0.28408360481262207
Current worst splitting domains [lb, ub] (depth):
[-0.79787,   inf] (5), [-0.67740,   inf] (5), [-0.66885,   inf] (5), [-0.57946,   inf] (5), [-0.52639,   inf] (5), [-0.48687,   inf] (5), [-0.46877,   inf] (5), [-0.36266,   inf] (5), 
length of domains: 8
Total time: 0.3187	 pickout: 0.0010	 decision: 0.0312	 get_bound: 0.2861	 add_domain: 0.0005
Current lb:-0.7978749871253967
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.2451157569885254

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([8, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 155] [2, 155] [2, 155] [2, 155] [2, 155] [2, 155] [2, 155] [2, 155] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 6.664437770843506 with beta sum per layer: [0.0, 0.0, 1.4813975095748901]
alpha/beta optimization time: 0.26265931129455566
This batch time : update_bounds func: 0.2684	 prepare: 0.0027	 bound: 0.2629	 transfer: 0.0015	 finalize: 0.0012
Accumulated time: update_bounds func: 0.5523	 prepare: 0.0055	 bound: 0.5405	 transfer: 0.0015	 finalize: 0.0024
batch bounding time:  0.2685878276824951
Current worst splitting domains [lb, ub] (depth):
[-0.71592,   inf] (7), [-0.59382,   inf] (7), [-0.58375,   inf] (7), [-0.57982,   inf] (7), [-0.49565,   inf] (7), [-0.45619,   inf] (7), [-0.43968,   inf] (7), [-0.43481,   inf] (7), [-0.39973,   inf] (7), [-0.38496,   inf] (7), [-0.37884,   inf] (7), [-0.29209,   inf] (7), [-0.27579,   inf] (7), [-0.27477,   inf] (7), [-0.23554,   inf] (7), [-0.12307,   inf] (7), 
length of domains: 16
Total time: 0.2960	 pickout: 0.0024	 decision: 0.0243	 get_bound: 0.2686	 add_domain: 0.0007
Current lb:-0.7159174680709839
32 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.541267156600952

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([16, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([16, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 214] [2, 214] [2, 214] [2, 214] [2, 214] [2, 214] [2, 214] [2, 214] [2, 214] [2, 214] 
regular batch size: 2*16, diving batch size 1*0
best_l after optimization: 8.53791618347168 with beta sum per layer: [0.0, 0.0, 4.2171525955200195]
alpha/beta optimization time: 0.2698237895965576
This batch time : update_bounds func: 0.2786	 prepare: 0.0040	 bound: 0.2701	 transfer: 0.0023	 finalize: 0.0021
Accumulated time: update_bounds func: 0.8309	 prepare: 0.0095	 bound: 0.8105	 transfer: 0.0023	 finalize: 0.0046
batch bounding time:  0.27876901626586914
Current worst splitting domains [lb, ub] (depth):
[-0.64008,   inf] (9), [-0.51361,   inf] (9), [-0.51034,   inf] (9), [-0.49850,   inf] (9), [-0.49595,   inf] (9), [-0.41959,   inf] (9), [-0.39018,   inf] (9), [-0.38343,   inf] (9), [-0.37825,   inf] (9), [-0.35858,   inf] (9), [-0.34954,   inf] (9), [-0.32787,   inf] (9), [-0.32469,   inf] (9), [-0.30538,   inf] (9), [-0.30172,   inf] (9), [-0.27461,   inf] (9), [-0.23774,   inf] (9), [-0.21455,   inf] (9), [-0.21277,   inf] (9), [-0.19588,   inf] (9), 
length of domains: 31
Total time: 0.3110	 pickout: 0.0036	 decision: 0.0272	 get_bound: 0.2788	 add_domain: 0.0014
Current lb:-0.6400808691978455
64 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.852543830871582

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([31, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([31, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 230] [2, 230] [2, 230] [2, 230] [2, 230] [2, 230] [2, 230] [2, 230] [2, 230] [2, 230] 
regular batch size: 2*31, diving batch size 1*0
best_l after optimization: 7.114384651184082 with beta sum per layer: [0.0, 0.0, 11.133882522583008]
alpha/beta optimization time: 0.28723621368408203
This batch time : update_bounds func: 0.3016	 prepare: 0.0065	 bound: 0.2875	 transfer: 0.0038	 finalize: 0.0036
Accumulated time: update_bounds func: 1.1325	 prepare: 0.0160	 bound: 1.0981	 transfer: 0.0038	 finalize: 0.0082
batch bounding time:  0.30176782608032227
Current worst splitting domains [lb, ub] (depth):
[-0.57420,   inf] (11), [-0.44649,   inf] (11), [-0.44406,   inf] (11), [-0.43302,   inf] (11), [-0.42880,   inf] (11), [-0.37969,   inf] (11), [-0.34887,   inf] (11), [-0.32218,   inf] (11), [-0.31345,   inf] (11), [-0.31048,   inf] (11), [-0.28940,   inf] (11), [-0.28229,   inf] (11), [-0.25622,   inf] (11), [-0.25322,   inf] (11), [-0.24293,   inf] (11), [-0.24220,   inf] (11), [-0.23166,   inf] (11), [-0.23131,   inf] (11), [-0.20921,   inf] (11), [-0.20161,   inf] (11), 
length of domains: 41
Total time: 0.3434	 pickout: 0.0062	 decision: 0.0334	 get_bound: 0.3019	 add_domain: 0.0018
Current lb:-0.5742020606994629
126 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.196445941925049

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([41, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([41, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 88] [2, 88] [2, 88] [2, 88] [2, 88] [2, 88] [2, 88] [2, 88] [2, 88] [2, 88] 
regular batch size: 2*41, diving batch size 1*0
best_l after optimization: 11.692965507507324 with beta sum per layer: [0.0, 0.0, 10.696757316589355]
alpha/beta optimization time: 0.30082130432128906
This batch time : update_bounds func: 0.3240	 prepare: 0.0079	 bound: 0.3011	 transfer: 0.0100	 finalize: 0.0047
Accumulated time: update_bounds func: 1.4565	 prepare: 0.0240	 bound: 1.3992	 transfer: 0.0100	 finalize: 0.0129
batch bounding time:  0.3242020606994629
Current worst splitting domains [lb, ub] (depth):
[-0.51954,   inf] (13), [-0.50216,   inf] (13), [-0.39396,   inf] (13), [-0.38552,   inf] (13), [-0.37811,   inf] (13), [-0.37741,   inf] (13), [-0.37188,   inf] (13), [-0.36296,   inf] (13), [-0.36181,   inf] (13), [-0.35310,   inf] (13), [-0.31627,   inf] (13), [-0.30627,   inf] (13), [-0.29517,   inf] (13), [-0.27458,   inf] (13), [-0.26547,   inf] (13), [-0.25828,   inf] (13), [-0.25002,   inf] (13), [-0.24980,   inf] (13), [-0.24614,   inf] (13), [-0.23318,   inf] (13), 
length of domains: 68
Total time: 0.3718	 pickout: 0.0085	 decision: 0.0358	 get_bound: 0.3243	 add_domain: 0.0031
Current lb:-0.5195352435112
208 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.5688512325286865

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([68, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([68, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 2] [2, 2] [2, 2] [2, 2] [2, 2] [2, 2] [2, 2] [2, 2] [2, 2] [2, 2] 
regular batch size: 2*68, diving batch size 1*0
best_l after optimization: 14.167312622070312 with beta sum per layer: [0.0, 0.0, 17.634153366088867]
alpha/beta optimization time: 0.3442189693450928
This batch time : update_bounds func: 0.3800	 prepare: 0.0124	 bound: 0.3445	 transfer: 0.0150	 finalize: 0.0077
Accumulated time: update_bounds func: 1.8365	 prepare: 0.0363	 bound: 1.7436	 transfer: 0.0150	 finalize: 0.0207
batch bounding time:  0.38020873069763184
Current worst splitting domains [lb, ub] (depth):
[-0.46845,   inf] (15), [-0.45201,   inf] (15), [-0.43866,   inf] (15), [-0.41487,   inf] (15), [-0.34193,   inf] (15), [-0.33544,   inf] (15), [-0.32809,   inf] (15), [-0.32739,   inf] (15), [-0.32206,   inf] (15), [-0.31416,   inf] (15), [-0.31415,   inf] (15), [-0.31106,   inf] (15), [-0.30445,   inf] (15), [-0.29741,   inf] (15), [-0.28620,   inf] (15), [-0.28598,   inf] (15), [-0.27501,   inf] (15), [-0.26982,   inf] (15), [-0.26848,   inf] (15), [-0.26416,   inf] (15), 
length of domains: 97
Total time: 0.4571	 pickout: 0.0136	 decision: 0.0583	 get_bound: 0.3804	 add_domain: 0.0047
Current lb:-0.4684503972530365
344 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.027018308639526

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([97, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([97, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 184] [2, 184] [2, 184] [2, 184] [2, 184] [2, 184] [2, 184] [2, 184] [2, 184] [2, 184] 
regular batch size: 2*97, diving batch size 1*0
best_l after optimization: 14.12637710571289 with beta sum per layer: [0.0, 0.0, 26.083417892456055]
alpha/beta optimization time: 0.4437696933746338
This batch time : update_bounds func: 0.4890	 prepare: 0.0171	 bound: 0.4441	 transfer: 0.0163	 finalize: 0.0111
Accumulated time: update_bounds func: 2.3255	 prepare: 0.0534	 bound: 2.1877	 transfer: 0.0163	 finalize: 0.0318
batch bounding time:  0.48925209045410156
Current worst splitting domains [lb, ub] (depth):
[-0.42495,   inf] (17), [-0.40782,   inf] (17), [-0.39550,   inf] (17), [-0.37130,   inf] (17), [-0.36381,   inf] (17), [-0.34796,   inf] (17), [-0.32214,   inf] (17), [-0.29939,   inf] (17), [-0.29906,   inf] (17), [-0.29170,   inf] (17), [-0.28451,   inf] (17), [-0.28448,   inf] (17), [-0.27984,   inf] (17), [-0.27120,   inf] (17), [-0.27076,   inf] (17), [-0.26881,   inf] (17), [-0.26267,   inf] (17), [-0.25352,   inf] (17), [-0.24336,   inf] (17), [-0.24216,   inf] (17), 
length of domains: 122
Total time: 0.6042	 pickout: 0.0191	 decision: 0.0892	 get_bound: 0.4895	 add_domain: 0.0064
Current lb:-0.4249533414840698
538 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.633088827133179

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([122, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([122, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 17] [2, 17] [2, 17] [2, 17] [2, 17] [2, 17] [2, 17] [2, 17] [2, 17] [2, 17] 
regular batch size: 2*122, diving batch size 1*0
best_l after optimization: 6.949260234832764 with beta sum per layer: [0.0, 0.0, 32.527320861816406]
alpha/beta optimization time: 0.49826717376708984
This batch time : update_bounds func: 0.5580	 prepare: 0.0218	 bound: 0.4986	 transfer: 0.0221	 finalize: 0.0148
Accumulated time: update_bounds func: 2.8834	 prepare: 0.0753	 bound: 2.6863	 transfer: 0.0221	 finalize: 0.0466
batch bounding time:  0.558351993560791
Current worst splitting domains [lb, ub] (depth):
[-0.38552,   inf] (19), [-0.36782,   inf] (19), [-0.35554,   inf] (19), [-0.33043,   inf] (19), [-0.32205,   inf] (19), [-0.30719,   inf] (19), [-0.27817,   inf] (19), [-0.26094,   inf] (19), [-0.25667,   inf] (19), [-0.25030,   inf] (19), [-0.24345,   inf] (19), [-0.24294,   inf] (19), [-0.24137,   inf] (19), [-0.23233,   inf] (19), [-0.23076,   inf] (19), [-0.23033,   inf] (19), [-0.22482,   inf] (19), [-0.21143,   inf] (19), [-0.20154,   inf] (19), [-0.20152,   inf] (19), 
length of domains: 119
Total time: 0.6729	 pickout: 0.0258	 decision: 0.0818	 get_bound: 0.5587	 add_domain: 0.0066
Current lb:-0.3855223059654236
782 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.30908203125

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([119, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([119, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 140] [2, 140] [2, 140] [2, 140] [2, 140] [2, 140] [2, 140] [2, 140] [2, 140] [2, 140] 
regular batch size: 2*119, diving batch size 1*0
best_l after optimization: 1.875373363494873 with beta sum per layer: [0.0, 0.0, 29.851909637451172]
alpha/beta optimization time: 0.48783421516418457
This batch time : update_bounds func: 0.5366	 prepare: 0.0208	 bound: 0.4881	 transfer: 0.0133	 finalize: 0.0138
Accumulated time: update_bounds func: 3.4201	 prepare: 0.0961	 bound: 3.1744	 transfer: 0.0133	 finalize: 0.0604
batch bounding time:  0.5369889736175537
Current worst splitting domains [lb, ub] (depth):
[-0.35077,   inf] (21), [-0.33284,   inf] (21), [-0.31956,   inf] (21), [-0.29393,   inf] (21), [-0.28405,   inf] (21), [-0.27093,   inf] (21), [-0.23896,   inf] (21), [-0.22826,   inf] (21), [-0.21985,   inf] (21), [-0.21360,   inf] (21), [-0.20748,   inf] (21), [-0.20704,   inf] (21), [-0.20622,   inf] (21), [-0.19845,   inf] (21), [-0.19780,   inf] (21), [-0.19233,   inf] (21), [-0.18890,   inf] (21), [-0.17441,   inf] (21), [-0.16485,   inf] (21), [-0.16362,   inf] (21), 
length of domains: 96
Total time: 0.6465	 pickout: 0.0234	 decision: 0.0803	 get_bound: 0.5374	 add_domain: 0.0055
Current lb:-0.3507739007472992
1020 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.957777500152588

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([96, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([96, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 191] [2, 191] [2, 191] [2, 191] [2, 191] [2, 191] [2, 191] [2, 191] [2, 191] [2, 191] 
regular batch size: 2*96, diving batch size 1*0
best_l after optimization: 4.014151573181152 with beta sum per layer: [0.0, 0.0, 22.237966537475586]
alpha/beta optimization time: 0.39735889434814453
This batch time : update_bounds func: 0.4319	 prepare: 0.0170	 bound: 0.3977	 transfer: 0.0058	 finalize: 0.0110
Accumulated time: update_bounds func: 3.8520	 prepare: 0.1131	 bound: 3.5721	 transfer: 0.0058	 finalize: 0.0713
batch bounding time:  0.43224000930786133
Current worst splitting domains [lb, ub] (depth):
[-0.31886,   inf] (23), [-0.30055,   inf] (23), [-0.28737,   inf] (23), [-0.26149,   inf] (23), [-0.25223,   inf] (23), [-0.23906,   inf] (23), [-0.20730,   inf] (23), [-0.19621,   inf] (23), [-0.18885,   inf] (23), [-0.18177,   inf] (23), [-0.17919,   inf] (23), [-0.17435,   inf] (23), [-0.17418,   inf] (23), [-0.17392,   inf] (23), [-0.16613,   inf] (23), [-0.16549,   inf] (23), [-0.16313,   inf] (23), [-0.15875,   inf] (23), [-0.15563,   inf] (23), [-0.15257,   inf] (23), 
length of domains: 94
Total time: 0.5270	 pickout: 0.0192	 decision: 0.0696	 get_bound: 0.4325	 add_domain: 0.0056
Current lb:-0.3188595771789551
1212 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.486910581588745

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([94, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([94, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 248] [2, 248] [2, 248] [2, 248] [2, 248] [2, 248] [2, 248] [2, 248] [2, 248] [2, 248] 
regular batch size: 2*94, diving batch size 1*0
best_l after optimization: 4.780721664428711 with beta sum per layer: [0.0, 0.0, 19.060245513916016]
alpha/beta optimization time: 0.3950204849243164
This batch time : update_bounds func: 0.4852	 prepare: 0.0183	 bound: 0.3953	 transfer: 0.0053	 finalize: 0.0659
Accumulated time: update_bounds func: 4.3372	 prepare: 0.1313	 bound: 3.9674	 transfer: 0.0053	 finalize: 0.1372
batch bounding time:  0.48558783531188965
Current worst splitting domains [lb, ub] (depth):
[-0.29142,   inf] (25), [-0.27271,   inf] (25), [-0.25923,   inf] (25), [-0.23366,   inf] (25), [-0.22785,   inf] (25), [-0.22388,   inf] (25), [-0.21125,   inf] (25), [-0.21005,   inf] (25), [-0.19520,   inf] (25), [-0.17829,   inf] (25), [-0.17093,   inf] (25), [-0.16733,   inf] (25), [-0.16105,   inf] (25), [-0.15264,   inf] (25), [-0.15232,   inf] (25), [-0.15024,   inf] (25), [-0.14535,   inf] (25), [-0.14523,   inf] (25), [-0.14416,   inf] (25), [-0.14109,   inf] (25), 
length of domains: 100
Total time: 0.5763	 pickout: 0.0183	 decision: 0.0660	 get_bound: 0.4859	 add_domain: 0.0061
Current lb:-0.2914242148399353
1400 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.065032720565796

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([100, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([100, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 67] [2, 67] [2, 67] [2, 67] [2, 67] [2, 67] [2, 67] [2, 67] [2, 67] [2, 67] 
regular batch size: 2*100, diving batch size 1*0
best_l after optimization: -0.19480347633361816 with beta sum per layer: [0.0, 0.0, 20.615005493164062]
alpha/beta optimization time: 0.44641804695129395
This batch time : update_bounds func: 0.4822	 prepare: 0.0178	 bound: 0.4467	 transfer: 0.0056	 finalize: 0.0112
Accumulated time: update_bounds func: 4.8194	 prepare: 0.1492	 bound: 4.4141	 transfer: 0.0056	 finalize: 0.1484
batch bounding time:  0.482452392578125
Current worst splitting domains [lb, ub] (depth):
[-0.26458,   inf] (27), [-0.24501,   inf] (27), [-0.23281,   inf] (27), [-0.20681,   inf] (27), [-0.19960,   inf] (27), [-0.19492,   inf] (27), [-0.18215,   inf] (27), [-0.18116,   inf] (27), [-0.16647,   inf] (27), [-0.15108,   inf] (27), [-0.14330,   inf] (27), [-0.14021,   inf] (27), [-0.13418,   inf] (27), [-0.12492,   inf] (27), [-0.12450,   inf] (27), [-0.12355,   inf] (27), [-0.11749,   inf] (27), [-0.11738,   inf] (27), [-0.11640,   inf] (27), [-0.11002,   inf] (27), 
length of domains: 77
Total time: 0.5785	 pickout: 0.0202	 decision: 0.0705	 get_bound: 0.4828	 add_domain: 0.0050
Current lb:-0.2645827531814575
1600 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.646062135696411

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([77, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([77, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 164] [2, 164] [2, 164] [2, 164] [2, 164] [2, 164] [2, 164] [2, 164] [2, 164] [2, 164] 
regular batch size: 2*77, diving batch size 1*0
best_l after optimization: -0.17353308200836182 with beta sum per layer: [0.0, 0.0, 14.171161651611328]
alpha/beta optimization time: 0.36392998695373535
This batch time : update_bounds func: 0.3931	 prepare: 0.0152	 bound: 0.3642	 transfer: 0.0045	 finalize: 0.0088
Accumulated time: update_bounds func: 5.2124	 prepare: 0.1643	 bound: 4.7783	 transfer: 0.0045	 finalize: 0.1572
batch bounding time:  0.39331674575805664
Current worst splitting domains [lb, ub] (depth):
[-0.23823,   inf] (29), [-0.21834,   inf] (29), [-0.20648,   inf] (29), [-0.17989,   inf] (29), [-0.17239,   inf] (29), [-0.16763,   inf] (29), [-0.15364,   inf] (29), [-0.15326,   inf] (29), [-0.13939,   inf] (29), [-0.12457,   inf] (29), [-0.11635,   inf] (29), [-0.11509,   inf] (29), [-0.10740,   inf] (29), [-0.09841,   inf] (29), [-0.09688,   inf] (29), [-0.09674,   inf] (29), [-0.09154,   inf] (29), [-0.09084,   inf] (29), [-0.08901,   inf] (29), [-0.08474,   inf] (29), 
length of domains: 59
Total time: 0.4708	 pickout: 0.0153	 decision: 0.0579	 get_bound: 0.3936	 add_domain: 0.0040
Current lb:-0.23823104798793793
1754 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.11824893951416

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([59, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([59, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 10] [2, 10] [2, 10] [2, 10] [2, 10] [2, 10] [2, 10] [2, 10] [2, 10] [2, 10] 
regular batch size: 2*59, diving batch size 1*0
best_l after optimization: -6.105954170227051 with beta sum per layer: [0.0, 0.0, 9.35344409942627]
alpha/beta optimization time: 0.3268110752105713
This batch time : update_bounds func: 0.3488	 prepare: 0.0109	 bound: 0.3271	 transfer: 0.0037	 finalize: 0.0068
Accumulated time: update_bounds func: 5.5613	 prepare: 0.1752	 bound: 5.1054	 transfer: 0.0037	 finalize: 0.1640
batch bounding time:  0.34908437728881836
Current worst splitting domains [lb, ub] (depth):
[-0.21735,   inf] (31), [-0.19728,   inf] (31), [-0.18495,   inf] (31), [-0.15902,   inf] (31), [-0.15188,   inf] (31), [-0.14662,   inf] (31), [-0.13346,   inf] (31), [-0.13188,   inf] (31), [-0.11853,   inf] (31), [-0.10392,   inf] (31), [-0.09549,   inf] (31), [-0.09474,   inf] (31), [-0.08651,   inf] (31), [-0.07809,   inf] (31), [-0.07746,   inf] (31), [-0.07262,   inf] (31), [-0.07091,   inf] (31), [-0.07009,   inf] (31), [-0.06743,   inf] (31), [-0.06474,   inf] (31), 
length of domains: 48
Total time: 0.4141	 pickout: 0.0120	 decision: 0.0495	 get_bound: 0.3493	 add_domain: 0.0033
Current lb:-0.2173479199409485
1872 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.533615112304688

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([48, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([48, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 105] [2, 105] [2, 105] [2, 105] [2, 105] [2, 105] [2, 105] [2, 167] [2, 105] [2, 105] 
regular batch size: 2*48, diving batch size 1*0
best_l after optimization: -6.630690097808838 with beta sum per layer: [0.0, 0.0, 6.040523529052734]
alpha/beta optimization time: 0.30936121940612793
This batch time : update_bounds func: 0.3278	 prepare: 0.0091	 bound: 0.3096	 transfer: 0.0033	 finalize: 0.0056
Accumulated time: update_bounds func: 5.8891	 prepare: 0.1843	 bound: 5.4151	 transfer: 0.0033	 finalize: 0.1696
batch bounding time:  0.32799196243286133
Current worst splitting domains [lb, ub] (depth):
[-0.20104,   inf] (33), [-0.18073,   inf] (33), [-0.16859,   inf] (33), [-0.14239,   inf] (33), [-0.13578,   inf] (33), [-0.13047,   inf] (33), [-0.11692,   inf] (33), [-0.11518,   inf] (33), [-0.10266,   inf] (33), [-0.08777,   inf] (33), [-0.07870,   inf] (33), [-0.07834,   inf] (33), [-0.06851,   inf] (33), [-0.06178,   inf] (33), [-0.06058,   inf] (33), [-0.05502,   inf] (33), [-0.05440,   inf] (33), [-0.05322,   inf] (33), [-0.05138,   inf] (33), [-0.04812,   inf] (33), 
length of domains: 37
Total time: 0.3783	 pickout: 0.0096	 decision: 0.0379	 get_bound: 0.3281	 add_domain: 0.0027
Current lb:-0.2010376751422882
1968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.914184093475342

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([37, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([37, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 167] [2, 167] [2, 167] [2, 167] [2, 167] [2, 167] [2, 167] [2, 105] [2, 167] [2, 167] 
regular batch size: 2*37, diving batch size 1*0
best_l after optimization: -3.0539236068725586 with beta sum per layer: [0.0, 0.0, 5.5628252029418945]
alpha/beta optimization time: 0.3063533306121826
This batch time : update_bounds func: 0.3214	 prepare: 0.0074	 bound: 0.3066	 transfer: 0.0028	 finalize: 0.0044
Accumulated time: update_bounds func: 6.2105	 prepare: 0.1917	 bound: 5.7217	 transfer: 0.0028	 finalize: 0.1740
batch bounding time:  0.32161712646484375
Current worst splitting domains [lb, ub] (depth):
[-0.18527,   inf] (35), [-0.16454,   inf] (35), [-0.15323,   inf] (35), [-0.12665,   inf] (35), [-0.12013,   inf] (35), [-0.11400,   inf] (35), [-0.10056,   inf] (35), [-0.09896,   inf] (35), [-0.08706,   inf] (35), [-0.07058,   inf] (35), [-0.06287,   inf] (35), [-0.06244,   inf] (35), [-0.05197,   inf] (35), [-0.04644,   inf] (35), [-0.04488,   inf] (35), [-0.03969,   inf] (35), [-0.03864,   inf] (35), [-0.03719,   inf] (35), [-0.03539,   inf] (35), [-0.03218,   inf] (35), 
length of domains: 28
Total time: 0.3654	 pickout: 0.0076	 decision: 0.0340	 get_bound: 0.3217	 add_domain: 0.0021
Current lb:-0.18526887893676758
2042 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.283215045928955

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([28, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([28, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 65] [1, 7580] [2, 65] [2, 65] [2, 203] [2, 203] [1, 7580] [2, 203] [2, 65] [2, 203] 
regular batch size: 2*28, diving batch size 1*0
best_l after optimization: -0.8009165525436401 with beta sum per layer: [0.0, 0.719907283782959, 3.582730293273926]
alpha/beta optimization time: 0.29938602447509766
This batch time : update_bounds func: 0.3173	 prepare: 0.0063	 bound: 0.2997	 transfer: 0.0073	 finalize: 0.0038
Accumulated time: update_bounds func: 6.5278	 prepare: 0.1980	 bound: 6.0214	 transfer: 0.0073	 finalize: 0.1778
batch bounding time:  0.3174865245819092
Current worst splitting domains [lb, ub] (depth):
[-0.17267,   inf] (37), [-0.14901,   inf] (37), [-0.14075,   inf] (37), [-0.14063,   inf] (37), [-0.11377,   inf] (37), [-0.10705,   inf] (37), [-0.10154,   inf] (37), [-0.08604,   inf] (37), [-0.08376,   inf] (37), [-0.07642,   inf] (37), [-0.07457,   inf] (37), [-0.05812,   inf] (37), [-0.05044,   inf] (37), [-0.04668,   inf] (37), [-0.03965,   inf] (37), [-0.03868,   inf] (37), [-0.03362,   inf] (37), [-0.03229,   inf] (37), [-0.02469,   inf] (37), [-0.02448,   inf] (37), 
length of domains: 32
Total time: 0.3571	 pickout: 0.0059	 decision: 0.0311	 get_bound: 0.3176	 add_domain: 0.0025
Current lb:-0.17267465591430664
2098 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.640849113464355

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([32, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([32, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7580] [2, 65] [2, 94] [2, 65] [1, 7580] [1, 7580] [2, 94] [1, 7580] [2, 65] [2, 65] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: 0.8981252908706665 with beta sum per layer: [0.0, 2.3611724376678467, 3.3154516220092773]
alpha/beta optimization time: 0.28770923614501953
This batch time : update_bounds func: 0.3029	 prepare: 0.0072	 bound: 0.2880	 transfer: 0.0037	 finalize: 0.0039
Accumulated time: update_bounds func: 6.8307	 prepare: 0.2051	 bound: 6.3094	 transfer: 0.0037	 finalize: 0.1818
batch bounding time:  0.30321645736694336
Current worst splitting domains [lb, ub] (depth):
[-0.15738,   inf] (39), [-0.14975,   inf] (39), [-0.13624,   inf] (39), [-0.12781,   inf] (39), [-0.12539,   inf] (39), [-0.09900,   inf] (39), [-0.09069,   inf] (39), [-0.09036,   inf] (39), [-0.08538,   inf] (39), [-0.08400,   inf] (39), [-0.07206,   inf] (39), [-0.07093,   inf] (39), [-0.06367,   inf] (39), [-0.05939,   inf] (39), [-0.05916,   inf] (39), [-0.04524,   inf] (39), [-0.04184,   inf] (39), [-0.03386,   inf] (39), [-0.03311,   inf] (39), [-0.02887,   inf] (39), 
length of domains: 35
Total time: 0.3461	 pickout: 0.0070	 decision: 0.0329	 get_bound: 0.3033	 add_domain: 0.0028
Current lb:-0.15738262236118317
2162 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.987610816955566

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([35, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([35, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 94] [2, 94] [2, 94] [2, 94] [1, 7580] [2, 94] [2, 65] [2, 94] [1, 7580] [2, 65] 
regular batch size: 2*35, diving batch size 1*0
best_l after optimization: 1.278303861618042 with beta sum per layer: [0.0, 1.7890772819519043, 3.34438419342041]
alpha/beta optimization time: 0.2918210029602051
This batch time : update_bounds func: 0.3077	 prepare: 0.0078	 bound: 0.2921	 transfer: 0.0032	 finalize: 0.0044
Accumulated time: update_bounds func: 7.1384	 prepare: 0.2129	 bound: 6.6015	 transfer: 0.0032	 finalize: 0.1862
batch bounding time:  0.3078634738922119
Current worst splitting domains [lb, ub] (depth):
[-0.14183,   inf] (41), [-0.13430,   inf] (41), [-0.12063,   inf] (41), [-0.11222,   inf] (41), [-0.11073,   inf] (41), [-0.10313,   inf] (41), [-0.08326,   inf] (41), [-0.07734,   inf] (41), [-0.07492,   inf] (41), [-0.07156,   inf] (41), [-0.07063,   inf] (41), [-0.06115,   inf] (41), [-0.05972,   inf] (41), [-0.05705,   inf] (41), [-0.05589,   inf] (41), [-0.04974,   inf] (41), [-0.04696,   inf] (41), [-0.04672,   inf] (41), [-0.04372,   inf] (41), [-0.04352,   inf] (41), 
length of domains: 39
Total time: 0.3540	 pickout: 0.0075	 decision: 0.0353	 get_bound: 0.3080	 add_domain: 0.0032
Current lb:-0.14183418452739716
2232 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.34228253364563

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([39, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([39, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 203] [1, 4781] [1, 4781] [1, 4781] [2, 203] [2, 203] [1, 4781] [2, 94] [1, 4781] [2, 226] 
regular batch size: 2*39, diving batch size 1*0
best_l after optimization: -0.26740139722824097 with beta sum per layer: [0.0, 4.080181121826172, 4.14204216003418]
alpha/beta optimization time: 0.29657673835754395
This batch time : update_bounds func: 0.3176	 prepare: 0.0087	 bound: 0.2969	 transfer: 0.0072	 finalize: 0.0046
Accumulated time: update_bounds func: 7.4560	 prepare: 0.2216	 bound: 6.8984	 transfer: 0.0072	 finalize: 0.1908
batch bounding time:  0.31777143478393555
Current worst splitting domains [lb, ub] (depth):
[-0.12931,   inf] (43), [-0.12150,   inf] (43), [-0.10841,   inf] (43), [-0.10726,   inf] (43), [-0.09891,   inf] (43), [-0.09836,   inf] (43), [-0.09561,   inf] (43), [-0.09061,   inf] (43), [-0.08687,   inf] (43), [-0.07054,   inf] (43), [-0.06173,   inf] (43), [-0.06164,   inf] (43), [-0.05966,   inf] (43), [-0.05637,   inf] (43), [-0.05506,   inf] (43), [-0.05462,   inf] (43), [-0.05060,   inf] (43), [-0.04617,   inf] (43), [-0.04504,   inf] (43), [-0.04317,   inf] (43), 
length of domains: 43
Total time: 0.3647	 pickout: 0.0083	 decision: 0.0347	 get_bound: 0.3179	 add_domain: 0.0038
Current lb:-0.12930510938167572
2310 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.707755088806152

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([43, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([43, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 226] [2, 226] [2, 226] [2, 203] [2, 203] [2, 226] [2, 203] [2, 226] [2, 203] [2, 203] 
regular batch size: 2*43, diving batch size 1*0
best_l after optimization: -1.9334429502487183 with beta sum per layer: [0.0, 5.683497905731201, 3.82114839553833]
alpha/beta optimization time: 0.30414795875549316
This batch time : update_bounds func: 0.3253	 prepare: 0.0095	 bound: 0.3044	 transfer: 0.0060	 finalize: 0.0051
Accumulated time: update_bounds func: 7.7813	 prepare: 0.2311	 bound: 7.2028	 transfer: 0.0060	 finalize: 0.1960
batch bounding time:  0.3254849910736084
Current worst splitting domains [lb, ub] (depth):
[-0.11427,   inf] (45), [-0.11182,   inf] (45), [-0.10657,   inf] (45), [-0.10308,   inf] (45), [-0.09456,   inf] (45), [-0.09281,   inf] (45), [-0.08974,   inf] (45), [-0.08620,   inf] (45), [-0.08334,   inf] (45), [-0.08249,   inf] (45), [-0.07907,   inf] (45), [-0.07597,   inf] (45), [-0.07366,   inf] (45), [-0.06996,   inf] (45), [-0.05818,   inf] (45), [-0.04946,   inf] (45), [-0.04698,   inf] (45), [-0.04676,   inf] (45), [-0.04424,   inf] (45), [-0.04209,   inf] (45), 
length of domains: 46
Total time: 0.3753	 pickout: 0.0091	 decision: 0.0364	 get_bound: 0.3256	 add_domain: 0.0041
Current lb:-0.11426527798175812
2396 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.083887338638306

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([46, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([46, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 4781] [1, 4781] [1, 7581] [1, 7581] [2, 226] [1, 7581] [1, 7581] [2, 226] [1, 4781] [2, 226] 
regular batch size: 2*46, diving batch size 1*0
best_l after optimization: 2.2316346168518066 with beta sum per layer: [0.0, 7.297933578491211, 2.868438243865967]
alpha/beta optimization time: 0.305286169052124
This batch time : update_bounds func: 0.3248	 prepare: 0.0100	 bound: 0.3056	 transfer: 0.0034	 finalize: 0.0056
Accumulated time: update_bounds func: 8.1060	 prepare: 0.2411	 bound: 7.5084	 transfer: 0.0034	 finalize: 0.2015
batch bounding time:  0.3249855041503906
Current worst splitting domains [lb, ub] (depth):
[-0.10159,   inf] (47), [-0.09929,   inf] (47), [-0.09363,   inf] (47), [-0.09256,   inf] (47), [-0.08986,   inf] (47), [-0.08907,   inf] (47), [-0.08807,   inf] (47), [-0.08597,   inf] (47), [-0.07951,   inf] (47), [-0.07919,   inf] (47), [-0.07906,   inf] (47), [-0.07715,   inf] (47), [-0.07607,   inf] (47), [-0.07598,   inf] (47), [-0.07147,   inf] (47), [-0.07132,   inf] (47), [-0.06779,   inf] (47), [-0.06760,   inf] (47), [-0.06726,   inf] (47), [-0.06499,   inf] (47), 
length of domains: 66
Total time: 0.3776	 pickout: 0.0094	 decision: 0.0371	 get_bound: 0.3251	 add_domain: 0.0059
Current lb:-0.10158563405275345
2488 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.462504863739014

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([66, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([66, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7581] [1, 7581] [2, 203] [2, 203] [2, 203] [2, 203] [1, 7581] [1, 7581] [2, 108] [2, 203] 
regular batch size: 2*66, diving batch size 1*0
best_l after optimization: -1.2664909362792969 with beta sum per layer: [0.0, 12.158742904663086, 3.893876552581787]
alpha/beta optimization time: 0.3474912643432617
This batch time : update_bounds func: 0.3788	 prepare: 0.0139	 bound: 0.3478	 transfer: 0.0090	 finalize: 0.0077
Accumulated time: update_bounds func: 8.4848	 prepare: 0.2550	 bound: 7.8562	 transfer: 0.0090	 finalize: 0.2092
batch bounding time:  0.3790318965911865
Current worst splitting domains [lb, ub] (depth):
[-0.08928,   inf] (49), [-0.08699,   inf] (49), [-0.08647,   inf] (49), [-0.08419,   inf] (49), [-0.08111,   inf] (49), [-0.08011,   inf] (49), [-0.07733,   inf] (49), [-0.07648,   inf] (49), [-0.07506,   inf] (49), [-0.07307,   inf] (49), [-0.07293,   inf] (49), [-0.07097,   inf] (49), [-0.06762,   inf] (49), [-0.06644,   inf] (49), [-0.06633,   inf] (49), [-0.06515,   inf] (49), [-0.06317,   inf] (49), [-0.06311,   inf] (49), [-0.05955,   inf] (49), [-0.05932,   inf] (49), 
length of domains: 81
Total time: 0.4552	 pickout: 0.0141	 decision: 0.0542	 get_bound: 0.3792	 add_domain: 0.0076
Current lb:-0.08928099274635315
2620 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.919030904769897

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([81, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([81, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 108] [2, 108] [2, 108] [2, 108] [2, 108] [2, 108] [2, 108] [2, 108] [2, 108] [2, 108] 
regular batch size: 2*81, diving batch size 1*0
best_l after optimization: -9.341825485229492 with beta sum per layer: [0.0, 15.437280654907227, 3.710935115814209]
alpha/beta optimization time: 0.3766794204711914
This batch time : update_bounds func: 0.4141	 prepare: 0.0164	 bound: 0.3770	 transfer: 0.0111	 finalize: 0.0092
Accumulated time: update_bounds func: 8.8989	 prepare: 0.2714	 bound: 8.2332	 transfer: 0.0111	 finalize: 0.2184
batch bounding time:  0.41440486907958984
Current worst splitting domains [lb, ub] (depth):
[-0.07710,   inf] (51), [-0.07470,   inf] (51), [-0.07432,   inf] (51), [-0.07181,   inf] (51), [-0.06910,   inf] (51), [-0.06814,   inf] (51), [-0.06512,   inf] (51), [-0.06423,   inf] (51), [-0.06268,   inf] (51), [-0.06054,   inf] (51), [-0.06051,   inf] (51), [-0.05832,   inf] (51), [-0.05622,   inf] (51), [-0.05437,   inf] (51), [-0.05427,   inf] (51), [-0.05372,   inf] (51), [-0.05218,   inf] (51), [-0.05081,   inf] (51), [-0.05074,   inf] (51), [-0.04941,   inf] (51), 
length of domains: 68
Total time: 0.4986	 pickout: 0.0164	 decision: 0.0604	 get_bound: 0.4147	 add_domain: 0.0071
Current lb:-0.07710222154855728
2782 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.419605493545532

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([68, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([68, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3557] [1, 3557] [1, 3557] [1, 3557] [1, 3557] [1, 3557] [1, 3557] [1, 3557] [1, 3557] [1, 3557] 
regular batch size: 2*68, diving batch size 1*0
best_l after optimization: 2.4684946537017822 with beta sum per layer: [0.0, 19.35006332397461, 2.6773228645324707]
alpha/beta optimization time: 0.3630702495574951
This batch time : update_bounds func: 0.3914	 prepare: 0.0139	 bound: 0.3634	 transfer: 0.0059	 finalize: 0.0079
Accumulated time: update_bounds func: 9.2903	 prepare: 0.2853	 bound: 8.5965	 transfer: 0.0059	 finalize: 0.2263
batch bounding time:  0.39171552658081055
Current worst splitting domains [lb, ub] (depth):
[-0.06670,   inf] (53), [-0.06468,   inf] (53), [-0.06435,   inf] (53), [-0.06359,   inf] (53), [-0.06270,   inf] (53), [-0.06213,   inf] (53), [-0.06114,   inf] (53), [-0.06007,   inf] (53), [-0.05841,   inf] (53), [-0.05739,   inf] (53), [-0.05728,   inf] (53), [-0.05675,   inf] (53), [-0.05457,   inf] (53), [-0.05346,   inf] (53), [-0.05329,   inf] (53), [-0.05314,   inf] (53), [-0.05280,   inf] (53), [-0.05111,   inf] (53), [-0.05042,   inf] (53), [-0.04842,   inf] (53), 
length of domains: 92
Total time: 0.5314	 pickout: 0.0152	 decision: 0.0552	 get_bound: 0.3919	 add_domain: 0.0691
Current lb:-0.06669574230909348
2918 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.952615022659302

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([92, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([92, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7579] [1, 7579] [1, 7579] [1, 7579] [1, 7579] [1, 7579] [1, 7579] [1, 7579] [1, 7579] [1, 7579] 
regular batch size: 2*92, diving batch size 1*0
best_l after optimization: 2.102583408355713 with beta sum per layer: [0.0, 44.03044891357422, 2.6664693355560303]
alpha/beta optimization time: 0.3896052837371826
This batch time : update_bounds func: 0.4304	 prepare: 0.0187	 bound: 0.3899	 transfer: 0.0108	 finalize: 0.0106
Accumulated time: update_bounds func: 9.7207	 prepare: 0.3039	 bound: 8.9864	 transfer: 0.0108	 finalize: 0.2369
batch bounding time:  0.4307067394256592
Current worst splitting domains [lb, ub] (depth):
[-0.05789,   inf] (55), [-0.05594,   inf] (55), [-0.05498,   inf] (55), [-0.05473,   inf] (55), [-0.05384,   inf] (55), [-0.05266,   inf] (55), [-0.05162,   inf] (55), [-0.05056,   inf] (55), [-0.05053,   inf] (55), [-0.04953,   inf] (55), [-0.04950,   inf] (55), [-0.04894,   inf] (55), [-0.04618,   inf] (55), [-0.04511,   inf] (55), [-0.04490,   inf] (55), [-0.04457,   inf] (55), [-0.04416,   inf] (55), [-0.04151,   inf] (55), [-0.04131,   inf] (55), [-0.03944,   inf] (55), 
length of domains: 118
Total time: 0.5290	 pickout: 0.0196	 decision: 0.0666	 get_bound: 0.4310	 add_domain: 0.0118
Current lb:-0.057886045426130295
3102 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.483253955841064

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([118, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([118, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 159] [2, 159] [2, 159] [2, 159] [2, 159] [2, 159] [2, 159] [2, 159] [2, 159] [2, 159] 
regular batch size: 2*118, diving batch size 1*0
best_l after optimization: 2.459545373916626 with beta sum per layer: [0.0, 48.837642669677734, 2.923942804336548]
alpha/beta optimization time: 0.4896206855773926
This batch time : update_bounds func: 0.5421	 prepare: 0.0236	 bound: 0.4900	 transfer: 0.0140	 finalize: 0.0141
Accumulated time: update_bounds func: 10.2629	 prepare: 0.3275	 bound: 9.4764	 transfer: 0.0140	 finalize: 0.2510
batch bounding time:  0.5424985885620117
Current worst splitting domains [lb, ub] (depth):
[-0.04730,   inf] (57), [-0.04668,   inf] (57), [-0.04533,   inf] (57), [-0.04448,   inf] (57), [-0.04430,   inf] (57), [-0.04413,   inf] (57), [-0.04394,   inf] (57), [-0.04355,   inf] (57), [-0.04325,   inf] (57), [-0.04262,   inf] (57), [-0.04210,   inf] (57), [-0.04165,   inf] (57), [-0.04101,   inf] (57), [-0.04066,   inf] (57), [-0.03992,   inf] (57), [-0.03991,   inf] (57), [-0.03947,   inf] (57), [-0.03946,   inf] (57), [-0.03893,   inf] (57), [-0.03885,   inf] (57), 
length of domains: 150
Total time: 0.6599	 pickout: 0.0230	 decision: 0.0783	 get_bound: 0.5429	 add_domain: 0.0158
Current lb:-0.04729804769158363
3338 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.145912408828735

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([150, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([150, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7779] [1, 7779] [1, 7779] [1, 7779] [1, 7779] [1, 7779] [1, 7779] [1, 7779] [1, 7779] [1, 7779] 
regular batch size: 2*150, diving batch size 1*0
best_l after optimization: 2.6645050048828125 with beta sum per layer: [0.0, 44.066558837890625, 3.141150712966919]
alpha/beta optimization time: 0.5746254920959473
This batch time : update_bounds func: 0.6418	 prepare: 0.0298	 bound: 0.5750	 transfer: 0.0192	 finalize: 0.0170
Accumulated time: update_bounds func: 10.9047	 prepare: 0.3573	 bound: 10.0513	 transfer: 0.0192	 finalize: 0.2680
batch bounding time:  0.6422381401062012
Current worst splitting domains [lb, ub] (depth):
[-0.03690,   inf] (59), [-0.03668,   inf] (59), [-0.03600,   inf] (59), [-0.03584,   inf] (59), [-0.03494,   inf] (59), [-0.03472,   inf] (59), [-0.03387,   inf] (59), [-0.03380,   inf] (59), [-0.03378,   inf] (59), [-0.03364,   inf] (59), [-0.03363,   inf] (59), [-0.03345,   inf] (59), [-0.03337,   inf] (59), [-0.03321,   inf] (59), [-0.03296,   inf] (59), [-0.03291,   inf] (59), [-0.03273,   inf] (59), [-0.03258,   inf] (59), [-0.03201,   inf] (59), [-0.03176,   inf] (59), 
length of domains: 215
Total time: 0.7970	 pickout: 0.0317	 decision: 0.0992	 get_bound: 0.6427	 add_domain: 0.0234
Current lb:-0.03689517080783844
3638 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.945969343185425

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([215, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([215, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7972] [1, 7972] [1, 7972] [1, 7972] [1, 7972] [1, 7972] [1, 7972] [1, 7972] [1, 7972] [1, 7972] 
regular batch size: 2*215, diving batch size 1*0
best_l after optimization: -1.6619023084640503 with beta sum per layer: [0.0, 63.513004302978516, 3.239978313446045]
alpha/beta optimization time: 0.7164082527160645
This batch time : update_bounds func: 0.8103	 prepare: 0.0413	 bound: 0.7167	 transfer: 0.0265	 finalize: 0.0247
Accumulated time: update_bounds func: 11.7149	 prepare: 0.3985	 bound: 10.7681	 transfer: 0.0265	 finalize: 0.2927
batch bounding time:  0.8107450008392334
Current worst splitting domains [lb, ub] (depth):
[-0.02983,   inf] (61), [-0.02966,   inf] (61), [-0.02886,   inf] (61), [-0.02865,   inf] (61), [-0.02788,   inf] (61), [-0.02772,   inf] (61), [-0.02683,   inf] (61), [-0.02667,   inf] (61), [-0.02663,   inf] (61), [-0.02656,   inf] (61), [-0.02650,   inf] (61), [-0.02645,   inf] (61), [-0.02607,   inf] (61), [-0.02601,   inf] (61), [-0.02594,   inf] (61), [-0.02592,   inf] (61), [-0.02572,   inf] (61), [-0.02566,   inf] (61), [-0.02496,   inf] (61), [-0.02469,   inf] (61), 
length of domains: 157
Total time: 0.9978	 pickout: 0.0429	 decision: 0.1263	 get_bound: 0.8114	 add_domain: 0.0173
Current lb:-0.029830554500222206
4068 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.94901752471924

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([157, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([157, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7587] [1, 5595] [1, 3301] [1, 3301] [1, 7587] [1, 5595] [1, 7587] [1, 3301] [1, 5595] [1, 5595] 
regular batch size: 2*157, diving batch size 1*0
best_l after optimization: -0.5125009417533875 with beta sum per layer: [0.0, 44.48719024658203, 1.8902506828308105]
alpha/beta optimization time: 0.5774838924407959
This batch time : update_bounds func: 0.6800	 prepare: 0.0301	 bound: 0.6142	 transfer: 0.0169	 finalize: 0.0179
Accumulated time: update_bounds func: 12.3949	 prepare: 0.4287	 bound: 11.3823	 transfer: 0.0169	 finalize: 0.3106
batch bounding time:  0.6803321838378906
Current worst splitting domains [lb, ub] (depth):
[-0.02310,   inf] (63), [-0.02295,   inf] (63), [-0.02112,   inf] (63), [-0.02106,   inf] (63), [-0.02006,   inf] (63), [-0.01989,   inf] (63), [-0.01966,   inf] (63), [-0.01960,   inf] (63), [-0.01916,   inf] (63), [-0.01906,   inf] (63), [-0.01895,   inf] (63), [-0.01875,   inf] (63), [-0.01761,   inf] (63), [-0.01760,   inf] (63), [-0.01755,   inf] (63), [-0.01739,   inf] (63), [-0.01662,   inf] (63), [-0.01659,   inf] (63), [-0.01657,   inf] (63), [-0.01641,   inf] (63), 
length of domains: 125
Total time: 0.8235	 pickout: 0.0323	 decision: 0.0959	 get_bound: 0.6808	 add_domain: 0.0145
Current lb:-0.02310076728463173
4382 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.775648593902588

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([125, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([125, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 5595] [1, 7587] [1, 5595] [1, 7587] [1, 5595] [1, 7587] [1, 7587] [1, 7587] [1, 5595] [1, 7587] 
regular batch size: 2*125, diving batch size 1*0
best_l after optimization: -0.6479138731956482 with beta sum per layer: [0.0, 23.061046600341797, 1.130515694618225]
alpha/beta optimization time: 0.5050818920135498
This batch time : update_bounds func: 0.5600	 prepare: 0.0245	 bound: 0.5054	 transfer: 0.0149	 finalize: 0.0145
Accumulated time: update_bounds func: 12.9549	 prepare: 0.4532	 bound: 11.8877	 transfer: 0.0149	 finalize: 0.3251
batch bounding time:  0.5603935718536377
Current worst splitting domains [lb, ub] (depth):
[-0.01668,   inf] (65), [-0.01639,   inf] (65), [-0.01475,   inf] (65), [-0.01441,   inf] (65), [-0.01356,   inf] (65), [-0.01341,   inf] (65), [-0.01322,   inf] (65), [-0.01297,   inf] (65), [-0.01273,   inf] (65), [-0.01251,   inf] (65), [-0.01192,   inf] (65), [-0.01186,   inf] (65), [-0.01122,   inf] (65), [-0.01092,   inf] (65), [-0.01040,   inf] (65), [-0.01039,   inf] (65), [-0.01003,   inf] (65), [-0.01000,   inf] (65), [-0.00957,   inf] (65), [-0.00949,   inf] (65), 
length of domains: 80
Total time: 0.6759	 pickout: 0.0253	 decision: 0.0804	 get_bound: 0.5608	 add_domain: 0.0094
Current lb:-0.016676602885127068
4632 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.455790281295776

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([80, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([80, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3301] [1, 3301] [1, 3301] [1, 3301] [1, 3301] [1, 3301] [1, 3301] [1, 3301] [1, 3301] [1, 3301] 
regular batch size: 2*80, diving batch size 1*0
best_l after optimization: -0.9813627004623413 with beta sum per layer: [0.0, 2.622422456741333, 0.7101096510887146]
alpha/beta optimization time: 0.3653223514556885
This batch time : update_bounds func: 0.4041	 prepare: 0.0159	 bound: 0.3656	 transfer: 0.0133	 finalize: 0.0090
Accumulated time: update_bounds func: 13.3591	 prepare: 0.4691	 bound: 12.2534	 transfer: 0.0133	 finalize: 0.3341
batch bounding time:  0.40439605712890625
Current worst splitting domains [lb, ub] (depth):
[-0.00712,   inf] (67), [-0.00680,   inf] (67), [-0.00592,   inf] (67), [-0.00559,   inf] (67), [-0.00559,   inf] (67), [-0.00538,   inf] (67), [-0.00510,   inf] (67), [-0.00472,   inf] (67), [-0.00438,   inf] (67), [-0.00408,   inf] (67), [-0.00403,   inf] (67), [-0.00378,   inf] (67), [-0.00377,   inf] (67), [-0.00364,   inf] (67), [-0.00358,   inf] (67), [-0.00340,   inf] (67), [-0.00312,   inf] (67), [-0.00299,   inf] (67), [-0.00298,   inf] (67), [-0.00298,   inf] (67), 
length of domains: 47
Total time: 0.4876	 pickout: 0.0182	 decision: 0.0589	 get_bound: 0.4046	 add_domain: 0.0059
Current lb:-0.007116779685020447
4792 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.945403337478638

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([47, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([47, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 199] [2, 199] [2, 199] [2, 199] [2, 199] [2, 199] [2, 199] [2, 199] [2, 199] [2, 199] 
regular batch size: 2*47, diving batch size 1*0
best_l after optimization: -1.8637055158615112 with beta sum per layer: [0.0, 1.4807054996490479, 0.34612950682640076]
alpha/beta optimization time: 0.30722689628601074
This batch time : update_bounds func: 0.3270	 prepare: 0.0103	 bound: 0.3075	 transfer: 0.0035	 finalize: 0.0055
Accumulated time: update_bounds func: 13.6861	 prepare: 0.4794	 bound: 12.5609	 transfer: 0.0035	 finalize: 0.3396
batch bounding time:  0.32721447944641113
Current worst splitting domains [lb, ub] (depth):
[-0.00113,   inf] (69), [-0.00082,   inf] (69), 
length of domains: 2
Total time: 0.3754	 pickout: 0.0100	 decision: 0.0376	 get_bound: 0.3274	 add_domain: 0.0004
Current lb:-0.001131284050643444
4886 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 19.32199501991272

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2, 32, 16, 16]) pre split depth:  3
batch:  torch.Size([2, 32, 16, 16]) post split depth:  3
splitting decisions: 
split level 0: [1, 732] [1, 732] 
split level 1: [1, 4573] [1, 4573] 
split level 2: [1, 7771] [1, 7771] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -0.6078648567199707 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.009882211685180664
This batch time : update_bounds func: 0.0153	 prepare: 0.0029	 bound: 0.0101	 transfer: 0.0012	 finalize: 0.0010
Accumulated time: update_bounds func: 13.7014	 prepare: 0.4823	 bound: 12.5710	 transfer: 0.0012	 finalize: 0.3406/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:462: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(preprocess_cifar(eps_temp, perturbation=True)).reshape(1,-1,1,1)

batch bounding time:  0.015459060668945312
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0419	 pickout: 0.0011	 decision: 0.0229	 get_bound: 0.0178	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 19.36408042907715

Image 70 label 4 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 19.446289777755737
70 1.0000000116860974e-07
##### [0:70] Tested against 2 ######
Model prediction is: tensor([[-83.4550, -86.1856, -79.0081, -81.0062, -77.6787, -81.7953, -75.8846,
         -84.0971, -85.2723, -86.8423]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /34 start_node /35
setting alpha for layer /34 start_node /45
not setting layer /34 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /36 start_node /45
not setting layer /36 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /46 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /33 torch.Size([1, 32, 16, 16])
1 /35 torch.Size([1, 128, 8, 8])
2 /45 torch.Size([1, 250])
best_l after optimization: 0.48892730474472046 with beta sum per layer: []
alpha/beta optimization time: 1.1454062461853027
alpha-CROWN with fixed intermediate bounds: tensor([[-0.4889]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.48892730474472046
layer 0 size torch.Size([8192]) unstable 1612
layer 1 size torch.Size([8192]) unstable 678
layer 2 size torch.Size([250]) unstable 66
-----------------
# of unstable neurons: 2356
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 248] 
split level 1: [2, 124] 
split level 2: [2, 65] 
split level 3: [2, 94] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -11.592544555664062 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.010638713836669922
This batch time : update_bounds func: 0.0161	 prepare: 0.0027	 bound: 0.0111	 transfer: 0.0012	 finalize: 0.0011
Accumulated time: update_bounds func: 13.7175	 prepare: 0.4850	 bound: 12.5821	 transfer: 0.0012	 finalize: 0.3417
batch bounding time:  0.016149044036865234
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0472	 pickout: 0.0008	 decision: 0.0283	 get_bound: 0.0181	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.2310116291046143

Image 70 label 2 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.3111677169799805
70 1.0000000116860974e-07
##### [0:70] Tested against 3 ######
Initial alpha-CROWN verified for label 3 with bound 2.3058576583862305
Image 70 label 3 verification end, final lower bound 2.3058576583862305, upper bound inf, time: 0.0004315376281738281
70 2.3058576583862305
##### [0:70] Tested against 5 ######
Initial alpha-CROWN verified for label 5 with bound 2.3242580890655518
Image 70 label 5 verification end, final lower bound 2.3242580890655518, upper bound inf, time: 0.00043463706970214844
70 2.3242580890655518
##### [0:70] Tested against 0 ######
Initial alpha-CROWN verified for label 0 with bound 3.0270497798919678
Image 70 label 0 verification end, final lower bound 3.0270497798919678, upper bound inf, time: 0.0003807544708251953
70 3.0270497798919678
##### [0:70] Tested against 7 ######
Initial alpha-CROWN verified for label 7 with bound 3.6332340240478516
Image 70 label 7 verification end, final lower bound 3.6332340240478516, upper bound inf, time: 0.00036263465881347656
70 3.6332340240478516
##### [0:70] Tested against 8 ######
Initial alpha-CROWN verified for label 8 with bound 4.279047966003418
Image 70 label 8 verification end, final lower bound 4.279047966003418, upper bound inf, time: 0.00036406517028808594
70 4.279047966003418
##### [0:70] Tested against 1 ######
Initial alpha-CROWN verified for label 1 with bound 4.941695213317871
Image 70 label 1 verification end, final lower bound 4.941695213317871, upper bound inf, time: 0.0003681182861328125
70 4.941695213317871
##### [0:70] Tested against 9 ######
Initial alpha-CROWN verified for label 9 with bound 5.917610168457031
Image 70 label 9 verification end, final lower bound 5.917610168457031, upper bound inf, time: 0.00036072731018066406
70 5.917610168457031
##### [0:70] Tested against 6 ######
groundtruth label, skip!
Result: image 70 verification success (with branch and bound)!
Wall time: 33.32082486152649

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 1): [70]
verification failure idx (total 0): []
final verified acc: 100.0%[1]
verifier is called on 1 examples.
total verified: 1
mean time [cnt:1] (excluding attack success): 30.829684019088745
