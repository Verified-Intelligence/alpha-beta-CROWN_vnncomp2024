Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_cnn_b_adv.model
  name: cnn_4layer_b
data:
  start: 6
  end: 7
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR_SDP
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.00784313725
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 256
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 90
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:08:46 2022 on diablo.cs.ucla.edu
Sequential(
  (0): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)
  (1): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2))
  (2): ReLU()
  (3): Conv2d(32, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (4): ReLU()
  (5): Flatten()
  (6): Linear(in_features=8192, out_features=250, bias=True)
  (7): ReLU()
  (8): Linear(in_features=250, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([200, 3, 32, 32]) torch.Size([200]) torch.Size([200])
X range: tensor(2.1256) tensor(-1.9889) tensor(-0.0131)
############################
epsilon after preprocessing: tensor([[[[0.0317]],

         [[0.0322]],

         [[0.0300]]]]), data_max = tensor([[[[2.0587]],

         [[2.1256]],

         [[2.1154]]]]), data_min = tensor([[[[-1.9889]],

         [[-1.9807]],

         [[-1.7076]]]])
Task length: 1
saving results to Verified_ret_[cnn_4layer_b]_start=6_end=7_iter=20_b=256_timeout=90_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 6 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 0, correct label 0, image norm 2445.97607421875, logits tensor([-110.0463, -113.1240, -117.2154, -117.8690, -117.7157, -119.6795,
        -119.7798, -119.0070, -114.5162, -116.4255], device='cuda:0',
       grad_fn=<SelectBackward>)
##### PGD attack: True label: 0, Tested against: ['all'] ######
pgd prediction: tensor([-110.6796, -112.1051, -117.3874, -117.5032, -117.6575, -119.2703,
        -119.5629, -118.8537, -114.1595, -115.5889], device='cuda:0',
       grad_fn=<SqueezeBackward1>)
attack margin tensor([   inf, 1.4255, 6.7078, 6.8236, 6.9779, 8.5907, 8.8833, 8.1741, 3.4799,
        4.9093], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[-110.0463, -113.1240, -117.2154, -117.8690, -117.7157, -119.6795,
         -119.7798, -119.0070, -114.5162, -116.4255]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-3.3788,  1.8884,  2.2122,  2.5016,  3.3197,  3.9358,  2.3318, -0.7768,
          0.4708]], device='cuda:0') None
best_l after optimization: -15.448700904846191 with beta sum per layer: []
alpha/beta optimization time: 8.186717987060547
initial alpha-CROWN bounds: tensor([[-2.9308,  2.1805,  2.5116,  2.7677,  3.6428,  4.2518,  2.7040, -0.5017,
          0.8229]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-2.9308, device='cuda:0', grad_fn=<MinBackward1>)
Sorted order for labels to verify: [1, 8, 9, 2, 3, 4, 7, 5, 6, 0]
##### [0:6] Tested against 1 ######
Model prediction is: tensor([[-110.0463, -113.1240, -117.2154, -117.8690, -117.7157, -119.6795,
         -119.7798, -119.0070, -114.5162, -116.4255]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /34 start_node /35
setting alpha for layer /34 start_node /45
not setting layer /34 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /36 start_node /45
not setting layer /36 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /46 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /33 torch.Size([1, 32, 16, 16])
1 /35 torch.Size([1, 128, 8, 8])
2 /45 torch.Size([1, 250])
best_l after optimization: 2.9304332733154297 with beta sum per layer: []
alpha/beta optimization time: 2.0056071281433105
alpha-CROWN with fixed intermediate bounds: tensor([[-2.9304]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-2.9304332733154297
layer 0 size torch.Size([8192]) unstable 1305
layer 1 size torch.Size([8192]) unstable 774
layer 2 size torch.Size([250]) unstable 59
-----------------
# of unstable neurons: 2138
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 74] 
split level 1: [2, 71] 
split level 2: [2, 131] 
split level 3: [2, 128] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 10.98259162902832 with beta sum per layer: [0.0, 0.0, 1.2733790874481201]
alpha/beta optimization time: 0.296952486038208
This batch time : update_bounds func: 0.3053	 prepare: 0.0053	 bound: 0.2976	 transfer: 0.0011	 finalize: 0.0012
Accumulated time: update_bounds func: 0.3053	 prepare: 0.0053	 bound: 0.2976	 transfer: 0.0011	 finalize: 0.0012
batch bounding time:  0.3054502010345459
Current worst splitting domains [lb, ub] (depth):
[-1.44765,   inf] (5), [-1.29094,   inf] (5), [-1.18599,   inf] (5), [-1.09906,   inf] (5), [-0.96917,   inf] (5), [-0.92675,   inf] (5), [-0.80280,   inf] (5), [-0.67867,   inf] (5), [-0.66276,   inf] (5), [-0.66236,   inf] (5), [-0.65844,   inf] (5), [-0.20044,   inf] (5), [-0.18413,   inf] (5), [-0.16456,   inf] (5), [-0.12118,   inf] (5), 
length of domains: 15
Total time: 0.3387	 pickout: 0.0009	 decision: 0.0298	 get_bound: 0.3075	 add_domain: 0.0006
Current lb:-1.447649598121643
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.2185988426208496

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([15, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([15, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 1] [2, 1] [2, 1] [2, 1] [2, 1] [2, 1] [2, 1] [2, 1] [2, 1] [2, 1] 
regular batch size: 2*15, diving batch size 1*0
best_l after optimization: 6.509394645690918 with beta sum per layer: [0.0, 0.0, 3.4496026039123535]
alpha/beta optimization time: 0.28163862228393555
This batch time : update_bounds func: 0.2894	 prepare: 0.0038	 bound: 0.2819	 transfer: 0.0017	 finalize: 0.0019
Accumulated time: update_bounds func: 0.5947	 prepare: 0.0090	 bound: 0.5795	 transfer: 0.0017	 finalize: 0.0031
batch bounding time:  0.28956079483032227
Current worst splitting domains [lb, ub] (depth):
[-1.17381,   inf] (7), [-1.01362,   inf] (7), [-0.91770,   inf] (7), [-0.82813,   inf] (7), [-0.70915,   inf] (7), [-0.70391,   inf] (7), [-0.65195,   inf] (7), [-0.52429,   inf] (7), [-0.50935,   inf] (7), [-0.43413,   inf] (7), [-0.41536,   inf] (7), [-0.39406,   inf] (7), [-0.39091,   inf] (7), [-0.38326,   inf] (7), [-0.31343,   inf] (7), [-0.11620,   inf] (7), 
length of domains: 16
Total time: 0.3205	 pickout: 0.0035	 decision: 0.0267	 get_bound: 0.2896	 add_domain: 0.0007
Current lb:-1.1738096475601196
46 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.5394201278686523

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([16, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([16, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 54] [2, 54] [2, 54] [2, 54] [2, 54] [2, 54] [2, 54] [2, 54] [2, 54] [2, 54] 
regular batch size: 2*16, diving batch size 1*0
best_l after optimization: 1.5535144805908203 with beta sum per layer: [0.0, 0.0, 2.29610538482666]
alpha/beta optimization time: 0.27193617820739746
This batch time : update_bounds func: 0.2802	 prepare: 0.0039	 bound: 0.2722	 transfer: 0.0018	 finalize: 0.0021
Accumulated time: update_bounds func: 0.8749	 prepare: 0.0130	 bound: 0.8518	 transfer: 0.0018	 finalize: 0.0052
batch bounding time:  0.2803208827972412
Current worst splitting domains [lb, ub] (depth):
[-1.00180,   inf] (9), [-0.83186,   inf] (9), [-0.72792,   inf] (9), [-0.63778,   inf] (9), [-0.52305,   inf] (9), [-0.51844,   inf] (9), [-0.45704,   inf] (9), [-0.32927,   inf] (9), [-0.32019,   inf] (9), [-0.24253,   inf] (9), [-0.22075,   inf] (9), [-0.18589,   inf] (9), [-0.18164,   inf] (9), [-0.16687,   inf] (9), [-0.12007,   inf] (9), [-0.01340,   inf] (9), 
length of domains: 16
Total time: 0.3121	 pickout: 0.0037	 decision: 0.0272	 get_bound: 0.2804	 add_domain: 0.0007
Current lb:-1.0017977952957153
78 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.85182523727417

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([16, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([16, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 75] [2, 75] [2, 75] [2, 75] [2, 75] [2, 75] [2, 75] [2, 75] [2, 75] [2, 75] 
regular batch size: 2*16, diving batch size 1*0
best_l after optimization: 4.801715850830078 with beta sum per layer: [0.0, 0.0, 2.387087345123291]
alpha/beta optimization time: 0.2723426818847656
This batch time : update_bounds func: 0.2805	 prepare: 0.0039	 bound: 0.2726	 transfer: 0.0018	 finalize: 0.0021
Accumulated time: update_bounds func: 1.1554	 prepare: 0.0169	 bound: 1.1244	 transfer: 0.0018	 finalize: 0.0073
batch bounding time:  0.28064846992492676
Current worst splitting domains [lb, ub] (depth):
[-0.84868,   inf] (11), [-0.67522,   inf] (11), [-0.63245,   inf] (11), [-0.58264,   inf] (11), [-0.48306,   inf] (11), [-0.43947,   inf] (11), [-0.36207,   inf] (11), [-0.35701,   inf] (11), [-0.32183,   inf] (11), [-0.30304,   inf] (11), [-0.25613,   inf] (11), [-0.17679,   inf] (11), [-0.16538,   inf] (11), [-0.14999,   inf] (11), [-0.09374,   inf] (11), [-0.07740,   inf] (11), [-0.05892,   inf] (11), [-0.02907,   inf] (11), [-0.02359,   inf] (11), [-0.01904,   inf] (11), 
length of domains: 21
Total time: 0.3124	 pickout: 0.0036	 decision: 0.0271	 get_bound: 0.2807	 add_domain: 0.0010
Current lb:-0.8486822843551636
110 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.164556503295898

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([21, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([21, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 193] [2, 193] [2, 193] [2, 193] [2, 193] [2, 193] [2, 193] [2, 193] [2, 193] [2, 193] 
regular batch size: 2*21, diving batch size 1*0
best_l after optimization: 4.726137161254883 with beta sum per layer: [0.0, 0.0, 3.559326171875]
alpha/beta optimization time: 0.2814502716064453
This batch time : update_bounds func: 0.2913	 prepare: 0.0047	 bound: 0.2817	 transfer: 0.0020	 finalize: 0.0027
Accumulated time: update_bounds func: 1.4467	 prepare: 0.0215	 bound: 1.4061	 transfer: 0.0020	 finalize: 0.0101
batch bounding time:  0.2914400100708008
Current worst splitting domains [lb, ub] (depth):
[-0.73919,   inf] (13), [-0.57964,   inf] (13), [-0.56639,   inf] (13), [-0.52573,   inf] (13), [-0.47775,   inf] (13), [-0.39510,   inf] (13), [-0.37238,   inf] (13), [-0.33945,   inf] (13), [-0.33148,   inf] (13), [-0.28947,   inf] (13), [-0.25479,   inf] (13), [-0.24435,   inf] (13), [-0.21940,   inf] (13), [-0.21197,   inf] (13), [-0.19313,   inf] (13), [-0.14526,   inf] (13), [-0.13811,   inf] (13), [-0.10903,   inf] (13), [-0.06755,   inf] (13), [-0.05962,   inf] (13), 
length of domains: 23
Total time: 0.3257	 pickout: 0.0046	 decision: 0.0285	 get_bound: 0.2915	 add_domain: 0.0011
Current lb:-0.7391877174377441
152 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.490676641464233

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([23, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([23, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 62] [2, 62] [2, 57] [2, 57] [2, 57] [2, 57] [2, 62] [2, 57] [2, 57] [2, 57] 
regular batch size: 2*23, diving batch size 1*0
best_l after optimization: 0.02017652988433838 with beta sum per layer: [0.0, 0.0, 4.834106922149658]
alpha/beta optimization time: 0.28453588485717773
This batch time : update_bounds func: 0.2959	 prepare: 0.0050	 bound: 0.2848	 transfer: 0.0027	 finalize: 0.0033
Accumulated time: update_bounds func: 1.7426	 prepare: 0.0265	 bound: 1.6909	 transfer: 0.0027	 finalize: 0.0133
batch bounding time:  0.29602551460266113
Current worst splitting domains [lb, ub] (depth):
[-0.66087,   inf] (15), [-0.49746,   inf] (15), [-0.49720,   inf] (15), [-0.45507,   inf] (15), [-0.40635,   inf] (15), [-0.32199,   inf] (15), [-0.29637,   inf] (15), [-0.26560,   inf] (15), [-0.26503,   inf] (15), [-0.26040,   inf] (15), [-0.21310,   inf] (15), [-0.17675,   inf] (15), [-0.17586,   inf] (15), [-0.13956,   inf] (15), [-0.13803,   inf] (15), [-0.12080,   inf] (15), [-0.06789,   inf] (15), [-0.06576,   inf] (15), [-0.05609,   inf] (15), [-0.03323,   inf] (15), 
length of domains: 20
Total time: 0.3311	 pickout: 0.0050	 decision: 0.0290	 get_bound: 0.2961	 add_domain: 0.0011
Current lb:-0.6608687043190002
198 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.822250127792358

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([20, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([20, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 57] [2, 62] [2, 57] [2, 62] [2, 62] [2, 62] [2, 199] [2, 62] [2, 57] [2, 62] 
regular batch size: 2*20, diving batch size 1*0
best_l after optimization: 1.1146600246429443 with beta sum per layer: [0.0, 0.0, 3.9893062114715576]
alpha/beta optimization time: 0.2797670364379883
This batch time : update_bounds func: 0.2893	 prepare: 0.0045	 bound: 0.2801	 transfer: 0.0020	 finalize: 0.0026
Accumulated time: update_bounds func: 2.0319	 prepare: 0.0311	 bound: 1.9710	 transfer: 0.0020	 finalize: 0.0159
batch bounding time:  0.2894458770751953
Current worst splitting domains [lb, ub] (depth):
[-0.59260,   inf] (17), [-0.42367,   inf] (17), [-0.42140,   inf] (17), [-0.37252,   inf] (17), [-0.31946,   inf] (17), [-0.24291,   inf] (17), [-0.21706,   inf] (17), [-0.18868,   inf] (17), [-0.18297,   inf] (17), [-0.18204,   inf] (17), [-0.12425,   inf] (17), [-0.09550,   inf] (17), [-0.09257,   inf] (17), [-0.05728,   inf] (17), [-0.05037,   inf] (17), [-0.04048,   inf] (17), [-0.03851,   inf] (17), [-0.02113,   inf] (17), [-0.00191,   inf] (17), 
length of domains: 19
Total time: 0.3235	 pickout: 0.0045	 decision: 0.0281	 get_bound: 0.2895	 add_domain: 0.0012
Current lb:-0.592598021030426
238 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.14617133140564

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([19, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([19, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 199] [2, 199] [2, 199] [2, 199] [2, 199] [2, 199] [2, 13] [2, 199] [2, 199] [2, 199] 
regular batch size: 2*19, diving batch size 1*0
best_l after optimization: 2.232290267944336 with beta sum per layer: [0.0, 0.0, 2.8995003700256348]
alpha/beta optimization time: 0.31345272064208984
This batch time : update_bounds func: 0.3228	 prepare: 0.0044	 bound: 0.3138	 transfer: 0.0019	 finalize: 0.0025
Accumulated time: update_bounds func: 2.3546	 prepare: 0.0355	 bound: 2.2848	 transfer: 0.0019	 finalize: 0.0185
batch bounding time:  0.3229360580444336
Current worst splitting domains [lb, ub] (depth):
[-0.51424,   inf] (19), [-0.34699,   inf] (19), [-0.34423,   inf] (19), [-0.33958,   inf] (19), [-0.28958,   inf] (19), [-0.23944,   inf] (19), [-0.18386,   inf] (19), [-0.18021,   inf] (19), [-0.15979,   inf] (19), [-0.14499,   inf] (19), [-0.14043,   inf] (19), [-0.10107,   inf] (19), [-0.09725,   inf] (19), [-0.09515,   inf] (19), [-0.06995,   inf] (19), [-0.04039,   inf] (19), [-0.01549,   inf] (19), [-0.01317,   inf] (19), [-0.00883,   inf] (19), 
length of domains: 19
Total time: 0.3570	 pickout: 0.0043	 decision: 0.0284	 get_bound: 0.3230	 add_domain: 0.0012
Current lb:-0.5142401456832886
276 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.503562927246094

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([19, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([19, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 13] [2, 13] [2, 13] [2, 13] [2, 13] [2, 13] [2, 13] [2, 13] [2, 13] [2, 13] 
regular batch size: 2*19, diving batch size 1*0
best_l after optimization: 2.004669189453125 with beta sum per layer: [0.0, 0.0, 2.803410768508911]
alpha/beta optimization time: 0.3002326488494873
This batch time : update_bounds func: 0.3094	 prepare: 0.0044	 bound: 0.3005	 transfer: 0.0019	 finalize: 0.0024
Accumulated time: update_bounds func: 2.6640	 prepare: 0.0399	 bound: 2.5853	 transfer: 0.0019	 finalize: 0.0209
batch bounding time:  0.3095977306365967
Current worst splitting domains [lb, ub] (depth):
[-0.43674,   inf] (21), [-0.31837,   inf] (21), [-0.26805,   inf] (21), [-0.26571,   inf] (21), [-0.26057,   inf] (21), [-0.21711,   inf] (21), [-0.16655,   inf] (21), [-0.15441,   inf] (21), [-0.14244,   inf] (21), [-0.12842,   inf] (21), [-0.09897,   inf] (21), [-0.09829,   inf] (21), [-0.08129,   inf] (21), [-0.06687,   inf] (21), [-0.06071,   inf] (21), [-0.04081,   inf] (21), [-0.02292,   inf] (21), [-0.02186,   inf] (21), [-0.02127,   inf] (21), [-0.01752,   inf] (21), 
length of domains: 20
Total time: 0.3452	 pickout: 0.0044	 decision: 0.0298	 get_bound: 0.3097	 add_domain: 0.0013
Current lb:-0.43674153089523315
314 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.84922194480896

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([20, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([20, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 80] [2, 80] [2, 80] [2, 80] [2, 80] [2, 80] [2, 80] [2, 80] [2, 80] [2, 80] 
regular batch size: 2*20, diving batch size 1*0
best_l after optimization: 1.5093152523040771 with beta sum per layer: [0.0, 0.0, 2.902620315551758]
alpha/beta optimization time: 0.27518630027770996
This batch time : update_bounds func: 0.2846	 prepare: 0.0045	 bound: 0.2755	 transfer: 0.0020	 finalize: 0.0025
Accumulated time: update_bounds func: 2.9486	 prepare: 0.0444	 bound: 2.8607	 transfer: 0.0020	 finalize: 0.0234
batch bounding time:  0.28473877906799316
Current worst splitting domains [lb, ub] (depth):
[-0.36110,   inf] (23), [-0.31876,   inf] (23), [-0.24576,   inf] (23), [-0.19088,   inf] (23), [-0.19082,   inf] (23), [-0.18728,   inf] (23), [-0.18564,   inf] (23), [-0.15924,   inf] (23), [-0.15291,   inf] (23), [-0.14363,   inf] (23), [-0.13895,   inf] (23), [-0.11616,   inf] (23), [-0.09565,   inf] (23), [-0.07904,   inf] (23), [-0.06390,   inf] (23), [-0.04973,   inf] (23), [-0.02954,   inf] (23), [-0.02367,   inf] (23), [-0.02164,   inf] (23), [-0.02003,   inf] (23), 
length of domains: 22
Total time: 0.3191	 pickout: 0.0045	 decision: 0.0283	 get_bound: 0.2848	 add_domain: 0.0015
Current lb:-0.3611045181751251
354 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.168735980987549

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([22, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([22, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 147] [2, 147] [2, 147] [2, 147] [2, 147] [2, 147] [2, 147] [2, 147] [2, 147] [2, 147] 
regular batch size: 2*22, diving batch size 1*0
best_l after optimization: -2.5839900970458984 with beta sum per layer: [0.0, 0.0, 3.4646925926208496]
alpha/beta optimization time: 0.2770977020263672
This batch time : update_bounds func: 0.2884	 prepare: 0.0051	 bound: 0.2774	 transfer: 0.0030	 finalize: 0.0028
Accumulated time: update_bounds func: 3.2370	 prepare: 0.0495	 bound: 3.1381	 transfer: 0.0030	 finalize: 0.0262
batch bounding time:  0.28850722312927246
Current worst splitting domains [lb, ub] (depth):
[-0.30531,   inf] (25), [-0.26209,   inf] (25), [-0.18862,   inf] (25), [-0.13424,   inf] (25), [-0.13296,   inf] (25), [-0.12963,   inf] (25), [-0.12705,   inf] (25), [-0.10595,   inf] (25), [-0.09684,   inf] (25), [-0.08503,   inf] (25), [-0.08020,   inf] (25), [-0.07821,   inf] (25), [-0.05509,   inf] (25), [-0.05179,   inf] (25), [-0.04051,   inf] (25), [-0.02169,   inf] (25), [-0.00725,   inf] (25), 
length of domains: 17
Total time: 0.3239	 pickout: 0.0049	 decision: 0.0293	 get_bound: 0.2886	 add_domain: 0.0012
Current lb:-0.30531176924705505
398 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.493047714233398

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([17, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([17, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2220] [1, 2220] [1, 2220] [2, 249] [2, 249] [1, 2220] [1, 2220] [2, 249] [2, 249] [1, 2220] 
regular batch size: 2*17, diving batch size 1*0
best_l after optimization: -6.1666669845581055 with beta sum per layer: [0.0, 0.0, 1.7543214559555054]
alpha/beta optimization time: 0.2770118713378906
This batch time : update_bounds func: 0.2873	 prepare: 0.0043	 bound: 0.2773	 transfer: 0.0032	 finalize: 0.0024
Accumulated time: update_bounds func: 3.5243	 prepare: 0.0538	 bound: 3.4154	 transfer: 0.0032	 finalize: 0.0286
batch bounding time:  0.2874794006347656
Current worst splitting domains [lb, ub] (depth):
[-0.24995,   inf] (27), [-0.20575,   inf] (27), [-0.17742,   inf] (27), [-0.13810,   inf] (27), [-0.12662,   inf] (27), [-0.08059,   inf] (27), [-0.07965,   inf] (27), [-0.07567,   inf] (27), [-0.06290,   inf] (27), [-0.06120,   inf] (27), [-0.05333,   inf] (27), [-0.04208,   inf] (27), [-0.03005,   inf] (27), [-0.02455,   inf] (27), [-0.01031,   inf] (27), [-0.00635,   inf] (27), 
length of domains: 16
Total time: 0.3201	 pickout: 0.0038	 decision: 0.0275	 get_bound: 0.2875	 add_domain: 0.0011
Current lb:-0.24994897842407227
432 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.813469886779785

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([16, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([16, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 249] [2, 249] [2, 249] [2, 249] [2, 249] [1, 2220] [1, 2220] [2, 249] [2, 249] [2, 249] 
regular batch size: 2*16, diving batch size 1*0
best_l after optimization: -15.69888973236084 with beta sum per layer: [0.0, 0.0, 1.423492193222046]
alpha/beta optimization time: 0.2724027633666992
This batch time : update_bounds func: 0.2820	 prepare: 0.0043	 bound: 0.2727	 transfer: 0.0027	 finalize: 0.0021
Accumulated time: update_bounds func: 3.8064	 prepare: 0.0581	 bound: 3.6881	 transfer: 0.0027	 finalize: 0.0307
batch bounding time:  0.28218865394592285
Current worst splitting domains [lb, ub] (depth):
[-0.19619,   inf] (29), [-0.15325,   inf] (29), [-0.11946,   inf] (29), [-0.08084,   inf] (29), [-0.07166,   inf] (29), [-0.03261,   inf] (29), [-0.02691,   inf] (29), [-0.02303,   inf] (29), [-0.00654,   inf] (29), [-0.00422,   inf] (29), [-0.00026,   inf] (29), 
length of domains: 11
Total time: 0.3141	 pickout: 0.0039	 decision: 0.0271	 get_bound: 0.2822	 add_domain: 0.0008
Current lb:-0.19618597626686096
464 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.127951145172119

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([11, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([11, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 156] [2, 156] [2, 156] [2, 156] [2, 156] [2, 156] [2, 156] [2, 89] [2, 156] [2, 156] 
regular batch size: 2*11, diving batch size 1*0
best_l after optimization: -0.5164443254470825 with beta sum per layer: [0.0, 0.0, 1.0641567707061768]
alpha/beta optimization time: 0.27735185623168945
This batch time : update_bounds func: 0.2844	 prepare: 0.0034	 bound: 0.2776	 transfer: 0.0016	 finalize: 0.0016
Accumulated time: update_bounds func: 4.0907	 prepare: 0.0615	 bound: 3.9657	 transfer: 0.0016	 finalize: 0.0323
batch bounding time:  0.2845127582550049
Current worst splitting domains [lb, ub] (depth):
[-0.15787,   inf] (31), [-0.11409,   inf] (31), [-0.08177,   inf] (31), [-0.04218,   inf] (31), [-0.03298,   inf] (31), 
length of domains: 5
Total time: 0.3134	 pickout: 0.0029	 decision: 0.0255	 get_bound: 0.2846	 add_domain: 0.0004
Current lb:-0.1578672081232071
486 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.441636800765991

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([5, 32, 16, 16]) pre split depth:  2
batch:  torch.Size([5, 32, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [2, 89] [2, 89] [2, 89] [2, 89] [2, 89] 
split level 1: [2, 93] [2, 93] [2, 93] [2, 93] [2, 93] 
regular batch size: 2*10, diving batch size 1*0
best_l after optimization: -1.901900053024292 with beta sum per layer: [0.0, 0.0, 0.6254314184188843]
alpha/beta optimization time: 0.2776050567626953
This batch time : update_bounds func: 0.2840	 prepare: 0.0032	 bound: 0.2779	 transfer: 0.0013	 finalize: 0.0015
Accumulated time: update_bounds func: 4.3747	 prepare: 0.0647	 bound: 4.2436	 transfer: 0.0013	 finalize: 0.0337
batch bounding time:  0.2841341495513916
Current worst splitting domains [lb, ub] (depth):
[-0.09668,   inf] (34), [-0.05350,   inf] (34), [-0.02102,   inf] (34), 
length of domains: 3
Total time: 0.3124	 pickout: 0.0017	 decision: 0.0243	 get_bound: 0.2859	 add_domain: 0.0004
Current lb:-0.0966789722442627
506 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.7543113231658936

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3, 32, 16, 16]) pre split depth:  3
batch:  torch.Size([3, 32, 16, 16]) post split depth:  3
splitting decisions: 
split level 0: [2, 94] [2, 94] [2, 94] 
split level 1: [2, 132] [2, 144] [2, 144] 
split level 2: [2, 144] [1, 1389] [2, 132] 
regular batch size: 2*12, diving batch size 1*0
best_l after optimization: -7.583062171936035 with beta sum per layer: [0.0, 0.0, 0.26572275161743164]
alpha/beta optimization time: 0.31509828567504883
This batch time : update_bounds func: 0.3225	 prepare: 0.0037	 bound: 0.3154	 transfer: 0.0015	 finalize: 0.0017
Accumulated time: update_bounds func: 4.6972	 prepare: 0.0685	 bound: 4.5590	 transfer: 0.0015	 finalize: 0.0354
batch bounding time:  0.3226501941680908
Current worst splitting domains [lb, ub] (depth):
[-0.04424,   inf] (38), [-0.00281,   inf] (38), 
length of domains: 2
Total time: 0.3511	 pickout: 0.0013	 decision: 0.0238	 get_bound: 0.3257	 add_domain: 0.0003
Current lb:-0.044241294264793396
530 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.105669260025024

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2, 32, 16, 16]) pre split depth:  3
batch:  torch.Size([2, 32, 16, 16]) post split depth:  3
splitting decisions: 
split level 0: [1, 3222] [1, 3222] 
split level 1: [1, 4845] [2, 132] 
split level 2: [1, 1389] [1, 116] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -2.8503055572509766 with beta sum per layer: [0.0, 0.0, 0.1882203072309494]
alpha/beta optimization time: 0.010648965835571289
This batch time : update_bounds func: 0.0163	 prepare: 0.0030	 bound: 0.0109	 transfer: 0.0012	 finalize: 0.0011
Accumulated time: update_bounds func: 4.7135	 prepare: 0.0714	 bound: 4.5700	 transfer: 0.0012	 finalize: 0.0366
batch bounding time:  0.016347885131835938
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0441	 pickout: 0.0011	 decision: 0.0244	 get_bound: 0.0186	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 8.150028705596924

Image 6 label 1 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 8.233206510543823
6 1.0000000116860974e-07
##### [0:6] Tested against 8 ######
Model prediction is: tensor([[-110.0463, -113.1240, -117.2154, -117.8690, -117.7157, -119.6795,
         -119.7798, -119.0070, -114.5162, -116.4255]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /34 start_node /35
setting alpha for layer /34 start_node /45
not setting layer /34 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /36 start_node /45
not setting layer /36 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /46 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /33 torch.Size([1, 32, 16, 16])
1 /35 torch.Size([1, 128, 8, 8])
2 /45 torch.Size([1, 250])
best_l after optimization: 0.5012803077697754 with beta sum per layer: []
alpha/beta optimization time: 1.2553508281707764
alpha-CROWN with fixed intermediate bounds: tensor([[-0.5013]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.5012803673744202
layer 0 size torch.Size([8192]) unstable 1305
layer 1 size torch.Size([8192]) unstable 774
layer 2 size torch.Size([250]) unstable 59
-----------------
# of unstable neurons: 2138
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 199] 
split level 1: [2, 36] 
split level 2: [2, 49] 
split level 3: [2, 178] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -20.799928665161133 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.01804351806640625
This batch time : update_bounds func: 0.0269	 prepare: 0.0039	 bound: 0.0207	 transfer: 0.0012	 finalize: 0.0011
Accumulated time: update_bounds func: 4.7403	 prepare: 0.0753	 bound: 4.5906	 transfer: 0.0012	 finalize: 0.0377
batch bounding time:  0.02693629264831543
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0600	 pickout: 0.0009	 decision: 0.0301	 get_bound: 0.0290	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.3497061729431152

Image 6 label 8 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.4283788204193115
6 1.0000000116860974e-07
##### [0:6] Tested against 9 ######
Initial alpha-CROWN verified for label 9 with bound 0.822856068611145/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:462: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(preprocess_cifar(eps_temp, perturbation=True)).reshape(1,-1,1,1)

Image 6 label 9 verification end, final lower bound 0.822856068611145, upper bound inf, time: 0.0004868507385253906
6 0.822856068611145
##### [0:6] Tested against 2 ######
Initial alpha-CROWN verified for label 2 with bound 2.1805293560028076
Image 6 label 2 verification end, final lower bound 2.1805293560028076, upper bound inf, time: 0.0003781318664550781
6 2.1805293560028076
##### [0:6] Tested against 3 ######
Initial alpha-CROWN verified for label 3 with bound 2.511579990386963
Image 6 label 3 verification end, final lower bound 2.511579990386963, upper bound inf, time: 0.00047898292541503906
6 2.511579990386963
##### [0:6] Tested against 4 ######
Initial alpha-CROWN verified for label 4 with bound 2.767686128616333
Image 6 label 4 verification end, final lower bound 2.767686128616333, upper bound inf, time: 0.00037741661071777344
6 2.767686128616333
##### [0:6] Tested against 7 ######
Initial alpha-CROWN verified for label 7 with bound 2.703956127166748
Image 6 label 7 verification end, final lower bound 2.703956127166748, upper bound inf, time: 0.0003712177276611328
6 2.703956127166748
##### [0:6] Tested against 5 ######
Initial alpha-CROWN verified for label 5 with bound 3.64284348487854
Image 6 label 5 verification end, final lower bound 3.64284348487854, upper bound inf, time: 0.0003666877746582031
6 3.64284348487854
##### [0:6] Tested against 6 ######
Initial alpha-CROWN verified for label 6 with bound 4.251789569854736
Image 6 label 6 verification end, final lower bound 4.251789569854736, upper bound inf, time: 0.00037550926208496094
6 4.251789569854736
##### [0:6] Tested against 0 ######
groundtruth label, skip!
Result: image 6 verification success (with branch and bound)!
Wall time: 21.85364079475403

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 1): [6]
verification failure idx (total 0): []
final verified acc: 100.0%[1]
verifier is called on 1 examples.
total verified: 1
mean time [cnt:1] (excluding attack success): 19.545220613479614
