Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_cnn_b_adv.model
  name: cnn_4layer_b
data:
  start: 18
  end: 19
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR_SDP
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.00784313725
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 256
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 90
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:09:14 2022 on diablo.cs.ucla.edu
Sequential(
  (0): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)
  (1): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2))
  (2): ReLU()
  (3): Conv2d(32, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (4): ReLU()
  (5): Flatten()
  (6): Linear(in_features=8192, out_features=250, bias=True)
  (7): ReLU()
  (8): Linear(in_features=250, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([200, 3, 32, 32]) torch.Size([200]) torch.Size([200])
X range: tensor(2.1256) tensor(-1.9889) tensor(-0.0131)
############################
epsilon after preprocessing: tensor([[[[0.0317]],

         [[0.0322]],

         [[0.0300]]]]), data_max = tensor([[[[2.0587]],

         [[2.1256]],

         [[2.1154]]]]), data_min = tensor([[[[-1.9889]],

         [[-1.9807]],

         [[-1.7076]]]])
Task length: 1
saving results to Verified_ret_[cnn_4layer_b]_start=18_end=19_iter=20_b=256_timeout=90_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 18 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 6, correct label 6, image norm 1670.1436767578125, logits tensor([-64.6945, -69.9097, -59.9142, -62.6577, -59.6494, -62.6440, -57.3551,
        -64.1125, -68.9975, -68.8836], device='cuda:0',
       grad_fn=<SelectBackward>)
##### PGD attack: True label: 6, Tested against: ['all'] ######
pgd prediction: tensor([-62.3256, -67.3247, -57.4575, -60.2253, -56.7546, -60.1252, -55.5857,
        -61.1704, -66.4811, -66.2763], device='cuda:0',
       grad_fn=<SqueezeBackward1>)
attack margin tensor([ 6.7399, 11.7390,  1.8718,  4.6396,  1.1690,  4.5395,     inf,  5.5847,
        10.8955, 10.6906], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[-64.6945, -69.9097, -59.9142, -62.6577, -59.6494, -62.6440, -57.3551,
         -64.1125, -68.9975, -68.8836]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 1.2833,  4.6484, -2.0698,  1.0010, -2.6499,  0.6610,  0.2936,  5.3297,
          3.7748]], device='cuda:0') None
best_l after optimization: -15.618361473083496 with beta sum per layer: []
alpha/beta optimization time: 8.208227634429932
initial alpha-CROWN bounds: tensor([[ 1.6419,  5.1426, -1.7619,  1.2367, -2.3528,  0.9104,  0.7260,  5.7915,
          4.2840]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-2.3528, device='cuda:0', grad_fn=<MinBackward1>)
Sorted order for labels to verify: [4, 2, 5, 3, 7, 0, 9, 8, 1, 6]
##### [0:18] Tested against 4 ######
Model prediction is: tensor([[-64.6945, -69.9097, -59.9142, -62.6577, -59.6494, -62.6440, -57.3551,
         -64.1125, -68.9975, -68.8836]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /34 start_node /35
setting alpha for layer /34 start_node /45
not setting layer /34 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /36 start_node /45
not setting layer /36 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /46 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /33 torch.Size([1, 32, 16, 16])
1 /35 torch.Size([1, 128, 8, 8])
2 /45 torch.Size([1, 250])
best_l after optimization: 2.352396011352539 with beta sum per layer: []
alpha/beta optimization time: 2.0135233402252197
alpha-CROWN with fixed intermediate bounds: tensor([[-2.3524]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-2.352396011352539
layer 0 size torch.Size([8192]) unstable 1094
layer 1 size torch.Size([8192]) unstable 884
layer 2 size torch.Size([250]) unstable 73
-----------------
# of unstable neurons: 2051
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 225] 
split level 1: [2, 160] 
split level 2: [2, 93] 
split level 3: [2, 114] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 16.20848846435547 with beta sum per layer: [0.0, 0.0, 0.8797717690467834]
alpha/beta optimization time: 0.2832949161529541
This batch time : update_bounds func: 0.2991	 prepare: 0.0099	 bound: 0.2867	 transfer: 0.0012	 finalize: 0.0012
Accumulated time: update_bounds func: 0.2991	 prepare: 0.0099	 bound: 0.2867	 transfer: 0.0012	 finalize: 0.0012
batch bounding time:  0.299208402633667
Current worst splitting domains [lb, ub] (depth):
[-1.45282,   inf] (5), [-1.41206,   inf] (5), [-1.39997,   inf] (5), [-1.32856,   inf] (5), [-1.14712,   inf] (5), [-1.12500,   inf] (5), [-1.10589,   inf] (5), [-1.08104,   inf] (5), [-1.07257,   inf] (5), [-1.06518,   inf] (5), [-0.94601,   inf] (5), [-0.87093,   inf] (5), [-0.61435,   inf] (5), [-0.60360,   inf] (5), [-0.51568,   inf] (5), [-0.46772,   inf] (5), 
length of domains: 16
Total time: 0.3327	 pickout: 0.0009	 decision: 0.0298	 get_bound: 0.3013	 add_domain: 0.0006
Current lb:-1.4528224468231201
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.2201666831970215

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([16, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([16, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 82] [2, 82] [2, 82] [2, 82] [2, 105] [2, 105] [2, 105] [2, 82] [2, 82] [2, 105] 
regular batch size: 2*16, diving batch size 1*0
best_l after optimization: 27.395709991455078 with beta sum per layer: [0.0, 0.0, 1.8788000345230103]
alpha/beta optimization time: 0.28304266929626465
This batch time : update_bounds func: 0.2912	 prepare: 0.0038	 bound: 0.2833	 transfer: 0.0018	 finalize: 0.0021
Accumulated time: update_bounds func: 0.5903	 prepare: 0.0137	 bound: 0.5701	 transfer: 0.0018	 finalize: 0.0033
batch bounding time:  0.29140639305114746
Current worst splitting domains [lb, ub] (depth):
[-1.30169,   inf] (7), [-1.29228,   inf] (7), [-1.25929,   inf] (7), [-1.25198,   inf] (7), [-1.25161,   inf] (7), [-1.23464,   inf] (7), [-1.18392,   inf] (7), [-1.16223,   inf] (7), [-0.99898,   inf] (7), [-0.99314,   inf] (7), [-0.97305,   inf] (7), [-0.97088,   inf] (7), [-0.95315,   inf] (7), [-0.95186,   inf] (7), [-0.92164,   inf] (7), [-0.91577,   inf] (7), [-0.91371,   inf] (7), [-0.91192,   inf] (7), [-0.91068,   inf] (7), [-0.90592,   inf] (7), 
length of domains: 32
Total time: 0.3230	 pickout: 0.0036	 decision: 0.0266	 get_bound: 0.2915	 add_domain: 0.0013
Current lb:-1.3016856908798218
48 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.5434885025024414

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([32, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([32, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 105] [2, 105] [2, 105] [2, 105] [2, 105] [2, 105] [2, 105] [2, 105] [2, 82] [2, 82] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: 44.77765655517578 with beta sum per layer: [0.0, 0.0, 3.963320732116699]
alpha/beta optimization time: 0.29421567916870117
This batch time : update_bounds func: 0.3095	 prepare: 0.0063	 bound: 0.2945	 transfer: 0.0046	 finalize: 0.0038
Accumulated time: update_bounds func: 0.8998	 prepare: 0.0201	 bound: 0.8646	 transfer: 0.0046	 finalize: 0.0072
batch bounding time:  0.30963945388793945
Current worst splitting domains [lb, ub] (depth):
[-1.15834,   inf] (9), [-1.15023,   inf] (9), [-1.14200,   inf] (9), [-1.13325,   inf] (9), [-1.11376,   inf] (9), [-1.10833,   inf] (9), [-1.10567,   inf] (9), [-1.10486,   inf] (9), [-1.09537,   inf] (9), [-1.09348,   inf] (9), [-1.08926,   inf] (9), [-1.07523,   inf] (9), [-1.03783,   inf] (9), [-1.03134,   inf] (9), [-1.01635,   inf] (9), [-1.00680,   inf] (9), [-0.85589,   inf] (9), [-0.85266,   inf] (9), [-0.83158,   inf] (9), [-0.83038,   inf] (9), 
length of domains: 64
Total time: 0.3515	 pickout: 0.0067	 decision: 0.0326	 get_bound: 0.3097	 add_domain: 0.0025
Current lb:-1.1583353281021118
112 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.895451545715332

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([64, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 214] [2, 214] [2, 214] [2, 214] [2, 214] [2, 214] [2, 214] [2, 214] [2, 214] [2, 214] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 66.69985961914062 with beta sum per layer: [0.0, 0.0, 10.638900756835938]
alpha/beta optimization time: 0.33768582344055176
This batch time : update_bounds func: 0.3748	 prepare: 0.0114	 bound: 0.3380	 transfer: 0.0172	 finalize: 0.0079
Accumulated time: update_bounds func: 1.2746	 prepare: 0.0315	 bound: 1.2025	 transfer: 0.0172	 finalize: 0.0150
batch bounding time:  0.3750574588775635
Current worst splitting domains [lb, ub] (depth):
[-1.03010,   inf] (11), [-1.02218,   inf] (11), [-1.01609,   inf] (11), [-1.00697,   inf] (11), [-0.99091,   inf] (11), [-0.98491,   inf] (11), [-0.98425,   inf] (11), [-0.97652,   inf] (11), [-0.97368,   inf] (11), [-0.96454,   inf] (11), [-0.96349,   inf] (11), [-0.96283,   inf] (11), [-0.95629,   inf] (11), [-0.94442,   inf] (11), [-0.94440,   inf] (11), [-0.94228,   inf] (11), [-0.91590,   inf] (11), [-0.91281,   inf] (11), [-0.90922,   inf] (11), [-0.90572,   inf] (11), 
length of domains: 113
Total time: 0.4460	 pickout: 0.0125	 decision: 0.0526	 get_bound: 0.3753	 add_domain: 0.0057
Current lb:-1.0300979614257812
240 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.342296361923218

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([113, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([113, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 168] [2, 168] [2, 168] [2, 168] [2, 168] [2, 168] [2, 168] [2, 168] [2, 168] [2, 168] 
regular batch size: 2*113, diving batch size 1*0
best_l after optimization: 67.26713562011719 with beta sum per layer: [0.0, 0.0, 26.032752990722656]
alpha/beta optimization time: 0.48264384269714355
This batch time : update_bounds func: 0.5369	 prepare: 0.0195	 bound: 0.4830	 transfer: 0.0205	 finalize: 0.0134
Accumulated time: update_bounds func: 1.8115	 prepare: 0.0510	 bound: 1.6855	 transfer: 0.0205	 finalize: 0.0284
batch bounding time:  0.5372397899627686
Current worst splitting domains [lb, ub] (depth):
[-0.93633,   inf] (13), [-0.92979,   inf] (13), [-0.92269,   inf] (13), [-0.91315,   inf] (13), [-0.89588,   inf] (13), [-0.89043,   inf] (13), [-0.88749,   inf] (13), [-0.88204,   inf] (13), [-0.87821,   inf] (13), [-0.87034,   inf] (13), [-0.86774,   inf] (13), [-0.86591,   inf] (13), [-0.86350,   inf] (13), [-0.85038,   inf] (13), [-0.84797,   inf] (13), [-0.84720,   inf] (13), [-0.81975,   inf] (13), [-0.81617,   inf] (13), [-0.81374,   inf] (13), [-0.80961,   inf] (13), 
length of domains: 175
Total time: 0.6445	 pickout: 0.0221	 decision: 0.0770	 get_bound: 0.5376	 add_domain: 0.0079
Current lb:-0.9363338351249695
466 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.9886109828948975

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([175, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([175, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 192] [2, 192] [2, 192] [2, 192] [2, 192] [2, 192] [2, 192] [2, 192] [2, 192] [2, 192] 
regular batch size: 2*175, diving batch size 1*0
best_l after optimization: 74.19229125976562 with beta sum per layer: [0.0, 0.0, 44.23857879638672]
alpha/beta optimization time: 0.631948709487915
This batch time : update_bounds func: 0.7103	 prepare: 0.0290	 bound: 0.6322	 transfer: 0.0285	 finalize: 0.0197
Accumulated time: update_bounds func: 2.5218	 prepare: 0.0800	 bound: 2.3177	 transfer: 0.0285	 finalize: 0.0481
batch bounding time:  0.710761547088623
Current worst splitting domains [lb, ub] (depth):
[-0.84994,   inf] (15), [-0.84158,   inf] (15), [-0.83418,   inf] (15), [-0.82331,   inf] (15), [-0.80965,   inf] (15), [-0.80348,   inf] (15), [-0.80028,   inf] (15), [-0.79697,   inf] (15), [-0.78977,   inf] (15), [-0.78340,   inf] (15), [-0.77932,   inf] (15), [-0.77870,   inf] (15), [-0.77651,   inf] (15), [-0.76199,   inf] (15), [-0.75885,   inf] (15), [-0.75787,   inf] (15), [-0.73350,   inf] (15), [-0.73078,   inf] (15), [-0.72655,   inf] (15), [-0.72256,   inf] (15), 
length of domains: 253
Total time: 0.8754	 pickout: 0.0339	 decision: 0.1177	 get_bound: 0.7113	 add_domain: 0.0125
Current lb:-0.8499400615692139
816 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.866644859313965

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([253, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([253, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 216] [2, 216] [2, 216] [2, 216] [2, 216] [2, 216] [2, 216] [2, 216] [2, 216] [2, 216] 
regular batch size: 2*253, diving batch size 1*0
best_l after optimization: 40.95175552368164 with beta sum per layer: [0.0, 0.0, 70.64839172363281]
alpha/beta optimization time: 0.8281290531158447
This batch time : update_bounds func: 1.0081	 prepare: 0.0414	 bound: 0.8285	 transfer: 0.0395	 finalize: 0.0975
Accumulated time: update_bounds func: 3.5299	 prepare: 0.1214	 bound: 3.1462	 transfer: 0.0395	 finalize: 0.1456
batch bounding time:  1.0087788105010986
Current worst splitting domains [lb, ub] (depth):
[-0.78260,   inf] (17), [-0.77573,   inf] (17), [-0.76595,   inf] (17), [-0.75627,   inf] (17), [-0.74145,   inf] (17), [-0.73630,   inf] (17), [-0.73140,   inf] (17), [-0.72799,   inf] (17), [-0.72146,   inf] (17), [-0.71315,   inf] (17), [-0.71293,   inf] (17), [-0.71084,   inf] (17), [-0.70895,   inf] (17), [-0.69332,   inf] (17), [-0.69096,   inf] (17), [-0.69004,   inf] (17), [-0.66457,   inf] (17), [-0.66061,   inf] (17), [-0.65902,   inf] (17), [-0.65264,   inf] (17), 
length of domains: 261
Total time: 1.2202	 pickout: 0.0498	 decision: 0.1473	 get_bound: 1.0096	 add_domain: 0.0135
Current lb:-0.7825961709022522
1322 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.091350555419922

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 117] [2, 117] [2, 117] [2, 117] [2, 117] [2, 117] [2, 117] [2, 117] [2, 117] [2, 117] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 71.89933013916016 with beta sum per layer: [0.0, 0.0, 57.61212158203125]
alpha/beta optimization time: 0.8416397571563721
This batch time : update_bounds func: 0.9703	 prepare: 0.0647	 bound: 0.8420	 transfer: 0.0330	 finalize: 0.0293
Accumulated time: update_bounds func: 4.5002	 prepare: 0.1861	 bound: 3.9882	 transfer: 0.0330	 finalize: 0.1748
batch bounding time:  0.9708502292633057
Current worst splitting domains [lb, ub] (depth):
[-0.71848,   inf] (19), [-0.71058,   inf] (19), [-0.70129,   inf] (19), [-0.69151,   inf] (19), [-0.67622,   inf] (19), [-0.67089,   inf] (19), [-0.66568,   inf] (19), [-0.66148,   inf] (19), [-0.65490,   inf] (19), [-0.64947,   inf] (19), [-0.64808,   inf] (19), [-0.64644,   inf] (19), [-0.64382,   inf] (19), [-0.62730,   inf] (19), [-0.62692,   inf] (19), [-0.62633,   inf] (19), [-0.60002,   inf] (19), [-0.59519,   inf] (19), [-0.59340,   inf] (19), [-0.58776,   inf] (19), 
length of domains: 360
Total time: 1.2301	 pickout: 0.0698	 decision: 0.1699	 get_bound: 0.9716	 add_domain: 0.0187
Current lb:-0.7184783816337585
1834 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.325531244277954

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 129] [2, 129] [2, 129] [2, 129] [2, 129] [2, 129] [2, 129] [2, 129] [2, 129] [2, 129] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: -52.33729934692383 with beta sum per layer: [0.0, 0.0, 40.34761047363281]
alpha/beta optimization time: 0.8148705959320068
This batch time : update_bounds func: 0.9332	 prepare: 0.0421	 bound: 0.8152	 transfer: 0.0456	 finalize: 0.0292
Accumulated time: update_bounds func: 5.4334	 prepare: 0.2282	 bound: 4.8034	 transfer: 0.0456	 finalize: 0.2040
batch bounding time:  0.9337751865386963
Current worst splitting domains [lb, ub] (depth):
[-0.66318,   inf] (21), [-0.65564,   inf] (21), [-0.64706,   inf] (21), [-0.63801,   inf] (21), [-0.62282,   inf] (21), [-0.61772,   inf] (21), [-0.61340,   inf] (21), [-0.60654,   inf] (21), [-0.60345,   inf] (21), [-0.59503,   inf] (21), [-0.59354,   inf] (21), [-0.59323,   inf] (21), [-0.58965,   inf] (21), [-0.57491,   inf] (21), [-0.57361,   inf] (21), [-0.57325,   inf] (21), [-0.54450,   inf] (21), [-0.53992,   inf] (21), [-0.53954,   inf] (21), [-0.53253,   inf] (21), 
length of domains: 360
Total time: 1.1476	 pickout: 0.0505	 decision: 0.1470	 get_bound: 0.9346	 add_domain: 0.0155
Current lb:-0.6631838083267212
2346 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.477631092071533

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 124] [2, 124] [2, 124] [2, 124] [2, 124] [2, 124] [2, 124] [2, 124] [2, 124] [2, 124] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: -4.831880569458008 with beta sum per layer: [0.0, 0.0, 71.73497009277344]
alpha/beta optimization time: 0.842494010925293
This batch time : update_bounds func: 0.9600	 prepare: 0.0421	 bound: 0.8428	 transfer: 0.0441	 finalize: 0.0299
Accumulated time: update_bounds func: 6.3935	 prepare: 0.2703	 bound: 5.6462	 transfer: 0.0441	 finalize: 0.2339
batch bounding time:  0.9606010913848877
Current worst splitting domains [lb, ub] (depth):
[-0.60505,   inf] (23), [-0.59879,   inf] (23), [-0.58881,   inf] (23), [-0.58099,   inf] (23), [-0.56479,   inf] (23), [-0.56036,   inf] (23), [-0.55585,   inf] (23), [-0.54825,   inf] (23), [-0.54671,   inf] (23), [-0.53853,   inf] (23), [-0.53703,   inf] (23), [-0.53481,   inf] (23), [-0.53238,   inf] (23), [-0.51720,   inf] (23), [-0.51662,   inf] (23), [-0.51659,   inf] (23), [-0.48816,   inf] (23), [-0.48371,   inf] (23), [-0.48037,   inf] (23), [-0.47498,   inf] (23), 
length of domains: 376
Total time: 1.2343	 pickout: 0.0530	 decision: 0.2043	 get_bound: 0.9613	 add_domain: 0.0157
Current lb:-0.6050522923469543
2858 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.716859340667725

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 196] [2, 196] [2, 196] [2, 196] [2, 196] [2, 196] [2, 196] [2, 196] [2, 196] [2, 196] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: -65.90731811523438 with beta sum per layer: [0.0, 0.0, 44.79546356201172]
alpha/beta optimization time: 0.8149063587188721
This batch time : update_bounds func: 0.9326	 prepare: 0.0429	 bound: 0.8152	 transfer: 0.0435	 finalize: 0.0296
Accumulated time: update_bounds func: 7.3261	 prepare: 0.3132	 bound: 6.4614	 transfer: 0.0435	 finalize: 0.2635
batch bounding time:  0.9331710338592529
Current worst splitting domains [lb, ub] (depth):
[-0.55571,   inf] (25), [-0.54922,   inf] (25), [-0.54015,   inf] (25), [-0.53206,   inf] (25), [-0.51639,   inf] (25), [-0.51220,   inf] (25), [-0.50800,   inf] (25), [-0.49953,   inf] (25), [-0.49876,   inf] (25), [-0.48732,   inf] (25), [-0.48650,   inf] (25), [-0.48513,   inf] (25), [-0.48354,   inf] (25), [-0.46849,   inf] (25), [-0.46575,   inf] (25), [-0.46536,   inf] (25), [-0.43743,   inf] (25), [-0.43351,   inf] (25), [-0.43343,   inf] (25), [-0.42693,   inf] (25), 
length of domains: 341
Total time: 1.1481	 pickout: 0.0540	 decision: 0.1467	 get_bound: 0.9339	 add_domain: 0.0134
Current lb:-0.555705726146698
3370 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.870168447494507

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 67] [2, 67] [2, 67] [2, 67] [2, 67] [2, 67] [2, 67] [2, 67] [2, 67] [2, 67] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 15.126596450805664 with beta sum per layer: [0.0, 0.0, 48.45908737182617]
alpha/beta optimization time: 0.834073543548584
This batch time : update_bounds func: 0.9672	 prepare: 0.0420	 bound: 0.8344	 transfer: 0.0456	 finalize: 0.0439
Accumulated time: update_bounds func: 8.2932	 prepare: 0.3552	 bound: 7.2958	 transfer: 0.0456	 finalize: 0.3074
batch bounding time:  0.9677784442901611
Current worst splitting domains [lb, ub] (depth):
[-0.49252,   inf] (27), [-0.48663,   inf] (27), [-0.48305,   inf] (27), [-0.47680,   inf] (27), [-0.47554,   inf] (27), [-0.46904,   inf] (27), [-0.46833,   inf] (27), [-0.46065,   inf] (27), [-0.45179,   inf] (27), [-0.44879,   inf] (27), [-0.44738,   inf] (27), [-0.44295,   inf] (27), [-0.44256,   inf] (27), [-0.43935,   inf] (27), [-0.43767,   inf] (27), [-0.43345,   inf] (27), [-0.43070,   inf] (27), [-0.42696,   inf] (27), [-0.42413,   inf] (27), [-0.42369,   inf] (27), 
length of domains: 382
Total time: 1.2313	 pickout: 0.0512	 decision: 0.1477	 get_bound: 0.9686	 add_domain: 0.0638
Current lb:-0.49252334237098694
3882 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.106340169906616

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 2] [2, 2] [2, 2] [2, 2] [2, 2] [2, 2] [2, 2] [2, 2] [2, 2] [2, 2] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 45.14704895019531 with beta sum per layer: [0.0, 0.0, 44.010711669921875]
alpha/beta optimization time: 0.8419437408447266
This batch time : update_bounds func: 0.9679	 prepare: 0.0644	 bound: 0.8423	 transfer: 0.0166	 finalize: 0.0433
Accumulated time: update_bounds func: 9.2611	 prepare: 0.4197	 bound: 8.1381	 transfer: 0.0166	 finalize: 0.3507
batch bounding time:  0.9685204029083252
Current worst splitting domains [lb, ub] (depth):
[-0.44131,   inf] (29), [-0.43571,   inf] (29), [-0.43192,   inf] (29), [-0.42480,   inf] (29), [-0.42417,   inf] (29), [-0.41753,   inf] (29), [-0.41693,   inf] (29), [-0.40948,   inf] (29), [-0.40101,   inf] (29), [-0.39807,   inf] (29), [-0.39680,   inf] (29), [-0.39195,   inf] (29), [-0.39128,   inf] (29), [-0.38749,   inf] (29), [-0.38660,   inf] (29), [-0.38197,   inf] (29), [-0.37909,   inf] (29), [-0.37443,   inf] (29), [-0.37235,   inf] (29), [-0.37202,   inf] (29), 
length of domains: 454
Total time: 1.2229	 pickout: 0.0659	 decision: 0.1657	 get_bound: 0.9694	 add_domain: 0.0220
Current lb:-0.4413139820098877
4394 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.334474325180054

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 17] [2, 140] [2, 17] [2, 17] [2, 140] [2, 17] [2, 140] [2, 140] [2, 140] [2, 140] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 30.383827209472656 with beta sum per layer: [0.0, 0.0, 43.3402099609375]
alpha/beta optimization time: 0.8162264823913574
This batch time : update_bounds func: 0.9607	 prepare: 0.0675	 bound: 0.8166	 transfer: 0.0457	 finalize: 0.0294
Accumulated time: update_bounds func: 10.2219	 prepare: 0.4872	 bound: 8.9547	 transfer: 0.0457	 finalize: 0.3801
batch bounding time:  0.9613149166107178
Current worst splitting domains [lb, ub] (depth):
[-0.39711,   inf] (31), [-0.39256,   inf] (31), [-0.38778,   inf] (31), [-0.38131,   inf] (31), [-0.37993,   inf] (31), [-0.37382,   inf] (31), [-0.37359,   inf] (31), [-0.36535,   inf] (31), [-0.35689,   inf] (31), [-0.35321,   inf] (31), [-0.35206,   inf] (31), [-0.34744,   inf] (31), [-0.34647,   inf] (31), [-0.34319,   inf] (31), [-0.34244,   inf] (31), [-0.33758,   inf] (31), [-0.33395,   inf] (31), [-0.33107,   inf] (31), [-0.32835,   inf] (31), [-0.32822,   inf] (31), 
length of domains: 520
Total time: 1.2267	 pickout: 0.0670	 decision: 0.1753	 get_bound: 0.9621	 add_domain: 0.0222
Current lb:-0.39710918068885803
4906 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.565718412399292

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 203] [2, 203] [2, 203] [2, 203] [2, 203] [2, 203] [2, 203] [2, 203] [2, 203] [2, 203] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 55.93070983886719 with beta sum per layer: [0.0, 0.0, 32.512550354003906]
alpha/beta optimization time: 0.8162264823913574
This batch time : update_bounds func: 0.9389	 prepare: 0.0432	 bound: 0.8166	 transfer: 0.0456	 finalize: 0.0324
Accumulated time: update_bounds func: 11.1608	 prepare: 0.5303	 bound: 9.7713	 transfer: 0.0456	 finalize: 0.4125
batch bounding time:  0.9395413398742676
Current worst splitting domains [lb, ub] (depth):
[-0.34827,   inf] (33), [-0.34380,   inf] (33), [-0.34090,   inf] (33), [-0.33922,   inf] (33), [-0.33707,   inf] (33), [-0.33330,   inf] (33), [-0.33125,   inf] (33), [-0.33059,   inf] (33), [-0.32576,   inf] (33), [-0.32492,   inf] (33), [-0.32473,   inf] (33), [-0.32448,   inf] (33), [-0.31795,   inf] (33), [-0.31721,   inf] (33), [-0.31662,   inf] (33), [-0.30982,   inf] (33), [-0.30921,   inf] (33), [-0.30544,   inf] (33), [-0.30472,   inf] (33), [-0.30040,   inf] (33), 
length of domains: 742
Total time: 1.2190	 pickout: 0.0514	 decision: 0.1919	 get_bound: 0.9403	 add_domain: 0.0355
Current lb:-0.3482731282711029
5418 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.788799285888672

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 73] [2, 73] [2, 73] [2, 73] [2, 73] [2, 73] [2, 73] [2, 73] [2, 73] [2, 73] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 63.81755447387695 with beta sum per layer: [0.0, 0.0, 26.19091796875]
alpha/beta optimization time: 0.8134381771087646
This batch time : update_bounds func: 0.9342	 prepare: 0.0422	 bound: 0.8137	 transfer: 0.0458	 finalize: 0.0311
Accumulated time: update_bounds func: 12.0950	 prepare: 0.5725	 bound: 10.5850	 transfer: 0.0458	 finalize: 0.4436
batch bounding time:  0.9347631931304932
Current worst splitting domains [lb, ub] (depth):
[-0.30268,   inf] (35), [-0.29800,   inf] (35), [-0.29508,   inf] (35), [-0.29335,   inf] (35), [-0.29126,   inf] (35), [-0.28946,   inf] (35), [-0.28513,   inf] (35), [-0.28439,   inf] (35), [-0.28202,   inf] (35), [-0.28146,   inf] (35), [-0.28091,   inf] (35), [-0.28030,   inf] (35), [-0.27848,   inf] (35), [-0.27782,   inf] (35), [-0.27353,   inf] (35), [-0.27308,   inf] (35), [-0.27290,   inf] (35), [-0.27228,   inf] (35), [-0.27190,   inf] (35), [-0.26978,   inf] (35), 
length of domains: 994
Total time: 1.1746	 pickout: 0.0533	 decision: 0.1473	 get_bound: 0.9355	 add_domain: 0.0385
Current lb:-0.3026791214942932
5930 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.967691898345947

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 140] [2, 17] [2, 140] [2, 140] [2, 17] [2, 140] [2, 17] [2, 140] [2, 140] [2, 140] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 10.516932487487793 with beta sum per layer: [0.0, 0.0, 35.33277130126953]
alpha/beta optimization time: 0.8162121772766113
This batch time : update_bounds func: 0.9860	 prepare: 0.0429	 bound: 0.8165	 transfer: 0.0436	 finalize: 0.0817
Accumulated time: update_bounds func: 13.0809	 prepare: 0.6154	 bound: 11.4016	 transfer: 0.0436	 finalize: 0.5252
batch bounding time:  0.9867205619812012
Current worst splitting domains [lb, ub] (depth):
[-0.25990,   inf] (37), [-0.25515,   inf] (37), [-0.25231,   inf] (37), [-0.24983,   inf] (37), [-0.24810,   inf] (37), [-0.24634,   inf] (37), [-0.24201,   inf] (37), [-0.24048,   inf] (37), [-0.23885,   inf] (37), [-0.23824,   inf] (37), [-0.23789,   inf] (37), [-0.23762,   inf] (37), [-0.23525,   inf] (37), [-0.23469,   inf] (37), [-0.23050,   inf] (37), [-0.22986,   inf] (37), [-0.22914,   inf] (37), [-0.22881,   inf] (37), [-0.22756,   inf] (37), [-0.22518,   inf] (37), 
length of domains: 1012
Total time: 1.2105	 pickout: 0.0548	 decision: 0.1467	 get_bound: 0.9876	 add_domain: 0.0214
Current lb:-0.2599044442176819
6442 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 19.18331003189087

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 230] [2, 230] [2, 230] [2, 230] [2, 230] [2, 230] [2, 230] [2, 230] [2, 230] [2, 230] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 1.8100299835205078 with beta sum per layer: [0.0, 0.0, 24.658998489379883]
alpha/beta optimization time: 0.8126053810119629
This batch time : update_bounds func: 0.9305	 prepare: 0.0424	 bound: 0.8129	 transfer: 0.0435	 finalize: 0.0303
Accumulated time: update_bounds func: 14.0115	 prepare: 0.6579	 bound: 12.2145	 transfer: 0.0435	 finalize: 0.5556
batch bounding time:  0.9311344623565674
Current worst splitting domains [lb, ub] (depth):
[-0.21726,   inf] (39), [-0.21451,   inf] (39), [-0.20976,   inf] (39), [-0.20755,   inf] (39), [-0.20748,   inf] (39), [-0.20421,   inf] (39), [-0.20146,   inf] (39), [-0.19817,   inf] (39), [-0.19700,   inf] (39), [-0.19676,   inf] (39), [-0.19563,   inf] (39), [-0.19518,   inf] (39), [-0.19410,   inf] (39), [-0.19297,   inf] (39), [-0.18952,   inf] (39), [-0.18883,   inf] (39), [-0.18734,   inf] (39), [-0.18682,   inf] (39), [-0.18548,   inf] (39), [-0.18399,   inf] (39), 
length of domains: 1016
Total time: 1.1540	 pickout: 0.0536	 decision: 0.1476	 get_bound: 0.9319	 add_domain: 0.0209
Current lb:-0.21726109087467194
6954 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 20.342159509658813

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 191] [2, 191] [2, 191] [2, 191] [2, 191] [2, 191] [2, 191] [2, 191] [2, 191] [2, 191] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: -1.6118106842041016 with beta sum per layer: [0.0, 0.0, 31.52353858947754]
alpha/beta optimization time: 0.8146731853485107
This batch time : update_bounds func: 0.9338	 prepare: 0.0437	 bound: 0.8150	 transfer: 0.0435	 finalize: 0.0302
Accumulated time: update_bounds func: 14.9452	 prepare: 0.7016	 bound: 13.0295	 transfer: 0.0435	 finalize: 0.5858
batch bounding time:  0.9343488216400146
Current worst splitting domains [lb, ub] (depth):
[-0.18023,   inf] (41), [-0.17789,   inf] (41), [-0.17291,   inf] (41), [-0.17116,   inf] (41), [-0.16973,   inf] (41), [-0.16671,   inf] (41), [-0.16435,   inf] (41), [-0.16093,   inf] (41), [-0.16009,   inf] (41), [-0.15897,   inf] (41), [-0.15866,   inf] (41), [-0.15796,   inf] (41), [-0.15741,   inf] (41), [-0.15644,   inf] (41), [-0.15280,   inf] (41), [-0.15143,   inf] (41), [-0.15066,   inf] (41), [-0.14914,   inf] (41), [-0.14818,   inf] (41), [-0.14765,   inf] (41), 
length of domains: 1034
Total time: 1.1591	 pickout: 0.0540	 decision: 0.1471	 get_bound: 0.9351	 add_domain: 0.0229
Current lb:-0.18023379147052765
7466 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 21.506444454193115

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 164] [2, 164] [2, 164] [2, 164] [2, 164] [2, 164] [2, 164] [2, 164] [2, 164] [2, 164] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: -11.643266677856445 with beta sum per layer: [0.0, 0.0, 30.721094131469727]
alpha/beta optimization time: 0.8280236721038818
This batch time : update_bounds func: 0.9467	 prepare: 0.0430	 bound: 0.8283	 transfer: 0.0436	 finalize: 0.0307
Accumulated time: update_bounds func: 15.8919	 prepare: 0.7445	 bound: 13.8578	 transfer: 0.0436	 finalize: 0.6165
batch bounding time:  0.9473056793212891
Current worst splitting domains [lb, ub] (depth):
[-0.15066,   inf] (43), [-0.14844,   inf] (43), [-0.14302,   inf] (43), [-0.14137,   inf] (43), [-0.13974,   inf] (43), [-0.13735,   inf] (43), [-0.13499,   inf] (43), [-0.13088,   inf] (43), [-0.13085,   inf] (43), [-0.12958,   inf] (43), [-0.12886,   inf] (43), [-0.12813,   inf] (43), [-0.12805,   inf] (43), [-0.12659,   inf] (43), [-0.12309,   inf] (43), [-0.12202,   inf] (43), [-0.12118,   inf] (43), [-0.11958,   inf] (43), [-0.11819,   inf] (43), [-0.11785,   inf] (43), 
length of domains: 1038
Total time: 1.2216	 pickout: 0.0539	 decision: 0.1971	 get_bound: 0.9481	 add_domain: 0.0224
Current lb:-0.15066491067409515
7978 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 22.733551263809204

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 248] [2, 248] [2, 248] [2, 248] [2, 248] [2, 248] [2, 248] [2, 248] [2, 248] [2, 248] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: -13.319931983947754 with beta sum per layer: [0.0, 0.0, 29.22241973876953]
alpha/beta optimization time: 0.8143236637115479
This batch time : update_bounds func: 0.9345	 prepare: 0.0434	 bound: 0.8146	 transfer: 0.0435	 finalize: 0.0317
Accumulated time: update_bounds func: 16.8265	 prepare: 0.7879	 bound: 14.6724	 transfer: 0.0435	 finalize: 0.6482
batch bounding time:  0.9351181983947754
Current worst splitting domains [lb, ub] (depth):
[-0.12243,   inf] (45), [-0.12008,   inf] (45), [-0.11509,   inf] (45), [-0.11355,   inf] (45), [-0.11109,   inf] (45), [-0.10900,   inf] (45), [-0.10686,   inf] (45), [-0.10257,   inf] (45), [-0.10245,   inf] (45), [-0.10110,   inf] (45), [-0.10036,   inf] (45), [-0.10013,   inf] (45), [-0.09966,   inf] (45), [-0.09817,   inf] (45), [-0.09504,   inf] (45), [-0.09350,   inf] (45), [-0.09298,   inf] (45), [-0.09110,   inf] (45), [-0.08964,   inf] (45), [-0.08958,   inf] (45), 
length of domains: 1037
Total time: 1.1592	 pickout: 0.0537	 decision: 0.1484	 get_bound: 0.9359	 add_domain: 0.0212
Current lb:-0.12242879718542099
8490 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 23.898457288742065

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 150] [2, 150] [2, 150] [2, 150] [2, 150] [2, 150] [2, 150] [2, 150] [2, 150] [2, 150] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: -14.691518783569336 with beta sum per layer: [0.0, 0.0, 27.195356369018555]
alpha/beta optimization time: 0.8345563411712646
This batch time : update_bounds func: 0.9538	 prepare: 0.0442	 bound: 0.8349	 transfer: 0.0415	 finalize: 0.0318
Accumulated time: update_bounds func: 17.7803	 prepare: 0.8321	 bound: 15.5073	 transfer: 0.0415	 finalize: 0.6799
batch bounding time:  0.9543724060058594
Current worst splitting domains [lb, ub] (depth):
[-0.09604,   inf] (47), [-0.09368,   inf] (47), [-0.08856,   inf] (47), [-0.08688,   inf] (47), [-0.08464,   inf] (47), [-0.08235,   inf] (47), [-0.08054,   inf] (47), [-0.07630,   inf] (47), [-0.07606,   inf] (47), [-0.07452,   inf] (47), [-0.07418,   inf] (47), [-0.07378,   inf] (47), [-0.07315,   inf] (47), [-0.07223,   inf] (47), [-0.06852,   inf] (47), [-0.06695,   inf] (47), [-0.06646,   inf] (47), [-0.06501,   inf] (47), [-0.06352,   inf] (47), [-0.06346,   inf] (47), 
length of domains: 963
Total time: 1.1738	 pickout: 0.0551	 decision: 0.1478	 get_bound: 0.9552	 add_domain: 0.0157
Current lb:-0.09603875875473022
9002 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 25.07883334159851

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 88] [2, 65] [2, 88] [2, 65] [2, 88] [2, 88] [2, 65] [2, 88] [2, 65] [2, 88] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: -15.453265190124512 with beta sum per layer: [0.0, 0.0, 27.255475997924805]
alpha/beta optimization time: 0.8294320106506348
This batch time : update_bounds func: 0.9475	 prepare: 0.0433	 bound: 0.8297	 transfer: 0.0415	 finalize: 0.0317
Accumulated time: update_bounds func: 18.7278	 prepare: 0.8754	 bound: 16.3370	 transfer: 0.0415	 finalize: 0.7117
batch bounding time:  0.9481077194213867
Current worst splitting domains [lb, ub] (depth):
[-0.07010,   inf] (49), [-0.06749,   inf] (49), [-0.06261,   inf] (49), [-0.06039,   inf] (49), [-0.05915,   inf] (49), [-0.05628,   inf] (49), [-0.05455,   inf] (49), [-0.05265,   inf] (49), [-0.05074,   inf] (49), [-0.05045,   inf] (49), [-0.04889,   inf] (49), [-0.04827,   inf] (49), [-0.04798,   inf] (49), [-0.04771,   inf] (49), [-0.04675,   inf] (49), [-0.04621,   inf] (49), [-0.04266,   inf] (49), [-0.04163,   inf] (49), [-0.04014,   inf] (49), [-0.04001,   inf] (49), 
length of domains: 831
Total time: 1.2351	 pickout: 0.0556	 decision: 0.2190	 get_bound: 0.9489	 add_domain: 0.0117
Current lb:-0.0700998306274414
9514 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 26.32109260559082

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 65] [2, 88] [2, 65] [2, 88] [2, 65] [2, 65] [2, 88] [2, 88] [2, 65] [2, 88] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: -26.996524810791016 with beta sum per layer: [0.0, 0.0, 30.12291717529297]
alpha/beta optimization time: 0.8473823070526123
This batch time : update_bounds func: 0.9783	 prepare: 0.0437	 bound: 0.8477	 transfer: 0.0446	 finalize: 0.0410
Accumulated time: update_bounds func: 19.7061	 prepare: 0.9191	 bound: 17.1847	 transfer: 0.0446	 finalize: 0.7527
batch bounding time:  0.9789824485778809
Current worst splitting domains [lb, ub] (depth):
[-0.04435,   inf] (51), [-0.04219,   inf] (51), [-0.03638,   inf] (51), [-0.03505,   inf] (51), [-0.03350,   inf] (51), [-0.03117,   inf] (51), [-0.02958,   inf] (51), [-0.02877,   inf] (51), [-0.02676,   inf] (51), [-0.02528,   inf] (51), [-0.02481,   inf] (51), [-0.02397,   inf] (51), [-0.02352,   inf] (51), [-0.02234,   inf] (51), [-0.02224,   inf] (51), [-0.02222,   inf] (51), [-0.02161,   inf] (51), [-0.02099,   inf] (51), [-0.01806,   inf] (37), [-0.01805,   inf] (35), 
length of domains: 622
Total time: 1.1895	 pickout: 0.0561	 decision: 0.1488	 get_bound: 0.9798	 add_domain: 0.0048
Current lb:-0.04435014724731445
10026 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 27.518359184265137

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 156] [2, 156] [2, 156] [2, 156] [2, 156] [2, 156] [2, 156] [2, 156] [2, 156] [2, 156] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: -42.333106994628906 with beta sum per layer: [0.0, 0.0, 37.78524398803711]
alpha/beta optimization time: 0.8147053718566895
This batch time : update_bounds func: 0.9817	 prepare: 0.0436	 bound: 0.8150	 transfer: 0.0414	 finalize: 0.0803
Accumulated time: update_bounds func: 20.6878	 prepare: 0.9628	 bound: 17.9997	 transfer: 0.0414	 finalize: 0.8330
batch bounding time:  0.9822795391082764
Current worst splitting domains [lb, ub] (depth):
[-0.02473,   inf] (53), [-0.02310,   inf] (53), [-0.01683,   inf] (53), [-0.01611,   inf] (53), [-0.01406,   inf] (53), [-0.01169,   inf] (53), [-0.01055,   inf] (37), [-0.01053,   inf] (53), [-0.01047,   inf] (31), [-0.01045,   inf] (43), [-0.01039,   inf] (51), [-0.01038,   inf] (25), [-0.01037,   inf] (35), [-0.01030,   inf] (49), [-0.01027,   inf] (39), [-0.01023,   inf] (37), [-0.01022,   inf] (17), [-0.01020,   inf] (41), [-0.01020,   inf] (33), [-0.01020,   inf] (35), 
length of domains: 384
Total time: 1.1907	 pickout: 0.0570	 decision: 0.1485	 get_bound: 0.9831	 add_domain: 0.0021
Current lb:-0.02473483793437481
10538 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 28.71609592437744

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 4259] [1, 4259] [1, 4259] [1, 4259] [1, 988] [1, 4957] [2, 230] [1, 4957] [2, 203] [2, 248] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: -42.863101959228516 with beta sum per layer: [0.0, 0.0, 36.35955810546875]
alpha/beta optimization time: 0.8268067836761475
This batch time : update_bounds func: 0.9495	 prepare: 0.0441	 bound: 0.8271	 transfer: 0.0456	 finalize: 0.0313
Accumulated time: update_bounds func: 21.6373	 prepare: 1.0069	 bound: 18.8269	 transfer: 0.0456	 finalize: 0.8643
batch bounding time:  0.9500973224639893
Current worst splitting domains [lb, ub] (depth):
[-0.01252,   inf] (55), [-0.00981,   inf] (55), [-0.00453,   inf] (55), [-0.00325,   inf] (33), [-0.00325,   inf] (41), [-0.00321,   inf] (27), [-0.00319,   inf] (29), [-0.00319,   inf] (47), [-0.00312,   inf] (43), [-0.00310,   inf] (39), [-0.00309,   inf] (39), [-0.00308,   inf] (31), [-0.00307,   inf] (39), [-0.00306,   inf] (41), [-0.00304,   inf] (33), [-0.00302,   inf] (39), [-0.00302,   inf] (51), [-0.00302,   inf] (33), [-0.00301,   inf] (25), [-0.00300,   inf] (37), 
length of domains: 133
Total time: 1.1528	 pickout: 0.0545	 decision: 0.1465	 get_bound: 0.9509	 add_domain: 0.0008
Current lb:-0.012521888129413128
11050 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 29.87584686279297

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([133, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([133, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 988] [1, 7579] [1, 988] [2, 73] [2, 164] [2, 2] [2, 230] [2, 150] [2, 248] [2, 191] 
regular batch size: 2*133, diving batch size 1*0
best_l after optimization: -22.70456886291504 with beta sum per layer: [0.0, 0.0, 19.079082489013672]
alpha/beta optimization time: 0.5312380790710449
This batch time : update_bounds func: 0.5785	 prepare: 0.0235	 bound: 0.5315	 transfer: 0.0071	 finalize: 0.0157
Accumulated time: update_bounds func: 22.2157	 prepare: 1.0304	 bound: 19.3584	 transfer: 0.0071	 finalize: 0.8800
batch bounding time:  0.5788359642028809
Current worst splitting domains [lb, ub] (depth):
[-0.00046,   inf] (57), 
length of domains: 1
Total time: 0.6930	 pickout: 0.0280	 decision: 0.0855	 get_bound: 0.5792	 add_domain: 0.0003
Current lb:-0.0004635753866750747
11316 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 30.57378649711609

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [1, 7579] 
split level 1: [1, 4957] 
split level 2: [1, 5853] 
split level 3: [1, 987] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -1.1083111763000488 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.01013946533203125
This batch time : update_bounds func: 0.0159	 prepare: 0.0029	 bound: 0.0104	 transfer: 0.0014	 finalize: 0.0011
Accumulated time: update_bounds func: 22.2316	 prepare: 1.0333	 bound: 19.3688	 transfer: 0.0014	 finalize: 0.8811
batch bounding time:  0.015930891036987305
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0493	 pickout: 0.0010	 decision: 0.0297	 get_bound: 0.0186	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 30.628170251846313

Image 18 label 4 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 30.712115049362183
18 1.0000000116860974e-07
##### [0:18] Tested against 2 ######
Model prediction is: tensor([[-64.6945, -69.9097, -59.9142, -62.6577, -59.6494, -62.6440, -57.3551,
         -64.1125, -68.9975, -68.8836]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /34 start_node /35
setting alpha for layer /34 start_node /45
not setting layer /34 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /36 start_node /45
not setting layer /36 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /46 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /33 torch.Size([1, 32, 16, 16])
1 /35 torch.Size([1, 128, 8, 8])
2 /45 torch.Size([1, 250])
best_l after optimization: 1.761486530303955 with beta sum per layer: []
alpha/beta optimization time: 1.190964698791504
alpha-CROWN with fixed intermediate bounds: tensor([[-1.7615]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-1.761486530303955
layer 0 size torch.Size([8192]) unstable 1094
layer 1 size torch.Size([8192]) unstable 884
layer 2 size torch.Size([250]) unstable 73
-----------------
# of unstable neurons: 2051
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 65] 
split level 1: [2, 156] 
split level 2: [2, 248] 
split level 3: [2, 150] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 3.5528855323791504 with beta sum per layer: [0.0, 0.0, 0.19217364490032196]
alpha/beta optimization time: 0.31722235679626465
This batch time : update_bounds func: 0.3293	 prepare: 0.0064	 bound: 0.3204	 transfer: 0.0012	 finalize: 0.0012
Accumulated time: update_bounds func: 22.5609	 prepare: 1.0397	 bound: 19.6892	 transfer: 0.0012	 finalize: 0.8823
batch bounding time:  0.32939815521240234
Current worst splitting domains [lb, ub] (depth):
[-0.69167,   inf] (5), [-0.68687,   inf] (5), [-0.64248,   inf] (5), [-0.63393,   inf] (5), [-0.46266,   inf] (5), [-0.46007,   inf] (5), [-0.39313,   inf] (5), [-0.37111,   inf] (5), [-0.02819,   inf] (5), 
length of domains: 9
Total time: 0.3635	 pickout: 0.0029	 decision: 0.0287	 get_bound: 0.3315	 add_domain: 0.0004
Current lb:-0.6916691660881042
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.59086275100708

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([9, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([9, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 97] [2, 97] [2, 33] [2, 33] [2, 97] [2, 97] [2, 97] [2, 97] [2, 33] 
regular batch size: 2*9, diving batch size 1*0
best_l after optimization: 4.082614421844482 with beta sum per layer: [0.0, 0.0, 0.5562369227409363]
alpha/beta optimization time: 0.28163862228393555
This batch time : update_bounds func: 0.2873	 prepare: 0.0028	 bound: 0.2819	 transfer: 0.0012	 finalize: 0.0013
Accumulated time: update_bounds func: 22.8482	 prepare: 1.0424	 bound: 19.9711	 transfer: 0.0012	 finalize: 0.8836
batch bounding time:  0.2874636650085449
Current worst splitting domains [lb, ub] (depth):
[-0.54696,   inf] (7), [-0.54007,   inf] (7), [-0.49329,   inf] (7), [-0.48195,   inf] (7), [-0.35626,   inf] (7), [-0.35436,   inf] (7), [-0.30750,   inf] (7), [-0.30650,   inf] (7), [-0.23546,   inf] (7), [-0.21476,   inf] (7), [-0.17589,   inf] (7), [-0.14845,   inf] (7), [-0.13793,   inf] (7), [-0.13439,   inf] (7), [-0.09172,   inf] (7), [-0.05764,   inf] (7), 
length of domains: 16
Total time: 0.3150	 pickout: 0.0025	 decision: 0.0244	 get_bound: 0.2875	 add_domain: 0.0006
Current lb:-0.5469619035720825
34 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.9061014652252197

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([16, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([16, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 33] [2, 33] [2, 97] [2, 97] [2, 33] [2, 33] [2, 33] [2, 33] [2, 33] [2, 33] 
regular batch size: 2*16, diving batch size 1*0
best_l after optimization: 0.4288511276245117 with beta sum per layer: [0.0, 0.0, 1.215440034866333]
alpha/beta optimization time: 0.28022241592407227
This batch time : update_bounds func: 0.2884	 prepare: 0.0039	 bound: 0.2805	 transfer: 0.0018	 finalize: 0.0021
Accumulated time: update_bounds func: 23.1366	 prepare: 1.0463	 bound: 20.2516	 transfer: 0.0018	 finalize: 0.8857
batch bounding time:  0.2885758876800537
Current worst splitting domains [lb, ub] (depth):
[-0.40855,   inf] (9), [-0.39453,   inf] (9), [-0.34642,   inf] (9), [-0.33788,   inf] (9), [-0.21467,   inf] (9), [-0.20871,   inf] (9), [-0.17649,   inf] (9), [-0.16990,   inf] (9), [-0.16543,   inf] (9), [-0.15268,   inf] (9), [-0.09082,   inf] (9), [-0.07119,   inf] (9), [-0.05166,   inf] (9), [-0.03717,   inf] (9), [-0.02196,   inf] (9), [-0.00177,   inf] (9), 
length of domains: 16
Total time: 0.3195	 pickout: 0.0039	 decision: 0.0263	 get_bound: 0.2886	 add_domain: 0.0007
Current lb:-0.4085499346256256
66 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.2259511947631836

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([16, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([16, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 105] [2, 168] [2, 168] [2, 168] [2, 105] [2, 168] [2, 168] [2, 105] [2, 168] [2, 168] 
regular batch size: 2*16, diving batch size 1*0
best_l after optimization: -0.9187989234924316 with beta sum per layer: [0.0, 0.0, 1.0693471431732178]
alpha/beta optimization time: 0.2894759178161621
This batch time : update_bounds func: 0.2977	 prepare: 0.0039	 bound: 0.2898	 transfer: 0.0018	 finalize: 0.0021
Accumulated time: update_bounds func: 23.4343	 prepare: 1.0502	 bound: 20.5414	 transfer: 0.0018	 finalize: 0.8878
batch bounding time:  0.29781103134155273
Current worst splitting domains [lb, ub] (depth):
[-0.30142,   inf] (11), [-0.29848,   inf] (11), [-0.28134,   inf] (11), [-0.23209,   inf] (11), [-0.22785,   inf] (11), [-0.10621,   inf] (11), [-0.10125,   inf] (11), [-0.08938,   inf] (11), [-0.05998,   inf] (11), [-0.05899,   inf] (11), [-0.05252,   inf] (11), [-0.04973,   inf] (11), [-0.03975,   inf] (11), 
length of domains: 13
Total time: 0.3288	 pickout: 0.0037	 decision: 0.0266	 get_bound: 0.2979	 add_domain: 0.0006
Current lb:-0.30141836404800415
98 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.555077075958252

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([13, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([13, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 168] [2, 168] [2, 105] [2, 105] [2, 105] [2, 168] [2, 168] [2, 105] [2, 168] [2, 168] 
regular batch size: 2*13, diving batch size 1*0
best_l after optimization: -0.5749151110649109 with beta sum per layer: [0.0, 0.0, 0.4989832937717438]
alpha/beta optimization time: 0.30139756202697754
This batch time : update_bounds func: 0.3085	 prepare: 0.0034	 bound: 0.3017	 transfer: 0.0016	 finalize: 0.0018
Accumulated time: update_bounds func: 23.7428	 prepare: 1.0536	 bound: 20.8430	 transfer: 0.0016	 finalize: 0.8896
batch bounding time:  0.30867838859558105
Current worst splitting domains [lb, ub] (depth):
[-0.20117,   inf] (13), [-0.19942,   inf] (13), [-0.17269,   inf] (13), [-0.17231,   inf] (13), [-0.12955,   inf] (13), [-0.12754,   inf] (13), [-0.11608,   inf] (13), [-0.11078,   inf] (13), 
length of domains: 8
Total time: 0.3501	 pickout: 0.0032	 decision: 0.0378	 get_bound: 0.3087	 add_domain: 0.0004
Current lb:-0.20117127895355225
124 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.9055347442626953

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([8, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 124] [2, 124] [2, 124] [2, 124] [2, 225] [2, 124] [2, 225] [2, 124] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.6321158409118652 with beta sum per layer: [0.0, 0.0, 0.0021010839845985174]
alpha/beta optimization time: 0.2797675132751465
This batch time : update_bounds func: 0.2851	 prepare: 0.0026	 bound: 0.2800	 transfer: 0.0011	 finalize: 0.0012
Accumulated time: update_bounds func: 24.0279	 prepare: 1.0563	 bound: 21.1231	 transfer: 0.0011	 finalize: 0.8908
batch bounding time:  0.2852201461791992
Current worst splitting domains [lb, ub] (depth):
[-0.13387,   inf] (15)/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:462: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(preprocess_cifar(eps_temp, perturbation=True)).reshape(1,-1,1,1)
, [-0.13191,   inf] (15), [-0.10045,   inf] (15), [-0.10026,   inf] (15), [-0.06225,   inf] (15), [-0.06138,   inf] (15), [-0.05941,   inf] (15), [-0.04889,   inf] (15), [-0.04835,   inf] (15), [-0.04260,   inf] (15), 
length of domains: 10
Total time: 0.3124	 pickout: 0.0022	 decision: 0.0243	 get_bound: 0.2853	 add_domain: 0.0006
Current lb:-0.1338711529970169
140 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.218122959136963

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([10, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([10, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 225] [2, 225] [2, 225] [2, 225] [2, 214] [2, 214] [2, 214] [2, 214] [2, 214] [2, 214] 
regular batch size: 2*10, diving batch size 1*0
best_l after optimization: 0.010136641561985016 with beta sum per layer: [0.0, 0.0, 0.00539902038872242]
alpha/beta optimization time: 0.3034956455230713
This batch time : update_bounds func: 0.3123	 prepare: 0.0056	 bound: 0.3039	 transfer: 0.0013	 finalize: 0.0014
Accumulated time: update_bounds func: 24.3402	 prepare: 1.0618	 bound: 21.4270	 transfer: 0.0013	 finalize: 0.8922
batch bounding time:  0.31241750717163086
Current worst splitting domains [lb, ub] (depth):
[-0.06767,   inf] (17), [-0.06639,   inf] (17), [-0.06521,   inf] (17), [-0.06319,   inf] (17), [-0.03722,   inf] (17), [-0.03622,   inf] (17), [-0.03029,   inf] (17), [-0.02931,   inf] (17), 
length of domains: 8
Total time: 0.3405	 pickout: 0.0026	 decision: 0.0250	 get_bound: 0.3125	 add_domain: 0.0005
Current lb:-0.06767138093709946
160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.558865785598755

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([8, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 82] [2, 214] [2, 82] [2, 214] [2, 214] [2, 82] [2, 82] [2, 214] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.41337689757347107 with beta sum per layer: [0.0, 0.0, 0.006131109781563282]
alpha/beta optimization time: 0.32962870597839355
This batch time : update_bounds func: 0.3380	 prepare: 0.0053	 bound: 0.3300	 transfer: 0.0011	 finalize: 0.0014
Accumulated time: update_bounds func: 24.6782	 prepare: 1.0671	 bound: 21.7570	 transfer: 0.0011	 finalize: 0.8936
batch bounding time:  0.3381519317626953
Current worst splitting domains [lb, ub] (depth):
[-0.00764,   inf] (19), [-0.00589,   inf] (19), [-0.00530,   inf] (19), [-0.00273,   inf] (19), [-0.00264,   inf] (19), 
length of domains: 5
Total time: 0.3675	 pickout: 0.0022	 decision: 0.0267	 get_bound: 0.3382	 add_domain: 0.0004
Current lb:-0.007642801385372877
176 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.926588535308838

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([5, 32, 16, 16]) pre split depth:  2
batch:  torch.Size([5, 32, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [2, 84] [2, 84] [2, 84] [2, 84] [2, 84] 
split level 1: [2, 214] [2, 82] [2, 214] [2, 214] [2, 82] 
regular batch size: 2*10, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -2.6887855529785156 with beta sum per layer: [0.0, 0.0, 0.006277106236666441]
alpha/beta optimization time: 0.011214971542358398
This batch time : update_bounds func: 0.0177	 prepare: 0.0035	 bound: 0.0115	 transfer: 0.0013	 finalize: 0.0013
Accumulated time: update_bounds func: 24.6959	 prepare: 1.0707	 bound: 21.7685	 transfer: 0.0013	 finalize: 0.8949
batch bounding time:  0.017748594284057617
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0458	 pickout: 0.0017	 decision: 0.0245	 get_bound: 0.0195	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 3.972658395767212

Image 18 label 2 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 4.057543754577637
18 1.0000000116860974e-07
##### [0:18] Tested against 5 ######
Initial alpha-CROWN verified for label 5 with bound 0.9104270935058594
Image 18 label 5 verification end, final lower bound 0.9104270935058594, upper bound inf, time: 0.0003838539123535156
18 0.9104270935058594
##### [0:18] Tested against 3 ######
Initial alpha-CROWN verified for label 3 with bound 1.2366596460342407
Image 18 label 3 verification end, final lower bound 1.2366596460342407, upper bound inf, time: 0.0003643035888671875
18 1.2366596460342407
##### [0:18] Tested against 7 ######
Initial alpha-CROWN verified for label 7 with bound 0.7259576320648193
Image 18 label 7 verification end, final lower bound 0.7259576320648193, upper bound inf, time: 0.00037407875061035156
18 0.7259576320648193
##### [0:18] Tested against 0 ######
Initial alpha-CROWN verified for label 0 with bound 1.6418976783752441
Image 18 label 0 verification end, final lower bound 1.6418976783752441, upper bound inf, time: 0.0003733634948730469
18 1.6418976783752441
##### [0:18] Tested against 9 ######
Initial alpha-CROWN verified for label 9 with bound 4.283985137939453
Image 18 label 9 verification end, final lower bound 4.283985137939453, upper bound inf, time: 0.00036072731018066406
18 4.283985137939453
##### [0:18] Tested against 8 ######
Initial alpha-CROWN verified for label 8 with bound 5.791500568389893
Image 18 label 8 verification end, final lower bound 5.791500568389893, upper bound inf, time: 0.0003612041473388672
18 5.791500568389893
##### [0:18] Tested against 1 ######
Initial alpha-CROWN verified for label 1 with bound 5.142576694488525
Image 18 label 1 verification end, final lower bound 5.142576694488525, upper bound inf, time: 0.0003631114959716797
18 5.142576694488525
##### [0:18] Tested against 6 ######
groundtruth label, skip!
Result: image 18 verification success (with branch and bound)!
Wall time: 47.1072633266449

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 1): [18]
verification failure idx (total 0): []
final verified acc: 100.0%[1]
verifier is called on 1 examples.
total verified: 1
mean time [cnt:1] (excluding attack success): 44.713985443115234
