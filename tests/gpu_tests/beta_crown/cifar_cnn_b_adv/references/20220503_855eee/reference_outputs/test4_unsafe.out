Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_cnn_b_adv.model
  name: cnn_4layer_b
data:
  start: 192
  end: 193
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR_SDP
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.00784313725
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 256
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 90
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:10:46 2022 on diablo.cs.ucla.edu
Sequential(
  (0): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)
  (1): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2))
  (2): ReLU()
  (3): Conv2d(32, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (4): ReLU()
  (5): Flatten()
  (6): Linear(in_features=8192, out_features=250, bias=True)
  (7): ReLU()
  (8): Linear(in_features=250, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([200, 3, 32, 32]) torch.Size([200]) torch.Size([200])
X range: tensor(2.1256) tensor(-1.9889) tensor(-0.0131)
############################
epsilon after preprocessing: tensor([[[[0.0317]],

         [[0.0322]],

         [[0.0300]]]]), data_max = tensor([[[[2.0587]],

         [[2.1256]],

         [[2.1154]]]]), data_min = tensor([[[[-1.9889]],

         [[-1.9807]],

         [[-1.7076]]]])
Task length: 1
saving results to Verified_ret_[cnn_4layer_b]_start=192_end=193_iter=20_b=256_timeout=90_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 192 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 2, correct label 2, image norm 1951.165283203125, logits tensor([-60.9434, -64.6752, -55.7020, -60.0135, -58.1674, -60.4250, -56.9600,
        -61.1792, -65.4126, -64.7254], device='cuda:0',
       grad_fn=<SelectBackward>)
Model prediction is: tensor([[-60.9434, -64.6752, -55.7020, -60.0135, -58.1674, -60.4250, -56.9600,
         -61.1792, -65.4126, -64.7254]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 0.3525,  3.2184,  0.0061, -1.6004,  0.0098, -3.1956, -0.8580,  4.5858,
          3.4038]], device='cuda:0') None
best_l after optimization: -8.206768989562988 with beta sum per layer: []
alpha/beta optimization time: 8.44644021987915
initial alpha-CROWN bounds: tensor([[ 0.6315,  3.5563,  0.2109, -1.4017,  0.2162, -2.9348, -0.5666,  4.8171,
          3.6778]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-2.9348, device='cuda:0', grad_fn=<MinBackward1>)
##### [0:192] Tested against 6 ######
Model prediction is: tensor([[-60.9434, -64.6752, -55.7020, -60.0135, -58.1674, -60.4250, -56.9600,
         -61.1792, -65.4126, -64.7254]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /34 start_node /35
setting alpha for layer /34 start_node /45
not setting layer /34 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /36 start_node /45
not setting layer /36 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /46 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /33 torch.Size([1, 32, 16, 16])
1 /35 torch.Size([1, 128, 8, 8])
2 /45 torch.Size([1, 250])
best_l after optimization: 2.9344632625579834 with beta sum per layer: []
alpha/beta optimization time: 1.9960739612579346
alpha-CROWN with fixed intermediate bounds: tensor([[-2.9345]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-2.9344632625579834
layer 0 size torch.Size([8192]) unstable 1349
layer 1 size torch.Size([8192]) unstable 888
layer 2 size torch.Size([250]) unstable 65
-----------------
# of unstable neurons: 2302
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 142] 
split level 1: [2, 57] 
split level 2: [2, 122] 
split level 3: [2, 89] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 23.21611785888672 with beta sum per layer: [0.0, 0.0, 0.8867591619491577]
alpha/beta optimization time: 0.28441667556762695
This batch time : update_bounds func: 0.2910	 prepare: 0.0031	 bound: 0.2850	 transfer: 0.0016	 finalize: 0.0013
Accumulated time: update_bounds func: 0.2910	 prepare: 0.0031	 bound: 0.2850	 transfer: 0.0016	 finalize: 0.0013
batch bounding time:  0.2910933494567871
Current worst splitting domains [lb, ub] (depth):
[-2.03126,   inf] (5), [-1.97728,   inf] (5), [-1.88270,   inf] (5), [-1.82048,   inf] (5), [-1.81931,   inf] (5), [-1.75304,   inf] (5), [-1.66835,   inf] (5), [-1.60802,   inf] (5), [-1.29275,   inf] (5), [-1.26094,   inf] (5), [-1.16614,   inf] (5), [-1.11849,   inf] (5), [-1.04801,   inf] (5), [-0.98068,   inf] (5), [-0.93208,   inf] (5), [-0.85659,   inf] (5), 
length of domains: 16
Total time: 0.3241	 pickout: 0.0009	 decision: 0.0294	 get_bound: 0.2932	 add_domain: 0.0006
Current lb:-2.0312628746032715
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.190239906311035

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([16, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([16, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 148] [2, 148] [2, 148] [2, 148] [2, 148] [2, 148] [2, 148] [2, 148] [2, 148] [2, 148] 
regular batch size: 2*16, diving batch size 1*0
best_l after optimization: 31.537015914916992 with beta sum per layer: [0.0, 0.0, 3.4105334281921387]
alpha/beta optimization time: 0.28133440017700195
This batch time : update_bounds func: 0.2898	 prepare: 0.0041	 bound: 0.2816	 transfer: 0.0018	 finalize: 0.0022
Accumulated time: update_bounds func: 0.5807	 prepare: 0.0071	 bound: 0.5666	 transfer: 0.0018	 finalize: 0.0034
batch bounding time:  0.28993868827819824
Current worst splitting domains [lb, ub] (depth):
[-1.86782,   inf] (7), [-1.79925,   inf] (7), [-1.72124,   inf] (7), [-1.66686,   inf] (7), [-1.64513,   inf] (7), [-1.59075,   inf] (7), [-1.52183,   inf] (7), [-1.45535,   inf] (7), [-1.33880,   inf] (7), [-1.31201,   inf] (7), [-1.16667,   inf] (7), [-1.13088,   inf] (7), [-1.12010,   inf] (7), [-1.07073,   inf] (7), [-1.06678,   inf] (7), [-1.04798,   inf] (7), [-0.99359,   inf] (7), [-0.93921,   inf] (7), [-0.88019,   inf] (7), [-0.87951,   inf] (7), 
length of domains: 32
Total time: 0.3285	 pickout: 0.0044	 decision: 0.0327	 get_bound: 0.2900	 add_domain: 0.0014
Current lb:-1.867815613746643
48 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.5190298557281494

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([32, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([32, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 161] [2, 161] [2, 161] [2, 161] [2, 161] [2, 161] [2, 161] [2, 161] [2, 161] [2, 161] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: 53.40308380126953 with beta sum per layer: [0.0, 0.0, 9.266501426696777]
alpha/beta optimization time: 0.3367958068847656
This batch time : update_bounds func: 0.3537	 prepare: 0.0067	 bound: 0.3371	 transfer: 0.0041	 finalize: 0.0056
Accumulated time: update_bounds func: 0.9344	 prepare: 0.0138	 bound: 0.9037	 transfer: 0.0041	 finalize: 0.0090
batch bounding time:  0.353865385055542
Current worst splitting domains [lb, ub] (depth):
[-1.80222,   inf] (9), [-1.73600,   inf] (9), [-1.67438,   inf] (9), [-1.65380,   inf] (9), [-1.60192,   inf] (9), [-1.58006,   inf] (9), [-1.57887,   inf] (9), [-1.54125,   inf] (9), [-1.53147,   inf] (9), [-1.45669,   inf] (9), [-1.43896,   inf] (9), [-1.43876,   inf] (9), [-1.39275,   inf] (9), [-1.32321,   inf] (9), [-1.30666,   inf] (9), [-1.25436,   inf] (9), [-1.23032,   inf] (9), [-1.20692,   inf] (9), [-1.11309,   inf] (9), [-1.10643,   inf] (9), 
length of domains: 58
Total time: 0.4001	 pickout: 0.0067	 decision: 0.0371	 get_bound: 0.3540	 add_domain: 0.0023
Current lb:-1.802220344543457
112 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.919649362564087

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([58, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([58, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 75] [2, 75] [2, 75] [2, 75] [2, 75] [2, 75] [2, 75] [2, 75] [2, 75] [2, 75] 
regular batch size: 2*58, diving batch size 1*0
best_l after optimization: 95.33457946777344 with beta sum per layer: [0.0, 0.0, 16.904251098632812]
alpha/beta optimization time: 0.3385353088378906
This batch time : update_bounds func: 0.3796	 prepare: 0.0167	 bound: 0.3389	 transfer: 0.0160	 finalize: 0.0077
Accumulated time: update_bounds func: 1.3140	 prepare: 0.0306	 bound: 1.2426	 transfer: 0.0160	 finalize: 0.0167
batch bounding time:  0.3798532485961914
Current worst splitting domains [lb, ub] (depth):
[-1.72122,   inf] (11), [-1.71903,   inf] (11), [-1.65394,   inf] (11), [-1.65325,   inf] (11), [-1.59003,   inf] (11), [-1.58844,   inf] (11), [-1.57402,   inf] (11), [-1.56921,   inf] (11), [-1.52154,   inf] (11), [-1.51681,   inf] (11), [-1.49983,   inf] (11), [-1.49636,   inf] (11), [-1.49522,   inf] (11), [-1.48815,   inf] (11), [-1.45786,   inf] (11), [-1.45688,   inf] (11), [-1.45057,   inf] (11), [-1.44646,   inf] (11), [-1.37806,   inf] (11), [-1.37083,   inf] (11), 
length of domains: 109
Total time: 0.4596	 pickout: 0.0169	 decision: 0.0581	 get_bound: 0.3800	 add_domain: 0.0045
Current lb:-1.7212212085723877
228 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.380069971084595

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([109, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([109, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 126] [2, 126] [2, 126] [2, 126] [2, 126] [2, 126] [2, 126] [2, 126] [2, 126] [2, 126] 
regular batch size: 2*109, diving batch size 1*0
best_l after optimization: 165.30796813964844 with beta sum per layer: [0.0, 0.0, 37.54586410522461]
alpha/beta optimization time: 0.4763460159301758
This batch time : update_bounds func: 0.5327	 prepare: 0.0194	 bound: 0.4767	 transfer: 0.0225	 finalize: 0.0137
Accumulated time: update_bounds func: 1.8467	 prepare: 0.0500	 bound: 1.7192	 transfer: 0.0225	 finalize: 0.0304
batch bounding time:  0.5331082344055176
Current worst splitting domains [lb, ub] (depth):
[-1.66486,   inf] (13), [-1.66302,   inf] (13), [-1.59628,   inf] (13), [-1.59509,   inf] (13), [-1.55655,   inf] (13), [-1.55067,   inf] (13), [-1.52987,   inf] (13), [-1.52820,   inf] (13), [-1.51600,   inf] (13), [-1.51180,   inf] (13), [-1.49301,   inf] (13), [-1.48830,   inf] (13), [-1.46501,   inf] (13), [-1.46062,   inf] (13), [-1.44449,   inf] (13), [-1.44120,   inf] (13), [-1.44069,   inf] (13), [-1.43638,   inf] (13), [-1.43407,   inf] (13), [-1.42591,   inf] (13), 
length of domains: 206
Total time: 0.6464	 pickout: 0.0270	 decision: 0.0758	 get_bound: 0.5335	 add_domain: 0.0101
Current lb:-1.664859414100647
446 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.028315544128418

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([206, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([206, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 38] [2, 38] [2, 38] [2, 38] [2, 38] [2, 38] [2, 38] [2, 38] [2, 38] [2, 38] 
regular batch size: 2*206, diving batch size 1*0
best_l after optimization: 225.89752197265625 with beta sum per layer: [0.0, 0.0, 94.93858337402344]
alpha/beta optimization time: 0.7200217247009277
This batch time : update_bounds func: 0.8264	 prepare: 0.0367	 bound: 0.7204	 transfer: 0.0428	 finalize: 0.0254
Accumulated time: update_bounds func: 2.6731	 prepare: 0.0867	 bound: 2.4396	 transfer: 0.0428	 finalize: 0.0558
batch bounding time:  0.8269209861755371
Current worst splitting domains [lb, ub] (depth):
[-1.61395,   inf] (15), [-1.61168,   inf] (15), [-1.54326,   inf] (15), [-1.54281,   inf] (15), [-1.50224,   inf] (15), [-1.49597,   inf] (15), [-1.47908,   inf] (15), [-1.47683,   inf] (15), [-1.46342,   inf] (15), [-1.45894,   inf] (15), [-1.43734,   inf] (15), [-1.43222,   inf] (15), [-1.41174,   inf] (15), [-1.40730,   inf] (15), [-1.38716,   inf] (15), [-1.38674,   inf] (15), [-1.38639,   inf] (15), [-1.38208,   inf] (15), [-1.38068,   inf] (15), [-1.37296,   inf] (15), 
length of domains: 359
Total time: 1.0143	 pickout: 0.0440	 decision: 0.1252	 get_bound: 0.8275	 add_domain: 0.0175
Current lb:-1.6139516830444336
858 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.047989845275879

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 154] [2, 154] [2, 154] [2, 154] [2, 154] [2, 154] [2, 154] [2, 154] [2, 154] [2, 154] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 122.71089172363281 with beta sum per layer: [0.0, 0.0, 168.81690979003906]
alpha/beta optimization time: 0.8354949951171875
This batch time : update_bounds func: 1.0316	 prepare: 0.0453	 bound: 0.8359	 transfer: 0.0430	 finalize: 0.1062
Accumulated time: update_bounds func: 3.7048	 prepare: 0.1320	 bound: 3.2755	 transfer: 0.0430	 finalize: 0.1621
batch bounding time:  1.0322341918945312
Current worst splitting domains [lb, ub] (depth):
[-1.56931,   inf] (17), [-1.56741,   inf] (17), [-1.49845,   inf] (17), [-1.49750,   inf] (17), [-1.45468,   inf] (17), [-1.44865,   inf] (17), [-1.43372,   inf] (17), [-1.43109,   inf] (17), [-1.42125,   inf] (17), [-1.41745,   inf] (17), [-1.38845,   inf] (17), [-1.38375,   inf] (17), [-1.36386,   inf] (17), [-1.36038,   inf] (17), [-1.34403,   inf] (17), [-1.33976,   inf] (17), [-1.33924,   inf] (17), [-1.33857,   inf] (17), [-1.33447,   inf] (17), [-1.32631,   inf] (17), 
length of domains: 377
Total time: 1.2561	 pickout: 0.0547	 decision: 0.1544	 get_bound: 1.0330	 add_domain: 0.0140
Current lb:-1.5693140029907227
1370 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.309119939804077

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 14] [2, 14] [2, 14] [2, 14] [2, 14] [2, 14] [2, 14] [2, 14] [2, 55] [2, 14] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 167.68475341796875 with beta sum per layer: [0.0, 0.0, 190.86965942382812]
alpha/beta optimization time: 0.8393311500549316
This batch time : update_bounds func: 0.9679	 prepare: 0.0442	 bound: 0.8397	 transfer: 0.0498	 finalize: 0.0329
Accumulated time: update_bounds func: 4.6727	 prepare: 0.1762	 bound: 4.1152	 transfer: 0.0498	 finalize: 0.1950
batch bounding time:  0.9685661792755127
Current worst splitting domains [lb, ub] (depth):
[-1.53112,   inf] (19), [-1.52903,   inf] (19), [-1.45926,   inf] (19), [-1.45821,   inf] (19), [-1.41621,   inf] (19), [-1.40997,   inf] (19), [-1.39572,   inf] (19), [-1.39323,   inf] (19), [-1.38269,   inf] (19), [-1.37907,   inf] (19), [-1.34886,   inf] (19), [-1.34475,   inf] (19), [-1.32636,   inf] (19), [-1.32261,   inf] (19), [-1.30471,   inf] (19), [-1.30073,   inf] (19), [-1.30025,   inf] (19), [-1.30018,   inf] (19), [-1.29547,   inf] (19), [-1.28676,   inf] (19), 
length of domains: 478
Total time: 1.1982	 pickout: 0.0569	 decision: 0.1512	 get_bound: 0.9694	 add_domain: 0.0206
Current lb:-1.5311222076416016
1882 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.512730598449707

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 55] [2, 55] [2, 55] [2, 55] [2, 55] [2, 55] [2, 55] [2, 55] [2, 14] [2, 55] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 242.39425659179688 with beta sum per layer: [0.0, 0.0, 181.49371337890625]
alpha/beta optimization time: 0.8392398357391357
This batch time : update_bounds func: 0.9804	 prepare: 0.0474	 bound: 0.8397	 transfer: 0.0575	 finalize: 0.0346
Accumulated time: update_bounds func: 5.6532	 prepare: 0.2235	 bound: 4.9549	 transfer: 0.0575	 finalize: 0.2296
batch bounding time:  0.9810705184936523
Current worst splitting domains [lb, ub] (depth):
[-1.49417,   inf] (21), [-1.49204,   inf] (21), [-1.42242,   inf] (21), [-1.42152,   inf] (21), [-1.37852,   inf] (21), [-1.37251,   inf] (21), [-1.35691,   inf] (21), [-1.35427,   inf] (21), [-1.34469,   inf] (21), [-1.34100,   inf] (21), [-1.34064,   inf] (21), [-1.33696,   inf] (21), [-1.31128,   inf] (21), [-1.30658,   inf] (21), [-1.29301,   inf] (21), [-1.28902,   inf] (21), [-1.27922,   inf] (21), [-1.27205,   inf] (21), [-1.26680,   inf] (21), [-1.26194,   inf] (21), 
length of domains: 640
Total time: 1.2180	 pickout: 0.0571	 decision: 0.1501	 get_bound: 0.9819	 add_domain: 0.0290
Current lb:-1.494166612625122
2394 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.739144563674927

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 31] [2, 31] [2, 31] [2, 31] [2, 31] [2, 31] [2, 31] [2, 31] [2, 31] [2, 31] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 338.76385498046875 with beta sum per layer: [0.0, 0.0, 152.35665893554688]
alpha/beta optimization time: 0.8358402252197266
This batch time : update_bounds func: 0.9760	 prepare: 0.0469	 bound: 0.8362	 transfer: 0.0569	 finalize: 0.0346
Accumulated time: update_bounds func: 6.6291	 prepare: 0.2704	 bound: 5.7911	 transfer: 0.0569	 finalize: 0.2642
batch bounding time:  0.9766786098480225
Current worst splitting domains [lb, ub] (depth):
[-1.46385,   inf] (23), [-1.46193,   inf] (23), [-1.39045,   inf] (23), [-1.38964,   inf] (23), [-1.34773,   inf] (23), [-1.34211,   inf] (23), [-1.32797,   inf] (23), [-1.32532,   inf] (23), [-1.31483,   inf] (23), [-1.31087,   inf] (23), [-1.30653,   inf] (23), [-1.30100,   inf] (23), [-1.27915,   inf] (23), [-1.27473,   inf] (23), [-1.26285,   inf] (23), [-1.25914,   inf] (23), [-1.24270,   inf] (23), [-1.23600,   inf] (23), [-1.23393,   inf] (23), [-1.23189,   inf] (23), 
length of domains: 877
Total time: 1.3232	 pickout: 0.0849	 decision: 0.2294	 get_bound: 0.9775	 add_domain: 0.0314
Current lb:-1.4638460874557495
2906 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.068073511123657

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 190] [2, 74] [2, 74] [2, 74] [2, 190] [2, 190] [2, 74] [2, 190] [2, 190] [2, 190] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 305.7842102050781 with beta sum per layer: [0.0, 0.0, 186.5452880859375]
alpha/beta optimization time: 0.8380248546600342
This batch time : update_bounds func: 0.9734	 prepare: 0.0466	 bound: 0.8384	 transfer: 0.0540	 finalize: 0.0331
Accumulated time: update_bounds func: 7.6026	 prepare: 0.3170	 bound: 6.6295	 transfer: 0.0540	 finalize: 0.2972
batch bounding time:  0.9742052555084229
Current worst splitting domains [lb, ub] (depth):
[-1.43679,   inf] (25), [-1.43496,   inf] (25), [-1.36354,   inf] (25), [-1.36281,   inf] (25), [-1.31987,   inf] (25), [-1.31397,   inf] (25), [-1.29955,   inf] (25), [-1.29804,   inf] (25), [-1.28707,   inf] (25), [-1.28326,   inf] (25), [-1.27374,   inf] (25), [-1.27139,   inf] (25), [-1.25058,   inf] (25), [-1.24601,   inf] (25), [-1.23651,   inf] (25), [-1.23322,   inf] (25), [-1.21235,   inf] (25), [-1.20693,   inf] (25), [-1.20539,   inf] (25), [-1.20411,   inf] (25), 
length of domains: 1060
Total time: 1.2193	 pickout: 0.0622	 decision: 0.1491	 get_bound: 0.9751	 add_domain: 0.0329
Current lb:-1.4367916584014893
3418 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.298471450805664

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 74] [2, 190] [2, 81] [2, 190] [2, 74] [2, 74] [2, 190] [2, 74] [2, 74] [2, 74] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 352.7840881347656 with beta sum per layer: [0.0, 0.0, 141.19285583496094]
alpha/beta optimization time: 0.8325588703155518
This batch time : update_bounds func: 1.0462	 prepare: 0.0457	 bound: 0.8329	 transfer: 0.0477	 finalize: 0.1184
Accumulated time: update_bounds func: 8.6488	 prepare: 0.3626	 bound: 7.4624	 transfer: 0.0477	 finalize: 0.4157
batch bounding time:  1.0468573570251465
Current worst splitting domains [lb, ub] (depth):
[-1.41019,   inf] (27), [-1.40831,   inf] (27), [-1.33824,   inf] (27), [-1.33735,   inf] (27), [-1.29084,   inf] (27), [-1.28525,   inf] (27), [-1.27291,   inf] (27), [-1.26977,   inf] (27), [-1.26023,   inf] (27), [-1.25639,   inf] (27), [-1.24533,   inf] (27), [-1.23908,   inf] (27), [-1.22480,   inf] (27), [-1.21985,   inf] (27), [-1.21000,   inf] (27), [-1.20655,   inf] (27), [-1.18648,   inf] (27), [-1.18612,   inf] (27), [-1.18050,   inf] (27), [-1.17900,   inf] (27), 
length of domains: 1283
Total time: 1.2952	 pickout: 0.0624	 decision: 0.1516	 get_bound: 1.0476	 add_domain: 0.0336
Current lb:-1.4101899862289429
3930 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.59925389289856

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 81] [2, 81] [2, 190] [2, 81] [2, 81] [2, 81] [2, 81] [2, 81] [2, 81] [2, 81] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 351.642578125 with beta sum per layer: [0.0, 0.0, 142.34725952148438]
alpha/beta optimization time: 0.8320198059082031
This batch time : update_bounds func: 0.9729	 prepare: 0.0483	 bound: 0.8324	 transfer: 0.0553	 finalize: 0.0353
Accumulated time: update_bounds func: 9.6217	 prepare: 0.4110	 bound: 8.2948	 transfer: 0.0553	 finalize: 0.4510
batch bounding time:  0.9735567569732666
Current worst splitting domains [lb, ub] (depth):
[-1.38557,   inf] (29), [-1.38373,   inf] (29), [-1.31320,   inf] (29), [-1.31188,   inf] (29), [-1.26535,   inf] (29), [-1.25972,   inf] (29), [-1.24999,   inf] (29), [-1.24708,   inf] (29), [-1.23553,   inf] (29), [-1.23158,   inf] (29), [-1.21917,   inf] (29), [-1.21496,   inf] (29), [-1.21428,   inf] (29), [-1.21182,   inf] (29), [-1.19821,   inf] (29), [-1.19348,   inf] (29), [-1.18424,   inf] (29), [-1.18111,   inf] (29), [-1.16047,   inf] (29), [-1.16023,   inf] (29), 
length of domains: 1505
Total time: 1.2196	 pickout: 0.0574	 decision: 0.1533	 get_bound: 0.9743	 add_domain: 0.0347
Current lb:-1.3855665922164917
4442 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.825101137161255

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 131] [2, 131] [2, 131] [2, 131] [2, 131] [2, 131] [2, 131] [2, 131] [2, 131] [2, 131] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 449.1778259277344 with beta sum per layer: [0.0, 0.0, 81.43806457519531]
alpha/beta optimization time: 0.8238892555236816
This batch time : update_bounds func: 0.9591	 prepare: 0.0457	 bound: 0.8242	 transfer: 0.0488	 finalize: 0.0388
Accumulated time: update_bounds func: 10.5808	 prepare: 0.4567	 bound: 9.1191	 transfer: 0.0488	 finalize: 0.4898
batch bounding time:  0.9597985744476318
Current worst splitting domains [lb, ub] (depth):
[-1.35981,   inf] (31), [-1.35787,   inf] (31), [-1.34309,   inf] (31), [-1.34135,   inf] (31), [-1.28726,   inf] (31), [-1.28573,   inf] (31), [-1.27531,   inf] (31), [-1.27485,   inf] (31), [-1.23931,   inf] (31), [-1.23388,   inf] (31), [-1.22385,   inf] (31), [-1.22344,   inf] (31), [-1.22062,   inf] (31), [-1.21919,   inf] (31), [-1.21282,   inf] (31), [-1.20910,   inf] (31), [-1.20845,   inf] (31), [-1.20532,   inf] (31), [-1.19798,   inf] (31), [-1.19468,   inf] (31), 
length of domains: 1753
Total time: 1.2088	 pickout: 0.0581	 decision: 0.1512	 get_bound: 0.9606	 add_domain: 0.0388
Current lb:-1.3598096370697021
4954 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.03949475288391

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 54] [2, 54] [2, 54] [2, 54] [2, 54] [2, 54] [2, 54] [2, 54] [2, 54] [2, 54] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 382.2893371582031 with beta sum per layer: [0.0, 0.0, 117.67528533935547]
alpha/beta optimization time: 0.830585241317749
This batch time : update_bounds func: 0.9731	 prepare: 0.0486	 bound: 0.8310	 transfer: 0.0600	 finalize: 0.0321
Accumulated time: update_bounds func: 11.5539	 prepare: 0.5053	 bound: 9.9501	 transfer: 0.0600	 finalize: 0.5218
batch bounding time:  0.9736943244934082
Current worst splitting domains [lb, ub] (depth):
[-1.33641,   inf] (33), [-1.33441,   inf] (33), [-1.31923,   inf] (33), [-1.31752,   inf] (33), [-1.26401,   inf] (33), [-1.26235,   inf] (33), [-1.25138,   inf] (33), [-1.25082,   inf] (33), [-1.21592,   inf] (33), [-1.21045,   inf] (33), [-1.20083,   inf] (33), [-1.19919,   inf] (33), [-1.19720,   inf] (33), [-1.19549,   inf] (33), [-1.18725,   inf] (33), [-1.18583,   inf] (33), [-1.18341,   inf] (33), [-1.18199,   inf] (33), [-1.17398,   inf] (33), [-1.17096,   inf] (33), 
length of domains: 2009
Total time: 1.3493	 pickout: 0.0624	 decision: 0.2729	 get_bound: 0.9745	 add_domain: 0.0395
Current lb:-1.3364149332046509
5466 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.393743991851807

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 45] [2, 45] [2, 45] [2, 45] [2, 45] [2, 45] [2, 45] [2, 45] [2, 45] [2, 45] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 430.19683837890625 with beta sum per layer: [0.0, 0.0, 86.05399322509766]
alpha/beta optimization time: 0.8287639617919922
This batch time : update_bounds func: 0.9670	 prepare: 0.0462	 bound: 0.8291	 transfer: 0.0565	 finalize: 0.0338
Accumulated time: update_bounds func: 12.5209	 prepare: 0.5515	 bound: 10.7792	 transfer: 0.0565	 finalize: 0.5557
batch bounding time:  0.9676759243011475
Current worst splitting domains [lb, ub] (depth):
[-1.31441,   inf] (35), [-1.31284,   inf] (35), [-1.29724,   inf] (35), [-1.29621,   inf] (35), [-1.24380,   inf] (35), [-1.24154,   inf] (35), [-1.23128,   inf] (35), [-1.23007,   inf] (35), [-1.20795,   inf] (35), [-1.19403,   inf] (35), [-1.18897,   inf] (35), [-1.18235,   inf] (35), [-1.18017,   inf] (35), [-1.17953,   inf] (35), [-1.17768,   inf] (35), [-1.17596,   inf] (35), [-1.17413,   inf] (35), [-1.16601,   inf] (35), [-1.16368,   inf] (35), [-1.16198,   inf] (35), 
length of domains: 2265
Total time: 1.2180	 pickout: 0.0556	 decision: 0.1501	 get_bound: 0.9685	 add_domain: 0.0438
Current lb:-1.3144066333770752
5978 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.61901593208313

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 236] [2, 236] [2, 236] [2, 236] [2, 236] [2, 236] [2, 236] [2, 236] [2, 236] [2, 236] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 461.7003173828125 with beta sum per layer: [0.0, 1.6183562278747559, 66.98575592041016]
alpha/beta optimization time: 0.8272309303283691
This batch time : update_bounds func: 0.9576	 prepare: 0.0474	 bound: 0.8276	 transfer: 0.0467	 finalize: 0.0346
Accumulated time: update_bounds func: 13.4785	 prepare: 0.5989	 bound: 11.6068	 transfer: 0.0467	 finalize: 0.5903
batch bounding time:  0.9583041667938232
Current worst splitting domains [lb, ub] (depth):
[-1.29900,   inf] (37), [-1.29760,   inf] (37), [-1.28176,   inf] (37), [-1.28094,   inf] (37), [-1.22846,   inf] (37), [-1.22587,   inf] (37), [-1.21573,   inf] (37), [-1.21439,   inf] (37), [-1.18995,   inf] (37), [-1.17865,   inf] (37), [-1.17379,   inf] (37), [-1.16567,   inf] (37), [-1.16532,   inf] (37), [-1.16205,   inf] (37), [-1.16123,   inf] (37), [-1.16086,   inf] (37), [-1.15901,   inf] (37), [-1.15120,   inf] (37), [-1.14824,   inf] (37), [-1.14687,   inf] (37), 
length of domains: 2521
Total time: 1.3202	 pickout: 0.0623	 decision: 0.2557	 get_bound: 0.9591	 add_domain: 0.0430
Current lb:-1.2990033626556396
6490 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 19.94494342803955

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6677] [1, 6677] [1, 6677] [1, 6677] [2, 44] [2, 44] [2, 44] [2, 44] [2, 44] [2, 44] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 455.1943359375 with beta sum per layer: [0.0, 3.636287212371826, 67.5059814453125]
alpha/beta optimization time: 0.8290879726409912
This batch time : update_bounds func: 0.9729	 prepare: 0.0475	 bound: 0.8294	 transfer: 0.0501	 finalize: 0.0445
Accumulated time: update_bounds func: 14.4514	 prepare: 0.6464	 bound: 12.4363	 transfer: 0.0501	 finalize: 0.6348
batch bounding time:  0.9740610122680664
Current worst splitting domains [lb, ub] (depth):
[-1.28377,   inf] (39), [-1.28107,   inf] (39), [-1.28010,   inf] (39), [-1.27783,   inf] (39), [-1.26695,   inf] (39), [-1.26455,   inf] (39), [-1.26303,   inf] (39), [-1.26101,   inf] (39), [-1.21542,   inf] (39), [-1.21286,   inf] (39), [-1.20274,   inf] (39), [-1.20152,   inf] (39), [-1.17535,   inf] (39), [-1.16451,   inf] (39), [-1.15936,   inf] (39), [-1.15418,   inf] (39), [-1.15204,   inf] (39), [-1.14953,   inf] (39), [-1.14765,   inf] (39), [-1.14738,   inf] (39), 
length of domains: 2777
Total time: 1.2308	 pickout: 0.0570	 decision: 0.1549	 get_bound: 0.9749	 add_domain: 0.0440
Current lb:-1.2837730646133423
7002 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 21.18438220024109

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 44] [2, 44] [2, 44] [2, 44] [2, 44] [2, 44] [2, 44] [2, 44] [1, 1589] [1, 1589] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 478.90655517578125 with beta sum per layer: [0.0, 23.024442672729492, 57.32683563232422]
alpha/beta optimization time: 0.8453540802001953
This batch time : update_bounds func: 1.1076	 prepare: 0.0487	 bound: 0.8458	 transfer: 0.0568	 finalize: 0.1549
Accumulated time: update_bounds func: 15.5590	 prepare: 0.6951	 bound: 13.2820	 transfer: 0.0568	 finalize: 0.7897
batch bounding time:  1.1083710193634033
Current worst splitting domains [lb, ub] (depth):
[-1.26991,   inf] (41), [-1.26717,   inf] (41), [-1.26626,   inf] (41), [-1.26386,   inf] (41), [-1.25329,   inf] (41), [-1.25054,   inf] (41), [-1.24926,   inf] (41), [-1.24702,   inf] (41), [-1.20446,   inf] (41), [-1.20169,   inf] (41), [-1.19520,   inf] (41), [-1.19232,   inf] (41), [-1.19175,   inf] (41), [-1.19024,   inf] (41), [-1.18183,   inf] (41), [-1.18044,   inf] (41), [-1.16305,   inf] (41), [-1.15175,   inf] (41), [-1.14504,   inf] (41), [-1.14015,   inf] (41), 
length of domains: 3025
Total time: 1.3606	 pickout: 0.0575	 decision: 0.1495	 get_bound: 1.1093	 add_domain: 0.0442
Current lb:-1.2699058055877686
7514 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 22.55063247680664

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 129] [2, 129] [2, 129] [2, 129] [2, 129] [2, 129] [2, 129] [2, 129] [2, 129] [2, 129] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 472.8255615234375 with beta sum per layer: [0.0, 35.03567123413086, 59.142635345458984]
alpha/beta optimization time: 0.8372862339019775
This batch time : update_bounds func: 1.0003	 prepare: 0.0560	 bound: 0.8377	 transfer: 0.0639	 finalize: 0.0410
Accumulated time: update_bounds func: 16.5592	 prepare: 0.7511	 bound: 14.1197	 transfer: 0.0639	 finalize: 0.8307
batch bounding time:  1.0009591579437256
Current worst splitting domains [lb, ub] (depth):
[-1.25754,   inf] (43), [-1.25495,   inf] (43), [-1.25389,   inf] (43), [-1.25160,   inf] (43), [-1.24082,   inf] (43), [-1.23813,   inf] (43), [-1.23680,   inf] (43), [-1.23460,   inf] (43), [-1.19170,   inf] (43), [-1.18877,   inf] (43), [-1.18240,   inf] (43), [-1.17949,   inf] (43), [-1.17868,   inf] (43), [-1.17740,   inf] (43), [-1.16901,   inf] (43), [-1.16759,   inf] (43), [-1.14826,   inf] (43), [-1.14042,   inf] (43), [-1.13869,   inf] (43), [-1.13743,   inf] (43), 
length of domains: 3251
Total time: 1.2907	 pickout: 0.0743	 decision: 0.1677	 get_bound: 1.0019	 add_domain: 0.0468
Current lb:-1.257536768913269
8026 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 23.848231315612793

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1589] [1, 1589] [1, 1589] [1, 1589] [1, 1589] [1, 1589] [1, 1589] [1, 1589] [2, 117] [2, 117] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 427.02069091796875 with beta sum per layer: [0.0, 41.28082275390625, 78.52244567871094]
alpha/beta optimization time: 0.8296980857849121
This batch time : update_bounds func: 0.9678	 prepare: 0.0535	 bound: 0.8301	 transfer: 0.0496	 finalize: 0.0332
Accumulated time: update_bounds func: 17.5271	 prepare: 0.8046	 bound: 14.9498	 transfer: 0.0496	 finalize: 0.8639
batch bounding time:  0.9684717655181885
Current worst splitting domains [lb, ub] (depth):
[-1.24680,   inf] (45), [-1.24465,   inf] (45), [-1.24317,   inf] (45), [-1.24128,   inf] (45), [-1.23139,   inf] (45), [-1.23022,   inf] (45), [-1.22992,   inf] (45), [-1.22772,   inf] (45), [-1.22763,   inf] (45), [-1.22653,   inf] (45), [-1.22627,   inf] (45), [-1.22402,   inf] (45), [-1.21460,   inf] (45), [-1.21259,   inf] (45), [-1.21063,   inf] (45), [-1.20897,   inf] (45), [-1.18042,   inf] (45), [-1.17745,   inf] (45), [-1.17111,   inf] (45), [-1.16822,   inf] (45), 
length of domains: 3460
Total time: 1.2279	 pickout: 0.0608	 decision: 0.1540	 get_bound: 0.9693	 add_domain: 0.0438
Current lb:-1.2468013763427734
8538 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 25.082597970962524

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 117] [2, 117] [2, 117] [2, 117] [2, 117] [2, 117] [2, 117] [2, 117] [2, 117] [2, 117] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 487.478515625 with beta sum per layer: [0.0, 59.60707092285156, 47.909568786621094]
alpha/beta optimization time: 0.8323400020599365
This batch time : update_bounds func: 0.9783	 prepare: 0.0540	 bound: 0.8328	 transfer: 0.0515	 finalize: 0.0387
Accumulated time: update_bounds func: 18.5053	 prepare: 0.8586	 bound: 15.7826	 transfer: 0.0515	 finalize: 0.9026
batch bounding time:  0.9789621829986572
Current worst splitting domains [lb, ub] (depth):
[-1.23545,   inf] (47), [-1.23322,   inf] (47), [-1.23174,   inf] (47), [-1.22982,   inf] (47), [-1.21993,   inf] (47), [-1.21879,   inf] (47), [-1.21827,   inf] (47), [-1.21630,   inf] (47), [-1.21617,   inf] (47), [-1.21489,   inf] (47), [-1.21483,   inf] (47), [-1.21263,   inf] (47), [-1.20362,   inf] (47), [-1.20328,   inf] (47), [-1.20301,   inf] (47), [-1.20124,   inf] (47), [-1.20044,   inf] (47), [-1.20040,   inf] (47), [-1.19912,   inf] (47), [-1.19745,   inf] (47), 
length of domains: 3702
Total time: 1.3841	 pickout: 0.0607	 decision: 0.2958	 get_bound: 0.9798	 add_domain: 0.0478
Current lb:-1.235445261001587
9050 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 26.473408222198486

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 114] [2, 114] [2, 114] [2, 114] [2, 114] [1, 7971] [2, 114] [2, 114] [2, 114] [1, 7971] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 462.9586181640625 with beta sum per layer: [0.0, 75.21465301513672, 56.03547286987305]
alpha/beta optimization time: 0.8294482231140137
This batch time : update_bounds func: 0.9642	 prepare: 0.0527	 bound: 0.8298	 transfer: 0.0470	 finalize: 0.0333
Accumulated time: update_bounds func: 19.4695	 prepare: 0.9113	 bound: 16.6124	 transfer: 0.0470	 finalize: 0.9359
batch bounding time:  0.9648244380950928
Current worst splitting domains [lb, ub] (depth):
[-1.22600,   inf] (49), [-1.22382,   inf] (49), [-1.22232,   inf] (49), [-1.22043,   inf] (49), [-1.21047,   inf] (49), [-1.20884,   inf] (49), [-1.20749,   inf] (49), [-1.20673,   inf] (49), [-1.20671,   inf] (49), [-1.20540,   inf] (49), [-1.20463,   inf] (49), [-1.20362,   inf] (49), [-1.20317,   inf] (49), [-1.20067,   inf] (49), [-1.19299,   inf] (49), [-1.19188,   inf] (49), [-1.19157,   inf] (49), [-1.19081,   inf] (49), [-1.19019,   inf] (49), [-1.18880,   inf] (49), 
length of domains: 3913
Total time: 1.2245	 pickout: 0.0597	 decision: 0.1532	 get_bound: 0.9656	 add_domain: 0.0459
Current lb:-1.2259955406188965
9562 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 27.7052218914032

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 676] [1, 676] [1, 676] [1, 676] [1, 676] [1, 676] [2, 114] [1, 676] [1, 676] [1, 676] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 413.086181640625 with beta sum per layer: [0.0, 111.80077362060547, 80.86026000976562]
alpha/beta optimization time: 0.8405516147613525
This batch time : update_bounds func: 1.1316	 prepare: 0.0537	 bound: 0.8409	 transfer: 0.0506	 finalize: 0.1850
Accumulated time: update_bounds func: 20.6011	 prepare: 0.9651	 bound: 17.4533	 transfer: 0.0506	 finalize: 1.1209
batch bounding time:  1.1322345733642578
Current worst splitting domains [lb, ub] (depth):
[-1.21739,   inf] (51), [-1.21509,   inf] (51), [-1.21372,   inf] (51), [-1.21172,   inf] (51), [-1.20174,   inf] (51), [-1.19995,   inf] (51), [-1.19806,   inf] (51), [-1.19804,   inf] (51), [-1.19798,   inf] (51), [-1.19654,   inf] (51), [-1.19505,   inf] (51), [-1.19415,   inf] (51), [-1.19262,   inf] (51), [-1.19119,   inf] (51), [-1.18986,   inf] (51), [-1.18407,   inf] (51), [-1.18240,   inf] (51), [-1.18183,   inf] (51), [-1.18140,   inf] (51), [-1.18130,   inf] (51), 
length of domains: 4134
Total time: 1.3981	 pickout: 0.0658	 decision: 0.1523	 get_bound: 1.1330	 add_domain: 0.0470
Current lb:-1.2173908948898315
10074 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 29.10908031463623

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7971] [1, 667] [1, 7971] [1, 667] [1, 7971] [1, 667] [1, 7971] [1, 7971] [1, 676] [1, 667] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 497.5335388183594 with beta sum per layer: [0.0, 160.09605407714844, 41.06480407714844]
alpha/beta optimization time: 0.8324856758117676
This batch time : update_bounds func: 0.9698	 prepare: 0.0517	 bound: 0.8329	 transfer: 0.0509	 finalize: 0.0329
Accumulated time: update_bounds func: 21.5709	 prepare: 1.0167	 bound: 18.2862	 transfer: 0.0509	 finalize: 1.1538
batch bounding time:  0.9704723358154297
Current worst splitting domains [lb, ub] (depth):
[-1.20695,   inf] (53), [-1.20474,   inf] (53), [-1.20432,   inf] (53), [-1.20337,   inf] (53), [-1.20336,   inf] (53), [-1.20098,   inf] (53), [-1.20085,   inf] (53), [-1.20010,   inf] (53), [-1.19145,   inf] (53), [-1.18940,   inf] (53), [-1.18914,   inf] (53), [-1.18897,   inf] (53), [-1.18819,   inf] (53), [-1.18782,   inf] (53), [-1.18741,   inf] (53), [-1.18655,   inf] (53), [-1.18565,   inf] (53), [-1.18562,   inf] (53), [-1.18517,   inf] (53), [-1.18493,   inf] (53), 
length of domains: 4378
Total time: 1.2379	 pickout: 0.0615	 decision: 0.1535	 get_bound: 0.9712	 add_domain: 0.0517
Current lb:-1.2069511413574219
10586 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 30.353000164031982

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 249] [2, 249] [1, 7971] [2, 249] [1, 7971] [2, 249] [1, 7971] [1, 7971] [2, 249] [2, 249] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 459.9394836425781 with beta sum per layer: [0.0, 247.77377319335938, 45.550209045410156]
alpha/beta optimization time: 0.8323161602020264
This batch time : update_bounds func: 0.9656	 prepare: 0.0513	 bound: 0.8327	 transfer: 0.0462	 finalize: 0.0341
Accumulated time: update_bounds func: 22.5364	 prepare: 1.0680	 bound: 19.1189	 transfer: 0.0462	 finalize: 1.1879
batch bounding time:  0.9662554264068604
Current worst splitting domains [lb, ub] (depth):
[-1.19914,   inf] (55), [-1.19695,   inf] (55), [-1.19554,   inf] (55), [-1.19489,   inf] (55), [-1.19397,   inf] (55), [-1.19318,   inf] (55), [-1.19247,   inf] (55), [-1.19170,   inf] (55), [-1.19147,   inf] (55), [-1.19068,   inf] (55), [-1.18902,   inf] (55), [-1.18835,   inf] (55), [-1.18365,   inf] (55), [-1.18153,   inf] (55), [-1.18120,   inf] (55), [-1.18001,   inf] (55), [-1.17987,   inf] (55), [-1.17969,   inf] (55), [-1.17892,   inf] (55), [-1.17877,   inf] (55), 
length of domains: 4634
Total time: 1.4085	 pickout: 0.0595	 decision: 0.1498	 get_bound: 0.9671	 add_domain: 0.2320
Current lb:-1.199143409729004
11098 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 31.767370223999023

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3245] [1, 3245] [1, 3245] [2, 249] [2, 249] [1, 3245] [2, 249] [2, 249] [2, 249] [2, 249] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 514.3338623046875 with beta sum per layer: [0.0, 261.09637451171875, 24.226734161376953]
alpha/beta optimization time: 0.8577296733856201
This batch time : update_bounds func: 0.9963	 prepare: 0.0517	 bound: 0.8582	 transfer: 0.0492	 finalize: 0.0361
Accumulated time: update_bounds func: 23.5328	 prepare: 1.1197	 bound: 19.9771	 transfer: 0.0492	 finalize: 1.2240
batch bounding time:  0.997065544128418
Current worst splitting domains [lb, ub] (depth):
[-1.19153,   inf] (57), [-1.18934,   inf] (57), [-1.18787,   inf] (57), [-1.18717,   inf] (57), [-1.18628,   inf] (57), [-1.18551,   inf] (57), [-1.18476,   inf] (57), [-1.18399,   inf] (57), [-1.18376,   inf] (57), [-1.18299,   inf] (57), [-1.18131,   inf] (57), [-1.18065,   inf] (57), [-1.17616,   inf] (57), [-1.17418,   inf] (57), [-1.17364,   inf] (57), [-1.17252,   inf] (57), [-1.17218,   inf] (57), [-1.17126,   inf] (57), [-1.17076,   inf] (57), [-1.17036,   inf] (57), 
length of domains: 4890
Total time: 1.2679	 pickout: 0.0590	 decision: 0.1528	 get_bound: 0.9979	 add_domain: 0.0581
Current lb:-1.1915333271026611
11610 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 33.04215669631958

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 667] [1, 667] [1, 667] [1, 3245] [1, 3245] [1, 667] [1, 7972] [1, 3245] [1, 3245] [1, 3245] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 558.972900390625 with beta sum per layer: [0.0, 251.1470947265625, 10.002395629882812]
alpha/beta optimization time: 0.8327369689941406
This batch time : update_bounds func: 0.9795	 prepare: 0.0531	 bound: 0.8331	 transfer: 0.0589	 finalize: 0.0331
Accumulated time: update_bounds func: 24.5123	 prepare: 1.1728	 bound: 20.8102	 transfer: 0.0589	 finalize: 1.2571
batch bounding time:  0.980144739151001
Current worst splitting domains [lb, ub] (depth):
[-1.18168,   inf] (59), [-1.18045,   inf] (59), [-1.17999,   inf] (59), [-1.17924,   inf] (59), [-1.17909,   inf] (59), [-1.17839,   inf] (59), [-1.17794,   inf] (59), [-1.17753,   inf] (59), [-1.17679,   inf] (59), [-1.17679,   inf] (59), [-1.17655,   inf] (59), [-1.17579,   inf] (59), [-1.17543,   inf] (59), [-1.17465,   inf] (59), [-1.17408,   inf] (59), [-1.17342,   inf] (59), [-1.16625,   inf] (59), [-1.16514,   inf] (59), [-1.16505,   inf] (59), [-1.16432,   inf] (59), 
length of domains: 5146
Total time: 1.2537	 pickout: 0.0626	 decision: 0.1524	 get_bound: 0.9810	 add_domain: 0.0576
Current lb:-1.1816761493682861
12122 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 34.303125619888306

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 4530] [1, 4530] [1, 4530] [1, 4530] [1, 4530] [1, 4530] [1, 4530] [1, 4530] [1, 4530] [1, 4530] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 574.744140625 with beta sum per layer: [0.0, 241.3328857421875, 5.013164043426514]
alpha/beta optimization time: 0.8497340679168701
This batch time : update_bounds func: 1.1637	 prepare: 0.0517	 bound: 0.8501	 transfer: 0.0495	 finalize: 0.2108
Accumulated time: update_bounds func: 25.6760	 prepare: 1.2245	 bound: 21.6604	 transfer: 0.0495	 finalize: 1.4679
batch bounding time:  1.1644461154937744
Current worst splitting domains [lb, ub] (depth):
[-1.17284,   inf] (61), [-1.17161,   inf] (61), [-1.17145,   inf] (61), [-1.17060,   inf] (61), [-1.17043,   inf] (61), [-1.16989,   inf] (61), [-1.16956,   inf] (61), [-1.16911,   inf] (61), [-1.16906,   inf] (61), [-1.16863,   inf] (61), [-1.16832,   inf] (61), [-1.16806,   inf] (61), [-1.16796,   inf] (61), [-1.16748,   inf] (61), [-1.16732,   inf] (61), [-1.16728,   inf] (61), [-1.16660,   inf] (61), [-1.16660,   inf] (61), [-1.16637,   inf] (61), [-1.16616,   inf] (61), 
length of domains: 5402
Total time: 1.4416	 pickout: 0.0610	 decision: 0.1534	 get_bound: 1.1654	 add_domain: 0.0619
Current lb:-1.172837257385254
12634 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 35.750640630722046

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7972] [1, 7972] [1, 7972] [1, 7972] [1, 7972] [1, 7972] [1, 7972] [1, 7972] [1, 3245] [1, 7972] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 575.0870361328125 with beta sum per layer: [0.0, 249.8662109375, 3.419149398803711]
alpha/beta optimization time: 0.8367648124694824
This batch time : update_bounds func: 0.9965	 prepare: 0.0760	 bound: 0.8372	 transfer: 0.0476	 finalize: 0.0342
Accumulated time: update_bounds func: 26.6725	 prepare: 1.3006	 bound: 22.4976	 transfer: 0.0476	 finalize: 1.5021
batch bounding time:  0.9971823692321777
Current worst splitting domains [lb, ub] (depth):
[-1.16542,   inf] (63), [-1.16455,   inf] (63), [-1.16420,   inf] (63), [-1.16364,   inf] (63), [-1.16264,   inf] (63), [-1.16250,   inf] (63), [-1.16193,   inf] (63), [-1.16184,   inf] (63), [-1.16169,   inf] (63), [-1.16126,   inf] (63), [-1.16124,   inf] (63), [-1.16113,   inf] (63), [-1.16055,   inf] (63), [-1.16037,   inf] (63), [-1.16034,   inf] (63), [-1.15973,   inf] (63), [-1.15940,   inf] (63), [-1.15901,   inf] (63), [-1.15885,   inf] (63), [-1.15880,   inf] (63), 
length of domains: 5658
Total time: 1.3012	 pickout: 0.0739	 decision: 0.1685	 get_bound: 0.9981	 add_domain: 0.0607
Current lb:-1.1654207706451416
13146 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 37.05878400802612

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3213] [1, 109] [1, 3213] [1, 7701] [1, 3213] [1, 3213] [1, 3213] [1, 7701] [1, 3213] [1, 7701] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 574.8401489257812 with beta sum per layer: [0.0, 226.4822998046875, 2.4325742721557617]
alpha/beta optimization time: 0.8415980339050293
This batch time : update_bounds func: 0.9765	 prepare: 0.0501	 bound: 0.8420	 transfer: 0.0499	 finalize: 0.0333
Accumulated time: update_bounds func: 27.6490	 prepare: 1.3506	 bound: 23.3395	 transfer: 0.0499	 finalize: 1.5354
batch bounding time:  0.9772012233734131
Current worst splitting domains [lb, ub] (depth):
[-1.15906,   inf] (65), [-1.15878,   inf] (65), [-1.15784,   inf] (65), [-1.15628,   inf] (65), [-1.15616,   inf] (65), [-1.15567,   inf] (65), [-1.15554,   inf] (65), [-1.15490,   inf] (65), [-1.15455,   inf] (65), [-1.15443,   inf] (65), [-1.15341,   inf] (65), [-1.15340,   inf] (65), [-1.15284,   inf] (65), [-1.15279,   inf] (65), [-1.15265,   inf] (65), [-1.15257,   inf] (65), [-1.15218,   inf] (65), [-1.15199,   inf] (65), [-1.15176,   inf] (65), [-1.15167,   inf] (65), 
length of domains: 5914
Total time: 1.2502	 pickout: 0.0600	 decision: 0.1487	 get_bound: 0.9781	 add_domain: 0.0634
Current lb:-1.159060001373291
13658 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 38.31608843803406

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 618] [1, 7701] [1, 618] [1, 618] [1, 618] [1, 618] [1, 618] [1, 618] [1, 618] [1, 109] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 573.575927734375 with beta sum per layer: [0.0, 235.46121215820312, 1.5432252883911133]
alpha/beta optimization time: 1.06803297996521
This batch time : update_bounds func: 1.2330	 prepare: 0.0524	 bound: 1.0684	 transfer: 0.0500	 finalize: 0.0607
Accumulated time: update_bounds func: 28.8820	 prepare: 1.4030	 bound: 24.4080	 transfer: 0.0500	 finalize: 1.5961
batch bounding time:  1.2337274551391602
Current worst splitting domains [lb, ub] (depth):
[-1.15244,   inf] (67), [-1.15119,   inf] (67), [-1.14958,   inf] (67), [-1.14951,   inf] (67), [-1.14949,   inf] (67), [-1.14906,   inf] (67), [-1.14877,   inf] (67), [-1.14867,   inf] (67), [-1.14862,   inf] (67), [-1.14822,   inf] (67), [-1.14790,   inf] (67), [-1.14765,   inf] (67), [-1.14672,   inf] (67), [-1.14670,   inf] (67), [-1.14615,   inf] (67), [-1.14613,   inf] (67), [-1.14612,   inf] (67), [-1.14600,   inf] (67), [-1.14588,   inf] (67), [-1.14582,   inf] (67), 
length of domains: 6170
Total time: 1.5353	 pickout: 0.0829	 decision: 0.1549	 get_bound: 1.2345	 add_domain: 0.0629
Current lb:-1.152438998222351
14170 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 39.8591411113739

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7701] [1, 7701] [1, 7701] [1, 3213] [1, 7701] [1, 109] [1, 109] [1, 3213] [1, 3213] [1, 7701] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 570.4410400390625 with beta sum per layer: [0.0, 251.32907104492188, 1.2994368076324463]
alpha/beta optimization time: 0.8391430377960205
This batch time : update_bounds func: 0.9716	 prepare: 0.0514	 bound: 0.8395	 transfer: 0.0457	 finalize: 0.0337
Accumulated time: update_bounds func: 29.8536	 prepare: 1.4544	 bound: 25.2475	 transfer: 0.0457	 finalize: 1.6298
batch bounding time:  0.9722278118133545
Current worst splitting domains [lb, ub] (depth):
[-1.14368,   inf] (69), [-1.14356,   inf] (69), [-1.14331,   inf] (69), [-1.14324,   inf] (69), [-1.14287,   inf] (69), [-1.14255,   inf] (69), [-1.14248,   inf] (69), [-1.14248,   inf] (69), [-1.14241,   inf] (69), [-1.14191,   inf] (69), [-1.14121,   inf] (69), [-1.14084,   inf] (69), [-1.14076,   inf] (69), [-1.14064,   inf] (69), [-1.14062,   inf] (69), [-1.14052,   inf] (69), [-1.14037,   inf] (69), [-1.14012,   inf] (69), [-1.14010,   inf] (69), [-1.14007,   inf] (69), 
length of domains: 6426
Total time: 1.2444	 pickout: 0.0577	 decision: 0.1504	 get_bound: 0.9731	 add_domain: 0.0632
Current lb:-1.1436759233474731
14682 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 41.1099271774292

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 109] [1, 7701] [1, 4822] [1, 7701] [1, 4822] [1, 109] [1, 109] [1, 4822] [1, 7701] [1, 4822] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 567.8392333984375 with beta sum per layer: [0.0, 213.0450897216797, 1.9914125204086304]
alpha/beta optimization time: 0.8374600410461426
This batch time : update_bounds func: 0.9754	 prepare: 0.0518	 bound: 0.8378	 transfer: 0.0490	 finalize: 0.0355
Accumulated time: update_bounds func: 30.8290	 prepare: 1.5062	 bound: 26.0853	 transfer: 0.0490	 finalize: 1.6654
batch bounding time:  0.9761617183685303
Current worst splitting domains [lb, ub] (depth):
[-1.13822,   inf] (71), [-1.13821,   inf] (71), [-1.13780,   inf] (71), [-1.13739,   inf] (71), [-1.13708,   inf] (71), [-1.13702,   inf] (71), [-1.13686,   inf] (71), [-1.13573,   inf] (71), [-1.13542,   inf] (71), [-1.13533,   inf] (71), [-1.13530,   inf] (71), [-1.13501,   inf] (71), [-1.13489,   inf] (71), [-1.13485,   inf] (71), [-1.13483,   inf] (71), [-1.13457,   inf] (71), [-1.13451,   inf] (71), [-1.13444,   inf] (71), [-1.13417,   inf] (71), [-1.13417,   inf] (71), 
length of domains: 6682
Total time: 1.2760	 pickout: 0.0776	 decision: 0.1534	 get_bound: 0.9770	 add_domain: 0.0680
Current lb:-1.138218879699707
15194 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 42.39352250099182

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2130] [1, 6949] [1, 6949] [1, 7710] [1, 2130] [1, 2130] [1, 7710] [1, 2130] [1, 6949] [1, 2130] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 565.543212890625 with beta sum per layer: [0.0, 238.31326293945312, 2.137080430984497]
alpha/beta optimization time: 0.8660714626312256
This batch time : update_bounds func: 1.3031	 prepare: 0.0647	 bound: 0.8666	 transfer: 0.0585	 finalize: 0.3119
Accumulated time: update_bounds func: 32.1321	 prepare: 1.5709	 bound: 26.9519	 transfer: 0.0585	 finalize: 1.9772
batch bounding time:  1.3037168979644775
Current worst splitting domains [lb, ub] (depth):
[-1.13339,   inf] (73), [-1.13224,   inf] (73), [-1.13218,   inf] (73), [-1.13216,   inf] (73), [-1.13165,   inf] (73), [-1.13094,   inf] (73), [-1.13087,   inf] (73), [-1.13052,   inf] (73), [-1.13050,   inf] (73), [-1.13047,   inf] (73), [-1.12975,   inf] (73), [-1.12964,   inf] (73), [-1.12951,   inf] (73), [-1.12938,   inf] (73), [-1.12933,   inf] (73), [-1.12933,   inf] (73), [-1.12930,   inf] (73), [-1.12923,   inf] (73), [-1.12923,   inf] (73), [-1.12878,   inf] (73), 
length of domains: 6938
Total time: 1.5881	 pickout: 0.0635	 decision: 0.1534	 get_bound: 1.3045	 add_domain: 0.0667
Current lb:-1.133390188217163
15706 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 43.98912239074707

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3476] [1, 3476] [1, 3476] [1, 6949] [1, 6949] [1, 2130] [1, 3476] [1, 7710] [1, 3476] [1, 3476] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 562.1392822265625 with beta sum per layer: [0.0, 266.6997375488281, 1.9117475748062134]
alpha/beta optimization time: 0.8451526165008545
This batch time : update_bounds func: 0.9924	 prepare: 0.0533	 bound: 0.8456	 transfer: 0.0568	 finalize: 0.0352
Accumulated time: update_bounds func: 33.1245	 prepare: 1.6242	 bound: 27.7975	 transfer: 0.0568	 finalize: 2.0125
batch bounding time:  0.9931659698486328
Current worst splitting domains [lb, ub] (depth):
[-1.12892,   inf] (75), [-1.12792,   inf] (75), [-1.12754,   inf] (75), [-1.12639,   inf] (75), [-1.12625,   inf] (75), [-1.12606,   inf] (75), [-1.12600,   inf] (75), [-1.12532,   inf] (75), [-1.12528,   inf] (75), [-1.12516,   inf] (75), [-1.12502,   inf] (75), [-1.12501,   inf] (75), [-1.12499,   inf] (75), [-1.12490,   inf] (75), [-1.12461,   inf] (75), [-1.12436,   inf] (75), [-1.12412,   inf] (75), [-1.12399,   inf] (75), [-1.12356,   inf] (75), [-1.12344,   inf] (75), 
length of domains: 7194
Total time: 1.2984	 pickout: 0.0800	 decision: 0.1553	 get_bound: 0.9940	 add_domain: 0.0691
Current lb:-1.1289207935333252
16218 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 45.29637312889099

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 4330] [1, 4330] [1, 4330] [1, 4330] [1, 618] [1, 4330] [1, 4330] [1, 2130] [1, 4330] [1, 4330] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 562.7303466796875 with beta sum per layer: [0.0, 274.43011474609375, 2.0368220806121826]
alpha/beta optimization time: 0.8531913757324219
This batch time : update_bounds func: 0.9981	 prepare: 0.0553	 bound: 0.8537	 transfer: 0.0484	 finalize: 0.0392
Accumulated time: update_bounds func: 34.1226	 prepare: 1.6795	 bound: 28.6511	 transfer: 0.0484	 finalize: 2.0517
batch bounding time:  0.9989049434661865
Current worst splitting domains [lb, ub] (depth):
[-1.12335,   inf] (77), [-1.12233,   inf] (77), [-1.12194,   inf] (77), [-1.12078,   inf] (77), [-1.12077,   inf] (77), [-1.12064,   inf] (77), [-1.12059,   inf] (77), [-1.11987,   inf] (77), [-1.11986,   inf] (77), [-1.11971,   inf] (77), [-1.11969,   inf] (77), [-1.11957,   inf] (77), [-1.11945,   inf] (77), [-1.11919,   inf] (77), [-1.11882,   inf] (77), [-1.11852,   inf] (77), [-1.11838,   inf] (77), [-1.11822,   inf] (77), [-1.11808,   inf] (77), [-1.11803,   inf] (77), 
length of domains: 7450
Total time: 1.3168	 pickout: 0.0861	 decision: 0.1576	 get_bound: 0.9998	 add_domain: 0.0733
Current lb:-1.123352289199829
16730 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 46.622599363327026

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 4822] [1, 4822] [1, 4822] [1, 4822] [1, 4822] [1, 618] [1, 4822] [1, 4822] [1, 7710] [1, 4822] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 560.9630126953125 with beta sum per layer: [0.0, 272.8470153808594, 2.262209177017212]
alpha/beta optimization time: 0.8446035385131836
This batch time : update_bounds func: 1.2339	 prepare: 0.0558	 bound: 0.8450	 transfer: 0.0480	 finalize: 0.2835
Accumulated time: update_bounds func: 35.3565	 prepare: 1.7353	 bound: 29.4962	 transfer: 0.0480	 finalize: 2.3351
batch bounding time:  1.2347078323364258
Current worst splitting domains [lb, ub] (depth):
[-1.11891,   inf] (79), [-1.11793,   inf] (79), [-1.11750,   inf] (79), [-1.11639,   inf] (79), [-1.11634,   inf] (79), [-1.11614,   inf] (79), [-1.11543,   inf] (79), [-1.11533,   inf] (79), [-1.11518,   inf] (79), [-1.11517,   inf] (79), [-1.11488,   inf] (79), [-1.11473,   inf] (79), [-1.11464,   inf] (79), [-1.11443,   inf] (79), [-1.11424,   inf] (79), [-1.11389,   inf] (79), [-1.11386,   inf] (79), [-1.11363,   inf] (79), [-1.11362,   inf] (79), [-1.11345,   inf] (65), 
length of domains: 7706
Total time: 1.5722	 pickout: 0.1090	 decision: 0.1600	 get_bound: 1.2357	 add_domain: 0.0675
Current lb:-1.11890709400177
17242 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 48.20316696166992

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6949] [1, 6949] [1, 6949] [1, 6949] [1, 6949] [1, 6949] [1, 6949] [1, 6949] [1, 6949] [1, 6949] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 560.606689453125 with beta sum per layer: [0.0, 299.76776123046875, 2.799833059310913]
alpha/beta optimization time: 0.854210376739502
This batch time : update_bounds func: 0.9973	 prepare: 0.0531	 bound: 0.8546	 transfer: 0.0522	 finalize: 0.0359
Accumulated time: update_bounds func: 36.3538	 prepare: 1.7884	 bound: 30.3508	 transfer: 0.0522	 finalize: 2.3710
batch bounding time:  0.9980404376983643
Current worst splitting domains [lb, ub] (depth):
[-1.11209,   inf] (71), [-1.11208,   inf] (69), [-1.11207,   inf] (73), [-1.11207,   inf] (65), [-1.11207,   inf] (75), [-1.11207,   inf] (63), [-1.11206,   inf] (65), [-1.11205,   inf] (67), [-1.11204,   inf] (71), [-1.11204,   inf] (71), [-1.11203,   inf] (69), [-1.11202,   inf] (61), [-1.11202,   inf] (67), [-1.11202,   inf] (71), [-1.11200,   inf] (75), [-1.11200,   inf] (65), [-1.11199,   inf] (77), [-1.11199,   inf] (65), [-1.11198,   inf] (69), [-1.11197,   inf] (75), 
length of domains: 7962
Total time: 1.2999	 pickout: 0.0773	 decision: 0.1546	 get_bound: 0.9990	 add_domain: 0.0691
Current lb:-1.1120893955230713
17754 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 49.51700282096863

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3476] [1, 4530] [1, 2130] [1, 109] [1, 618] [1, 7701] [1, 7701] [1, 3213] [1, 7710] [1, 2130] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 559.7393798828125 with beta sum per layer: [0.0, 299.884033203125, 2.7885429859161377]
alpha/beta optimization time: 0.8463153839111328
This batch time : update_bounds func: 0.9944	 prepare: 0.0541	 bound: 0.8467	 transfer: 0.0564	 finalize: 0.0353
Accumulated time: update_bounds func: 37.3482	 prepare: 1.8425	 bound: 31.1975	 transfer: 0.0564	 finalize: 2.4063
batch bounding time:  0.9950551986694336
Current worst splitting domains [lb, ub] (depth):
[-1.11071,   inf] (69), [-1.11070,   inf] (67), [-1.11070,   inf] (67), [-1.11070,   inf] (75), [-1.11069,   inf] (79), [-1.11069,   inf] (71), [-1.11068,   inf] (61), [-1.11068,   inf] (77), [-1.11066,   inf] (65), [-1.11064,   inf] (67), [-1.11064,   inf] (59), [-1.11063,   inf] (69), [-1.11063,   inf] (69), [-1.11063,   inf] (75), [-1.11063,   inf] (63), [-1.11062,   inf] (69), [-1.11062,   inf] (73), [-1.11061,   inf] (69), [-1.11061,   inf] (65), [-1.11061,   inf] (65), 
length of domains: 8218
Total time: 1.3158	 pickout: 0.0866	 decision: 0.1612	 get_bound: 0.9959	 add_domain: 0.0721
Current lb:-1.1107063293457031
18266 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 50.84027814865112

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 4822] [1, 3213] [1, 4822] [1, 618] [1, 6949] [1, 2130] [1, 4530] [1, 2130] [1, 618] [1, 109] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 558.6055908203125 with beta sum per layer: [0.0, 319.70166015625, 2.551265001296997]
alpha/beta optimization time: 0.8481845855712891
This batch time : update_bounds func: 1.0075	 prepare: 0.0563	 bound: 0.8486	 transfer: 0.0585	 finalize: 0.0425
Accumulated time: update_bounds func: 38.3556	 prepare: 1.8988	 bound: 32.0461	 transfer: 0.0585	 finalize: 2.4488
batch bounding time:  1.0082333087921143
Current worst splitting domains [lb, ub] (depth):
[-1.10935,   inf] (71), [-1.10933,   inf] (63), [-1.10931,   inf] (65), [-1.10931,   inf] (75), [-1.10930,   inf] (71), [-1.10929,   inf] (71), [-1.10928,   inf] (67), [-1.10928,   inf] (65), [-1.10928,   inf] (63), [-1.10927,   inf] (73), [-1.10927,   inf] (67), [-1.10927,   inf] (73), [-1.10926,   inf] (65), [-1.10926,   inf] (67), [-1.10925,   inf] (67), [-1.10925,   inf] (65), [-1.10925,   inf] (67), [-1.10924,   inf] (59), [-1.10924,   inf] (61), [-1.10924,   inf] (75), 
length of domains: 8474
Total time: 1.3227	 pickout: 0.0793	 decision: 0.1557	 get_bound: 1.0091	 add_domain: 0.0787
Current lb:-1.1093546152114868
18778 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 52.172513008117676

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2130] [1, 109] [1, 109] [1, 4330] [1, 2130] [1, 2130] [1, 7701] [1, 618] [1, 109] [1, 6949] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 558.1171264648438 with beta sum per layer: [0.0, 324.68243408203125, 2.8990726470947266]
alpha/beta optimization time: 0.8460588455200195
This batch time : update_bounds func: 0.9906	 prepare: 0.0515	 bound: 0.8465	 transfer: 0.0545	 finalize: 0.0369
Accumulated time: update_bounds func: 39.3463	 prepare: 1.9503	 bound: 32.8926	 transfer: 0.0545	 finalize: 2.4857
batch bounding time:  0.9913375377655029
Current worst splitting domains [lb, ub] (depth):
[-1.10811,   inf] (73), [-1.10810,   inf] (71), [-1.10810,   inf] (65), [-1.10809,   inf] (59), [-1.10808,   inf] (67), [-1.10808,   inf] (65), [-1.10807,   inf] (77), [-1.10805,   inf] (69), [-1.10805,   inf] (77), [-1.10804,   inf] (67), [-1.10803,   inf] (67), [-1.10802,   inf] (65), [-1.10802,   inf] (77), [-1.10801,   inf] (69), [-1.10801,   inf] (67), [-1.10801,   inf] (65), [-1.10801,   inf] (71), [-1.10801,   inf] (61), [-1.10801,   inf] (65), [-1.10801,   inf] (69), 
length of domains: 8730
Total time: 1.5776	 pickout: 0.0683	 decision: 0.4483	 get_bound: 0.9922	 add_domain: 0.0689
Current lb:-1.10811185836792
19290 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 53.75826334953308

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6949] [1, 2130] [1, 618] [1, 7710] [1, 7701] [1, 109] [1, 2130] [1, 4822] [1, 4822] [1, 109] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 557.5867919921875 with beta sum per layer: [0.0, 325.7362060546875, 2.662736415863037]
alpha/beta optimization time: 0.857658863067627
This batch time : update_bounds func: 1.0161	 prepare: 0.0603	 bound: 0.8581	 transfer: 0.0535	 finalize: 0.0384
Accumulated time: update_bounds func: 40.3624	 prepare: 2.0106	 bound: 33.7507	 transfer: 0.0535	 finalize: 2.5241
batch bounding time:  1.0169236660003662
Current worst splitting domains [lb, ub] (depth):
[-1.10698,   inf] (73), [-1.10698,   inf] (75), [-1.10698,   inf] (71), [-1.10698,   inf] (63), [-1.10697,   inf] (65), [-1.10697,   inf] (67), [-1.10697,   inf] (61), [-1.10697,   inf] (61), [-1.10696,   inf] (67), [-1.10696,   inf] (69), [-1.10696,   inf] (71), [-1.10696,   inf] (69), [-1.10695,   inf] (75), [-1.10694,   inf] (69), [-1.10694,   inf] (71), [-1.10694,   inf] (63), [-1.10694,   inf] (63), [-1.10694,   inf] (75), [-1.10693,   inf] (67), [-1.10693,   inf] (73), 
length of domains: 8986
Total time: 1.3173	 pickout: 0.0727	 decision: 0.1530	 get_bound: 1.0179	 add_domain: 0.0737
Current lb:-1.1069833040237427
19802 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 55.08336400985718

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 4330] [1, 4330] [1, 3476] [1, 109] [1, 7701] [1, 7701] [1, 3213] [1, 3213] [1, 3213] [1, 7701] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 556.9774780273438 with beta sum per layer: [0.0, 337.36468505859375, 2.724036693572998]
alpha/beta optimization time: 0.8531336784362793
This batch time : update_bounds func: 0.9961	 prepare: 0.0550	 bound: 0.8536	 transfer: 0.0497	 finalize: 0.0362
Accumulated time: update_bounds func: 41.3585	 prepare: 2.0656	 bound: 34.6043	 transfer: 0.0497	 finalize: 2.5602
batch bounding time:  0.9968500137329102
Current worst splitting domains [lb, ub] (depth):
[-1.10587,   inf] (67), [-1.10586,   inf] (69), [-1.10585,   inf] (61), [-1.10585,   inf] (69), [-1.10584,   inf] (67), [-1.10584,   inf] (69), [-1.10584,   inf] (67), [-1.10583,   inf] (65), [-1.10583,   inf] (73), [-1.10583,   inf] (73), [-1.10583,   inf] (67), [-1.10583,   inf] (69), [-1.10582,   inf] (61), [-1.10582,   inf] (77), [-1.10582,   inf] (69), [-1.10582,   inf] (71), [-1.10581,   inf] (71), [-1.10581,   inf] (67), [-1.10580,   inf] (69), [-1.10580,   inf] (81), 
length of domains: 9242
Total time: 1.2974	 pickout: 0.0685	 decision: 0.1626	 get_bound: 0.9977	 add_domain: 0.0686
Current lb:-1.1058655977249146
20314 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 56.38933444023132

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3213] [1, 109] [1, 618] [1, 109] [1, 3213] [1, 7701] [1, 4530] [1, 109] [1, 3476] [1, 6949] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 556.5045776367188 with beta sum per layer: [0.0, 336.8463134765625, 3.1010189056396484]
alpha/beta optimization time: 0.8445413112640381
This batch time : update_bounds func: 0.9859	 prepare: 0.0561	 bound: 0.8449	 transfer: 0.0468	 finalize: 0.0362
Accumulated time: update_bounds func: 42.3444	 prepare: 2.1217	 bound: 35.4492	 transfer: 0.0468	 finalize: 2.5964
batch bounding time:  0.9866683483123779
Current worst splitting domains [lb, ub] (depth):
[-1.10483,   inf] (73), [-1.10482,   inf] (83), [-1.10482,   inf] (73), [-1.10482,   inf] (67), [-1.10482,   inf] (69), [-1.10481,   inf] (71), [-1.10481,   inf] (63), [-1.10480,   inf] (73), [-1.10480,   inf] (67), [-1.10480,   inf] (69), [-1.10480,   inf] (61), [-1.10480,   inf] (61), [-1.10479,   inf] (63), [-1.10479,   inf] (75), [-1.10479,   inf] (71), [-1.10478,   inf] (61), [-1.10478,   inf] (69), [-1.10477,   inf] (65), [-1.10477,   inf] (67), [-1.10477,   inf] (73), 
length of domains: 9498
Total time: 1.5661	 pickout: 0.0801	 decision: 0.1556	 get_bound: 0.9875	 add_domain: 0.3428
Current lb:-1.1048253774642944
20826 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 57.96309757232666

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6949] [1, 470] [1, 6949] [1, 109] [1, 4822] [1, 469] [1, 109] [1, 3476] [1, 7701] [1, 109] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 555.2724609375 with beta sum per layer: [0.0, 338.85650634765625, 2.777806520462036]
alpha/beta optimization time: 0.8482544422149658
This batch time : update_bounds func: 1.0021	 prepare: 0.0579	 bound: 0.8487	 transfer: 0.0552	 finalize: 0.0385
Accumulated time: update_bounds func: 43.3465	 prepare: 2.1796	 bound: 36.2979	 transfer: 0.0552	 finalize: 2.6349
batch bounding time:  1.002868413925171
Current worst splitting domains [lb, ub] (depth):
[-1.10386,   inf] (71), [-1.10386,   inf] (77), [-1.10385,   inf] (63), [-1.10385,   inf] (77), [-1.10384,   inf] (63), [-1.10384,   inf] (63), [-1.10384,   inf] (77), [-1.10383,   inf] (61), [-1.10383,   inf] (71), [-1.10383,   inf] (71), [-1.10383,   inf] (83), [-1.10382,   inf] (75), [-1.10382,   inf] (77), [-1.10382,   inf] (73), [-1.10382,   inf] (75), [-1.10381,   inf] (59), [-1.10381,   inf] (67), [-1.10381,   inf] (73), [-1.10380,   inf] (67), [-1.10380,   inf] (77), 
length of domains: 9754
Total time: 1.3202	 pickout: 0.0837	 decision: 0.1593	 get_bound: 1.0038	 add_domain: 0.0734
Current lb:-1.1038614511489868
21338 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 59.29131197929382

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 469] [1, 2130] [1, 7701] [1, 4822] [1, 7701] [1, 667] [1, 6949] [1, 7972] [1, 469] [1, 6949] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 555.3394775390625 with beta sum per layer: [0.0, 335.4979553222656, 3.015305280685425]
alpha/beta optimization time: 0.8638663291931152
This batch time : update_bounds func: 1.0188	 prepare: 0.0570	 bound: 0.8643	 transfer: 0.0590	 finalize: 0.0369
Accumulated time: update_bounds func: 44.3654	 prepare: 2.2366	 bound: 37.1622	 transfer: 0.0590	 finalize: 2.6717
batch bounding time:  1.0196373462677002
Current worst splitting domains [lb, ub] (depth):
[-1.10293,   inf] (73), [-1.10293,   inf] (69), [-1.10293,   inf] (67), [-1.10293,   inf] (73), [-1.10293,   inf] (65), [-1.10292,   inf] (71), [-1.10292,   inf] (83), [-1.10292,   inf] (65), [-1.10291,   inf] (67), [-1.10291,   inf] (63), [-1.10291,   inf] (67), [-1.10290,   inf] (75), [-1.10290,   inf] (67), [-1.10289,   inf] (75), [-1.10289,   inf] (63), [-1.10289,   inf] (67), [-1.10289,   inf] (59), [-1.10289,   inf] (63), [-1.10289,   inf] (69), [-1.10288,   inf] (75), 
length of domains: 10010
Total time: 1.3342	 pickout: 0.0858	 decision: 0.1592	 get_bound: 1.0205	 add_domain: 0.0686
Current lb:-1.1029326915740967
21850 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 60.63448691368103

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3476] [1, 7701] [1, 109] [1, 6949] [1, 3213] [1, 6949] [1, 470] [1, 7701] [1, 667] [1, 7701] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 554.71142578125 with beta sum per layer: [0.0, 342.6793212890625, 3.2722878456115723]
alpha/beta optimization time: 0.8394896984100342
This batch time : update_bounds func: 0.9841	 prepare: 0.0562	 bound: 0.8399	 transfer: 0.0494	 finalize: 0.0369
Accumulated time: update_bounds func: 45.3495	 prepare: 2.2928	 bound: 38.0022	 transfer: 0.0494	 finalize: 2.7086
batch bounding time:  0.9849543571472168
Current worst splitting domains [lb, ub] (depth):
[-1.10202,   inf] (77), [-1.10202,   inf] (63), [-1.10202,   inf] (73), [-1.10201,   inf] (71), [-1.10201,   inf] (81), [-1.10201,   inf] (67), [-1.10201,   inf] (63), [-1.10201,   inf] (65), [-1.10200,   inf] (71), [-1.10200,   inf] (65), [-1.10200,   inf] (75), [-1.10200,   inf] (69), [-1.10199,   inf] (75), [-1.10199,   inf] (63), [-1.10199,   inf] (77), [-1.10199,   inf] (69), [-1.10199,   inf] (77), [-1.10198,   inf] (73), [-1.10198,   inf] (71), [-1.10198,   inf] (59), 
length of domains: 10266
Total time: 1.2845	 pickout: 0.0729	 decision: 0.1549	 get_bound: 0.9858	 add_domain: 0.0709
Current lb:-1.102023720741272
22362 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 61.93311595916748

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 4822] [1, 7701] [1, 2130] [1, 3476] [1, 4330] [1, 3213] [1, 3213] [1, 618] [1, 7710] [1, 109] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 554.16162109375 with beta sum per layer: [0.0, 354.0393981933594, 3.058572769165039]
alpha/beta optimization time: 0.8529098033905029
This batch time : update_bounds func: 1.0311	 prepare: 0.0785	 bound: 0.8535	 transfer: 0.0577	 finalize: 0.0399
Accumulated time: update_bounds func: 46.3806	 prepare: 2.3712	 bound: 38.8556	 transfer: 0.0577	 finalize: 2.7485
batch bounding time:  1.031902551651001
Current worst splitting domains [lb, ub] (depth):
[-1.10117,   inf] (69), [-1.10117,   inf] (73), [-1.10116,   inf] (63), [-1.10116,   inf] (61), [-1.10115,   inf] (75), [-1.10115,   inf] (71), [-1.10114,   inf] (65), [-1.10114,   inf] (61), [-1.10113,   inf] (83), [-1.10112,   inf] (77), [-1.10112,   inf] (75), [-1.10112,   inf] (59), [-1.10112,   inf] (75), [-1.10111,   inf] (65), [-1.10111,   inf] (77), [-1.10111,   inf] (69), [-1.10110,   inf] (73), [-1.10110,   inf] (59), [-1.10110,   inf] (63), [-1.10110,   inf] (73), 
length of domains: 10522
Total time: 1.3700	 pickout: 0.1068	 decision: 0.1559	 get_bound: 1.0330	 add_domain: 0.0744
Current lb:-1.1011704206466675
22874 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 63.31262135505676

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7701] [1, 3476] [1, 109] [1, 3213] [1, 4330] [1, 2130] [1, 618] [1, 3213] [1, 470] [1, 2130] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 553.14501953125 with beta sum per layer: [0.0, 336.99530029296875, 3.376230239868164]
alpha/beta optimization time: 0.843982458114624
This batch time : update_bounds func: 0.9895	 prepare: 0.0538	 bound: 0.8444	 transfer: 0.0544	 finalize: 0.0354
Accumulated time: update_bounds func: 47.3701	 prepare: 2.4250	 bound: 39.7000	 transfer: 0.0544	 finalize: 2.7839
batch bounding time:  0.9901857376098633
Current worst splitting domains [lb, ub] (depth):
[-1.10034,   inf] (79), [-1.10033,   inf] (71), [-1.10033,   inf] (75), [-1.10033,   inf] (65), [-1.10032,   inf] (71), [-1.10032,   inf] (75), [-1.10032,   inf] (75), [-1.10032,   inf] (77), [-1.10031,   inf] (75), [-1.10031,   inf] (69), [-1.10031,   inf] (73), [-1.10031,   inf] (65), [-1.10031,   inf] (63), [-1.10030,   inf] (75), [-1.10030,   inf] (71), [-1.10030,   inf] (67), [-1.10030,   inf] (71), [-1.10029,   inf] (67), [-1.10029,   inf] (73), [-1.10029,   inf] (73), 
length of domains: 10778
Total time: 1.6842	 pickout: 0.1235	 decision: 0.4991	 get_bound: 0.9911	 add_domain: 0.0706
Current lb:-1.100337028503418
23386 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 65.00779914855957

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6949] [1, 2130] [1, 2130] [1, 618] [1, 469] [1, 4330] [1, 2130] [1, 3476] [1, 7710] [1, 7701] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 552.7523803710938 with beta sum per layer: [0.0, 351.1698913574219, 3.3166394233703613]
alpha/beta optimization time: 0.8490936756134033
This batch time : update_bounds func: 0.9937	 prepare: 0.0550	 bound: 0.8495	 transfer: 0.0519	 finalize: 0.0358
Accumulated time: update_bounds func: 48.3638	 prepare: 2.4800	 bound: 40.5495	 transfer: 0.0519	 finalize: 2.8197
batch bounding time:  0.9944534301757812
Current worst splitting domains [lb, ub] (depth):
[-1.09963,   inf] (77), [-1.09963,   inf] (81), [-1.09963,   inf] (73), [-1.09963,   inf] (79), [-1.09962,   inf] (71), [-1.09962,   inf] (75), [-1.09962,   inf] (75), [-1.09961,   inf] (65), [-1.09961,   inf] (73), [-1.09961,   inf] (67), [-1.09960,   inf] (77), [-1.09960,   inf] (77), [-1.09959,   inf] (79), [-1.09959,   inf] (75), [-1.09959,   inf] (75), [-1.09959,   inf] (73), [-1.09959,   inf] (73), [-1.09958,   inf] (59), [-1.09958,   inf] (75), [-1.09958,   inf] (77), 
length of domains: 11034
Total time: 1.2928	 pickout: 0.0718	 decision: 0.1541	 get_bound: 0.9954	 add_domain: 0.0715
Current lb:-1.099632978439331
23898 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 66.3094847202301

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2130] [1, 4330] [1, 3476] [1, 4330] [1, 2130] [1, 618] [1, 618] [1, 618] [1, 2130] [1, 7701] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 552.234375 with beta sum per layer: [0.0, 368.5058288574219, 2.897651195526123]
alpha/beta optimization time: 0.8539607524871826
This batch time : update_bounds func: 1.0073	 prepare: 0.0547	 bound: 0.8544	 transfer: 0.0568	 finalize: 0.0399
Accumulated time: update_bounds func: 49.3711	 prepare: 2.5347	 bound: 41.4038	 transfer: 0.0568	 finalize: 2.8595
batch bounding time:  1.0080702304840088
Current worst splitting domains [lb, ub] (depth):
[-1.09891,   inf] (75), [-1.09890,   inf] (71), [-1.09890,   inf] (77), [-1.09889,   inf] (69), [-1.09889,   inf] (65), [-1.09888,   inf] (71), [-1.09888,   inf] (69), [-1.09888,   inf] (65), [-1.09888,   inf] (69), [-1.09887,   inf] (71), [-1.09887,   inf] (73), [-1.09887,   inf] (69), [-1.09887,   inf] (63), [-1.09886,   inf] (59), [-1.09886,   inf] (71), [-1.09885,   inf] (71), [-1.09885,   inf] (73), [-1.09885,   inf] (71), [-1.09884,   inf] (81), [-1.09884,   inf] (67), 
length of domains: 11290
Total time: 1.3025	 pickout: 0.0680	 decision: 0.1542	 get_bound: 1.0090	 add_domain: 0.0713
Current lb:-1.0989055633544922
24410 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 67.61994409561157

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2130] [1, 2130] [1, 2130] [1, 4822] [1, 3213] [1, 3476] [1, 4822] [1, 109] [1, 7701] [1, 7710] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 552.5733032226562 with beta sum per layer: [0.0, 375.61602783203125, 3.2890520095825195]
alpha/beta optimization time: 0.8489551544189453
This batch time : update_bounds func: 0.9967	 prepare: 0.0594	 bound: 0.8494	 transfer: 0.0481	 finalize: 0.0385
Accumulated time: update_bounds func: 50.3678	 prepare: 2.5940	 bound: 42.2532	 transfer: 0.0481	 finalize: 2.8981
batch bounding time:  0.9974625110626221
Current worst splitting domains [lb, ub] (depth):
[-1.09822,   inf] (83), [-1.09822,   inf] (67), [-1.09821,   inf] (69), [-1.09821,   inf] (73), [-1.09821,   inf] (65), [-1.09821,   inf] (73), [-1.09820,   inf] (75), [-1.09820,   inf] (69), [-1.09820,   inf] (73), [-1.09820,   inf] (71), [-1.09819,   inf] (69), [-1.09819,   inf] (69), [-1.09819,   inf] (67), [-1.09819,   inf] (83), [-1.09819,   inf] (63), [-1.09818,   inf] (63), [-1.09818,   inf] (65), [-1.09818,   inf] (77), [-1.09817,   inf] (71), [-1.09817,   inf] (73), 
length of domains: 11546
Total time: 1.3399	 pickout: 0.1084	 decision: 0.1566	 get_bound: 0.9985	 add_domain: 0.0765
Current lb:-1.0982182025909424
24922 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 68.96963763237

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6676] [1, 3213] [1, 3213] [1, 2130] [1, 618] [1, 3476] [1, 4330] [1, 667] [1, 3213] [1, 2130] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 550.6971435546875 with beta sum per layer: [0.0, 372.971435546875, 3.2436721324920654]
alpha/beta optimization time: 0.842644214630127
This batch time : update_bounds func: 0.9902	 prepare: 0.0558	 bound: 0.8431	 transfer: 0.0532	 finalize: 0.0357
Accumulated time: update_bounds func: 51.3580	 prepare: 2.6498	 bound: 43.0963	 transfer: 0.0532	 finalize: 2.9338
batch bounding time:  0.990912675857544
Current worst splitting domains [lb, ub] (depth):
[-1.09755,   inf] (67), [-1.09755,   inf] (67), [-1.09754,   inf] (83), [-1.09754,   inf] (67), [-1.09754,   inf] (69), [-1.09753,   inf] (85), [-1.09753,   inf] (63), [-1.09752,   inf] (69), [-1.09752,   inf] (85), [-1.09752,   inf] (61), [-1.09751,   inf] (71), [-1.09751,   inf] (75), [-1.09751,   inf] (77), [-1.09751,   inf] (77), [-1.09750,   inf] (77), [-1.09750,   inf] (73), [-1.09750,   inf] (57), [-1.09749,   inf] (73), [-1.09749,   inf] (73), [-1.09749,   inf] (69), 
length of domains: 11802
Total time: 1.7551	 pickout: 0.0801	 decision: 0.6111	 get_bound: 0.9917	 add_domain: 0.0722
Current lb:-1.0975456237792969
25434 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 70.73309898376465

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3213] [1, 109] [1, 4330] [1, 3213] [1, 4822] [1, 470] [1, 3213] [1, 109] [1, 470] [1, 4530] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 551.5 with beta sum per layer: [0.0, 364.67144775390625, 3.516592502593994]
alpha/beta optimization time: 0.854996919631958
This batch time : update_bounds func: 1.0201	 prepare: 0.0556	 bound: 0.8554	 transfer: 0.0591	 finalize: 0.0482
Accumulated time: update_bounds func: 52.3781	 prepare: 2.7054	 bound: 43.9517	 transfer: 0.0591	 finalize: 2.9820
batch bounding time:  1.0208284854888916
Current worst splitting domains [lb, ub] (depth):
[-1.09691,   inf] (73), [-1.09691,   inf] (67), [-1.09691,   inf] (67), [-1.09691,   inf] (63), [-1.09691,   inf] (69), [-1.09690,   inf] (73), [-1.09689,   inf] (79), [-1.09689,   inf] (65), [-1.09689,   inf] (71), [-1.09689,   inf] (83), [-1.09689,   inf] (83), [-1.09689,   inf] (57), [-1.09688,   inf] (85), [-1.09688,   inf] (63), [-1.09688,   inf] (73), [-1.09688,   inf] (69), [-1.09688,   inf] (71), [-1.09688,   inf] (71), [-1.09688,   inf] (71), [-1.09688,   inf] (77), 
length of domains: 12058
Total time: 1.3169	 pickout: 0.0687	 decision: 0.1551	 get_bound: 1.0217	 add_domain: 0.0715
Current lb:-1.0969105958938599
25946 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 72.06057858467102

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3213] [1, 3213] [1, 109] [1, 618] [1, 4822] [1, 2130] [1, 4822] [1, 7701] [1, 3476] [1, 470] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 549.9072875976562 with beta sum per layer: [0.0, 363.6631774902344, 3.7986042499542236]
alpha/beta optimization time: 0.8434176445007324
This batch time : update_bounds func: 0.9878	 prepare: 0.0554	 bound: 0.8438	 transfer: 0.0503	 finalize: 0.0366
Accumulated time: update_bounds func: 53.3659	 prepare: 2.7608	 bound: 44.7955	 transfer: 0.0503	 finalize: 3.0186
batch bounding time:  0.9885444641113281
Current worst splitting domains [lb, ub] (depth):
[-1.09628,   inf] (77), [-1.09628,   inf] (69), [-1.09628,   inf] (63), [-1.09627,   inf] (85), [-1.09627,   inf] (63), [-1.09627,   inf] (73), [-1.09626,   inf] (75), [-1.09626,   inf] (75), [-1.09626,   inf] (69), [-1.09626,   inf] (77), [-1.09626,   inf] (81), [-1.09626,   inf] (69), [-1.09625,   inf] (61), [-1.09625,   inf] (69), [-1.09625,   inf] (73), [-1.09625,   inf] (75), [-1.09625,   inf] (75), [-1.09625,   inf] (65), [-1.09625,   inf] (69), [-1.09623,   inf] (61), 
length of domains: 12314
Total time: 1.3521	 pickout: 0.1381	 decision: 0.1534	 get_bound: 0.9894	 add_domain: 0.0711
Current lb:-1.0962835550308228
26458 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 73.42090106010437

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6949] [1, 4822] [1, 109] [1, 470] [1, 7701] [1, 6949] [1, 3476] [1, 618] [1, 4822] [1, 4822] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 549.5667724609375 with beta sum per layer: [0.0, 372.1142578125, 3.800116539001465]
alpha/beta optimization time: 0.8434956073760986
This batch time : update_bounds func: 0.9929	 prepare: 0.0549	 bound: 0.8439	 transfer: 0.0487	 finalize: 0.0434
Accumulated time: update_bounds func: 54.3588	 prepare: 2.8157	 bound: 45.6394	 transfer: 0.0487	 finalize: 3.0620
batch bounding time:  0.9939241409301758
Current worst splitting domains [lb, ub] (depth):
[-1.09570,   inf] (83), [-1.09570,   inf] (73), [-1.09570,   inf] (65), [-1.09570,   inf] (69), [-1.09570,   inf] (81), [-1.09570,   inf] (75), [-1.09569,   inf] (67), [-1.09569,   inf] (69), [-1.09569,   inf] (73), [-1.09568,   inf] (61), [-1.09568,   inf] (81), [-1.09568,   inf] (65), [-1.09568,   inf] (71), [-1.09568,   inf] (63), [-1.09568,   inf] (69), [-1.09567,   inf] (67), [-1.09567,   inf] (71), [-1.09567,   inf] (73), [-1.09567,   inf] (75), [-1.09566,   inf] (69), 
length of domains: 12570
Total time: 1.3339	 pickout: 0.0995	 decision: 0.1564	 get_bound: 0.9952	 add_domain: 0.0828
Current lb:-1.0957027673721313
26970 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 74.76615262031555

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6676] [1, 3476] [1, 109] [1, 7701] [1, 7710] [1, 618] [1, 7701] [1, 3213] [1, 2130] [1, 109] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 550.6957397460938 with beta sum per layer: [0.0, 371.37506103515625, 3.145778179168701]
alpha/beta optimization time: 0.844977617263794
This batch time : update_bounds func: 0.9978	 prepare: 0.0573	 bound: 0.8455	 transfer: 0.0550	 finalize: 0.0385
Accumulated time: update_bounds func: 55.3566	 prepare: 2.8730	 bound: 46.4849	 transfer: 0.0550	 finalize: 3.1005
batch bounding time:  0.9985852241516113
Current worst splitting domains [lb, ub] (depth):
[-1.09513,   inf] (69), [-1.09513,   inf] (71), [-1.09513,   inf] (71), [-1.09513,   inf] (73), [-1.09513,   inf] (69), [-1.09513,   inf] (83), [-1.09513,   inf] (77), [-1.09512,   inf] (71), [-1.09512,   inf] (71), [-1.09512,   inf] (73), [-1.09511,   inf] (71), [-1.09511,   inf] (75), [-1.09511,   inf] (77), [-1.09511,   inf] (73), [-1.09510,   inf] (75), [-1.09510,   inf] (69), [-1.09510,   inf] (81), [-1.09510,   inf] (79), [-1.09509,   inf] (77), [-1.09509,   inf] (71), 
length of domains: 12826
Total time: 1.3085	 pickout: 0.0777	 decision: 0.1605	 get_bound: 0.9995	 add_domain: 0.0708
Current lb:-1.095133662223816
27482 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 76.08371424674988

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 4822] [1, 6949] [1, 7710] [1, 4330] [1, 4822] [1, 6676] [1, 4822] [1, 469] [1, 2130] [1, 3213] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 550.046142578125 with beta sum per layer: [0.0, 361.4315185546875, 3.713745594024658]
alpha/beta optimization time: 0.8580360412597656
This batch time : update_bounds func: 1.0045	 prepare: 0.0540	 bound: 0.8584	 transfer: 0.0544	 finalize: 0.0359
Accumulated time: update_bounds func: 56.3611	 prepare: 2.9270	 bound: 47.3433	 transfer: 0.0544	 finalize: 3.1364
batch bounding time:  1.0052547454833984
Current worst splitting domains [lb, ub] (depth):
[-1.09456,   inf] (71), [-1.09455,   inf] (67), [-1.09455,   inf] (69), [-1.09455,   inf] (65), [-1.09455,   inf] (63), [-1.09455,   inf] (65), [-1.09454,   inf] (67), [-1.09454,   inf] (79), [-1.09454,   inf] (71), [-1.09454,   inf] (79), [-1.09453,   inf] (71), [-1.09453,   inf] (77), [-1.09453,   inf] (79), [-1.09453,   inf] (79), [-1.09453,   inf] (75), [-1.09453,   inf] (61), [-1.09453,   inf] (65), [-1.09453,   inf] (77), [-1.09453,   inf] (73), [-1.09452,   inf] (71), 
length of domains: 13082
Total time: 1.7429	 pickout: 0.0758	 decision: 0.5884	 get_bound: 1.0061	 add_domain: 0.0725
Current lb:-1.0945558547973633
27994 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 77.8356761932373

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 618] [1, 7701] [1, 4822] [1, 3213] [1, 3213] [1, 7701] [1, 3213] [1, 4822] [0, 7258] [1, 6676] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 549.9200439453125 with beta sum per layer: [0.0, 360.44110107421875, 3.706181526184082]
alpha/beta optimization time: 0.8534688949584961
This batch time : update_bounds func: 1.0164	 prepare: 0.0586	 bound: 0.8540	 transfer: 0.0505	 finalize: 0.0513
/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:462: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(preprocess_cifar(eps_temp, perturbation=True)).reshape(1,-1,1,1)
Accumulated time: update_bounds func: 57.3775	 prepare: 2.9856	 bound: 48.1973	 transfer: 0.0505	 finalize: 3.1876
batch bounding time:  1.0172343254089355
Current worst splitting domains [lb, ub] (depth):
[-1.09404,   inf] (85), [-1.09403,   inf] (73), [-1.09403,   inf] (61), [-1.09403,   inf] (65), [-1.09403,   inf] (73), [-1.09402,   inf] (65), [-1.09402,   inf] (83), [-1.09402,   inf] (69), [-1.09402,   inf] (59), [-1.09402,   inf] (71), [-1.09402,   inf] (71), [-1.09402,   inf] (69), [-1.09401,   inf] (69), [-1.09401,   inf] (75), [-1.09401,   inf] (83), [-1.09401,   inf] (69), [-1.09400,   inf] (73), [-1.09399,   inf] (69), [-1.09399,   inf] (63), [-1.09399,   inf] (73), 
length of domains: 13338
Total time: 1.3348	 pickout: 0.0801	 decision: 0.1596	 get_bound: 1.0182	 add_domain: 0.0769
Current lb:-1.0940369367599487
28506 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 79.17955493927002

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7561] [1, 3476] [1, 4530] [1, 3213] [1, 3476] [1, 618] [1, 6676] [1, 3213] [1, 3213] [1, 618] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 549.7196044921875 with beta sum per layer: [0.0, 391.6982421875, 3.6389057636260986]
alpha/beta optimization time: 0.8778164386749268
This batch time : update_bounds func: 1.0523	 prepare: 0.0800	 bound: 0.8783	 transfer: 0.0478	 finalize: 0.0442
Accumulated time: update_bounds func: 58.4298	 prepare: 3.0656	 bound: 49.0757	 transfer: 0.0478	 finalize: 3.2319
batch bounding time:  1.0531210899353027
Current worst splitting domains [lb, ub] (depth):
[-1.09347,   inf] (65), [-1.09346,   inf] (73), [-1.09346,   inf] (69), [-1.09346,   inf] (75), [-1.09346,   inf] (71), [-1.09345,   inf] (61), [-1.09345,   inf] (69), [-1.09345,   inf] (65), [-1.09345,   inf] (69), [-1.09345,   inf] (73), [-1.09345,   inf] (87), [-1.09345,   inf] (73), [-1.09345,   inf] (81), [-1.09345,   inf] (59), [-1.09345,   inf] (73), [-1.09344,   inf] (73), [-1.09344,   inf] (69), [-1.09344,   inf] (75), [-1.09344,   inf] (65), [-1.09344,   inf] (71), 
length of domains: 13594
Total time: 1.4332	 pickout: 0.1197	 decision: 0.1772	 get_bound: 1.0544	 add_domain: 0.0819
Current lb:-1.0934650897979736
29018 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Time out!!!!!!!!
Image 192 label 6 verification end, final lower bound -1.0934650897979736, upper bound inf, time: 81.06210494041443
192 -1.0934650897979736
Result: image 192 verification failure (with branch and bound).
Wall time: 91.28661608695984

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 0): []
verification failure idx (total 1): [192]
final verified acc: 0.0%[1]
verifier is called on 1 examples.
total verified: 0
mean time [cnt:1] (excluding attack success): 91.20374178886414
