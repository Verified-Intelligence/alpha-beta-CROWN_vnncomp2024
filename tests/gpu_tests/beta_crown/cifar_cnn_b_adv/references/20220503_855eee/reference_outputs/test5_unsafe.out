Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_cnn_b_adv.model
  name: cnn_4layer_b
data:
  start: 34
  end: 35
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR_SDP
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.00784313725
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 256
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 90
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:12:24 2022 on diablo.cs.ucla.edu
Sequential(
  (0): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)
  (1): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2))
  (2): ReLU()
  (3): Conv2d(32, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (4): ReLU()
  (5): Flatten()
  (6): Linear(in_features=8192, out_features=250, bias=True)
  (7): ReLU()
  (8): Linear(in_features=250, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([200, 3, 32, 32]) torch.Size([200]) torch.Size([200])
X range: tensor(2.1256) tensor(-1.9889) tensor(-0.0131)
############################
epsilon after preprocessing: tensor([[[[0.0317]],

         [[0.0322]],

         [[0.0300]]]]), data_max = tensor([[[[2.0587]],

         [[2.1256]],

         [[2.1154]]]]), data_min = tensor([[[[-1.9889]],

         [[-1.9807]],

         [[-1.7076]]]])
Task length: 1
saving results to Verified_ret_[cnn_4layer_b]_start=34_end=35_iter=20_b=256_timeout=90_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 34 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 3, correct label 3, image norm 3174.79736328125, logits tensor([-57.0025, -57.4930, -52.4853, -50.3490, -51.1245, -51.8085, -51.8720,
        -53.3276, -59.3430, -56.3984], device='cuda:0',
       grad_fn=<SelectBackward>)
Model prediction is: tensor([[-57.0025, -57.4930, -52.4853, -50.3490, -51.1245, -51.8085, -51.8720,
         -53.3276, -59.3430, -56.3984]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 1.0716, -0.1853, -2.7121, -3.2309, -0.2545, -3.4325, -3.7364,  3.0737,
         -2.4518]], device='cuda:0') None
best_l after optimization: 7.809802055358887 with beta sum per layer: []
alpha/beta optimization time: 8.439802885055542
initial alpha-CROWN bounds: tensor([[ 1.4226,  0.4395, -2.3380, -2.8837, -0.1279, -2.8093, -3.1635,  3.5416,
         -1.8911]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-3.1635, device='cuda:0', grad_fn=<MinBackward1>)
##### [0:34] Tested against 7 ######
Model prediction is: tensor([[-57.0025, -57.4930, -52.4853, -50.3490, -51.1245, -51.8085, -51.8720,
         -53.3276, -59.3430, -56.3984]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /34 start_node /35
setting alpha for layer /34 start_node /45
not setting layer /34 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /36 start_node /45
not setting layer /36 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /46 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /33 torch.Size([1, 32, 16, 16])
1 /35 torch.Size([1, 128, 8, 8])
2 /45 torch.Size([1, 250])
best_l after optimization: 3.1629951000213623 with beta sum per layer: []
alpha/beta optimization time: 2.1630401611328125
alpha-CROWN with fixed intermediate bounds: tensor([[-3.1630]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-3.1629953384399414
layer 0 size torch.Size([8192]) unstable 1453
layer 1 size torch.Size([8192]) unstable 907
layer 2 size torch.Size([250]) unstable 80
-----------------
# of unstable neurons: 2440
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 108] 
split level 1: [2, 207] 
split level 2: [2, 216] 
split level 3: [2, 88] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 16.964651107788086 with beta sum per layer: [0.0, 0.0, 0.023335695266723633]
alpha/beta optimization time: 0.2894744873046875
This batch time : update_bounds func: 0.2965	 prepare: 0.0039	 bound: 0.2900	 transfer: 0.0013	 finalize: 0.0012
Accumulated time: update_bounds func: 0.2965	 prepare: 0.0039	 bound: 0.2900	 transfer: 0.0013	 finalize: 0.0012
batch bounding time:  0.29660892486572266
Current worst splitting domains [lb, ub] (depth):
[-1.45299,   inf] (5), [-1.44243,   inf] (5), [-1.39006,   inf] (5), [-1.38280,   inf] (5), [-1.37620,   inf] (5), [-1.30585,   inf] (5), [-1.29626,   inf] (5), [-1.25744,   inf] (5), [-0.82784,   inf] (5), [-0.79437,   inf] (5), [-0.77350,   inf] (5), [-0.75560,   inf] (5), [-0.75048,   inf] (5), [-0.74402,   inf] (5), [-0.71163,   inf] (5), [-0.70317,   inf] (5), 
length of domains: 16
Total time: 0.3303	 pickout: 0.0010	 decision: 0.0299	 get_bound: 0.2987	 add_domain: 0.0007
Current lb:-1.4529938697814941
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.3507659435272217

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([16, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([16, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 140] [2, 140] [2, 140] [2, 140] [2, 140] [2, 140] [2, 140] [2, 140] [2, 140] [2, 140] 
regular batch size: 2*16, diving batch size 1*0
best_l after optimization: 20.77254295349121 with beta sum per layer: [0.0, 0.0, 0.05372878164052963]
alpha/beta optimization time: 0.27664971351623535
This batch time : update_bounds func: 0.2853	 prepare: 0.0040	 bound: 0.2769	 transfer: 0.0022	 finalize: 0.0021
Accumulated time: update_bounds func: 0.5818	 prepare: 0.0078	 bound: 0.5669	 transfer: 0.0022	 finalize: 0.0033
batch bounding time:  0.28542113304138184
Current worst splitting domains [lb, ub] (depth):
[-1.04864,   inf] (7), [-1.03748,   inf] (7), [-1.03065,   inf] (7), [-1.02897,   inf] (7), [-0.98644,   inf] (7), [-0.97948,   inf] (7), [-0.96378,   inf] (7), [-0.96216,   inf] (7), [-0.96168,   inf] (7), [-0.94911,   inf] (7), [-0.89936,   inf] (7), [-0.89015,   inf] (7), [-0.88994,   inf] (7), [-0.87321,   inf] (7), [-0.84071,   inf] (7), [-0.83635,   inf] (7), [-0.42450,   inf] (7), [-0.40452,   inf] (7), [-0.38905,   inf] (7), [-0.38052,   inf] (7), 
length of domains: 32
Total time: 0.3182	 pickout: 0.0038	 decision: 0.0275	 get_bound: 0.2855	 add_domain: 0.0015
Current lb:-1.0486412048339844
48 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.6693222522735596

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([32, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([32, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 191] [2, 191] [2, 191] [2, 191] [2, 191] [2, 191] [2, 191] [2, 191] [2, 191] [2, 191] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: 16.26449203491211 with beta sum per layer: [0.0, 0.0, 0.2866027355194092]
alpha/beta optimization time: 0.2927217483520508
This batch time : update_bounds func: 0.3104	 prepare: 0.0065	 bound: 0.2930	 transfer: 0.0069	 finalize: 0.0039
Accumulated time: update_bounds func: 0.8922	 prepare: 0.0143	 bound: 0.8599	 transfer: 0.0069	 finalize: 0.0072
batch bounding time:  0.310605525970459
Current worst splitting domains [lb, ub] (depth):
[-0.74781,   inf] (9), [-0.71776,   inf] (9), [-0.71628,   inf] (9), [-0.69701,   inf] (9), [-0.69648,   inf] (9), [-0.68024,   inf] (9), [-0.65671,   inf] (9), [-0.64805,   inf] (9), [-0.64230,   inf] (9), [-0.63702,   inf] (9), [-0.59264,   inf] (9), [-0.57426,   inf] (9), [-0.56784,   inf] (9), [-0.56166,   inf] (9), [-0.55953,   inf] (9), [-0.55095,   inf] (9), [-0.54833,   inf] (9), [-0.53928,   inf] (9), [-0.52997,   inf] (9), [-0.51999,   inf] (9), 
length of domains: 46
Total time: 0.3524	 pickout: 0.0067	 decision: 0.0331	 get_bound: 0.3107	 add_domain: 0.0019
Current lb:-0.7478078603744507
112 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.022290229797363

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([46, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([46, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 164] [2, 164] [2, 164] [2, 164] [2, 164] [2, 164] [2, 164] [2, 164] [2, 164] [2, 164] 
regular batch size: 2*46, diving batch size 1*0
best_l after optimization: 1.4955840110778809 with beta sum per layer: [0.0, 0.0, 0.8436970710754395]
alpha/beta optimization time: 0.308990478515625
This batch time : update_bounds func: 0.3366	 prepare: 0.0087	 bound: 0.3093	 transfer: 0.0131	 finalize: 0.0053
Accumulated time: update_bounds func: 1.2288	 prepare: 0.0231	 bound: 1.1692	 transfer: 0.0131	 finalize: 0.0125
batch bounding time:  0.3368258476257324
Current worst splitting domains [lb, ub] (depth):
[-0.48826,   inf] (11), [-0.46334,   inf] (11), [-0.45391,   inf] (11), [-0.43980,   inf] (11), [-0.43003,   inf] (11), [-0.41279,   inf] (11), [-0.38867,   inf] (11), [-0.37556,   inf] (11), [-0.37389,   inf] (11), [-0.37350,   inf] (11), [-0.32370,   inf] (11), [-0.31679,   inf] (11), [-0.30538,   inf] (11), [-0.30509,   inf] (11), [-0.29876,   inf] (11), [-0.29680,   inf] (11), [-0.29551,   inf] (11), [-0.28564,   inf] (11), [-0.27681,   inf] (11), [-0.25370,   inf] (11), 
length of domains: 49
Total time: 0.3871	 pickout: 0.0093	 decision: 0.0386	 get_bound: 0.3370	 add_domain: 0.0022
Current lb:-0.48826393485069275
204 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.410211801528931

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([49, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([49, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 230] [2, 230] [2, 230] [2, 230] [2, 230] [2, 230] [2, 161] [2, 230] [2, 230] [2, 230] 
regular batch size: 2*49, diving batch size 1*0
best_l after optimization: -19.075151443481445 with beta sum per layer: [0.0, 0.0, 1.078028917312622]
alpha/beta optimization time: 0.31967711448669434
This batch time : update_bounds func: 0.3438	 prepare: 0.0093	 bound: 0.3200	 transfer: 0.0087	 finalize: 0.0056
Accumulated time: update_bounds func: 1.5726	 prepare: 0.0323	 bound: 1.4892	 transfer: 0.0087	 finalize: 0.0180
batch bounding time:  0.343961238861084
Current worst splitting domains [lb, ub] (depth):
[-0.32796,   inf] (13), [-0.28901,   inf] (13), [-0.28510,   inf] (13), [-0.27280,   inf] (13), [-0.26567,   inf] (13), [-0.24124,   inf] (13), [-0.22486,   inf] (13), [-0.21214,   inf] (13), [-0.21114,   inf] (13), [-0.20605,   inf] (13), [-0.16740,   inf] (13), [-0.15316,   inf] (13), [-0.14173,   inf] (13), [-0.13784,   inf] (13), [-0.13671,   inf] (13), [-0.13500,   inf] (13), [-0.12055,   inf] (13), [-0.11307,   inf] (13), [-0.10891,   inf] (13), [-0.09738,   inf] (13), 
length of domains: 35
Total time: 0.4017	 pickout: 0.0099	 decision: 0.0459	 get_bound: 0.3441	 add_domain: 0.0017
Current lb:-0.32795801758766174
302 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.812829256057739

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([35, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([35, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 161] [2, 161] [2, 161] [2, 161] [2, 161] [2, 161] [2, 230] [2, 161] [2, 161] [2, 161] 
regular batch size: 2*35, diving batch size 1*0
best_l after optimization: -8.872740745544434 with beta sum per layer: [0.0, 0.0, 0.534152626991272]
alpha/beta optimization time: 0.3044006824493408
This batch time : update_bounds func: 0.3195	 prepare: 0.0069	 bound: 0.3047	 transfer: 0.0036	 finalize: 0.0041
Accumulated time: update_bounds func: 1.8921	 prepare: 0.0393	 bound: 1.7939	 transfer: 0.0036	 finalize: 0.0221
batch bounding time:  0.3196835517883301
Current worst splitting domains [lb, ub] (depth):
[-0.17512,   inf] (15), [-0.14485,   inf] (15), [-0.13699,   inf] (15), [-0.12685,   inf] (15), [-0.12371,   inf] (15), [-0.10484,   inf] (15), [-0.07416,   inf] (15), [-0.07038,   inf] (15), [-0.06830,   inf] (15), [-0.05154,   inf] (15), [-0.01797,   inf] (15), 
length of domains: 11
Total time: 0.3620	 pickout: 0.0076	 decision: 0.0339	 get_bound: 0.3198	 add_domain: 0.0007
Current lb:-0.17511752247810364
372 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.175594329833984

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([11, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([11, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 117] [2, 117] [2, 117] [2, 117] [2, 117] [2, 117] [2, 117] [2, 17] [2, 117] [2, 17] 
regular batch size: 2*11, diving batch size 1*0
best_l after optimization: -7.291496276855469 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.27469325065612793
This batch time : update_bounds func: 0.2814	 prepare: 0.0032	 bound: 0.2750	 transfer: 0.0016	 finalize: 0.0015
Accumulated time: update_bounds func: 2.1735	 prepare: 0.0424	 bound: 2.0688	 transfer: 0.0016	 finalize: 0.0236
batch bounding time:  0.2815380096435547
Current worst splitting domains [lb, ub] (depth):
[-0.05121,   inf] (17), [-0.02256,   inf] (17), [-0.01799,   inf] (17), [-0.00170,   inf] (17), 
length of domains: 4
Total time: 0.3105	 pickout: 0.0029	 decision: 0.0258	 get_bound: 0.2816	 add_domain: 0.0003
Current lb:-0.05120939388871193
394 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.486410140991211

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 32, 16, 16]) pre split depth:  2
batch:  torch.Size([4, 32, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [2, 17] [2, 17] [2, 17] [2, 17] 
split level 1: [2, 225] [2, 225] [2, 225] [2, 225] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -8.687456130981445 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.00998067855834961
This batch time : update_bounds func: 0.0157	 prepare: 0.0027	 bound: 0.0103	 transfer: 0.0016	 finalize: 0.0010
Accumulated time: update_bounds func: 2.1892	 prepare: 0.0451	 bound: 2.0791	 transfer: 0.0016	 finalize: 0.0247
batch bounding time:  0.01573014259338379
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0448	 pickout: 0.0015	 decision: 0.0260	 get_bound: 0.0172	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 5.531391382217407

Image 34 label 7 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 5.616096496582031
34 1.0000000116860974e-07
##### [0:34] Tested against 4 ######
Model prediction is: tensor([[-57.0025, -57.4930, -52.4853, -50.3490, -51.1245, -51.8085, -51.8720,
         -53.3276, -59.3430, -56.3984]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /34 start_node /35
setting alpha for layer /34 start_node /45
not setting layer /34 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /36 start_node /45
not setting layer /36 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /46 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /33 torch.Size([1, 32, 16, 16])
1 /35 torch.Size([1, 128, 8, 8])
2 /45 torch.Size([1, 250])
best_l after optimization: 2.8833394050598145 with beta sum per layer: []
alpha/beta optimization time: 1.201960563659668
alpha-CROWN with fixed intermediate bounds: tensor([[-2.8833]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-2.8833394050598145
layer 0 size torch.Size([8192]) unstable 1453
layer 1 size torch.Size([8192]) unstable 907
layer 2 size torch.Size([250]) unstable 80
-----------------
# of unstable neurons: 2440
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 225] 
split level 1: [2, 160] 
split level 2: [2, 114] 
split level 3: [2, 8] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 27.118268966674805 with beta sum per layer: [0.0, 0.0, 0.3037872314453125]
alpha/beta optimization time: 0.3346130847930908
This batch time : update_bounds func: 0.3445	 prepare: 0.0059	 bound: 0.3354	 transfer: 0.0016	 finalize: 0.0015
Accumulated time: update_bounds func: 2.5336	 prepare: 0.0510	 bound: 2.4146	 transfer: 0.0016	 finalize: 0.0262
batch bounding time:  0.3446178436279297
Current worst splitting domains [lb, ub] (depth):
[-1.98093,   inf] (5), [-1.96606,   inf] (5), [-1.86819,   inf] (5), [-1.85211,   inf] (5), [-1.84421,   inf] (5), [-1.81036,   inf] (5), [-1.74040,   inf] (5), [-1.71249,   inf] (5), [-1.70769,   inf] (5), [-1.67420,   inf] (5), [-1.60214,   inf] (5), [-1.57989,   inf] (5), [-1.54709,   inf] (5), [-1.47673,   inf] (5), [-1.42204,   inf] (5), [-1.33376,   inf] (5), 
length of domains: 16
Total time: 0.3772	 pickout: 0.0008	 decision: 0.0291	 get_bound: 0.3467	 add_domain: 0.0007
Current lb:-1.980926275253296
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.6151859760284424

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([16, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([16, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 129] [2, 129] [2, 129] [2, 129] [2, 23] [2, 129] [2, 129] [2, 129] [2, 129] [2, 129] 
regular batch size: 2*16, diving batch size 1*0
best_l after optimization: 44.47870635986328 with beta sum per layer: [0.0, 0.0, 1.0975531339645386]
alpha/beta optimization time: 0.2819516658782959
This batch time : update_bounds func: 0.2915	 prepare: 0.0040	 bound: 0.2822	 transfer: 0.0032	 finalize: 0.0020
Accumulated time: update_bounds func: 2.8252	 prepare: 0.0549	 bound: 2.6968	 transfer: 0.0032	 finalize: 0.0282
batch bounding time:  0.291703462600708
Current worst splitting domains [lb, ub] (depth):
[-1.80048,   inf] (7), [-1.78486,   inf] (7), [-1.67550,   inf] (7), [-1.67419,   inf] (7), [-1.66126,   inf] (7), [-1.61891,   inf] (7), [-1.55228,   inf] (7), [-1.53920,   inf] (7), [-1.53741,   inf] (7), [-1.53400,   inf] (7), [-1.52612,   inf] (7), [-1.49103,   inf] (7), [-1.48136,   inf] (7), [-1.48070,   inf] (7), [-1.43652,   inf] (7), [-1.40276,   inf] (7), [-1.38095,   inf] (7), [-1.36239,   inf] (7), [-1.36050,   inf] (7), [-1.29854,   inf] (7), 
length of domains: 32
Total time: 0.3241	 pickout: 0.0039	 decision: 0.0271	 get_bound: 0.2918	 add_domain: 0.0013
Current lb:-1.8004798889160156
48 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.9395525455474854

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([32, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([32, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 23] [2, 155] [2, 23] [2, 155] [2, 129] [2, 155] [2, 155] [2, 155] [2, 155] [2, 23] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: 73.5455322265625 with beta sum per layer: [0.0, 0.0, 3.11905574798584]
alpha/beta optimization time: 0.29191040992736816
This batch time : update_bounds func: 0.3102	 prepare: 0.0065	 bound: 0.2922	 transfer: 0.0073	 finalize: 0.0041
Accumulated time: update_bounds func: 3.1354	 prepare: 0.0614	 bound: 2.9890	 transfer: 0.0073	 finalize: 0.0323
batch bounding time:  0.310422420501709
Current worst splitting domains [lb, ub] (depth):
[-1.64314,   inf] (9), [-1.62825,   inf] (9), [-1.56244,   inf] (9), [-1.51585,   inf] (9), [-1.51504,   inf] (9), [-1.49176,   inf] (9), [-1.45862,   inf] (9), [-1.45606,   inf] (9), [-1.43570,   inf] (9), [-1.40527,   inf] (9), [-1.38674,   inf] (9), [-1.38632,   inf] (9), [-1.37880,   inf] (9), [-1.37720,   inf] (9), [-1.34684,   inf] (9), [-1.34005,   inf] (9), [-1.32612,   inf] (9), [-1.32498,   inf] (9), [-1.31713,   inf] (9), [-1.30587,   inf] (9), 
length of domains: 64
Total time: 0.3542	 pickout: 0.0071	 decision: 0.0340	 get_bound: 0.3105	 add_domain: 0.0025
Current lb:-1.6431437730789185
112 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.2941854000091553

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([64, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 155] [2, 23] [2, 23] [2, 23] [2, 155] [2, 155] [2, 23] [2, 23] [2, 155] [2, 23] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 117.13954162597656 with beta sum per layer: [0.0, 0.0, 8.256357192993164]
alpha/beta optimization time: 0.34125471115112305
This batch time : update_bounds func: 0.3803	 prepare: 0.0115	 bound: 0.3415	 transfer: 0.0190	 finalize: 0.0079
Accumulated time: update_bounds func: 3.5157	 prepare: 0.0729	 bound: 3.3305	 transfer: 0.0190	 finalize: 0.0402
batch bounding time:  0.3805820941925049
Current worst splitting domains [lb, ub] (depth):
[-1.49386,   inf] (11), [-1.48813,   inf] (11), [-1.41780,   inf] (11), [-1.40160,   inf] (11), [-1.38855,   inf] (11), [-1.35816,   inf] (11), [-1.33394,   inf] (11), [-1.32378,   inf] (11), [-1.31164,   inf] (11), [-1.29143,   inf] (11), [-1.27443,   inf] (11), [-1.26090,   inf] (11), [-1.25883,   inf] (11), [-1.25121,   inf] (11), [-1.23838,   inf] (11), [-1.22767,   inf] (11), [-1.22597,   inf] (11), [-1.22359,   inf] (11), [-1.19911,   inf] (11), [-1.18807,   inf] (11), 
length of domains: 128
Total time: 0.4505	 pickout: 0.0126	 decision: 0.0514	 get_bound: 0.3808	 add_domain: 0.0056
Current lb:-1.4938629865646362
240 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.7454514503479004

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([128, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([128, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 108] [2, 108] [2, 108] [2, 108] [2, 108] [2, 108] [2, 108] [2, 108] [2, 108] [2, 108] 
regular batch size: 2*128, diving batch size 1*0
best_l after optimization: 203.1392822265625 with beta sum per layer: [0.0, 0.0, 19.90453338623047]
alpha/beta optimization time: 0.5077135562896729
This batch time : update_bounds func: 0.5732	 prepare: 0.0218	 bound: 0.5080	 transfer: 0.0279	 finalize: 0.0149
Accumulated time: update_bounds func: 4.0889	 prepare: 0.0947	 bound: 3.8386	 transfer: 0.0279	 finalize: 0.0552
batch bounding time:  0.5735020637512207
Current worst splitting domains [lb, ub] (depth):
[-1.42653,   inf] (13), [-1.42124,   inf] (13), [-1.34883,   inf] (13), [-1.33124,   inf] (13), [-1.31907,   inf] (13), [-1.31530,   inf] (13), [-1.29711,   inf] (13), [-1.28930,   inf] (13), [-1.26565,   inf] (13), [-1.25280,   inf] (13), [-1.25104,   inf] (13), [-1.23997,   inf] (13), [-1.22837,   inf] (13), [-1.22604,   inf] (13), [-1.22087,   inf] (13), [-1.20565,   inf] (13), [-1.19274,   inf] (13), [-1.19119,   inf] (13), [-1.18913,   inf] (13), [-1.17772,   inf] (13), 
length of domains: 256
Total time: 0.6951	 pickout: 0.0250	 decision: 0.0843	 get_bound: 0.5739	 add_domain: 0.0120
Current lb:-1.426533579826355
496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.44233775138855

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 230] [2, 230] [2, 230] [2, 230] [2, 230] [2, 230] [2, 230] [2, 230] [2, 230] [2, 230] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 208.60476684570312 with beta sum per layer: [0.0, 0.0, 155.80767822265625]
alpha/beta optimization time: 0.8411374092102051
This batch time : update_bounds func: 0.9760	 prepare: 0.0497	 bound: 0.8415	 transfer: 0.0512	 finalize: 0.0316
Accumulated time: update_bounds func: 5.0648	 prepare: 0.1444	 bound: 4.6800	 transfer: 0.0512	 finalize: 0.0868
batch bounding time:  0.9765450954437256
Current worst splitting domains [lb, ub] (depth):
[-1.36361,   inf] (15), [-1.35789,   inf] (15), [-1.28747,   inf] (15), [-1.26975,   inf] (15), [-1.25735,   inf] (15), [-1.25027,   inf] (15), [-1.23205,   inf] (15), [-1.22959,   inf] (15), [-1.20358,   inf] (15), [-1.19431,   inf] (15), [-1.18564,   inf] (15), [-1.17936,   inf] (15), [-1.16283,   inf] (15), [-1.16160,   inf] (15), [-1.16153,   inf] (15), [-1.14494,   inf] (15), [-1.12878,   inf] (15), [-1.12743,   inf] (15), [-1.12567,   inf] (15), [-1.11922,   inf] (15), 
length of domains: 400
Total time: 1.2177	 pickout: 0.0526	 decision: 0.1634	 get_bound: 0.9773	 add_domain: 0.0245
Current lb:-1.3636101484298706
1008 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.664775609970093

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 216] [2, 216] [2, 216] [2, 216] [2, 216] [2, 216] [2, 216] [2, 216] [2, 216] [2, 216] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 354.2147216796875 with beta sum per layer: [0.0, 0.0, 42.74733352661133]
alpha/beta optimization time: 0.8269948959350586
This batch time : update_bounds func: 0.9476	 prepare: 0.0433	 bound: 0.8273	 transfer: 0.0461	 finalize: 0.0296
Accumulated time: update_bounds func: 6.0124	 prepare: 0.1877	 bound: 5.5074	 transfer: 0.0461	 finalize: 0.1164
batch bounding time:  0.9481213092803955
Current worst splitting domains [lb, ub] (depth):
[-1.28820,   inf] (17), [-1.28306,   inf] (17), [-1.27993,   inf] (17), [-1.27288,   inf] (17), [-1.20895,   inf] (17), [-1.20599,   inf] (17), [-1.19270,   inf] (17), [-1.18529,   inf] (17), [-1.18424,   inf] (17), [-1.17383,   inf] (17), [-1.17118,   inf] (17), [-1.16614,   inf] (17), [-1.15890,   inf] (17), [-1.15116,   inf] (17), [-1.14849,   inf] (17), [-1.14187,   inf] (17), [-1.12668,   inf] (17), [-1.11894,   inf] (17), [-1.11816,   inf] (17), [-1.11008,   inf] (17), 
length of domains: 656
Total time: 1.2499	 pickout: 0.0535	 decision: 0.2133	 get_bound: 0.9490	 add_domain: 0.0341
Current lb:-1.2881975173950195
1520 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.9185545444488525

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 214] [2, 214] [2, 214] [2, 214] [2, 214] [2, 214] [2, 214] [2, 214] [2, 214] [2, 214] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 256.9649658203125 with beta sum per layer: [0.0, 0.0, 123.59230041503906]
alpha/beta optimization time: 0.8279345035552979
This batch time : update_bounds func: 0.9635	 prepare: 0.0493	 bound: 0.8283	 transfer: 0.0540	 finalize: 0.0305
Accumulated time: update_bounds func: 6.9759	 prepare: 0.2371	 bound: 6.3357	 transfer: 0.0540	 finalize: 0.1469
batch bounding time:  0.9641153812408447
Current worst splitting domains [lb, ub] (depth):
[-1.23247,   inf] (19), [-1.22896,   inf] (19), [-1.22364,   inf] (19), [-1.21786,   inf] (19), [-1.15313,   inf] (19), [-1.14974,   inf] (19), [-1.13832,   inf] (19), [-1.13068,   inf] (19), [-1.13003,   inf] (19), [-1.11875,   inf] (19), [-1.11588,   inf] (19), [-1.11097,   inf] (19), [-1.10423,   inf] (19), [-1.09560,   inf] (19), [-1.09224,   inf] (19), [-1.08540,   inf] (19), [-1.07178,   inf] (19), [-1.06385,   inf] (19), [-1.06326,   inf] (19), [-1.05538,   inf] (19), 
length of domains: 847
Total time: 1.2030	 pickout: 0.0615	 decision: 0.1501	 get_bound: 0.9649	 add_domain: 0.0265
Current lb:-1.2324669361114502
2032 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.126231908798218

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 191] [2, 191] [2, 191] [2, 191] [2, 191] [2, 191] [2, 191] [2, 191] [2, 191] [2, 191] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 374.46209716796875 with beta sum per layer: [0.0, 0.0, 36.386905670166016]
alpha/beta optimization time: 0.8166427612304688
This batch time : update_bounds func: 0.9463	 prepare: 0.0441	 bound: 0.8170	 transfer: 0.0535	 finalize: 0.0305
Accumulated time: update_bounds func: 7.9223	 prepare: 0.2812	 bound: 7.1526	 transfer: 0.0535	 finalize: 0.1774
batch bounding time:  0.9469313621520996
Current worst splitting domains [lb, ub] (depth):
[-1.18017,   inf] (21), [-1.17843,   inf] (21), [-1.17658,   inf] (21), [-1.17460,   inf] (21), [-1.17150,   inf] (21), [-1.17028,   inf] (21), [-1.16562,   inf] (21), [-1.16317,   inf] (21), [-1.10257,   inf] (21), [-1.09894,   inf] (21), [-1.09663,   inf] (21), [-1.09264,   inf] (21), [-1.08636,   inf] (21), [-1.08372,   inf] (21), [-1.07881,   inf] (21), [-1.07874,   inf] (21), [-1.07614,   inf] (21), [-1.07417,   inf] (21), [-1.06796,   inf] (21), [-1.06507,   inf] (21), 
length of domains: 1084
Total time: 1.2411	 pickout: 0.0562	 decision: 0.1468	 get_bound: 0.9477	 add_domain: 0.0904
Current lb:-1.180173635482788
2544 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.371001243591309

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 140] [2, 140] [2, 140] [2, 140] [2, 140] [2, 140] [2, 140] [2, 140] [2, 140] [2, 140] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 421.7502136230469 with beta sum per layer: [0.0, 0.0, 17.362550735473633]
alpha/beta optimization time: 0.81418776512146
This batch time : update_bounds func: 0.9443	 prepare: 0.0438	 bound: 0.8145	 transfer: 0.0538	 finalize: 0.0308
Accumulated time: update_bounds func: 8.8665	 prepare: 0.3250	 bound: 7.9672	 transfer: 0.0538	 finalize: 0.2081
batch bounding time:  0.9449820518493652
Current worst splitting domains [lb, ub] (depth):
[-1.13101,   inf] (23), [-1.12902,   inf] (23), [-1.12777,   inf] (23), [-1.12695,   inf] (23), [-1.12677,   inf] (23), [-1.12503,   inf] (23), [-1.12475,   inf] (23), [-1.12308,   inf] (23), [-1.12302,   inf] (23), [-1.12165,   inf] (23), [-1.11833,   inf] (23), [-1.11729,   inf] (23), [-1.11538,   inf] (23), [-1.11445,   inf] (23), [-1.11318,   inf] (23), [-1.11183,   inf] (23), [-1.05443,   inf] (23), [-1.05114,   inf] (23), [-1.04856,   inf] (23), [-1.04783,   inf] (23), 
length of domains: 1340
Total time: 1.1853	 pickout: 0.0572	 decision: 0.1490	 get_bound: 0.9458	 add_domain: 0.0334
Current lb:-1.1310073137283325
3056 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.560194730758667

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 88] [2, 88] [2, 88] [2, 88] [2, 88] [2, 88] [2, 88] [2, 88] [2, 88] [2, 88] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 437.9214782714844 with beta sum per layer: [0.0, 0.0, 12.883102416992188]
alpha/beta optimization time: 0.813420295715332
This batch time : update_bounds func: 0.9430	 prepare: 0.0432	 bound: 0.8137	 transfer: 0.0539	 finalize: 0.0309
Accumulated time: update_bounds func: 9.8095	 prepare: 0.3682	 bound: 8.7809	 transfer: 0.0539	 finalize: 0.2391
batch bounding time:  0.9436049461364746
Current worst splitting domains [lb, ub] (depth):
[-1.08469,   inf] (25), [-1.08285,   inf] (25), [-1.08053,   inf] (25), [-1.07970,   inf] (25), [-1.07857,   inf] (25), [-1.07728,   inf] (25), [-1.07674,   inf] (25), [-1.07623,   inf] (25), [-1.07593,   inf] (25), [-1.07443,   inf] (25), [-1.07184,   inf] (25), [-1.07133,   inf] (25), [-1.06792,   inf] (25), [-1.06645,   inf] (25), [-1.06556,   inf] (25), [-1.06378,   inf] (25), [-1.04354,   inf] (25), [-1.04248,   inf] (25), [-1.04028,   inf] (25), [-1.04003,   inf] (25), 
length of domains: 1596
Total time: 1.1852	 pickout: 0.0570	 decision: 0.1499	 get_bound: 0.9444	 add_domain: 0.0340
Current lb:-1.0846855640411377
3568 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.749253034591675

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 97] [2, 97] [2, 97] [2, 97] [2, 97] [2, 97] [2, 97] [2, 97] [2, 97] [2, 97] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 452.5171813964844 with beta sum per layer: [0.0, 0.0, 9.290660858154297]
alpha/beta optimization time: 0.8105108737945557
This batch time : update_bounds func: 0.9405	 prepare: 0.0434	 bound: 0.8108	 transfer: 0.0538	 finalize: 0.0311
Accumulated time: update_bounds func: 10.7500	 prepare: 0.4116	 bound: 9.5917	 transfer: 0.0538	 finalize: 0.2701
batch bounding time:  0.9411945343017578
Current worst splitting domains [lb, ub] (depth):
[-1.04515,   inf] (27), [-1.04422,   inf] (27), [-1.04335,   inf] (27), [-1.04240,   inf] (27), [-1.04107,   inf] (27), [-1.03990,   inf] (27), [-1.03983,   inf] (27), [-1.03936,   inf] (27), [-1.03889,   inf] (27), [-1.03792,   inf] (27), [-1.03730,   inf] (27), [-1.03727,   inf] (27), [-1.03696,   inf] (27), [-1.03673,   inf] (27), [-1.03626,   inf] (27), [-1.03611,   inf] (27), [-1.03604,   inf] (27), [-1.03555,   inf] (27), [-1.03474,   inf] (27), [-1.03377,   inf] (27), 
length of domains: 1852
Total time: 1.2402	 pickout: 0.0576	 decision: 0.2039	 get_bound: 0.9420	 add_domain: 0.0367
Current lb:-1.0451457500457764
4080 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.99394154548645

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 196] [2, 196] [2, 196] [2, 196] [2, 196] [2, 196] [2, 196] [2, 196] [2, 196] [2, 196] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 63.27834701538086 with beta sum per layer: [0.0, 0.0, 90.01026916503906]
alpha/beta optimization time: 0.8186566829681396
This batch time : update_bounds func: 0.9468	 prepare: 0.0429	 bound: 0.8190	 transfer: 0.0527	 finalize: 0.0310
Accumulated time: update_bounds func: 11.6969	 prepare: 0.4545	 bound: 10.4107	 transfer: 0.0527	 finalize: 0.3012
batch bounding time:  0.9474244117736816
Current worst splitting domains [lb, ub] (depth):
[-1.01112,   inf] (29), [-1.01031,   inf] (29), [-1.00958,   inf] (29), [-1.00915,   inf] (29), [-1.00736,   inf] (29), [-1.00665,   inf] (29), [-1.00665,   inf] (29), [-1.00620,   inf] (29), [-1.00493,   inf] (29), [-1.00411,   inf] (29), [-1.00348,   inf] (29), [-1.00345,   inf] (29), [-1.00319,   inf] (29), [-1.00270,   inf] (29), [-1.00258,   inf] (29), [-1.00245,   inf] (29), [-1.00243,   inf] (29), [-1.00159,   inf] (29), [-1.00076,   inf] (29), [-0.99996,   inf] (29), 
length of domains: 1852
Total time: 1.1691	 pickout: 0.0552	 decision: 0.1465	 get_bound: 0.9482	 add_domain: 0.0191
Current lb:-1.0111217498779297
4592 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.168200016021729

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 94] [2, 94] [2, 94] [2, 94] [2, 94] [2, 94] [2, 94] [2, 94] [2, 94] [2, 94] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 362.40667724609375 with beta sum per layer: [0.0, 0.0, 26.832366943359375]
alpha/beta optimization time: 0.818035364151001
This batch time : update_bounds func: 1.0192	 prepare: 0.0441	 bound: 0.8184	 transfer: 0.0540	 finalize: 0.1014
Accumulated time: update_bounds func: 12.7161	 prepare: 0.4986	 bound: 11.2291	 transfer: 0.0540	 finalize: 0.4026
batch bounding time:  1.0199644565582275
Current worst splitting domains [lb, ub] (depth):
[-0.98688,   inf] (31), [-0.98644,   inf] (31), [-0.98577,   inf] (31), [-0.98540,   inf] (31), [-0.98333,   inf] (31), [-0.98264,   inf] (31), [-0.98251,   inf] (31), [-0.98232,   inf] (31), [-0.98030,   inf] (31), [-0.98022,   inf] (31), [-0.97992,   inf] (31), [-0.97942,   inf] (31), [-0.97906,   inf] (31), [-0.97901,   inf] (31), [-0.97837,   inf] (31), [-0.97785,   inf] (31), [-0.97782,   inf] (31), [-0.97666,   inf] (31), [-0.97593,   inf] (31), [-0.97510,   inf] (31), 
length of domains: 2053
Total time: 1.2628	 pickout: 0.0564	 decision: 0.1493	 get_bound: 1.0209	 add_domain: 0.0363
Current lb:-0.9868772029876709
5104 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.435457468032837

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 57] [2, 57] [2, 57] [2, 57] [2, 57] [2, 57] [2, 57] [2, 57] [2, 57] [2, 57] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 412.64434814453125 with beta sum per layer: [0.0, 0.0, 25.64080810546875]
alpha/beta optimization time: 0.817014217376709
This batch time : update_bounds func: 0.9495	 prepare: 0.0445	 bound: 0.8174	 transfer: 0.0565	 finalize: 0.0298
Accumulated time: update_bounds func: 13.6656	 prepare: 0.5431	 bound: 12.0464	 transfer: 0.0565	 finalize: 0.4324
batch bounding time:  0.9501497745513916
Current worst splitting domains [lb, ub] (depth):
[-0.96561,   inf] (33), [-0.96531,   inf] (33), [-0.96505,   inf] (33), [-0.96469,   inf] (33), [-0.96199,   inf] (33), [-0.96168,   inf] (33), [-0.96164,   inf] (33), [-0.96125,   inf] (33), [-0.96021,   inf] (33), [-0.95938,   inf] (33), [-0.95927,   inf] (33), [-0.95890,   inf] (33), [-0.95834,   inf] (33), [-0.95831,   inf] (33), [-0.95823,   inf] (33), [-0.95766,   inf] (33), [-0.95755,   inf] (33), [-0.95639,   inf] (33), [-0.95554,   inf] (33), [-0.95481,   inf] (33), 
length of domains: 2296
Total time: 1.1988	 pickout: 0.0596	 decision: 0.1484	 get_bound: 0.9509	 add_domain: 0.0398
Current lb:-0.9656054973602295
5616 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.638682126998901

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 122] [2, 122] [2, 122] [2, 122] [2, 122] [2, 122] [2, 122] [2, 122] [2, 122] [2, 122] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 423.1805725097656 with beta sum per layer: [0.0, 0.0, 22.141403198242188]
alpha/beta optimization time: 0.8165507316589355
This batch time : update_bounds func: 0.9477	 prepare: 0.0446	 bound: 0.8169	 transfer: 0.0544	 finalize: 0.0306
Accumulated time: update_bounds func: 14.6133	 prepare: 0.5877	 bound: 12.8633	 transfer: 0.0544	 finalize: 0.4630
batch bounding time:  0.9482719898223877
Current worst splitting domains [lb, ub] (depth):
[-0.94825,   inf] (35), [-0.94784,   inf] (35), [-0.94754,   inf] (35), [-0.94713,   inf] (35), [-0.94467,   inf] (35), [-0.94422,   inf] (35), [-0.94418,   inf] (35), [-0.94384,   inf] (35), [-0.94322,   inf] (35), [-0.94224,   inf] (35), [-0.94138,   inf] (35), [-0.94127,   inf] (35), [-0.94114,   inf] (35), [-0.94055,   inf] (35), [-0.94049,   inf] (35), [-0.94046,   inf] (35), [-0.94044,   inf] (35), [-0.93917,   inf] (35), [-0.93837,   inf] (35), [-0.93763,   inf] (35), 
length of domains: 2550
Total time: 1.1939	 pickout: 0.0556	 decision: 0.1475	 get_bound: 0.9490	 add_domain: 0.0417
Current lb:-0.9482505321502686
6128 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.83659553527832

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 93] [2, 93] [2, 93] [2, 93] [2, 93] [2, 93] [2, 93] [2, 93] [2, 93] [2, 93] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 163.42909240722656 with beta sum per layer: [0.0, 0.6220349669456482, 71.69912719726562]
alpha/beta optimization time: 0.8233599662780762
This batch time : update_bounds func: 0.9574	 prepare: 0.0455	 bound: 0.8237	 transfer: 0.0560	 finalize: 0.0307
Accumulated time: update_bounds func: 15.5707	 prepare: 0.6332	 bound: 13.6870	 transfer: 0.0560	 finalize: 0.4937
batch bounding time:  0.9579918384552002
Current worst splitting domains [lb, ub] (depth):
[-0.93419,   inf] (37), [-0.93356,   inf] (37), [-0.93340,   inf] (37), [-0.93279,   inf] (37), [-0.93077,   inf] (37), [-0.93011,   inf] (37), [-0.92989,   inf] (37), [-0.92979,   inf] (37), [-0.92846,   inf] (37), [-0.92758,   inf] (37), [-0.92698,   inf] (37), [-0.92690,   inf] (37), [-0.92642,   inf] (37), [-0.92611,   inf] (37), [-0.92606,   inf] (37), [-0.92564,   inf] (37), [-0.92555,   inf] (37), [-0.92410,   inf] (37), [-0.92292,   inf] (37), [-0.92226,   inf] (37), 
length of domains: 2616
Total time: 1.2643	 pickout: 0.0554	 decision: 0.2224	 get_bound: 0.9587	 add_domain: 0.0278
Current lb:-0.9341936111450195
6640 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.106197357177734

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 65] [2, 65] [2, 65] [2, 65] [2, 65] [2, 65] [2, 65] [2, 65] [1, 6708] [1, 6708] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 315.89080810546875 with beta sum per layer: [0.0, 0.7656311988830566, 40.277748107910156]
alpha/beta optimization time: 0.8179230690002441
This batch time : update_bounds func: 0.9539	 prepare: 0.0459	 bound: 0.8183	 transfer: 0.0569	 finalize: 0.0315
Accumulated time: update_bounds func: 16.5246	 prepare: 0.6791	 bound: 14.5053	 transfer: 0.0569	 finalize: 0.5252
batch bounding time:  0.954458475112915
Current worst splitting domains [lb, ub] (depth):
[-0.92273,   inf] (39), [-0.92206,   inf] (39), [-0.92194,   inf] (39), [-0.92134,   inf] (39), [-0.91931,   inf] (39), [-0.91857,   inf] (39), [-0.91835,   inf] (39), [-0.91822,   inf] (39), [-0.91542,   inf] (39), [-0.91536,   inf] (39), [-0.91489,   inf] (39), [-0.91460,   inf] (39), [-0.91394,   inf] (39), [-0.91310,   inf] (39), [-0.91171,   inf] (39), [-0.91116,   inf] (39), [-0.91100,   inf] (39), [-0.91023,   inf] (39), [-0.91013,   inf] (39), [-0.90995,   inf] (39), 
length of domains: 2806
Total time: 1.1958	 pickout: 0.0537	 decision: 0.1483	 get_bound: 0.9552	 add_domain: 0.0385
Current lb:-0.9227321147918701
7152 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 19.306605577468872

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6708] [1, 6708] [1, 6708] [1, 6708] [1, 6708] [1, 6708] [1, 6708] [1, 6708] [1, 6708] [1, 6708] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 345.9678955078125 with beta sum per layer: [0.0, 5.8422465324401855, 33.54492950439453]
alpha/beta optimization time: 0.8180074691772461
This batch time : update_bounds func: 0.9951	 prepare: 0.0478	 bound: 0.8183	 transfer: 0.0234	 finalize: 0.0327
Accumulated time: update_bounds func: 17.5197	 prepare: 0.7269	 bound: 15.3236	 transfer: 0.0234	 finalize: 0.5579
batch bounding time:  0.9958205223083496
Current worst splitting domains [lb, ub] (depth):
[-0.91140,   inf] (41), [-0.91108,   inf] (41), [-0.91102,   inf] (41), [-0.91079,   inf] (41), [-0.90772,   inf] (41), [-0.90742,   inf] (41), [-0.90735,   inf] (41), [-0.90679,   inf] (41), [-0.90423,   inf] (41), [-0.90410,   inf] (41), [-0.90407,   inf] (41), [-0.90390,   inf] (41), [-0.90369,   inf] (41), [-0.90295,   inf] (41), [-0.90244,   inf] (41), [-0.90166,   inf] (41), [-0.90135,   inf] (41), [-0.90045,   inf] (41), [-0.89940,   inf] (41), [-0.89921,   inf] (41), 
length of domains: 3030
Total time: 1.2450	 pickout: 0.0534	 decision: 0.1507	 get_bound: 0.9966	 add_domain: 0.0442
Current lb:-0.9114000201225281
7664 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 20.556929111480713

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 117] [2, 117] [2, 117] [2, 117] [2, 117] [2, 117] [2, 117] [2, 117] [2, 117] [2, 117] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 352.80755615234375 with beta sum per layer: [0.0, 13.027774810791016, 28.23282241821289]
alpha/beta optimization time: 0.8168981075286865
This batch time : update_bounds func: 0.9528	 prepare: 0.0497	 bound: 0.8172	 transfer: 0.0522	 finalize: 0.0324
Accumulated time: update_bounds func: 18.4725	 prepare: 0.7766	 bound: 16.1409	 transfer: 0.0522	 finalize: 0.5903
batch bounding time:  0.9533753395080566
Current worst splitting domains [lb, ub] (depth):
[-0.90151,   inf] (43), [-0.90125,   inf] (43), [-0.90120,   inf] (43), [-0.90098,   inf] (43), [-0.89774,   inf] (43), [-0.89743,   inf] (43), [-0.89742,   inf] (43), [-0.89687,   inf] (43), [-0.89427,   inf] (43), [-0.89413,   inf] (43), [-0.89411,   inf] (43), [-0.89405,   inf] (43), [-0.89363,   inf] (43), [-0.89282,   inf] (43), [-0.89244,   inf] (43), [-0.89160,   inf] (43), [-0.88937,   inf] (43), [-0.88900,   inf] (43), [-0.88895,   inf] (43), [-0.88878,   inf] (43), 
length of domains: 3277
Total time: 1.2089	 pickout: 0.0590	 decision: 0.1484	 get_bound: 0.9542	 add_domain: 0.0474
Current lb:-0.9015087485313416
8176 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 21.77051568031311

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6739] [1, 6730] [1, 6730] [1, 6730] [1, 6739] [1, 6739] [1, 6739] [1, 6739] [1, 6739] [1, 6739] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 383.6343688964844 with beta sum per layer: [0.0, 14.554333686828613, 21.810871124267578]
alpha/beta optimization time: 0.819103479385376
This batch time : update_bounds func: 0.9551	 prepare: 0.0506	 bound: 0.8194	 transfer: 0.0521	 finalize: 0.0316
Accumulated time: update_bounds func: 19.4276	 prepare: 0.8272	 bound: 16.9603	 transfer: 0.0521	 finalize: 0.6219
batch bounding time:  0.9557242393493652
Current worst splitting domains [lb, ub] (depth):
[-0.89178,   inf] (45), [-0.89160,   inf] (45), [-0.89154,   inf] (45), [-0.89122,   inf] (45), [-0.89054,   inf] (45), [-0.88797,   inf] (45), [-0.88772,   inf] (45), [-0.88748,   inf] (45), [-0.88732,   inf] (45), [-0.88732,   inf] (45), [-0.88708,   inf] (45), [-0.88689,   inf] (45), [-0.88683,   inf] (45), [-0.88670,   inf] (45), [-0.88640,   inf] (45), [-0.88601,   inf] (45), [-0.88407,   inf] (45), [-0.88406,   inf] (45), [-0.88403,   inf] (45), [-0.88374,   inf] (45), 
length of domains: 3527
Total time: 1.2968	 pickout: 0.0602	 decision: 0.1501	 get_bound: 0.9565	 add_domain: 0.1300
Current lb:-0.8917792439460754
8688 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 23.07167339324951

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6739] [1, 6739] [1, 6739] [1, 6730] [2, 17] [1, 6739] [1, 6739] [1, 6739] [1, 6730] [1, 6730] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 341.7926330566406 with beta sum per layer: [0.0, 21.815425872802734, 24.81515121459961]
alpha/beta optimization time: 0.8233704566955566
This batch time : update_bounds func: 0.9609	 prepare: 0.0502	 bound: 0.8237	 transfer: 0.0528	 finalize: 0.0327
Accumulated time: update_bounds func: 20.3885	 prepare: 0.8774	 bound: 17.7840	 transfer: 0.0528	 finalize: 0.6545
batch bounding time:  0.9615478515625
Current worst splitting domains [lb, ub] (depth):
[-0.88169,   inf] (47), [-0.88169,   inf] (47), [-0.88159,   inf] (47), [-0.88157,   inf] (47), [-0.88151,   inf] (47), [-0.88141,   inf] (47), [-0.88134,   inf] (47), [-0.88120,   inf] (47), [-0.87825,   inf] (47), [-0.87805,   inf] (47), [-0.87771,   inf] (47), [-0.87763,   inf] (47), [-0.87751,   inf] (47), [-0.87750,   inf] (47), [-0.87749,   inf] (47), [-0.87741,   inf] (47), [-0.87735,   inf] (47), [-0.87725,   inf] (47), [-0.87714,   inf] (47), [-0.87707,   inf] (47), 
length of domains: 3783
Total time: 1.2231	 pickout: 0.0597	 decision: 0.1488	 get_bound: 0.9623	 add_domain: 0.0522
Current lb:-0.881688117980957
9200 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 24.299663305282593

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 17] [2, 17] [2, 17] [2, 17] [2, 17] [2, 17] [2, 17] [1, 6730] [2, 17] [2, 17] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 325.86700439453125 with beta sum per layer: [0.0, 46.84600067138672, 27.51595115661621]
alpha/beta optimization time: 0.8247280120849609
This batch time : update_bounds func: 0.9623	 prepare: 0.0502	 bound: 0.8251	 transfer: 0.0532	 finalize: 0.0326
Accumulated time: update_bounds func: 21.3508	 prepare: 0.9276	 bound: 18.6091	 transfer: 0.0532	 finalize: 0.6871
batch bounding time:  0.9628455638885498
Current worst splitting domains [lb, ub] (depth):
[-0.87247,   inf] (49), [-0.87244,   inf] (49), [-0.87237,   inf] (49), [-0.87233,   inf] (49), [-0.87223,   inf] (49), [-0.87221,   inf] (49), [-0.87213,   inf] (49), [-0.87210,   inf] (49), [-0.86892,   inf] (49), [-0.86877,   inf] (49), [-0.86853,   inf] (49), [-0.86838,   inf] (49), [-0.86832,   inf] (49), [-0.86828,   inf] (49), [-0.86826,   inf] (49), [-0.86821,   inf] (49), [-0.86807,   inf] (49), [-0.86796,   inf] (49), [-0.86789,   inf] (49), [-0.86780,   inf] (49), 
length of domains: 4039
Total time: 1.2240	 pickout: 0.0584	 decision: 0.1491	 get_bound: 0.9636	 add_domain: 0.0529
Current lb:-0.8724715113639832
9712 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 25.52849006652832

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 4893] [1, 6100] [1, 4893] [1, 6100] [1, 6100] [1, 6100] [1, 4893] [1, 4893] [1, 6100] [1, 4893] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 413.9107360839844 with beta sum per layer: [0.0, 22.23518943786621, 5.2973833084106445]
alpha/beta optimization time: 0.8250718116760254
This batch time : update_bounds func: 0.9631	 prepare: 0.0495	 bound: 0.8254	 transfer: 0.0565	 finalize: 0.0304
Accumulated time: update_bounds func: 22.3139	 prepare: 0.9771	 bound: 19.4345	 transfer: 0.0565	 finalize: 0.7175
batch bounding time:  0.9637391567230225
Current worst splitting domains [lb, ub] (depth):
[-0.86471,   inf] (51), [-0.86468,   inf] (51), [-0.86464,   inf] (51), [-0.86458,   inf] (51), [-0.86435,   inf] (51), [-0.86432,   inf] (51), [-0.86410,   inf] (51), [-0.86407,   inf] (51), [-0.86119,   inf] (51), [-0.86098,   inf] (51), [-0.86078,   inf] (51), [-0.86072,   inf] (51), [-0.86041,   inf] (51), [-0.86036,   inf] (51), [-0.86029,   inf] (51), [-0.86028,   inf] (51), [-0.86007,   inf] (51), [-0.86001,   inf] (51), [-0.85987,   inf] (51), [-0.85985,   inf] (51), 
length of domains: 4295
Total time: 1.3204	 pickout: 0.0593	 decision: 0.2420	 get_bound: 0.9645	 add_domain: 0.0546
Current lb:-0.8647080659866333
10224 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 26.85398006439209

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 4893] [1, 6100] [1, 6100] [1, 4893] [1, 461] [1, 461] [1, 461] [1, 461] [1, 4893] [1, 6100] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 430.0474853515625 with beta sum per layer: [0.0, 21.934934616088867, 0.4127446413040161]
alpha/beta optimization time: 0.8308782577514648
This batch time : update_bounds func: 0.9694	 prepare: 0.0490	 bound: 0.8312	 transfer: 0.0547	 finalize: 0.0331
Accumulated time: update_bounds func: 23.2833	 prepare: 1.0261	 bound: 20.2657	 transfer: 0.0547	 finalize: 0.7506
batch bounding time:  0.9700782299041748
Current worst splitting domains [lb, ub] (depth):
[-0.85754,   inf] (53), [-0.85748,   inf] (53), [-0.85721,   inf] (53), [-0.85713,   inf] (53), [-0.85620,   inf] (53), [-0.85614,   inf] (53), [-0.85609,   inf] (53), [-0.85608,   inf] (53), [-0.85548,   inf] (53), [-0.85545,   inf] (53), [-0.85531,   inf] (53), [-0.85528,   inf] (53), [-0.85386,   inf] (53), [-0.85369,   inf] (53), [-0.85337,   inf] (53), [-0.85321,   inf] (53), [-0.85305,   inf] (53), [-0.85299,   inf] (53), [-0.85296,   inf] (53), [-0.85283,   inf] (53), 
length of domains: 4551
Total time: 1.2354	 pickout: 0.0578	 decision: 0.1489	 get_bound: 0.9709	 add_domain: 0.0578
Current lb:-0.8575381636619568
10736 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 28.09517216682434

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3236] [1, 3236] [1, 3236] [1, 6092] [1, 6100] [1, 6100] [1, 4893] [1, 4893] [1, 4893] [1, 4893] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 427.93017578125 with beta sum per layer: [0.0, 31.68177032470703, 0.28718313574790955]
alpha/beta optimization time: 0.8307697772979736
This batch time : update_bounds func: 0.9640	 prepare: 0.0488	 bound: 0.8311	 transfer: 0.0520	 finalize: 0.0309
Accumulated time: update_bounds func: 24.2473	 prepare: 1.0749	 bound: 21.0968	 transfer: 0.0520	 finalize: 0.7815
batch bounding time:  0.9646246433258057
Current worst splitting domains [lb, ub] (depth):
[-0.85090,   inf] (55), [-0.85083,   inf] (55), [-0.85046,   inf] (55), [-0.85037,   inf] (55), [-0.84894,   inf] (55), [-0.84891,   inf] (55), [-0.84828,   inf] (55), [-0.84825,   inf] (55), [-0.84815,   inf] (55), [-0.84810,   inf] (55), [-0.84778,   inf] (55), [-0.84777,   inf] (55), [-0.84721,   inf] (55), [-0.84693,   inf] (55), [-0.84661,   inf] (55), [-0.84643,   inf] (55), [-0.84637,   inf] (55), [-0.84633,   inf] (55), [-0.84631,   inf] (55), [-0.84613,   inf] (55), 
length of domains: 4807
Total time: 1.3526	 pickout: 0.0587	 decision: 0.1491	 get_bound: 0.9654	 add_domain: 0.1794
Current lb:-0.8508976697921753
11248 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 29.452927112579346

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6092] [1, 6092] [1, 461] [1, 461] [1, 3236] [1, 3236] [1, 3236] [1, 3236] [1, 3236] [1, 3236] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 420.7526550292969 with beta sum per layer: [0.0, 43.66655349731445, 1.6791751384735107]
alpha/beta optimization time: 0.8298273086547852
This batch time : update_bounds func: 0.9673	 prepare: 0.0507	 bound: 0.8302	 transfer: 0.0544	 finalize: 0.0308
Accumulated time: update_bounds func: 25.2146	 prepare: 1.1255	 bound: 21.9270	 transfer: 0.0544	 finalize: 0.8123
batch bounding time:  0.9679207801818848
Current worst splitting domains [lb, ub] (depth):
[-0.84450,   inf] (57), [-0.84433,   inf] (57), [-0.84251,   inf] (57), [-0.84248,   inf] (57), [-0.84216,   inf] (57), [-0.84186,   inf] (57), [-0.84177,   inf] (57), [-0.84173,   inf] (57), [-0.84171,   inf] (57), [-0.84169,   inf] (57), [-0.84158,   inf] (57), [-0.84153,   inf] (57), [-0.84109,   inf] (57), [-0.84108,   inf] (57), [-0.84089,   inf] (57), [-0.83993,   inf] (57), [-0.83991,   inf] (57), [-0.83975,   inf] (57), [-0.83968,   inf] (57), [-0.83953,   inf] (57), 
length of domains: 5063
Total time: 1.2395	 pickout: 0.0621	 decision: 0.1502	 get_bound: 0.9687	 add_domain: 0.0586
Current lb:-0.8444986343383789
11760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 30.697347402572632

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 461] [1, 461] [2, 167] [2, 167] [1, 6092] [1, 3236] [1, 3236] [2, 167] [2, 167] [1, 6092] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 411.21734619140625 with beta sum per layer: [0.0, 42.130184173583984, 4.762475967407227]
alpha/beta optimization time: 0.8308689594268799
This batch time : update_bounds func: 0.9694	 prepare: 0.0500	 bound: 0.8312	 transfer: 0.0549	 finalize: 0.0321
Accumulated time: update_bounds func: 26.1841	 prepare: 1.1755	 bound: 22.7582	 transfer: 0.0549	 finalize: 0.8444
batch bounding time:  0.9700500965118408
Current worst splitting domains [lb, ub] (depth):
[-0.83652,   inf] (59), [-0.83635,   inf] (59), [-0.83617,   inf] (59), [-0.83616,   inf] (59), [-0.83609,   inf] (59), [-0.83589,   inf] (59), [-0.83568,   inf] (55), [-0.83567,   inf] (55), [-0.83564,   inf] (49), [-0.83564,   inf] (55), [-0.83563,   inf] (47), [-0.83562,   inf] (57), [-0.83561,   inf] (49), [-0.83560,   inf] (57), [-0.83560,   inf] (55), [-0.83560,   inf] (45), [-0.83560,   inf] (51), [-0.83559,   inf] (57), [-0.83558,   inf] (53), [-0.83556,   inf] (55), 
length of domains: 5319
Total time: 1.2397	 pickout: 0.0602	 decision: 0.1501	 get_bound: 0.9709	 add_domain: 0.0586
Current lb:-0.8365204334259033
12272 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 31.942394256591797

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 167] [2, 167] [1, 6092] [1, 6092] [2, 167] [2, 167] [1, 6092] [1, 6092] [1, 6730] [1, 6092] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 403.1083984375 with beta sum per layer: [0.0, 49.61876678466797, 7.863479137420654]
alpha/beta optimization time: 0.8257486820220947
This batch time : update_bounds func: 1.0843	 prepare: 0.0502	 bound: 0.8261	 transfer: 0.0520	 finalize: 0.1546
Accumulated time: update_bounds func: 27.2683	 prepare: 1.2257	 bound: 23.5843	 transfer: 0.0520	 finalize: 0.9990
batch bounding time:  1.0848701000213623
Current worst splitting domains [lb, ub] (depth):
[-0.83372,   inf] (55), [-0.83371,   inf] (31), [-0.83371,   inf] (53), [-0.83370,   inf] (45), [-0.83370,   inf] (55), [-0.83369,   inf] (57), [-0.83368,   inf] (47), [-0.83368,   inf] (55), [-0.83367,   inf] (27), [-0.83365,   inf] (53), [-0.83365,   inf] (57), [-0.83365,   inf] (53), [-0.83364,   inf] (57), [-0.83363,   inf] (39), [-0.83362,   inf] (45), [-0.83361,   inf] (45), [-0.83360,   inf] (27), [-0.83360,   inf] (53), [-0.83359,   inf] (55), [-0.83359,   inf] (55), 
length of domains: 5575
Total time: 1.3551	 pickout: 0.0598	 decision: 0.1516	 get_bound: 1.0857	 add_domain: 0.0581
Current lb:-0.8337175846099854
12784 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 33.30225992202759

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 3236] [2, 57] [1, 3236] [1, 6708] [1, 6092] [2, 167] [1, 6730] [1, 6092] [2, 196] [1, 6100] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 388.3798522949219 with beta sum per layer: [0.0, 43.72868347167969, 11.022668838500977]
alpha/beta optimization time: 0.8221840858459473
This batch time : update_bounds func: 0.9668	 prepare: 0.0508	 bound: 0.8225	 transfer: 0.0553	 finalize: 0.0368
Accumulated time: update_bounds func: 28.2352	 prepare: 1.2765	 bound: 24.4068	 transfer: 0.0553	 finalize: 1.0358
batch bounding time:  0.9674079418182373
Current worst splitting domains [lb, ub] (depth):
[-0.83224,   inf] (59), [-0.83224,   inf] (49), [-0.83224,   inf] (55), [-0.83223,   inf] (45), [-0.83223,   inf] (59), [-0.83222,   inf] (55), [-0.83222,   inf] (57), [-0.83222,   inf] (45), [-0.83222,   inf] (47), [-0.83221,   inf] (55), [-0.83220,   inf] (45), [-0.83219,   inf] (37), [-0.83219,   inf] (53), [-0.83219,   inf] (49), [-0.83218,   inf] (57), [-0.83217,   inf] (33), [-0.83217,   inf] (49), [-0.83216,   inf] (35), [-0.83216,   inf] (57), [-0.83216,   inf] (55), 
length of domains: 5822
Total time: 1.2409	 pickout: 0.0613	 decision: 0.1500	 get_bound: 0.9682	 add_domain: 0.0614
Current lb:-0.832244873046875
13296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 34.54840397834778

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6092] [1, 4893] [1, 6092] [2, 117] [2, 167] [1, 7588] [1, 3236] [2, 17] [1, 4893] [2, 150] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 387.890380859375 with beta sum per layer: [0.0, 43.69340515136719, 12.854557037353516]
alpha/beta optimization time: 0.8254785537719727
This batch time : update_bounds func: 0.9679	 prepare: 0.0573	 bound: 0.8258	 transfer: 0.0501	 finalize: 0.0325
Accumulated time: update_bounds func: 29.2031	 prepare: 1.3338	 bound: 25.2326	 transfer: 0.0501	 finalize: 1.0683
batch bounding time:  0.9685580730438232
Current worst splitting domains [lb, ub] (depth):
[-0.83123,   inf] (51), [-0.83123,   inf] (57), [-0.83123,   inf] (45), [-0.83122,   inf] (49), [-0.83122,   inf] (37), [-0.83122,   inf] (43), [-0.83122,   inf] (55), [-0.83121,   inf] (55), [-0.83121,   inf] (57), [-0.83121,   inf] (59), [-0.83120,   inf] (51), [-0.83120,   inf] (57), [-0.83120,   inf] (55), [-0.83119,   inf] (49), [-0.83119,   inf] (55), [-0.83118,   inf] (45), [-0.83117,   inf] (59), [-0.83116,   inf] (57), [-0.83116,   inf] (57), [-0.83115,   inf] (55), 
length of domains: 6067
Total time: 1.2428	 pickout: 0.0624	 decision: 0.1544	 get_bound: 0.9694	 add_domain: 0.0566
Current lb:-0.8312296867370605
13808 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 35.79678750038147

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 4269] [1, 3236] [2, 17] [1, 6730] [2, 65] [1, 6730] [1, 461] [1, 6092] [1, 3236] [1, 6092] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 380.29071044921875 with beta sum per layer: [0.0, 42.01041030883789, 15.487049102783203]
alpha/beta optimization time: 0.8268415927886963
This batch time : update_bounds func: 0.9759	 prepare: 0.0618	 bound: 0.8272	 transfer: 0.0524	 finalize: 0.0322
Accumulated time: update_bounds func: 30.1789	 prepare: 1.3956	 bound: 26.0598	 transfer: 0.0524	 finalize: 1.1005
batch bounding time:  0.9764399528503418
Current worst splitting domains [lb, ub] (depth):
[-0.83008,   inf] (29), [-0.83008,   inf] (59), [-0.83008,   inf] (39), [-0.83008,   inf] (55), [-0.83008,   inf] (53), [-0.83007,   inf] (41), [-0.83007,   inf] (53), [-0.83006,   inf] (27), [-0.83006,   inf] (55), [-0.83005,   inf] (57), [-0.83005,   inf] (55), [-0.83004,   inf] (43), [-0.83003,   inf] (25), [-0.83003,   inf] (55), [-0.83003,   inf] (61), [-0.83002,   inf] (53), [-0.83002,   inf] (59), [-0.83002,   inf] (57), [-0.83000,   inf] (59), [-0.82999,   inf] (55), 
length of domains: 6315
Total time: 1.3943	 pickout: 0.0603	 decision: 0.3001	 get_bound: 0.9773	 add_domain: 0.0565
Current lb:-0.8300809860229492
14320 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 37.19634413719177

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 94] [2, 167] [1, 6708] [1, 461] [1, 4269] [1, 6708] [1, 7588] [2, 196] [1, 461] [1, 6092] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 386.3639221191406 with beta sum per layer: [0.0, 44.30355453491211, 13.456380844116211]
alpha/beta optimization time: 0.8182849884033203
This batch time : update_bounds func: 0.9547	 prepare: 0.0501	 bound: 0.8186	 transfer: 0.0518	 finalize: 0.0327
Accumulated time: update_bounds func: 31.1336	 prepare: 1.4457	 bound: 26.8785	 transfer: 0.0518	 finalize: 1.1331
batch bounding time:  0.955327033996582
Current worst splitting domains [lb, ub] (depth):
[-0.82890,   inf] (55), [-0.82889,   inf] (55), [-0.82888,   inf] (55), [-0.82888,   inf] (31), [-0.82888,   inf] (57), [-0.82887,   inf] (59), [-0.82887,   inf] (29), [-0.82887,   inf] (45), [-0.82886,   inf] (53), [-0.82886,   inf] (57), [-0.82886,   inf] (57), [-0.82886,   inf] (27), [-0.82886,   inf] (57), [-0.82886,   inf] (57), [-0.82885,   inf] (59), [-0.82884,   inf] (55), [-0.82884,   inf] (49), [-0.82883,   inf] (55), [-0.82882,   inf] (57), [-0.82882,   inf] (61), 
length of domains: 6565
Total time: 1.2225	 pickout: 0.0593	 decision: 0.1503	 get_bound: 0.9562	 add_domain: 0.0567
Current lb:-0.8288994431495667
14832 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 38.42422342300415

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 461] [1, 3236] [1, 469] [2, 57] [1, 3236] [1, 6092] [2, 94] [2, 17] [1, 7588] [2, 167] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 371.53253173828125 with beta sum per layer: [0.0, 55.23871612548828, 17.066518783569336]
alpha/beta optimization time: 0.8278276920318604
This batch time : update_bounds func: 0.9652	 prepare: 0.0502	 bound: 0.8282	 transfer: 0.0525	 finalize: 0.0327
Accumulated time: update_bounds func: 32.0988	 prepare: 1.4959	 bound: 27.7067	 transfer: 0.0525	 finalize: 1.1658
batch bounding time:  0.9657618999481201
Current worst splitting domains [lb, ub] (depth):
[-0.82786,   inf] (51), [-0.82786,   inf] (57), [-0.82786,   inf] (43), [-0.82786,   inf] (47), [-0.82785,   inf] (53), [-0.82784,   inf] (55), [-0.82784,   inf] (55), [-0.82784,   inf] (35), [-0.82784,   inf] (55), [-0.82783,   inf] (57), [-0.82783,   inf] (41), [-0.82783,   inf] (59), [-0.82782,   inf] (55), [-0.82782,   inf] (49), [-0.82782,   inf] (59), [-0.82781,   inf] (27), [-0.82779,   inf] (53), [-0.82779,   inf] (57), [-0.82779,   inf] (45), [-0.82779,   inf] (57), 
length of domains: 6808
Total time: 1.2333	 pickout: 0.0611	 decision: 0.1507	 get_bound: 0.9665	 add_domain: 0.0549
Current lb:-0.8278627395629883
15344 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 39.66313076019287

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7588] [1, 3236] [2, 117] [1, 6100] [1, 4971] [1, 6092] [1, 7588] [2, 93] [1, 6092] [1, 461] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 383.974853515625 with beta sum per layer: [0.0, 51.07196044921875, 14.141392707824707]
alpha/beta optimization time: 0.8212339878082275
This batch time : update_bounds func: 1.1104	 prepare: 0.0501	 bound: 0.8216	 transfer: 0.0525	 finalize: 0.0333
Accumulated time: update_bounds func: 33.2092	 prepare: 1.5460	 bound: 28.5282	 transfer: 0.0525	 finalize: 1.1991
batch bounding time:  1.1109874248504639
Current worst splitting domains [lb, ub] (depth):
[-0.82697,   inf] (49), [-0.82696,   inf] (55), [-0.82696,   inf] (49), [-0.82695,   inf] (57), [-0.82695,   inf] (59), [-0.82695,   inf] (59), [-0.82694,   inf] (53), [-0.82693,   inf] (31), [-0.82693,   inf] (47), [-0.82691,   inf] (53), [-0.82691,   inf] (55), [-0.82691,   inf] (49), [-0.82691,   inf] (59), [-0.82691,   inf] (59), [-0.82690,   inf] (57), [-0.82689,   inf] (55), [-0.82689,   inf] (59), [-0.82689,   inf] (59), [-0.82688,   inf] (49), [-0.82688,   inf] (41), 
length of domains: 7056
Total time: 1.3806	 pickout: 0.0587	 decision: 0.1511	 get_bound: 1.1118	 add_domain: 0.0589
Current lb:-0.8269655704498291
15856 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 41.04911208152771

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 4893] [1, 3236] [1, 4893] [1, 461] [2, 167] [2, 167] [1, 4971] [2, 57] [1, 4893] [1, 6100] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 389.7458190917969 with beta sum per layer: [0.0, 49.32508087158203, 12.799077987670898]
alpha/beta optimization time: 0.8404266834259033
This batch time : update_bounds func: 0.9813	 prepare: 0.0515	 bound: 0.8408	 transfer: 0.0520	 finalize: 0.0354
Accumulated time: update_bounds func: 34.1904	 prepare: 1.5975	 bound: 29.3690	 transfer: 0.0520	 finalize: 1.2345
batch bounding time:  0.9821937084197998
Current worst splitting domains [lb, ub] (depth):
[-0.82608,   inf] (27), [-0.82607,   inf] (55), [-0.82607,   inf] (59), [-0.82607,   inf] (57), [-0.82607,   inf] (27), [-0.82607,   inf] (59), [-0.82606,   inf] (59), [-0.82605,   inf] (45), [-0.82605,   inf] (55), [-0.82605,   inf] (53), [-0.82604,   inf] (49), [-0.82604,   inf] (55), [-0.82604,   inf] (59), [-0.82603,   inf] (55), [-0.82603,   inf] (59), [-0.82603,   inf] (57), [-0.82603,   inf] (61), [-0.82602,   inf] (57), [-0.82602,   inf] (57), [-0.82602,   inf] (53), 
length of domains: 7307
Total time: 1.2741	 pickout: 0.0567	 decision: 0.1543	 get_bound: 0.9836	 add_domain: 0.0795
Current lb:-0.8260760307312012
16368 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 42.32954001426697

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 196] [1, 6092] [1, 6092] [1, 7588] [2, 196] [2, 167] [2, 167] [2, 17] [1, 7588] [1, 4269] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 373.651611328125 with beta sum per layer: [0.0, 56.03586959838867, 17.193992614746094]
alpha/beta optimization time: 0.8293182849884033
This batch time : update_bounds func: 0.9461	 prepare: 0.0508	 bound: 0.8297	 transfer: 0.0283	 finalize: 0.0358
Accumulated time: update_bounds func: 35.1365	 prepare: 1.6483	 bound: 30.1987	 transfer: 0.0283	 finalize: 1.2703
batch bounding time:  0.9470140933990479
Current worst splitting domains [lb, ub] (depth):
[-0.82523,   inf] (59), [-0.82522,   inf] (57), [-0.82522,   inf] (55), [-0.82522,   inf] (57), [-0.82522,   inf] (37), [-0.82521,   inf] (35), [-0.82521,   inf] (61), [-0.82521,   inf] (61), [-0.82521,   inf] (49), [-0.82521,   inf] (57), [-0.82521,   inf] (43), [-0.82520,   inf] (57), [-0.82520,   inf] (59), [-0.82520,   inf] (31), [-0.82520,   inf] (59), [-0.82520,   inf] (43), [-0.82519,   inf] (55), [-0.82519,   inf] (35), [-0.82519,   inf] (57), [-0.82519,   inf] (55), 
length of domains: 7555
Total time: 1.2152	 pickout: 0.0564	 decision: 0.1515	 get_bound: 0.9479	 add_domain: 0.0594
Current lb:-0.825228214263916
16880 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 43.55086064338684

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 167] [1, 461] [1, 3236] [2, 150] [2, 65] [2, 93] [2, 167] [2, 167] [1, 6730] [1, 6100] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 362.4061279296875 with beta sum per layer: [0.0, 59.201446533203125, 20.002328872680664]
alpha/beta optimization time: 0.8220157623291016
This batch time : update_bounds func: 1.1296	 prepare: 0.0504	 bound: 0.8224	 transfer: 0.0509	 finalize: 0.2042
Accumulated time: update_bounds func: 36.2661	 prepare: 1.6987	 bound: 31.0211	 transfer: 0.0509	 finalize: 1.4745
batch bounding time:  1.1302261352539062
Current worst splitting domains [lb, ub] (depth):
[-0.82447,   inf] (57), [-0.82446,   inf] (53), [-0.82446,   inf] (55), [-0.82446,   inf] (57), [-0.82445,   inf] (41), [-0.82445,   inf] (47), [-0.82445,   inf] (57), [-0.82444,   inf] (55), [-0.82444,   inf] (57), [-0.82444,   inf] (47), [-0.82443,   inf] (55), [-0.82443,   inf] (57), [-0.82442,   inf] (61), [-0.82442,   inf] (57), [-0.82442,   inf] (57), [-0.82442,   inf] (59), [-0.82442,   inf] (49), [-0.82442,   inf] (53), [-0.82441,   inf] (61), [-0.82441,   inf] (59), 
length of domains: 7805
Total time: 1.4015	 pickout: 0.0571	 decision: 0.1544	 get_bound: 1.1310	 add_domain: 0.0590
Current lb:-0.8244660496711731
17392 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 44.95782518386841

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 461] [1, 4971] [1, 6092] [2, 167] [1, 6730] [1, 6708] [2, 150] [1, 6092] [2, 167] [2, 17] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 370.97247314453125 with beta sum per layer: [0.0, 68.146240234375, 17.2922306060791]
alpha/beta optimization time: 0.8232455253601074
This batch time : update_bounds func: 0.9583	 prepare: 0.0512	 bound: 0.8236	 transfer: 0.0489	 finalize: 0.0331
Accumulated time: update_bounds func: 37.2243	 prepare: 1.7499	 bound: 31.8447	 transfer: 0.0489	 finalize: 1.5076
batch bounding time:  0.9588606357574463
Current worst splitting domains [lb, ub] (depth):
[-0.82367,   inf] (49), [-0.82367,   inf] (59), [-0.82367,   inf] (51), [-0.82366,   inf] (49), [-0.82365,   inf] (57), [-0.82365,   inf] (27), [-0.82365,   inf] (53), [-0.82365,   inf] (47), [-0.82365,   inf] (55), [-0.82365,   inf] (41), [-0.82364,   inf] (57), [-0.82364,   inf] (53), [-0.82364,   inf] (55), [-0.82363,   inf] (57), [-0.82362,   inf] (53), [-0.82362,   inf] (57), [-0.82361,   inf] (59), [-0.82359,   inf] (47), [-0.82359,   inf] (57), [-0.82359,   inf] (31), 
length of domains: 8053
Total time: 1.2294	 pickout: 0.0588	 decision: 0.1535	 get_bound: 0.9597	 add_domain: 0.0574
Current lb:-0.8236715793609619
17904 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 46.19274425506592

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 4893] [2, 167] [1, 7588] [1, 6100] [1, 3236] [2, 196] [1, 4269] [2, 17] [1, 3236] [1, 6730] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 379.3543701171875 with beta sum per layer: [0.0, 70.55367279052734, 16.183483123779297]
alpha/beta optimization time: 0.8251953125
This batch time : update_bounds func: 0.9595	 prepare: 0.0508	 bound: 0.8255	 transfer: 0.0491	 finalize: 0.0326
Accumulated time: update_bounds func: 38.1839	 prepare: 1.8007	 bound: 32.6702	 transfer: 0.0491	 finalize: 1.5402
batch bounding time:  0.9601137638092041
Current worst splitting domains [lb, ub] (depth):
[-0.82283,   inf] (47), [-0.82283,   inf] (57), [-0.82283,   inf] (57), [-0.82282,   inf] (57), [-0.82282,   inf] (61), [-0.82281,   inf] (41), [-0.82281,   inf] (53), [-0.82280,   inf] (57), [-0.82280,   inf] (45), [-0.82280,   inf] (53), [-0.82280,   inf] (55), [-0.82280,   inf] (55), [-0.82280,   inf] (61), [-0.82280,   inf] (53), [-0.82279,   inf] (31), [-0.82278,   inf] (59), [-0.82278,   inf] (51), [-0.82278,   inf] (37), [-0.82278,   inf] (57), [-0.82278,   inf] (59), 
length of domains: 8304
Total time: 1.2275	 pickout: 0.0572	 decision: 0.1506	 get_bound: 0.9610	 add_domain: 0.0588
Current lb:-0.8228321075439453
18416 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 47.42593741416931

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 17] [1, 4901] [2, 150] [2, 167] [2, 150] [2, 17] [1, 7588] [2, 167] [2, 17] [1, 7588] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 378.68310546875 with beta sum per layer: [0.0, 73.58657836914062, 16.6553955078125]
alpha/beta optimization time: 0.8202192783355713
This batch time : update_bounds func: 0.9552	 prepare: 0.0505	 bound: 0.8206	 transfer: 0.0494	 finalize: 0.0331
Accumulated time: update_bounds func: 39.1391	 prepare: 1.8512	 bound: 33.4908	 transfer: 0.0494	 finalize: 1.5733
batch bounding time:  0.9558866024017334
Current worst splitting domains [lb, ub] (depth):
[-0.82205,   inf] (47), [-0.82205,   inf] (57), [-0.82205,   inf] (59), [-0.82204,   inf] (59), [-0.82204,   inf] (55), [-0.82204,   inf] (45), [-0.82204,   inf] (59), [-0.82203,   inf] (57), [-0.82202,   inf] (37), [-0.82202,   inf] (57), [-0.82201,   inf] (57), [-0.82201,   inf] (57), [-0.82201,   inf] (59), [-0.82200,   inf] (59), [-0.82200,   inf] (59), [-0.82199,   inf] (53), [-0.82199,   inf] (59), [-0.82199,   inf] (53), [-0.82199,   inf] (61), [-0.82198,   inf] (61), 
length of domains: 8555
Total time: 1.2278	 pickout: 0.0589	 decision: 0.1524	 get_bound: 0.9567	 add_domain: 0.0597
Current lb:-0.8220529556274414
18928 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 48.65964937210083

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2082] [1, 3236] [2, 167] [2, 167] [1, 7588] [2, 17] [2, 167] [1, 461] [1, 4893] [1, 4901] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 369.41546630859375 with beta sum per layer: [0.0, 68.56663513183594, 17.507230758666992]
alpha/beta optimization time: 0.8240647315979004
This batch time : update_bounds func: 0.9619	 prepare: 0.0502	 bound: 0.8245	 transfer: 0.0519	 finalize: 0.0339
Accumulated time: update_bounds func: 40.1009	 prepare: 1.9014	 bound: 34.3153	 transfer: 0.0519	 finalize: 1.6071
batch bounding time:  0.9624900817871094
Current worst splitting domains [lb, ub] (depth):
[-0.82133,   inf] (59), [-0.82132,   inf] (51), [-0.82132,   inf] (61), [-0.82132,   inf] (59), [-0.82132,   inf] (57), [-0.82131,   inf] (37), [-0.82131,   inf] (55), [-0.82130,   inf] (55), [-0.82130,   inf] (31), [-0.82129,   inf] (47), [-0.82129,   inf] (49), [-0.82128,   inf] (55), [-0.82128,   inf] (59), [-0.82127,   inf] (57), [-0.82127,   inf] (53), [-0.82127,   inf] (57), [-0.82127,   inf] (55), [-0.82127,   inf] (61), [-0.82127,   inf] (43), [-0.82126,   inf] (43), 
length of domains: 8800
Total time: 1.4174	 pickout: 0.0586	 decision: 0.3365	 get_bound: 0.9633	 add_domain: 0.0590
Current lb:-0.8213257789611816
19440 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 50.08366370201111

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6092] [1, 6092] [2, 150] [2, 167] [1, 3236] [2, 65] [1, 7588] [1, 4269] [2, 57] [1, 4893] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 365.7746887207031 with beta sum per layer: [0.0, 64.82859802246094, 16.66647720336914]
alpha/beta optimization time: 0.8212566375732422
This batch time : update_bounds func: 0.9528	 prepare: 0.0506	 bound: 0.8216	 transfer: 0.0468	 finalize: 0.0321
Accumulated time: update_bounds func: 41.0538	 prepare: 1.9520	 bound: 35.1369	 transfer: 0.0468	 finalize: 1.6393
batch bounding time:  0.9534409046173096
Current worst splitting domains [lb, ub] (depth):
[-0.82058,   inf] (59), [-0.82058,   inf] (33), [-0.82058,   inf] (31), [-0.82058,   inf] (59), [-0.82058,   inf] (57), [-0.82057,   inf] (57), [-0.82057,   inf] (59), [-0.82057,   inf] (59), [-0.82057,   inf] (55), [-0.82056,   inf] (59), [-0.82056,   inf] (47), [-0.82056,   inf] (55), [-0.82056,   inf] (25), [-0.82056,   inf] (61), [-0.82055,   inf] (31), [-0.82055,   inf] (59), [-0.82055,   inf] (47), [-0.82055,   inf] (57), [-0.82055,   inf] (59), [-0.82054,   inf] (59), 
length of domains: 9048
Total time: 1.2284	 pickout: 0.0608	 decision: 0.1536	 get_bound: 0.9543	 add_domain: 0.0598
Current lb:-0.8205837607383728
19952 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 51.31759691238403

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 167] [2, 122] [2, 57] [2, 167] [1, 7588] [2, 167] [2, 167] [2, 150] [2, 150] [1, 6092] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 365.6897277832031 with beta sum per layer: [0.0, 81.25140380859375, 19.107154846191406]
alpha/beta optimization time: 0.8243019580841064
This batch time : update_bounds func: 0.9975	 prepare: 0.0848	 bound: 0.8247	 transfer: 0.0512	 finalize: 0.0339
Accumulated time: update_bounds func: 42.0512	 prepare: 2.0368	 bound: 35.9616	 transfer: 0.0512	 finalize: 1.6732
batch bounding time:  0.9981200695037842
Current worst splitting domains [lb, ub] (depth):
[-0.82000,   inf] (61), [-0.82000,   inf] (37), [-0.82000,   inf] (59), [-0.81999,   inf] (53), [-0.81999,   inf] (33), [-0.81999,   inf] (59), [-0.81999,   inf] (55), [-0.81998,   inf] (59), [-0.81998,   inf] (61), [-0.81998,   inf] (37), [-0.81998,   inf] (55), [-0.81997,   inf] (53), [-0.81997,   inf] (55), [-0.81997,   inf] (55), [-0.81997,   inf] (57), [-0.81997,   inf] (59), [-0.81997,   inf] (61), [-0.81996,   inf] (59), [-0.81996,   inf] (59), [-0.81996,   inf] (61), 
length of domains: 9300
Total time: 1.2731	 pickout: 0.0602	 decision: 0.1540	 get_bound: 0.9990	 add_domain: 0.0600
Current lb:-0.8199958801269531
20464 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 52.596627712249756

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 150] [2, 65] [2, 150] [1, 4971] [2, 122] [2, 167] [2, 150] [2, 167] [2, 150] [2, 65] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 357.0509033203125 with beta sum per layer: [0.0, 83.31590270996094, 20.59771728515625]
alpha/beta optimization time: 0.8207123279571533
This batch time : update_bounds func: 0.9593	 prepare: 0.0498	 bound: 0.8211	 transfer: 0.0532	 finalize: 0.0340
Accumulated time: update_bounds func: 43.0105	 prepare: 2.0866	 bound: 36.7826	 transfer: 0.0532	 finalize: 1.7071
batch bounding time:  0.9598963260650635
Current worst splitting domains [lb, ub] (depth):
[-0.81942,   inf] (27), [-0.81942,   inf] (49), [-0.81941,   inf] (53), [-0.81941,   inf] (63), [-0.81941,   inf] (61), [-0.81941,   inf] (55), [-0.81941,   inf] (39), [-0.81939,   inf] (43), [-0.81939,   inf] (63), [-0.81939,   inf] (55), [-0.81939,   inf] (45), [-0.81938,   inf] (37), [-0.81938,   inf] (57), [-0.81938,   inf] (57), [-0.81938,   inf] (51), [-0.81938,   inf] (43), [-0.81938,   inf] (51), [-0.81938,   inf] (57), [-0.81937,   inf] (57), [-0.81937,   inf] (59), 
length of domains: 9548
Total time: 1.2310	 pickout: 0.0618	 decision: 0.1494	 get_bound: 0.9607	 add_domain: 0.0590
Current lb:-0.8194215297698975
20976 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 53.833471059799194

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 196] [1, 6739] [1, 4269] [1, 4380] [2, 150] [1, 4269] [1, 4893] [1, 6730] [1, 3820] [1, 6092] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 363.44573974609375 with beta sum per layer: [0.0, 91.75313568115234, 19.283279418945312]
alpha/beta optimization time: 0.824462890625
This batch time : update_bounds func: 0.9681	 prepare: 0.0509	 bound: 0.8248	 transfer: 0.0570	 finalize: 0.0337
Accumulated time: update_bounds func: 43.9786	 prepare: 2.1375	 bound: 37.6075	 transfer: 0.0570	 finalize: 1.7408
batch bounding time:  0.9687724113464355
Current worst splitting domains [lb, ub] (depth):
[-0.81888,   inf] (59), [-0.81888,   inf] (59), [-0.81888,   inf] (57), [-0.81888,   inf] (57), [-0.81887,   inf] (47), [-0.81887,   inf] (57), [-0.81887,   inf] (61), [-0.81887,   inf] (57), [-0.81886,   inf] (57), [-0.81886,   inf] (57), [-0.81886,   inf] (53), [-0.81886,   inf] (31), [-0.81886,   inf] (61), [-0.81885,   inf] (61), [-0.81885,   inf] (53), [-0.81885,   inf] (55), [-0.81884,   inf] (61), [-0.81884,   inf] (59), [-0.81884,   inf] (59), [-0.81883,   inf] (47), 
length of domains: 9799
Total time: 1.4609	 pickout: 0.0623	 decision: 0.3657	 get_bound: 0.9696	 add_domain: 0.0633
Current lb:-0.8188836574554443
21488 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 55.30052471160889

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 150] [2, 150] [1, 6092] [2, 150] [2, 17] [1, 6092] [2, 150] [1, 461] [2, 167] [2, 167] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 360.5560302734375 with beta sum per layer: [0.0, 101.344970703125, 20.5797176361084]
alpha/beta optimization time: 0.8255178928375244
This batch time : update_bounds func: 0.9701	 prepare: 0.0504	 bound: 0.8259	 transfer: 0.0554	 finalize: 0.0369
Accumulated time: update_bounds func: 44.9487	 prepare: 2.1879	 bound: 38.4333	 transfer: 0.0554	 finalize: 1.7777
batch bounding time:  0.9707989692687988
Current worst splitting domains [lb, ub] (depth):
[-0.81836,   inf] (57), [-0.81836,   inf] (59), [-0.81835,   inf] (25), [-0.81835,   inf] (59), [-0.81835,   inf] (63), [-0.81835,   inf] (61), [-0.81835,   inf] (61), [-0.81834,   inf] (51), [-0.81834,   inf] (57), [-0.81834,   inf] (53), [-0.81834,   inf] (59), [-0.81834,   inf] (59), [-0.81833,   inf] (57), [-0.81833,   inf] (59), [-0.81833,   inf] (55), [-0.81833,   inf] (55), [-0.81832,   inf] (39), [-0.81832,   inf] (61), [-0.81832,   inf] (31), [-0.81832,   inf] (59), 
length of domains: 10045
Total time: 1.2475	 pickout: 0.0603	 decision: 0.1526	 get_bound: 0.9718	 add_domain: 0.0628
Current lb:-0.8183624744415283
22000 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 56.555362701416016

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 150] [2, 167] [2, 97] [2, 167] [1, 3820] [2, 167] [2, 150] [1, 6100] [1, 4901] [1, 4971] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 361.49212646484375 with beta sum per layer: [0.0, 94.60218811035156, 21.02001190185547]
alpha/beta optimization time: 0.8311402797698975
This batch time : update_bounds func: 0.9690	 prepare: 0.0509	 bound: 0.8315	 transfer: 0.0518	 finalize: 0.0333
Accumulated time: update_bounds func: 45.9177	 prepare: 2.2388	 bound: 39.2649	 transfer: 0.0518	 finalize: 1.8110
batch bounding time:  0.9695870876312256
Current worst splitting domains [lb, ub] (depth):
[-0.81774,   inf] (59), [-0.81774,   inf] (25), [-0.81774,   inf] (27), [-0.81774,   inf] (59), [-0.81773,   inf] (37), [-0.81773,   inf] (57), [-0.81773,   inf] (55), [-0.81773,   inf] (59), [-0.81773,   inf] (47), [-0.81773,   inf] (61), [-0.81773,   inf] (55), [-0.81772,   inf] (55), [-0.81771,   inf] (63), [-0.81771,   inf] (61), [-0.81771,   inf] (59), [-0.81771,   inf] (41), [-0.81771,   inf] (59), [-0.81771,   inf] (57), [-0.81771,   inf] (45), [-0.81771,   inf] (57), 
length of domains: 10292
Total time: 1.2457	 pickout: 0.0634	 decision: 0.1528	 get_bound: 0.9705	 add_domain: 0.0590
Current lb:-0.8177422881126404
22512 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 57.806803464889526

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6092] [2, 97] [2, 196] [1, 6092] [1, 4893] [1, 7588] [1, 6092] [2, 150] [1, 6739] [2, 167] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 367.2843322753906 with beta sum per layer: [0.0, 88.9021224975586, 17.504474639892578]
alpha/beta optimization time: 0.8283360004425049
This batch time : update_bounds func: 0.9724	 prepare: 0.0570	 bound: 0.8287	 transfer: 0.0523	 finalize: 0.0327
Accumulated time: update_bounds func: 46.8901	 prepare: 2.2958	 bound: 40.0936	 transfer: 0.0523	 finalize: 1.8438
batch bounding time:  0.9730613231658936
Current worst splitting domains [lb, ub] (depth):
[-0.81716,   inf] (59), [-0.81715,   inf] (57), [-0.81715,   inf] (57), [-0.81715,   inf] (55), [-0.81715,   inf] (59), [-0.81715,   inf] (57), [-0.81714,   inf] (63), [-0.81714,   inf] (53), [-0.81714,   inf] (57), [-0.81714,   inf] (61), [-0.81714,   inf] (25), [-0.81713,   inf] (57), [-0.81712,   inf] (59), [-0.81712,   inf] (57), [-0.81712,   inf] (55), [-0.81712,   inf] (61), [-0.81712,   inf] (59), [-0.81711,   inf] (57), [-0.81711,   inf] (49), [-0.81711,   inf] (59), 
length of domains: 10543
Total time: 1.2548	 pickout: 0.0601	 decision: 0.1587	 get_bound: 0.9739	 add_domain: 0.0622
Current lb:-0.8171570301055908
23024 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 59.06779503822327

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7588] [1, 6092] [2, 167] [1, 469] [2, 167] [2, 150] [1, 3820] [1, 4971] [1, 3236] [2, 150] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 360.65533447265625 with beta sum per layer: [0.0, 70.29247283935547, 20.400970458984375]
alpha/beta optimization time: 0.8218810558319092
This batch time : update_bounds func: 0.9392	 prepare: 0.0505	 bound: 0.8222	 transfer: 0.0319	 finalize: 0.0332
Accumulated time: update_bounds func: 47.8293	 prepare: 2.3463	 bound: 40.9158	 transfer: 0.0319	 finalize: 1.8770
batch bounding time:  0.9398858547210693
Current worst splitting domains [lb, ub] (depth):
[-0.81652,   inf] (59), [-0.81652,   inf] (61), [-0.81651,   inf] (39), [-0.81651,   inf] (59), [-0.81651,   inf] (61), [-0.81650,   inf] (45), [-0.81650,   inf] (63), [-0.81650,   inf] (49), [-0.81649,   inf] (61), [-0.81649,   inf] (63), [-0.81648,   inf] (59), [-0.81648,   inf] (57), [-0.81648,   inf] (51), [-0.81648,   inf] (61), [-0.81648,   inf] (59), [-0.81648,   inf] (61), [-0.81648,   inf] (57), [-0.81647,   inf] (57), [-0.81647,   inf] (59), [-0.81647,   inf] (61), 
length of domains: 10786
Total time: 1.4642	 pickout: 0.0577	 decision: 0.4060	 get_bound: 0.9407	 add_domain: 0.0598
Current lb:-0.8165212869644165
23536 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 60.53774356842041

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 167] [1, 4380] [1, 6708] [2, 167] [1, 7588] [2, 17] [1, 4380] [1, 461] [2, 150] [1, 4380] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 366.0279846191406 with beta sum per layer: [0.0, 95.0733642578125, 17.308250427246094]
alpha/beta optimization time: 0.828960657119751
This batch time : update_bounds func: 0.9693	 prepare: 0.0510	 bound: 0.8294	 transfer: 0.0541	 finalize: 0.0334
Accumulated time: update_bounds func: 48.7986	 prepare: 2.3972	 bound: 41.7452	 transfer: 0.0541	 finalize: 1.9104
batch bounding time:  0.9699149131774902
Current worst splitting domains [lb, ub] (depth):
[-0.81596,   inf] (57), [-0.81596,   inf] (57), [-0.81596,   inf] (57), [-0.81596,   inf] (59), [-0.81596,   inf] (51), [-0.81595,   inf] (59), [-0.81595,   inf] (61), [-0.81595,   inf] (63), [-0.81595,   inf] (51), [-0.81594,   inf] (59), [-0.81594,   inf] (57), [-0.81594,   inf] (59), [-0.81594,   inf] (61), [-0.81594,   inf] (61), [-0.81593,   inf] (59), [-0.81593,   inf] (39), [-0.81593,   inf] (57), [-0.81593,   inf] (47), [-0.81592,   inf] (61), [-0.81592,   inf] (49), 
length of domains: 11038
Total time: 1.2429	 pickout: 0.0589	 decision: 0.1518	 get_bound: 0.9708	 add_domain: 0.0614
Current lb:-0.8159592151641846
24048 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 61.78645086288452

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 150] [2, 150] [2, 150] [2, 167] [2, 150] [1, 7588] [2, 150] [2, 150] [1, 7588] [2, 167] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 354.47991943359375 with beta sum per layer: [0.0, 95.24153900146484, 20.4154052734375]
alpha/beta optimization time: 0.8218319416046143
This batch time : update_bounds func: 0.9589	 prepare: 0.0510	 bound: 0.8222	 transfer: 0.0518	 finalize: 0.0325
Accumulated time: update_bounds func: 49.7575	 prepare: 2.4483	 bound: 42.5674	 transfer: 0.0518	 finalize: 1.9429
batch bounding time:  0.9596230983734131
Current worst splitting domains [lb, ub] (depth):
[-0.81550,   inf] (57), [-0.81550,   inf] (61), [-0.81550,   inf] (57), [-0.81550,   inf] (61), [-0.81550,   inf] (49), [-0.81550,   inf] (61), [-0.81550,   inf] (57), [-0.81549,   inf] (59), [-0.81549,   inf] (61), [-0.81549,   inf] (63), [-0.81549,   inf] (33), [-0.81549,   inf] (59), [-0.81549,   inf] (59), [-0.81548,   inf] (59), [-0.81548,   inf] (47), [-0.81548,   inf] (57), [-0.81548,   inf] (55), [-0.81547,   inf] (51), [-0.81547,   inf] (57), [-0.81547,   inf] (61), 
length of domains: 11290
Total time: 1.2370	 pickout: 0.0608	 decision: 0.1535	 get_bound: 0.9605	 add_domain: 0.0621
Current lb:-0.8155043125152588
24560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 63.03025794029236

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 167] [1, 461] [1, 6092] [2, 150] [1, 6092] [2, 150] [1, 469] [1, 7588] [1, 7588] [2, 150] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 357.41064453125 with beta sum per layer: [0.0, 96.7862319946289, 18.46917724609375]
alpha/beta optimization time: 0.821528434753418
This batch time : update_bounds func: 0.9592	 prepare: 0.0508	 bound: 0.8219	 transfer: 0.0522	 finalize: 0.0327
Accumulated time: update_bounds func: 50.7167	 prepare: 2.4991	 bound: 43.3892	 transfer: 0.0522	 finalize: 1.9756
batch bounding time:  0.9598004817962646
Current worst splitting domains [lb, ub] (depth):
[-0.81501,   inf] (49), [-0.81501,   inf] (61), [-0.81501,   inf] (61), [-0.81501,   inf] (61), [-0.81501,   inf] (57), [-0.81500,   inf] (61), [-0.81500,   inf] (59), [-0.81500,   inf] (63), [-0.81499,   inf] (61), [-0.81499,   inf] (57), [-0.81499,   inf] (63), [-0.81499,   inf] (63), [-0.81499,   inf] (59), [-0.81499,   inf] (55), [-0.81499,   inf] (43), [-0.81499,   inf] (63), [-0.81499,   inf] (51), [-0.81499,   inf] (35), [-0.81498,   inf] (61), [-0.81498,   inf] (63), 
length of domains: 11542
Total time: 1.2365	 pickout: 0.0613	 decision: 0.1525	 get_bound: 0.9607	 add_domain: 0.0620
Current lb:-0.8150134682655334
25072 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 64.27262592315674

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6739] [2, 150] [2, 150] [2, 167] [1, 7588] [2, 150] [2, 150] [1, 7588] [2, 150] [1, 7588] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 353.38336181640625 with beta sum per layer: [0.0, 112.85411071777344, 21.028820037841797]
alpha/beta optimization time: 0.8233039379119873
This batch time : update_bounds func: 0.9643	 prepare: 0.0511	 bound: 0.8237	 transfer: 0.0531	 finalize: 0.0349
Accumulated time: update_bounds func: 51.6810	 prepare: 2.5502	 bound: 44.2129	 transfer: 0.0531	 finalize: 2.0105
batch bounding time:  0.9649548530578613
Current worst splitting domains [lb, ub] (depth):
[-0.81454,   inf] (49), [-0.81454,   inf] (61), [-0.81454,   inf] (61), [-0.81454,   inf] (61), [-0.81453,   inf] (65), [-0.81453,   inf] (57), [-0.81453,   inf] (41), [-0.81452,   inf] (49), [-0.81452,   inf] (59), [-0.81452,   inf] (55), [-0.81452,   inf] (59), [-0.81451,   inf] (43), [-0.81451,   inf] (53), [-0.81451,   inf] (61), [-0.81451,   inf] (57), [-0.81451,   inf] (57), [-0.81450,   inf] (61), [-0.81450,   inf] (59), [-0.81450,   inf] (59), [-0.81450,   inf] (63), 
length of domains: 11794
Total time: 1.5078	 pickout: 0.0596	 decision: 0.1516	 get_bound: 0.9658	 add_domain: 0.3307
Current lb:-0.8145439624786377
25584 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 65.78618216514587

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6100] [2, 150] [2, 150] [2, 150] [1, 4380] [1, 6092] [1, 6730] [1, 6092] [1, 6092] [1, 469] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 370.85540771484375 with beta sum per layer: [0.0, 101.88744354248047, 14.750856399536133]
alpha/beta optimization time: 0.8209826946258545
This batch time : update_bounds func: 0.9641	 prepare: 0.0517	 bound: 0.8214	 transfer: 0.0564	 finalize: 0.0331
Accumulated time: update_bounds func: 52.6451	 prepare: 2.6019	 bound: 45.0343	 transfer: 0.0564	 finalize: 2.0435
batch bounding time:  0.9647221565246582
Current worst splitting domains [lb, ub] (depth):
[-0.81406,   inf] (61), [-0.81406,   inf] (61), [-0.81405,   inf] (49), [-0.81405,   inf] (53), [-0.81405,   inf] (59), [-0.81405,   inf] (59), [-0.81405,   inf] (65), [-0.81405,   inf] (57), [-0.81405,   inf] (53), [-0.81404,   inf] (59), [-0.81404,   inf] (63), [-0.81404,   inf] (65), [-0.81404,   inf] (57), [-0.81404,   inf] (61), [-0.81403,   inf] (65), [-0.81403,   inf] (61), [-0.81403,   inf] (61), [-0.81403,   inf] (61), [-0.81402,   inf] (67), [-0.81402,   inf] (63), 
length of domains: 12047
Total time: 1.2418	 pickout: 0.0609	 decision: 0.1517	 get_bound: 0.9656	 add_domain: 0.0636
Current lb:-0.8140562772750854
26096 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 67.03426599502563

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 150] [2, 150] [1, 4269] [1, 4971] [2, 167] [1, 7588] [1, 3547] [1, 4901] [1, 6092] [2, 167] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 360.26470947265625 with beta sum per layer: [0.0, 117.61687469482422, 18.872966766357422]
alpha/beta optimization time: 0.824639081954956
This batch time : update_bounds func: 0.9648	 prepare: 0.0507	 bound: 0.8250	 transfer: 0.0540	 finalize: 0.0336
Accumulated time: update_bounds func: 53.6099	 prepare: 2.6527	 bound: 45.8593	 transfer: 0.0540	 finalize: 2.0771
batch bounding time:  0.965482234954834
Current worst splitting domains [lb, ub] (depth):
[-0.81366,   inf] (55), [-0.81365,   inf] (61), [-0.81365,   inf] (59), [-0.81365,   inf] (59), [-0.81365,   inf] (63), [-0.81365,   inf] (63), [-0.81365,   inf] (57), [-0.81365,   inf] (61), [-0.81364,   inf] (43), [-0.81364,   inf] (49), [-0.81363,   inf] (55), [-0.81363,   inf] (61), [-0.81363,   inf] (63), [-0.81363,   inf] (61), [-0.81363,   inf] (59), [-0.81362,   inf] (59), [-0.81362,   inf] (59), [-0.81362,   inf] (55), [-0.81362,   inf] (57), [-0.81362,   inf] (57), 
length of domains: 12301
Total time: 1.2414	 pickout: 0.0600	 decision: 0.1527	 get_bound: 0.9663	 add_domain: 0.0624
Current lb:-0.8136565685272217
26608 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 68.28180265426636

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7588] [2, 167] [2, 150] [1, 7588] [1, 3820] [1, 4380] [1, 3236] [2, 150] [2, 117] [1, 3236] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 364.2066650390625 with beta sum per layer: [0.0, 118.79167938232422, 17.479951858520508]
alpha/beta optimization time: 0.8327343463897705
This batch time : update_bounds func: 0.9798	 prepare: 0.0504	 bound: 0.8331	 transfer: 0.0548	 finalize: 0.0400
Accumulated time: update_bounds func: 54.5896	 prepare: 2.7031	 bound: 46.6923	 transfer: 0.0548	 finalize: 2.1172
batch bounding time:  0.9808282852172852
Current worst splitting domains [lb, ub] (depth):
[-0.81322,   inf] (59), [-0.81321,   inf] (57), [-0.81321,   inf] (41), [-0.81320,   inf] (61), [-0.81320,   inf] (61), [-0.81320,   inf] (57), [-0.81320,   inf] (57), [-0.81320,   inf] (59), [-0.81320,   inf] (61), [-0.81319,   inf] (57), [-0.81319,   inf] (51)/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:462: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(preprocess_cifar(eps_temp, perturbation=True)).reshape(1,-1,1,1)
, [-0.81319,   inf] (57), [-0.81318,   inf] (59), [-0.81318,   inf] (57), [-0.81318,   inf] (59), [-0.81318,   inf] (63), [-0.81318,   inf] (47), [-0.81317,   inf] (61), [-0.81317,   inf] (63), [-0.81317,   inf] (65), 
length of domains: 12555
Total time: 1.2702	 pickout: 0.0609	 decision: 0.1523	 get_bound: 0.9818	 add_domain: 0.0752
Current lb:-0.8132162094116211
27120 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 69.55784344673157

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7588] [2, 150] [1, 4893] [2, 150] [2, 150] [2, 150] [1, 6092] [2, 150] [2, 167] [1, 7588] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 364.80023193359375 with beta sum per layer: [0.0, 115.94935607910156, 18.023866653442383]
alpha/beta optimization time: 0.8345801830291748
This batch time : update_bounds func: 0.9771	 prepare: 0.0559	 bound: 0.8349	 transfer: 0.0518	 finalize: 0.0327
Accumulated time: update_bounds func: 55.5667	 prepare: 2.7589	 bound: 47.5273	 transfer: 0.0518	 finalize: 2.1499
batch bounding time:  0.9776933193206787
Current worst splitting domains [lb, ub] (depth):
[-0.81275,   inf] (45), [-0.81275,   inf] (57), [-0.81275,   inf] (57), [-0.81275,   inf] (39), [-0.81274,   inf] (57), [-0.81274,   inf] (59), [-0.81274,   inf] (61), [-0.81274,   inf] (57), [-0.81273,   inf] (61), [-0.81273,   inf] (53), [-0.81273,   inf] (53), [-0.81273,   inf] (49), [-0.81273,   inf] (37), [-0.81273,   inf] (63), [-0.81272,   inf] (59), [-0.81272,   inf] (55), [-0.81272,   inf] (61), [-0.81272,   inf] (63), [-0.81272,   inf] (59), [-0.81272,   inf] (61), 
length of domains: 12807
Total time: 1.2655	 pickout: 0.0610	 decision: 0.1635	 get_bound: 0.9785	 add_domain: 0.0626
Current lb:-0.8127484321594238
27632 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 70.82950115203857

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 117] [1, 3820] [2, 150] [2, 117] [1, 6092] [2, 167] [2, 150] [2, 150] [2, 167] [1, 461] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 361.34698486328125 with beta sum per layer: [0.0, 119.49142456054688, 20.357715606689453]
alpha/beta optimization time: 0.8297882080078125
This batch time : update_bounds func: 1.2731	 prepare: 0.0608	 bound: 0.8302	 transfer: 0.0516	 finalize: 0.3289
Accumulated time: update_bounds func: 56.8398	 prepare: 2.8197	 bound: 48.3574	 transfer: 0.0516	 finalize: 2.4788
batch bounding time:  1.2739131450653076
Current worst splitting domains [lb, ub] (depth):
[-0.81231,   inf] (59), [-0.81230,   inf] (61), [-0.81230,   inf] (45), [-0.81230,   inf] (59), [-0.81230,   inf] (59), [-0.81230,   inf] (63), [-0.81230,   inf] (57), [-0.81230,   inf] (59), [-0.81230,   inf] (63), [-0.81230,   inf] (59), [-0.81230,   inf] (61), [-0.81230,   inf] (59), [-0.81230,   inf] (59), [-0.81230,   inf] (57), [-0.81229,   inf] (59), [-0.81229,   inf] (57), [-0.81229,   inf] (57), [-0.81229,   inf] (59), [-0.81229,   inf] (59), [-0.81229,   inf] (49), 
length of domains: 13061
Total time: 1.5544	 pickout: 0.0597	 decision: 0.1578	 get_bound: 1.2748	 add_domain: 0.0620
Current lb:-0.8123053908348083
28144 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 72.38974499702454

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6092] [2, 150] [2, 117] [2, 167] [1, 7588] [1, 2082] [2, 150] [2, 150] [1, 3820] [1, 7588] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 360.32037353515625 with beta sum per layer: [0.0, 101.37205505371094, 19.4865779876709]
alpha/beta optimization time: 0.8173143863677979
This batch time : update_bounds func: 0.9525	 prepare: 0.0515	 bound: 0.8177	 transfer: 0.0491	 finalize: 0.0328
Accumulated time: update_bounds func: 57.7923	 prepare: 2.8712	 bound: 49.1751	 transfer: 0.0491	 finalize: 2.5116
batch bounding time:  0.953131914138794
Current worst splitting domains [lb, ub] (depth):
[-0.81189,   inf] (59), [-0.81189,   inf] (57), [-0.81188,   inf] (33), [-0.81188,   inf] (45), [-0.81188,   inf] (63), [-0.81188,   inf] (63), [-0.81188,   inf] (63), [-0.81188,   inf] (57), [-0.81188,   inf] (57), [-0.81188,   inf] (67), [-0.81188,   inf] (39), [-0.81187,   inf] (61), [-0.81187,   inf] (39), [-0.81187,   inf] (55), [-0.81187,   inf] (59), [-0.81187,   inf] (63), [-0.81187,   inf] (61), [-0.81187,   inf] (61), [-0.81186,   inf] (59), [-0.81186,   inf] (55), 
length of domains: 13311
Total time: 1.2280	 pickout: 0.0591	 decision: 0.1527	 get_bound: 0.9540	 add_domain: 0.0622
Current lb:-0.8118891716003418
28656 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 73.62388205528259

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 167] [2, 150] [2, 122] [1, 4893] [1, 3820] [2, 150] [1, 3820] [1, 6092] [1, 3236] [1, 4380] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 352.49310302734375 with beta sum per layer: [0.0, 94.7452392578125, 19.95911407470703]
alpha/beta optimization time: 0.8195347785949707
This batch time : update_bounds func: 0.9516	 prepare: 0.0505	 bound: 0.8199	 transfer: 0.0469	 finalize: 0.0324
Accumulated time: update_bounds func: 58.7440	 prepare: 2.9217	 bound: 49.9950	 transfer: 0.0469	 finalize: 2.5440
batch bounding time:  0.9522526264190674
Current worst splitting domains [lb, ub] (depth):
[-0.81144,   inf] (59), [-0.81144,   inf] (61), [-0.81144,   inf] (59), [-0.81143,   inf] (65), [-0.81143,   inf] (59), [-0.81143,   inf] (55), [-0.81143,   inf] (61), [-0.81143,   inf] (51), [-0.81142,   inf] (53), [-0.81142,   inf] (49), [-0.81142,   inf] (63), [-0.81142,   inf] (41), [-0.81141,   inf] (59), [-0.81141,   inf] (59), [-0.81141,   inf] (55), [-0.81141,   inf] (61), [-0.81140,   inf] (55), [-0.81140,   inf] (57), [-0.81140,   inf] (49), [-0.81140,   inf] (61), 
length of domains: 13559
Total time: 1.2280	 pickout: 0.0595	 decision: 0.1525	 get_bound: 0.9531	 add_domain: 0.0629
Current lb:-0.8114397525787354
29168 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Time out!!!!!!!!
Image 34 label 4 verification end, final lower bound -0.8114397525787354, upper bound inf, time: 75.1745400428772
34 -0.8114397525787354
Result: image 34 verification failure (with branch and bound).
Wall time: 91.05603337287903

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 0): []
verification failure idx (total 1): [34]
final verified acc: 0.0%[1]
verifier is called on 1 examples.
total verified: 0
mean time [cnt:1] (excluding attack success): 90.93413352966309
