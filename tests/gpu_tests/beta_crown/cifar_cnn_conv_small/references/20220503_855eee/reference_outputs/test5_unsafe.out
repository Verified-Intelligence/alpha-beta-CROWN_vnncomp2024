Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_conv_small_pgd.pth
  name: cifar_conv_small
data:
  start: 821
  end: 822
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR_ERAN
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.00784313725
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 2048
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 120
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 100
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:35:38 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2))
  (1): ReLU()
  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))
  (3): ReLU()
  (4): Flatten()
  (5): Linear(in_features=1152, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([1000, 3, 32, 32]) torch.Size([1000]) torch.Size([1000])
X range: tensor(2.7537) tensor(-2.4291) tensor(0.0238)
Note runnerup label is empty here!
############################
epsilon after preprocessing: tensor([[[[0.0388]],

         [[0.0393]],

         [[0.0390]]]]), data_max = tensor([[[[2.5141]],

         [[2.5968]],

         [[2.7537]]]]), data_min = tensor([[[[-2.4291]],

         [[-2.4183]],

         [[-2.2214]]]])
Task length: 1
saving results to Verified_ret_[cifar_conv_small]_start=821_end=822_iter=20_b=2048_timeout=120_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 821 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 2, correct label 2, image norm 2989.9375, logits tensor([ 2.4164, -8.7224,  5.2464,  2.9749,  1.7516,  2.7063, -1.2580,  4.0314,
        -0.5413, -5.8133], device='cuda:0', grad_fn=<SelectBackward>)
Model prediction is: tensor([[ 2.4164, -8.7224,  5.2464,  2.9749,  1.7516,  2.7063, -1.2580,  4.0314,
         -0.5413, -5.8133]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 5.9307e-01,  1.0321e+01,  9.3815e-02,  9.5626e-01, -3.1195e-03,
          4.3868e+00, -1.1800e+00,  3.2982e+00,  7.7150e+00]], device='cuda:0') None
best_l after optimization: -27.046972274780273 with beta sum per layer: []
alpha/beta optimization time: 7.382114887237549
initial alpha-CROWN bounds: tensor([[ 0.6814, 10.4272,  0.1657,  1.1005,  0.1084,  4.4400, -1.1072,  3.3871,
          7.8439]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-1.1072, device='cuda:0', grad_fn=<MinBackward1>)
##### [0:821] Tested against 7 ######
Model prediction is: tensor([[ 2.4164, -8.7224,  5.2464,  2.9749,  1.7516,  2.7063, -1.2580,  4.0314,
         -0.5413, -5.8133]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 15, 15]) != torch.Size([2, 9, 1, 16, 15, 15]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 6, 6]) != torch.Size([2, 9, 1, 32, 6, 6]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 15, 15])
1 /11 torch.Size([1, 32, 6, 6])
2 /21 torch.Size([1, 100])
best_l after optimization: 1.1071882247924805 with beta sum per layer: []
alpha/beta optimization time: 1.7727916240692139
alpha-CROWN with fixed intermediate bounds: tensor([[-1.1072]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-1.1071882247924805
layer 0 size torch.Size([3600]) unstable 427
layer 1 size torch.Size([1152]) unstable 129
layer 2 size torch.Size([100]) unstable 33
-----------------
# of unstable neurons: 589
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 15, 15]) pre split depth:  7
batch:  torch.Size([1, 16, 15, 15]) post split depth:  7
splitting decisions: 
split level 0: [2, 21] 
split level 1: [2, 12] 
split level 2: [2, 58] 
split level 3: [2, 15] 
split level 4: [2, 60] 
split level 5: [2, 54] 
split level 6: [2, 80] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -28.086326599121094 with beta sum per layer: [0.0, 0.0, 43.01276397705078]
alpha/beta optimization time: 0.2531418800354004
This batch time : update_bounds func: 0.2733	 prepare: 0.0098	 bound: 0.2534	 transfer: 0.0024	 finalize: 0.0073
Accumulated time: update_bounds func: 0.2733	 prepare: 0.0098	 bound: 0.2534	 transfer: 0.0024	 finalize: 0.0073
batch bounding time:  0.273500919342041
Current worst splitting domains [lb, ub] (depth):
[-0.49441,   inf] (8), [-0.43659,   inf] (8), [-0.38973,   inf] (8), [-0.36812,   inf] (8), [-0.34386,   inf] (8), [-0.27619,   inf] (8), [-0.27574,   inf] (8), [-0.25202,   inf] (8), [-0.21109,   inf] (8), [-0.16192,   inf] (8), [-0.14532,   inf] (8), [-0.11644,   inf] (8), [-0.09045,   inf] (8), [-0.08803,   inf] (8), [-0.04893,   inf] (8), [-0.03662,   inf] (8), [-0.03180,   inf] (8), 
length of domains: 17
Total time: 0.3323	 pickout: 0.0009	 decision: 0.0416	 get_bound: 0.2889	 add_domain: 0.0009
Current lb:-0.49441152811050415
128 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.9618968963623047

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([17, 16, 15, 15]) pre split depth:  3
batch:  torch.Size([17, 16, 15, 15]) post split depth:  3
splitting decisions: 
split level 0: [2, 85] [2, 85] [2, 85] [2, 85] [2, 85] [2, 85] [2, 85] [2, 85] [2, 85] [2, 85] 
split level 1: [2, 77] [2, 77] [1, 261] [2, 77] [1, 261] [1, 261] [1, 261] [1, 261] [1, 261] [1, 261] 
split level 2: [1, 815] [2, 49] [2, 77] [1, 815] [2, 77] [2, 77] [2, 77] [2, 77] [2, 77] [2, 77] 
regular batch size: 2*68, diving batch size 1*0
best_l after optimization: -7.984349250793457 with beta sum per layer: [0.0, 0.9630990028381348, 141.7741241455078]
alpha/beta optimization time: 0.2555816173553467
This batch time : update_bounds func: 0.2832	 prepare: 0.0129	 bound: 0.2559	 transfer: 0.0056	 finalize: 0.0084
Accumulated time: update_bounds func: 0.5565	 prepare: 0.0227	 bound: 0.5093	 transfer: 0.0056	 finalize: 0.0157
batch bounding time:  0.2837088108062744
Current worst splitting domains [lb, ub] (depth):
[-0.43604,   inf] (12), [-0.38893,   inf] (12), [-0.38559,   inf] (12), [-0.37445,   inf] (12), [-0.33680,   inf] (12), [-0.31547,   inf] (12), [-0.31236,   inf] (12), [-0.30815,   inf] (12), [-0.29557,   inf] (12), [-0.26628,   inf] (12), [-0.25994,   inf] (12), [-0.25236,   inf] (12), [-0.24577,   inf] (12), [-0.21615,   inf] (12), [-0.21171,   inf] (12), [-0.20057,   inf] (12), [-0.19352,   inf] (12), [-0.19048,   inf] (12), [-0.18305,   inf] (12), [-0.17797,   inf] (12), 
length of domains: 39
Total time: 0.3355	 pickout: 0.0032	 decision: 0.0335	 get_bound: 0.2968	 add_domain: 0.0021
Current lb:-0.4360436201095581
264 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.29818058013916

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([39, 16, 15, 15]) pre split depth:  2
batch:  torch.Size([39, 16, 15, 15]) post split depth:  2
splitting decisions: 
split level 0: [1, 261] [1, 261] [1, 261] [1, 261] [1, 261] [1, 261] [1, 798] [1, 261] [1, 798] [1, 798] 
split level 1: [1, 798] [2, 49] [1, 798] [1, 798] [2, 49] [2, 90] [2, 49] [2, 49] [2, 49] [2, 49] 
regular batch size: 2*78, diving batch size 1*0
best_l after optimization: -4.394867897033691 with beta sum per layer: [0.0, 3.788018226623535, 154.4075469970703]
alpha/beta optimization time: 0.26421403884887695
This batch time : update_bounds func: 0.2968	 prepare: 0.0158	 bound: 0.2645	 transfer: 0.0059	 finalize: 0.0101
Accumulated time: update_bounds func: 0.8533	 prepare: 0.0385	 bound: 0.7739	 transfer: 0.0059	 finalize: 0.0258
batch bounding time:  0.2971076965332031
Current worst splitting domains [lb, ub] (depth):
[-0.40018,   inf] (15), [-0.39362,   inf] (15), [-0.35250,   inf] (15), [-0.35013,   inf] (15), [-0.34379,   inf] (15), [-0.34245,   inf] (15), [-0.33775,   inf] (15), [-0.33733,   inf] (15), [-0.33376,   inf] (15), [-0.33281,   inf] (15), [-0.30032,   inf] (15), [-0.29372,   inf] (15), [-0.28609,   inf] (15), [-0.28427,   inf] (15), [-0.27980,   inf] (15), [-0.27873,   inf] (15), [-0.27598,   inf] (15), [-0.27508,   inf] (15), [-0.27114,   inf] (15), [-0.26627,   inf] (15), 
length of domains: 65
Total time: 0.3543	 pickout: 0.0064	 decision: 0.0361	 get_bound: 0.3080	 add_domain: 0.0038
Current lb:-0.4001847505569458
420 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.653498888015747

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([65, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([65, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 49] [2, 49] [1, 798] [2, 49] [2, 49] [2, 49] [1, 798] [2, 49] [2, 90] [2, 90] 
regular batch size: 2*65, diving batch size 1*0
best_l after optimization: 11.704361915588379 with beta sum per layer: [0.0, 8.269034385681152, 112.2966079711914]
alpha/beta optimization time: 0.27596378326416016
This batch time : update_bounds func: 0.3019	 prepare: 0.0135	 bound: 0.2763	 transfer: 0.0038	 finalize: 0.0079
Accumulated time: update_bounds func: 1.1552	 prepare: 0.0520	 bound: 1.0502	 transfer: 0.0038	 finalize: 0.0337
batch bounding time:  0.3021054267883301
Current worst splitting domains [lb, ub] (depth):
[-0.38710,   inf] (17), [-0.38016,   inf] (17), [-0.33776,   inf] (17), [-0.33715,   inf] (17), [-0.33021,   inf] (17), [-0.32906,   inf] (17), [-0.32325,   inf] (17), [-0.32314,   inf] (17), [-0.32298,   inf] (17), [-0.32204,   inf] (17), [-0.28561,   inf] (17), [-0.28064,   inf] (17), [-0.28029,   inf] (17), [-0.27234,   inf] (17), [-0.26992,   inf] (17), [-0.26764,   inf] (17), [-0.26587,   inf] (17), [-0.26466,   inf] (17), [-0.26384,   inf] (17), [-0.26325,   inf] (17), 
length of domains: 88
Total time: 0.3593	 pickout: 0.0103	 decision: 0.0415	 get_bound: 0.3023	 add_domain: 0.0052
Current lb:-0.38710036873817444
550 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.0139241218566895

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([88, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([88, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 29] [2, 29] [2, 29] [2, 29] [2, 29] [2, 29] [2, 90] [2, 29] [1, 384] [1, 384] 
regular batch size: 2*88, diving batch size 1*0
best_l after optimization: 13.903252601623535 with beta sum per layer: [0.0, 11.336386680603027, 152.50491333007812]
alpha/beta optimization time: 0.25987768173217773
This batch time : update_bounds func: 0.2939	 prepare: 0.0185	 bound: 0.2602	 transfer: 0.0042	 finalize: 0.0105
Accumulated time: update_bounds func: 1.4490	 prepare: 0.0705	 bound: 1.3104	 transfer: 0.0042	 finalize: 0.0442
batch bounding time:  0.2941873073577881
Current worst splitting domains [lb, ub] (depth):
[-0.37318,   inf] (19), [-0.36656,   inf] (19), [-0.35599,   inf] (19), [-0.34660,   inf] (19), [-0.32362,   inf] (19), [-0.32252,   inf] (19), [-0.31610,   inf] (19), [-0.31573,   inf] (19), [-0.31525,   inf] (19), [-0.31206,   inf] (19), [-0.31097,   inf] (19), [-0.30988,   inf] (19), [-0.30933,   inf] (19), [-0.30271,   inf] (19), [-0.29641,   inf] (19), [-0.29582,   inf] (19), [-0.29490,   inf] (19), [-0.29213,   inf] (19), [-0.28519,   inf] (19), [-0.27066,   inf] (19), 
length of domains: 116
Total time: 0.3576	 pickout: 0.0132	 decision: 0.0425	 get_bound: 0.2945	 add_domain: 0.0075
Current lb:-0.37318047881126404
726 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.373335838317871

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([116, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([116, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 384] [1, 384] [1, 384] [1, 384] [1, 384] [2, 90] [1, 384] [1, 384] [2, 90] [2, 42] 
regular batch size: 2*116, diving batch size 1*0
best_l after optimization: 23.93327522277832 with beta sum per layer: [0.0, 17.09920883178711, 182.34939575195312]
alpha/beta optimization time: 0.26368117332458496
This batch time : update_bounds func: 0.3089	 prepare: 0.0229	 bound: 0.2640	 transfer: 0.0079	 finalize: 0.0136
Accumulated time: update_bounds func: 1.7580	 prepare: 0.0934	 bound: 1.5744	 transfer: 0.0079	 finalize: 0.0578
batch bounding time:  0.30924510955810547
Current worst splitting domains [lb, ub] (depth):
[-0.36174,   inf] (21), [-0.35523,   inf] (21), [-0.35447,   inf] (21), [-0.34796,   inf] (21), [-0.34474,   inf] (21), [-0.33565,   inf] (21), [-0.33530,   inf] (21), [-0.32616,   inf] (21), [-0.31211,   inf] (21), [-0.31122,   inf] (21), [-0.30486,   inf] (21), [-0.30435,   inf] (21), [-0.30411,   inf] (21), [-0.30397,   inf] (21), [-0.30123,   inf] (21), [-0.29749,   inf] (21), [-0.29728,   inf] (21), [-0.29715,   inf] (21), [-0.29685,   inf] (21), [-0.29618,   inf] (21), 
length of domains: 176
Total time: 0.3914	 pickout: 0.0174	 decision: 0.0529	 get_bound: 0.3096	 add_domain: 0.0115
Current lb:-0.3617401421070099
958 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.7668235301971436

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([176, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([176, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 90] [2, 90] [2, 90] [2, 90] [2, 90] [2, 90] [2, 90] [2, 90] [2, 90] [2, 42] 
regular batch size: 2*176, diving batch size 1*0
best_l after optimization: 24.996627807617188 with beta sum per layer: [0.0, 29.21303939819336, 283.512451171875]
alpha/beta optimization time: 0.29074668884277344
This batch time : update_bounds func: 0.3571	 prepare: 0.0343	 bound: 0.2911	 transfer: 0.0102	 finalize: 0.0207
Accumulated time: update_bounds func: 2.1151	 prepare: 0.1277	 bound: 1.8654	 transfer: 0.0102	 finalize: 0.0785
batch bounding time:  0.3574972152709961
Current worst splitting domains [lb, ub] (depth):
[-0.35112,   inf] (23), [-0.34469,   inf] (23), [-0.34378,   inf] (23), [-0.33736,   inf] (23), [-0.33399,   inf] (23), [-0.32481,   inf] (23), [-0.32480,   inf] (23), [-0.31558,   inf] (23), [-0.30138,   inf] (23), [-0.30027,   inf] (23), [-0.29411,   inf] (23), [-0.29370,   inf] (23), [-0.29334,   inf] (23), [-0.29297,   inf] (23), [-0.28669,   inf] (23), [-0.28646,   inf] (23), [-0.28642,   inf] (23), [-0.28640,   inf] (23), [-0.28577,   inf] (23), [-0.28563,   inf] (23), 
length of domains: 246
Total time: 0.4703	 pickout: 0.0262	 decision: 0.0682	 get_bound: 0.3580	 add_domain: 0.0179
Current lb:-0.3511228561401367
1310 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.24040150642395

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([246, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([246, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 42] [2, 42] [2, 42] [2, 42] [2, 42] [2, 42] [2, 42] [2, 42] [2, 42] [1, 159] 
regular batch size: 2*246, diving batch size 1*0
best_l after optimization: 40.813777923583984 with beta sum per layer: [0.0, 48.574928283691406, 403.72784423828125]
alpha/beta optimization time: 0.33335447311401367
This batch time : update_bounds func: 0.4343	 prepare: 0.0475	 bound: 0.3337	 transfer: 0.0227	 finalize: 0.0293
Accumulated time: update_bounds func: 2.5494	 prepare: 0.1752	 bound: 2.1991	 transfer: 0.0227	 finalize: 0.1078
batch bounding time:  0.4348914623260498
Current worst splitting domains [lb, ub] (depth):
[-0.34060,   inf] (25), [-0.33443,   inf] (25), [-0.33329,   inf] (25), [-0.32714,   inf] (25), [-0.32359,   inf] (25), [-0.31460,   inf] (25), [-0.31443,   inf] (25), [-0.30538,   inf] (25), [-0.29220,   inf] (25), [-0.29093,   inf] (25), [-0.28456,   inf] (25), [-0.28362,   inf] (25), [-0.28353,   inf] (25), [-0.28177,   inf] (25), [-0.28002,   inf] (25), [-0.27917,   inf] (25), [-0.27727,   inf] (25), [-0.27630,   inf] (25), [-0.27565,   inf] (25), [-0.27460,   inf] (25), 
length of domains: 395
Total time: 0.6503	 pickout: 0.0348	 decision: 0.1511	 get_bound: 0.4356	 add_domain: 0.0288
Current lb:-0.34060317277908325
1802 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.8954079151153564

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([395, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([395, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 801] [1, 801] [1, 801] [1, 801] [1, 159] [1, 159] [1, 159] [1, 159] [1, 801] [1, 801] 
regular batch size: 2*395, diving batch size 1*0
best_l after optimization: 76.67488098144531 with beta sum per layer: [0.0, 101.3951416015625, 631.5015258789062]
alpha/beta optimization time: 0.43953537940979004
This batch time : update_bounds func: 0.5920	 prepare: 0.0759	 bound: 0.4399	 transfer: 0.0249	 finalize: 0.0493
Accumulated time: update_bounds func: 3.1414	 prepare: 0.2512	 bound: 2.6390	 transfer: 0.0249	 finalize: 0.1570
batch bounding time:  0.5928082466125488
Current worst splitting domains [lb, ub] (depth):
[-0.33469,   inf] (27), [-0.32775,   inf] (27), [-0.32737,   inf] (27), [-0.32045,   inf] (27), [-0.31569,   inf] (27), [-0.30646,   inf] (27), [-0.30611,   inf] (27), [-0.29683,   inf] (27), [-0.28893,   inf] (27), [-0.28712,   inf] (27), [-0.28653,   inf] (27), [-0.28488,   inf] (27), [-0.28472,   inf] (27), [-0.28353,   inf] (27), [-0.28010,   inf] (27), [-0.27982,   inf] (27), [-0.27940,   inf] (27), [-0.27757,   inf] (27), [-0.27671,   inf] (27), [-0.27641,   inf] (27), 
length of domains: 708
Total time: 0.8297	 pickout: 0.0568	 decision: 0.1262	 get_bound: 0.5940	 add_domain: 0.0528
Current lb:-0.3346864879131317
2592 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.731898307800293

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([708, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([708, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 159] [1, 159] [1, 159] [1, 159] [1, 801] [1, 801] [1, 801] [1, 801] [1, 801] [1, 159] 
regular batch size: 2*708, diving batch size 1*0
best_l after optimization: 116.57434844970703 with beta sum per layer: [0.11665160953998566, 237.58309936523438, 1089.815673828125]
alpha/beta optimization time: 0.6252322196960449
This batch time : update_bounds func: 0.9610	 prepare: 0.1413	 bound: 0.6257	 transfer: 0.0376	 finalize: 0.1529
Accumulated time: update_bounds func: 4.1025	 prepare: 0.3924	 bound: 3.2647	 transfer: 0.0376	 finalize: 0.3099
batch bounding time:  0.9626047611236572
Current worst splitting domains [lb, ub] (depth):
[-0.32856,   inf] (29), [-0.32123,   inf] (29), [-0.32090,   inf] (29), [-0.31356,   inf] (29), [-0.30920,   inf] (29), [-0.29991,   inf] (29), [-0.29965,   inf] (29), [-0.29499,   inf] (29), [-0.29275,   inf] (29), [-0.29026,   inf] (29), [-0.28761,   inf] (29), [-0.28545,   inf] (29), [-0.28099,   inf] (29), [-0.27916,   inf] (29), [-0.27807,   inf] (29), [-0.27786,   inf] (29), [-0.27637,   inf] (29), [-0.27485,   inf] (29), [-0.27190,   inf] (29), [-0.27186,   inf] (29), 
length of domains: 1223
Total time: 1.4403	 pickout: 0.1036	 decision: 0.2788	 get_bound: 0.9649	 add_domain: 0.0929
Current lb:-0.32855749130249023
4008 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.18421196937561

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1223, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1223, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 8] [2, 8] [2, 8] [2, 8] [1, 533] [1, 533] [1, 533] [2, 8] [2, 8] [1, 533] 
regular batch size: 2*1223, diving batch size 1*0
best_l after optimization: 144.28529357910156 with beta sum per layer: [0.5218616127967834, 481.5366516113281, 1841.099365234375]
alpha/beta optimization time: 0.975250244140625
This batch time : update_bounds func: 1.5038	 prepare: 0.2404	 bound: 0.9756	 transfer: 0.0690	 finalize: 0.2129
Accumulated time: update_bounds func: 5.6063	 prepare: 0.6329	 bound: 4.2403	 transfer: 0.0690	 finalize: 0.5228
batch bounding time:  1.5063867568969727
Current worst splitting domains [lb, ub] (depth):
[-0.32315,   inf] (31), [-0.31584,   inf] (31), [-0.31518,   inf] (31), [-0.30786,   inf] (31), [-0.29793,   inf] (31), [-0.29754,   inf] (31), [-0.28908,   inf] (31), [-0.28856,   inf] (31), [-0.28822,   inf] (31), [-0.28817,   inf] (31), [-0.28784,   inf] (31), [-0.28680,   inf] (31), [-0.28174,   inf] (31), [-0.27952,   inf] (31), [-0.27869,   inf] (31), [-0.27831,   inf] (31), [-0.27310,   inf] (31), [-0.27242,   inf] (31), [-0.27151,   inf] (31), [-0.26986,   inf] (31), 
length of domains: 1898
Total time: 2.2824	 pickout: 0.1934	 decision: 0.4222	 get_bound: 1.5108	 add_domain: 0.1560
Current lb:-0.32314538955688477
6454 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.490363836288452

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1898, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1898, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 611] [1, 611] [1, 611] [1, 611] [2, 8] [2, 8] [1, 611] [2, 8] [2, 8] [2, 8] 
regular batch size: 2*1898, diving batch size 1*0
best_l after optimization: 180.92318725585938 with beta sum per layer: [1.9541689157485962, 844.8438720703125, 2801.64794921875]
alpha/beta optimization time: 1.4878199100494385
This batch time : update_bounds func: 2.3361	 prepare: 0.3792	 bound: 1.4882	 transfer: 0.1015	 finalize: 0.2979
Accumulated time: update_bounds func: 7.9423	 prepare: 1.0120	 bound: 5.7286	 transfer: 0.1015	 finalize: 0.8208
batch bounding time:  2.339904546737671
Current worst splitting domains [lb, ub] (depth):
[-0.31827,   inf] (33), [-0.31096,   inf] (33), [-0.31030,   inf] (33), [-0.30299,   inf] (33), [-0.30230,   inf] (33), [-0.29506,   inf] (33), [-0.29432,   inf] (33), [-0.29237,   inf] (33), [-0.29202,   inf] (33), [-0.28705,   inf] (33), [-0.28414,   inf] (33), [-0.28307,   inf] (33), [-0.28272,   inf] (33), [-0.28241,   inf] (33), [-0.28205,   inf] (33), [-0.28190,   inf] (33), [-0.27687,   inf] (33), [-0.27460,   inf] (33), [-0.27293,   inf] (33), [-0.27260,   inf] (33), 
length of domains: 2842
Total time: 3.5245	 pickout: 0.3248	 decision: 0.6135	 get_bound: 2.3460	 add_domain: 0.2402
Current lb:-0.31827354431152344
10250 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.061143159866333

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 154] [1, 154] [0, 2615] [0, 2615] [1, 154] [1, 154] [0, 2615] [1, 299] [1, 1097] [0, 2615] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 248.85366821289062 with beta sum per layer: [2.867600440979004, 968.94287109375, 2685.3408203125]
alpha/beta optimization time: 1.5838062763214111
This batch time : update_bounds func: 2.4703	 prepare: 0.4075	 bound: 1.5843	 transfer: 0.1105	 finalize: 0.3572
Accumulated time: update_bounds func: 10.4126	 prepare: 1.4195	 bound: 7.3128	 transfer: 0.1105	 finalize: 1.1780
batch bounding time:  2.4739062786102295
Current worst splitting domains [lb, ub] (depth):
[-0.31444,   inf] (35), [-0.30713,   inf] (35), [-0.30553,   inf] (35), [-0.29883,   inf] (35), [-0.29844,   inf] (35), [-0.29822,   inf] (35), [-0.29152,   inf] (35), [-0.29115,   inf] (35), [-0.28951,   inf] (35), [-0.28635,   inf] (35), [-0.28462,   inf] (35), [-0.28279,   inf] (35), [-0.28227,   inf] (35), [-0.27920,   inf] (35), [-0.27789,   inf] (35), [-0.27739,   inf] (35), [-0.27703,   inf] (35), [-0.27556,   inf] (35), [-0.27457,   inf] (35), [-0.27424,   inf] (35), 
length of domains: 4110
Total time: 3.9702	 pickout: 0.3218	 decision: 0.7692	 get_bound: 2.4817	 add_domain: 0.3976
Current lb:-0.31444215774536133
14346 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.072873830795288

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 1097] [1, 1097] [0, 1954] [0, 1954] [1, 1097] [0, 1954] [0, 1954] [1, 1097] [0, 1954] [1, 299] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 388.71160888671875 with beta sum per layer: [2.558516025543213, 984.4813232421875, 2099.33056640625]
alpha/beta optimization time: 1.5774450302124023
This batch time : update_bounds func: 2.4600	 prepare: 0.4096	 bound: 1.5778	 transfer: 0.1124	 finalize: 0.3491
Accumulated time: update_bounds func: 12.8726	 prepare: 1.8291	 bound: 8.8907	 transfer: 0.1124	 finalize: 1.5271
batch bounding time:  2.464064359664917
Current worst splitting domains [lb, ub] (depth):
[-0.30927,   inf] (37), [-0.30196,   inf] (37), [-0.30013,   inf] (37), [-0.29950,   inf] (37), [-0.29433,   inf] (37), [-0.29386,   inf] (37), [-0.29321,   inf] (37), [-0.29287,   inf] (37), [-0.29148,   inf] (37), [-0.28805,   inf] (37), [-0.28598,   inf] (37), [-0.28484,   inf] (37), [-0.28407,   inf] (37), [-0.28343,   inf] (37), [-0.27896,   inf] (37), [-0.27862,   inf] (37), [-0.27824,   inf] (37), [-0.27778,   inf] (37), [-0.27679,   inf] (37), [-0.27551,   inf] (37), 
length of domains: 5745
Total time: 3.9534	 pickout: 0.3312	 decision: 0.6921	 get_bound: 2.4718	 add_domain: 0.4583
Current lb:-0.3092684745788574
18442 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 22.06575107574463

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 341] [1, 341] [0, 1013] [0, 1013] [0, 1013] [0, 1013] [1, 341] [0, 1013] [0, 1013] [0, 1013] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 558.247802734375 with beta sum per layer: [2.4481441974639893, 991.97705078125, 1341.519775390625]
alpha/beta optimization time: 1.5887291431427002
This batch time : update_bounds func: 2.5369	 prepare: 0.4147	 bound: 1.5892	 transfer: 0.1176	 finalize: 0.4042
Accumulated time: update_bounds func: 15.4095	 prepare: 2.2438	 bound: 10.4799	 transfer: 0.1176	 finalize: 1.9313
batch bounding time:  2.540912389755249
Current worst splitting domains [lb, ub] (depth):
[-0.30203,   inf] (39), [-0.29594,   inf] (39), [-0.29532,   inf] (39), [-0.29472,   inf] (39), [-0.29271,   inf] (39), [-0.29209,   inf] (39), [-0.29014,   inf] (39), [-0.28969,   inf] (39), [-0.28869,   inf] (39), [-0.28731,   inf] (39), [-0.28700,   inf] (39), [-0.28693,   inf] (39), [-0.28647,   inf] (39), [-0.28592,   inf] (39), [-0.28548,   inf] (39), [-0.28409,   inf] (39), [-0.28387,   inf] (39), [-0.28066,   inf] (39), [-0.28066,   inf] (39), [-0.27986,   inf] (39), 
length of domains: 7750
Total time: 4.1560	 pickout: 0.3262	 decision: 0.7299	 get_bound: 2.5479	 add_domain: 0.5521
Current lb:-0.30202770233154297
22538 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 26.259552001953125

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 108] [1, 154] [1, 154] [1, 108] [1, 154] [1, 154] [1, 154] [1, 154] [1, 154] [1, 154] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 642.9747924804688 with beta sum per layer: [8.76494026184082, 994.3612060546875, 902.609375]
alpha/beta optimization time: 1.573883295059204
This batch time : update_bounds func: 2.6512	 prepare: 0.4157	 bound: 1.5744	 transfer: 0.1166	 finalize: 0.5336
Accumulated time: update_bounds func: 18.0607	 prepare: 2.6595	 bound: 12.0543	 transfer: 0.1166	 finalize: 2.4649
batch bounding time:  2.656221389770508
Current worst splitting domains [lb, ub] (depth):
[-0.29965,   inf] (41), [-0.29291,   inf] (41), [-0.29234,   inf] (41), [-0.29229,   inf] (41), [-0.28970,   inf] (41), [-0.28908,   inf] (41), [-0.28712,   inf] (41), [-0.28667,   inf] (41), [-0.28567,   inf] (41), [-0.28457,   inf] (41), [-0.28428,   inf] (41), [-0.28393,   inf] (41), [-0.28350,   inf] (41), [-0.28348,   inf] (41), [-0.28248,   inf] (41), [-0.28110,   inf] (41), [-0.28086,   inf] (41), [-0.27766,   inf] (41), [-0.27766,   inf] (41), [-0.27727,   inf] (41), 
length of domains: 9782
Total time: 4.1952	 pickout: 0.3560	 decision: 0.7745	 get_bound: 2.6645	 add_domain: 0.4002
Current lb:-0.29964637756347656
26634 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 30.49515390396118

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 299] [1, 1097] [1, 299] [1, 1097] [1, 1097] [1, 1097] [1, 1097] [1, 1097] [1, 1097] [1, 299] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 699.4496459960938 with beta sum per layer: [16.96718978881836, 962.16015625, 671.4805908203125]
alpha/beta optimization time: 1.5742461681365967
This batch time : update_bounds func: 2.5903	 prepare: 0.4287	 bound: 1.5747	 transfer: 0.1172	 finalize: 0.2492
Accumulated time: update_bounds func: 20.6510	 prepare: 3.0882	 bound: 13.6290	 transfer: 0.1172	 finalize: 2.7141
batch bounding time:  2.5944950580596924
Current worst splitting domains [lb, ub] (depth):
[-0.29244,   inf] (43), [-0.28764,   inf] (43), [-0.28702,   inf] (43), [-0.28513,   inf] (43), [-0.28444,   inf] (43), [-0.28382,   inf] (43), [-0.28185,   inf] (43), [-0.28175,   inf] (43), [-0.28141,   inf] (43), [-0.28041,   inf] (43), [-0.27903,   inf] (43), [-0.27867,   inf] (43), [-0.27823,   inf] (43), [-0.27723,   inf] (43), [-0.27647,   inf] (43), [-0.27627,   inf] (43), [-0.27584,   inf] (43), [-0.27560,   inf] (43), [-0.27454,   inf] (43), [-0.27242,   inf] (43), 
length of domains: 11830
Total time: 4.4378	 pickout: 0.3601	 decision: 0.8105	 get_bound: 2.6012	 add_domain: 0.6660
Current lb:-0.29243990778923035
30730 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 34.97297286987305

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 533] [1, 341] [1, 341] [1, 533] [1, 341] [1, 341] [1, 341] [1, 533] [1, 341] [1, 341] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 735.51611328125 with beta sum per layer: [20.889705657958984, 893.0970458984375, 542.5966796875]
alpha/beta optimization time: 1.5721213817596436
This batch time : update_bounds func: 2.3832	 prepare: 0.4298	 bound: 1.5727	 transfer: 0.1173	 finalize: 0.2517
Accumulated time: update_bounds func: 23.0342	 prepare: 3.5179	 bound: 15.2017	 transfer: 0.1173	 finalize: 2.9657
batch bounding time:  2.3869972229003906
Current worst splitting domains [lb, ub] (depth):
[-0.28352,   inf] (45), [-0.28276,   inf] (45), [-0.28042,   inf] (45), [-0.27980,   inf] (45), [-0.27720,   inf] (45), [-0.27658,   inf] (45), [-0.27621,   inf] (45), [-0.27546,   inf] (45), [-0.27463,   inf] (45), [-0.27418,   inf] (45), [-0.27318,   inf] (45), [-0.27284,   inf] (45), [-0.27210,   inf] (45), [-0.27180,   inf] (45), [-0.27143,   inf] (45), [-0.27098,   inf] (45), [-0.26998,   inf] (45), [-0.26860,   inf] (45), [-0.26837,   inf] (45), [-0.26764,   inf] (45), 
length of domains: 13878
Total time: 4.2732	 pickout: 0.3334	 decision: 0.8380	 get_bound: 2.3934	 add_domain: 0.7084
Current lb:-0.28351646661758423
34826 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 39.29062628746033

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [0, 2615] [0, 2615] [1, 108] [1, 108] [1, 299] [1, 108] [0, 2615] [0, 2615] [1, 108] [1, 108] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 764.748291015625 with beta sum per layer: [30.54319190979004, 844.0872802734375, 401.360595703125]
alpha/beta optimization time: 1.5644145011901855
This batch time : update_bounds func: 2.7072	 prepare: 0.4303	 bound: 1.5648	 transfer: 0.1178	 finalize: 0.5828
Accumulated time: update_bounds func: 25.7413	 prepare: 3.9482	 bound: 16.7665	 transfer: 0.1178	 finalize: 3.5486
batch bounding time:  2.7115566730499268
Current worst splitting domains [lb, ub] (depth):
[-0.27874,   inf] (47), [-0.27801,   inf] (47), [-0.27798,   inf] (47), [-0.27739,   inf] (47), [-0.27416,   inf] (47), [-0.27221,   inf] (47), [-0.27203,   inf] (47), [-0.27176,   inf] (47), [-0.27144,   inf] (47), [-0.27127,   inf] (47), [-0.27076,   inf] (47), [-0.27069,   inf] (47), [-0.26990,   inf] (47), [-0.26940,   inf] (47), [-0.26902,   inf] (47), [-0.26857,   inf] (47), [-0.26808,   inf] (47), [-0.26756,   inf] (47), [-0.26734,   inf] (47), [-0.26619,   inf] (47), 
length of domains: 15926
Total time: 4.0838	 pickout: 0.3324	 decision: 0.6031	 get_bound: 2.7186	 add_domain: 0.4296
Current lb:-0.27874112129211426
38922 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 43.415727376937866

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 479] [1, 299] [1, 479] [1, 299] [1, 299] [1, 299] [1, 479] [1, 299] [1, 479] [1, 479] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 721.6317749023438 with beta sum per layer: [45.805580139160156, 935.517578125, 297.9815979003906]
alpha/beta optimization time: 1.565847635269165
This batch time : update_bounds func: 2.6950	 prepare: 0.4362	 bound: 1.5662	 transfer: 0.1162	 finalize: 0.5653
Accumulated time: update_bounds func: 28.4363	 prepare: 4.3844	 bound: 18.3328	 transfer: 0.1162	 finalize: 4.1138
batch bounding time:  2.6986193656921387
Current worst splitting domains [lb, ub] (depth):
[-0.27542,   inf] (49), [-0.27466,   inf] (49), [-0.27071,   inf] (49), [-0.27011,   inf] (49), [-0.26871,   inf] (49), [-0.26811,   inf] (49), [-0.26795,   inf] (49), [-0.26746,   inf] (49), [-0.26735,   inf] (49), [-0.26687,   inf] (49), [-0.26498,   inf] (49), [-0.26453,   inf] (49), [-0.26399,   inf] (49), [-0.26353,   inf] (49), [-0.26323,   inf] (49), [-0.26216,   inf] (49), [-0.26176,   inf] (49), [-0.26141,   inf] (49), [-0.26131,   inf] (49), [-0.26065,   inf] (49), 
length of domains: 17974
Total time: 4.3963	 pickout: 0.3343	 decision: 0.8958	 get_bound: 2.7053	 add_domain: 0.4608
Current lb:-0.27541667222976685
43018 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 47.85324478149414

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 1091] [1, 1091] [1, 533] [1, 533] [1, 1091] [1, 1091] [1, 1091] [1, 533] [1, 1091] [1, 533] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 768.1265258789062 with beta sum per layer: [42.31867599487305, 814.747802734375, 290.52630615234375]
alpha/beta optimization time: 1.5709152221679688
This batch time : update_bounds func: 2.3949	 prepare: 0.4419	 bound: 1.5713	 transfer: 0.1179	 finalize: 0.2525
Accumulated time: update_bounds func: 30.8312	 prepare: 4.8263	 bound: 19.9041	 transfer: 0.1179	 finalize: 4.3664
batch bounding time:  2.399088144302368
Current worst splitting domains [lb, ub] (depth):
[-0.27074,   inf] (51), [-0.26998,   inf] (51), [-0.26405,   inf] (51), [-0.26344,   inf] (51), [-0.26328,   inf] (51), [-0.26269,   inf] (51), [-0.26180,   inf] (51), [-0.26119,   inf] (51), [-0.26113,   inf] (51), [-0.26051,   inf] (51), [-0.25945,   inf] (51), [-0.25870,   inf] (51), [-0.25856,   inf] (51), [-0.25796,   inf] (51), [-0.25788,   inf] (51), [-0.25727,   inf] (51), [-0.25674,   inf] (51), [-0.25636,   inf] (51), [-0.25605,   inf] (51), [-0.25599,   inf] (51), 
length of domains: 20022
Total time: 4.1599	 pickout: 0.3408	 decision: 0.9591	 get_bound: 2.4058	 add_domain: 0.4542
Current lb:-0.27074432373046875
47114 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 52.05842590332031

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 763] [1, 763] [1, 763] [1, 763] [1, 763] [1, 763] [1, 479] [1, 479] [1, 479] [1, 479] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 780.55859375 with beta sum per layer: [41.05413055419922, 807.593505859375, 234.0580596923828]
alpha/beta optimization time: 1.5692534446716309
This batch time : update_bounds func: 2.8643	 prepare: 0.4835	 bound: 1.5698	 transfer: 0.1162	 finalize: 0.6833
Accumulated time: update_bounds func: 33.6955	 prepare: 5.3098	 bound: 21.4739	 transfer: 0.1162	 finalize: 5.0496
batch bounding time:  2.8687777519226074
Current worst splitting domains [lb, ub] (depth):
[-0.26505,   inf] (53), [-0.26429,   inf] (53), [-0.25852,   inf] (53), [-0.25836,   inf] (53), [-0.25791,   inf] (53), [-0.25785,   inf] (53), [-0.25775,   inf] (53), [-0.25760,   inf] (53), [-0.25723,   inf] (53), [-0.25699,   inf] (53), [-0.25555,   inf] (53), [-0.25529,   inf] (53), [-0.25479,   inf] (53), [-0.25468,   inf] (53), [-0.25461,   inf] (53), [-0.25399,   inf] (53), [-0.25292,   inf] (53), [-0.25278,   inf] (53), [-0.25252,   inf] (53), [-0.25234,   inf] (53), 
length of domains: 22070
Total time: 4.6645	 pickout: 0.3375	 decision: 0.9847	 get_bound: 2.8758	 add_domain: 0.4665
Current lb:-0.2650543451309204
51210 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 56.77125883102417

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 396] [1, 396] [1, 1091] [1, 396] [1, 1091] [1, 1091] [1, 396] [1, 396] [1, 1091] [1, 396] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 751.9500732421875 with beta sum per layer: [53.79714584350586, 912.3251953125, 196.89524841308594]
alpha/beta optimization time: 1.5734367370605469
This batch time : update_bounds func: 2.9176	 prepare: 0.4481	 bound: 1.5739	 transfer: 0.1202	 finalize: 0.7640
Accumulated time: update_bounds func: 36.6131	 prepare: 5.7579	 bound: 23.0478	 transfer: 0.1202	 finalize: 5.8137
batch bounding time:  2.9217374324798584
Current worst splitting domains [lb, ub] (depth):
[-0.26218,   inf] (55), [-0.26142,   inf] (55), [-0.25550,   inf] (55), [-0.25488,   inf] (55), [-0.25473,   inf] (55), [-0.25413,   inf] (55), [-0.25383,   inf] (55), [-0.25322,   inf] (55), [-0.25315,   inf] (55), [-0.25252,   inf] (55), [-0.25060,   inf] (55), [-0.25000,   inf] (55), [-0.24999,   inf] (55), [-0.24991,   inf] (55), [-0.24989,   inf] (55), [-0.24930,   inf] (55), [-0.24923,   inf] (55), [-0.24912,   inf] (55), [-0.24820,   inf] (55), [-0.24807,   inf] (55), 
length of domains: 24118
Total time: 4.3645	 pickout: 0.3420	 decision: 0.6097	 get_bound: 2.9287	 add_domain: 0.4841
Current lb:-0.26218461990356445
55306 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 61.17999887466431

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 723] [1, 723] [1, 723] [1, 723] [1, 723] [1, 723] [1, 763] [1, 763] [1, 763] [1, 763] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 769.7256469726562 with beta sum per layer: [52.191463470458984, 864.2130737304688, 184.4237060546875]
alpha/beta optimization time: 1.574843406677246
This batch time : update_bounds func: 2.4390	 prepare: 0.4684	 bound: 1.5753	 transfer: 0.1181	 finalize: 0.2652
Accumulated time: update_bounds func: 39.0520	 prepare: 6.2263	 bound: 24.6231	 transfer: 0.1181	 finalize: 6.0789
batch bounding time:  2.4434006214141846
Current worst splitting domains [lb, ub] (depth):
[-0.25466,   inf] (57), [-0.25394,   inf] (57), [-0.25389,   inf] (57), [-0.25317,   inf] (57), [-0.24823,   inf] (57), [-0.24797,   inf] (57), [-0.24762,   inf] (57), [-0.24752,   inf] (57), [-0.24735,   inf] (57), [-0.24724,   inf] (57), [-0.24720,   inf] (57), [-0.24704,   inf] (57), [-0.24689,   inf] (57), [-0.24663,   inf] (57), [-0.24659,   inf] (57), [-0.24648,   inf] (57), [-0.24627,   inf] (57), [-0.24587,   inf] (57), [-0.24501,   inf] (57), [-0.24440,   inf] (57), 
length of domains: 26166
Total time: 4.4697	 pickout: 0.3453	 decision: 1.1653	 get_bound: 2.4510	 add_domain: 0.5081
Current lb:-0.25466060638427734
59402 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 65.70049095153809

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 444] [1, 444] [1, 444] [1, 444] [1, 396] [1, 444] [1, 396] [1, 396] [1, 444] [1, 444] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 773.2608642578125 with beta sum per layer: [29.30582046508789, 823.7914428710938, 176.54669189453125]
alpha/beta optimization time: 1.5691320896148682
This batch time : update_bounds func: 2.4261	 prepare: 0.4559	 bound: 1.5696	 transfer: 0.1171	 finalize: 0.2724
Accumulated time: update_bounds func: 41.4782	 prepare: 6.6822	 bound: 26.1927	 transfer: 0.1171	 finalize: 6.3513
batch bounding time:  2.4303879737854004
Current worst splitting domains [lb, ub] (depth):
[-0.25179,   inf] (59), [-0.25106,   inf] (59), [-0.25102,   inf] (59), [-0.25030,   inf] (59), [-0.24543,   inf] (59), [-0.24508,   inf] (59), [-0.24479,   inf] (59), [-0.24465,   inf] (59), [-0.24450,   inf] (59), [-0.24436,   inf] (59), [-0.24432,   inf] (59), [-0.24400,   inf] (59), [-0.24378,   inf] (59), [-0.24374,   inf] (59), [-0.24360,   inf] (59), [-0.24302,   inf] (59), [-0.24222,   inf] (59), [-0.24161,   inf] (59), [-0.24149,   inf] (59), [-0.24084,   inf] (59), 
length of domains: 28214
Total time: 4.6074	 pickout: 0.3577	 decision: 1.2884	 get_bound: 2.4378	 add_domain: 0.5235
Current lb:-0.251785010099411
63498 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 70.36641049385071

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [0, 1954] [0, 1954] [0, 1954] [0, 1954] [1, 723] [0, 1954] [1, 723] [1, 723] [0, 1954] [0, 1954] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 774.3648071289062 with beta sum per layer: [25.792400360107422, 710.2950439453125, 172.17449951171875]
alpha/beta optimization time: 1.5652358531951904
This batch time : update_bounds func: 2.4186	 prepare: 0.4570	 bound: 1.5657	 transfer: 0.1170	 finalize: 0.2671
Accumulated time: update_bounds func: 43.8968	 prepare: 7.1392	 bound: 27.7584	 transfer: 0.1170	 finalize: 6.6184
batch bounding time:  2.422795295715332
Current worst splitting domains [lb, ub] (depth):
[-0.24640,   inf] (61), [-0.24577,   inf] (61), [-0.24568,   inf] (61), [-0.24564,   inf] (61), [-0.24504,   inf] (61), [-0.24500,   inf] (61), [-0.24492,   inf] (61), [-0.24428,   inf] (61), [-0.24062,   inf] (61), [-0.24013,   inf] (61), [-0.23989,   inf] (61), [-0.23985,   inf] (61), [-0.23941,   inf] (61), [-0.23937,   inf] (61), [-0.23913,   inf] (61), [-0.23912,   inf] (61), [-0.23903,   inf] (61), [-0.23865,   inf] (61), [-0.23840,   inf] (61), [-0.23837,   inf] (61), 
length of domains: 30262
Total time: 4.4947	 pickout: 0.3445	 decision: 1.2020	 get_bound: 2.4297	 add_domain: 0.5185
Current lb:-0.24640130996704102
67594 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 74.92132925987244

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 329] [1, 329] [1, 329] [1, 329] [1, 329] [1, 329] [1, 329] [1, 329] [1, 329] [1, 329] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 787.8558349609375 with beta sum per layer: [15.164474487304688, 619.304443359375, 155.62924194335938]
alpha/beta optimization time: 1.5616955757141113
This batch time : update_bounds func: 2.4308	 prepare: 0.4700	 bound: 1.5621	 transfer: 0.1181	 finalize: 0.2679
Accumulated time: update_bounds func: 46.3276	 prepare: 7.6092	 bound: 29.3205	 transfer: 0.1181	 finalize: 6.8863
batch bounding time:  2.4349851608276367
Current worst splitting domains [lb, ub] (depth):
[-0.24139,   inf] (63), [-0.24076,   inf] (63), [-0.24069,   inf] (63), [-0.24063,   inf] (63), [-0.24005,   inf] (63), [-0.23999,   inf] (63), [-0.23992,   inf] (63), [-0.23929,   inf] (63), [-0.23610,   inf] (63), [-0.23561,   inf] (63), [-0.23557,   inf] (63), [-0.23545,   inf] (63), [-0.23533,   inf] (63), [-0.23512,   inf] (63), [-0.23494,   inf] (63), [-0.23490,   inf] (63), [-0.23484,   inf] (63), [-0.23482,   inf] (63), [-0.23476,   inf] (63), [-0.23470,   inf] (63), 
length of domains: 32310
Total time: 4.5852	 pickout: 0.3444	 decision: 1.2606	 get_bound: 2.4423	 add_domain: 0.5379
Current lb:-0.24139165878295898
71690 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 79.5571801662445

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 684] [1, 684] [1, 684] [1, 684] [1, 684] [1, 684] [1, 684] [1, 684] [1, 684] [1, 684] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 793.983154296875 with beta sum per layer: [11.983721733093262, 579.1481323242188, 94.18829345703125]
alpha/beta optimization time: 1.5610201358795166
This batch time : update_bounds func: 2.4006	 prepare: 0.4588	 bound: 1.5614	 transfer: 0.1164	 finalize: 0.2521
Accumulated time: update_bounds func: 48.7281	 prepare: 8.0680	 bound: 30.8819	 transfer: 0.1164	 finalize: 7.1384
batch bounding time:  2.404184579849243
Current worst splitting domains [lb, ub] (depth):
[-0.23595,   inf] (65), [-0.23532,   inf] (65), [-0.23525,   inf] (65), [-0.23519,   inf] (65), [-0.23461,   inf] (65), [-0.23455,   inf] (65), [-0.23448,   inf] (65), [-0.23385,   inf] (65), [-0.23315,   inf] (65), [-0.23252,   inf] (65), [-0.23245,   inf] (65), [-0.23239,   inf] (65), [-0.23182,   inf] (65), [-0.23176,   inf] (65), [-0.23168,   inf] (65), [-0.23105,   inf] (65), [-0.23064,   inf] (65), [-0.23043,   inf] (65), [-0.23032,   inf] (65), [-0.23017,   inf] (65), 
length of domains: 34358
Total time: 4.5628	 pickout: 0.3450	 decision: 1.2725	 get_bound: 2.4108	 add_domain: 0.5345
Current lb:-0.23595333099365234
75786 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 84.17369532585144

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 44] [2, 44] [2, 44] [2, 44] [2, 44] [2, 44] [2, 44] [2, 44] [2, 44] [2, 44] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 740.0668334960938 with beta sum per layer: [8.97439193725586, 491.87872314453125, 543.5857543945312]
alpha/beta optimization time: 1.5824456214904785
This batch time : update_bounds func: 2.4367	 prepare: 0.4605	 bound: 1.5829	 transfer: 0.1180	 finalize: 0.2628
Accumulated time: update_bounds func: 51.1649	 prepare: 8.5284	 bound: 32.4648	 transfer: 0.1180	 finalize: 7.4012
batch bounding time:  2.4405906200408936
Current worst splitting domains [lb, ub] (depth):
[-0.23096,   inf] (67), [-0.23033,   inf] (67), [-0.23027,   inf] (67), [-0.23020,   inf] (67), [-0.22964,   inf] (67), [-0.22956,   inf] (67), [-0.22950,   inf] (67), [-0.22887,   inf] (67), [-0.22812,   inf] (67), [-0.22749,   inf] (67), [-0.22743,   inf] (67), [-0.22736,   inf] (67), [-0.22680,   inf] (67), [-0.22673,   inf] (67), [-0.22667,   inf] (67), [-0.22604,   inf] (67), [-0.22563,   inf] (67), [-0.22522,   inf] (67), [-0.22516,   inf] (67), [-0.22499,   inf] (67), 
length of domains: 36406
Total time: 4.6977	 pickout: 0.3453	 decision: 1.3512	 get_bound: 2.4478	 add_domain: 0.5533
Current lb:-0.23095703125
79882 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 88.92661380767822

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 1075] [1, 1075] [1, 1075] [1, 1075] [1, 1075] [1, 1075] [1, 1075] [1, 1075] [1, 1075] [1, 1075] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 679.0740356445312 with beta sum per layer: [28.68114471435547, 538.145751953125, 809.513427734375]
alpha/beta optimization time: 1.5940206050872803
This batch time : update_bounds func: 3.1736	 prepare: 0.4647	 bound: 1.5945	 transfer: 0.1161	 finalize: 0.2647
Accumulated time: update_bounds func: 54.3385	 prepare: 8.9931	 bound: 34.0592	 transfer: 0.1161	 finalize: 7.6659
batch bounding time:  3.1781466007232666
Current worst splitting domains [lb, ub] (depth):
[-0.22701,   inf] (69), [-0.22644,   inf] (69), [-0.22631,   inf] (69), [-0.22624,   inf] (69), [-0.22574,   inf] (69), [-0.22567,   inf] (69), [-0.22555,   inf] (69), [-0.22498,   inf] (69), [-0.22414,   inf] (69), [-0.22357,   inf] (69), [-0.22345,   inf] (69), [-0.22337,   inf] (69), [-0.22288,   inf] (69), [-0.22280,   inf] (69), [-0.22268,   inf] (69), [-0.22212,   inf] (69), [-0.22153,   inf] (69), [-0.22121,   inf] (69), [-0.22083,   inf] (69), [-0.22076,   inf] (69), 
length of domains: 38454
Total time: 4.7377	 pickout: 0.3492	 decision: 0.6167	 get_bound: 3.1857	 add_domain: 0.5860
Current lb:-0.2270050048828125
83978 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 93.72135925292969

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [0, 1940] [0, 1940] [0, 1940] [0, 1940] [0, 1940] [0, 1940] [0, 1940] [0, 1940] [0, 1940] [0, 1940] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 725.8856811523438 with beta sum per layer: [21.158784866333008, 569.0052490234375, 356.9161376953125]
alpha/beta optimization time: 1.5782575607299805
This batch time : update_bounds func: 3.2484	 prepare: 0.4614	 bound: 1.5787	 transfer: 0.1176	 finalize: 1.0791
Accumulated time: update_bounds func: 57.5869	 prepare: 9.4545	 bound: 35.6379	 transfer: 0.1176	 finalize: 8.7450
batch bounding time:  3.252620220184326
Current worst splitting domains [lb, ub] (depth):
[-0.22355,   inf] (71), [-0.22287,   inf] (71), [-0.22280,   inf] (71), [-0.22210,   inf] (71), [-0.22190,   inf] (71), [-0.22121,   inf] (71), [-0.22114,   inf] (71), [-0.22099,   inf] (71), [-0.22070,   inf] (71), [-0.22068,   inf] (71), [-0.22044,   inf] (71), [-0.22030,   inf] (71), [-0.22023,   inf] (71), [-0.22001,   inf] (71), [-0.21999,   inf] (71), [-0.21994,   inf] (71), [-0.21993,   inf] (71), [-0.21953,   inf] (71), [-0.21925,   inf] (71), [-0.21923,   inf] (71), 
length of domains: 40473
Total time: 4.8051	 pickout: 0.3557	 decision: 0.6175	 get_bound: 3.2601	 add_domain: 0.5718
Current lb:-0.22355413436889648
88074 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 98.57878613471985

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [0, 1013] [0, 1013] [0, 1013] [0, 1013] [0, 1013] [0, 1013] [0, 1013] [0, 1013] [0, 1013] [0, 1013] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 764.380126953125 with beta sum per layer: [20.510433197021484, 438.84857177734375, 165.49423217773438]
alpha/beta optimization time: 1.5623345375061035
This batch time : update_bounds func: 2.4123	 prepare: 0.4592	 bound: 1.5628	 transfer: 0.1172	 finalize: 0.2615
Accumulated time: update_bounds func: 59.9991	 prepare: 9.9137	 bound: 37.2007	 transfer: 0.1172	 finalize: 9.0064
batch bounding time:  2.4162158966064453
Current worst splitting domains [lb, ub] (depth):
[-0.21933,   inf] (73), [-0.21864,   inf] (73), [-0.21858,   inf] (73), [-0.21789,   inf] (73), [-0.21767,   inf] (73), [-0.21698,   inf] (73), [-0.21692,   inf] (73), [-0.21677,   inf] (73), [-0.21647,   inf] (73), [-0.21646,   inf] (73), [-0.21622,   inf] (73), [-0.21617,   inf] (73), [-0.21608,   inf] (73), [-0.21602,   inf] (73), [-0.21579,   inf] (73), [-0.21577,   inf] (73), [-0.21573,   inf] (73), [-0.21572,   inf] (73), [-0.21547,   inf] (73), [-0.21542,   inf] (73), 
length of domains: 42512
Total time: 3.9635	 pickout: 0.3473	 decision: 0.6153	 get_bound: 2.4232	 add_domain: 0.5778
Current lb:-0.21933002769947052
92170 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 102.59696674346924

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 55] [2, 55] [2, 55] [2, 55] [2, 55] [2, 55] [2, 55] [2, 55] [2, 55] [2, 55] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 311.95257568359375 with beta sum per layer: [44.42271423339844, 329.1312255859375, 689.951904296875]
alpha/beta optimization time: 1.5975513458251953
This batch time : update_bounds func: 2.4551	 prepare: 0.4696	 bound: 1.5980	 transfer: 0.1163	 finalize: 0.2596
Accumulated time: update_bounds func: 62.4542	 prepare: 10.3833	 bound: 38.7987	 transfer: 0.1163	 finalize: 9.2660
batch bounding time:  2.459188222885132
Current worst splitting domains [lb, ub] (depth):
[-0.21615,   inf] (75), [-0.21545,   inf] (75), [-0.21541,   inf] (75), [-0.21471,   inf] (75), [-0.21450,   inf] (75), [-0.21380,   inf] (75), [-0.21376,   inf] (75), [-0.21359,   inf] (75), [-0.21331,   inf] (75), /home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:530: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(eps_temp / std).reshape(1, -1, 1, 1)
[-0.21330,   inf] (75), [-0.21306,   inf] (75), [-0.21304,   inf] (75), [-0.21289,   inf] (75), [-0.21285,   inf] (75), [-0.21259,   inf] (75), [-0.21259,   inf] (75), [-0.21255,   inf] (75), [-0.21252,   inf] (75), [-0.21234,   inf] (75), [-0.21227,   inf] (75), 
length of domains: 43288
Total time: 4.7233	 pickout: 0.3527	 decision: 1.4900	 get_bound: 2.4666	 add_domain: 0.4141
Current lb:-0.21615171432495117
96266 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 107.38852667808533

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [0, 2642] [0, 2642] [0, 2642] [0, 2642] [0, 2642] [0, 2642] [0, 2642] [0, 2642] [0, 2642] [0, 2642] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 644.9410400390625 with beta sum per layer: [24.19124984741211, 420.9876708984375, 271.5489807128906]
alpha/beta optimization time: 1.572871446609497
This batch time : update_bounds func: 3.3743	 prepare: 0.4670	 bound: 1.5733	 transfer: 0.1173	 finalize: 0.2699
Accumulated time: update_bounds func: 65.8285	 prepare: 10.8503	 bound: 40.3720	 transfer: 0.1173	 finalize: 9.5359
batch bounding time:  3.3784916400909424
Current worst splitting domains [lb, ub] (depth):
[-0.21365,   inf] (77), [-0.21295,   inf] (77), [-0.21291,   inf] (77), [-0.21220,   inf] (77), [-0.21199,   inf] (77), [-0.21130,   inf] (77), [-0.21126,   inf] (77), [-0.21109,   inf] (77), [-0.21080,   inf] (77), [-0.21079,   inf] (77), [-0.21055,   inf] (77), [-0.21054,   inf] (77), [-0.21040,   inf] (77), [-0.21035,   inf] (77), [-0.21010,   inf] (77), [-0.21008,   inf] (77), [-0.21006,   inf] (77), [-0.21003,   inf] (77), [-0.20984,   inf] (77), [-0.20977,   inf] (77), 
length of domains: 45013
Total time: 4.9276	 pickout: 0.3681	 decision: 0.6262	 get_bound: 3.3858	 add_domain: 0.5475
Current lb:-0.21364986896514893
100362 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Time out!!!!!!!!
Image 821 label 7 verification end, final lower bound -0.21364986896514893, upper bound inf, time: 113.3436553478241
821 -0.21364986896514893
Result: image 821 verification failure (with branch and bound).
Wall time: 122.48167991638184

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 0): []
verification failure idx (total 1): [821]
final verified acc: 0.0%[1]
verifier is called on 1 examples.
total verified: 0
mean time [cnt:1] (excluding attack success): 122.40092515945435
