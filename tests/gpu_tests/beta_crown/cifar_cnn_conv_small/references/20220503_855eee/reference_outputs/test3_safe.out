Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_conv_small_pgd.pth
  name: cifar_conv_small
data:
  start: 920
  end: 921
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR_ERAN
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.00784313725
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 2048
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 120
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 100
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:32:55 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2))
  (1): ReLU()
  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))
  (3): ReLU()
  (4): Flatten()
  (5): Linear(in_features=1152, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([1000, 3, 32, 32]) torch.Size([1000]) torch.Size([1000])
X range: tensor(2.7537) tensor(-2.4291) tensor(0.0238)
Note runnerup label is empty here!
############################
epsilon after preprocessing: tensor([[[[0.0388]],

         [[0.0393]],

         [[0.0390]]]]), data_max = tensor([[[[2.5141]],

         [[2.5968]],

         [[2.7537]]]]), data_min = tensor([[[[-2.4291]],

         [[-2.4183]],

         [[-2.2214]]]])
Task length: 1
saving results to Verified_ret_[cifar_conv_small]_start=920_end=921_iter=20_b=2048_timeout=120_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 920 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 6, correct label 6, image norm 2885.46826171875, logits tensor([ 0.8211, -3.5389,  2.3878,  1.3320,  1.9461, -1.4003,  3.7240, -0.6937,
         0.9622, -3.5892], device='cuda:0', grad_fn=<SelectBackward>)
##### PGD attack: True label: 6, Tested against: ['all'] ######
pgd prediction: tensor([ 0.9314, -3.5753,  2.9250,  1.2271,  1.9789, -1.3490,  3.0391, -0.4933,
         1.0428, -3.8129], device='cuda:0', grad_fn=<SqueezeBackward1>)
attack margin tensor([2.1077, 6.6144, 0.1141, 1.8121, 1.0602, 4.3881,    inf, 3.5324, 1.9963,
        6.8520], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[ 0.8211, -3.5389,  2.3878,  1.3320,  1.9461, -1.4003,  3.7240, -0.6937,
          0.9622, -3.5892]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-0.3188,  4.2435, -1.2499,  0.1143, -0.4892,  2.4779,  0.9632, -0.4430,
          3.9507]], device='cuda:0') None
best_l after optimization: -10.03355884552002 with beta sum per layer: []
alpha/beta optimization time: 7.367169618606567
initial alpha-CROWN bounds: tensor([[-0.2179,  4.3615, -1.1640,  0.1798, -0.4224,  2.5507,  1.0529, -0.3576,
          4.0505]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-1.1640, device='cuda:0', grad_fn=<MinBackward1>)
Sorted order for labels to verify: [2, 4, 3, 8, 0, 7, 5, 1, 9, 6]
##### [0:920] Tested against 2 ######
Model prediction is: tensor([[ 0.8211, -3.5389,  2.3878,  1.3320,  1.9461, -1.4003,  3.7240, -0.6937,
          0.9622, -3.5892]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 15, 15]) != torch.Size([2, 9, 1, 16, 15, 15]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 6, 6]) != torch.Size([2, 9, 1, 32, 6, 6]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 15, 15])
1 /11 torch.Size([1, 32, 6, 6])
2 /21 torch.Size([1, 100])
best_l after optimization: 1.1639654636383057 with beta sum per layer: []
alpha/beta optimization time: 1.8632640838623047
alpha-CROWN with fixed intermediate bounds: tensor([[-1.1640]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-1.1639654636383057
layer 0 size torch.Size([3600]) unstable 333
layer 1 size torch.Size([1152]) unstable 123
layer 2 size torch.Size([100]) unstable 35
-----------------
# of unstable neurons: 491
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 15, 15]) pre split depth:  7
batch:  torch.Size([1, 16, 15, 15]) post split depth:  7
splitting decisions: 
split level 0: [2, 52] 
split level 1: [2, 23] 
split level 2: [2, 99] 
split level 3: [2, 40] 
split level 4: [2, 13] 
split level 5: [2, 85] 
split level 6: [2, 82] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -13.170568466186523 with beta sum per layer: [0.0, 0.0, 17.55510139465332]
alpha/beta optimization time: 0.25318384170532227
This batch time : update_bounds func: 0.2734	 prepare: 0.0098	 bound: 0.2535	 transfer: 0.0019	 finalize: 0.0078
Accumulated time: update_bounds func: 0.2734	 prepare: 0.0098	 bound: 0.2535	 transfer: 0.0019	 finalize: 0.0078
batch bounding time:  0.2737271785736084
Current worst splitting domains [lb, ub] (depth):
[-0.35075,   inf] (8), [-0.34670,   inf] (8), [-0.32677,   inf] (8), [-0.32642,   inf] (8), [-0.32398,   inf] (8), [-0.32118,   inf] (8), [-0.32091,   inf] (8), [-0.31086,   inf] (8), [-0.29661,   inf] (8), [-0.29286,   inf] (8), [-0.28875,   inf] (8), [-0.28065,   inf] (8), [-0.25879,   inf] (8), [-0.25612,   inf] (8), [-0.23082,   inf] (8), [-0.22852,   inf] (8), [-0.17624,   inf] (8), [-0.16062,   inf] (8), [-0.15581,   inf] (8), [-0.15420,   inf] (8), 
length of domains: 32
Total time: 0.3349	 pickout: 0.0009	 decision: 0.0429	 get_bound: 0.2895	 add_domain: 0.0016
Current lb:-0.35075053572654724
128 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.120950222015381

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([32, 16, 15, 15]) pre split depth:  2
batch:  torch.Size([32, 16, 15, 15]) post split depth:  2
splitting decisions: 
split level 0: [2, 44] [2, 44] [2, 44] [2, 44] [2, 44] [2, 44] [2, 44] [2, 44] [2, 44] [2, 44] 
split level 1: [2, 50] [2, 50] [2, 50] [2, 50] [2, 50] [2, 50] [2, 50] [2, 50] [2, 50] [2, 50] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.991657733917236 with beta sum per layer: [0.0, 0.0, 85.49169921875]
alpha/beta optimization time: 0.24364042282104492
This batch time : update_bounds func: 0.2674	 prepare: 0.0117	 bound: 0.2439	 transfer: 0.0039	 finalize: 0.0075
Accumulated time: update_bounds func: 0.5408	 prepare: 0.0216	 bound: 0.4974	 transfer: 0.0039	 finalize: 0.0153
batch bounding time:  0.26760363578796387
Current worst splitting domains [lb, ub] (depth):
[-0.25760,   inf] (11), [-0.25285,   inf] (11), [-0.23789,   inf] (11), [-0.23620,   inf] (11), [-0.23450,   inf] (11), [-0.23351,   inf] (11), [-0.23083,   inf] (11), [-0.22803,   inf] (11), [-0.22349,   inf] (11), [-0.21433,   inf] (11), [-0.21339,   inf] (11), [-0.21185,   inf] (11), [-0.21045,   inf] (11), [-0.20824,   inf] (11), [-0.20823,   inf] (11), [-0.20593,   inf] (11), [-0.20283,   inf] (11), [-0.20160,   inf] (11), [-0.19292,   inf] (11), [-0.18553,   inf] (11), 
length of domains: 71
Total time: 0.3173	 pickout: 0.0051	 decision: 0.0325	 get_bound: 0.2761	 add_domain: 0.0036
Current lb:-0.2575952708721161
256 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.439002275466919

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([71, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([71, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 92] [2, 92] [2, 92] [2, 92] [2, 92] [2, 92] [2, 92] [2, 92] [2, 92] [2, 92] 
regular batch size: 2*71, diving batch size 1*0
best_l after optimization: 3.57197904586792 with beta sum per layer: [0.0, 0.0, 87.49552917480469]
alpha/beta optimization time: 0.24688243865966797
This batch time : update_bounds func: 0.2718	 prepare: 0.0127	 bound: 0.2472	 transfer: 0.0034	 finalize: 0.0082
Accumulated time: update_bounds func: 0.8126	 prepare: 0.0343	 bound: 0.7446	 transfer: 0.0034	 finalize: 0.0235
batch bounding time:  0.2720489501953125
Current worst splitting domains [lb, ub] (depth):
[-0.22274,   inf] (13), [-0.21798,   inf] (13), [-0.20244,   inf] (13), [-0.20161,   inf] (13), [-0.19853,   inf] (13), [-0.19750,   inf] (13), [-0.19453,   inf] (13), [-0.19113,   inf] (13), [-0.18745,   inf] (13), [-0.17911,   inf] (13), [-0.17773,   inf] (13), [-0.17451,   inf] (13), [-0.17397,   inf] (13), [-0.17213,   inf] (13), [-0.17209,   inf] (13), [-0.17102,   inf] (13), [-0.16527,   inf] (13), [-0.16463,   inf] (13), [-0.15657,   inf] (13), [-0.14989,   inf] (13), 
length of domains: 73
Total time: 0.3234	 pickout: 0.0100	 decision: 0.0372	 get_bound: 0.2723	 add_domain: 0.0040
Current lb:-0.22273872792720795
398 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.763651132583618

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([73, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([73, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 71] [2, 71] [2, 71] [2, 71] [2, 71] [2, 71] [2, 71] [2, 71] [2, 71] [2, 71] 
regular batch size: 2*73, diving batch size 1*0
best_l after optimization: -18.418270111083984 with beta sum per layer: [0.0, 0.0, 68.67084503173828]
alpha/beta optimization time: 0.24634528160095215
This batch time : update_bounds func: 0.2714	 prepare: 0.0130	 bound: 0.2466	 transfer: 0.0030	 finalize: 0.0083
Accumulated time: update_bounds func: 1.0840	 prepare: 0.0473	 bound: 0.9912	 transfer: 0.0030	 finalize: 0.0318
batch bounding time:  0.27162718772888184
Current worst splitting domains [lb, ub] (depth):
[-0.19309,   inf] (15), [-0.18921,   inf] (15), [-0.17335,   inf] (15), [-0.17169,   inf] (15), [-0.16878,   inf] (15), [-0.16748,   inf] (15), [-0.16494,   inf] (15), [-0.16192,   inf] (15), [-0.15583,   inf] (15), [-0.14806,   inf] (15), [-0.14526,   inf] (15), [-0.14498,   inf] (15), [-0.14368,   inf] (15), [-0.14211,   inf] (15), [-0.14205,   inf] (15), [-0.13896,   inf] (15), [-0.13549,   inf] (15), [-0.13461,   inf] (15), [-0.12381,   inf] (15), [-0.11820,   inf] (15), 
length of domains: 42
Total time: 0.3220	 pickout: 0.0105	 decision: 0.0374	 get_bound: 0.2719	 add_domain: 0.0023
Current lb:-0.193094864487648
544 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.087091445922852

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([42, 16, 15, 15]) pre split depth:  2
batch:  torch.Size([42, 16, 15, 15]) post split depth:  2
splitting decisions: 
split level 0: [2, 76] [2, 57] [2, 57] [2, 76] [2, 57] [2, 57] [2, 76] [2, 57] [2, 76] [2, 57] 
split level 1: [2, 57] [2, 76] [2, 76] [2, 57] [2, 76] [2, 76] [2, 57] [2, 76] [2, 57] [2, 76] 
regular batch size: 2*84, diving batch size 1*0
best_l after optimization: -22.354320526123047 with beta sum per layer: [0.0, 0.0, 55.818382263183594]
alpha/beta optimization time: 0.24997210502624512
This batch time : update_bounds func: 0.2805	 prepare: 0.0148	 bound: 0.2502	 transfer: 0.0053	 finalize: 0.0095
Accumulated time: update_bounds func: 1.3645	 prepare: 0.0621	 bound: 1.2414	 transfer: 0.0053	 finalize: 0.0413
batch bounding time:  0.2807800769805908
Current worst splitting domains [lb, ub] (depth):
[-0.14575,   inf] (18), [-0.14234,   inf] (18), [-0.12586,   inf] (18), [-0.12374,   inf] (18), [-0.12043,   inf] (18), [-0.11958,   inf] (18), [-0.11807,   inf] (18), [-0.11516,   inf] (18), [-0.10643,   inf] (18), [-0.09889,   inf] (18), [-0.09739,   inf] (18), [-0.09541,   inf] (18), [-0.09505,   inf] (18), [-0.09429,   inf] (18), [-0.09342,   inf] (18), [-0.08928,   inf] (18), [-0.08771,   inf] (18), [-0.08758,   inf] (18), [-0.07555,   inf] (18), [-0.06952,   inf] (18), 
length of domains: 32
Total time: 0.3331	 pickout: 0.0063	 decision: 0.0324	 get_bound: 0.2923	 add_domain: 0.0020
Current lb:-0.14575254917144775
712 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.42142653465271

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([32, 16, 15, 15]) pre split depth:  2
batch:  torch.Size([32, 16, 15, 15]) post split depth:  2
splitting decisions: 
split level 0: [2, 93] [2, 93] [2, 93] [2, 93] [2, 93] [2, 93] [2, 93] [2, 93] [1, 267] [1, 267] 
split level 1: [1, 606] [1, 1124] [1, 1124] [1, 606] [2, 94] [2, 94] [2, 94] [2, 94] [2, 93] [2, 93] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -2.4824705123901367 with beta sum per layer: [0.0, 1.1214332580566406, 31.30836296081543]
alpha/beta optimization time: 0.25060343742370605
This batch time : update_bounds func: 0.2752	 prepare: 0.0121	 bound: 0.2509	 transfer: 0.0039	 finalize: 0.0080
Accumulated time: update_bounds func: 1.6397	 prepare: 0.0742	 bound: 1.4924	 transfer: 0.0039	 finalize: 0.0494
batch bounding time:  0.27545762062072754
Current worst splitting domains [lb, ub] (depth):
[-0.12391,   inf] (21), [-0.12082,   inf] (21), [-0.10788,   inf] (21), [-0.10703,   inf] (21), [-0.09945,   inf] (21), [-0.09668,   inf] (21), [-0.09535,   inf] (21), [-0.09502,   inf] (21), [-0.09220,   inf] (21), [-0.08244,   inf] (21), [-0.07532,   inf] (21), [-0.07469,   inf] (21), [-0.07129,   inf] (21), [-0.07117,   inf] (21), [-0.07015,   inf] (21), [-0.07008,   inf] (21), [-0.06670,   inf] (21), [-0.06435,   inf] (21), [-0.06425,   inf] (21), [-0.06249,   inf] (21), 
length of domains: 42
Total time: 0.3221	 pickout: 0.0051	 decision: 0.0295	 get_bound: 0.2846	 add_domain: 0.0029
Current lb:-0.1239083930850029
840 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.744405508041382

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([42, 16, 15, 15]) pre split depth:  2
batch:  torch.Size([42, 16, 15, 15]) post split depth:  2
splitting decisions: 
split level 0: [2, 94] [2, 94] [2, 94] [2, 94] [1, 1096] [1, 416] [1, 606] [1, 1096] [1, 1096] [2, 94] 
split level 1: [1, 23] [1, 1124] [1, 1124] [1, 23] [2, 94] [1, 1124] [1, 1096] [1, 1124] [1, 1124] [1, 1124] 
regular batch size: 2*84, diving batch size 1*0
best_l after optimization: -2.4697630405426025 with beta sum per layer: [0.0, 4.8546552658081055, 19.47540283203125]
alpha/beta optimization time: 0.25228452682495117
This batch time : update_bounds func: 0.2841	 prepare: 0.0164	 bound: 0.2526	 transfer: 0.0045	 finalize: 0.0102
Accumulated time: update_bounds func: 1.9239	 prepare: 0.0906	 bound: 1.7450	 transfer: 0.0045	 finalize: 0.0595
batch bounding time:  0.2843775749206543
Current worst splitting domains [lb, ub] (depth):
[-0.10791,   inf] (24), [-0.10625,   inf] (24), [-0.09317,   inf] (24), [-0.09102,   inf] (24), [-0.08631,   inf] (24), [-0.08120,   inf] (24), [-0.07989,   inf] (24), [-0.07946,   inf] (24), [-0.07764,   inf] (24), [-0.07608,   inf] (24), [-0.07590,   inf] (24), [-0.06719,   inf] (24), [-0.06430,   inf] (24), [-0.06162,   inf] (24), [-0.06131,   inf] (24), [-0.06003,   inf] (24), [-0.05570,   inf] (24), [-0.05541,   inf] (24), [-0.05485,   inf] (24), [-0.05195,   inf] (24), 
length of domains: 66
Total time: 0.3405	 pickout: 0.0068	 decision: 0.0326	 get_bound: 0.2964	 add_domain: 0.0047
Current lb:-0.10790503770112991
1008 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.0859785079956055

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([66, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([66, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 735] [1, 1096] [1, 1096] [1, 416] [1, 735] [1, 23] [2, 3] [2, 3] [1, 1096] [1, 1096] 
regular batch size: 2*66, diving batch size 1*0
best_l after optimization: 2.9874038696289062 with beta sum per layer: [0.0, 7.1119232177734375, 15.598148345947266]
alpha/beta optimization time: 0.2521791458129883
This batch time : update_bounds func: 0.2777	 prepare: 0.0137	 bound: 0.2525	 transfer: 0.0025	 finalize: 0.0086
Accumulated time: update_bounds func: 2.2016	 prepare: 0.1043	 bound: 1.9974	 transfer: 0.0025	 finalize: 0.0681
batch bounding time:  0.2779722213745117
Current worst splitting domains [lb, ub] (depth):
[-0.09873,   inf] (26), [-0.09704,   inf] (26), [-0.08991,   inf] (26), [-0.08392,   inf] (26), [-0.08056,   inf] (26), [-0.07727,   inf] (26), [-0.07666,   inf] (26), [-0.07359,   inf] (26), [-0.07235,   inf] (26), [-0.07107,   inf] (26), [-0.07105,   inf] (26), [-0.06912,   inf] (26), [-0.06856,   inf] (26), [-0.06754,   inf] (26), [-0.06604,   inf] (26), [-0.06364,   inf] (26), [-0.06243,   inf] (26), [-0.05769,   inf] (26), [-0.05659,   inf] (26), [-0.05415,   inf] (26), 
length of domains: 99
Total time: 0.3323	 pickout: 0.0100	 decision: 0.0368	 get_bound: 0.2782	 add_domain: 0.0074
Current lb:-0.09873291850090027
1140 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.419304370880127

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([99, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([99, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 416] [1, 407] [1, 416] [1, 407] [1, 735] [1, 407] [1, 416] [1, 407] [1, 1096] [1, 485] 
regular batch size: 2*99, diving batch size 1*0
best_l after optimization: 3.181730270385742 with beta sum per layer: [0.0, 12.08056640625, 24.991779327392578]
alpha/beta optimization time: 0.25399231910705566
This batch time : update_bounds func: 0.2899	 prepare: 0.0196	 bound: 0.2543	 transfer: 0.0038	 finalize: 0.0118
Accumulated time: update_bounds func: 2.4915	 prepare: 0.1239	 bound: 2.2517	 transfer: 0.0038	 finalize: 0.0799
batch bounding time:  0.2902247905731201
Current worst splitting domains [lb, ub] (depth):
[-0.08827,   inf] (28), [-0.08795,   inf] (28), [-0.08429,   inf] (28), [-0.08256,   inf] (28), [-0.07898,   inf] (28), [-0.07687,   inf] (28), [-0.07471,   inf] (28), [-0.07167,   inf] (28), [-0.06924,   inf] (28), [-0.06593,   inf] (28), [-0.06552,   inf] (28), [-0.06489,   inf] (28), [-0.06480,   inf] (28), [-0.06400,   inf] (28), [-0.06388,   inf] (28), [-0.06329,   inf] (28), [-0.06198,   inf] (28), [-0.06123,   inf] (28), [-0.06043,   inf] (28), [-0.05928,   inf] (28), 
length of domains: 131
Total time: 0.3607	 pickout: 0.0147	 decision: 0.0452	 get_bound: 0.2905	 add_domain: 0.0102
Current lb:-0.08826735615730286
1338 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.7816877365112305

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([131, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([131, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 1096] [2, 3] [1, 1096] [2, 3] [1, 1096] [1, 1096] [2, 3] [1, 1096] [2, 3] [2, 3] 
regular batch size: 2*131, diving batch size 1*0
best_l after optimization: 3.1828482151031494 with beta sum per layer: [0.0, 17.48509979248047, 35.96381759643555]
alpha/beta optimization time: 0.2649056911468506
This batch time : update_bounds func: 0.3139	 prepare: 0.0258	 bound: 0.2652	 transfer: 0.0070	 finalize: 0.0152
Accumulated time: update_bounds func: 2.8055	 prepare: 0.1497	 bound: 2.5170	 transfer: 0.0070	 finalize: 0.0951
batch bounding time:  0.3142826557159424
Current worst splitting domains [lb, ub] (depth):
[-0.07997,   inf] (30), [-0.07933,   inf] (30), [-0.07583,   inf] (30), [-0.07393,   inf] (30), [-0.07028,   inf] (30), [-0.06804,   inf] (30), [-0.06614,   inf] (30), [-0.06279,   inf] (30), [-0.06059,   inf] (30), [-0.05708,   inf] (30), [-0.05676,   inf] (30), [-0.05665,   inf] (30), [-0.05663,   inf] (30), [-0.05616,   inf] (30), [-0.05443,   inf] (30), [-0.05441,   inf] (30), [-0.05351,   inf] (30), [-0.05266,   inf] (30), [-0.05239,   inf] (30), [-0.05184,   inf] (30), 
length of domains: 177
Total time: 0.4076	 pickout: 0.0189	 decision: 0.0600	 get_bound: 0.3147	 add_domain: 0.0141
Current lb:-0.07997020334005356
1600 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.191607475280762

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([177, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([177, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 3] [1, 305] [2, 3] [1, 305] [2, 3] [2, 3] [1, 305] [1, 606] [1, 305] [2, 3] 
regular batch size: 2*177, diving batch size 1*0
best_l after optimization: 1.8012350797653198 with beta sum per layer: [0.0, 23.454757690429688, 58.63826370239258]
alpha/beta optimization time: 0.28923583030700684
This batch time : update_bounds func: 0.3550	 prepare: 0.0342	 bound: 0.2896	 transfer: 0.0091	 finalize: 0.0211
Accumulated time: update_bounds func: 3.1605	 prepare: 0.1840	 bound: 2.8065	 transfer: 0.0091	 finalize: 0.1162
batch bounding time:  0.35544848442077637
Current worst splitting domains [lb, ub] (depth):
[-0.07161,   inf] (32), [-0.06892,   inf] (32), [-0.06846,   inf] (32), [-0.06735,   inf] (32), [-0.06347,   inf] (32), [-0.06338,   inf] (32), [-0.06165,   inf] (32), [-0.05935,   inf] (32), [-0.05604,   inf] (32), [-0.05569,   inf] (32), [-0.05532,   inf] (32), [-0.05016,   inf] (32), [-0.05008,   inf] (32), [-0.05008,   inf] (32), [-0.04856,   inf] (32), [-0.04832,   inf] (32), [-0.04776,   inf] (32), [-0.04734,   inf] (32), [-0.04602,   inf] (32), [-0.04584,   inf] (32), 
length of domains: 168
Total time: 0.5274	 pickout: 0.0262	 decision: 0.1309	 get_bound: 0.3560	 add_domain: 0.0142
Current lb:-0.07161056995391846
1954 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.722798585891724

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([168, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([168, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 606] [1, 23] [1, 23] [1, 606] [1, 23] [1, 23] [1, 606] [1, 606] [2, 3] [1, 23] 
regular batch size: 2*168, diving batch size 1*0
best_l after optimization: 2.6446430683135986 with beta sum per layer: [0.0, 21.735183715820312, 39.4586296081543]
alpha/beta optimization time: 0.27927637100219727
This batch time : update_bounds func: 0.3394	 prepare: 0.0319	 bound: 0.2796	 transfer: 0.0072	 finalize: 0.0198
Accumulated time: update_bounds func: 3.4998	 prepare: 0.2159	 bound: 3.0861	 transfer: 0.0072	 finalize: 0.1361
batch bounding time:  0.339752197265625
Current worst splitting domains [lb, ub] (depth):
[-0.06421,   inf] (34), [-0.06143,   inf] (34), [-0.06119,   inf] (34), [-0.06002,   inf] (34), [-0.05627,   inf] (34), [-0.05592,   inf] (34), [-0.05434,   inf] (34), [-0.05210,   inf] (34), [-0.05099,   inf] (34), [-0.04918,   inf] (34), [-0.04823,   inf] (34), [-0.04806,   inf] (34), [-0.04784,   inf] (34), [-0.04664,   inf] (34), [-0.04590,   inf] (34), [-0.04388,   inf] (34), [-0.04344,   inf] (34), [-0.04299,   inf] (34), [-0.04266,   inf] (34), [-0.04112,   inf] (34), 
length of domains: 194
Total time: 0.4446	 pickout: 0.0249	 decision: 0.0630	 get_bound: 0.3403	 add_domain: 0.0164
Current lb:-0.06420635432004929
2290 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.1707916259765625

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([194, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([194, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 379] [1, 416] [1, 416] [1, 407] [1, 416] [1, 416] [1, 379] [1, 407] [1, 379] [1, 416] 
regular batch size: 2*194, diving batch size 1*0
best_l after optimization: 2.878060817718506 with beta sum per layer: [0.0, 28.082454681396484, 31.827035903930664]
alpha/beta optimization time: 0.2979617118835449
This batch time : update_bounds func: 0.3655	 prepare: 0.0368	 bound: 0.2983	 transfer: 0.0068	 finalize: 0.0226
Accumulated time: update_bounds func: 3.8654	 prepare: 0.2527	 bound: 3.3844	 transfer: 0.0068	 finalize: 0.1586
batch bounding time:  0.36596059799194336
Current worst splitting domains [lb, ub] (depth):
[-0.05862,   inf] (36), [-0.05438,   inf] (36), [-0.05191,   inf] (36), [-0.05186,   inf] (36), [-0.05057,   inf] (36), [-0.05056,   inf] (36), [-0.04854,   inf] (36), [-0.04731,   inf] (36), [-0.04686,   inf] (36), [-0.04651,   inf] (36), [-0.04616,   inf] (36), [-0.04553,   inf] (36), [-0.04543,   inf] (36), [-0.04517,   inf] (36), [-0.04094,   inf] (36), [-0.04089,   inf] (36), [-0.03949,   inf] (36), [-0.03925,   inf] (36), [-0.03914,   inf] (36), [-0.03854,   inf] (36), 
length of domains: 236
Total time: 0.4888	 pickout: 0.0292	 decision: 0.0715	 get_bound: 0.3666	 add_domain: 0.0216
Current lb:-0.058621883392333984
2678 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.663073778152466

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([236, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([236, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 485] [1, 485] [1, 735] [1, 735] [1, 735] [1, 735] [1, 407] [1, 485] [1, 735] [1, 735] 
regular batch size: 2*236, diving batch size 1*0
best_l after optimization: 2.145819664001465 with beta sum per layer: [0.0, 35.83469772338867, 28.865142822265625]
alpha/beta optimization time: 0.32237863540649414
This batch time : update_bounds func: 0.4060	 prepare: 0.0446	 bound: 0.3227	 transfer: 0.0101	 finalize: 0.0272
Accumulated time: update_bounds func: 4.2713	 prepare: 0.2973	 bound: 3.7071	 transfer: 0.0101	 finalize: 0.1858
batch bounding time:  0.40654587745666504
Current worst splitting domains [lb, ub] (depth):
[-0.05301,   inf] (38), [-0.04895,   inf] (38), [-0.04508,   inf] (38), [-0.04492,   inf] (38), [-0.04343,   inf] (38), [-0.04332,   inf] (38), [-0.04256,   inf] (38), [-0.04162,   inf] (38), [-0.04155,   inf] (38), [-0.04147,   inf] (38), [-0.04089,   inf] (38), [-0.04053,   inf] (38), [-0.04044,   inf] (38), [-0.03991,   inf] (38), [-0.03959,   inf] (38), [-0.03922,   inf] (38), [-0.03791,   inf] (38), [-0.03754,   inf] (38), [-0.03676,   inf] (38), [-0.03636,   inf] (38), 
length of domains: 264
Total time: 0.6076	 pickout: 0.0342	 decision: 0.1422	 get_bound: 0.4073	 add_domain: 0.0239
Current lb:-0.05301213264465332
3150 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.275278568267822

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([264, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([264, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 305] [1, 305] [1, 340] [1, 340] [1, 340] [1, 340] [1, 305] [1, 305] [1, 340] [1, 340] 
regular batch size: 2*264, diving batch size 1*0
best_l after optimization: 2.254767417907715 with beta sum per layer: [0.0, 41.207340240478516, 23.41500473022461]
alpha/beta optimization time: 0.34198951721191406
This batch time : update_bounds func: 0.4326	 prepare: 0.0501	 bound: 0.3423	 transfer: 0.0082	 finalize: 0.0307
Accumulated time: update_bounds func: 4.7039	 prepare: 0.3475	 bound: 4.0494	 transfer: 0.0082	 finalize: 0.2166
batch bounding time:  0.4331023693084717
Current worst splitting domains [lb, ub] (depth):
[-0.04422,   inf] (40), [-0.04418,   inf] (40), [-0.04013,   inf] (40), [-0.03986,   inf] (40), [-0.03790,   inf] (40), [-0.03770,   inf] (40), [-0.03657,   inf] (40), [-0.03652,   inf] (40), [-0.03633,   inf] (40), [-0.03614,   inf] (40), [-0.03498,   inf] (40), [-0.03487,   inf] (40), [-0.03424,   inf] (40), [-0.03413,   inf] (40), [-0.03371,   inf] (40), [-0.03370,   inf] (40), [-0.03336,   inf] (40), [-0.03333,   inf] (40), [-0.03327,   inf] (40), [-0.03317,   inf] (40), 
length of domains: 278
Total time: 0.5883	 pickout: 0.0388	 decision: 0.0897	 get_bound: 0.4339	 add_domain: 0.0259
Current lb:-0.044216275215148926
3678 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.868443727493286

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([278, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([278, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 717] [1, 717] [1, 717] [1, 717] [1, 485] [1, 485] [1, 485] [1, 485] [1, 485] [1, 485] 
regular batch size: 2*278, diving batch size 1*0
best_l after optimization: 1.9606612920761108 with beta sum per layer: [0.0, 37.62428283691406, 20.42812156677246]
alpha/beta optimization time: 0.34818339347839355
This batch time : update_bounds func: 0.4396	 prepare: 0.0521	 bound: 0.3485	 transfer: 0.0051	 finalize: 0.0325
Accumulated time: update_bounds func: 5.1435	 prepare: 0.3995	 bound: 4.3979	 transfer: 0.0051	 finalize: 0.2491
batch bounding time:  0.44023609161376953
Current worst splitting domains [lb, ub] (depth):
[-0.03818,   inf] (42), [-0.03813,   inf] (42), [-0.03395,   inf] (42), [-0.03369,   inf] (42), [-0.03136,   inf] (42), [-0.03083,   inf] (42), [-0.03060,   inf] (42), [-0.03057,   inf] (42), [-0.02997,   inf] (42), [-0.02982,   inf] (42), [-0.02979,   inf] (42), [-0.02929,   inf] (42), [-0.02834,   inf] (42), [-0.02819,   inf] (42), [-0.02796,   inf] (42), [-0.02741,   inf] (42), [-0.02727,   inf] (42), [-0.02710,   inf] (42), [-0.02684,   inf] (42), [-0.02677,   inf] (42), 
length of domains: 307
Total time: 0.6556	 pickout: 0.0406	 decision: 0.0938	 get_bound: 0.4411	 add_domain: 0.0801
Current lb:-0.038178544491529465
4234 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.52949571609497

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([307, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([307, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 407] [1, 407] [1, 379] [1, 379] [1, 267] [1, 267] [1, 407] [1, 407] [1, 267] [1, 267] 
regular batch size: 2*307, diving batch size 1*0
best_l after optimization: 1.129483699798584 with beta sum per layer: [0.0, 33.51253128051758, 13.973634719848633]
alpha/beta optimization time: 0.36666083335876465
This batch time : update_bounds func: 0.4701	 prepare: 0.0573	 bound: 0.3670	 transfer: 0.0088	 finalize: 0.0355
Accumulated time: update_bounds func: 5.6136	 prepare: 0.4569	 bound: 4.7649	 transfer: 0.0088	 finalize: 0.2846
batch bounding time:  0.47073864936828613
Current worst splitting domains [lb, ub] (depth):
[-0.03256,   inf] (44), [-0.03225,   inf] (44), [-0.02870,   inf] (44), [-0.02844,   inf] (44), [-0.02616,   inf] (44), [-0.02604,   inf] (44), [-0.02569,   inf] (44), [-0.02536,   inf] (44), [-0.02490,   inf] (44), [-0.02490,   inf] (44), [-0.02466,   inf] (44), [-0.02438,   inf] (44), [-0.02404,   inf] (44), [-0.02355,   inf] (44), [-0.02276,   inf] (44), [-0.02271,   inf] (44), [-0.02185,   inf] (44), [-0.02131,   inf] (44), [-0.02114,   inf] (44), [-0.02107,   inf] (44), 
length of domains: 293
Total time: 0.6514	 pickout: 0.0447	 decision: 0.1059	 get_bound: 0.4717	 add_domain: 0.0291
Current lb:-0.03256046772003174
4848 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.18714165687561

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([293, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([293, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 340] [1, 340] [1, 267] [1, 967] [1, 970] [1, 591] [1, 970] [1, 591] [1, 970] [1, 970] 
regular batch size: 2*293, diving batch size 1*0
best_l after optimization: 0.2440599799156189 with beta sum per layer: [0.0, 27.275480270385742, 6.255226135253906]
alpha/beta optimization time: 0.35804295539855957
This batch time : update_bounds func: 0.4557	 prepare: 0.0541	 bound: 0.3584	 transfer: 0.0084	 finalize: 0.0335
Accumulated time: update_bounds func: 6.0693	 prepare: 0.5110	 bound: 5.1233	 transfer: 0.0084	 finalize: 0.3181
batch bounding time:  0.45633864402770996
Current worst splitting domains [lb, ub] (depth):
[-0.02573,   inf] (46), [-0.02573,   inf] (46), [-0.02537,   inf] (46), [-0.02469,   inf] (46), [-0.02337,   inf] (46), [-0.02337,   inf] (46), [-0.02061,   inf] (46), [-0.02030,   inf] (46), [-0.01989,   inf] (46), [-0.01980,   inf] (46), [-0.01909,   inf] (46), [-0.01902,   inf] (46), [-0.01808,   inf] (46), [-0.01758,   inf] (46), [-0.01756,   inf] (46), [-0.01754,   inf] (46), [-0.01721,   inf] (46), [-0.01683,   inf] (46), [-0.01673,   inf] (46), [-0.01655,   inf] (46), 
length of domains: 254
Total time: 0.6225	 pickout: 0.0426	 decision: 0.0972	 get_bound: 0.4572	 add_domain: 0.0254
Current lb:-0.02573263645172119
5434 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.815805673599243

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([254, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([254, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 267] [1, 267] [1, 267] [1, 267] [1, 967] [1, 267] [1, 967] [1, 379] [1, 967] [1, 379] 
regular batch size: 2*254, diving batch size 1*0
best_l after optimization: -0.9196794629096985 with beta sum per layer: [0.0, 26.601551055908203, 2.8926143646240234]
alpha/beta optimization time: 0.3328559398651123
This batch time : update_bounds func: 0.4156	 prepare: 0.0476	 bound: 0.3332	 transfer: 0.0045	 finalize: 0.0292
Accumulated time: update_bounds func: 6.4849	 prepare: 0.5585	 bound: 5.4564	 transfer: 0.0045	 finalize: 0.3473
batch bounding time:  0.41613316535949707
Current worst splitting domains [lb, ub] (depth):
[-0.02060,   inf] (48), [-0.02050,   inf] (48), [-0.02008,   inf] (48), [-0.01944,   inf] (48), [-0.01830,   inf] (48), [-0.01823,   inf] (48), [-0.01573,   inf] (48), [-0.01535,   inf] (48), [-0.01522,   inf] (48), [-0.01462,   inf] (48), [-0.01456,   inf] (48), [-0.01442,   inf] (48), [-0.01368,   inf] (48), [-0.01318,   inf] (48), [-0.01255,   inf] (48), [-0.01238,   inf] (48), [-0.01223,   inf] (48), [-0.01213,   inf] (48), [-0.01177,   inf] (48), [-0.01109,   inf] (48), 
length of domains: 174
Total time: 0.6092	 pickout: 0.0369	 decision: 0.1372	 get_bound: 0.4169	 add_domain: 0.0182
Current lb:-0.020603299140930176
5942 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.43096137046814

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([174, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([174, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 967] [1, 967] [1, 967] [1, 967] [1, 591] [1, 591] [1, 753] [1, 267] [1, 753] [1, 267] 
regular batch size: 2*174, diving batch size 1*0
best_l after optimization: -4.628426551818848 with beta sum per layer: [0.0, 14.472248077392578, 0.7419365644454956]
alpha/beta optimization time: 0.28525495529174805
This batch time : update_bounds func: 0.3430	 prepare: 0.0328	 bound: 0.2856	 transfer: 0.0035	 finalize: 0.0203
Accumulated time: update_bounds func: 6.8279	 prepare: 0.5913	 bound: 5.7420	 transfer: 0.0035	 finalize: 0.3676
batch bounding time:  0.34347081184387207
Current worst splitting domains [lb, ub] (depth):
[-0.01575,   inf] (50), [-0.01563,   inf] (50), [-0.01519,   inf] (50), [-0.01457,   inf] (50), [-0.01307,   inf] (50), [-0.01304,   inf] (50), [-0.01207,   inf] (50), [-0.01155,   inf] (50), [-0.01089,   inf] (50), [-0.01075,   inf] (50), [-0.01059,   inf] (50), [-0.00998,   inf] (50), [-0.00976,   inf] (50), [-0.00949,   inf] (50), [-0.00887,   inf] (50), [-0.00870,   inf] (50), [-0.00741,   inf] (50), [-0.00731,   inf] (50), [-0.00713,   inf] (50), [-0.00701,   inf] (50), 
length of domains: 104
Total time: 0.4457	 pickout: 0.0258	 decision: 0.0647	 get_bound: 0.3440	 add_domain: 0.0111
Current lb:-0.015745162963867188
6290 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.880890607833862

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([104, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([104, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 591] [1, 591] [1, 591] [1, 591] [1, 340] [1, 625] [2, 75] [2, 75] [2, 75] [2, 75] 
regular batch size: 2*104, diving batch size 1*0
best_l after optimization: -0.7004473209381104 with beta sum per layer: [0.0, 6.461676597595215, 0.44555556774139404]
alpha/beta optimization time: 0.2876546382904053
This batch time : update_bounds func: 0.3249	 prepare: 0.0216	 bound: 0.2880	 transfer: 0.0026	 finalize: 0.0122
Accumulated time: update_bounds func: 7.1528	 prepare: 0.6129	 bound: 6.0300	 transfer: 0.0026	 finalize: 0.3798
batch bounding time:  0.325244665145874
Current worst splitting domains [lb, ub] (depth):
[-0.01084,   inf] (52), [-0.01071,   inf] (52), [-0.01030,   inf] (52), [-0.00981,   inf] (52), [-0.00807,   inf] (52), [-0.00766,   inf] (52), [-0.00753,   inf] (52), [-0.00688,   inf] (52), [-0.00683,   inf] (52), [-0.00679,   inf] (52), [-0.00631,   inf] (52), [-0.00598,   inf] (52), [-0.00584,   inf] (52), [-0.00558,   inf] (52), [-0.00548,   inf] (52), [-0.00485,   inf] (52), [-0.00472,   inf] (52), [-0.00256,   inf] (52), [-0.00255,   inf] (52), [-0.00253,   inf] (52), 
length of domains: 44
Total time: 0.3941	 pickout: 0.0157	 decision: 0.0474	 get_bound: 0.3256	 add_domain: 0.0055
Current lb:-0.01084301806986332
6498 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.277355670928955

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([44, 16, 15, 15]) pre split depth:  2
batch:  torch.Size([44, 16, 15, 15]) post split depth:  2
splitting decisions: 
split level 0: [1, 625] [1, 625] [1, 625] [1, 625] [1, 567] [1, 753] [1, 567] [1, 567] [1, 625] [1, 567] 
split level 1: [1, 753] [1, 753] [1, 753] [1, 753] [1, 955] [1, 402] [1, 955] [1, 955] [1, 753] [1, 955] 
regular batch size: 2*88, diving batch size 1*0
best_l after optimization: -5.106814384460449 with beta sum per layer: [0.0, 3.6248555183410645, 0.0]
alpha/beta optimization time: 0.27258777618408203
This batch time : update_bounds func: 0.3045	 prepare: 0.0177	 bound: 0.2729	 transfer: 0.0029	 finalize: 0.0104
Accumulated time: update_bounds func: 7.4574	 prepare: 0.6306	 bound: 6.3029	 transfer: 0.0029	 finalize: 0.3902
batch bounding time:  0.30481743812561035
Current worst splitting domains [lb, ub] (depth):
[-0.00250,   inf] (55), [-0.00236,   inf] (55), [-0.00190,   inf] (55), [-0.00142,   inf] (55), [-0.00098,   inf] (55), [-0.00091,   inf] (55), [-0.00043,   inf] (55), 
length of domains: 7
Total time: 0.3618	 pickout: 0.0071	 decision: 0.0342	 get_bound: 0.3196	 add_domain: 0.0010
Current lb:-0.0024973670952022076
6674 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.640846252441406

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([7, 16, 15, 15]) pre split depth:  4
batch:  torch.Size([7, 16, 15, 15]) post split depth:  4
splitting decisions: 
split level 0: [1, 483] [1, 483] [1, 483] [1, 483] [1, 775] [1, 340] [1, 775] 
split level 1: [2, 75] [2, 75] [2, 75] [2, 75] [1, 625] [1, 970] [1, 625] 
split level 2: [1, 402] [1, 402] [1, 402] [1, 402] [1, 591] [2, 75] [1, 591] 
split level 3: [2, 83] [2, 83] [2, 83] [2, 83] [2, 83] [2, 83] [2, 83] 
regular batch size: 2*56, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -12.706911087036133 with beta sum per layer: [0.0, 0.2628253698348999, 0.0]
alpha/beta optimization time: 0.011873960494995117
This batch time : update_bounds func: 0.0325	 prepare: 0.0116	 bound: 0.0122	 transfer: 0.0017	 finalize: 0.0066
Accumulated time: update_bounds func: 7.4899	 prepare: 0.6423	 bound: 6.3150	 transfer: 0.0017	 finalize: 0.3968
batch bounding time:  0.03267645835876465
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0812	 pickout: 0.0018	 decision: 0.0303	 get_bound: 0.0491	 add_domain: 0.0001
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 12.722846508026123

Image 920 label 2 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 12.789785385131836
920 1.0000000116860974e-07
##### [0:920] Tested against 4 ######
Model prediction is: tensor([[ 0.8211, -3.5389,  2.3878,  1.3320,  1.9461, -1.4003,  3.7240, -0.6937,
          0.9622, -3.5892]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 15, 15]) != torch.Size([2, 9, 1, 16, 15, 15]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 6, 6]) != torch.Size([2, 9, 1, 32, 6, 6]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 15, 15])
1 /11 torch.Size([1, 32, 6, 6])
2 /21 torch.Size([1, 100])
best_l after optimization: 0.42229926586151123 with beta sum per layer: []
alpha/beta optimization time: 1.0149378776550293
alpha-CROWN with fixed intermediate bounds: tensor([[-0.4223]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.42229926586151123
layer 0 size torch.Size([3600]) unstable 333
layer 1 size torch.Size([1152]) unstable 123
layer 2 size torch.Size([100]) unstable 35
-----------------
# of unstable neurons: 491
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 15, 15]) pre split depth:  7
batch:  torch.Size([1, 16, 15, 15]) post split depth:  7
splitting decisions: 
split level 0: [2, 44] 
split level 1: [2, 52] 
split level 2: [2, 93] 
split level 3: [2, 40] 
split level 4: [2, 82] 
split level 5: [2, 13] 
split level 6: [2, 94] 
regular batch size: 2*64, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -84.97055053710938 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.011597394943237305
This batch time : update_bounds func: 0.0353	 prepare: 0.0104	 bound: 0.0119	 transfer: 0.0047	 finalize: 0.0079
Accumulated time: update_bounds func: 7.5252	 prepare: 0.6527	 bound: 6.3270	 transfer: 0.0047	 finalize: 0.4046
batch bounding time:  0.03551983833312988
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0963	 pickout: 0.0009	 decision: 0.0433	 get_bound: 0.0520	 add_domain: 0.0001
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.1286330223083496

Image 920 label 4 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.1891937255859375
920 1.0000000116860974e-07
##### [0:920] Tested against 3 ######
Initial alpha-CROWN verified for label 3 with bound 0.17981815338134766
Image 920 label 3 verification end, final lower bound 0.17981815338134766, upper bound inf, time: 0.00047588348388671875
920 0.17981815338134766
##### [0:920] Tested against 8 ######
Model prediction is: tensor([[ 0.8211, -3.5389,  2.3878,  1.3320,  1.9461, -1.4003,  3.7240, -0.6937,
          0.9622, -3.5892]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 15, 15]) != torch.Size([2, 9, 1, 16, 15, 15]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 6, 6]) != torch.Size([2, 9, 1, 32, 6, 6]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 15, 15])
1 /11 torch.Size([1, 32, 6, 6])
2 /21 torch.Size([1, 100])
best_l after optimization: 0.3575296401977539 with beta sum per layer: []
alpha/beta optimization time: 1.0770938396453857
alpha-CROWN with fixed intermediate bounds: tensor([[-0.3575]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.3575296401977539
layer 0 size torch.Size([3600]) unstable 333
layer 1 size torch.Size([1152]) unstable 123
layer 2 size torch.Size([100]) unstable 35
-----------------
# of unstable neurons: 491
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 15, 15]) pre split depth:  7
batch:  torch.Size([1, 16, 15, 15]) post split depth:  7
splitting decisions: 
split level 0: [2, 52] 
split level 1: [2, 44] 
split level 2: [2, 40] 
split level 3: [2, 18] 
split level 4: [2, 56] 
split level 5: [2, 3] 
split level 6: [2, 99] 
regular batch size: 2*64, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -76.75057220458984 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.021380901336669922
This batch time : update_bounds func: 0.0522	 prepare: 0.0147	 bound: 0.0217	 transfer: 0.0042	 finalize: 0.0112
Accumulated time: update_bounds func: 7.5774	 prepare: 0.6674	 bound: 6.3487	 transfer: 0.0042	 finalize: 0.4158
batch bounding time:  0.0523836612701416
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.1253	 pickout: 0.0011	 decision: 0.0490	 get_bound: 0.0750	 add_domain: 0.0001
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.220536708831787

Image 920 label 8 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.284505844116211
920 1.0000000116860974e-07
##### [0:920] Tested against 0 ######
Model prediction is: tensor([[ 0.8211, -3.5389,  2.3878,  1.3320,  1.9461, -1.4003,  3.7240, -0.6937,
          0.9622, -3.5892]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 15, 15]) != torch.Size([2, 9, 1, 16, 15, 15]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 6, 6]) != torch.Size([2, 9, 1, 32, 6, 6]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 15, 15])
1 /11 torch.Size([1, 32, 6, 6])
2 /21 torch.Size([1, 100])
best_l after optimization: 0.21779364347457886 with beta sum per layer: []
alpha/beta optimization time: 0.9924118518829346
alpha-CROWN with fixed intermediate bounds: tensor([[-0.2178]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.21779365837574005
layer 0 size torch.Size([3600]) unstable 333
layer 1 size torch.Size([1152]) unstable 123
layer 2 size torch.Size([100]) unstable 35
-----------------
# of unstable neurons: 491
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 15, 15]) pre split depth:  7
batch:  torch.Size([1, 16, 15, 15]) post split depth:  7
splitting decisions: 
split level 0: [2, 52] 
split level 1: [2, 93] 
split level 2: [2, 44] 
split level 3: [2, 3] 
split level 4: [2, 34] 
split level 5: [2, 85] 
split level 6: [2, 82] 
regular batch size: 2*64, diving batch size 1*0

all verified at 0th iter
best_l after optimization:/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:530: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(eps_temp / std).reshape(1, -1, 1, 1)
 -157.42822265625 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.012757062911987305
This batch time : update_bounds func: 0.0367	 prepare: 0.0117	 bound: 0.0131	 transfer: 0.0039	 finalize: 0.0076
Accumulated time: update_bounds func: 7.6141	 prepare: 0.6791	 bound: 6.3617	 transfer: 0.0039	 finalize: 0.4234
batch bounding time:  0.036844730377197266
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0945	 pickout: 0.0009	 decision: 0.0411	 get_bound: 0.0524	 add_domain: 0.0001
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.1040990352630615

Image 920 label 0 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.1902153491973877
920 1.0000000116860974e-07
##### [0:920] Tested against 7 ######
Initial alpha-CROWN verified for label 7 with bound 1.0529277324676514
Image 920 label 7 verification end, final lower bound 1.0529277324676514, upper bound inf, time: 0.0003914833068847656
920 1.0529277324676514
##### [0:920] Tested against 5 ######
Initial alpha-CROWN verified for label 5 with bound 2.5506882667541504
Image 920 label 5 verification end, final lower bound 2.5506882667541504, upper bound inf, time: 0.00038170814514160156
920 2.5506882667541504
##### [0:920] Tested against 1 ######
Initial alpha-CROWN verified for label 1 with bound 4.361494064331055
Image 920 label 1 verification end, final lower bound 4.361494064331055, upper bound inf, time: 0.0003771781921386719
920 4.361494064331055
##### [0:920] Tested against 9 ######
Initial alpha-CROWN verified for label 9 with bound 4.050515174865723
Image 920 label 9 verification end, final lower bound 4.050515174865723, upper bound inf, time: 0.0003669261932373047
920 4.050515174865723
##### [0:920] Tested against 6 ######
groundtruth label, skip!
Result: image 920 verification success (with branch and bound)!
Wall time: 27.12048864364624

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 1): [920]
verification failure idx (total 0): []
final verified acc: 100.0%[1]
verifier is called on 1 examples.
total verified: 1
mean time [cnt:1] (excluding attack success): 25.45056653022766
