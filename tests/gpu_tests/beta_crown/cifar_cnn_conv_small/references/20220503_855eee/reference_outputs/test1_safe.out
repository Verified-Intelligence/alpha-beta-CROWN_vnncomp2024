Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_conv_small_pgd.pth
  name: cifar_conv_small
data:
  start: 373
  end: 374
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR_ERAN
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.00784313725
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 2048
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 120
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 100
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:30:34 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2))
  (1): ReLU()
  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))
  (3): ReLU()
  (4): Flatten()
  (5): Linear(in_features=1152, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([1000, 3, 32, 32]) torch.Size([1000]) torch.Size([1000])
X range: tensor(2.7537) tensor(-2.4291) tensor(0.0238)
Note runnerup label is empty here!
############################
epsilon after preprocessing: tensor([[[[0.0388]],

         [[0.0393]],

         [[0.0390]]]]), data_max = tensor([[[[2.5141]],

         [[2.5968]],

         [[2.7537]]]]), data_min = tensor([[[[-2.4291]],

         [[-2.4183]],

         [[-2.2214]]]])
Task length: 1
saving results to Verified_ret_[cifar_conv_small]_start=373_end=374_iter=20_b=2048_timeout=120_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 373 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 4, correct label 4, image norm 2252.531494140625, logits tensor([ 0.2101, -3.1308,  0.7758,  1.4857,  2.6303,  1.0480, -2.9723,  1.2019,
        -0.5508,  0.7050], device='cuda:0', grad_fn=<SelectBackward>)
##### PGD attack: True label: 4, Tested against: ['all'] ######
pgd prediction: tensor([ 0.0856, -3.0544,  0.6408,  1.8679,  2.0227,  1.2614, -2.8020,  0.7941,
        -0.4348,  0.9962], device='cuda:0', grad_fn=<SqueezeBackward1>)
attack margin tensor([1.9371, 5.0771, 1.3819, 0.1548,    inf, 0.7613, 4.8247, 1.2286, 2.4575,
        1.0265], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[ 0.2101, -3.1308,  0.7758,  1.4857,  2.6303,  1.0480, -2.9723,  1.2019,
         -0.5508,  0.7050]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-0.8527,  2.0722, -1.0524, -1.0419, -0.8185,  2.4029, -1.6222, -0.0507,
         -1.2365]], device='cuda:0') None
best_l after optimization: 1.0453006029129028 with beta sum per layer: []
alpha/beta optimization time: 7.678439140319824
initial alpha-CROWN bounds: tensor([[-0.6736,  2.2355, -0.9420, -0.9456, -0.7177,  2.5116, -1.5046,  0.0972,
         -1.1061]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-1.5046, device='cuda:0', grad_fn=<MinBackward1>)
Sorted order for labels to verify: [3, 5, 9, 7, 2, 0, 8, 6, 1, 4]
##### [0:373] Tested against 3 ######
Model prediction is: tensor([[ 0.2101, -3.1308,  0.7758,  1.4857,  2.6303,  1.0480, -2.9723,  1.2019,
         -0.5508,  0.7050]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 15, 15]) != torch.Size([2, 9, 1, 16, 15, 15]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 6, 6]) != torch.Size([2, 9, 1, 32, 6, 6]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 15, 15])
1 /11 torch.Size([1, 32, 6, 6])
2 /21 torch.Size([1, 100])
best_l after optimization: 0.9455192685127258 with beta sum per layer: []
alpha/beta optimization time: 1.9201560020446777
alpha-CROWN with fixed intermediate bounds: tensor([[-0.9455]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.9455192685127258
layer 0 size torch.Size([3600]) unstable 526
layer 1 size torch.Size([1152]) unstable 163
layer 2 size torch.Size([100]) unstable 49
-----------------
# of unstable neurons: 738
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 15, 15]) pre split depth:  7
batch:  torch.Size([1, 16, 15, 15]) post split depth:  7
splitting decisions: 
split level 0: [2, 91] 
split level 1: [2, 13] 
split level 2: [2, 79] 
split level 3: [2, 7] 
split level 4: [2, 23] 
split level 5: [2, 30] 
split level 6: [2, 34] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -7.025778770446777 with beta sum per layer: [0.0, 0.0, 53.34173583984375]
alpha/beta optimization time: 0.31232571601867676
This batch time : update_bounds func: 0.3376	 prepare: 0.0097	 bound: 0.3127	 transfer: 0.0022	 finalize: 0.0126
Accumulated time: update_bounds func: 0.3376	 prepare: 0.0097	 bound: 0.3127	 transfer: 0.0022	 finalize: 0.0126
batch bounding time:  0.33786702156066895
Current worst splitting domains [lb, ub] (depth):
[-0.41391,   inf] (8), [-0.41355,   inf] (8), [-0.40238,   inf] (8), [-0.40142,   inf] (8), [-0.39045,   inf] (8), [-0.39020,   inf] (8), [-0.38252,   inf] (8), [-0.37884,   inf] (8), [-0.29139,   inf] (8), [-0.28750,   inf] (8), [-0.27102,   inf] (8), [-0.26862,   inf] (8), [-0.25670,   inf] (8), [-0.25214,   inf] (8), [-0.24305,   inf] (8), [-0.24255,   inf] (8), [-0.22100,   inf] (8), [-0.20458,   inf] (8), [-0.20035,   inf] (8), [-0.18199,   inf] (8), 
length of domains: 34
Total time: 0.3988	 pickout: 0.0008	 decision: 0.0419	 get_bound: 0.3545	 add_domain: 0.0016
Current lb:-0.41390830278396606
128 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.16459584236145

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([34, 16, 15, 15]) pre split depth:  2
batch:  torch.Size([34, 16, 15, 15]) post split depth:  2
splitting decisions: 
split level 0: [2, 25] [2, 25] [2, 29] [2, 29] [2, 29] [2, 29] [2, 29] [2, 29] [2, 25] [2, 25] 
split level 1: [2, 29] [2, 29] [2, 25] [2, 25] [2, 25] [2, 25] [2, 25] [2, 25] [2, 29] [2, 29] 
regular batch size: 2*68, diving batch size 1*0
best_l after optimization: 9.55482292175293 with beta sum per layer: [0.0, 0.0, 115.11156463623047]
alpha/beta optimization time: 0.2546863555908203
This batch time : update_bounds func: 0.2811	 prepare: 0.0122	 bound: 0.2550	 transfer: 0.0057	 finalize: 0.0078
Accumulated time: update_bounds func: 0.6187	 prepare: 0.0220	 bound: 0.5677	 transfer: 0.0057	 finalize: 0.0204
batch bounding time:  0.28130364418029785
Current worst splitting domains [lb, ub] (depth):
[-0.33023,   inf] (11), [-0.32975,   inf] (11), [-0.31667,   inf] (11), [-0.31636,   inf] (11), [-0.30521,   inf] (11), [-0.30257,   inf] (11), [-0.29407,   inf] (11), [-0.29330,   inf] (11), [-0.26505,   inf] (11), [-0.26454,   inf] (11), [-0.26429,   inf] (11), [-0.26162,   inf] (11), [-0.25772,   inf] (11), [-0.25746,   inf] (11), [-0.25448,   inf] (11), [-0.25358,   inf] (11), [-0.25163,   inf] (11), [-0.24617,   inf] (11), [-0.24009,   inf] (11), [-0.23797,   inf] (11), 
length of domains: 83
Total time: 0.3602	 pickout: 0.0052	 decision: 0.0528	 get_bound: 0.2983	 add_domain: 0.0040
Current lb:-0.33022552728652954
264 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.5255353450775146

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([83, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([83, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 18] [2, 18] [2, 18] [2, 18] [2, 18] [2, 18] [2, 18] [2, 18] [2, 18] [2, 18] 
regular batch size: 2*83, diving batch size 1*0
best_l after optimization: 17.209680557250977 with beta sum per layer: [0.0, 0.0, 128.70101928710938]
alpha/beta optimization time: 0.25331568717956543
This batch time : update_bounds func: 0.2840	 prepare: 0.0145	 bound: 0.2536	 transfer: 0.0060	 finalize: 0.0095
Accumulated time: update_bounds func: 0.9027	 prepare: 0.0364	 bound: 0.8213	 transfer: 0.0060	 finalize: 0.0300
batch bounding time:  0.2842824459075928
Current worst splitting domains [lb, ub] (depth):
[-0.29175,   inf] (13), [-0.29082,   inf] (13), [-0.27711,   inf] (13), [-0.27647,   inf] (13), [-0.27239,   inf] (13), [-0.27183,   inf] (13), [-0.26667,   inf] (13), [-0.26365,   inf] (13), [-0.26307,   inf] (13), [-0.26208,   inf] (13), [-0.25349,   inf] (13), [-0.25301,   inf] (13), [-0.24819,   inf] (13), [-0.24661,   inf] (13), [-0.24015,   inf] (13), [-0.23659,   inf] (13), [-0.22366,   inf] (13), [-0.22324,   inf] (13), [-0.22215,   inf] (13), [-0.22099,   inf] (13), 
length of domains: 142
Total time: 0.3449	 pickout: 0.0118	 decision: 0.0410	 get_bound: 0.2845	 add_domain: 0.0076
Current lb:-0.29175159335136414
430 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.8716635704040527

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([142, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([142, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 51] [2, 51] [2, 51] [2, 51] [2, 51] [2, 51] [2, 51] [2, 51] [2, 51] [2, 51] 
regular batch size: 2*142, diving batch size 1*0
best_l after optimization: 5.571417808532715 with beta sum per layer: [0.0, 0.0, 231.93954467773438]
alpha/beta optimization time: 0.2688460350036621
This batch time : update_bounds func: 0.3188	 prepare: 0.0238	 bound: 0.2691	 transfer: 0.0089	 finalize: 0.0163
Accumulated time: update_bounds func: 1.2215	 prepare: 0.0602	 bound: 1.0904	 transfer: 0.0089	 finalize: 0.0463
batch bounding time:  0.31915879249572754
Current worst splitting domains [lb, ub] (depth):
[-0.27446,   inf] (15), [-0.27333,   inf] (15), [-0.25942,   inf] (15), [-0.25795,   inf] (15), [-0.25399,   inf] (15), [-0.25382,   inf] (15), [-0.24891,   inf] (15), [-0.24567,   inf] (15), [-0.24461,   inf] (15), [-0.24403,   inf] (15), [-0.23556,   inf] (15), [-0.23410,   inf] (15), [-0.22986,   inf] (15), [-0.22860,   inf] (15), [-0.22078,   inf] (15), [-0.21800,   inf] (15), [-0.20568,   inf] (15), [-0.20430,   inf] (15), [-0.20391,   inf] (15), [-0.20016,   inf] (15), 
length of domains: 135
Total time: 0.4023	 pickout: 0.0188	 decision: 0.0567	 get_bound: 0.3196	 add_domain: 0.0072
Current lb:-0.2744581997394562
714 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.276369571685791

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([135, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([135, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 55] [2, 55] [2, 55] [2, 55] [2, 55] [2, 55] [2, 55] [2, 55] [2, 43] [2, 55] 
regular batch size: 2*135, diving batch size 1*0
best_l after optimization: -3.296978712081909 with beta sum per layer: [0.0, 0.0, 193.10479736328125]
alpha/beta optimization time: 0.2790818214416504
This batch time : update_bounds func: 0.3257	 prepare: 0.0236	 bound: 0.2794	 transfer: 0.0066	 finalize: 0.0155
Accumulated time: update_bounds func: 1.5472	 prepare: 0.0838	 bound: 1.3698	 transfer: 0.0066	 finalize: 0.0618
batch bounding time:  0.32602834701538086
Current worst splitting domains [lb, ub] (depth):
[-0.25765,   inf] (17), [-0.25673,   inf] (17), [-0.24327,   inf] (17), [-0.24179,   inf] (17), [-0.23739,   inf] (17), [-0.23722,   inf] (17), [-0.23257,   inf] (17), [-0.22938,   inf] (17), [-0.22847,   inf] (17), [-0.22776,   inf] (17), [-0.21905,   inf] (17), [-0.21767,   inf] (17), [-0.21351,   inf] (17), [-0.21206,   inf] (17), [-0.20411,   inf] (17), [-0.20124,   inf] (17), [-0.18853,   inf] (17), [-0.18607,   inf] (17), [-0.18529,   inf] (17), [-0.18063,   inf] (17), 
length of domains: 122
Total time: 0.4052	 pickout: 0.0178	 decision: 0.0541	 get_bound: 0.3264	 add_domain: 0.0068
Current lb:-0.2576543092727661
984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.684587240219116

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([122, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([122, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 12] [2, 12] [2, 12] [2, 12] [2, 12] [2, 12] [2, 12] [2, 12] [2, 12] [2, 12] 
regular batch size: 2*122, diving batch size 1*0
best_l after optimization: 12.60550308227539 with beta sum per layer: [0.0, 0.0, 167.15728759765625]
alpha/beta optimization time: 0.26422762870788574
This batch time : update_bounds func: 0.3037	 prepare: 0.0215	 bound: 0.2645	 transfer: 0.0027	 finalize: 0.0143
Accumulated time: update_bounds func: 1.8509	 prepare: 0.1053	 bound: 1.6343	 transfer: 0.0027	 finalize: 0.0761
batch bounding time:  0.3040013313293457
Current worst splitting domains [lb, ub] (depth):
[-0.23742,   inf] (19), [-0.23581,   inf] (19), [-0.23405,   inf] (19), [-0.23183,   inf] (19), [-0.22291,   inf] (19), [-0.22076,   inf] (19), [-0.21893,   inf] (19), [-0.21880,   inf] (19), [-0.21677,   inf] (19), [-0.21592,   inf] (19), [-0.21489,   inf] (19), [-0.21288,   inf] (19), [-0.21257,   inf] (19), [-0.20869,   inf] (19), [-0.20745,   inf] (19), [-0.20702,   inf] (19), [-0.20642,   inf] (19), [-0.20628,   inf] (19), [-0.20552,   inf] (19), [-0.20247,   inf] (19), 
length of domains: 175
Total time: 0.3821	 pickout: 0.0169	 decision: 0.0509	 get_bound: 0.3044	 add_domain: 0.0099
Current lb:-0.23742423951625824
1228 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.068492650985718

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([175, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([175, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 43] [2, 43] [2, 43] [2, 43] [2, 43] [2, 43] [2, 43] [2, 43] [2, 43] [2, 43] 
regular batch size: 2*175, diving batch size 1*0
best_l after optimization: 5.945493698120117 with beta sum per layer: [0.0, 0.0, 232.05364990234375]
alpha/beta optimization time: 0.300828218460083
This batch time : update_bounds func: 0.4147	 prepare: 0.0309	 bound: 0.3012	 transfer: 0.0067	 finalize: 0.0206
Accumulated time: update_bounds func: 2.2656	 prepare: 0.1362	 bound: 1.9355	 transfer: 0.0067	 finalize: 0.0967
batch bounding time:  0.4151465892791748
Current worst splitting domains [lb, ub] (depth):
[-0.22195,   inf] (21), [-0.22017,   inf] (21), [-0.21856,   inf] (21), [-0.21594,   inf] (21), [-0.20720,   inf] (21), [-0.20504,   inf] (21), [-0.20309,   inf] (21), [-0.20291,   inf] (21), [-0.20154,   inf] (21), [-0.20076,   inf] (21), [-0.19983,   inf] (21), [-0.19716,   inf] (21), [-0.19684,   inf] (21), [-0.19310,   inf] (21), [-0.19158,   inf] (21), [-0.19125,   inf] (21), [-0.19061,   inf] (21), [-0.19049,   inf] (21), [-0.18980,   inf] (21), [-0.18630,   inf] (21), 
length of domains: 198
Total time: 0.5247	 pickout: 0.0256	 decision: 0.0714	 get_bound: 0.4157	 add_domain: 0.0120
Current lb:-0.22195294499397278
1578 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.596633195877075

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([198, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([198, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 48] [2, 48] [2, 48] [2, 48] [2, 48] [2, 48] [2, 48] [2, 48] [2, 48] [2, 48] 
regular batch size: 2*198, diving batch size 1*0
best_l after optimization: 1.8481206893920898 with beta sum per layer: [0.0, 0.006672609131783247, 263.21197509765625]
alpha/beta optimization time: 0.3067035675048828
This batch time : update_bounds func: 0.3729	 prepare: 0.0346	 bound: 0.3070	 transfer: 0.0075	 finalize: 0.0230
Accumulated time: update_bounds func: 2.6385	 prepare: 0.1708	 bound: 2.2425	 transfer: 0.0075	 finalize: 0.1197
batch bounding time:  0.3733956813812256
Current worst splitting domains [lb, ub] (depth):
[-0.20691,   inf] (23), [-0.20524,   inf] (23), [-0.20360,   inf] (23), [-0.20083,   inf] (23), [-0.19206,   inf] (23), [-0.19002,   inf] (23), [-0.18816,   inf] (23), [-0.18787,   inf] (23), [-0.18627,   inf] (23), [-0.18571,   inf] (23), [-0.18471,   inf] (23), [-0.18184,   inf] (23), [-0.18167,   inf] (23), [-0.17656,   inf] (23), [-0.17648,   inf] (23), [-0.17562,   inf] (23), [-0.17463,   inf] (23), [-0.17440,   inf] (23), [-0.17382,   inf] (23), [-0.17144,   inf] (23), 
length of domains: 200
Total time: 0.4868	 pickout: 0.0267	 decision: 0.0735	 get_bound: 0.3740	 add_domain: 0.0126
Current lb:-0.20691382884979248
1974 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.090850830078125

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([200, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([200, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 1109] [1, 1109] [1, 1109] [1, 1109] [1, 170] [1, 170] [1, 1109] [1, 170] [1, 170] [1, 170] 
regular batch size: 2*200, diving batch size 1*0
best_l after optimization: 16.121501922607422 with beta sum per layer: [0.0, 2.824518918991089, 243.1580810546875]
alpha/beta optimization time: 0.32000207901000977
This batch time : update_bounds func: 0.3855	 prepare: 0.0355	 bound: 0.3203	 transfer: 0.0058	 finalize: 0.0229
Accumulated time: update_bounds func: 3.0240	 prepare: 0.2063	 bound: 2.5628	 transfer: 0.0058	 finalize: 0.1426
batch bounding time:  0.38596487045288086
Current worst splitting domains [lb, ub] (depth):
[-0.19447,   inf] (25), [-0.19156,   inf] (25), [-0.18986,   inf] (25), [-0.18802,   inf] (25), [-0.17711,   inf] (25), [-0.17494,   inf] (25), [-0.17467,   inf] (25), [-0.17352,   inf] (25), [-0.17247,   inf] (25), [-0.17170,   inf] (25), [-0.17136,   inf] (25), [-0.17061,   inf] (25), [-0.17033,   inf] (25), [-0.16954,   inf] (25), [-0.16907,   inf] (25), [-0.16821,   inf] (25), [-0.16532,   inf] (25), [-0.16470,   inf] (25), [-0.16421,   inf] (25), [-0.16357,   inf] (25), 
length of domains: 276
Total time: 0.5068	 pickout: 0.0281	 decision: 0.0733	 get_bound: 0.3866	 add_domain: 0.0189
Current lb:-0.19446596503257751
2374 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.601384162902832

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([276, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([276, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 170] [2, 49] [2, 49] [2, 49] [1, 1109] [1, 1109] [1, 170] [1, 1109] [1, 1109] [1, 1109] 
regular batch size: 2*276, diving batch size 1*0
best_l after optimization: 23.989477157592773 with beta sum per layer: [0.0, 9.72348403930664, 322.2990417480469]
alpha/beta optimization time: 0.3455827236175537
This batch time : update_bounds func: 0.4837	 prepare: 0.0520	 bound: 0.3459	 transfer: 0.0152	 finalize: 0.0323
Accumulated time: update_bounds func: 3.5077	 prepare: 0.2583	 bound: 2.9087	 transfer: 0.0152	 finalize: 0.1750
batch bounding time:  0.4842660427093506
Current worst splitting domains [lb, ub] (depth):
[-0.18237,   inf] (27), [-0.17710,   inf] (27), [-0.17606,   inf] (27), [-0.17538,   inf] (27), [-0.17364,   inf] (27), [-0.16449,   inf] (27), [-0.16109,   inf] (27), [-0.16056,   inf] (27), [-0.15994,   inf] (27), [-0.15983,   inf] (27), [-0.15980,   inf] (27), [-0.15895,   inf] (27), [-0.15884,   inf] (27), [-0.15820,   inf] (27), [-0.15668,   inf] (27), [-0.15656,   inf] (27), [-0.15612,   inf] (27), [-0.15521,   inf] (27), [-0.15492,   inf] (27), [-0.15374,   inf] (27), 
length of domains: 397
Total time: 0.6483	 pickout: 0.0395	 decision: 0.0953	 get_bound: 0.4851	 add_domain: 0.0284
Current lb:-0.1823701560497284
2926 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.254729270935059

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([397, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([397, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 49] [1, 170] [2, 49] [2, 31] [2, 31] [2, 49] [2, 49] [2, 49] [2, 49] [2, 49] 
regular batch size: 2*397, diving batch size 1*0
best_l after optimization: 26.255651473999023 with beta sum per layer: [0.0, 20.963212966918945, 449.9332275390625]
alpha/beta optimization time: 0.42317628860473633
This batch time : update_bounds func: 0.5590	 prepare: 0.0746	 bound: 0.4235	 transfer: 0.0128	 finalize: 0.0462
Accumulated time: update_bounds func: 4.0667	 prepare: 0.3329	 bound: 3.3322	 transfer: 0.0128	 finalize: 0.2211
batch bounding time:  0.5597095489501953
Current worst splitting domains [lb, ub] (depth):
[-0.16818,   inf] (29), [-0.16497,   inf] (29), [-0.16438,   inf] (29), [-0.16325,   inf] (29), [-0.16196,   inf] (29), [-0.15896,   inf] (29), [-0.14993,   inf] (29), [-0.14671,   inf] (29), [-0.14640,   inf] (29), [-0.14599,   inf] (29), [-0.14534,   inf] (29), [-0.14516,   inf] (29), [-0.14509,   inf] (29), [-0.14422,   inf] (29), [-0.14405,   inf] (29), [-0.14398,   inf] (29), [-0.14337,   inf] (29), [-0.14233,   inf] (29), [-0.14193,   inf] (29), [-0.14167,   inf] (29), 
length of domains: 514
Total time: 0.7830	 pickout: 0.0558	 decision: 0.1285	 get_bound: 0.5609	 add_domain: 0.0378
Current lb:-0.16818071901798248
3720 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.04547929763794

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([514, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([514, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 31] [1, 170] [2, 31] [1, 493] [2, 31] [2, 31] [2, 31] [2, 31] [2, 31] [2, 31] 
regular batch size: 2*514, diving batch size 1*0
best_l after optimization: -3.493961811065674 with beta sum per layer: [0.0, 42.860076904296875, 564.8109741210938]
alpha/beta optimization time: 0.5001223087310791
This batch time : update_bounds func: 0.6761	 prepare: 0.0950	 bound: 0.5004	 transfer: 0.0187	 finalize: 0.0596
Accumulated time: update_bounds func: 4.7428	 prepare: 0.4279	 bound: 3.8327	 transfer: 0.0187	 finalize: 0.2807
batch bounding time:  0.677025318145752
Current worst splitting domains [lb, ub] (depth):
[-0.15748,   inf] (31), [-0.15434,   inf] (31), [-0.15382,   inf] (31), [-0.15240,   inf] (31), [-0.15137,   inf] (31), [-0.14844,   inf] (31), [-0.14709,   inf] (31), [-0.13937,   inf] (31), [-0.13590,   inf] (31), [-0.13532,   inf] (31), [-0.13514,   inf] (31), [-0.13500,   inf] (31), [-0.13482,   inf] (31), [-0.13463,   inf] (31), [-0.13373,   inf] (31), [-0.13338,   inf] (31), [-0.13308,   inf] (31), [-0.13265,   inf] (31), [-0.13154,   inf] (31), [-0.13139,   inf] (31), 
length of domains: 616
Total time: 1.0011	 pickout: 0.0725	 decision: 0.2027	 get_bound: 0.6785	 add_domain: 0.0475
Current lb:-0.15747511386871338
4748 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.057224988937378

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([616, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([616, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 493] [1, 170] [2, 86] [2, 86] [1, 493] [2, 86] [2, 86] [2, 86] [2, 60] [2, 86] 
regular batch size: 2*616, diving batch size 1*0
best_l after optimization: -35.54560852050781 with beta sum per layer: [0.0, 51.023948669433594, 601.7708740234375]
alpha/beta optimization time: 0.5599019527435303
This batch time : update_bounds func: 0.7858	 prepare: 0.1156	 bound: 0.5602	 transfer: 0.0298	 finalize: 0.0773
Accumulated time: update_bounds func: 5.5285	 prepare: 0.5434	 bound: 4.3929	 transfer: 0.0298	 finalize: 0.3580
batch bounding time:  0.786860466003418
Current worst splitting domains [lb, ub] (depth):
[-0.14916,   inf] (33), [-0.14561,   inf] (33), [-0.14411,   inf] (33), [-0.14326,   inf] (33), [-0.14278,   inf] (33), [-0.14024,   inf] (33), [-0.13886,   inf] (33), [-0.13732,   inf] (33), [-0.13104,   inf] (33), [-0.12712,   inf] (33), [-0.12676,   inf] (33), [-0.12649,   inf] (33), [-0.12616,   inf] (33), [-0.12581,   inf] (33), [-0.12526,   inf] (33), [-0.12520,   inf] (33), [-0.12422,   inf] (33), [-0.12421,   inf] (33), [-0.12395,   inf] (33), [-0.12312,   inf] (33), 
length of domains: 770
Total time: 1.1717	 pickout: 0.0889	 decision: 0.2333	 get_bound: 0.7887	 add_domain: 0.0608
Current lb:-0.1491587907075882
5980 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.24176549911499

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([770, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([770, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 60] [2, 60] [2, 60] [2, 60] [2, 60] [2, 60] [2, 60] [2, 60] [2, 60] [2, 86] 
regular batch size: 2*770, diving batch size 1*0
best_l after optimization: -11.293200492858887 with beta sum per layer: [0.0, 85.68212890625, 761.4908447265625]
alpha/beta optimization time: 0.6601157188415527
This batch time : update_bounds func: 0.9287	 prepare: 0.1470	 bound: 0.6605	 transfer: 0.0261	 finalize: 0.0912
Accumulated time: update_bounds func: 6.4572	 prepare: 0.6905	 bound: 5.0534	 transfer: 0.0261	 finalize: 0.4492
batch bounding time:  0.9300622940063477
Current worst splitting domains [lb, ub] (depth):
[-0.13778,   inf] (35), [-0.13403,   inf] (35), [-0.13262,   inf] (35), [-0.13192,   inf] (35), [-0.13155,   inf] (35), [-0.12869,   inf] (35), [-0.12742,   inf] (35), [-0.12624,   inf] (35), [-0.11960,   inf] (35), [-0.11862,   inf] (35), [-0.11777,   inf] (35), [-0.11763,   inf] (35), [-0.11733,   inf] (35), [-0.11678,   inf] (35), [-0.11608,   inf] (35), [-0.11552,   inf] (35), [-0.11504,   inf] (35), [-0.11455,   inf] (35), [-0.11452,   inf] (35), [-0.11397,   inf] (35), 
length of domains: 1005
Total time: 1.4070	 pickout: 0.1106	 decision: 0.2821	 get_bound: 0.9324	 add_domain: 0.0820
Current lb:-0.1377774029970169
7520 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.66465139389038

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1005, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1005, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 27] [2, 27] [2, 27] [2, 27] [2, 27] [2, 27] [2, 27] [2, 27] [2, 27] [2, 60] 
regular batch size: 2*1005, diving batch size 1*0
best_l after optimization: 5.566534996032715 with beta sum per layer: [0.0, 130.30740356445312, 1064.818359375]
alpha/beta optimization time: 0.8220691680908203
This batch time : update_bounds func: 1.2438	 prepare: 0.2043	 bound: 0.8224	 transfer: 0.0383	 finalize: 0.1736
Accumulated time: update_bounds func: 7.7010	 prepare: 0.8947	 bound: 5.8758	 transfer: 0.0383	 finalize: 0.6227
batch bounding time:  1.2455997467041016
Current worst splitting domains [lb, ub] (depth):
[-0.12761,   inf] (37), [-0.12389,   inf] (37), [-0.12243,   inf] (37), [-0.12172,   inf] (37), [-0.12117,   inf] (37), [-0.11854,   inf] (37), [-0.11725,   inf] (37), [-0.11590,   inf] (37), [-0.10931,   inf] (37), [-0.10883,   inf] (37), [-0.10794,   inf] (37), [-0.10729,   inf] (37), [-0.10640,   inf] (37), [-0.10623,   inf] (37), [-0.10546,   inf] (37), [-0.10516,   inf] (37), [-0.10468,   inf] (37), [-0.10465,   inf] (37), [-0.10421,   inf] (37), [-0.10369,   inf] (37), 
length of domains: 1219
Total time: 1.8662	 pickout: 0.1485	 decision: 0.3654	 get_bound: 1.2486	 add_domain: 0.1037
Current lb:-0.1276077926158905
9530 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.55232858657837

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1219, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1219, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 86] [1, 493] [1, 493] [2, 86] [2, 86] [1, 493] [1, 493] [2, 86] [1, 493] [2, 27] 
regular batch size: 2*1219, diving batch size 1*0
best_l after optimization: -13.13311767578125 with beta sum per layer: [0.0, 174.0078887939453, 1282.940185546875]
alpha/beta optimization time: 0.9606766700744629
This batch time : update_bounds func: 1.4481	 prepare: 0.2316	 bound: 0.9610	 transfer: 0.0450	 finalize: 0.2037
Accumulated time: update_bounds func: 9.1491	 prepare: 1.1263	 bound: 6.8369	 transfer: 0.0450	 finalize: 0.8265
batch bounding time:  1.4501593112945557
Current worst splitting domains [lb, ub] (depth):
[-0.11964,   inf] (39), [-0.11594,   inf] (39), [-0.11411,   inf] (39), [-0.11374,   inf] (39), [-0.11298,   inf] (39), [-0.11084,   inf] (39), [-0.10913,   inf] (39), [-0.10770,   inf] (39), [-0.10182,   inf] (39), [-0.09832,   inf] (39), [-0.09820,   inf] (39), [-0.09742,   inf] (39), [-0.09726,   inf] (39), [-0.09725,   inf] (39), [-0.09706,   inf] (39), [-0.09679,   inf] (39), [-0.09607,   inf] (39), [-0.09563,   inf] (39), [-0.09507,   inf] (39), [-0.09425,   inf] (39), 
length of domains: 1319
Total time: 2.1740	 pickout: 0.1798	 decision: 0.4236	 get_bound: 1.4538	 add_domain: 0.1168
Current lb:-0.11963534355163574
11968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.754866123199463

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1319, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1319, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 80] [2, 80] [2, 80] [2, 80] [2, 80] [2, 80] [2, 80] [2, 80] [1, 504] [1, 493] 
regular batch size: 2*1319, diving batch size 1*0
best_l after optimization: -61.53670120239258 with beta sum per layer: [0.0, 201.7147979736328, 1312.0157470703125]
alpha/beta optimization time: 1.0250518321990967
This batch time : update_bounds func: 1.5545	 prepare: 0.2529	 bound: 1.0254	 transfer: 0.0568	 finalize: 0.2126
Accumulated time: update_bounds func: 10.7036	 prepare: 1.3792	 bound: 7.8623	 transfer: 0.0568	 finalize: 1.0391
batch bounding time:  1.5570755004882812
Current worst splitting domains [lb, ub] (depth):
[-0.11269,   inf] (41), [-0.10894,   inf] (41), [-0.10714,   inf] (41), [-0.10665,   inf] (41), [-0.10605,   inf] (41), [-0.10373,   inf] (41), [-0.10205,   inf] (41), [-0.10065,   inf] (41), [-0.09433,   inf] (41), [-0.09140,   inf] (41), [-0.09080,   inf] (41), [-0.09023,   inf] (41), [-0.09016,   inf] (41), [-0.09007,   inf] (41), [-0.08960,   inf] (41), [-0.08886,   inf] (41), [-0.08879,   inf] (41), [-0.08790,   inf] (41), [-0.08777,   inf] (41), [-0.08717,   inf] (41), 
length of domains: 1254
Total time: 2.3305	 pickout: 0.1973	 decision: 0.4559	 get_bound: 1.5619	 add_domain: 0.1154
Current lb:-0.11268892884254456
14606 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.117009162902832

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1254, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1254, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 504] [2, 96] [1, 1111] [1, 504] [1, 504] [2, 96] [1, 1111] [1, 504] [2, 80] [1, 343] 
regular batch size: 2*1254, diving batch size 1*0
best_l after optimization: -26.716161727905273 with beta sum per layer: [0.0, 172.9093475341797, 1161.225830078125]
alpha/beta optimization time: 0.9795804023742676
This batch time : update_bounds func: 1.4709	 prepare: 0.2369	 bound: 0.9799	 transfer: 0.0451	 finalize: 0.1483
Accumulated time: update_bounds func: 12.1744	 prepare: 1.6160	 bound: 8.8422	 transfer: 0.0451	 finalize: 1.1873
batch bounding time:  1.473076343536377
Current worst splitting domains [lb, ub] (depth):
[-0.10664,   inf] (43), [-0.10319,   inf] (43), [-0.10060,   inf] (43), [-0.09951,   inf] (43), [-0.09849,   inf] (43), [-0.09798,   inf] (43), [-0.09739,   inf] (43), [-0.09428,   inf] (43), [-0.09408,   inf] (43), [-0.09167,   inf] (43), [-0.09135,   inf] (43), [-0.09060,   inf] (43), [-0.08716,   inf] (43), [-0.08523,   inf] (43), [-0.08449,   inf] (43), [-0.08334,   inf] (43), [-0.08333,   inf] (43), [-0.08282,   inf] (43), [-0.08275,   inf] (43), [-0.08243,   inf] (43), 
length of domains: 1403
Total time: 2.2303	 pickout: 0.1901	 decision: 0.4333	 get_bound: 1.4768	 add_domain: 0.1301
Current lb:-0.10663831233978271
17114 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 20.377438068389893

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1403, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1403, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 96] [1, 1111] [2, 96] [2, 96] [2, 96] [1, 1111] [2, 96] [1, 486] [2, 96] [2, 96] 
regular batch size: 2*1403, diving batch size 1*0
best_l after optimization: -37.050209045410156 with beta sum per layer: [0.0, 205.49139404296875, 1184.04931640625]
alpha/beta optimization time: 1.082554578781128
This batch time : update_bounds func: 1.6700	 prepare: 0.2695	 bound: 1.0829	 transfer: 0.0647	 finalize: 0.2454
Accumulated time: update_bounds func: 13.8445	 prepare: 1.8856	 bound: 9.9252	 transfer: 0.0647	 finalize: 1.4327
batch bounding time:  1.672820806503296
Current worst splitting domains [lb, ub] (depth):
[-0.10097,   inf] (45), [-0.09493,   inf] (45), [-0.09444,   inf] (45), [-0.09379,   inf] (45), [-0.09264,   inf] (45), [-0.09168,   inf] (45), [-0.09016,   inf] (45), [-0.08842,   inf] (45), [-0.08768,   inf] (45), [-0.08764,   inf] (45), [-0.08568,   inf] (45), [-0.08540,   inf] (45), [-0.08490,   inf] (45), [-0.08174,   inf] (45), [-0.07950,   inf] (45), [-0.07810,   inf] (45), [-0.07787,   inf] (45), [-0.07725,   inf] (45), [-0.07692,   inf] (45), [-0.07691,   inf] (45), 
length of domains: 1568
Total time: 2.5945	 pickout: 0.2244	 decision: 0.5427	 get_bound: 1.6774	 add_domain: 0.1501
Current lb:-0.10097040235996246
19920 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 23.007543802261353

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1568, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1568, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 486] [1, 486] [1, 486] [1, 486] [1, 486] [1, 486] [1, 486] [1, 486] [1, 486] [2, 96] 
regular batch size: 2*1568, diving batch size 1*0
best_l after optimization: -25.394174575805664 with beta sum per layer: [0.0, 240.22930908203125, 1241.7431640625]
alpha/beta optimization time: 1.1847665309906006
This batch time : update_bounds func: 1.8108	 prepare: 0.3037	 bound: 1.1851	 transfer: 0.0630	 finalize: 0.2506
Accumulated time: update_bounds func: 15.6553	 prepare: 2.1893	 bound: 11.1103	 transfer: 0.0630	 finalize: 1.6833
batch bounding time:  1.813821792602539
Current worst splitting domains [lb, ub] (depth):
[-0.09595,   inf] (47), [-0.08992,   inf] (47), [-0.08849,   inf] (47), [-0.08792,   inf] (47), [-0.08658,   inf] (47), [-0.08600,   inf] (47), [-0.08364,   inf] (47), [-0.08311,   inf] (47), [-0.08183,   inf] (47), [-0.08074,   inf] (47), [-0.08061,   inf] (47), [-0.07951,   inf] (47), [-0.07854,   inf] (47), [-0.07634,   inf] (47), [-0.07414,   inf] (47), [-0.07324,   inf] (47), [-0.07258,   inf] (47), [-0.07193,   inf] (47), [-0.07188,   inf] (47), [-0.07114,   inf] (47), 
length of domains: 1785
Total time: 2.7775	 pickout: 0.2387	 decision: 0.5442	 get_bound: 1.8189	 add_domain: 0.1757
Current lb:-0.09595352411270142
23056 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 25.82219672203064

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1785, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([1785, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 331] [1, 331] [1, 171] [1, 235] [1, 478] [1, 235] [1, 235] [1, 171] [1, 235] [1, 235] 
regular batch size: 2*1785, diving batch size 1*0
best_l after optimization: -5.194124698638916 with beta sum per layer: [0.002561195520684123, 306.2981872558594, 1239.4853515625]
alpha/beta optimization time: 1.386765480041504
This batch time : update_bounds func: 2.1051	 prepare: 0.3417	 bound: 1.3872	 transfer: 0.0834	 finalize: 0.2831
Accumulated time: update_bounds func: 17.7604	 prepare: 2.5309	 bound: 12.4975	 transfer: 0.0834	 finalize: 1.9664
batch bounding time:  2.1083967685699463
Current worst splitting domains [lb, ub] (depth):
[-0.08906,   inf] (49), [-0.08679,   inf] (49), [-0.08299,   inf] (49), [-0.08295,   inf] (49), [-0.08185,   inf] (49), [-0.08073,   inf] (49), [-0.07955,   inf] (49), [-0.07749,   inf] (49), [-0.07730,   inf] (49), [-0.07696,   inf] (49), [-0.07664,   inf] (49), [-0.07513,   inf] (49), [-0.07503,   inf] (49), [-0.07391,   inf] (49), [-0.07361,   inf] (49), [-0.07326,   inf] (49), [-0.07248,   inf] (49), [-0.07214,   inf] (49), [-0.07198,   inf] (49), [-0.07161,   inf] (49), 
length of domains: 2151
Total time: 3.2749	 pickout: 0.2705	 decision: 0.6737	 get_bound: 2.1140	 add_domain: 0.2167
Current lb:-0.08906253427267075
26626 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 29.137336015701294

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 478] [1, 478] [1, 478] [1, 235] [1, 331] [1, 478] [1, 343] [1, 343] [1, 235] [1, 343] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: -0.5498099327087402 with beta sum per layer: [0.02419927529990673, 378.3370361328125, 1209.2593994140625]
alpha/beta optimization time: 1.5596373081207275
This batch time : update_bounds func: 2.3578	 prepare: 0.3882	 bound: 1.5600	 transfer: 0.0832	 finalize: 0.3155
Accumulated time: update_bounds func: 20.1182	 prepare: 2.9192	 bound: 14.0575	 transfer: 0.0832	 finalize: 2.2819
batch bounding time:  2.3617136478424072
Current worst splitting domains [lb, ub] (depth):
[-0.08438,   inf] (51), [-0.08202,   inf] (51), [-0.07833,   inf] (51), [-0.07597,   inf] (51), [-0.07560,   inf] (51), [-0.07490,   inf] (51), [-0.07449,   inf] (51), [-0.07290,   inf] (51), [-0.07065,   inf] (51), [-0.07030,   inf] (51), [-0.06998,   inf] (51), [-0.06925,   inf] (51), [-0.06892,   inf] (51), [-0.06886,   inf] (51), [-0.06872,   inf] (51), [-0.06852,   inf] (51), [-0.06833,   inf] (51), [-0.06826,   inf] (51), [-0.06795,   inf] (51), [-0.06687,   inf] (51), 
length of domains: 2588
Total time: 3.8839	 pickout: 0.3090	 decision: 0.8559	 get_bound: 2.3683	 add_domain: 0.3508
Current lb:-0.08437798172235489
30722 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 33.06810450553894

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 235] [1, 235] [1, 235] [1, 235] [1, 331] [1, 235] [1, 331] [1, 235] [1, 478] [1, 478] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 34.99229431152344 with beta sum per layer: [0.07375351339578629, 392.8417663574219, 1011.8106689453125]
alpha/beta optimization time: 1.5535552501678467
This batch time : update_bounds func: 2.3840	 prepare: 0.3869	 bound: 1.5539	 transfer: 0.0980	 finalize: 0.3342
Accumulated time: update_bounds func: 22.5021	 prepare: 3.3060	 bound: 15.6114	 transfer: 0.0980	 finalize: 2.6162
batch bounding time:  2.3878471851348877
Current worst splitting domains [lb, ub] (depth):
[-0.07736,   inf] (53), [-0.07566,   inf] (53), [-0.07501,   inf] (53), [-0.07340,   inf] (53), [-0.07139,   inf] (53), [-0.06965,   inf] (53), [-0.06905,   inf] (53), [-0.06902,   inf] (53), [-0.06792,   inf] (53), [-0.06786,   inf] (53), [-0.06748,   inf] (53), [-0.06710,   inf] (53), [-0.06616,   inf] (53), [-0.06587,   inf] (53), [-0.06584,   inf] (53), [-0.06565,   inf] (53), [-0.06529,   inf] (53), [-0.06419,   inf] (53), [-0.06356,   inf] (53), [-0.06341,   inf] (53), 
length of domains: 3373
Total time: 3.7918	 pickout: 0.3223	 decision: 0.7704	 get_bound: 2.3944	 add_domain: 0.3047
Current lb:-0.0773584172129631
34818 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 36.90637969970703

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 171] [1, 171] [1, 171] [1, 171] [1, 171] [1, 171] [1, 171] [1, 478] [1, 478] [1, 171] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 47.18705368041992 with beta sum per layer: [0.04217475280165672, 399.5787353515625, 829.6605834960938]
alpha/beta optimization time: 1.5705797672271729
This batch time : update_bounds func: 2.4215	 prepare: 0.3925	 bound: 1.5710	 transfer: 0.0994	 finalize: 0.3476
Accumulated time: update_bounds func: 24.9237	 prepare: 3.6985	 bound: 17.1824	 transfer: 0.0994	 finalize: 2.9637
batch bounding time:  2.4257125854492188
Current worst splitting domains [lb, ub] (depth):
[-0.07241,   inf] (55), [-0.07074,   inf] (55), [-0.07006,   inf] (55), [-0.06850,   inf] (55), [-0.06627,   inf] (55), [-0.06482,   inf] (55), [-0.06476,   inf] (55), [-0.06461,   inf] (55), [-0.06393,   inf] (55), [-0.06367,   inf] (55), [-0.06301,   inf] (55), [-0.06294,   inf] (55), [-0.06281,   inf] (55), [-0.06244,   inf] (55), [-0.06241,   inf] (55), [-0.06155,   inf] (55), [-0.06125,   inf] (55), [-0.06091,   inf] (55), [-0.06077,   inf] (55), [-0.06035,   inf] (55), 
length of domains: 4518
Total time: 4.0442	 pickout: 0.3151	 decision: 0.8097	 get_bound: 2.4324	 add_domain: 0.4869
Current lb:-0.07240767776966095
38914 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 40.99581837654114

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 313] [1, 313] [1, 313] [1, 313] [1, 313] [1, 111] [1, 313] [1, 313] [1, 313] [1, 111] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 51.74641418457031 with beta sum per layer: [0.045134320855140686, 420.312744140625, 681.3014526367188]
alpha/beta optimization time: 1.5579369068145752
This batch time : update_bounds func: 2.5586	 prepare: 0.3907	 bound: 1.5583	 transfer: 0.1044	 finalize: 0.3803
Accumulated time: update_bounds func: 27.4823	 prepare: 4.0892	 bound: 18.7407	 transfer: 0.1044	 finalize: 3.3441
batch bounding time:  2.5627031326293945
Current worst splitting domains [lb, ub] (depth):
[-0.06693,   inf] (57), [-0.06541,   inf] (57), [-0.06456,   inf] (57), [-0.06318,   inf] (57), [-0.06129,   inf] (57), [-0.05979,   inf] (57), [-0.05908,   inf] (57), [-0.05892,   inf] (57), [-0.05867,   inf] (57), [-0.05756,   inf] (57), [-0.05752,   inf] (57), [-0.05747,   inf] (57), [-0.05663,   inf] (57), [-0.05662,   inf] (57), [-0.05636,   inf] (57), [-0.05538,   inf] (57), [-0.05524,   inf] (57), [-0.05480,   inf] (57), [-0.05470,   inf] (57), [-0.05462,   inf] (57), 
length of domains: 5935
Total time: 4.0114	 pickout: 0.3164	 decision: 0.7297	 get_bound: 2.5696	 add_domain: 0.3958
Current lb:-0.06693381071090698
43010 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 45.05187225341797

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 111] [1, 111] [1, 111] [1, 111] [1, 111] [1, 111] [1, 111] [1, 111] [1, 485] [1, 111] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 50.56452178955078 with beta sum per layer: [0.07469180226325989, 452.73992919921875, 547.131591796875]
alpha/beta optimization time: 1.5641956329345703
This batch time : update_bounds func: 2.6533	 prepare: 0.4016	 bound: 1.5646	 transfer: 0.1038	 finalize: 0.4302
Accumulated time: update_bounds func: 30.1356	 prepare: 4.4908	 bound: 20.3053	 transfer: 0.1038	 finalize: 3.7743
batch bounding time:  2.6572766304016113
Current worst splitting domains [lb, ub] (depth):
[-0.06046,   inf] (59), [-0.05891,   inf] (59), [-0.05809,   inf] (59), [-0.05807,   inf] (59), [-0.05669,   inf] (59), [-0.05651,   inf] (59), [-0.05538,   inf] (59), [-0.05485,   inf] (59), [-0.05474,   inf] (59), [-0.05393,   inf] (59), [-0.05358,   inf] (59), [-0.05338,   inf] (59), [-0.05271,   inf] (59), [-0.05251,   inf] (59), [-0.05246,   inf] (59), [-0.05241,   inf] (59), [-0.05136,   inf] (59), [-0.05110,   inf] (59), [-0.05100,   inf] (59), [-0.05090,   inf] (59), 
length of domains: 7425
Total time: 4.1628	 pickout: 0.3246	 decision: 0.7602	 get_bound: 2.6639	 add_domain: 0.4141
Current lb:-0.060455597937107086
47106 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 49.25998091697693

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 420] [1, 420] [1, 420] [1, 420] [1, 420] [1, 420] [1, 420] [1, 420] [1, 274] [1, 420] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 46.9969596862793 with beta sum per layer: [0.031126756221055984, 435.99932861328125, 440.2662353515625]
alpha/beta optimization time: 1.5603969097137451
This batch time : update_bounds func: 2.6471	 prepare: 0.4065	 bound: 1.5608	 transfer: 0.1044	 finalize: 0.5636
Accumulated time: update_bounds func: 32.7827	 prepare: 4.8973	 bound: 21.8661	 transfer: 0.1044	 finalize: 4.3379
batch bounding time:  2.6515393257141113
Current worst splitting domains [lb, ub] (depth):
[-0.05353,   inf] (61), [-0.05323,   inf] (61), [-0.05190,   inf] (61), [-0.05165,   inf] (61), [-0.05113,   inf] (61), [-0.05108,   inf] (61), [-0.05085,   inf] (61), [-0.05078,   inf] (61), [-0.04960,   inf] (61), [-0.04951,   inf] (61), [-0.04932,   inf] (61), [-0.04925,   inf] (61), [-0.04838,   inf] (61), [-0.04814,   inf] (61), [-0.04808,   inf] (61), [-0.04779,   inf] (61), [-0.04765,   inf] (61), [-0.04754,   inf] (61), [-0.04699,   inf] (61), [-0.04688,   inf] (61), 
length of domains: 8901
Total time: 4.4168	 pickout: 0.3181	 decision: 0.7826	 get_bound: 2.6593	 add_domain: 0.6567
Current lb:-0.05353084206581116
51202 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 53.72271132469177

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 485] [1, 485] [1, 485] [1, 485] [1, 485] [1, 485] [1, 485] [1, 485] [1, 485] [1, 485] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 34.19763946533203 with beta sum per layer: [0.030552376061677933, 443.88824462890625, 335.26568603515625]
alpha/beta optimization time: 1.5586357116699219
This batch time : update_bounds func: 2.6607	 prepare: 0.6150	 bound: 1.5591	 transfer: 0.1029	 finalize: 0.3723
Accumulated time: update_bounds func: 35.4434	 prepare: 5.5123	 bound: 23.4252	 transfer: 0.1029	 finalize: 4.7101
batch bounding time:  2.6655943393707275
Current worst splitting domains [lb, ub] (depth):
[-0.04913,   inf] (63), [-0.04882,   inf] (63), [-0.04748,   inf] (63), [-0.04724,   inf] (63), [-0.04674,   inf] (63), [-0.04668,   inf] (63), [-0.04645,   inf] (63), [-0.04635,   inf] (63), [-0.04522,   inf] (63), [-0.04508,   inf] (63), [-0.04494,   inf] (63), [-0.04487,   inf] (63), [-0.04397,   inf] (63), [-0.04372,   inf] (63), [-0.04330,   inf] (63), [-0.04324,   inf] (63), [-0.04314,   inf] (63), [-0.04292,   inf] (63), [-0.04248,   inf] (63), [-0.04222,   inf] (63), 
length of domains: 9994
Total time: 4.7219	 pickout: 0.4374	 decision: 0.9776	 get_bound: 2.6738	 add_domain: 0.6332
Current lb:-0.04912915825843811
55298 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 58.49535036087036

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 274] [1, 274] [1, 274] [1, 274] [1, 274] [1, 274] [1, 274] [1, 274] [1, 274] [1, 274] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 18.45332908630371 with beta sum per layer: [0.01893499121069908, 415.77569580078125, 370.76910400390625]
alpha/beta optimization time: 1.560713291168213
This batch time : update_bounds func: 2.8129	 prepare: 0.6271	 bound: 1.5612	 transfer: 0.1045	 finalize: 0.5088
Accumulated time: update_bounds func: 38.2563	 prepare: 6.1394	 bound: 24.9864	 transfer: 0.1045	 finalize: 5.2189
batch bounding time:  2.8169448375701904
Current worst splitting domains [lb, ub] (depth):
[-0.04325,   inf] (65), [-0.04291,   inf] (65), [-0.04191,   inf] (65), [-0.04159,   inf] (65), [-0.04158,   inf] (65), [-0.04135,   inf] (65), [-0.04090,   inf] (65), [-0.04080,   inf] (65), [-0.04058,   inf] (65), [-0.04043,   inf] (65), [-0.04031,   inf] (65), [-0.04009,   inf] (65), [-0.03958,   inf] (65), [-0.03944,   inf] (65), [-0.03929,   inf] (65), [-0.03926,   inf] (65), [-0.03921,   inf] (65), [-0.03912,   inf] (65), [-0.03900,   inf] (65), [-0.03898,   inf] (65), 
length of domains: 11143
Total time: 4.6575	 pickout: 0.4444	 decision: 0.9828	 get_bound: 2.8238	 add_domain: 0.4064
Current lb:-0.04325047507882118
59394 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 63.20510244369507

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 56] [2, 56] [2, 56] [2, 56] [2, 56] [2, 56] [2, 56] [2, 56] [2, 56] [2, 56] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: -1.8328057527542114 with beta sum per layer: [0.2919944226741791, 404.68133544921875, 410.02276611328125]
alpha/beta optimization time: 1.558356761932373
This batch time : update_bounds func: 2.6542	 prepare: 0.4182	 bound: 1.5588	 transfer: 0.1039	 finalize: 0.5615
Accumulated time: update_bounds func: 40.9104	 prepare: 6.5576	 bound: 26.5451	 transfer: 0.1039	 finalize: 5.7805
batch bounding time:  2.658299207687378
Current worst splitting domains [lb, ub] (depth):
[-0.03899,   inf] (67), [-0.03868,   inf] (67), [-0.03762,   inf] (67), [-0.03732,   inf] (67), [-0.03732,   inf] (67), [-0.03709,   inf] (67), [-0.03662,   inf] (67), [-0.03651,   inf] (67), [-0.03634,   inf] (67), [-0.03623,   inf] (67), [-0.03604,   inf] (67), [-0.03580,   inf] (67), [-0.03531,   inf] (67), [-0.03520,   inf] (67), [-0.03505,   inf] (67), [-0.03502,   inf] (67), [-0.03496,   inf] (67), [-0.03485,   inf] (67), [-0.03476,   inf] (67), [-0.03471,   inf] (67), 
length of domains: 12223
Total time: 4.2831	 pickout: 0.3299	 decision: 0.8840	 get_bound: 2.6665	 add_domain: 0.4026
Current lb:-0.03898585960268974
63490 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 67.54270386695862

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 343] [1, 343] [1, 343] [1, 343] [1, 343] [1, 343] [1, 343] [1, 343] [1, 343] [1, 369] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 5.004775047302246 with beta sum per layer: [0.09643421322107315, 370.26611328125, 341.4534912109375]
alpha/beta optimization time: 1.5582528114318848
This batch time : update_bounds func: 2.3564	 prepare: 0.4176	 bound: 1.5587	 transfer: 0.1030	 finalize: 0.2651
Accumulated time: update_bounds func: 43.2669	 prepare: 6.9751	 bound: 28.1038	 transfer: 0.1030	 finalize: 6.0456
batch bounding time:  2.360893726348877
Current worst splitting domains [lb, ub] (depth):
[-0.03316,   inf] (69), [-0.03283,   inf] (69), [-0.03257,   inf] (69), [-0.03237,   inf] (69), [-0.03187,   inf] (69), [-0.03185,   inf] (69), [-0.03156,   inf] (69), [-0.03147,   inf] (69), [-0.03122,   inf] (69), [-0.03103,   inf] (69), [-0.03079,   inf] (69), [-0.03076,   inf] (69), [-0.03075,   inf] (69), [-0.03056,   inf] (69), [-0.03045,   inf] (69), [-0.03028,   inf] (69), [-0.03025,   inf] (69), [-0.03020,   inf] (69), [-0.03016,   inf] (69), [-0.03003,   inf] (69), 
length of domains: 13232
Total time: 4.3011	 pickout: 0.3294	 decision: 0.9018	 get_bound: 2.3682	 add_domain: 0.7016
Current lb:-0.033158741891384125
67586 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 71.90197587013245

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 369] [1, 369] [1, 369] [1, 369] [1, 369] [1, 369] [1, 369] [1, 369] [1, 369] [1, 369] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 17.503061294555664 with beta sum per layer: [0.21142438054084778, 337.0224304199219, 309.85162353515625]
alpha/beta optimization time: 1.5573551654815674
This batch time : update_bounds func: 2.3579	 prepare: 0.4195	 bound: 1.5577	 transfer: 0.1040	 finalize: 0.2643
Accumulated time: update_bounds func: 45.6248	 prepare: 7.3947	 bound: 29.6615	 transfer: 0.1040	 finalize: 6.3099
batch bounding time:  2.362316370010376
Current worst splitting domains [lb, ub] (depth):
[-0.02772,   inf] (71), [-0.02734,   inf] (71), [-0.02704,   inf] (71), [-0.02681,   inf] (71), [-0.02644,   inf] (71), [-0.02634,   inf] (71), [-0.02615,   inf] (71), [-0.02612,   inf] (71), [-0.02595,   inf] (71), [-0.02581,   inf] (71), [-0.02567,   inf] (71), [-0.02548,   inf] (71), [-0.02546,   inf] (71), [-0.02531,   inf] (71), [-0.02527,   inf] (71), [-0.02514,   inf] (71), [-0.02503,   inf] (71), [-0.02493,   inf] (71), [-0.02482,   inf] (71), [-0.02480,   inf] (71), 
length of domains: 14501
Total time: 4.0760	 pickout: 0.3313	 decision: 0.9365	 get_bound: 2.3696	 add_domain: 0.4386
Current lb:-0.027720123529434204
71682 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 76.0316174030304

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [0, 2424] [0, 2424] [0, 2424] [1, 882] [0, 2424] [0, 2424] [0, 2424] [0, 2424] [0, 2424] [0, 2424] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 2.5107054710388184 with beta sum per layer: [0.27566248178482056, 290.427734375, 259.57366943359375]
alpha/beta optimization time: 1.5499005317687988
This batch time : update_bounds func: 2.7183	 prepare: 0.4386	 bound: 1.5503	 transfer: 0.1032	 finalize: 0.6136
Accumulated time: update_bounds func: 48.3431	 prepare: 7.8333	 bound: 31.2119	 transfer: 0.1032	 finalize: 6.9235
batch bounding time:  2.7222981452941895
Current worst splitting domains [lb, ub] (depth):
[-0.02387,   inf] (73), [-0.02351,   inf] (73), [-0.02318,   inf] (73), [-0.02286,   inf] (73), [-0.02260,   inf] (73), [-0.02244,   inf] (73), [-0.02229,   inf] (73), [-0.02227,   inf] (73), [-0.02222,   inf] (73), [-0.02206,   inf] (73), [-0.02191,   inf] (73), [-0.02189,   inf] (73), [-0.02177,   inf] (73), [-0.02159,   inf] (73), [-0.02157,   inf] (73), [-0.02149,   inf] (73), [-0.02148,   inf] (73), [-0.02125,   inf] (73), [-0.02121,   inf] (73), [-0.02115,   inf] (73), 
length of domains: 15362
Total time: 4.4277	 pickout: 0.3345	 decision: 0.9598	 get_bound: 2.7295	 add_domain: 0.4039
Current lb:-0.023867493495345116
75778 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 80.51971125602722

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 882] [1, 882] [1, 882] [0, 2424] [1, 882] [1, 882] [1, 882] [1, 882] [1, 882] [1, 882] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: -45.89032745361328 with beta sum per layer: [0.2988005578517914, 280.23394775390625, 251.03456115722656]
alpha/beta optimization time: 1.5489537715911865
This batch time : update_bounds func: 2.3803	 prepare: 0.4408	 bound: 1.5493	 transfer: 0.1029	 finalize: 0.2748
Accumulated time: update_bounds func: 50.7233	 prepare: 8.2741	 bound: 32.7612	 transfer: 0.1029	 finalize: 7.1983
batch bounding time:  2.3849666118621826
Current worst splitting domains [lb, ub] (depth):
[-0.02047,   inf] (75), [-0.01984,   inf] (75), [-0.01933,   inf] (75), [-0.01922,   inf] (75), [-0.01910,   inf] (75), [-0.01899,   inf] (75), [-0.01890,   inf] (75), [-0.01882,   inf] (75), [-0.01875,   inf] (75), [-0.01843,   inf] (75), [-0.01826,   inf] (75), [-0.01815,   inf] (75), [-0.01806,   inf] (75), [-0.01801,   inf] (75), [-0.01787,   inf] (75), [-0.01775,   inf] (75), [-0.01775,   inf] (75), [-0.01769,   inf] (75), [-0.01766,   inf] (75), [-0.01765,   inf] (75), 
length of domains: 15355
Total time: 4.4034	 pickout: 0.3532	 decision: 0.9836	 get_bound: 2.3925	 add_domain: 0.6741
Current lb:-0.020466241985559464
79874 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 84.99092268943787

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 975] [1, 975] [1, 975] [1, 975] [1, 975] [1, 975] [1, 975] [1, 975] [1, 703] [1, 975] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: -26.672069549560547 with beta sum per layer: [0.25150686502456665, 331.0951843261719, 316.3980712890625]
alpha/beta optimization time: 1.547023057937622
This batch time : update_bounds func: 2.7479	 prepare: 0.4358	 bound: 1.5474	 transfer: 0.1034	 finalize: 0.6490
Accumulated time: update_bounds func: 53.4712	 prepare: 8.7099	 bound: 34.3086	 transfer: 0.1034	 finalize: 7.8474
batch bounding time:  2.7530314922332764
Current worst splitting domains [lb, ub] (depth):
[-0.01670,   inf] (77), [-0.01606,   inf] (77), [-0.01559,   inf] (77), [-0.01555,   inf] (77), [-0.01548,   inf] (77), [-0.01536,   inf] (77), [-0.01525,   inf] (77), [-0.01515,   inf] (77), [-0.01505,   inf] (77), [-0.01501,   inf] (77), [-0.01470,   inf] (77), [-0.01451,   inf] (77), [-0.01451,   inf] (77), [-0.01430,   inf] (77), [-0.01428,   inf] (77), [-0.01423,   inf] (77), [-0.01415,   inf] (77), [-0.01406,   inf] (77), [-0.01400,   inf] (77), [-0.01400,   inf] (77), 
length of domains: 15354
Total time: 4.0511	 pickout: 0.3460	 decision: 0.6522	 get_bound: 2.7611	 add_domain: 0.2917
Current lb:-0.016700908541679382
83970 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 89.11554288864136

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 703] [1, 703] [1, 1111] [1, 703] [2, 95] [1, 703] [1, 703] [1, 703] [2, 95] [1, 1111] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: -40.0649299621582 with beta sum per layer: [0.24215959012508392, 331.0064392089844, 370.3473815917969]
alpha/beta optimization time: 1.5435070991516113
This batch time : update_bounds func: 2.3823	 prepare: 0.4456	 bound: 1.5439	 transfer: 0.1040	 finalize: 0.2758
Accumulated time: update_bounds func: 55.8535	 prepare: 9.1555	 bound: 35.8526	 transfer: 0.1040	 finalize: 8.1231
batch bounding time:  2.3866419792175293
Current worst splitting domains [lb, ub] (depth):
[-0.01368,   inf] (79), [-0.01305,   inf] (79), [-0.01268,   inf] (79), [-0.01239,   inf] (79), [-0.01236,   inf] (79), [-0.01228,   inf] (79), [-0.01213,   inf] (79), [-0.01212,   inf] (79), [-0.01171,   inf] (79), [-0.01150,   inf] (79), [-0.01134,   inf] (79), [-0.01132,   inf] (79), [-0.01113,   inf] (79), [-0.01107,   inf] (79), [-0.01096,   inf] (79), [-0.01093,   inf] (79), [-0.01082,   inf] (79), [-0.01078,   inf] (79), [-0.01072,   inf] (79), [-0.01070,   inf] (79), 
length of domains: 14732
Total time: 3.9533	 pickout: 0.3457	 decision: 1.0061	 get_bound: 2.3941	 add_domain: 0.2074
Current lb:-0.013683842495083809
88066 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 93.14646053314209

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 1111] [1, 1111] [1, 1111] [1, 1111] [1, 1111] [1, 1111] [1, 1111] [1, 1111] [1, 1111] [1, 1111] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: -25.4747314453125 with beta sum per layer: [0.19940409064292908, 362.013916015625, 412.247802734375]
alpha/beta optimization time: 1.5442149639129639
This batch time : update_bounds func: 2.7598	 prepare: 0.4327	 bound: 1.5446	 transfer: 0.1034	 finalize: 0.6664
Accumulated time: update_bounds func: 58.6133	 prepare: 9.5882	 bound: 37.3972	 transfer: 0.1034	 finalize: 8.7896
batch bounding time:  2.764346122741699
Current worst splitting domains [lb, ub] (depth):
[-0.00874,   inf] (81), [-0.00814,   inf] (81), [-0.00774,   inf] (81), [-0.00754,   inf] (81), [-0.00752,   inf] (81), [-0.00738,   inf] (81), [-0.00727,   inf] (81), [-0.00720,   inf] (81), [-0.00692,   inf] (81), [-0.00660,   inf] (81), [-0.00654,   inf] (81), [-0.00651,   inf] (81), [-0.00640,   inf] (81), [-0.00626,   inf] (81), [-0.00620,   inf] (81), [-0.00615,   inf] (81), [-0.00610,   inf] (81), [-0.00601,   inf] (81), [-0.00601,   inf] (81), [-0.00600,   inf] (81), 
length of domains: 13693
Total time: 4.2765	 pickout: 0.3511	 decision: 0.9907	 get_bound: 2.7729	 add_domain: 0.1619
Current lb:-0.008742709644138813
92162 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 97.5126085281372

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 422] [1, 422] [1, 422] [1, 422] [1, 422] [1, 422] [1, 422] [1, 422] [1, 422] [1, 422] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: -30.590389251708984 with beta sum per layer: [0.19360587000846863, 380.3896179199219, 440.4100341796875]
alpha/beta optimization time: 1.5463674068450928
This batch time : update_bounds func: 2.4145	 prepare: 0.4232	 bound: 1.5468	 transfer: 0.1038	 finalize: 0.3279
Accumulated time: update_bounds func: 61.0278	 prepare: 10.0114	 bound: 38.9440	 transfer: 0.1038	 finalize: 9.1175
batch bounding time:  2.4192616939544678
Current worst splitting domains [lb, ub] (depth):
[-0.00383,   inf] (83), [-0.00361,   inf] (57), [-0.00361,   inf] (65), [-0.00361,   inf] (51), [-0.00361,   inf] (55), [-0.00361,   inf] (79), [-0.00361,   inf] (63), [-0.00360,   inf] (67), [-0.00360,   inf] (61), [-0.00360,   inf] (53), [-0.00360,   inf] (55), [-0.00360,   inf] (63), [-0.00360,   inf] (55), [-0.00360,   inf] (61), [-0.00360,   inf] (57), [-0.00360,   inf] (61), [-0.00360,   inf] (69), [-0.00360,   inf] (75), [-0.00360,   inf] (69)/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:530: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(eps_temp / std).reshape(1, -1, 1, 1)
, [-0.00360,   inf] (67), 
length of domains: 12074
Total time: 3.8567	 pickout: 0.3641	 decision: 0.9978	 get_bound: 2.4270	 add_domain: 0.0677
Current lb:-0.0038318398874253035
96258 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 101.45959877967834

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [2, 95] [1, 331] [1, 274] [1, 478] [0, 2424] [1, 1111] [1, 1111] [1, 485] [1, 343] [1, 171] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: -37.861392974853516 with beta sum per layer: [0.24097773432731628, 388.21356201171875, 475.682373046875]
alpha/beta optimization time: 1.555760145187378
This batch time : update_bounds func: 2.7604	 prepare: 0.4258	 bound: 1.5561	 transfer: 0.1073	 finalize: 0.6586
Accumulated time: update_bounds func: 63.7881	 prepare: 10.4372	 bound: 40.5001	 transfer: 0.1073	 finalize: 9.7760
batch bounding time:  2.768017053604126
Current worst splitting domains [lb, ub] (depth):
[-0.00291,   inf] (53), [-0.00291,   inf] (53), [-0.00291,   inf] (59), [-0.00291,   inf] (75), [-0.00291,   inf] (67), [-0.00291,   inf] (55), [-0.00291,   inf] (69), [-0.00291,   inf] (77), [-0.00291,   inf] (65), [-0.00291,   inf] (59), [-0.00291,   inf] (57), [-0.00291,   inf] (67), [-0.00291,   inf] (71), [-0.00291,   inf] (57), [-0.00291,   inf] (59), [-0.00291,   inf] (75), [-0.00291,   inf] (61), [-0.00291,   inf] (65), [-0.00291,   inf] (75), [-0.00291,   inf] (61), 
length of domains: 10161
Total time: 4.0984	 pickout: 0.3540	 decision: 0.9353	 get_bound: 2.7817	 add_domain: 0.0273
Current lb:-0.0029126498848199844
100354 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 105.65882587432861

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 486] [1, 504] [1, 331] [2, 95] [1, 485] [1, 331] [1, 422] [1, 422] [1, 343] [1, 331] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: -41.32368469238281 with beta sum per layer: [0.21005399525165558, 390.5369873046875, 460.6128845214844]
alpha/beta optimization time: 1.5294628143310547
This batch time : update_bounds func: 2.6437	 prepare: 0.4384	 bound: 1.5299	 transfer: 0.1029	 finalize: 0.5605
Accumulated time: update_bounds func: 66.4318	 prepare: 10.8756	 bound: 42.0300	 transfer: 0.1029	 finalize: 10.3366
batch bounding time:  2.648172378540039
Current worst splitting domains [lb, ub] (depth):
[-0.00227,   inf] (63), [-0.00227,   inf] (63), [-0.00227,   inf] (77), [-0.00227,   inf] (77), [-0.00227,   inf] (51), [-0.00227,   inf] (53), [-0.00227,   inf] (79), [-0.00227,   inf] (65), [-0.00227,   inf] (61), [-0.00227,   inf] (73), [-0.00227,   inf] (69), [-0.00227,   inf] (79), [-0.00227,   inf] (59), [-0.00226,   inf] (57), [-0.00226,   inf] (65), [-0.00226,   inf] (57), [-0.00226,   inf] (77), [-0.00226,   inf] (77), [-0.00226,   inf] (63), [-0.00226,   inf] (67), 
length of domains: 8122
Total time: 3.9838	 pickout: 0.4048	 decision: 0.9189	 get_bound: 2.6565	 add_domain: 0.0036
Current lb:-0.0022693276405334473
104450 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 109.73708534240723

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 15, 15]) pre split depth:  1
batch:  torch.Size([2048, 16, 15, 15]) post split depth:  1
splitting decisions: 
split level 0: [1, 313] [1, 331] [1, 975] [1, 629] [1, 171] [1, 331] [1, 629] [0, 2424] [1, 1111] [1, 703] 
regular batch size: 2*2048, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -43.93280792236328 with beta sum per layer: [0.32747191190719604, 393.0653381347656, 485.60546875]
alpha/beta optimization time: 0.04846000671386719
This batch time : update_bounds func: 1.1299	 prepare: 0.4263	 bound: 0.0488	 transfer: 0.1030	 finalize: 0.5400
Accumulated time: update_bounds func: 67.5617	 prepare: 11.3018	 bound: 42.0788	 transfer: 0.1030	 finalize: 10.8765
batch bounding time:  1.134767770767212
Current worst splitting domains [lb, ub] (depth):
[-0.00166,   inf] (51), [-0.00166,   inf] (57), [-0.00166,   inf] (69), [-0.00166,   inf] (67), [-0.00166,   inf] (59), [-0.00166,   inf] (81), [-0.00166,   inf] (67), [-0.00166,   inf] (53), [-0.00166,   inf] (57), [-0.00166,   inf] (69), [-0.00166,   inf] (75), [-0.00165,   inf] (63), [-0.00165,   inf] (53), [-0.00165,   inf] (57), [-0.00165,   inf] (65), [-0.00165,   inf] (65), [-0.00165,   inf] (63), [-0.00165,   inf] (65), [-0.00165,   inf] (65), [-0.00165,   inf] (51), 
length of domains: 6074
Total time: 2.3735	 pickout: 0.3568	 decision: 0.8718	 get_bound: 1.1428	 add_domain: 0.0022
Current lb:-0.001658782595768571
108546 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Time out!!!!!!!!
Image 373 label 3 verification end, final lower bound -0.001658782595768571, upper bound inf, time: 112.42053437232971
373 -0.001658782595768571
Result: image 373 verification failure (with branch and bound).
Wall time: 122.94703435897827

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 0): []
verification failure idx (total 1): [373]
final verified acc: 0.0%[1]
verifier is called on 1 examples.
total verified: 0
mean time [cnt:1] (excluding attack success): 121.7545838356018
