Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: specify-target
  complete_verifier: bab
  enable_incomplete_verification: false
  get_crown_verified_acc: false
model:
  path: cifar_base.pth
  name: cifar_model_base
data:
  start: 64
  end: 65
  num_outputs: 10
  mean: [0.485, 0.456, 0.406]
  std: [0.225, 0.225, 0.225]
  pkl_path: base_100.pkl
  dataset: CIFAR
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: null
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 1024
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 240
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: fsb
    candidates: 1
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Tue May  3 01:27:30 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(3, 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(8, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Flatten()
  (5): Linear(in_features=1024, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=10, bias=True)
)
No epsilon defined!
Files already downloaded and verified
Overwrite epsilon that saved in .pkl file, they should be after normalized!
Task length: 1
saving results to Verified_ret_[cifar_model_base]_start=64_end=65_iter=20_b=1024_timeout=240_branching=fsb-min-1_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 64 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 6, correct label 6, image norm 2367.672119140625, logits tensor([-1.6128,  0.3564, -0.3262,  0.6126, -0.1604,  0.2011,  1.6899, -0.3649,
        -1.1587,  0.7631], device='cuda:0', grad_fn=<SelectBackward>)
##### [0:64] Tested against 3 ######
Model prediction is: tensor([[-1.6128,  0.3564, -0.3262,  0.6126, -0.1604,  0.2011,  1.6899, -0.3649,
         -1.1587,  0.7631]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-0.7594]], device='cuda:0') None
best_l after optimization: 0.5989242196083069 with beta sum per layer: []
alpha/beta optimization time: 7.17936110496521
initial alpha-CROWN bounds: tensor([[-0.5989]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.5989, device='cuda:0', grad_fn=<MinBackward1>)
-0.5989242196083069
layer 0 size torch.Size([2048]) unstable 351
layer 1 size torch.Size([1024]) unstable 269
layer 2 size torch.Size([100]) unstable 44
-----------------
# of unstable neurons: 664
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 8, 16, 16]) pre split depth:  6
batch:  torch.Size([1, 8, 16, 16]) post split depth:  6
splitting decisions: 
split level 0: [2, 81] 
split level 1: [2, 42] 
split level 2: [2, 57] 
split level 3: [2, 15] 
split level 4: [2, 54] 
split level 5: [2, 93] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: -12.525283813476562 with beta sum per layer: [0.0, 0.0, 11.671758651733398]
alpha/beta optimization time: 0.2515254020690918
This batch time : update_bounds func: 0.2631	 prepare: 0.0058	 bound: 0.2518	 transfer: 0.0013	 finalize: 0.0039
Accumulated time: update_bounds func: 0.2631	 prepare: 0.0058	 bound: 0.2518	 transfer: 0.0013	 finalize: 0.0039
batch bounding time:  0.26331257820129395
Current worst splitting domains [lb, ub] (depth):
[-0.24287,   inf] (7), [-0.23630,   inf] (7), [-0.23158,   inf] (7), [-0.22872,   inf] (7), [-0.22308,   inf] (7), [-0.19222,   inf] (7), [-0.18304,   inf] (7), [-0.17933,   inf] (7), [-0.17847,   inf] (7), [-0.17228,   inf] (7), [-0.17152,   inf] (7), [-0.16965,   inf] (7), [-0.15955,   inf] (7), [-0.15781,   inf] (7), [-0.15227,   inf] (7), [-0.14685,   inf] (7), [-0.14232,   inf] (7), [-0.14065,   inf] (7), [-0.13575,   inf] (7), [-0.13425,   inf] (7), 
length of domains: 29
Total time: 0.3438	 pickout: 0.0009	 decision: 0.0711	 get_bound: 0.2708	 add_domain: 0.0011
Current lb:-0.2428668737411499
64 neurons visited
0 diving domains visited
Global ub: tensor([[inf]], device='cuda:0'), batch ub: inf
Cumulative time: 9.295936822891235

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([29, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([29, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 50] [2, 50] [2, 50] [2, 50] [2, 50] [2, 50] [2, 50] [2, 50] [2, 50] [2, 50] 
regular batch size: 2*29, diving batch size 1*0
best_l after optimization: 1.2681424617767334 with beta sum per layer: [0.0, 0.0, 22.713220596313477]
alpha/beta optimization time: 0.24362468719482422
This batch time : update_bounds func: 0.2549	 prepare: 0.0064	 bound: 0.2439	 transfer: 0.0010	 finalize: 0.0035
Accumulated time: update_bounds func: 0.5180	 prepare: 0.0122	 bound: 0.4957	 transfer: 0.0010	 finalize: 0.0074
batch bounding time:  0.25507235527038574
Current worst splitting domains [lb, ub] (depth):
[-0.21724,   inf] (9), [-0.21382,   inf] (9), [-0.20436,   inf] (9), [-0.20279,   inf] (9), [-0.19612,   inf] (9), [-0.16068,   inf] (9), [-0.15565,   inf] (9), [-0.15252,   inf] (9), [-0.15204,   inf] (9), [-0.14979,   inf] (9), [-0.13982,   inf] (9), [-0.13889,   inf] (9), [-0.13347,   inf] (9), [-0.13280,   inf] (9), [-0.12056,   inf] (9), [-0.12054,   inf] (9), [-0.11723,   inf] (9), [-0.11558,   inf] (9), [-0.10888,   inf] (9), [-0.10361,   inf] (9), 
length of domains: 26
Total time: 0.2908	 pickout: 0.0044	 decision: 0.0303	 get_bound: 0.2552	 add_domain: 0.0009
Current lb:-0.2172359973192215
122 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.587379217147827

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([26, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([26, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 79] [2, 79] [2, 79] [2, 79] [2, 79] [2, 79] [2, 79] [2, 79] [2, 79] [2, 79] 
regular batch size: 2*26, diving batch size 1*0
best_l after optimization: 2.1401443481445312 with beta sum per layer: [0.0, 0.0, 20.536174774169922]
alpha/beta optimization time: 0.2376115322113037
This batch time : update_bounds func: 0.2477	 prepare: 0.0057	 bound: 0.2379	 transfer: 0.0009	 finalize: 0.0030
Accumulated time: update_bounds func: 0.7657	 prepare: 0.0179	 bound: 0.7336	 transfer: 0.0009	 finalize: 0.0105
batch bounding time:  0.24780511856079102
Current worst splitting domains [lb, ub] (depth):
[-0.18892,   inf] (11), [-0.18565,   inf] (11), [-0.17578,   inf] (11), [-0.17560,   inf] (11), [-0.16812,   inf] (11), [-0.13260,   inf] (11), [-0.13247,   inf] (11), [-0.13021,   inf] (11), [-0.12848,   inf] (11), [-0.12429,   inf] (11), [-0.11526,   inf] (11), [-0.11494,   inf] (11), [-0.09720,   inf] (11), [-0.09694,   inf] (11), [-0.09687,   inf] (11), [-0.09603,   inf] (11), [-0.09494,   inf] (11), [-0.08692,   inf] (11), [-0.08114,   inf] (11), [-0.07963,   inf] (11), 
length of domains: 33
Total time: 0.2821	 pickout: 0.0040	 decision: 0.0291	 get_bound: 0.2479	 add_domain: 0.0011
Current lb:-0.18892426788806915
174 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.869795560836792

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([33, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([33, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 62] [2, 62] [2, 62] [2, 62] [2, 62] [2, 62] [2, 62] [2, 62] [2, 62] [2, 62] 
regular batch size: 2*33, diving batch size 1*0
best_l after optimization: 0.9652782678604126 with beta sum per layer: [0.0, 0.0, 25.322145462036133]
alpha/beta optimization time: 0.23923897743225098
This batch time : update_bounds func: 0.2515	 prepare: 0.0069	 bound: 0.2395	 transfer: 0.0010	 finalize: 0.0038
Accumulated time: update_bounds func: 1.0172	 prepare: 0.0248	 bound: 0.9731	 transfer: 0.0010	 finalize: 0.0143
batch bounding time:  0.2516052722930908
Current worst splitting domains [lb, ub] (depth):
[-0.16570,   inf] (13), [-0.16439,   inf] (13), [-0.15427,   inf] (13), [-0.15233,   inf] (13), [-0.14253,   inf] (13), [-0.11040,   inf] (13), [-0.10878,   inf] (13), [-0.10664,   inf] (13), [-0.10388,   inf] (13), [-0.09899,   inf] (13), [-0.09264,   inf] (13), [-0.09171,   inf] (13), [-0.07398,   inf] (13), [-0.07302,   inf] (13), [-0.07230,   inf] (13), [-0.07154,   inf] (13), [-0.07011,   inf] (13), [-0.05718,   inf] (13), [-0.05702,   inf] (13), [-0.05073,   inf] (13), 
length of domains: 31
Total time: 0.2903	 pickout: 0.0048	 decision: 0.0326	 get_bound: 0.2517	 add_domain: 0.0011
Current lb:-0.1657027155160904
240 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.160610675811768

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([31, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([31, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 40] [2, 40] [2, 40] [2, 40] [2, 40] [2, 40] [2, 40] [2, 40] [2, 40] [2, 40] 
regular batch size: 2*31, diving batch size 1*0
best_l after optimization: 3.6978583335876465 with beta sum per layer: [0.0, 0.0, 16.28591537475586]
alpha/beta optimization time: 0.24332523345947266
This batch time : update_bounds func: 0.2555	 prepare: 0.0070	 bound: 0.2436	 transfer: 0.0010	 finalize: 0.0037
Accumulated time: update_bounds func: 1.2726	 prepare: 0.0318	 bound: 1.2167	 transfer: 0.0010	 finalize: 0.0181
batch bounding time:  0.2556033134460449
Current worst splitting domains [lb, ub] (depth):
[-0.15367,   inf] (15), [-0.15178,   inf] (15), [-0.15162,   inf] (15), [-0.15066,   inf] (15), [-0.14181,   inf] (15), [-0.14027,   inf] (15), [-0.13949,   inf] (15), [-0.13663,   inf] (15), [-0.12993,   inf] (15), [-0.12846,   inf] (15), [-0.09877,   inf] (15), [-0.09668,   inf] (15), [-0.09494,   inf] (15), [-0.09441,   inf] (15), [-0.09322,   inf] (15), [-0.09247,   inf] (15), [-0.09114,   inf] (15), [-0.09066,   inf] (15), [-0.08626,   inf] (15), [-0.08614,   inf] (15), 
length of domains: 54
Total time: 0.2936	 pickout: 0.0045	 decision: 0.0312	 get_bound: 0.2557	 add_domain: 0.0022
Current lb:-0.15367326140403748
302 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.454628467559814

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([54, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([54, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 7] [2, 7] [2, 7] [2, 7] [2, 7] [2, 7] [2, 7] [2, 7] [2, 7] [2, 7] 
regular batch size: 2*54, diving batch size 1*0
best_l after optimization: 5.31800651550293 with beta sum per layer: [0.0, 0.0, 32.71993637084961]
alpha/beta optimization time: 0.2425076961517334
This batch time : update_bounds func: 0.2615	 prepare: 0.0109	 bound: 0.2428	 transfer: 0.0014	 finalize: 0.0062
Accumulated time: update_bounds func: 1.5341	 prepare: 0.0426	 bound: 1.4595	 transfer: 0.0014	 finalize: 0.0243
batch bounding time:  0.2617018222808838
Current worst splitting domains [lb, ub] (depth):
[-0.14707,   inf] (17), [-0.14550,   inf] (17), [-0.14491,   inf] (17), [-0.14436,   inf] (17), [-0.13550,   inf] (17), [-0.13383,   inf] (17), [-0.13294,   inf] (17), [-0.12968,   inf] (17), [-0.12233,   inf] (17), [-0.12089,   inf] (17), [-0.12050,   inf] (17), [-0.11994,   inf] (17), [-0.10867,   inf] (17), [-0.10864,   inf] (17), [-0.10347,   inf] (17), [-0.10339,   inf] (17), [-0.09849,   inf] (17), [-0.09816,   inf] (17), [-0.09190,   inf] (17), [-0.09026,   inf] (17), 
length of domains: 88
Total time: 0.3175	 pickout: 0.0074	 decision: 0.0451	 get_bound: 0.2619	 add_domain: 0.0032
Current lb:-0.147074893116951
410 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.772767543792725

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([88, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([88, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 70] [2, 70] [2, 70] [2, 70] [2, 70] [2, 70] [2, 70] [2, 70] [2, 70] [2, 70] 
regular batch size: 2*88, diving batch size 1*0
best_l after optimization: -0.28489017486572266 with beta sum per layer: [0.0, 0.27103903889656067, 58.59498596191406]
alpha/beta optimization time: 0.24573397636413574
This batch time : update_bounds func: 0.2752	 prepare: 0.0166	 bound: 0.2460	 transfer: 0.0022	 finalize: 0.0100
Accumulated time: update_bounds func: 1.8094	 prepare: 0.0593	 bound: 1.7055	 transfer: 0.0022	 finalize: 0.0343
batch bounding time:  0.2754788398742676
Current worst splitting domains [lb, ub] (depth):
[-0.14236,   inf] (19), [-0.14138,   inf] (19), [-0.14019,   inf] (19), [-0.14011,   inf] (19), [-0.13147,   inf] (19), [-0.12927,   inf] (19), [-0.12880,   inf] (19), [-0.12503,   inf] (19), [-0.11736,   inf] (19), [-0.11545,   inf] (19), [-0.11381,   inf] (19), [-0.11314,   inf] (19), [-0.10265,   inf] (19), [-0.10245,   inf] (19), [-0.09654,   inf] (19), [-0.09653,   inf] (19), [-0.09009,   inf] (19), [-0.08992,   inf] (19), [-0.08721,   inf] (19), [-0.08623,   inf] (19), 
length of domains: 89
Total time: 0.3557	 pickout: 0.0115	 decision: 0.0650	 get_bound: 0.2757	 add_domain: 0.0034
Current lb:-0.14236275851726532
586 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.129714965820312

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([89, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([89, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 12] [2, 12] [2, 12] [2, 12] [2, 12] [2, 12] [2, 12] [2, 12] [2, 12] [2, 12] 
regular batch size: 2*89, diving batch size 1*0
best_l after optimization: 0.6401221752166748 with beta sum per layer: [0.0, 0.6857258081436157, 67.3884048461914]
alpha/beta optimization time: 0.2478017807006836
This batch time : update_bounds func: 0.2801	 prepare: 0.0174	 bound: 0.2481	 transfer: 0.0040	 finalize: 0.0102
Accumulated time: update_bounds func: 2.0895	 prepare: 0.0767	 bound: 1.9536	 transfer: 0.0040	 finalize: 0.0444
batch bounding time:  0.28034472465515137
Current worst splitting domains [lb, ub] (depth):
[-0.13760,   inf] (21), [-0.13656,   inf] (21), [-0.13543,   inf] (21), [-0.13528,   inf] (21), [-0.12663,   inf] (21), [-0.12441,   inf] (21), [-0.12393,   inf] (21), [-0.12017,   inf] (21), [-0.11279,   inf] (21), [-0.11090,   inf] (21), [-0.10848,   inf] (21), [-0.10789,   inf] (21), [-0.09787,   inf] (21), [-0.09776,   inf] (21), [-0.09083,   inf] (21), [-0.09033,   inf] (21), [-0.08329,   inf] (21), [-0.08316,   inf] (21), [-0.07793,   inf] (21), [-0.07587,   inf] (21), 
length of domains: 110
Total time: 0.3632	 pickout: 0.0120	 decision: 0.0659	 get_bound: 0.2806	 add_domain: 0.0047
Current lb:-0.13759946823120117
764 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.494304895401001

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([110, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([110, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 787] [1, 787] [1, 787] [1, 787] [1, 787] [1, 787] [1, 787] [1, 787] [1, 787] [1, 787] 
regular batch size: 2*110, diving batch size 1*0
best_l after optimization: 4.816740036010742 with beta sum per layer: [0.0, 2.7008056640625, 57.75751876831055]
alpha/beta optimization time: 0.24785518646240234
This batch time : update_bounds func: 0.2867	 prepare: 0.0213	 bound: 0.2481	 transfer: 0.0038	 finalize: 0.0129
Accumulated time: update_bounds func: 2.3761	 prepare: 0.0979	 bound: 2.2018	 transfer: 0.0038	 finalize: 0.0573
batch bounding time:  0.2869377136230469
Current worst splitting domains [lb, ub] (depth):
[-0.13324,   inf] (23), [-0.13284,   inf] (23), [-0.13145,   inf] (23), [-0.13119,   inf] (23), [-0.12316,   inf] (23), [-0.12041,   inf] (23), [-0.12020,   inf] (23), [-0.11610,   inf] (23), [-0.10872,   inf] (23), [-0.10699,   inf] (23), [-0.10395,   inf] (23), [-0.10339,   inf] (23), [-0.09405,   inf] (23), [-0.09404,   inf] (23), [-0.08716,   inf] (23), [-0.08618,   inf] (23), [-0.07833,   inf] (23), [-0.07809,   inf] (23), [-0.07428,   inf] (23), [-0.07357,   inf] (23), 
length of domains: 142
Total time: 0.3883	 pickout: 0.0149	 decision: 0.0806	 get_bound: 0.2873	 add_domain: 0.0056
Current lb:-0.13323722779750824
984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.884052276611328

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([142, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([142, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 795] [1, 795] [1, 795] [1, 795] [1, 795] [1, 795] [1, 795] [1, 795] [1, 786] [1, 786] 
regular batch size: 2*142, diving batch size 1*0
best_l after optimization: 7.101354122161865 with beta sum per layer: [0.0, 4.295000076293945, 62.90253448486328]
alpha/beta optimization time: 0.25371313095092773
This batch time : update_bounds func: 0.3052	 prepare: 0.0281	 bound: 0.2540	 transfer: 0.0062	 finalize: 0.0162
Accumulated time: update_bounds func: 2.6813	 prepare: 0.1261	 bound: 2.4558	 transfer: 0.0062	 finalize: 0.0736
batch bounding time:  0.305497407913208
Current worst splitting domains [lb, ub] (depth):
[-0.12147,   inf] (25), [-0.12011,   inf] (25), [-0.11866,   inf] (25), [-0.11646,   inf] (25), [-0.11470,   inf] (25), [-0.11313,   inf] (25), [-0.11312,   inf] (25), [-0.11125,   inf] (25), [-0.11087,   inf] (25), [-0.10865,   inf] (25), [-0.10603,   inf] (25), [-0.10436,   inf] (25), [-0.10185,   inf] (25), [-0.10138,   inf] (25), [-0.09986,   inf] (25), [-0.09952,   inf] (25), [-0.09780,   inf] (25), [-0.09522,   inf] (25), [-0.08859,   inf] (25), [-0.08809,   inf] (25), 
length of domains: 191
Total time: 0.4318	 pickout: 0.0197	 decision: 0.0985	 get_bound: 0.3059	 add_domain: 0.0077
Current lb:-0.12147355079650879
1268 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.317626476287842

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([191, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([191, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 786] [1, 786] [1, 786] [1, 786] [1, 786] [1, 786] [1, 786] [1, 786] [1, 786] [1, 786] 
regular batch size: 2*191, diving batch size 1*0
best_l after optimization: 10.142763137817383 with beta sum per layer: [0.0, 7.796994686126709, 65.66336059570312]
alpha/beta optimization time: 0.26473164558410645
This batch time : update_bounds func: 0.3324	 prepare: 0.0374	 bound: 0.2650	 transfer: 0.0070	 finalize: 0.0221
Accumulated time: update_bounds func: 3.0137	 prepare: 0.1635	 bound: 2.7208	 transfer: 0.0070	 finalize: 0.0956
batch bounding time:  0.33280205726623535
Current worst splitting domains [lb, ub] (depth):
[-0.11308,   inf] (27), [-0.11183,   inf] (27), [-0.10842,   inf] (27), [-0.10686,   inf] (27), [-0.10611,   inf] (27), [-0.10541,   inf] (27), [-0.10354,   inf] (27), [-0.10200,   inf] (27), [-0.10128,   inf] (27), [-0.10108,   inf] (27), [-0.09952,   inf] (27), [-0.09936,   inf] (27), [-0.09567,   inf] (27), [-0.09566,   inf] (27), [-0.09475,   inf] (27), [-0.09430,   inf] (27), [-0.09313,   inf] (27), [-0.09263,   inf] (27), [-0.09179,   inf] (27), [-0.09171,   inf] (27), 
length of domains: 295
Total time: 0.5543	 pickout: 0.0263	 decision: 0.1312	 get_bound: 0.3334	 add_domain: 0.0634
Current lb:-0.1130795106291771
1650 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.87471318244934

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([295, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([295, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 723] [1, 723] [1, 861] [1, 723] [1, 861] [1, 723] [1, 861] [1, 723] [1, 861] [1, 723] 
regular batch size: 2*295, diving batch size 1*0
best_l after optimization: 13.616327285766602 with beta sum per layer: [0.0, 14.830140113830566, 87.04216003417969]
alpha/beta optimization time: 0.30188846588134766
This batch time : update_bounds func: 0.4080	 prepare: 0.0577	 bound: 0.3022	 transfer: 0.0119	 finalize: 0.0349
Accumulated time: update_bounds func: 3.4217	 prepare: 0.2211	 bound: 3.0230	 transfer: 0.0119	 finalize: 0.1305
batch bounding time:  0.40859127044677734
Current worst splitting domains [lb, ub] (depth):
[-0.10179,   inf] (29), [-0.10086,   inf] (29), [-0.09953,   inf] (29), [-0.09937,   inf] (29), [-0.09932,   inf] (29), [-0.09788,   inf] (29), [-0.09715,   inf] (29), [-0.09548,   inf] (29), [-0.09457,   inf] (29), [-0.09407,   inf] (29), [-0.09371,   inf] (29), [-0.09210,   inf] (29), [-0.08893,   inf] (29), [-0.08885,   inf] (29), [-0.08829,   inf] (29), [-0.08770,   inf] (29), [-0.08750,   inf] (29), [-0.08739,   inf] (29), [-0.08716,   inf] (29), [-0.08624,   inf] (29), 
length of domains: 466
Total time: 0.6665	 pickout: 0.0405	 decision: 0.1958	 get_bound: 0.4095	 add_domain: 0.0207
Current lb:-0.10178689658641815
2240 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.546761274337769

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([466, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([466, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 723] [1, 861] [1, 861] [1, 861] [1, 723] [1, 861] [1, 723] [1, 861] [1, 723] [1, 861] 
regular batch size: 2*466, diving batch size 1*0
best_l after optimization: 16.776901245117188 with beta sum per layer: [0.0, 29.750423431396484, 130.0033416748047]
alpha/beta optimization time: 0.365706205368042
This batch time : update_bounds func: 0.5308	 prepare: 0.0904	 bound: 0.3660	 transfer: 0.0179	 finalize: 0.0541
Accumulated time: update_bounds func: 3.9525	 prepare: 0.3115	 bound: 3.3890	 transfer: 0.0179	 finalize: 0.1846
batch bounding time:  0.5315735340118408
Current worst splitting domains [lb, ub] (depth):
[-0.09431,   inf] (31), [-0.09298,   inf] (31), [-0.09259,   inf] (31), [-0.09110,   inf] (31), [-0.08906,   inf] (31), [-0.08877,   inf] (31), [-0.08838,   inf] (31), [-0.08750,   inf] (31), [-0.08705,   inf] (31), [-0.08658,   inf] (31), [-0.08608,   inf] (31), [-0.08521,   inf] (31), [-0.08441,   inf] (31), [-0.08401,   inf] (31), [-0.08234,   inf] (31), [-0.08217,   inf] (31), [-0.08142,   inf] (31), [-0.08136,   inf] (31), [-0.08072,   inf] (31), [-0.08057,   inf] (31), 
length of domains: 635
Total time: 1.0362	 pickout: 0.0642	 decision: 0.3670	 get_bound: 0.5329	 add_domain: 0.0720
Current lb:-0.09430765360593796
3172 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.590395212173462

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([635, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([635, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 347] [1, 347] [1, 347] [1, 347] [1, 347] [1, 797] [1, 797] [1, 347] [1, 347] [1, 797] 
regular batch size: 2*635, diving batch size 1*0
best_l after optimization: 22.880035400390625 with beta sum per layer: [0.0, 45.05466842651367, 151.24777221679688]
alpha/beta optimization time: 0.46195125579833984
This batch time : update_bounds func: 0.7906	 prepare: 0.1824	 bound: 0.4623	 transfer: 0.0264	 finalize: 0.1163
Accumulated time: update_bounds func: 4.7430	 prepare: 0.4939	 bound: 3.8514	 transfer: 0.0264	 finalize: 0.3009
batch bounding time:  0.7918288707733154
Current worst splitting domains [lb, ub] (depth):
[-0.08602,   inf] (33), [-0.08451,   inf] (33), [-0.08440,   inf] (33), [-0.08281,   inf] (33), [-0.08164,   inf] (33), [-0.08116,   inf] (33), [-0.08086,   inf] (33), [-0.07962,   inf] (33), [-0.07940,   inf] (33), [-0.07929,   inf] (33), [-0.07908,   inf] (33), [-0.07877,   inf] (33), [-0.07833,   inf] (33), [-0.07735,   inf] (33), [-0.07728,   inf] (33), [-0.07688,   inf] (33), [-0.07601,   inf] (33), [-0.07505,   inf] (33), [-0.07466,   inf] (33), [-0.07438,   inf] (33), 
length of domains: 896
Total time: 1.3435	 pickout: 0.0871	 decision: 0.4193	 get_bound: 0.7940	 add_domain: 0.0432
Current lb:-0.08602022379636765
4442 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.944753408432007

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([896, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([896, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 284] [1, 284] [1, 284] [1, 284] [1, 284] [1, 284] [1, 284] [1, 284] [1, 284] [1, 284] 
regular batch size: 2*896, diving batch size 1*0
best_l after optimization: 27.75765609741211 with beta sum per layer: [0.0, 88.50211334228516, 187.18789672851562]
alpha/beta optimization time: 0.5631651878356934
This batch time : update_bounds func: 1.0636	 prepare: 0.2609	 bound: 0.5636	 transfer: 0.0273	 finalize: 0.2073
Accumulated time: update_bounds func: 5.8066	 prepare: 0.7547	 bound: 4.4150	 transfer: 0.0273	 finalize: 0.5081
batch bounding time:  1.0655100345611572
Current worst splitting domains [lb, ub] (depth):
[-0.08030,   inf] (35), [-0.07868,   inf] (35), [-0.07862,   inf] (35), [-0.07691,   inf] (35), [-0.07519,   inf] (35), [-0.07475,   inf] (35), [-0.07458,   inf] (35), [-0.07332,   inf] (35), [-0.07282,   inf] (35), [-0.07278,   inf] (35), [-0.07267,   inf] (35), [-0.07213,   inf] (35), [-0.07211,   inf] (35), [-0.07082,   inf] (35), [-0.07049,   inf] (35), [-0.06999,   inf] (35), [-0.06867,   inf] (35), [-0.06854,   inf] (35), [-0.06797,   inf] (35), [-0.06785,   inf] (35), 
length of domains: 1254
Total time: 2.0963	 pickout: 0.1732	 decision: 0.7930	 get_bound: 1.0687	 add_domain: 0.0614
Current lb:-0.0802992433309555
6234 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.05481243133545

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 797] [1, 797] [1, 797] [1, 797] [1, 347] [1, 347] [1, 797] [1, 797] [1, 797] [1, 347] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 37.40800476074219 with beta sum per layer: [0.0, 148.97006225585938, 154.28274536132812]
alpha/beta optimization time: 0.6212019920349121
This batch time : update_bounds func: 1.1759	 prepare: 0.2916	 bound: 0.6216	 transfer: 0.0302	 finalize: 0.2275
Accumulated time: update_bounds func: 6.9824	 prepare: 1.0463	 bound: 5.0365	 transfer: 0.0302	 finalize: 0.7356
batch bounding time:  1.1777989864349365
Current worst splitting domains [lb, ub] (depth):
[-0.07337,   inf] (37), [-0.07177,   inf] (37), [-0.07173,   inf] (37), [-0.07004,   inf] (37), [-0.06872,   inf] (37), [-0.06784,   inf] (37), [-0.06740,   inf] (37), [-0.06712,   inf] (37), [-0.06692,   inf] (37), [-0.06646,   inf] (37), [-0.06608,   inf] (37), [-0.06606,   inf] (37), [-0.06566,   inf] (37), [-0.06470,   inf] (37), [-0.06422,   inf] (37), [-0.06405,   inf] (37), [-0.06367,   inf] (37), [-0.06330,   inf] (37), [-0.06321,   inf] (37), [-0.06235,   inf] (37), 
length of domains: 1972
Total time: 2.3232	 pickout: 0.1964	 decision: 0.8570	 get_bound: 1.1812	 add_domain: 0.0886
Current lb:-0.0733698159456253
8282 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 20.39367985725403

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 497] [1, 497] [1, 497] [1, 497] [1, 497] [1, 497] [1, 497] [1, 497] [1, 853] [1, 853] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 43.598350524902344 with beta sum per layer: [0.0, 181.20724487304688, 98.89566040039062]
alpha/beta optimization time: 0.6209781169891357
This batch time : update_bounds func: 1.1414	 prepare: 0.2996	 bound: 0.6214	 transfer: 0.0386	 finalize: 0.1766
Accumulated time: update_bounds func: 8.1239	 prepare: 1.3459	 bound: 5.6579	 transfer: 0.0386	 finalize: 0.9123
batch bounding time:  1.1433541774749756
Current worst splitting domains [lb, ub] (depth):
[-0.06965,   inf] (39), [-0.06829,   inf] (39), [-0.06808,   inf] (39), [-0.06655,   inf] (39), [-0.06495,   inf] (39), [-0.06423,   inf] (39), [-0.06384,   inf] (39), [-0.06336,   inf] (39), [-0.06245,   inf] (39), [-0.06213,   inf] (39), [-0.06120,   inf] (39), [-0.06070,   inf] (39), [-0.06070,   inf] (39), [-0.06068,   inf] (39), [-0.05953,   inf] (39), [-0.05938,   inf] (39), [-0.05880,   inf] (39), [-0.05846,   inf] (39), [-0.05817,   inf] (39), [-0.05793,   inf] (39), 
length of domains: 2883
Total time: 2.4301	 pickout: 0.1988	 decision: 0.9148	 get_bound: 1.1468	 add_domain: 0.1697
Current lb:-0.06965027749538422
10330 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 22.838125467300415

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 843] [1, 481] [1, 843] [1, 481] [1, 843] [1, 843] [1, 481] [1, 843] [1, 843] [1, 481] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 42.97107696533203 with beta sum per layer: [0.0, 160.2005615234375, 83.05506896972656]
alpha/beta optimization time: 0.6004576683044434
This batch time : update_bounds func: 1.1376	 prepare: 0.2994	 bound: 0.6008	 transfer: 0.0391	 finalize: 0.1927
Accumulated time: update_bounds func: 9.2615	 prepare: 1.6453	 bound: 6.2587	 transfer: 0.0391	 finalize: 1.1049
batch bounding time:  1.1392781734466553
Current worst splitting domains [lb, ub] (depth):
[-0.06511,   inf] (41), [-0.06356,   inf] (41), [-0.06035,   inf] (41), [-0.06029,   inf] (41), [-0.05976,   inf] (41), [-0.05932,   inf] (41), [-0.05876,   inf] (41), [-0.05863,   inf] (41), [-0.05807,   inf] (41), [-0.05751,   inf] (41), [-0.05616,   inf] (41), [-0.05589,   inf] (41), [-0.05572,   inf] (41), [-0.05511,   inf] (41), [-0.05498,   inf] (41), [-0.05491,   inf] (41), [-0.05477,   inf] (41), [-0.05401,   inf] (41), [-0.05383,   inf] (41), [-0.05357,   inf] (41), 
length of domains: 3834
Total time: 2.3181	 pickout: 0.2023	 decision: 0.8658	 get_bound: 1.1423	 add_domain: 0.1077
Current lb:-0.0651141032576561
12378 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 25.171399116516113

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 481] [1, 481] [1, 481] [1, 843] [1, 481] [1, 843] [1, 481] [1, 843] [1, 481] [1, 843] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 37.47057342529297 with beta sum per layer: [0.0, 176.22705078125, 69.56066131591797]
alpha/beta optimization time: 0.5967438220977783
This batch time : update_bounds func: 0.9660	 prepare: 0.2007	 bound: 0.5971	 transfer: 0.0392	 finalize: 0.1242
Accumulated time: update_bounds func: 10.2275	 prepare: 1.8459	 bound: 6.8558	 transfer: 0.0392	 finalize: 1.2291
batch bounding time:  0.9677755832672119
Current worst splitting domains [lb, ub] (depth):
[-0.05674,   inf] (43), [-0.05668,   inf] (43), [-0.05569,   inf] (43), [-0.05519,   inf] (43), [-0.05511,   inf] (43), [-0.05477,   inf] (43), [-0.05408,   inf] (43), [-0.05312,   inf] (43), [-0.05193,   inf] (43), [-0.05189,   inf] (43), [-0.05151,   inf] (43), [-0.05147,   inf] (43), [-0.05094,   inf] (43), [-0.05040,   inf] (43), [-0.05031,   inf] (43), [-0.05027,   inf] (43), [-0.05009,   inf] (43), [-0.04985,   inf] (43), [-0.04974,   inf] (43), [-0.04946,   inf] (43), 
length of domains: 4680
Total time: 2.0496	 pickout: 0.1476	 decision: 0.7279	 get_bound: 0.9708	 add_domain: 0.2033
Current lb:-0.05673804506659508
14426 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 27.236878633499146

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 853] [1, 853] [1, 741] [1, 853] [1, 853] [1, 741] [1, 741] [1, 741] [1, 853] [1, 853] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 30.886493682861328 with beta sum per layer: [0.0, 136.89706420898438, 62.35432434082031]
alpha/beta optimization time: 0.5954511165618896
This batch time : update_bounds func: 1.0699	 prepare: 0.2017	 bound: 0.5958	 transfer: 0.0390	 finalize: 0.2280
Accumulated time: update_bounds func: 11.2974	 prepare: 2.0476	 bound: 7.4515	 transfer: 0.0390	 finalize: 1.4571
batch bounding time:  1.0716688632965088
Current worst splitting domains [lb, ub] (depth):
[-0.05084,   inf] (45), [-0.05070,   inf] (45), [-0.04942,   inf] (45), [-0.04910,   inf] (45), [-0.04893,   inf] (45), [-0.04857,   inf] (45), [-0.04789,   inf] (45), [-0.04694,   inf] (45), [-0.04678,   inf] (45), [-0.04662,   inf] (45), [-0.04607,   inf] (45), [-0.04574,   inf] (45), [-0.04560,   inf] (45), [-0.04545,   inf] (45), [-0.04536,   inf] (45), [-0.04527,   inf] (45), [-0.04521,   inf] (45), [-0.04509,   inf] (45), [-0.04443,   inf] (45), [-0.04401,   inf] (45), 
length of domains: 5525
Total time: 1.9755	 pickout: 0.1489	 decision: 0.6448	 get_bound: 1.0747	 add_domain: 0.1071
Current lb:-0.05084232985973358
16474 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 29.229603052139282

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 741] [1, 741] [1, 853] [1, 794] [1, 794] [1, 853] [1, 853] [1, 853] [1, 741] [1, 741] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 29.880619049072266 with beta sum per layer: [0.0, 140.09765625, 55.88875961303711]
alpha/beta optimization time: 0.5985012054443359
This batch time : update_bounds func: 0.9712	 prepare: 0.2023	 bound: 0.5988	 transfer: 0.0379	 finalize: 0.1269
Accumulated time: update_bounds func: 12.2686	 prepare: 2.2499	 bound: 8.0504	 transfer: 0.0379	 finalize: 1.5840
batch bounding time:  0.9729893207550049
Current worst splitting domains [lb, ub] (depth):
[-0.04472,   inf] (47), [-0.04457,   inf] (47), [-0.04419,   inf] (47), [-0.04357,   inf] (47), [-0.04240,   inf] (47), [-0.04188,   inf] (47), [-0.04181,   inf] (47), [-0.04173,   inf] (47), [-0.04128,   inf] (47), [-0.04106,   inf] (47), [-0.04079,   inf] (47), [-0.04063,   inf] (47), [-0.04049,   inf] (47), [-0.04035,   inf] (47), [-0.04014,   inf] (47), [-0.03963,   inf] (47), [-0.03947,   inf] (47), [-0.03933,   inf] (47), [-0.03926,   inf] (47), [-0.03916,   inf] (47), 
length of domains: 6377
Total time: 2.1313	 pickout: 0.1494	 decision: 0.7614	 get_bound: 0.9760	 add_domain: 0.2444
Current lb:-0.04472096636891365
18522 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 31.37815022468567

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 794] [1, 794] [1, 794] [1, 794] [1, 794] [1, 794] [1, 794] [1, 794] [1, 741] [1, 741] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 21.805458068847656 with beta sum per layer: [0.0, 164.2935791015625, 52.35702896118164]
alpha/beta optimization time: 0.596947193145752
This batch time : update_bounds func: 1.1198	 prepare: 0.2051	 bound: 0.5973	 transfer: 0.0390	 finalize: 0.2732
Accumulated time: update_bounds func: 13.3884	 prepare: 2.4550	 bound: 8.6476	 transfer: 0.0390	 finalize: 1.8572
batch bounding time:  1.1219031810760498
Current worst splitting domains [lb, ub] (depth):
[-0.03696,   inf] (49), [-0.03673,   inf] (49), [-0.03630,   inf] (49), [-0.03581,   inf] (49), [-0.03520,   inf] (49), [-0.03497,   inf] (49), [-0.03446,   inf] (49), [-0.03411,   inf] (49), [-0.03399,   inf] (49), [-0.03389,   inf] (49), [-0.03361,   inf] (49), [-0.03291,   inf] (49), [-0.03289,   inf] (49), [-0.03289,   inf] (49), [-0.03268,   inf] (49), [-0.03238,   inf] (49), [-0.03226,   inf] (49), [-0.03214,   inf] (49), [-0.03179,   inf] (49), [-0.03157,   inf] (49), 
length of domains: 7085
Total time: 2.0302	 pickout: 0.1498	 decision: 0.6503	 get_bound: 1.1252	 add_domain: 0.1050
Current lb:-0.036958932876586914
20570 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 33.426674127578735

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 725] [1, 725] [1, 725] [1, 725] [1, 725] [1, 725] [1, 725] [1, 725] [1, 725] [1, 725] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 19.226818084716797 with beta sum per layer: [0.0, 134.3408203125, 62.562198638916016]
alpha/beta optimization time: 0.5964975357055664
This batch time : update_bounds func: 1.1384	 prepare: 0.2055	 bound: 0.5968	 transfer: 0.0391	 finalize: 0.2913
Accumulated time: update_bounds func: 14.5269	 prepare: 2.6605	 bound: 9.2444	 transfer: 0.0391	 finalize: 2.1485
batch bounding time:  1.1403477191925049
Current worst splitting domains [lb, ub] (depth):
[-0.03241,   inf] (51), [-0.03218,   inf] (51), [-0.03099,   inf] (51), [-0.03045,   inf] (51), [-0.03027,   inf] (51), [-0.03020,   inf] (51), [-0.02987,   inf] (51), [-0.02964,   inf] (51), [-0.02954,   inf] (51), [-0.02930,   inf] (51), [-0.02895,   inf] (51), [-0.02894,   inf] (51), [-0.02880,   inf] (51), [-0.02872,   inf] (51), [-0.02827,   inf] (51), [-0.02818,   inf] (51), [-0.02818,   inf] (51), [-0.02802,   inf] (51), [-0.02759,   inf] (51), [-0.02745,   inf] (51), 
length of domains: 7838
Total time: 2.0523	 pickout: 0.1518	 decision: 0.6491	 get_bound: 1.1436	 add_domain: 0.1078
Current lb:-0.03241264820098877
22618 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 35.49851703643799

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 41] [2, 41] [2, 41] [2, 41] [1, 489] [2, 41] [2, 41] [2, 41] [2, 41] [2, 41] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -1.2282781600952148 with beta sum per layer: [0.0, 122.32611846923828, 66.1303939819336]
alpha/beta optimization time: 0.5957269668579102
This batch time : update_bounds func: 1.1530	 prepare: 0.2037	 bound: 0.5960	 transfer: 0.0373	 finalize: 0.3103
Accumulated time: update_bounds func: 15.6799	 prepare: 2.8643	 bound: 9.8405	 transfer: 0.0373	 finalize: 2.4588
batch bounding time:  1.1548821926116943
Current worst splitting domains [lb, ub] (depth):
[-0.02971,   inf] (53), [-0.02944,   inf] (53), [-0.02819,   inf] (53), [-0.02771,   inf] (53), [-0.02743,   inf] (53), [-0.02713,   inf] (53), [-0.02685,   inf] (53), [-0.02676,   inf] (53), [-0.02667,   inf] (53), [-0.02649,   inf] (53), [-0.02627,   inf] (53), [-0.02623,   inf] (53), [-0.02602,   inf] (53), [-0.02597,   inf] (53), [-0.02550,   inf] (53), [-0.02523,   inf] (53), [-0.02478,   inf] (53), [-0.02465,   inf] (53), [-0.02464,   inf] (53), [-0.02458,   inf] (53), 
length of domains: 8282
Total time: 2.0474	 pickout: 0.1529	 decision: 0.6461	 get_bound: 1.1581	 add_domain: 0.0903
Current lb:-0.029710769653320312
24666 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 37.568846464157104

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 51] [2, 51] [1, 489] [2, 51] [2, 51] [2, 51] [2, 51] [2, 51] [2, 41] [2, 51] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 3.5253024101257324 with beta sum per layer: [0.0, 145.4945831298828, 65.53463745117188]
alpha/beta optimization time: 0.5943582057952881
This batch time : update_bounds func: 1.1492	 prepare: 0.2068	 bound: 0.5947	 transfer: 0.0331	 finalize: 0.1313
Accumulated time: update_bounds func: 16.8291	 prepare: 3.0711	 bound: 10.4352	 transfer: 0.0331	 finalize: 2.5902
batch bounding time:  1.1510751247406006
Current worst splitting domains [lb, ub] (depth):
[-0.02754,   inf] (55), [-0.02726,   inf] (55), [-0.02566,   inf] (55), [-0.02550,   inf] (55), [-0.02522,   inf] (55), [-0.02498,   inf] (55), [-0.02469,   inf] (55), [-0.02458,   inf] (55), [-0.02431,   inf] (55), [-0.02413,   inf] (55), [-0.02392,   inf] (55), [-0.02383,   inf] (55), [-0.02352,   inf] (55), [-0.02341,   inf] (55), [-0.02333,   inf] (55), [-0.02304,   inf] (55), [-0.02259,   inf] (55), [-0.02256,   inf] (55), [-0.02242,   inf] (55), [-0.02230,   inf] (55), 
length of domains: 8696
Total time: 2.0462	 pickout: 0.1541	 decision: 0.6489	 get_bound: 1.1543	 add_domain: 0.0889
Current lb:-0.027541296556591988
26714 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 39.638896226882935

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 148] [1, 148] [2, 51] [1, 148] [1, 148] [1, 148] [1, 148] [1, 148] [1, 148] [1, 148] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 0.9048532247543335 with beta sum per layer: [0.0, 148.55218505859375, 62.69209289550781]
alpha/beta optimization time: 0.5946073532104492
This batch time : update_bounds func: 0.9790	 prepare: 0.2084	 bound: 0.5949	 transfer: 0.0375	 finalize: 0.1318
Accumulated time: update_bounds func: 17.8081	 prepare: 3.2796	 bound: 11.0301	 transfer: 0.0375	 finalize: 2.7219
batch bounding time:  0.9808499813079834
Current worst splitting domains [lb, ub] (depth):
[-0.02554,   inf] (57), [-0.02527,   inf] (57), [-0.02360,   inf] (57), [-0.02344,   inf] (57), [-0.02331,   inf] (57), [-0.02307,   inf] (57), [-0.02279,   inf] (57), [-0.02258,   inf] (57), [-0.02230,   inf] (57), [-0.02212,   inf] (57), [-0.02182,   inf] (57), [-0.02174,   inf] (57), [-0.02141,   inf] (57), [-0.02128,   inf] (57), [-0.02123,   inf] (57), [-0.02112,   inf] (57), [-0.02066,   inf] (57), [-0.02048,   inf] (57), [-0.02038,   inf] (57), [-0.02026,   inf] (57), 
length of domains: 9118
Total time: 2.0683	 pickout: 0.1540	 decision: 0.8396	 get_bound: 0.9842	 add_domain: 0.0905
Current lb:-0.02554473839700222
28762 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 41.7316951751709

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 922] [1, 922] [1, 922] [1, 148] [1, 922] [1, 922] [1, 922] [1, 922] [1, 922] [1, 922] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 3.6334917545318604 with beta sum per layer: [0.0, 141.15374755859375, 62.37942886352539]
alpha/beta optimization time: 0.5969924926757812
This batch time : update_bounds func: 0.9834	 prepare: 0.2058	 bound: 0.5973	 transfer: 0.0375	 finalize: 0.1364
Accumulated time: update_bounds func: 18.7915	 prepare: 3.4853	 bound: 11.6275	 transfer: 0.0375	 finalize: 2.8584
batch bounding time:  0.9854373931884766
Current worst splitting domains [lb, ub] (depth):
[-0.02250,   inf] (59), [-0.02237,   inf] (59), [-0.02224,   inf] (59), [-0.02135,   inf] (59), [-0.02123,   inf] (59), [-0.02057,   inf] (59), [-0.02049,   inf] (59), [-0.02042,   inf] (59), [-0.02005,   inf] (59), [-0.01991,   inf] (59), [-0.01979,   inf] (59), [-0.01975,   inf] (59), [-0.01962,   inf] (59), [-0.01954,   inf] (59), [-0.01940,   inf] (59), [-0.01934,   inf] (59), [-0.01931,   inf] (59), [-0.01925,   inf] (59), [-0.01907,   inf] (59), [-0.01897,   inf] (59), 
length of domains: 9624
Total time: 2.1009	 pickout: 0.1544	 decision: 0.8604	 get_bound: 0.9889	 add_domain: 0.0973
Current lb:-0.022498250007629395
30810 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 43.85769867897034

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 155] [1, 155] [1, 155] [1, 922] [1, 155] [1, 155] [1, 155] [1, 155] [1, 155] [1, 155] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1.1674939393997192 with beta sum per layer: [0.0, 144.53921508789062, 58.46882247924805]
alpha/beta optimization time: 0.5950853824615479
This batch time : update_bounds func: 0.9797	 prepare: 0.2055	 bound: 0.5954	 transfer: 0.0374	 finalize: 0.1348
Accumulated time: update_bounds func: 19.7711	 prepare: 3.6908	 bound: 12.2229	 transfer: 0.0374	 finalize: 2.9932
batch bounding time:  0.9815905094146729
Current worst splitting domains [lb, ub] (depth):
[-0.01869,   inf] (61), [-0.01851,   inf] (61), [-0.01837,   inf] (61), [-0.01790,   inf] (61), [-0.01742,   inf] (61), [-0.01694,   inf] (61), [-0.01683,   inf] (61), [-0.01663,   inf] (61), [-0.01660,   inf] (61), [-0.01659,   inf] (61), [-0.01654,   inf] (61), [-0.01645,   inf] (61), [-0.01643,   inf] (61), [-0.01604,   inf] (61), [-0.01591,   inf] (61), [-0.01561,   inf] (61), [-0.01555,   inf] (61), [-0.01547,   inf] (61), [-0.01542,   inf] (61), [-0.01540,   inf] (61), 
length of domains: 10169
Total time: 2.1096	 pickout: 0.1578	 decision: 0.8667	 get_bound: 0.9849	 add_domain: 0.1003
Current lb:-0.01869487762451172
32858 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 45.991931438446045

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 155] [1, 952] [1, 952] [1, 952] [1, 155] [1, 155] [1, 952] [1, 155] [1, 155] [1, 952] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -0.30424708127975464 with beta sum per layer: [0.0, 136.0732421875, 70.51460266113281]
alpha/beta optimization time: 0.5951476097106934
This batch time : update_bounds func: 1.2093	 prepare: 0.2063	 bound: 0.5955	 transfer: 0.0380	 finalize: 0.1336
Accumulated time: update_bounds func: 20.9805	 prepare: 3.8971	 bound: 12.8183	 transfer: 0.0380	 finalize: 3.1268
batch bounding time:  1.2112677097320557
Current worst splitting domains [lb, ub] (depth):
[-0.01637,   inf] (63), [-0.01625,   inf] (63), [-0.01562,   inf] (63), [-0.01462,   inf] (63), [-0.01460,   inf] (63), [-0.01452,   inf] (63), [-0.01439,   inf] (63), [-0.01435,   inf] (63), [-0.01400,   inf] (63), [-0.01386,   inf] (63), [-0.01361,   inf] (63), [-0.01348,   inf] (63), [-0.01339,   inf] (63), [-0.01330,   inf] (63), [-0.01325,   inf] (63), [-0.01324,   inf] (63), [-0.01300,   inf] (63), [-0.01291,   inf] (63), [-0.01291,   inf] (63), [-0.01290,   inf] (63), 
length of domains: 10669
Total time: 2.1205	 pickout: 0.1580	 decision: 0.6498	 get_bound: 1.2145	 add_domain: 0.0981
Current lb:-0.016373896971344948
34906 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 48.13819456100464

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 141] [1, 141] [1, 141] [1, 952] [1, 141] [1, 141] [1, 141] [1, 141] [1, 141] [1, 141] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -2.990471839904785 with beta sum per layer: [0.0, 140.00881958007812, 66.6834945678711]
alpha/beta optimization time: 0.5958962440490723
This batch time : update_bounds func: 1.2431	 prepare: 0.2051	 bound: 0.5962	 transfer: 0.0374	 finalize: 0.3991
Accumulated time: update_bounds func: 22.2236	 prepare: 4.1022	 bound: 13.4146	 transfer: 0.0374	 finalize: 3.5258
batch bounding time:  1.245105504989624
Current worst splitting domains [lb, ub] (depth):
[-0.01326,   inf] (65), [-0.01313,   inf] (65), [-0.01244,   inf] (65), [-0.01241,   inf] (65), [-0.01143,   inf] (65), [-0.01130,   inf] (65), [-0.01130,   inf] (65), [-0.01129,   inf] (65), [-0.01127,   inf] (65), [-0.01116,   inf] (65), [-0.01079,   inf] (65), [-0.01062,   inf] (65), [-0.01053,   inf] (65), [-0.01045,   inf] (65), [-0.01043,   inf] (65), [-0.01041,   inf] (65), [-0.01034,   inf] (65), [-0.01027,   inf] (65), [-0.01024,   inf] (65), [-0.01023,   inf] (65), 
length of domains: 11102
Total time: 2.1508	 pickout: 0.1573	 decision: 0.6510	 get_bound: 1.2485	 add_domain: 0.0940
Current lb:-0.013255399651825428
36954 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 50.31297779083252

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 149] [1, 149] [1, 141] [1, 149] [1, 149] [1, 149] [1, 732] [1, 149] [1, 149] [1, 732] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -6.218704700469971 with beta sum per layer: [0.0, 151.34254455566406, 65.39286041259766]
alpha/beta optimization time: 0.5980947017669678
This batch time : update_bounds func: 1.2636	 prepare: 0.2060	 bound: 0.5984	 transfer: 0.0374	 finalize: 0.4156
Accumulated time: update_bounds func: 23.4872	 prepare: 4.3082	 bound: 14.0130	 transfer: 0.0374	 finalize: 3.9414
batch bounding time:  1.2656238079071045
Current worst splitting domains [lb, ub] (depth):
[-0.01165,   inf] (67), [-0.01151,   inf] (67), [-0.01072,   inf] (67), [-0.00973,   inf] (67), [-0.00960,   inf] (67), [-0.00955,   inf] (67), [-0.00953,   inf] (67), [-0.00945,   inf] (67), [-0.00943,   inf] (67), [-0.00929,   inf] (67), [-0.00919,   inf] (53), [-0.00919,   inf] (51), [-0.00919,   inf] (63), [-0.00919,   inf] (51), [-0.00919,   inf] (41), [-0.00919,   inf] (47), [-0.00919,   inf] (55), [-0.00919,   inf] (45), [-0.00919,   inf] (59), [-0.00919,   inf] (61), 
length of domains: 11399
Total time: 2.1618	 pickout: 0.1587	 decision: 0.6471	 get_bound: 1.2691	 add_domain: 0.0869
Current lb:-0.011645183898508549
39002 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 52.50551700592041

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 721] [1, 721] [1, 721] [1, 721] [1, 721] [1, 721] [1, 721] [1, 149] [1, 489] [1, 489] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -7.957209587097168 with beta sum per layer: [0.0, 149.23086547851562, 61.66954803466797]
alpha/beta optimization time: 0.5946002006530762
This batch time : update_bounds func: 1.2702	 prepare: 0.2078	 bound: 0.5949	 transfer: 0.0372	 finalize: 0.4237
Accumulated time: update_bounds func: 24.7574	 prepare: 4.5160	 bound: 14.6079	 transfer: 0.0372	 finalize: 4.3651
batch bounding time:  1.2725880146026611
Current worst splitting domains [lb, ub] (depth):
[-0.00848,   inf] (45), [-0.00848,   inf] (47), [-0.00847,   inf] (61), [-0.00847,   inf] (43), [-0.00847,   inf] (65), [-0.00847,   inf] (45), [-0.00847,   inf] (43), [-0.00847,   inf] (45), [-0.00847,   inf] (37), [-0.00847,   inf] (41), [-0.00847,   inf] (43), [-0.00847,   inf] (55), [-0.00847,   inf] (43), [-0.00847,   inf] (63), [-0.00846,   inf] (47), [-0.00846,   inf] (43), [-0.00846,   inf] (47), [-0.00846,   inf] (61), [-0.00846,   inf] (49), [-0.00846,   inf] (43), 
length of domains: 11595
Total time: 2.1641	 pickout: 0.1579	 decision: 0.6494	 get_bound: 1.2764	 add_domain: 0.0803
Current lb:-0.008478641510009766
41050 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 54.698988914489746

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 853] [1, 794] [1, 481] [2, 41] [1, 149] [1, 853] [2, 41] [1, 794] [1, 797] [1, 741] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -9.643092155456543 with beta sum per layer: [0.0, 150.3418426513672, 59.46487808227539]
alpha/beta optimization time: 0.5950703620910645
This batch time : update_bounds func: 0.9834	 prepare: 0.2064	 bound: 0.5954	 transfer: 0.0374	 finalize: 0.1375
Accumulated time: update_bounds func: 25.7408	 prepare: 4.7224	 bound: 15.2033	 transfer: 0.0374	 finalize: 4.5026
batch bounding time:  0.985389232635498
Current worst splitting domains [lb, ub] (depth):
[-0.00782,   inf] (45), [-0.00782,   inf] (53), [-0.00781,   inf] (41), [-0.00781,   inf] (45), [-0.00781,   inf] (39), [-0.00781,   inf] (43), [-0.00781,   inf] (43), [-0.00781,   inf] (49), [-0.00781,   inf] (45), [-0.00781,   inf] (43), [-0.00781,   inf] (47), [-0.00781,   inf] (39), [-0.00781,   inf] (61), [-0.00781,   inf] (51), [-0.00781,   inf] (53), [-0.00781,   inf] (61), [-0.00781,   inf] (51), [-0.00781,   inf] (43), [-0.00781,   inf] (47), [-0.00781,   inf] (49), 
length of domains: 11662
Total time: 1.8737	 pickout: 0.1569	 decision: 0.6547	 get_bound: 0.9889	 add_domain: 0.0733
Current lb:-0.007815718650817871
43098 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 56.6035258769989

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 741] [1, 489] [1, 497] [1, 853] [1, 843] [1, 853] [1, 725] [1, 497] [1, 853] [1, 497] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -8.962835311889648 with beta sum per layer: [0.0, 150.227783203125, 62.757049560546875]
alpha/beta optimization time: 0.5942666530609131
This batch time : update_bounds func: 0.9818	 prepare: 0.2055	 bound: 0.5946	 transfer: 0.0374	 finalize: 0.1375
Accumulated time: update_bounds func: 26.7226	 prepare: 4.9278	 bound: 15.7979	 transfer: 0.0374	 finalize: 4.6401
batch bounding time:  0.9837527275085449
Current worst splitting domains [lb, ub] (depth):
[-0.00719,   inf] (51), [-0.00719,   inf] (53), [-0.00719,   inf] (57), [-0.00719,   inf] (53), [-0.00719,   inf] (49), [-0.00719,   inf] (49), [-0.00719,   inf] (55), [-0.00719,   inf] (45), [-0.00719,   inf] (63), [-0.00718,   inf] (45), [-0.00718,   inf] (39), [-0.00718,   inf] (43), [-0.00718,   inf] (57), [-0.00718,   inf] (59), [-0.00718,   inf] (55), [-0.00718,   inf] (51), [-0.00718,   inf] (45), [-0.00718,   inf] (47), [-0.00718,   inf] (53), [-0.00718,   inf] (41), 
length of domains: 11551
Total time: 2.1305	 pickout: 0.1570	 decision: 0.9219	 get_bound: 0.9890	 add_domain: 0.0626
Current lb:-0.007191061973571777
45146 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 58.767417907714844

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 41] [1, 489] [1, 922] [2, 51] [1, 481] [1, 794] [1, 148] [1, 741] [1, 141] [1, 667] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -11.834596633911133 with beta sum per layer: [0.0, 152.00228881835938, 66.02167510986328]
alpha/beta optimization time: 0.5951552391052246
This batch time : update_bounds func: 0.9844	 prepare: 0.2068	 bound: 0.5955	 transfer: 0.0375	 finalize: 0.1377
Accumulated time: update_bounds func: 27.7070	 prepare: 5.1346	 bound: 16.3934	 transfer: 0.0375	 finalize: 4.7778
batch bounding time:  0.9864070415496826
Current worst splitting domains [lb, ub] (depth):
[-0.00659,   inf] (55), [-0.00659,   inf] (51), [-0.00659,   inf] (47), [-0.00658,   inf] (49), [-0.00658,   inf] (51), [-0.00658,   inf] (49), [-0.00658,   inf] (43), [-0.00658,   inf] (41), [-0.00658,   inf] (53), [-0.00658,   inf] (55), [-0.00658,   inf] (47), [-0.00658,   inf] (61), [-0.00658,   inf] (49), [-0.00658,   inf] (49), [-0.00658,   inf] (49), [-0.00658,   inf] (61), [-0.00658,   inf] (53), [-0.00658,   inf] (53), [-0.00657,   inf] (43), [-0.00657,   inf] (45), 
length of domains: 11365
Total time: 2.1288	 pickout: 0.1580	 decision: 0.9223	 get_bound: 0.9899	 add_domain: 0.0585
Current lb:-0.0065872943960130215
47194 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 60.93050289154053

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 148] [1, 794] [1, 586] [1, 725] [2, 41] [1, 725] [1, 741] [1, 481] [2, 51] [1, 148] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -11.586024284362793 with beta sum per layer: [0.0, 143.67666625976562, 68.15287017822266]
alpha/beta optimization time: 0.5965955257415771
This batch time : update_bounds func: 1.2705	 prepare: 0.2072	 bound: 0.5969	 transfer: 0.0390	 finalize: 0.4206
Accumulated time: update_bounds func: 28.9775	 prepare: 5.3418	 bound: 16.9903	 transfer: 0.0390	 finalize: 5.1984
batch bounding time:  1.2725250720977783
Current worst splitting domains [lb, ub] (depth):
[-0.00602,   inf] (53), [-0.00602,   inf] (53), [-0.00602,   inf] (53), [-0.00602,   inf] (65), [-0.00602,   inf] (55), [-0.00602,   inf] (41), [-0.00602,   inf] (51), [-0.00602,   inf] (45), [-0.00602,   inf] (63), [-0.00602,   inf] (61), [-0.00602,   inf] (45), [-0.00602,   inf] (59), [-0.00602,   inf] (45), [-0.00602,   inf] (35), [-0.00602,   inf] (49), [-0.00602,   inf] (55), [-0.00602,   inf] (51), [-0.00602,   inf] (35), [-0.00602,   inf] (51), [-0.00601,   inf] (47), 
length of domains: 11119
Total time: 2.1446	 pickout: 0.1577	 decision: 0.6561	 get_bound: 1.2760	 add_domain: 0.0548
Current lb:-0.006024044007062912
49242 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 63.110663175582886

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 51] [1, 73] [2, 51] [1, 630] [1, 148] [1, 725] [2, 51] [1, 853] [1, 952] [1, 481] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -12.570444107055664 with beta sum per layer: [0.0, 154.34703063964844, 68.41812133789062]
alpha/beta optimization time: 0.5980527400970459
This batch time : update_bounds func: 1.2841	 prepare: 0.2072	 bound: 0.5984	 transfer: 0.0377	 finalize: 0.4340
Accumulated time: update_bounds func: 30.2617	 prepare: 5.5490	 bound: 17.5887	 transfer: 0.0377	 finalize: 5.6324
batch bounding time:  1.286384105682373
Current worst splitting domains [lb, ub] (depth):
[-0.00552,   inf] (53), [-0.00552,   inf] (43), [-0.00552,   inf] (51), [-0.00552,   inf] (63), [-0.00552,   inf] (51), [-0.00552,   inf] (53), [-0.00552,   inf] (55), [-0.00552,   inf] (57), [-0.00552,   inf] (51), [-0.00552,   inf] (39), [-0.00552,   inf] (49), [-0.00552,   inf] (49), [-0.00552,   inf] (59), [-0.00552,   inf] (55), [-0.00552,   inf] (45), [-0.00552,   inf] (57), [-0.00552,   inf] (63), [-0.00552,   inf] (53), [-0.00551,   inf] (43), [-0.00551,   inf] (49), 
length of domains: 10820
Total time: 2.1574	 pickout: 0.1586	 decision: 0.6567	 get_bound: 1.2902	 add_domain: 0.0519
Current lb:-0.00552364531904459
51290 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 65.30395698547363

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 489] [1, 853] [2, 41] [1, 732] [2, 41] [1, 482] [2, 51] [2, 51] [1, 489] [1, 843] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -13.979549407958984 with beta sum per layer: [0.0, 152.84707641601562, 68.45082092285156]
alpha/beta optimization time: 0.5962135791778564
This batch time : update_bounds func: 0.9913	 prepare: 0.2076	 bound: 0.5966	 transfer: 0.0398	 finalize: 0.1408
Accumulated time: update_bounds func: 31.2530	 prepare: 5.7566	 bound: 18.1853	 transfer: 0.0398	 finalize: 5.7732
batch bounding time:  0.9933145046234131
Current worst splitting domains [lb, ub] (depth):
[-0.00504,   inf] (49), [-0.00504,   inf] (59), [-0.00504,   inf] (51), [-0.00504,   inf] (51), [-0.00504,   inf] (45), [-0.00504,   inf] (55), [-0.00504,   inf] (59), [-0.00504,   inf] (57), [-0.00504,   inf] (51), [-0.00504,   inf] (55), [-0.00503,   inf] (45), [-0.00503,   inf] (61), [-0.00503,   inf] (35), [-0.00503,   inf] (47), [-0.00503,   inf] (49), [-0.00503,   inf] (47), [-0.00503,   inf] (51), [-0.00503,   inf] (47), [-0.00503,   inf] (45), [-0.00503,   inf] (37), 
length of domains: 10509
Total time: 1.8674	 pickout: 0.1599	 decision: 0.6594	 get_bound: 0.9968	 add_domain: 0.0512
Current lb:-0.00504148006439209
53338 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 67.20748734474182

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 794] [1, 922] [2, 41] [1, 73] [1, 667] [2, 41] [1, 155] [1, 922] [1, 481] [1, 922] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -14.656481742858887 with beta sum per layer: [0.0, 152.72738647460938, 68.81761169433594]
alpha/beta optimization time: 0.5964841842651367
This batch time : update_bounds func: 0.9873	 prepare: 0.2073	 bound: 0.5968	 transfer: 0.0373	 finalize: 0.1393
Accumulated time: update_bounds func: 32.2403	 prepare: 5.9639	 bound: 18.7821	 transfer: 0.0373	 finalize: 5.9125
batch bounding time:  0.9893229007720947
Current worst splitting domains [lb, ub] (depth):
[-0.00455,   inf] (37), [-0.00455,   inf] (69), [-0.00455,   inf] (47), [-0.00455,   inf] (43), [-0.00455,   inf] (51), [-0.00455,   inf] (45), [-0.00455,   inf] (45), [-0.00455,   inf] (47), [-0.00455,   inf] (47), [-0.00455,   inf] (51), [-0.00454,   inf] (41), [-0.00454,   inf] (43), [-0.00454,   inf] (53), [-0.00454,   inf] (51), [-0.00454,   inf] (47), [-0.00454,   inf] (53), [-0.00454,   inf] (65), [-0.00454,   inf] (41), [-0.00454,   inf] (47), [-0.00454,   inf] (67), 
length of domains: 10135
Total time: 2.1235	 pickout: 0.1596	 decision: 0.9241	 get_bound: 0.9928	 add_domain: 0.0470
Current lb:-0.004552006721496582
55386 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 69.36554026603699

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 797] [1, 925] [2, 41] [1, 741] [2, 41] [1, 853] [1, 853] [1, 794] [1, 741] [1, 489] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -16.032075881958008 with beta sum per layer: [0.0, 146.22215270996094, 69.88928985595703]
alpha/beta optimization time: 0.5947885513305664
This batch time : update_bounds func: 0.9912	 prepare: 0.2111	 bound: 0.5951	 transfer: 0.0373	 finalize: 0.1413
Accumulated time: update_bounds func: 33.2315	 prepare: 6.1750	 bound: 19.3772	 transfer: 0.0373	 finalize: 6.0538
batch bounding time:  0.9932568073272705
Current worst splitting domains [lb, ub] (depth):
[-0.00410,   inf] (57), [-0.00410,   inf] (51), [-0.00410,   inf] (41), [-0.00410,   inf] (41), [-0.00410,   inf] (47), [-0.00410,   inf] (43), [-0.00410,   inf] (59), [-0.00410,   inf] (51), [-0.00410,   inf] (45), [-0.00410,   inf] (55), [-0.00409,   inf] (55), [-0.00409,   inf] (65), [-0.00409,   inf] (67), [-0.00409,   inf] (37), [-0.00409,   inf] (43), [-0.00409,   inf] (45), [-0.00409,   inf] (53), [-0.00409,   inf] (39), [-0.00409,   inf] (41), [-0.00409,   inf] (57), 
length of domains: 9727
Total time: 2.1229	 pickout: 0.1634	 decision: 0.9190	 get_bound: 0.9968	 add_domain: 0.0435
Current lb:-0.004099845886230469
57434 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 71.52394962310791

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 922] [2, 41] [1, 725] [1, 853] [1, 868] [1, 725] [1, 922] [2, 41] [1, 741] [1, 148] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -17.264768600463867 with beta sum per layer: [0.0, 145.58267211914062, 71.38066101074219]
alpha/beta optimization time: 0.5957748889923096
This batch time : update_bounds func: 0.9953	 prepare: 0.2120	 bound: 0.5961	 transfer: 0.0391	 finalize: 0.1413
Accumulated time: update_bounds func: 34.2268	 prepare: 6.3870	 bound: 19.9733	 transfer: 0.0391	 finalize: 6.1951
batch bounding time:  0.9974279403686523
Current worst splitting domains [lb, ub] (depth):
[-0.00368,   inf] (53), [-0.00368,   inf] (49), [-0.00368,   inf] (43), [-0.00368,   inf] (61), [-0.00368,   inf] (37), [-0.00368,   inf] (63), [-0.00368,   inf] (65), [-0.00368,   inf] (55), [-0.00368,   inf] (43), [-0.00368,   inf] (51), [-0.00368,   inf] (63), [-0.00368,   inf] (47), [-0.00368,   inf] (51), [-0.00368,   inf] (53), [-0.00368,   inf] (51), [-0.00368,   inf] (37), [-0.00368,   inf] (55), [-0.00368,   inf] (51), [-0.00368,   inf] (43), [-0.00368,   inf] (47), 
length of domains: 9224
Total time: 2.1264	 pickout: 0.1622	 decision: 0.9241	 get_bound: 1.0010	 add_domain: 0.0390
Current lb:-0.003681659698486328
59482 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 73.68670701980591

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 51] [2, 41] [1, 725] [1, 952] [1, 797] [1, 489] [1, 732] [2, 41] [1, 725] [2, 41] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -17.582948684692383 with beta sum per layer: [0.0, 147.59951782226562, 70.72509765625]
alpha/beta optimization time: 0.5979399681091309
This batch time : update_bounds func: 1.2395	 prepare: 0.2091	 bound: 0.5983	 transfer: 0.0393	 finalize: 0.3864
Accumulated time: update_bounds func: 35.4663	 prepare: 6.5961	 bound: 20.5716	 transfer: 0.0393	 finalize: 6.5815
batch bounding time:  1.2415261268615723
Current worst splitting domains [lb, ub] (depth):
[-0.00325,   inf] (55), [-0.00325,   inf] (47), [-0.00325,   inf] (39), [-0.00325,   inf] (65), [-0.00325,   inf] (41), [-0.00325,   inf] (63), [-0.00325,   inf] (61), [-0.00325,   inf] (49), [-0.00325,   inf] (43), [-0.00324,   inf] (41), [-0.00324,   inf] (47), [-0.00324,   inf] (61), [-0.00324,   inf] (63), [-0.00324,   inf] (51), [-0.00324,   inf] (47), [-0.00324,   inf] (49), [-0.00324,   inf] (47), [-0.00324,   inf] (47), [-0.00324,   inf] (43), [-0.00324,   inf] (55), 
length of domains: 8651
Total time: 2.0967	 pickout: 0.1634	 decision: 0.6556	 get_bound: 1.2451	 add_domain: 0.0326
Current lb:-0.0032503642141819
61530 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 75.82012748718262

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 51] [1, 794] [2, 41] [1, 630] [1, 497] [1, 141] [1, 952] [1, 725] [1, 725] [1, 741] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -17.431350708007812 with beta sum per layer: [0.0, 149.63661193847656, 64.11994934082031]
alpha/beta optimization time: 0.591599702835083
This batch time : update_bounds func: 1.2281	 prepare: 0.2108	 bound: 0.5919	 transfer: 0.0394	 finalize: 0.3794
Accumulated time: update_bounds func: 36.6944	 prepare: 6.8068	 bound: 21.1635	 transfer: 0.0394	 finalize: 6.9609
batch bounding time:  1.2302231788635254
Current worst splitting domains [lb, ub] (depth):
[-0.00285,   inf] (45), [-0.00285,   inf] (47), [-0.00285,   inf] (55), [-0.00285,   inf] (67), [-0.00285,   inf] (59), [-0.00285,   inf] (67), [-0.00285,   inf] (63), [-0.00285,   inf] (41), [-0.00285,   inf] (47), [-0.00285,   inf] (43), [-0.00285,   inf] (45), [-0.00285,   inf] (59), [-0.00285,   inf] (49), [-0.00285,   inf] (63), [-0.00284,   inf] (51), [-0.00284,   inf] (45), [-0.00284,   inf] (65), [-0.00284,   inf] (69), [-0.00284,   inf] (47), [-0.00284,   inf] (51), 
length of domains: 8043
Total time: 2.0947	 pickout: 0.1686	 decision: 0.6606	 get_bound: 1.2337	 add_domain: 0.0317
Current lb:-0.002852916717529297
63578 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 77.9516749382019

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 41] [1, 794] [2, 51] [1, 721] [1, 155] [1, 489] [1, 141] [1, 868] [1, 794] [2, 41] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -18.351993560791016 with beta sum per layer: [0.0, 153.69952392578125, 66.10067749023438]
alpha/beta optimization time: 0.5955145359039307
This batch time : update_bounds func: 1.2230	 prepare: 0.2066	 bound: 0.5959	 transfer: 0.0373	 finalize: 0.3769
Accumulated time: update_bounds func: 37.9174	 prepare: 7.0134	 bound: 21.7594	 transfer: 0.0373	 finalize: 7.3378
batch bounding time:  1.225060224533081
Current worst splitting domains [lb, ub] (depth):
[-0.00245,   inf] (53), [-0.00245,   inf] (45), [-0.00245,   inf] (53), [-0.00245,   inf] (45), [-0.00245,   inf] (49), [-0.00245,   inf] (51), [-0.00245,   inf] (51), [-0.00245,   inf] (41), [-0.00245,   inf] (67), [-0.00245,   inf] (67), [-0.00245,   inf] (53), [-0.00245,   inf] (65), [-0.00245,   inf] (47), [-0.00245,   inf] (65), [-0.00245,   inf] (65), [-0.00245,   inf] (51), [-0.00245,   inf] (59), [-0.00244,   inf] (43), [-0.00244,   inf] (49), [-0.00244,   inf] (47), 
length of domains: 7286
Total time: 2.0691	 pickout: 0.1655	 decision: 0.6549	 get_bound: 1.2285	 add_domain: 0.0202
Current lb:-0.0024540163576602936
65626 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 80.05930685997009

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 51] [2, 41] [1, 148] [1, 868] [1, 794] [2, 51] [2, 41] [1, 725] [1, 721] [1, 149] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -19.560749053955078 with beta sum per layer: [0.0, 143.67776489257812, 66.21220397949219]
alpha/beta optimization time: 0.596165657043457
This batch time : update_bounds func: 1.2134	 prepare: 0.2061	 bound: 0.5965	 transfer: 0.0373	 finalize: 0.3671
Accumulated time: update_bounds func: 39.1309	 prepare: 7.2195	 bound: 22.3559	 transfer: 0.0373	 finalize: 7.7050
batch bounding time:  1.215644121170044
Current worst splitting domains [lb, ub] (depth):
[-0.00206,   inf] (65), [-0.00206,   inf] (65), [-0.00206,   inf] (55), [-0.00206,   inf] (69), [-0.00206,   inf] (53), [-0.00206,   inf] (51), [-0.00206,   inf] (49), [-0.00206,   inf] (47), [-0.00206,   inf] (43), [-0.00206,   inf] (57), [-0.00206,   inf] (55), [-0.00206,   inf] (53), [-0.00206,   inf] (69), [-0.00206,   inf] (51), [-0.00206,   inf] (49), [-0.00206,   inf] (43), [-0.00206,   inf] (61), [-0.00206,   inf] (45), [-0.00205,   inf] (55), [-0.00205,   inf] (49), 
length of domains: 6456
Total time: 2.0552	 pickout: 0.1652	 decision: 0.6555	 get_bound: 1.2193	 add_domain: 0.0152
Current lb:-0.0020605800673365593
67674 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 82.15299868583679

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 732] [1, 149] [2, 51] [1, 925] [1, 148] [1, 794] [1, 725] [1, 667] [1, 725] [1, 922] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -20.043041229248047 with beta sum per layer: [0.0, 153.35101318359375, 68.10741424560547]
alpha/beta optimization time: 0.5913946628570557
This batch time : update_bounds func: 1.1851	 prepare: 0.2070	 bound: 0.5917	 transfer: 0.0387	 finalize: 0.3415
Accumulated time: update_bounds func: 40.3159	 prepare: 7.4266	 bound: 22.9476	 transfer: 0.0387	 finalize: 8.0464
batch bounding time:  1.1875011920928955
Current worst splitting domains [lb, ub] (depth):
[-0.00171,   inf] (47), [-0.00171,   inf] (45), [-0.00171,   inf] (35), [-0.00171,   inf] (47), [-0.00171,   inf] (45), [-0.00171,   inf] (35), [-0.00171,   inf] (43), [-0.00171,   inf] (63), [-0.00171,   inf] (41), [-0.00171,   inf] (67), [-0.00171,   inf] (67), [-0.00171,   inf] (43), [-0.00171,   inf] (65), [-0.00171,   inf] (49), [-0.00170,   inf] (49), [-0.00170,   inf] (53), [-0.00170,   inf] (55), [-0.00170,   inf] (45), [-0.00170,   inf] (51), [-0.00170,   inf] (53), 
length of domains: 5488
Total time: 2.0179	 pickout: 0.1687	 decision: 0.6525	 get_bound: 1.1913	 add_domain: 0.0054
Current lb:-0.0017114877700805664
69722 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 84.20993971824646

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 794] [1, 741] [1, 797] [1, 794] [1, 853] [1, 284] [1, 489] [1, 141] [1, 794] [1, 489] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -20.406021118164062 with beta sum per layer: [0.0, 156.02789306640625, 75.32997131347656]
alpha/beta optimization time: 0.5905933380126953
This batch time : update_bounds func: 1.1550	 prepare: 0.2081	 bound: 0.5909	 transfer: 0.0333	 finalize: 0.3170
Accumulated time: update_bounds func: 41.4709	 prepare: 7.6347	 bound: 23.5386	 transfer: 0.0333	 finalize: 8.3634
batch bounding time:  1.1574265956878662
Current worst splitting domains [lb, ub] (depth):
[-0.00137,   inf] (49), [-0.00137,   inf] (61), [-0.00137,   inf] (47), [-0.00137,   inf] (55), [-0.00137,   inf] (61), [-0.00137,   inf] (43), [-0.00137,   inf] (53), [-0.00137,   inf] (53), [-0.00137,   inf] (49), [-0.00137,   inf] (41), [-0.00137,   inf] (51), [-0.00137,   inf] (53), [-0.00137,   inf] (65), [-0.00137,   inf] (51), [-0.00137,   inf] (59), [-0.00137,   inf] (47), [-0.00137,   inf] (61), [-0.00137,   inf] (69), [-0.00137,   inf] (69), [-0.00137,   inf] (65), 
length of domains: 4472
Total time: 1.9775	 pickout: 0.1687	 decision: 0.6460	 get_bound: 1.1612	 add_domain: 0.0016
Current lb:-0.0013742446899414062
71770 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 86.22626423835754

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 741] [1, 952] [1, 741] [1, 148] [1, 732] [1, 794] [1, 482] [1, 482] [1, 725] [1, 725] 
regular batch size: 2*1024, diving batch size 1*0

all verified at 12th iter
best_l after optimization: -21.930923461914062 with beta sum per layer: [0.0, 153.40025329589844, 68.06327819824219]
alpha/beta optimization time: 0.3347749710083008
This batch time : update_bounds func: 0.7205	 prepare: 0.2056	 bound: 0.3351	 transfer: 0.0369	 finalize: 0.1372
Accumulated time: update_bounds func: 42.1915	 prepare: 7.8403	 bound: 23.8737	 transfer: 0.0369	 finalize: 8.5006
batch bounding time:  0.7224242687225342
Current worst splitting domains [lb, ub] (depth):
[-0.00105,   inf] (57), [-0.00105,   inf] (45), [-0.00105,   inf] (47), [-0.00105,   inf] (49), [-0.00105,   inf] (51), [-0.00105,   inf] (65), [-0.00105,   inf] (67), [-0.00105,   inf] (43), [-0.00105,   inf] (51), [-0.00105,   inf] (53), [-0.00105,   inf] (45), [-0.00105,   inf] (53), [-0.00105,   inf] (47), [-0.00105,   inf] (41), [-0.00105,   inf] (41), [-0.00105,   inf] (69), [-0.00105,   inf] (43), [-0.00105,   inf] (39), [-0.00105,   inf] (57), [-0.00105,   inf] (49), 
length of domains: 3448
Total time: 1.5420	 pickout: 0.1701	 decision: 0.6451	 get_bound: 0.7258	 add_domain: 0.0010
Current lb:-0.0010535717010498047
73818 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 87.8094871044159

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 922] [1, 741] [1, 794] [1, 481] [2, 41] [1, 482] [1, 721] [1, 725] [1, 725] [1, 489] 
regular batch size: 2*1024, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -22.791772842407227 with beta sum per layer: [0.0, 147.29110717773438, 68.2070083618164]
alpha/beta optimization time: 0.019031763076782227
This batch time : update_bounds func: 0.5216	 prepare: 0.2075	 bound: 0.0193	 transfer: 0.0333	 finalize: 0.2557
Accumulated time: update_bounds func: 42.7131	 prepare: 8.0478	 bound: 23.8930	 transfer: 0.0333	 finalize: 8.7563
batch bounding time:  0.5234241485595703
Current worst splitting domains [lb, ub] (depth):
[-0.00074,   inf] (53), [-0.00074,   inf] (51), [-0.00074,   inf] (69), [-0.00074,   inf] (51), [-0.00074,   inf] (43), [-0.00074,   inf] (49), [-0.00074,   inf] (49), [-0.00074,   inf] (51), [-0.00074,   inf] (65), [-0.00074,   inf] (59), [-0.00074,   inf] (47), [-0.00074,   inf] (65), [-0.00074,   inf] (43), [-0.00074,   inf] (47), [-0.00074,   inf] (55), [-0.00074,   inf] (51), [-0.00074,   inf] (45), [-0.00074,   inf] (39), [-0.00073,   inf] (47), [-0.00073,   inf] (63), 
length of domains: 2424
Total time: 1.4561	 pickout: 0.1653	 decision: 0.7630	 get_bound: 0.5268	 add_domain: 0.0010
Current lb:-0.0007410049438476562
75866 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 89.30474519729614

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 51] [2, 41] [1, 721] [1, 489] [1, 794] [1, 725] [1, 481] [1, 843] [1, 149] [1, 155] 
regular batch size: 2*1024, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -22.73244285583496 with beta sum per layer: [0.0, 163.59524536132812, 65.37101745605469]
alpha/beta optimization time: 0.018991947174072266
This batch time : update_bounds func: 0.4865	 prepare: 0.2050	 bound: 0.0193	 transfer: 0.0318	 finalize: 0.2245
Accumulated time: update_bounds func: 43.1995	 prepare: 8.2528	 bound: 23.9123	 transfer: 0.0318	 finalize: 8.9808
batch bounding time:  0.48825764656066895
Current worst splitting domains [lb, ub] (depth):
[-0.00041,   inf] (45), [-0.00041,   inf] (35), [-0.00041,   inf] (45), [-0.00041,   inf] (57), [-0.00041,   inf] (51), [-0.00041,   inf] (47), [-0.00041,   inf] (51), [-0.00041,   inf] (67), [-0.00041,   inf] (41), [-0.00041,   inf] (55), [-0.00041,   inf] (43), [-0.00041,   inf] (45), [-0.00041,   inf] (65), [-0.00041,   inf] (49), [-0.00041,   inf] (41), [-0.00041,   inf] (41), [-0.00041,   inf] (49), [-0.00041,   inf] (41), [-0.00041,   inf] (61), [-0.00041,   inf] (59), 
length of domains: 1400
Total time: 1.3101	 pickout: 0.1680	 decision: 0.6495	 get_bound: 0.4915	 add_domain: 0.0010
Current lb:-0.00041338062146678567
77914 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 90.65252566337585

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 741] [1, 797] [1, 853] [1, 922] [1, 868] [1, 794] [2, 41] [1, 482] [1, 725] [2, 51] 
regular batch size: 2*1024, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -22.241283416748047 with beta sum per layer: [0.0, 159.201171875, 64.70864868164062]
alpha/beta optimization time: 0.018874645233154297
This batch time : update_bounds func: 0.3635	 prepare: 0.2025	 bound: 0.0192	 transfer: 0.0126	 finalize: 0.1239
Accumulated time: update_bounds func: 43.5631	 prepare: 8.4553	 bound: 23.9314	 transfer: 0.0126	 finalize: 9.1047
batch bounding time:  0.3653113842010498
Current worst splitting domains [lb, ub] (depth):
[-0.00012,   inf] (61), [-0.00012,   inf] (43), [-0.00012,   inf] (69), [-0.00012,   inf] (63), [-0.00011,   inf] (45), [-0.00011,   inf] (43), [-0.00011,   inf] (39), [-0.00011,   inf] (49), [-0.00011,   inf] (61), [-0.00011,   inf] (61), [-0.00011,   inf] (49), [-0.00011,   inf] (59), [-0.00011,   inf] (43), [-0.00011,   inf] (61), [-0.00011,   inf] (37), [-0.00011,   inf] (59), [-0.00011,   inf] (61), [-0.00011,   inf] (49), [-0.00011,   inf] (39), [-0.00011,   inf] (53), 
length of domains: 376
Total time: 1.2624	 pickout: 0.1763	 decision: 0.7166	 get_bound: 0.3686	 add_domain: 0.0010
Current lb:-0.00011568114132387564
79962 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 91.95002698898315

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([376, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([376, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 732] [2, 41] [1, 925] [1, 586] [1, 853] [1, 794] [1, 497] [1, 725] [1, 155] [1, 952] 
regular batch size: 2*376, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -8.270467758178711 with beta sum per layer: [0.0, 56.50432205200195, 23.975589752197266]
alpha/beta optimization time: 0.011980772018432617
This batch time : update_bounds func: 0.1800	 prepare: 0.0759	 bound: 0.0123	 transfer: 0.0046	 finalize: 0.0854
Accumulated time: update_bounds func: 43.7431	 prepare: 8.5312	 bound: 23.9437	 transfer: 0.0046	 finalize: 9.1901
batch bounding time:  0.18066811561584473
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.4995	 pickout: 0.0753	 decision: 0.2420	 get_bound: 0.1819	 add_domain: 0.0003
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 92.46609330177307

Image 64 label 3 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 92.53647375106812
64 1.0000000116860974e-07
Result: image 64 verification success (with branch and bound)!
Wall time: 92.57229256629944

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 1): [64]
verification failure idx (total 0): []
final verified acc: 100.0%[1]
verifier is called on 1 examples.
total verified: 1
mean time [cnt:1] (excluding attack success): 92.53647375106812
