Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: specify-target
  complete_verifier: bab
  enable_incomplete_verification: false
  get_crown_verified_acc: false
model:
  path: cifar_base.pth
  name: cifar_model_base
data:
  start: 66
  end: 67
  num_outputs: 10
  mean: [0.485, 0.456, 0.406]
  std: [0.225, 0.225, 0.225]
  pkl_path: base_100.pkl
  dataset: CIFAR
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: null
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 1024
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 360
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: fsb
    candidates: 1
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Tue May  3 01:29:11 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(3, 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(8, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Flatten()
  (5): Linear(in_features=1024, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=10, bias=True)
)
No epsilon defined!
Files already downloaded and verified
Overwrite epsilon that saved in .pkl file, they should be after normalized!
Task length: 1
saving results to Verified_ret_[cifar_model_base]_start=66_end=67_iter=20_b=1024_timeout=360_branching=fsb-min-1_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 66 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 0, correct label 0, image norm 3320.24267578125, logits tensor([ 2.3019, -1.9807,  1.6448,  0.4504,  0.7473, -0.0675,  0.5546, -0.9867,
        -0.9355, -1.7287], device='cuda:0', grad_fn=<SelectBackward>)
##### [0:66] Tested against 5 ######
Model prediction is: tensor([[ 2.3019, -1.9807,  1.6448,  0.4504,  0.7473, -0.0675,  0.5546, -0.9867,
         -0.9355, -1.7287]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-1.1941]], device='cuda:0') None
best_l after optimization: 0.8571346998214722 with beta sum per layer: []
alpha/beta optimization time: 7.256927251815796
initial alpha-CROWN bounds: tensor([[-0.8571]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.8571, device='cuda:0', grad_fn=<MinBackward1>)
-0.8571346998214722
layer 0 size torch.Size([2048]) unstable 509
layer 1 size torch.Size([1024]) unstable 255
layer 2 size torch.Size([100]) unstable 40
-----------------
# of unstable neurons: 804
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 8, 16, 16]) pre split depth:  6
batch:  torch.Size([1, 8, 16, 16]) post split depth:  6
splitting decisions: 
split level 0: [2, 42] 
split level 1: [2, 31] 
split level 2: [2, 83] 
split level 3: [2, 79] 
split level 4: [2, 65] 
split level 5: [2, 47] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: 1.0738784074783325 with beta sum per layer: [0.0, 0.0, 47.5264778137207]
alpha/beta optimization time: 0.28936314582824707
This batch time : update_bounds func: 0.3054	 prepare: 0.0086	 bound: 0.2897	 transfer: 0.0012	 finalize: 0.0055
Accumulated time: update_bounds func: 0.3054	 prepare: 0.0086	 bound: 0.2897	 transfer: 0.0012	 finalize: 0.0055
batch bounding time:  0.30562257766723633
Current worst splitting domains [lb, ub] (depth):
[-0.44236,   inf] (7), [-0.43882,   inf] (7), [-0.39760,   inf] (7), [-0.38459,   inf] (7), [-0.30171,   inf] (7), [-0.27026,   inf] (7), [-0.26118,   inf] (7), [-0.24298,   inf] (7), [-0.23166,   inf] (7), [-0.23137,   inf] (7), [-0.21718,   inf] (7), [-0.21300,   inf] (7), [-0.20770,   inf] (7), [-0.20513,   inf] (7), [-0.14492,   inf] (7), [-0.13931,   inf] (7), [-0.11269,   inf] (7), [-0.10564,   inf] (7), [-0.10384,   inf] (7), [-0.07997,   inf] (7), 
length of domains: 25
Total time: 0.4049	 pickout: 0.0012	 decision: 0.0861	 get_bound: 0.3165	 add_domain: 0.0011
Current lb:-0.44236382842063904
64 neurons visited
0 diving domains visited
Global ub: tensor([[inf]], device='cuda:0'), batch ub: inf
Cumulative time: 9.456104040145874

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([25, 8, 16, 16]) pre split depth:  2
batch:  torch.Size([25, 8, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [2, 3] [2, 23] [2, 23] [2, 23] [2, 3] [1, 82] [2, 23] [2, 23] [2, 23] [2, 3] 
split level 1: [2, 23] [1, 597] [1, 91] [2, 3] [2, 23] [2, 3] [1, 98] [1, 91] [2, 3] [2, 23] 
regular batch size: 2*50, diving batch size 1*0
best_l after optimization: 1.1544886827468872 with beta sum per layer: [0.0, 0.8803428411483765, 124.11358642578125]
alpha/beta optimization time: 0.2521553039550781
This batch time : update_bounds func: 0.2716	 prepare: 0.0102	 bound: 0.2525	 transfer: 0.0020	 finalize: 0.0066
Accumulated time: update_bounds func: 0.5770	 prepare: 0.0188	 bound: 0.5422	 transfer: 0.0020	 finalize: 0.0122
batch bounding time:  0.27182936668395996
Current worst splitting domains [lb, ub] (depth):
[-0.39244,   inf] (10), [-0.37505,   inf] (10), [-0.34239,   inf] (10), [-0.31370,   inf] (10), [-0.30250,   inf] (10), [-0.24664,   inf] (10), [-0.24110,   inf] (10), [-0.21219,   inf] (10), [-0.20419,   inf] (10), [-0.20244,   inf] (10), [-0.19900,   inf] (10), [-0.18873,   inf] (10), [-0.18730,   inf] (10), [-0.18623,   inf] (10), [-0.18019,   inf] (10), [-0.16502,   inf] (10), [-0.15744,   inf] (10), [-0.15202,   inf] (10), [-0.15154,   inf] (10), [-0.15006,   inf] (10), 
length of domains: 35
Total time: 0.3381	 pickout: 0.0055	 decision: 0.0535	 get_bound: 0.2778	 add_domain: 0.0013
Current lb:-0.39244309067726135
164 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.794764041900635

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([35, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([35, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 3] [1, 82] [2, 3] [2, 62] [1, 82] [2, 3] [1, 82] [2, 23] [2, 23] [1, 82] 
regular batch size: 2*35, diving batch size 1*0
best_l after optimization: 6.064894199371338 with beta sum per layer: [0.0, 1.652115821838379, 73.31556701660156]
alpha/beta optimization time: 0.2467641830444336
This batch time : update_bounds func: 0.2606	 prepare: 0.0079	 bound: 0.2470	 transfer: 0.0014	 finalize: 0.0041
Accumulated time: update_bounds func: 0.8376	 prepare: 0.0267	 bound: 0.7892	 transfer: 0.0014	 finalize: 0.0163
batch bounding time:  0.26098060607910156
Current worst splitting domains [lb, ub] (depth):
[-0.35947,   inf] (12), [-0.34324,   inf] (12), [-0.34011,   inf] (12), [-0.30956,   inf] (12), [-0.29014,   inf] (12), [-0.26379,   inf] (12), [-0.26146,   inf] (12), [-0.21448,   inf] (12), [-0.21312,   inf] (12), [-0.21203,   inf] (12), [-0.17965,   inf] (12), [-0.17275,   inf] (12), [-0.16310,   inf] (12), [-0.15844,   inf] (12), [-0.15087,   inf] (12), [-0.14651,   inf] (12), [-0.14608,   inf] (12), [-0.14385,   inf] (12), [-0.14020,   inf] (12), [-0.13938,   inf] (12), 
length of domains: 49
Total time: 0.3013	 pickout: 0.0050	 decision: 0.0335	 get_bound: 0.2611	 add_domain: 0.0017
Current lb:-0.3594721257686615
234 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.096648931503296

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([49, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([49, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 82] [2, 62] [2, 62] [1, 82] [2, 50] [2, 3] [2, 3] [2, 62] [2, 62] [2, 62] 
regular batch size: 2*49, diving batch size 1*0
best_l after optimization: 3.5515220165252686 with beta sum per layer: [0.0, 2.0658962726593018, 105.80070495605469]
alpha/beta optimization time: 0.24348092079162598
This batch time : update_bounds func: 0.2624	 prepare: 0.0107	 bound: 0.2438	 transfer: 0.0017	 finalize: 0.0059
Accumulated time: update_bounds func: 1.1000	 prepare: 0.0374	 bound: 1.0330	 transfer: 0.0017	 finalize: 0.0222
batch bounding time:  0.2625575065612793
Current worst splitting domains [lb, ub] (depth):
[-0.32612,   inf] (14), [-0.32380,   inf] (14), [-0.31740,   inf] (14), [-0.31412,   inf] (14), [-0.27786,   inf] (14), [-0.27612,   inf] (14), [-0.27033,   inf] (14), [-0.23022,   inf] (14), [-0.22564,   inf] (14), [-0.19097,   inf] (14), [-0.18552,   inf] (14), [-0.18306,   inf] (14), [-0.15342,   inf] (14), [-0.14639,   inf] (14), [-0.13076,   inf] (14), [-0.12958,   inf] (14), [-0.12947,   inf] (14), [-0.12421,   inf] (14), [-0.11623,   inf] (14), [-0.11393,   inf] (14), 
length of domains: 54
Total time: 0.3138	 pickout: 0.0068	 decision: 0.0423	 get_bound: 0.2627	 add_domain: 0.0020
Current lb:-0.3261178135871887
332 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.41122817993164

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([54, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([54, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 62] [2, 62] [2, 50] [2, 50] [2, 62] [2, 62] [1, 91] [2, 62] [2, 62] [1, 110] 
regular batch size: 2*54, diving batch size 1*0
best_l after optimization: 3.1229584217071533 with beta sum per layer: [0.0, 2.3246679306030273, 113.41151428222656]
alpha/beta optimization time: 0.25880861282348633
This batch time : update_bounds func: 0.2843	 prepare: 0.0118	 bound: 0.2592	 transfer: 0.0034	 finalize: 0.0097
Accumulated time: update_bounds func: 1.3843	 prepare: 0.0492	 bound: 1.2922	 transfer: 0.0034	 finalize: 0.0319
batch bounding time:  0.28467702865600586
Current worst splitting domains [lb, ub] (depth):
[-0.30114,   inf] (16), [-0.29916,   inf] (16), [-0.29807,   inf] (16), [-0.29478,   inf] (16), [-0.25608,   inf] (16), [-0.25374,   inf] (16), [-0.25301,   inf] (16), [-0.20346,   inf] (16), [-0.19728,   inf] (16), [-0.16812,   inf] (16), [-0.16557,   inf] (16), [-0.16228,   inf] (16), [-0.15450,   inf] (16), [-0.14728,   inf] (16), [-0.13608,   inf] (16), [-0.12950,   inf] (16), [-0.10543,   inf] (16), [-0.10178,   inf] (16), [-0.10035,   inf] (16), [-0.09994,   inf] (16), 
length of domains: 56
Total time: 0.3402	 pickout: 0.0074	 decision: 0.0452	 get_bound: 0.2849	 add_domain: 0.0026
Current lb:-0.30113765597343445
440 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.752495765686035

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([56, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([56, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 50] [1, 98] [2, 18] [2, 18] [2, 50] [2, 50] [2, 18] [2, 50] [2, 50] [2, 18] 
regular batch size: 2*56, diving batch size 1*0
best_l after optimization: 2.3355207443237305 with beta sum per layer: [0.0, 2.2623982429504395, 108.11517333984375]
alpha/beta optimization time: 0.28769993782043457
This batch time : update_bounds func: 0.3181	 prepare: 0.0178	 bound: 0.2881	 transfer: 0.0026	 finalize: 0.0094
Accumulated time: update_bounds func: 1.7024	 prepare: 0.0670	 bound: 1.5802	 transfer: 0.0026	 finalize: 0.0413
batch bounding time:  0.3183908462524414
Current worst splitting domains [lb, ub] (depth):
[-0.28297,   inf] (18), [-0.28205,   inf] (18), [-0.27991,   inf] (18), [-0.27924,   inf] (18), [-0.25251,   inf] (18), [-0.23738,   inf] (18), [-0.23624,   inf] (18), [-0.23505,   inf] (18), [-0.18500,   inf] (18), [-0.17818,   inf] (18), [-0.15430,   inf] (18), [-0.15198,   inf] (18), [-0.14337,   inf] (18), [-0.12790,   inf] (18), [-0.12371,   inf] (18), [-0.12181,   inf] (18), [-0.11518,   inf] (18), [-0.11126,   inf] (18), [-0.08556,   inf] (18), [-0.08496,   inf] (18), 
length of domains: 58
Total time: 0.3938	 pickout: 0.0113	 decision: 0.0615	 get_bound: 0.3186	 add_domain: 0.0024
Current lb:-0.28297412395477295
552 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.147284984588623

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([58, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([58, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 10] [2, 18] [2, 10] [2, 50] [2, 50] [2, 18] [2, 10] [2, 18] [1, 91] [1, 91] 
regular batch size: 2*58, diving batch size 1*0
best_l after optimization: 1.5065948963165283 with beta sum per layer: [0.0, 3.7688348293304443, 105.28820037841797]
alpha/beta optimization time: 0.28698205947875977
This batch time : update_bounds func: 0.3187	 prepare: 0.0186	 bound: 0.2873	 transfer: 0.0024	 finalize: 0.0102
Accumulated time: update_bounds func: 2.0212	 prepare: 0.0856	 bound: 1.8676	 transfer: 0.0024	 finalize: 0.0516
batch bounding time:  0.3189713954925537
Current worst splitting domains [lb, ub] (depth):
[-0.27022,   inf] (20), [-0.26722,   inf] (20), [-0.26689,   inf] (20), [-0.26034,   inf] (20), [-0.23251,   inf] (20), [-0.22419,   inf] (20), [-0.22070,   inf] (20), [-0.21856,   inf] (20), [-0.16657,   inf] (20), [-0.16070,   inf] (20), [-0.14159,   inf] (20), [-0.13914,   inf] (20), [-0.12652,   inf] (20), [-0.12112,   inf] (20), [-0.11115,   inf] (20), [-0.10931,   inf] (20), [-0.10695,   inf] (20), [-0.10261,   inf] (20), [-0.09428,   inf] (20), [-0.08925,   inf] (20), 
length of domains: 60
Total time: 0.4005	 pickout: 0.0157	 decision: 0.0633	 get_bound: 0.3192	 add_domain: 0.0023
Current lb:-0.27022117376327515
668 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.548665285110474

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([60, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([60, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 597] [1, 597] [1, 91] [2, 18] [2, 18] [1, 109] [1, 110] [1, 597] [1, 98] [1, 98] 
regular batch size: 2*60, diving batch size 1*0
best_l after optimization: 3.008366584777832 with beta sum per layer: [0.0, 5.8976945877075195, 96.78788757324219]
alpha/beta optimization time: 0.2885284423828125
This batch time : update_bounds func: 0.3201	 prepare: 0.0190	 bound: 0.2889	 transfer: 0.0016	 finalize: 0.0103
Accumulated time: update_bounds func: 2.3413	 prepare: 0.1046	 bound: 2.1565	 transfer: 0.0016	 finalize: 0.0618
batch bounding time:  0.320357084274292
Current worst splitting domains [lb, ub] (depth):
[-0.25977,   inf] (22), [-0.25619,   inf] (22), [-0.25279,   inf] (22), [-0.24510,   inf] (22), [-0.21692,   inf] (22), [-0.21000,   inf] (22), [-0.20461,   inf] (22), [-0.19727,   inf] (22), [-0.18219,   inf] (22), [-0.17717,   inf] (22), [-0.17227,   inf] (22), [-0.16943,   inf] (22), [-0.14581,   inf] (22), [-0.13949,   inf] (22), [-0.13372,   inf] (22), [-0.13274,   inf] (22), [-0.13047,   inf] (22), [-0.12006,   inf] (22), [-0.11435,   inf] (22), [-0.10874,   inf] (22), 
length of domains: 70
Total time: 0.4003	 pickout: 0.0119	 decision: 0.0643	 get_bound: 0.3206	 add_domain: 0.0035
Current lb:-0.25977277755737305
788 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.949862718582153

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([70, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([70, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 109] [1, 109] [1, 98] [2, 10] [2, 10] [1, 110] [1, 110] [1, 597] [1, 597] [1, 98] 
regular batch size: 2*70, diving batch size 1*0
best_l after optimization: 3.1870498657226562 with beta sum per layer: [0.0, 11.336369514465332, 92.64823150634766]
alpha/beta optimization time: 0.2870626449584961
This batch time : update_bounds func: 0.3237	 prepare: 0.0218	 bound: 0.2874	 transfer: 0.0025	 finalize: 0.0117
Accumulated time: update_bounds func: 2.6650	 prepare: 0.1264	 bound: 2.4439	 transfer: 0.0025	 finalize: 0.0735
batch bounding time:  0.32393622398376465
Current worst splitting domains [lb, ub] (depth):
[-0.24843,   inf] (24), [-0.24484,   inf] (24), [-0.23283,   inf] (24), [-0.23267,   inf] (24), [-0.20644,   inf] (24), [-0.20436,   inf] (24), [-0.18982,   inf] (24), [-0.18720,   inf] (24), [-0.18689,   inf] (24), [-0.18378,   inf] (24), [-0.18043,   inf] (24), [-0.17070,   inf] (24), [-0.16869,   inf] (24), [-0.16535,   inf] (24), [-0.15797,   inf] (24), [-0.15637,   inf] (24), [-0.15363,   inf] (24), [-0.13122,   inf] (24), [-0.12489,   inf] (24), [-0.12382,   inf] (24), 
length of domains: 79
Total time: 0.4138	 pickout: 0.0137	 decision: 0.0726	 get_bound: 0.3242	 add_domain: 0.0033
Current lb:-0.24842870235443115
928 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.364630699157715

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([79, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([79, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 98] [1, 98] [1, 109] [2, 10] [2, 10] [1, 109] [1, 91] [1, 597] [1, 98] [1, 109] 
regular batch size: 2*79, diving batch size 1*0
best_l after optimization: 4.6591796875 with beta sum per layer: [0.0, 16.45612907409668, 85.69572448730469]
alpha/beta optimization time: 0.2619602680206299
This batch time : update_bounds func: 0.3046	 prepare: 0.0243	 bound: 0.2623	 transfer: 0.0077	 finalize: 0.0099
Accumulated time: update_bounds func: 2.9696	 prepare: 0.1508	 bound: 2.7062	 transfer: 0.0077	 finalize: 0.0834
batch bounding time:  0.30489349365234375
Current worst splitting domains [lb, ub] (depth):
[-0.22937,   inf] (26), [-0.22595,   inf] (26), [-0.22179,   inf] (26), [-0.22012,   inf] (26), [-0.20162,   inf] (26), [-0.19776,   inf] (26), [-0.19340,   inf] (26), [-0.19309,   inf] (26), [-0.17615,   inf] (26), [-0.17432,   inf] (26), [-0.17095,   inf] (26), [-0.16794,   inf] (26), [-0.16744,   inf] (26), [-0.16431,   inf] (26), [-0.15276,   inf] (26), [-0.14943,   inf] (26), [-0.14376,   inf] (26), [-0.14248,   inf] (26), [-0.14041,   inf] (26), [-0.13988,   inf] (26), 
length of domains: 94
Total time: 0.4065	 pickout: 0.0152	 decision: 0.0815	 get_bound: 0.3051	 add_domain: 0.0047
Current lb:-0.22936566174030304
1086 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.772491216659546

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([94, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([94, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 91] [1, 91] [1, 91] [1, 109] [1, 91] [1, 91] [1, 109] [1, 91] [1, 98] [1, 82] 
regular batch size: 2*94, diving batch size 1*0
best_l after optimization: 8.529526710510254 with beta sum per layer: [0.0, 26.00341796875, 73.23281860351562]
alpha/beta optimization time: 0.26016831398010254
This batch time : update_bounds func: 0.2979	 prepare: 0.0191	 bound: 0.2605	 transfer: 0.0069	 finalize: 0.0110
Accumulated time: update_bounds func: 3.2675	 prepare: 0.1699	 bound: 2.9666	 transfer: 0.0069	 finalize: 0.0944
batch bounding time:  0.2981686592102051
Current worst splitting domains [lb, ub] (depth):
[-0.21573,   inf] (28), [-0.21240,   inf] (28), [-0.20902,   inf] (28), [-0.20770,   inf] (28), [-0.18729,   inf] (28), [-0.18332,   inf] (28), [-0.18206,   inf] (28), [-0.17970,   inf] (28), [-0.16155,   inf] (28), [-0.15688,   inf] (28), [-0.15530,   inf] (28), [-0.15415,   inf] (28), [-0.15058,   inf] (28), [-0.14993,   inf] (28), [-0.14811,   inf] (28), [-0.14607,   inf] (28), [-0.14512,   inf] (28), [-0.14417,   inf] (28), [-0.14395,   inf] (28), [-0.13853,   inf] (28), 
length of domains: 130
Total time: 0.3884	 pickout: 0.0136	 decision: 0.0705	 get_bound: 0.2985	 add_domain: 0.0058
Current lb:-0.2157296985387802
1274 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.16209101676941

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([130, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([130, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 110] [1, 110] [1, 110] [1, 110] [1, 110] [1, 110] [1, 110] [1, 110] [1, 110] [1, 110] 
regular batch size: 2*130, diving batch size 1*0
best_l after optimization: 12.282190322875977 with beta sum per layer: [0.0, 42.34638977050781, 70.83174133300781]
alpha/beta optimization time: 0.26577091217041016
This batch time : update_bounds func: 0.3164	 prepare: 0.0267	 bound: 0.2661	 transfer: 0.0074	 finalize: 0.0149
Accumulated time: update_bounds func: 3.5839	 prepare: 0.1965	 bound: 3.2327	 transfer: 0.0074	 finalize: 0.1093
batch bounding time:  0.3167853355407715
Current worst splitting domains [lb, ub] (depth):
[-0.19957,   inf] (30), [-0.19641,   inf] (30), [-0.19351,   inf] (30), [-0.19229,   inf] (30), [-0.18557,   inf] (30), [-0.18220,   inf] (30), [-0.17670,   inf] (30), [-0.17536,   inf] (30), [-0.17086,   inf] (30), [-0.16687,   inf] (30), [-0.16618,   inf] (30), [-0.16424,   inf] (30), [-0.15674,   inf] (30), [-0.15268,   inf] (30), [-0.14943,   inf] (30), [-0.14721,   inf] (30), [-0.14502,   inf] (30), [-0.13947,   inf] (30), [-0.13809,   inf] (30), [-0.13536,   inf] (30), 
length of domains: 196
Total time: 0.4371	 pickout: 0.0175	 decision: 0.0928	 get_bound: 0.3172	 add_domain: 0.0096
Current lb:-0.19956767559051514
1534 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.601527214050293

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([196, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([196, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 99] [1, 99] [1, 99] [1, 99] [1, 99] [1, 99] [1, 99] [1, 99] [1, 99] [1, 99] 
regular batch size: 2*196, diving batch size 1*0
best_l after optimization: 15.786295890808105 with beta sum per layer: [0.0, 76.9471435546875, 91.513427734375]
alpha/beta optimization time: 0.26412010192871094
This batch time : update_bounds func: 0.3372	 prepare: 0.0394	 bound: 0.2644	 transfer: 0.0095	 finalize: 0.0229
Accumulated time: update_bounds func: 3.9211	 prepare: 0.2360	 bound: 3.4972	 transfer: 0.0095	 finalize: 0.1322
batch bounding time:  0.3376467227935791
Current worst splitting domains [lb, ub] (depth):
[-0.18583,   inf] (32), [-0.18301,   inf] (32), [-0.17949,   inf] (32), [-0.17842,   inf] (32), [-0.17152,   inf] (32), [-0.16858,   inf] (32), [-0.16478,   inf] (32), [-0.16270,   inf] (32), [-0.16196,   inf] (32), [-0.16139,   inf] (32), [-0.15847,   inf] (32), [-0.15758,   inf] (32), [-0.15755,   inf] (32), [-0.15391,   inf] (32), [-0.15292,   inf] (32), [-0.15119,   inf] (32), [-0.15044,   inf] (32), [-0.14768,   inf] (32), [-0.14322,   inf] (32), [-0.14166,   inf] (32), 
length of domains: 276
Total time: 0.5658	 pickout: 0.0256	 decision: 0.1891	 get_bound: 0.3382	 add_domain: 0.0128
Current lb:-0.18582701683044434
1926 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.170812129974365

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([276, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([276, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 745] [1, 745] [1, 745] [2, 73] [1, 745] [1, 745] [1, 745] [1, 745] [1, 745] [2, 73] 
regular batch size: 2*276, diving batch size 1*0
best_l after optimization: 18.569355010986328 with beta sum per layer: [0.0, 107.25817108154297, 117.689453125]
alpha/beta optimization time: 0.29425811767578125
This batch time : update_bounds func: 0.3952	 prepare: 0.0552	 bound: 0.2946	 transfer: 0.0121	 finalize: 0.0321
Accumulated time: update_bounds func: 4.3163	 prepare: 0.2912	 bound: 3.7917	 transfer: 0.0121	 finalize: 0.1643
batch bounding time:  0.39577746391296387
Current worst splitting domains [lb, ub] (depth):
[-0.17472,   inf] (34), [-0.17341,   inf] (34), [-0.17179,   inf] (34), [-0.16823,   inf] (34), [-0.16534,   inf] (34), [-0.16300,   inf] (34), [-0.16209,   inf] (34), [-0.16042,   inf] (34), [-0.15739,   inf] (34), [-0.15630,   inf] (34), [-0.15391,   inf] (34), [-0.15253,   inf] (34), [-0.15143,   inf] (34), [-0.15110,   inf] (34), [-0.15086,   inf] (34), [-0.14859,   inf] (34), [-0.14754,   inf] (34), [-0.14702,   inf] (34), [-0.14621,   inf] (34), [-0.14532,   inf] (34), 
length of domains: 404
Total time: 0.6396	 pickout: 0.0363	 decision: 0.1875	 get_bound: 0.3966	 add_domain: 0.0192
Current lb:-0.1747184693813324
2478 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.814910650253296

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([404, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([404, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 721] [2, 34] [1, 66] [2, 73] [1, 721] [1, 66] [1, 66] [1, 721] [1, 66] [2, 34] 
regular batch size: 2*404, diving batch size 1*0
best_l after optimization: 26.855247497558594 with beta sum per layer: [0.0, 155.56765747070312, 172.20248413085938]
alpha/beta optimization time: 0.34099507331848145
This batch time : update_bounds func: 0.5587	 prepare: 0.0795	 bound: 0.3413	 transfer: 0.0160	 finalize: 0.1200
Accumulated time: update_bounds func: 4.8749	 prepare: 0.3707	 bound: 4.1330	 transfer: 0.0160	 finalize: 0.2842
batch bounding time:  0.5596072673797607
Current worst splitting domains [lb, ub] (depth):
[-0.16688,   inf] (36), [-0.16295,   inf] (36), [-0.16255,   inf] (36), [-0.16030,   inf] (36), [-0.15991,   inf] (36), [-0.15563,   inf] (36), [-0.15360,   inf] (36), [-0.15198,   inf] (36), [-0.15038,   inf] (36), [-0.15026,   inf] (36), [-0.14982,   inf] (36), [-0.14823,   inf] (36), [-0.14602,   inf] (36), [-0.14602,   inf] (36), [-0.14600,   inf] (36), [-0.14600,   inf] (36), [-0.14231,   inf] (36), [-0.14166,   inf] (36), [-0.14136,   inf] (36), [-0.14133,   inf] (36), 
length of domains: 628
Total time: 0.9195	 pickout: 0.0637	 decision: 0.2639	 get_bound: 0.5609	 add_domain: 0.0311
Current lb:-0.1668798178434372
3286 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.740432739257812

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([628, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([628, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 925] [2, 34] [2, 73] [1, 66] [1, 745] [1, 66] [2, 73] [2, 73] [1, 66] [2, 73] 
regular batch size: 2*628, diving batch size 1*0
best_l after optimization: 35.10923767089844 with beta sum per layer: [0.0, 248.5799560546875, 284.63922119140625]
alpha/beta optimization time: 0.4290342330932617
This batch time : update_bounds func: 0.6506	 prepare: 0.1238	 bound: 0.4293	 transfer: 0.0209	 finalize: 0.0738
Accumulated time: update_bounds func: 5.5255	 prepare: 0.4945	 bound: 4.5623	 transfer: 0.0209	 finalize: 0.3580
batch bounding time:  0.6516420841217041
Current worst splitting domains [lb, ub] (depth):
[-0.16240,   inf] (38), [-0.15709,   inf] (38), [-0.15626,   inf] (38), [-0.15254,   inf] (38), [-0.15125,   inf] (38), [-0.14827,   inf] (38), [-0.14824,   inf] (38), [-0.14691,   inf] (38), [-0.14636,   inf] (38), [-0.14539,   inf] (38), [-0.14476,   inf] (38), [-0.14265,   inf] (38), [-0.14251,   inf] (38), [-0.14163,   inf] (38), [-0.14134,   inf] (38), [-0.13936,   inf] (38), [-0.13825,   inf] (38), [-0.13692,   inf] (38), [-0.13661,   inf] (38), [-0.13614,   inf] (38), 
length of domains: 900
Total time: 1.1817	 pickout: 0.0832	 decision: 0.3991	 get_bound: 0.6535	 add_domain: 0.0458
Current lb:-0.1623978614807129
4542 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.932148456573486

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([900, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([900, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 745] [2, 34] [1, 925] [1, 66] [2, 73] [2, 34] [1, 66] [2, 34] [2, 73] [1, 745] 
regular batch size: 2*900, diving batch size 1*0
best_l after optimization: 44.0622444152832 with beta sum per layer: [0.0, 347.69696044921875, 428.21636962890625]
alpha/beta optimization time: 0.5427532196044922
This batch time : update_bounds func: 0.9757	 prepare: 0.1824	 bound: 0.5431	 transfer: 0.0497	 finalize: 0.1947
Accumulated time: update_bounds func: 6.5012	 prepare: 0.6769	 bound: 5.1055	 transfer: 0.0497	 finalize: 0.5527
batch bounding time:  0.9776830673217773
Current worst splitting domains [lb, ub] (depth):
[-0.15159,   inf] (40), [-0.15071,   inf] (40), [-0.15041,   inf] (40), [-0.14706,   inf] (40), [-0.14568,   inf] (40), [-0.14536,   inf] (40), [-0.14158,   inf] (40), [-0.14096,   inf] (40), [-0.14070,   inf] (40), [-0.14019,   inf] (40), [-0.13807,   inf] (40), [-0.13802,   inf] (40), [-0.13622,   inf] (40), [-0.13600,   inf] (40), [-0.13598,   inf] (40), [-0.13585,   inf] (40), [-0.13471,   inf] (40), [-0.13443,   inf] (40), [-0.13366,   inf] (40), [-0.13266,   inf] (40), 
length of domains: 1178
Total time: 1.7990	 pickout: 0.1225	 decision: 0.6335	 get_bound: 0.9807	 add_domain: 0.0623
Current lb:-0.15159273147583008
6342 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.75091004371643

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 66] [1, 66] [1, 925] [1, 67] [2, 34] [1, 66] [1, 925] [1, 873] [2, 34] [1, 925] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 60.181922912597656 with beta sum per layer: [0.0, 409.97119140625, 431.7514343261719]
alpha/beta optimization time: 0.5924878120422363
This batch time : update_bounds func: 1.0215	 prepare: 0.2064	 bound: 0.5928	 transfer: 0.0319	 finalize: 0.1848
Accumulated time: update_bounds func: 7.5227	 prepare: 0.8833	 bound: 5.6983	 transfer: 0.0319	 finalize: 0.7376
batch bounding time:  1.0232086181640625
Current worst splitting domains [lb, ub] (depth):
[-0.14640,   inf] (42), [-0.14210,   inf] (42), [-0.14080,   inf] (42), [-0.13891,   inf] (42), [-0.13752,   inf] (42), [-0.13740,   inf] (42), [-0.13556,   inf] (42), [-0.13513,   inf] (42), [-0.13473,   inf] (42), [-0.13409,   inf] (42), [-0.13381,   inf] (42), [-0.13350,   inf] (42), [-0.13206,   inf] (42), [-0.12931,   inf] (42), [-0.12866,   inf] (42), [-0.12780,   inf] (42), [-0.12744,   inf] (42), [-0.12668,   inf] (42), [-0.12585,   inf] (42), [-0.12574,   inf] (42), 
length of domains: 1672
Total time: 1.9031	 pickout: 0.1434	 decision: 0.6497	 get_bound: 1.0262	 add_domain: 0.0838
Current lb:-0.14640212059020996
8390 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 20.67333197593689

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 721] [1, 873] [1, 873] [1, 925] [1, 721] [1, 67] [1, 873] [1, 873] [1, 763] [1, 721] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 68.49388122558594 with beta sum per layer: [0.0, 450.42095947265625, 329.93328857421875]
alpha/beta optimization time: 0.5976791381835938
This batch time : update_bounds func: 0.9763	 prepare: 0.2060	 bound: 0.5980	 transfer: 0.0396	 finalize: 0.1275
Accumulated time: update_bounds func: 8.4989	 prepare: 1.0893	 bound: 6.2964	 transfer: 0.0396	 finalize: 0.8651
batch bounding time:  0.978492259979248
Current worst splitting domains [lb, ub] (depth):
[-0.13489,   inf] (44), [-0.13225,   inf] (44), [-0.12983,   inf] (44), [-0.12950,   inf] (44), [-0.12668,   inf] (44), [-0.12598,   inf] (44), [-0.12567,   inf] (44), [-0.12530,   inf] (44), [-0.12516,   inf] (44), [-0.12333,   inf] (44), [-0.12242,   inf] (44), [-0.12242,   inf] (44), [-0.12175,   inf] (44), [-0.12089,   inf] (44), [-0.12065,   inf] (44), [-0.12062,   inf] (44), [-0.12057,   inf] (44), [-0.12025,   inf] (44), [-0.11985,   inf] (44), [-0.11969,   inf] (44), 
length of domains: 2283
Total time: 2.0856	 pickout: 0.1462	 decision: 0.7361	 get_bound: 0.9815	 add_domain: 0.2218
Current lb:-0.13488757610321045
10438 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 22.77686333656311

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 67] [1, 67] [1, 67] [1, 67] [1, 721] [1, 724] [1, 67] [1, 68] [1, 67] [1, 67] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 97.1407470703125 with beta sum per layer: [0.0, 306.641357421875, 264.83758544921875]
alpha/beta optimization time: 0.5946187973022461
This batch time : update_bounds func: 1.1009	 prepare: 0.2081	 bound: 0.5950	 transfer: 0.0505	 finalize: 0.2414
Accumulated time: update_bounds func: 9.5998	 prepare: 1.2974	 bound: 6.8914	 transfer: 0.0505	 finalize: 1.1065
batch bounding time:  1.1027004718780518
Current worst splitting domains [lb, ub] (depth):
[-0.12423,   inf] (46), [-0.12140,   inf] (46), [-0.11912,   inf] (46), [-0.11851,   inf] (46), [-0.11841,   inf] (46), [-0.11702,   inf] (46), [-0.11460,   inf] (46), [-0.11436,   inf] (46), [-0.11334,   inf] (46), [-0.11294,   inf] (46), [-0.11279,   inf] (46), [-0.11244,   inf] (46), [-0.11212,   inf] (46), [-0.11084,   inf] (46), [-0.10985,   inf] (46), [-0.10962,   inf] (46), [-0.10962,   inf] (46), [-0.10960,   inf] (46), [-0.10937,   inf] (46), [-0.10914,   inf] (46), 
length of domains: 3237
Total time: 2.0310	 pickout: 0.1497	 decision: 0.6601	 get_bound: 1.1058	 add_domain: 0.1153
Current lb:-0.12422776222229004
12486 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 24.824684143066406

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 68] [1, 68] [1, 68] [1, 68] [1, 68] [1, 925] [1, 68] [1, 869] [1, 68] [1, 68] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 103.9716796875 with beta sum per layer: [0.0, 222.97775268554688, 237.27557373046875]
alpha/beta optimization time: 0.5936121940612793
This batch time : update_bounds func: 0.9732	 prepare: 0.2047	 bound: 0.5940	 transfer: 0.0402	 finalize: 0.1287
Accumulated time: update_bounds func: 10.5730	 prepare: 1.5020	 bound: 7.4853	 transfer: 0.0402	 finalize: 1.2352
batch bounding time:  0.9750080108642578
Current worst splitting domains [lb, ub] (depth):
[-0.11554,   inf] (48), [-0.11277,   inf] (48), [-0.11274,   inf] (48), [-0.11044,   inf] (48), [-0.10964,   inf] (48), [-0.10963,   inf] (48), [-0.10600,   inf] (48), [-0.10532,   inf] (48), [-0.10384,   inf] (48), [-0.10380,   inf] (48), [-0.10372,   inf] (48), [-0.10349,   inf] (48), [-0.10244,   inf] (48), [-0.10167,   inf] (48), [-0.10139,   inf] (48), [-0.10136,   inf] (48), [-0.10134,   inf] (48), [-0.10117,   inf] (48), [-0.10101,   inf] (48), [-0.10079,   inf] (48), 
length of domains: 4205
Total time: 2.1198	 pickout: 0.1467	 decision: 0.7464	 get_bound: 0.9780	 add_domain: 0.2486
Current lb:-0.11553720384836197
14534 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 26.959778547286987

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 873] [1, 873] [1, 721] [1, 873] [1, 873] [1, 724] [1, 724] [1, 721] [1, 873] [1, 721] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 99.63179779052734 with beta sum per layer: [0.0, 163.5808868408203, 168.54714965820312]
alpha/beta optimization time: 0.5943820476531982
This batch time : update_bounds func: 1.0878	 prepare: 0.2066	 bound: 0.5947	 transfer: 0.0395	 finalize: 0.2414
Accumulated time: update_bounds func: 11.6608	 prepare: 1.7086	 bound: 8.0801	 transfer: 0.0395	 finalize: 1.4766
batch bounding time:  1.0894951820373535
Current worst splitting domains [lb, ub] (depth):
[-0.10226,   inf] (50), [-0.09983,   inf] (50), [-0.09895,   inf] (50), [-0.09774,   inf] (50), [-0.09719,   inf] (50), [-0.09662,   inf] (50), [-0.09532,   inf] (50), [-0.09506,   inf] (50), [-0.09308,   inf] (50), [-0.09279,   inf] (50), [-0.09243,   inf] (50), [-0.09238,   inf] (50), [-0.09181,   inf] (50), [-0.09111,   inf] (50), [-0.09047,   inf] (50), [-0.09002,   inf] (50), [-0.08987,   inf] (50), [-0.08975,   inf] (50), [-0.08956,   inf] (50), [-0.08942,   inf] (50), 
length of domains: 5167
Total time: 2.0163	 pickout: 0.1446	 decision: 0.6592	 get_bound: 1.0925	 add_domain: 0.1200
Current lb:-0.1022571250796318
16582 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 28.991999626159668

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 763] [1, 757] [1, 757] [1, 757] [1, 763] [1, 757] [1, 763] [1, 763] [1, 925] [1, 757] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 83.93994140625 with beta sum per layer: [0.0, 169.82730102539062, 143.75914001464844]
alpha/beta optimization time: 0.594656229019165
This batch time : update_bounds func: 0.9690	 prepare: 0.2067	 bound: 0.5950	 transfer: 0.0387	 finalize: 0.1231
Accumulated time: update_bounds func: 12.6298	 prepare: 1.9154	 bound: 8.6751	 transfer: 0.0387	 finalize: 1.5998
batch bounding time:  0.9707601070404053
Current worst splitting domains [lb, ub] (depth):
[-0.09324,   inf] (52), [-0.09243,   inf] (52), [-0.09149,   inf] (52), [-0.09035,   inf] (52), [-0.08922,   inf] (52), [-0.08881,   inf] (52), [-0.08823,   inf] (52), [-0.08605,   inf] (52), [-0.08598,   inf] (52), [-0.08575,   inf] (52), [-0.08526,   inf] (52), [-0.08438,   inf] (52), [-0.08332,   inf] (52), [-0.08296,   inf] (52), [-0.08196,   inf] (52), [-0.08193,   inf] (52), [-0.08127,   inf] (52), [-0.08115,   inf] (52), [-0.08115,   inf] (52), [-0.08095,   inf] (52), 
length of domains: 6055
Total time: 2.1869	 pickout: 0.1449	 decision: 0.7774	 get_bound: 0.9738	 add_domain: 0.2907
Current lb:-0.09324189275503159
18630 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 31.194701433181763

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 724] [1, 869] [1, 724] [1, 873] [1, 869] [1, 873] [1, 724] [1, 724] [1, 724] [1, 873] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 77.17610168457031 with beta sum per layer: [0.0, 128.83908081054688, 144.31866455078125]
alpha/beta optimization time: 0.5964212417602539
This batch time : update_bounds func: 1.1068	 prepare: 0.2036	 bound: 0.5967	 transfer: 0.0393	 finalize: 0.2616
Accumulated time: update_bounds func: 13.7366	 prepare: 2.1189	 bound: 9.2718	 transfer: 0.0393	 finalize: 1.8614
batch bounding time:  1.1085774898529053
Current worst splitting domains [lb, ub] (depth):
[-0.08072,   inf] (54), [-0.07984,   inf] (54), [-0.07747,   inf] (54), [-0.07695,   inf] (54), [-0.07557,   inf] (54), [-0.07524,   inf] (54), [-0.07452,   inf] (54), [-0.07350,   inf] (54), [-0.07338,   inf] (54), [-0.07276,   inf] (54), [-0.07269,   inf] (54), [-0.07214,   inf] (54), [-0.07202,   inf] (54), [-0.07174,   inf] (54), [-0.07146,   inf] (54), [-0.07077,   inf] (54), [-0.07055,   inf] (54), [-0.07010,   inf] (54), [-0.07005,   inf] (54), [-0.06979,   inf] (54), 
length of domains: 7030
Total time: 2.0436	 pickout: 0.1469	 decision: 0.6589	 get_bound: 1.1117	 add_domain: 0.1262
Current lb:-0.08072353154420853
20678 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 33.25605845451355

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 763] [1, 757] [1, 763] [1, 724] [1, 873] [1, 757] [1, 725] [1, 869] [1, 763] [1, 757] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 64.22903442382812 with beta sum per layer: [0.0, 142.89105224609375, 146.6959991455078]
alpha/beta optimization time: 0.5937795639038086
This batch time : update_bounds func: 1.1415	 prepare: 0.2070	 bound: 0.5941	 transfer: 0.0401	 finalize: 0.1263
Accumulated time: update_bounds func: 14.8781	 prepare: 2.3259	 bound: 9.8659	 transfer: 0.0401	 finalize: 1.9877
batch bounding time:  1.1432511806488037
Current worst splitting domains [lb, ub] (depth):
[-0.07262,   inf] (56), [-0.07235,   inf] (56), [-0.06915,   inf] (56), [-0.06802,   inf] (56), [-0.06560,   inf] (56), [-0.06558,   inf] (56), [-0.06492,   inf] (56), [-0.06442,   inf] (56), [-0.06434,   inf] (56), [-0.06427,   inf] (56), [-0.06427,   inf] (56), [-0.06254,   inf] (56), [-0.06245,   inf] (56), [-0.06215,   inf] (56), [-0.06185,   inf] (56), [-0.06160,   inf] (56), [-0.06159,   inf] (56), [-0.06159,   inf] (56), [-0.06116,   inf] (56), [-0.06116,   inf] (56), 
length of domains: 8012
Total time: 2.0907	 pickout: 0.1492	 decision: 0.6669	 get_bound: 1.1463	 add_domain: 0.1283
Current lb:-0.07262301445007324
22726 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 35.36402606964111

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 725] [1, 65] [2, 4] [1, 65] [1, 65] [1, 65] [1, 65] [1, 725] [1, 757] [1, 65] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 48.93949890136719 with beta sum per layer: [0.0, 171.00369262695312, 189.05674743652344]
alpha/beta optimization time: 0.5930120944976807
This batch time : update_bounds func: 0.9688	 prepare: 0.2060	 bound: 0.5933	 transfer: 0.0395	 finalize: 0.1241
Accumulated time: update_bounds func: 15.8468	 prepare: 2.5318	 bound: 10.4593	 transfer: 0.0395	 finalize: 2.1118
batch bounding time:  0.9705514907836914
Current worst splitting domains [lb, ub] (depth):
[-0.06565,   inf] (58), [-0.06333,   inf] (58), [-0.06001,   inf] (58), [-0.05821,   inf] (58), [-0.05820,   inf] (58), [-0.05792,   inf] (58), [-0.05721,   inf] (58), [-0.05701,   inf] (58), [-0.05537,   inf] (58), [-0.05525,   inf] (58), [-0.05483,   inf] (58), [-0.05472,   inf] (58), [-0.05454,   inf] (58), [-0.05314,   inf] (58), [-0.05270,   inf] (58), [-0.05264,   inf] (58), [-0.05248,   inf] (58), [-0.05246,   inf] (58), [-0.05185,   inf] (58), [-0.05135,   inf] (58), 
length of domains: 8924
Total time: 2.0700	 pickout: 0.1525	 decision: 0.8200	 get_bound: 0.9736	 add_domain: 0.1239
Current lb:-0.06564748287200928
24774 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 37.45242476463318

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 917] [1, 65] [2, 4] [1, 917] [1, 917] [1, 917] [2, 4] [2, 4] [2, 64] [1, 725] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 33.934608459472656 with beta sum per layer: [0.0, 198.15699768066406, 218.50433349609375]
alpha/beta optimization time: 0.5938904285430908
This batch time : update_bounds func: 0.9720	 prepare: 0.2068	 bound: 0.5942	 transfer: 0.0391	 finalize: 0.1258
Accumulated time: update_bounds func: 16.8189	 prepare: 2.7387	 bound: 11.0535	 transfer: 0.0391	 finalize: 2.2376
batch bounding time:  0.9738743305206299
Current worst splitting domains [lb, ub] (depth):
[-0.06323,   inf] (60), [-0.05660,   inf] (60), [-0.05552,   inf] (60), [-0.05550,   inf] (60), [-0.05534,   inf] (60), [-0.05378,   inf] (60), [-0.05362,   inf] (60), [-0.05310,   inf] (60), [-0.05218,   inf] (60), [-0.05212,   inf] (60), [-0.05112,   inf] (60), [-0.05025,   inf] (60), [-0.05007,   inf] (60), [-0.04978,   inf] (60), [-0.04888,   inf] (60), [-0.04846,   inf] (60), [-0.04839,   inf] (60), [-0.04829,   inf] (60), [-0.04784,   inf] (60), [-0.04700,   inf] (60), 
length of domains: 9758
Total time: 2.0971	 pickout: 0.1549	 decision: 0.8461	 get_bound: 0.9769	 add_domain: 0.1192
Current lb:-0.06322753429412842
26822 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 39.56909966468811

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 64] [1, 917] [2, 64] [1, 725] [2, 64] [1, 917] [1, 917] [1, 917] [2, 64] [2, 64] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 30.281742095947266 with beta sum per layer: [0.0, 215.67991638183594, 197.68951416015625]
alpha/beta optimization time: 0.595137357711792
This batch time : update_bounds func: 0.9801	 prepare: 0.2114	 bound: 0.5954	 transfer: 0.0371	 finalize: 0.1301
Accumulated time: update_bounds func: 17.7989	 prepare: 2.9501	 bound: 11.6489	 transfer: 0.0371	 finalize: 2.3677
batch bounding time:  0.9819509983062744
Current worst splitting domains [lb, ub] (depth):
[-0.06094,   inf] (62), [-0.05421,   inf] (62), [-0.05323,   inf] (62), [-0.05306,   inf] (62), [-0.05138,   inf] (62), [-0.05093,   inf] (62), [-0.05073,   inf] (62), [-0.04992,   inf] (62), [-0.04983,   inf] (62), [-0.04848,   inf] (62), [-0.04780,   inf] (62), [-0.04742,   inf] (62), [-0.04686,   inf] (62), [-0.04636,   inf] (62), [-0.04609,   inf] (62), [-0.04606,   inf] (62), [-0.04584,   inf] (62), [-0.04581,   inf] (62), [-0.04458,   inf] (62), [-0.04441,   inf] (62), 
length of domains: 10545
Total time: 2.1198	 pickout: 0.1519	 decision: 0.8636	 get_bound: 0.9851	 add_domain: 0.1192
Current lb:-0.06094348430633545
28870 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 41.707990646362305

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 484] [2, 64] [1, 484] [1, 484] [2, 64] [2, 64] [1, 484] [1, 484] [1, 484] [2, 64] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 27.198734283447266 with beta sum per layer: [0.0, 195.30462646484375, 206.17208862304688]
alpha/beta optimization time: 0.5940237045288086
This batch time : update_bounds func: 0.9871	 prepare: 0.2106	 bound: 0.5944	 transfer: 0.0396	 finalize: 0.1363
Accumulated time: update_bounds func: 18.7861	 prepare: 3.1606	 bound: 12.2433	 transfer: 0.0396	 finalize: 2.5040
batch bounding time:  0.9890627861022949
Current worst splitting domains [lb, ub] (depth):
[-0.05887,   inf] (64), [-0.05197,   inf] (64), [-0.05099,   inf] (64), [-0.05092,   inf] (64), [-0.04913,   inf] (64), [-0.04869,   inf] (64), [-0.04857,   inf] (64), [-0.04758,   inf] (64), [-0.04751,   inf] (64), [-0.04620,   inf] (64), [-0.04575,   inf] (64), [-0.04517,   inf] (64), [-0.04413,   inf] (64), [-0.04407,   inf] (64), [-0.04385,   inf] (64), [-0.04358,   inf] (64), [-0.04355,   inf] (64), [-0.04355,   inf] (64), [-0.04232,   inf] (64), [-0.04214,   inf] (64), 
length of domains: 11251
Total time: 2.1451	 pickout: 0.1546	 decision: 0.8839	 get_bound: 0.9923	 add_domain: 0.1143
Current lb:-0.05887115001678467
30918 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 43.87725877761841

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 65] [1, 484] [1, 725] [1, 65] [1, 484] [1, 484] [1, 65] [1, 725] [1, 725] [1, 484] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 25.192276000976562 with beta sum per layer: [0.0, 201.7861328125, 194.6673583984375]
alpha/beta optimization time: 0.5950767993927002
This batch time : update_bounds func: 0.9865	 prepare: 0.2158	 bound: 0.5954	 transfer: 0.0330	 finalize: 0.1356
Accumulated time: update_bounds func: 19.7725	 prepare: 3.3765	 bound: 12.8387	 transfer: 0.0330	 finalize: 2.6396
batch bounding time:  0.9884746074676514
Current worst splitting domains [lb, ub] (depth):
[-0.04990,   inf] (66), [-0.04705,   inf] (66), [-0.04661,   inf] (66), [-0.04635,   inf] (66), [-0.04393,   inf] (66), [-0.04381,   inf] (66), [-0.04315,   inf] (66), [-0.04204,   inf] (66), [-0.04182,   inf] (66), [-0.04180,   inf] (66), [-0.04136,   inf] (66), [-0.04114,   inf] (66), [-0.04030,   inf] (66), [-0.04007,   inf] (66), [-0.03971,   inf] (66), [-0.03925,   inf] (66), [-0.03917,   inf] (66), [-0.03908,   inf] (66), [-0.03896,   inf] (66), [-0.03876,   inf] (66), 
length of domains: 11919
Total time: 2.1898	 pickout: 0.1724	 decision: 0.9108	 get_bound: 0.9918	 add_domain: 0.1149
Current lb:-0.04989978298544884
32966 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 46.09123373031616

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 485] [1, 485] [1, 485] [1, 65] [1, 65] [1, 485] [1, 724] [1, 485] [1, 484] [1, 724] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 21.619884490966797 with beta sum per layer: [0.0, 188.52523803710938, 213.65338134765625]
alpha/beta optimization time: 0.5925724506378174
This batch time : update_bounds func: 0.9772	 prepare: 0.2095	 bound: 0.5929	 transfer: 0.0379	 finalize: 0.1305
Accumulated time: update_bounds func: 20.7497	 prepare: 3.5860	 bound: 13.4316	 transfer: 0.0379	 finalize: 2.7701
batch bounding time:  0.9791066646575928
Current worst splitting domains [lb, ub] (depth):
[-0.04748,   inf] (68), [-0.04461,   inf] (68), [-0.04417,   inf] (68), [-0.04134,   inf] (68), [-0.03975,   inf] (68), [-0.03960,   inf] (68), [-0.03766,   inf] (68), [-0.03719,   inf] (68), [-0.03681,   inf] (68), [-0.03624,   inf] (68), [-0.03621,   inf] (68), [-0.03600,   inf] (68), [-0.03477,   inf] (68), [-0.03468,   inf] (68), [-0.03385,   inf] (68), [-0.03343,   inf] (68), [-0.03334,   inf] (68), [-0.03334,   inf] (68), [-0.03302,   inf] (68), [-0.03290,   inf] (68), 
length of domains: 12542
Total time: 2.1866	 pickout: 0.1584	 decision: 0.9336	 get_bound: 0.9824	 add_domain: 0.1122
Current lb:-0.047484397888183594
35014 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 48.301722288131714

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 724] [1, 724] [1, 108] [1, 108] [1, 869] [1, 724] [1, 724] [1, 869] [1, 724] [1, 108] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 19.770174026489258 with beta sum per layer: [0.0, 206.4200439453125, 194.4088592529297]
alpha/beta optimization time: 0.59403395652771
This batch time : update_bounds func: 1.2497	 prepare: 0.2087	 bound: 0.5944	 transfer: 0.0372	 finalize: 0.1316
Accumulated time: update_bounds func: 21.9993	 prepare: 3.7947	 bound: 14.0260	 transfer: 0.0372	 finalize: 2.9017
batch bounding time:  1.2516200542449951
Current worst splitting domains [lb, ub] (depth):
[-0.03780,   inf] (70), [-0.03495,   inf] (70), [-0.03411,   inf] (70), [-0.03144,   inf] (70), [-0.03130,   inf] (70), [-0.02992,   inf] (54), [-0.02991,   inf] (54), [-0.02991,   inf] (58), [-0.02991,   inf] (54), [-0.02991,   inf] (56), [-0.02991,   inf] (48), [-0.02991,   inf] (52), [-0.02991,   inf] (48), [-0.02991,   inf] (50), [-0.02991,   inf] (48), [-0.02991,   inf] (54), [-0.02991,   inf] (46), [-0.02991,   inf] (54), [-0.02991,   inf] (56), [-0.02991,   inf] (50), 
length of domains: 13172
Total time: 2.1840	 pickout: 0.1556	 decision: 0.6621	 get_bound: 1.2549	 add_domain: 0.1114
Current lb:-0.037795424461364746
37062 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 50.50953125953674

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 724] [1, 724] [1, 725] [1, 725] [1, 725] [1, 725] [1, 725] [2, 4] [1, 757] [1, 65] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 15.330917358398438 with beta sum per layer: [0.0, 205.32730102539062, 227.59671020507812]
alpha/beta optimization time: 0.5950064659118652
This batch time : update_bounds func: 1.2731	 prepare: 0.2065	 bound: 0.5953	 transfer: 0.0373	 finalize: 0.4284
Accumulated time: update_bounds func: 23.2725	 prepare: 4.0011	 bound: 14.6213	 transfer: 0.0373	 finalize: 3.3301
batch bounding time:  1.275165319442749
Current worst splitting domains [lb, ub] (depth):
[-0.02843,   inf] (50), [-0.02843,   inf] (50), [-0.02843,   inf] (62), [-0.02843,   inf] (66), [-0.02843,   inf] (46), [-0.02843,   inf] (50), [-0.02843,   inf] (60), [-0.02843,   inf] (66), [-0.02843,   inf] (56), [-0.02843,   inf] (46), [-0.02843,   inf] (54), [-0.02843,   inf] (54), [-0.02843,   inf] (58), [-0.02842,   inf] (50), [-0.02842,   inf] (48), [-0.02842,   inf] (58), [-0.02842,   inf] (56), [-0.02842,   inf] (56), [-0.02841,   inf] (58), [-0.02841,   inf] (66), 
length of domains: 13768
Total time: 2.2042	 pickout: 0.1553	 decision: 0.6620	 get_bound: 1.2786	 add_domain: 0.1083
Current lb:-0.02843308448791504
39110 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 52.73888635635376

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 757] [1, 724] [2, 64] [1, 65] [1, 67] [1, 68] [2, 4] [1, 484] [1, 757] [1, 721] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 11.192144393920898 with beta sum per layer: [0.0, 214.1882781982422, 208.53085327148438]
alpha/beta optimization time: 0.5943856239318848
This batch time : update_bounds func: 0.9857	 prepare: 0.2095	 bound: 0.5947	 transfer: 0.0373	 finalize: 0.1383
Accumulated time: update_bounds func: 24.2582	 prepare: 4.2106	 bound: 15.2160	 transfer: 0.0373	 finalize: 3.4684
batch bounding time:  0.9877173900604248
Current worst splitting domains [lb, ub] (depth):
[-0.02701,   inf] (52), [-0.02701,   inf] (62), [-0.02701,   inf] (48), [-0.02701,   inf] (52), [-0.02701,   inf] (50), [-0.02700,   inf] (68), [-0.02700,   inf] (58), [-0.02700,   inf] (50), [-0.02700,   inf] (54), [-0.02700,   inf] (56), [-0.02700,   inf] (52), [-0.02699,   inf] (56), [-0.02699,   inf] (50), [-0.02699,   inf] (50), [-0.02699,   inf] (58), [-0.02699,   inf] (60), [-0.02698,   inf] (54), [-0.02698,   inf] (54), [-0.02698,   inf] (64), [-0.02698,   inf] (64), 
length of domains: 14323
Total time: 1.9179	 pickout: 0.1536	 decision: 0.6663	 get_bound: 0.9911	 add_domain: 0.1069
Current lb:-0.027013659477233887
41158 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 54.68407607078552

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 724] [1, 917] [1, 724] [1, 725] [1, 873] [1, 724] [2, 4] [1, 757] [1, 724] [1, 725] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 11.593528747558594 with beta sum per layer: [0.0, 198.60208129882812, 207.2841033935547]
alpha/beta optimization time: 0.5931813716888428
This batch time : update_bounds func: 0.9826	 prepare: 0.2086	 bound: 0.5935	 transfer: 0.0373	 finalize: 0.1367
Accumulated time: update_bounds func: 25.2408	 prepare: 4.4192	 bound: 15.8096	 transfer: 0.0373	 finalize: 3.6051
batch bounding time:  0.984626293182373
Current worst splitting domains [lb, ub] (depth):
[-0.02570,   inf] (66), [-0.02570,   inf] (54), [-0.02570,   inf] (56), [-0.02569,   inf] (68), [-0.02569,   inf] (64), [-0.02569,   inf] (58), [-0.02569,   inf] (50), [-0.02569,   inf] (46), [-0.02569,   inf] (50), [-0.02569,   inf] (56), [-0.02569,   inf] (56), [-0.02568,   inf] (52), [-0.02568,   inf] (60), [-0.02568,   inf] (58), [-0.02568,   inf] (54), [-0.02568,   inf] (54), [-0.02568,   inf] (54), [-0.02568,   inf] (54), [-0.02567,   inf] (54), [-0.02567,   inf] (54), 
length of domains: 14897
Total time: 2.2339	 pickout: 0.1565	 decision: 0.9802	 get_bound: 0.9881	 add_domain: 0.1091
Current lb:-0.02570021152496338
43206 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 56.94478225708008

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 485] [1, 65] [1, 725] [1, 724] [1, 65] [2, 4] [1, 763] [1, 721] [1, 757] [1, 65] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 7.5560431480407715 with beta sum per layer: [0.0, 193.73501586914062, 205.99032592773438]
alpha/beta optimization time: 0.5943834781646729
This batch time : update_bounds func: 1.3298	 prepare: 0.2128	 bound: 0.5947	 transfer: 0.0382	 finalize: 0.1466
Accumulated time: update_bounds func: 26.5706	 prepare: 4.6320	 bound: 16.4043	 transfer: 0.0382	 finalize: 3.7517
batch bounding time:  1.3319804668426514
Current worst splitting domains [lb, ub] (depth):
[-0.02451,   inf] (50), [-0.02451,   inf] (52), [-0.02451,   inf] (54), [-0.02451,   inf] (52), [-0.02451,   inf] (58), [-0.02451,   inf] (58), [-0.02450,   inf] (54), [-0.02450,   inf] (58), [-0.02450,   inf] (52), [-0.02450,   inf] (60), [-0.02450,   inf] (52), [-0.02450,   inf] (54), [-0.02449,   inf] (52), [-0.02449,   inf] (60), [-0.02449,   inf] (54), [-0.02449,   inf] (60), [-0.02449,   inf] (56), [-0.02449,   inf] (58), [-0.02449,   inf] (56), [-0.02449,   inf] (44), 
length of domains: 15401
Total time: 2.2742	 pickout: 0.1596	 decision: 0.6693	 get_bound: 1.3356	 add_domain: 0.1098
Current lb:-0.02450859732925892
45254 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 59.2476270198822

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 757] [1, 724] [1, 757] [1, 763] [1, 869] [1, 65] [1, 868] [1, 725] [1, 869] [2, 64] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 6.049679756164551 with beta sum per layer: [0.0, 203.16746520996094, 214.44522094726562]
alpha/beta optimization time: 0.5946297645568848
This batch time : update_bounds func: 1.3566	 prepare: 0.2084	 bound: 0.5950	 transfer: 0.0379	 finalize: 0.5086
Accumulated time: update_bounds func: 27.9271	 prepare: 4.8405	 bound: 16.9993	 transfer: 0.0379	 finalize: 4.2603
batch bounding time:  1.359114170074463
Current worst splitting domains [lb, ub] (depth):
[-0.02336,   inf] (44), [-0.02336,   inf] (46), [-0.02336,   inf] (52), [-0.02335,   inf] (60), [-0.02335,   inf] (52), [-0.02335,   inf] (52), [-0.02335,   inf] (54), [-0.02335,   inf] (64), [-0.02335,   inf] (56), [-0.02335,   inf] (56), [-0.02335,   inf] (52), [-0.02335,   inf] (54), [-0.02335,   inf] (50), [-0.02334,   inf] (66), [-0.02334,   inf] (44), [-0.02334,   inf] (52), [-0.02334,   inf] (54), [-0.02334,   inf] (50), [-0.02334,   inf] (58), [-0.02334,   inf] (52), 
length of domains: 15894
Total time: 2.2981	 pickout: 0.1640	 decision: 0.6658	 get_bound: 1.3630	 add_domain: 0.1052
Current lb:-0.023356281220912933
47302 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 61.57278275489807

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 67] [1, 67] [1, 873] [2, 4] [1, 721] [1, 873] [1, 724] [1, 65] [1, 757] [2, 4] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 3.9777472019195557 with beta sum per layer: [0.0, 192.43582153320312, 197.67572021484375]
alpha/beta optimization time: 0.5951814651489258
This batch time : update_bounds func: 0.9845	 prepare: 0.2078	 bound: 0.5955	 transfer: 0.0397	 finalize: 0.1347
Accumulated time: update_bounds func: 28.9117	 prepare: 5.0482	 bound: 17.5948	 transfer: 0.0397	 finalize: 4.3950
batch bounding time:  0.9865670204162598
Current worst splitting domains [lb, ub] (depth):
[-0.02225,   inf] (62), [-0.02225,   inf] (56), [-0.02225,   inf] (50), [-0.02225,   inf] (46), [-0.02225,   inf] (52), [-0.02225,   inf] (66), [-0.02225,   inf] (56), [-0.02225,   inf] (44), [-0.02225,   inf] (54), [-0.02225,   inf] (44), [-0.02225,   inf] (60), [-0.02225,   inf] (64), [-0.02225,   inf] (56), [-0.02225,   inf] (50), [-0.02224,   inf] (52), [-0.02224,   inf] (54), [-0.02224,   inf] (44), [-0.02224,   inf] (56), [-0.02224,   inf] (54), [-0.02224,   inf] (52), 
length of domains: 16363
Total time: 1.9160	 pickout: 0.1579	 decision: 0.6657	 get_bound: 0.9900	 add_domain: 0.1024
Current lb:-0.022253327071666718
49350 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 63.51624345779419

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 64] [1, 861] [1, 757] [1, 68] [1, 861] [1, 485] [1, 917] [1, 67] [1, 725] [1, 721] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 0.2695951461791992 with beta sum per layer: [0.0, 200.09300231933594, 217.44039916992188]
alpha/beta optimization time: 0.5931999683380127
This batch time : update_bounds func: 0.9811	 prepare: 0.2083	 bound: 0.5935	 transfer: 0.0373	 finalize: 0.1353
Accumulated time: update_bounds func: 29.8927	 prepare: 5.2565	 bound: 18.1883	 transfer: 0.0373	 finalize: 4.5303
batch bounding time:  0.9830942153930664
Current worst splitting domains [lb, ub] (depth):
[-0.02125,   inf] (44), [-0.02125,   inf] (54), [-0.02125,   inf] (54), [-0.02125,   inf] (54), [-0.02125,   inf] (58), [-0.02125,   inf] (54), [-0.02125,   inf] (58), [-0.02125,   inf] (46), [-0.02125,   inf] (54), [-0.02124,   inf] (56), [-0.02124,   inf] (50), [-0.02124,   inf] (72), [-0.02124,   inf] (52), [-0.02124,   inf] (58), [-0.02124,   inf] (60), [-0.02124,   inf] (62), [-0.02124,   inf] (44), [-0.02124,   inf] (60), [-0.02124,   inf] (60), [-0.02123,   inf] (54), 
length of domains: 16737
Total time: 2.2817	 pickout: 0.1593	 decision: 1.0385	 get_bound: 0.9865	 add_domain: 0.0973
Current lb:-0.02125251293182373
51398 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 65.82641291618347

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 67] [1, 861] [1, 873] [1, 763] [1, 65] [1, 725] [2, 4] [1, 67] [1, 763] [1, 65] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -2.3764114379882812 with beta sum per layer: [0.0, 198.83694458007812, 221.30335998535156]
alpha/beta optimization time: 0.603532075881958
This batch time : update_bounds func: 1.0135	 prepare: 0.2101	 bound: 0.6039	 transfer: 0.0472	 finalize: 0.1458
Accumulated time: update_bounds func: 30.9063	 prepare: 5.4666	 bound: 18.7922	 transfer: 0.0472	 finalize: 4.6761
batch bounding time:  1.015960931777954
Current worst splitting domains [lb, ub] (depth):
[-0.02027,   inf] (48), [-0.02027,   inf] (64), [-0.02027,   inf] (58), [-0.02027,   inf] (60), [-0.02027,   inf] (52), [-0.02027,   inf] (46), [-0.02027,   inf] (68), [-0.02027,   inf] (56), [-0.02026,   inf] (54), [-0.02026,   inf] (62), [-0.02026,   inf] (66), [-0.02026,   inf] (54), [-0.02026,   inf] (56), [-0.02026,   inf] (56), [-0.02026,   inf] (56), [-0.02026,   inf] (42), [-0.02026,   inf] (56), [-0.02026,   inf] (50), [-0.02026,   inf] (60), [-0.02026,   inf] (54), 
length of domains: 17056
Total time: 2.6200	 pickout: 0.1586	 decision: 0.6651	 get_bound: 1.0198	 add_domain: 0.7766
Current lb:-0.02027106285095215
53446 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 68.47955656051636

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 925] [1, 65] [1, 724] [1, 725] [1, 873] [1, 68] [1, 108] [1, 725] [1, 868] [2, 64] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -2.423192024230957 with beta sum per layer: [0.0, 199.3889923095703, 226.760986328125]
alpha/beta optimization time: 0.5991115570068359
This batch time : update_bounds func: 0.9902	 prepare: 0.2083	 bound: 0.5994	 transfer: 0.0375	 finalize: 0.1378
Accumulated time: update_bounds func: 31.8964	 prepare: 5.6749	 bound: 19.3916	 transfer: 0.0375	 finalize: 4.8139
batch bounding time:  0.992222785949707
Current worst splitting domains [lb, ub] (depth):
[-0.01935,   inf] (58), [-0.01935,   inf] (44), [-0.01935,   inf] (62), [-0.01935,   inf] (52), [-0.01935,   inf] (56), [-0.01935,   inf] (56), [-0.01935,   inf] (50), [-0.01935,   inf] (66), [-0.01934,   inf] (50), [-0.01934,   inf] (50), [-0.01934,   inf] (54), [-0.01934,   inf] (56), [-0.01934,   inf] (56), [-0.01934,   inf] (54), [-0.01934,   inf] (50), [-0.01934,   inf] (52), [-0.01933,   inf] (62), [-0.01933,   inf] (58), [-0.01933,   inf] (58), [-0.01933,   inf] (44), 
length of domains: 17370
Total time: 1.9205	 pickout: 0.1597	 decision: 0.6705	 get_bound: 0.9958	 add_domain: 0.0946
Current lb:-0.019351840019226074
55494 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 70.43160223960876

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 724] [1, 873] [1, 917] [1, 861] [1, 757] [1, 725] [1, 873] [1, 763] [1, 68] [1, 757] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -5.175961494445801 with beta sum per layer: [0.0, 192.48681640625, 209.60012817382812]
alpha/beta optimization time: 0.593900203704834
This batch time : update_bounds func: 1.4091	 prepare: 0.2103	 bound: 0.5942	 transfer: 0.0178	 finalize: 0.5796
Accumulated time: update_bounds func: 33.3056	 prepare: 5.8852	 bound: 19.9859	 transfer: 0.0178	 finalize: 5.3935
batch bounding time:  1.4111595153808594
Current worst splitting domains [lb, ub] (depth):
[-0.01846,   inf] (58), [-0.01846,   inf] (56), [-0.01846,   inf] (56), [-0.01846,   inf] (56), [-0.01846,   inf] (56), [-0.01846,   inf] (54), [-0.01846,   inf] (50), [-0.01845,   inf] (46), [-0.01845,   inf] (52), [-0.01845,   inf] (64), [-0.01845,   inf] (66), [-0.01845,   inf] (52), [-0.01845,   inf] (64), [-0.01845,   inf] (58), [-0.01845,   inf] (50), [-0.01845,   inf] (56), [-0.01845,   inf] (56), [-0.01844,   inf] (60), [-0.01844,   inf] (60), [-0.01844,   inf] (54), 
length of domains: 17655
Total time: 2.3709	 pickout: 0.1906	 decision: 0.6730	 get_bound: 1.4147	 add_domain: 0.0926
Current lb:-0.018461227416992188
57542 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 72.83149361610413

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 757] [1, 757] [1, 65] [1, 65] [1, 65] [1, 763] [1, 68] [1, 763] [1, 738] [1, 484] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -7.1668171882629395 with beta sum per layer: [0.0, 204.25042724609375, 214.0155029296875]
alpha/beta optimization time: 0.5944249629974365
This batch time : update_bounds func: 0.9989	 prepare: 0.2188	 bound: 0.5948	 transfer: 0.0373	 finalize: 0.1412
Accumulated time: update_bounds func: 34.3045	 prepare: 6.1040	 bound: 20.5806	 transfer: 0.0373	 finalize: 5.5347
batch bounding time:  1.0010850429534912
Current worst splitting domains [lb, ub] (depth):
[-0.01763,   inf] (52), [-0.01763,   inf] (60), [-0.01763,   inf] (44), [-0.01762,   inf] (50), [-0.01762,   inf] (60), [-0.01762,   inf] (42), [-0.01762,   inf] (52), [-0.01762,   inf] (62), [-0.01762,   inf] (60), [-0.01762,   inf] (52), [-0.01762,   inf] (54), [-0.01762,   inf] (64), [-0.01762,   inf] (56), [-0.01762,   inf] (52), [-0.01762,   inf] (64), [-0.01762,   inf] (66), [-0.01762,   inf] (42), [-0.01762,   inf] (56), [-0.01762,   inf] (60), [-0.01762,   inf] (48), 
length of domains: 17889
Total time: 1.9281	 pickout: 0.1627	 decision: 0.6721	 get_bound: 1.0047	 add_domain: 0.0886
Current lb:-0.017627635970711708
59590 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 74.79145503044128

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 861] [2, 64] [1, 68] [1, 68] [2, 4] [1, 868] [1, 861] [1, 917] [2, 4] [1, 738] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -8.391624450683594 with beta sum per layer: [0.0, 196.25051879882812, 221.1110076904297]
alpha/beta optimization time: 0.5976028442382812
This batch time : update_bounds func: 0.9909	 prepare: 0.2095	 bound: 0.5979	 transfer: 0.0373	 finalize: 0.1391
Accumulated time: update_bounds func: 35.2955	 prepare: 6.3135	 bound: 21.1786	 transfer: 0.0373	 finalize: 5.6737
batch bounding time:  0.9929847717285156
Current worst splitting domains [lb, ub] (depth):
[-0.01682,   inf] (58), [-0.01682,   inf] (54), [-0.01682,   inf] (56), [-0.01681,   inf] (62), [-0.01681,   inf] (46), [-0.01681,   inf] (56), [-0.01681,   inf] (58), [-0.01681,   inf] (64), [-0.01681,   inf] (50), [-0.01681,   inf] (52), [-0.01681,   inf] (60), [-0.01681,   inf] (58), [-0.01681,   inf] (60), [-0.01680,   inf] (62), [-0.01680,   inf] (52), [-0.01680,   inf] (64), [-0.01680,   inf] (52), [-0.01680,   inf] (68), [-0.01680,   inf] (54), [-0.01680,   inf] (60), 
length of domains: 18076
Total time: 2.3405	 pickout: 0.1598	 decision: 1.0973	 get_bound: 0.9966	 add_domain: 0.0868
Current lb:-0.016817092895507812
61638 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 77.16452836990356

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 65] [1, 725] [1, 757] [2, 64] [1, 67] [1, 725] [2, 4] [1, 917] [1, 876] [1, 861] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -9.834962844848633 with beta sum per layer: [0.0, 204.55087280273438, 216.26455688476562]
alpha/beta optimization time: 0.5941119194030762
This batch time : update_bounds func: 0.9885	 prepare: 0.2098	 bound: 0.5945	 transfer: 0.0373	 finalize: 0.1403
Accumulated time: update_bounds func: 36.2840	 prepare: 6.5233	 bound: 21.7730	 transfer: 0.0373	 finalize: 5.8140
batch bounding time:  0.9905660152435303
Current worst splitting domains [lb, ub] (depth):
[-0.01601,   inf] (54), [-0.01600,   inf] (60), [-0.01600,   inf] (54), [-0.01600,   inf] (48), [-0.01600,   inf] (50), [-0.01600,   inf] (56), [-0.01600,   inf] (50), [-0.01600,   inf] (50), [-0.01600,   inf] (58), [-0.01600,   inf] (70), [-0.01600,   inf] (64), [-0.01600,   inf] (52), [-0.01600,   inf] (66), [-0.01600,   inf] (50), [-0.01599,   inf] (52), [-0.01599,   inf] (50), [-0.01599,   inf] (58), [-0.01599,   inf] (52), [-0.01599,   inf] (48), [-0.01599,   inf] (54), 
length of domains: 18189
Total time: 2.3598	 pickout: 0.1601	 decision: 0.6724	 get_bound: 0.9942	 add_domain: 0.5332
Current lb:-0.01600503921508789
63686 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 79.55691480636597

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 725] [2, 4] [1, 725] [1, 869] [1, 873] [1, 65] [1, 869] [1, 68] [1, 725] [1, 724] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -11.013631820678711 with beta sum per layer: [0.0, 211.838134765625, 210.50555419921875]
alpha/beta optimization time: 0.595360279083252
This batch time : update_bounds func: 0.9974	 prepare: 0.2150	 bound: 0.5957	 transfer: 0.0380	 finalize: 0.1418
Accumulated time: update_bounds func: 37.2814	 prepare: 6.7383	 bound: 22.3687	 transfer: 0.0380	 finalize: 5.9558
batch bounding time:  0.9995050430297852
Current worst splitting domains [lb, ub] (depth):
[-0.01524,   inf] (66), [-0.01524,   inf] (48), [-0.01524,   inf] (56), [-0.01524,   inf] (42), [-0.01524,   inf] (56), [-0.01524,   inf] (52), [-0.01524,   inf] (54), [-0.01524,   inf] (54), [-0.01524,   inf] (52), [-0.01524,   inf] (54), [-0.01524,   inf] (54), [-0.01524,   inf] (58), [-0.01524,   inf] (58), [-0.01523,   inf] (52), [-0.01523,   inf] (66), [-0.01523,   inf] (56), [-0.01523,   inf] (50), [-0.01523,   inf] (52), [-0.01523,   inf] (66), [-0.01523,   inf] (52), 
length of domains: 18265
Total time: 1.9190	 pickout: 0.1618	 decision: 0.6736	 get_bound: 1.0031	 add_domain: 0.0804
Current lb:-0.015240192413330078
65734 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 81.50955033302307

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 484] [1, 108] [1, 757] [1, 67] [1, 725] [1, 108] [1, 725] [2, 4] [1, 869] [1, 725] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -13.435775756835938 with beta sum per layer: [0.0, 201.02880859375, 209.0346221923828]
alpha/beta optimization time: 0.5952491760253906
This batch time : update_bounds func: 1.4556	 prepare: 0.2091	 bound: 0.5956	 transfer: 0.0378	 finalize: 0.6062
Accumulated time: update_bounds func: 38.7370	 prepare: 6.9474	 bound: 22.9643	 transfer: 0.0378	 finalize: 6.5620
batch bounding time:  1.4580202102661133
Current worst splitting domains [lb, ub] (depth):
[-0.01454,   inf] (58), [-0.01454,   inf] (60), [-0.01454,   inf] (56), [-0.01454,   inf] (60), [-0.01454,   inf] (48), [-0.01454,   inf] (48), [-0.01454,   inf] (68), [-0.01454,   inf] (54), [-0.01454,   inf] (68), [-0.01454,   inf] (54), [-0.01453,   inf] (48), [-0.01453,   inf] (56), [-0.01453,   inf] (52), [-0.01453,   inf] (56), [-0.01453,   inf] (54), [-0.01453,   inf] (60), [-0.01453,   inf] (66), [-0.01453,   inf] (56), [-0.01453,   inf] (56), [-0.01453,   inf] (52), 
length of domains: 18269
Total time: 2.3722	 pickout: 0.1616	 decision: 0.6745	 get_bound: 1.4619	 add_domain: 0.0742
Current lb:-0.014544129371643066
67782 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 83.9138994216919

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 4] [2, 4] [1, 65] [1, 917] [1, 873] [1, 108] [1, 724] [1, 757] [1, 485] [1, 725] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -16.106094360351562 with beta sum per layer: [0.0, 200.04373168945312, 205.38009643554688]
alpha/beta optimization time: 0.5947785377502441
This batch time : update_bounds func: 0.9919	 prepare: 0.2097	 bound: 0.5951	 transfer: 0.0374	 finalize: 0.1427
Accumulated time: update_bounds func: 39.7289	 prepare: 7.1570	 bound: 23.5594	 transfer: 0.0374	 finalize: 6.7047
batch bounding time:  0.993966817855835
Current worst splitting domains [lb, ub] (depth):
[-0.01385,   inf] (58), [-0.01385,   inf] (66), [-0.01385,   inf] (58), [-0.01384,   inf] (54), [-0.01384,   inf] (70), [-0.01384,   inf] (62), [-0.01384,   inf] (50), [-0.01384,   inf] (56), [-0.01384,   inf] (42), [-0.01384,   inf] (54), [-0.01384,   inf] (62), [-0.01384,   inf] (56), [-0.01384,   inf] (52), [-0.01384,   inf] (62), [-0.01384,   inf] (60), [-0.01384,   inf] (58), [-0.01384,   inf] (56), [-0.01384,   inf] (52), [-0.01384,   inf] (54), [-0.01384,   inf] (58), 
length of domains: 18220
Total time: 1.9413	 pickout: 0.1870	 decision: 0.6800	 get_bound: 0.9977	 add_domain: 0.0767
Current lb:-0.013847589492797852
69830 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 85.89600706100464

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 724] [1, 65] [2, 4] [1, 763] [1, 730] [2, 64] [1, 757] [1, 725] [1, 745] [1, 861] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -16.5575008392334 with beta sum per layer: [0.0, 219.34268188476562, 215.8209228515625]
alpha/beta optimization time: 0.5961542129516602
This batch time : update_bounds func: 1.4710	 prepare: 0.2115	 bound: 0.5965	 transfer: 0.0390	 finalize: 0.6165
Accumulated time: update_bounds func: 41.1999	 prepare: 7.3685	 bound: 24.1559	 transfer: 0.0390	 finalize: 7.3213
batch bounding time:  1.4730720520019531
Current worst splitting domains [lb, ub] (depth):
[-0.01319,   inf] (66), [-0.01319,   inf] (60), [-0.01319,   inf] (56), [-0.01319,   inf] (56), [-0.01318,   inf] (56), [-0.01318,   inf] (56), [-0.01318,   inf] (62), [-0.01318,   inf] (60), [-0.01318,   inf] (56), [-0.01318,   inf] (54), [-0.01318,   inf] (52), [-0.01318,   inf] (56), [-0.01318,   inf] (50), [-0.01318,   inf] (52), [-0.01318,   inf] (56), [-0.01318,   inf] (52), [-0.01318,   inf] (70), [-0.01318,   inf] (52), [-0.01318,   inf] (50), [-0.01317,   inf] (54), 
length of domains: 18077
Total time: 2.3838	 pickout: 0.1687	 decision: 0.6733	 get_bound: 1.4767	 add_domain: 0.0651
Current lb:-0.013186335563659668
71878 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 88.31630730628967

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 485] [2, 4] [2, 4] [2, 4] [1, 876] [1, 65] [1, 484] [1, 65] [1, 725] [1, 873] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -18.492740631103516 with beta sum per layer: [0.0, 198.47760009765625, 218.06781005859375]
alpha/beta optimization time: 0.5953433513641357
This batch time : update_bounds func: 0.9916	 prepare: 0.2098	 bound: 0.5957	 transfer: 0.0372	 finalize: 0.1416
Accumulated time: update_bounds func: 42.1915	 prepare: 7.5784	 bound: 24.7517	 transfer: 0.0372	 finalize: 7.4629
batch bounding time:  0.9937152862548828
Current worst splitting domains [lb, ub] (depth):
[-0.01250,   inf] (60), [-0.01250,   inf] (60), [-0.01250,   inf] (54), [-0.01250,   inf] (46), [-0.01250,   inf] (50), [-0.01250,   inf] (62), [-0.01250,   inf] (62), [-0.01250,   inf] (60), [-0.01250,   inf] (50), [-0.01250,   inf] (56), [-0.01249,   inf] (62), [-0.01249,   inf] (46), [-0.01249,   inf] (50), [-0.01249,   inf] (54), [-0.01249,   inf] (54), [-0.01249,   inf] (58), [-0.01249,   inf] (62), [-0.01249,   inf] (64), [-0.01249,   inf] (66), [-0.01249,   inf] (66), 
length of domains: 17843
Total time: 1.8987	 pickout: 0.1647	 decision: 0.6776	 get_bound: 0.9973	 add_domain: 0.0591
Current lb:-0.012500091455876827
73926 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 90.25287461280823

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 484] [2, 64] [1, 861] [1, 67] [1, 68] [1, 724] [2, 64] [2, 4] [1, 763] [1, 65] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -17.69933319091797 with beta sum per layer: [0.0, 200.52462768554688, 220.15887451171875]
alpha/beta optimization time: 0.5960228443145752
This batch time : update_bounds func: 0.9946	 prepare: 0.2110	 bound: 0.5964	 transfer: 0.0373	 finalize: 0.1431
Accumulated time: update_bounds func: 43.1861	 prepare: 7.7893	 bound: 25.3480	 transfer: 0.0373	 finalize: 7.6059
batch bounding time:  0.9966633319854736
Current worst splitting domains [lb, ub] (depth):
[-0.01185,   inf] (50), [-0.01185,   inf] (58), [-0.01185,   inf] (50), [-0.01185,   inf] (52), [-0.01185,   inf] (58), [-0.01185,   inf] (46), [-0.01185,   inf] (64), [-0.01185,   inf] (62), [-0.01185,   inf] (56), [-0.01185,   inf] (60), [-0.01184,   inf] (56), [-0.01184,   inf] (58), [-0.01184,   inf] (52), [-0.01184,   inf] (58), [-0.01184,   inf] (56), [-0.01184,   inf] (58), [-0.01184,   inf] (52), [-0.01184,   inf] (66), [-0.01184,   inf] (56), [-0.01184,   inf] (66), 
length of domains: 17535
Total time: 2.3524	 pickout: 0.1660	 decision: 1.1316	 get_bound: 1.0003	 add_domain: 0.0544
Current lb:-0.011847888119518757
75974 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 92.6445779800415

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 68] [1, 868] [1, 757] [1, 876] [2, 4] [1, 68] [1, 484] [2, 64] [1, 65] [2, 4] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -16.6083927154541 with beta sum per layer: [0.0, 188.30044555664062, 202.60995483398438]
alpha/beta optimization time: 0.594160795211792
This batch time : update_bounds func: 1.0036	 prepare: 0.2138	 bound: 0.5945	 transfer: 0.0402	 finalize: 0.1483
Accumulated time: update_bounds func: 44.1897	 prepare: 8.0031	 bound: 25.9425	 transfer: 0.0402	 finalize: 7.7542
batch bounding time:  1.0056912899017334
Current worst splitting domains [lb, ub] (depth):
[-0.01124,   inf] (62), [-0.01124,   inf] (64), [-0.01124,   inf] (42), [-0.01123,   inf] (54), [-0.01123,   inf] (46), [-0.01123,   inf] (58), [-0.01123,   inf] (56), [-0.01123,   inf] (64), [-0.01123,   inf] (58), [-0.01123,   inf] (60), [-0.01123,   inf] (64), [-0.01123,   inf] (48), [-0.01123,   inf] (52), [-0.01123,   inf] (60), [-0.01123,   inf] (52), [-0.01123,   inf] (66), [-0.01123,   inf] (54), [-0.01123,   inf] (56), [-0.01123,   inf] (54), [-0.01123,   inf] (54), 
length of domains: 17189
Total time: 1.9004	 pickout: 0.1648	 decision: 0.6747	 get_bound: 1.0093	 add_domain: 0.0515
Current lb:-0.011235952377319336
78022 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 94.58190059661865

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 64] [2, 64] [1, 66] [1, 763] [1, 67] [2, 4] [1, 725] [2, 64] [1, 869] [1, 917] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -11.873004913330078 with beta sum per layer: [0.0, 199.76852416992188, 195.538330078125]
alpha/beta optimization time: 0.5963149070739746
This batch time : update_bounds func: 1.0013	 prepare: 0.2132	 bound: 0.5967	 transfer: 0.0391	 finalize: 0.1453
Accumulated time: update_bounds func: 45.1910	 prepare: 8.2163	 bound: 26.5392	 transfer: 0.0391	 finalize: 7.8995
batch bounding time:  1.0033307075500488
Current worst splitting domains [lb, ub] (depth):
[-0.01066,   inf] (58), [-0.01066,   inf] (56), [-0.01065,   inf] (54), [-0.01065,   inf] (54), [-0.01065,   inf] (58), [-0.01065,   inf] (56), [-0.01065,   inf] (52), [-0.01065,   inf] (56), [-0.01065,   inf] (60), [-0.01065,   inf] (66), [-0.01065,   inf] (54), [-0.01065,   inf] (54), [-0.01065,   inf] (68), [-0.01065,   inf] (50), [-0.01065,   inf] (60), [-0.01065,   inf] (52), [-0.01065,   inf] (60), [-0.01065,   inf] (54), [-0.01064,   inf] (64), [-0.01064,   inf] (46), 
length of domains: 16807
Total time: 2.3273	 pickout: 0.1662	 decision: 1.1054	 get_bound: 1.0069	 add_domain: 0.0487
Current lb:-0.010657787322998047
80070 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 96.94578909873962

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 725] [1, 65] [1, 873] [1, 725] [2, 4] [1, 65] [1, 721] [1, 65] [1, 917] [1, 65] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -12.848154067993164 with beta sum per layer: [0.0, 202.09295654296875, 193.04345703125]
alpha/beta optimization time: 0.594689130783081
This batch time : update_bounds func: 1.4391	 prepare: 0.2110	 bound: 0.5950	 transfer: 0.0361	 finalize: 0.5900
Accumulated time: update_bounds func: 46.6301	 prepare: 8.4273	 bound: 27.1342	 transfer: 0.0361	 finalize: 8.4894
batch bounding time:  1.4415397644042969
Current worst splitting domains [lb, ub] (depth):
[-0.01006,   inf] (58), [-0.01006,   inf] (50), [-0.01006,   inf] (58), [-0.01006,   inf] (54), [-0.01006,   inf] (54), [-0.01006,   inf] (66), [-0.01006,   inf] (42), [-0.01006,   inf] (52), [-0.01006,   inf] (52), [-0.01006,   inf] (52), [-0.01006,   inf] (58), [-0.01006,   inf] (60), [-0.01006,   inf] (56), [-0.01006,   inf] (54), [-0.01006,   inf] (58), [-0.01006,   inf] (66), [-0.01006,   inf] (64), [-0.01005,   inf] (46), [-0.01005,   inf] (58), [-0.01005,   inf] (62), 
length of domains: 16398
Total time: 2.3303	 pickout: 0.1634	 decision: 0.6747	 get_bound: 1.4455	 add_domain: 0.0466
Current lb:-0.010063004679977894
82118 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 99.3142340183258

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 725] [1, 757] [2, 4] [1, 725] [1, 861] [1, 724] [1, 721] [1, 861] [1, 861] [1, 721] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -15.41510009765625 with beta sum per layer: [0.0, 197.94004821777344, 189.6695556640625]
alpha/beta optimization time: 0.5966246128082275
This batch time : update_bounds func: 0.9896	 prepare: 0.2152	 bound: 0.5970	 transfer: 0.0227	 finalize: 0.1483
Accumulated time: update_bounds func: 47.6197	 prepare: 8.6426	 bound: 27.7312	 transfer: 0.0227	 finalize: 8.6377
batch bounding time:  0.9916973114013672
Current worst splitting domains [lb, ub] (depth):
[-0.00950,   inf] (44), [-0.00950,   inf] (58), [-0.00950,   inf] (56), [-0.00949,   inf] (54), [-0.00949,   inf] (54), [-0.00949,   inf] (56), [-0.00949,   inf] (54), [-0.00949,   inf] (68), [-0.00949,   inf] (52), [-0.00949,   inf] (68), [-0.00949,   inf] (70), [-0.00949,   inf] (68), [-0.00949,   inf] (68), [-0.00949,   inf] (70), [-0.00949,   inf] (44), [-0.00949,   inf] (52), [-0.00949,   inf] (66), [-0.00949,   inf] (56), [-0.00949,   inf] (56), [-0.00949,   inf] (56), 
length of domains: 15964
Total time: 1.8783	 pickout: 0.1609	 decision: 0.6767	 get_bound: 0.9953	 add_domain: 0.0454
Current lb:-0.009495139122009277
84166 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 101.2300910949707

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 67] [2, 4] [1, 65] [1, 757] [1, 757] [1, 65] [1, 725] [1, 730] [1, 861] [1, 485] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -16.554641723632812 with beta sum per layer: [0.0, 197.30909729003906, 176.74362182617188]
alpha/beta optimization time: 0.5948226451873779
This batch time : update_bounds func: 1.4204	 prepare: 0.2127	 bound: 0.5951	 transfer: 0.0384	 finalize: 0.5673
Accumulated time: update_bounds func: 49.0401	 prepare: 8.8553	 bound: 28.3263	 transfer: 0.0384	 finalize: 9.2050
batch bounding time:  1.4224388599395752
Current worst splitting domains [lb, ub] (depth):
[-0.00894,   inf] (68), [-0.00894,   inf] (58), [-0.00894,   inf] (64), [-0.00894,   inf] (52), [-0.00894,   inf] (62), [-0.00894,   inf] (64), [-0.00894,   inf] (64), [-0.00894,   inf] (52), [-0.00894,   inf] (50), [-0.00894,   inf] (58), [-0.00894,   inf] (46), [-0.00894,   inf] (52), [-0.00894,   inf] (62), [-0.00893,   inf] (52), [-0.00893,   inf] (58), [-0.00893,   inf] (58), [-0.00893,   inf] (54), [-0.00893,   inf] (68), [-0.00893,   inf] (56), [-0.00893,   inf] (56), 
length of domains: 15468
Total time: 2.3015	 pickout: 0.1636	 decision: 0.6724	 get_bound: 1.4260	 add_domain: 0.0395
Current lb:-0.008943898603320122
86214 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 103.57023358345032

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 725] [2, 4] [2, 64] [1, 869] [1, 917] [2, 64] [1, 65] [1, 873] [1, 725] [1, 763] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -17.152042388916016 with beta sum per layer: [0.0, 199.76333618164062, 205.54742431640625]
alpha/beta optimization time: 0.5960361957550049
This batch time : update_bounds func: 1.0061	 prepare: 0.2132	 bound: 0.5964	 transfer: 0.0382	 finalize: 0.1514
Accumulated time: update_bounds func: 50.0463	 prepare: 9.0685	 bound: 28.9227	 transfer: 0.0382	 finalize: 9.3564
batch bounding time:  1.008181095123291
Current worst splitting domains [lb, ub] (depth):
[-0.00839,   inf] (52), [-0.00839,   inf] (58), [-0.00839,   inf] (54), [-0.00839,   inf] (46), [-0.00839,   inf] (58), [-0.00839,   inf] (54), [-0.00839,   inf] (68), [-0.00838,   inf] (68), [-0.00838,   inf] (60), [-0.00838,   inf] (56), [-0.00838,   inf] (56), [-0.00838,   inf] (56), [-0.00838,   inf] (62), [-0.00838,   inf] (60), [-0.00838,   inf] (68), [-0.00838,   inf] (52), [-0.00838,   inf] (52), [-0.00838,   inf] (54), [-0.00838,   inf] (66), [-0.00838,   inf] (54), 
length of domains: 14924
Total time: 1.8883	 pickout: 0.1645	 decision: 0.6744	 get_bound: 1.0118	 add_domain: 0.0376
Current lb:-0.008389949798583984
88262 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 105.49811553955078

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 876] [1, 724] [1, 861] [1, 721] [1, 724] [1, 725] [1, 730] [1, 724] [1, 917] [1, 861] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -17.312307357788086 with beta sum per layer: [0.0, 196.99224853515625, 205.07949829101562]
alpha/beta optimization time: 0.5951509475708008
This batch time : update_bounds func: 0.9998	 prepare: 0.2130	 bound: 0.5955	 transfer: 0.0372	 finalize: 0.1473
Accumulated time: update_bounds func: 51.0461	 prepare: 9.2815	 bound: 29.5182	 transfer: 0.0372	 finalize: 9.5038
batch bounding time:  1.00189208984375
Current worst splitting domains [lb, ub] (depth):
[-0.00788,   inf] (58), [-0.00788,   inf] (48), [-0.00788,   inf] (68), [-0.00788,   inf] (64), [-0.00788,   inf] (52), [-0.00788,   inf] (54), [-0.00788,   inf] (56), [-0.00788,   inf] (62), [-0.00788,   inf] (56), [-0.00788,   inf] (62), [-0.00787,   inf] (54), [-0.00787,   inf] (58), [-0.00787,   inf] (52), [-0.00787,   inf] (54), [-0.00787,   inf] (48), [-0.00787,   inf] (50), [-0.00787,   inf] (50), [-0.00787,   inf] (54), [-0.00787,   inf] (56), [-0.00787,   inf] (58), 
length of domains: 14379
Total time: 2.2814	 pickout: 0.1676	 decision: 1.0723	 get_bound: 1.0054	 add_domain: 0.0361
Current lb:-0.007880035787820816
90310 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 107.81922507286072

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 868] [1, 68] [1, 869] [1, 484] [1, 873] [1, 869] [1, 65] [1, 917] [1, 725] [2, 64] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -19.454837799072266 with beta sum per layer: [0.0, 195.89486694335938, 169.34683227539062]
alpha/beta optimization time: 0.5911049842834473
This batch time : update_bounds func: 1.4012	 prepare: 0.2161	 bound: 0.5914	 transfer: 0.0387	 finalize: 0.5486
Accumulated time: update_bounds func: 52.4473	 prepare: 9.4976	 bound: 30.1097	 transfer: 0.0387	 finalize: 10.0524
batch bounding time:  1.4036920070648193
Current worst splitting domains [lb, ub] (depth):
[-0.00737,   inf] (66), [-0.00737,   inf] (52), [-0.00737,   inf] (60), [-0.00737,   inf] (70), [-0.00737,   inf] (70), [-0.00737,   inf] (56), [-0.00737,   inf] (58), [-0.00737,   inf] (58), [-0.00737,   inf] (60), [-0.00736,   inf] (52), [-0.00736,   inf] (60), [-0.00736,   inf] (54), [-0.00736,   inf] (52), [-0.00736,   inf] (52), [-0.00736,   inf] (58), [-0.00736,   inf] (60), [-0.00736,   inf] (52), [-0.00736,   inf] (60), [-0.00736,   inf] (58), [-0.00736,   inf] (54), 
length of domains: 13831
Total time: 2.2795	 pickout: 0.1649	 decision: 0.6700	 get_bound: 1.4077	 add_domain: 0.0369
Current lb:-0.007368516176939011
92358 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 110.13733005523682

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 65] [1, 725] [1, 858] [1, 869] [1, 730] [1, 757] [1, 730] [2, 4] [2, 4] [1, 869] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -19.67495346069336 with beta sum per layer: [0.0, 209.2835693359375, 188.73126220703125]
alpha/beta optimization time: 0.5948936939239502
This batch time : update_bounds func: 1.0050	 prepare: 0.2165	 bound: 0.5952	 transfer: 0.0357	 finalize: 0.1510
Accumulated time: update_bounds func: 53.4523	 prepare: 9.7141	 bound: 30.7049	 transfer: 0.0357	 finalize: 10.2034
batch bounding time:  1.0070457458496094
Current worst splitting domains [lb, ub] (depth):
[-0.00686,   inf] (52), [-0.00686,   inf] (58), [-0.00686,   inf] (42), [-0.00686,   inf] (58), [-0.00686,   inf] (40), [-0.00686,   inf] (68), [-0.00686,   inf] (52), [-0.00686,   inf] (66), [-0.00686,   inf] (62), [-0.00686,   inf] (60), [-0.00686,   inf] (62), [-0.00686,   inf] (52), [-0.00686,   inf] (52), [-0.00686,   inf] (68), [-0.00686,   inf] (58), [-0.00686,   inf] (40), [-0.00686,   inf] (46), [-0.00686,   inf] (66), [-0.00686,   inf] (70), [-0.00686,   inf] (48), 
length of domains: 13214
Total time: 1.8803	 pickout: 0.1654	 decision: 0.6733	 get_bound: 1.0106	 add_domain: 0.0310
Current lb:-0.006864070892333984
94406 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 112.05987977981567

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 724] [2, 4] [1, 725] [1, 725] [2, 73] [1, 724] [1, 873] [1, 484] [2, 64] [1, 917] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -21.371265411376953 with beta sum per layer: [0.0, 205.05160522460938, 189.91864013671875]
alpha/beta optimization time: 0.5946657657623291
This batch time : update_bounds func: 1.3379	 prepare: 0.2192	 bound: 0.5950	 transfer: 0.0234	 finalize: 0.1467
Accumulated time: update_bounds func: 54.7902	 prepare: 9.9333	 bound: 31.2999	 transfer: 0.0234	 finalize: 10.3501
batch bounding time:  1.3400263786315918
Current worst splitting domains [lb, ub] (depth):
[-0.00638,   inf] (54), [-0.00638,   inf] (40), [-0.00638,   inf] (42), [-0.00638,   inf] (64), [-0.00638,   inf] (46), [-0.00638,   inf] (46), [-0.00638,   inf] (44), [-0.00638,   inf] (64), [-0.00638,   inf] (50), [-0.00638,   inf] (54), [-0.00638,   inf] (62), [-0.00638,   inf] (54), [-0.00638,   inf] (46), [-0.00638,   inf] (56), [-0.00638,   inf] (58), [-0.00638,   inf] (62), [-0.00638,   inf] (58), [-0.00638,   inf] (54), [-0.00638,   inf] (58), [-0.00638,   inf] (62), 
length of domains: 12617
Total time: 2.2208	 pickout: 0.1723	 decision: 0.6710	 get_bound: 1.3436	 add_domain: 0.0339
Current lb:-0.006384134292602539
96454 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 114.31998300552368

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 763] [1, 67] [1, 868] [1, 65] [1, 721] [1, 67] [1, 67] [1, 484] [1, 757] [1, 861] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -22.307249069213867 with beta sum per layer: [0.0, 195.8959197998047, 197.51226806640625]
alpha/beta optimization time: 0.5932185649871826
This batch time : update_bounds func: 1.3564	 prepare: 0.2116	 bound: 0.5936	 transfer: 0.0384	 finalize: 0.5063
Accumulated time: update_bounds func: 56.1466	 prepare: 10.1448	 bound: 31.8935	 transfer: 0.0384	 finalize: 10.8564
batch bounding time:  1.3590402603149414
Current worst splitting domains [lb, ub] (depth):
[-0.00587,   inf] (58), [-0.00587,   inf] (50), [-0.00587,   inf] (68), [-0.00587,   inf] (62), [-0.00587,   inf] (68), [-0.00587,   inf] (54), [-0.00587,   inf] (54), [-0.00587,   inf] (68), [-0.00587,   inf] (48), [-0.00587,   inf] (64), [-0.00587,   inf] (56), [-0.00587,   inf] (52), [-0.00587,   inf] (50), [-0.00587,   inf] (54), [-0.00586,   inf] (60), [-0.00586,   inf] (58), [-0.00586,   inf] (68), [-0.00586,   inf] (64), [-0.00586,   inf] (46), [-0.00586,   inf] (54), 
length of domains: 11967
Total time: 2.2316	 pickout: 0.1681	 decision: 0.6723	 get_bound: 1.3631	 add_domain: 0.0281
Current lb:-0.005867502652108669
98502 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 116.59119057655334

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 941] [1, 763] [1, 724] [1, 724] [1, 485] [1, 861] [1, 757] [1, 869] [1, 68] [1, 484] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -24.302326202392578 with beta sum per layer: [0.0, 205.87228393554688, 205.96055603027344]
alpha/beta optimization time: 0.5950772762298584
This batch time : update_bounds func: 0.9983	 prepare: 0.2122	 bound: 0.5954	 transfer: 0.0380	 finalize: 0.1463
Accumulated time: update_bounds func: 57.1449	 prepare: 10.3571	 bound: 32.4889	 transfer: 0.0380	 finalize: 11.0026
batch bounding time:  1.000349521636963
Current worst splitting domains [lb, ub] (depth):
[-0.00538,   inf] (50), [-0.00538,   inf] (68), [-0.00538,   inf] (56), [-0.00538,   inf] (58), [-0.00538,   inf] (66), [-0.00538,   inf] (60), [-0.00538,   inf] (46), [-0.00538,   inf] (64), [-0.00538,   inf] (52), [-0.00538,   inf] (56), [-0.00538,   inf] (60), [-0.00538,   inf] (48), [-0.00538,   inf] (54), [-0.00538,   inf] (56), [-0.00538,   inf] (66), [-0.00538,   inf] (50), [-0.00538,   inf] (58), [-0.00538,   inf] (64), [-0.00538,   inf] (52), [-0.00538,   inf] (64), 
length of domains: 11332
Total time: 1.8788	 pickout: 0.1670	 decision: 0.6782	 get_bound: 1.0039	 add_domain: 0.0297
Current lb:-0.005384683609008789
100550 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 118.51082587242126

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 757] [1, 485] [1, 757] [1, 861] [1, 65] [1, 868] [1, 67] [1, 65] [1, 763] [1, 757] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -25.053340911865234 with beta sum per layer: [0.0, 201.69015502929688, 211.55307006835938]
alpha/beta optimization time: 0.5927047729492188
This batch time : update_bounds func: 1.3154	 prepare: 0.2165	 bound: 0.5930	 transfer: 0.0355	 finalize: 0.1454
Accumulated time: update_bounds func: 58.4603	 prepare: 10.5735	 bound: 33.0819	 transfer: 0.0355	 finalize: 11.1480
batch bounding time:  1.3174898624420166
Current worst splitting domains [lb, ub] (depth):
[-0.00495,   inf] (66), [-0.00495,   inf] (56), [-0.00495,   inf] (66), [-0.00495,   inf] (42), [-0.00495,   inf] (64), [-0.00495,   inf] (40), [-0.00494,   inf] (62), [-0.00494,   inf] (58), [-0.00494,   inf] (58), [-0.00494,   inf] (56), [-0.00494,   inf] (54), [-0.00494,   inf] (48), [-0.00494,   inf] (62), [-0.00494,   inf] (62), [-0.00494,   inf] (60), [-0.00494,   inf] (56), [-0.00494,   inf] (56), [-0.00494,   inf] (60), [-0.00494,   inf] (52), [-0.00494,   inf] (58), 
length of domains: 10682
Total time: 2.1952	 pickout: 0.1702	 decision: 0.6736	 get_bound: 1.3210	 add_domain: 0.0303
Current lb:-0.0049468278884887695
102598 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 120.74718856811523

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 484] [1, 876] [1, 65] [1, 108] [1, 725] [1, 721] [2, 64] [1, 941] [2, 64] [1, 725] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -25.047697067260742 with beta sum per layer: [0.0, 207.47073364257812, 197.6855010986328]
alpha/beta optimization time: 0.5908982753753662
This batch time : update_bounds func: 1.3062	 prepare: 0.2175	 bound: 0.5912	 transfer: 0.0267	 finalize: 0.4648
Accumulated time: update_bounds func: 59.7665	 prepare: 10.7910	 bound: 33.6731	 transfer: 0.0267	 finalize: 11.6128
batch bounding time:  1.3082425594329834
Current worst splitting domains [lb, ub] (depth):
[-0.00449,   inf] (62), [-0.00449,   inf] (66), [-0.00449,   inf] (74), [-0.00449,   inf] (56), [-0.00449,   inf] (54), [-0.00449,   inf] (50), [-0.00449,   inf] (58), [-0.00449,   inf] (58), [-0.00449,   inf] (58), [-0.00449,   inf] (54), [-0.00449,   inf] (58), [-0.00449,   inf] (58), [-0.00449,   inf] (46), [-0.00449,   inf] (64), [-0.00449,   inf] (56), [-0.00449,   inf] (68), [-0.00449,   inf] (58), [-0.00449,   inf] (50), [-0.00449,   inf] (54), [-0.00448,   inf] (58), 
length of domains: 10026
Total time: 2.1783	 pickout: 0.1660	 decision: 0.6727	 get_bound: 1.3117	 add_domain: 0.0279
Current lb:-0.004491686820983887
104646 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 122.96646070480347

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 484] [1, 484] [1, 738] [1, 65] [1, 757] [1, 763] [1, 757] [1, 65] [1, 65] [1, 725] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -25.620967864990234 with beta sum per layer: [0.0, 208.65921020507812, 197.61851501464844]
alpha/beta optimization time: 0.5908215045928955
This batch time : update_bounds func: 0.9760	 prepare: 0.2120	 bound: 0.5911	 transfer: 0.0213	 finalize: 0.1453
Accumulated time: update_bounds func: 60.7426	 prepare: 11.0030	 bound: 34.2643	 transfer: 0.0213	 finalize: 11.7581
batch bounding time:  0.9780919551849365
Current worst splitting domains [lb, ub] (depth):
[-0.00407,   inf] (62), [-0.00407,   inf] (62), [-0.00407,   inf] (56), [-0.00407,   inf] (56), [-0.00407,   inf] (42), [-0.00407,   inf] (56), [-0.00407,   inf] (54), [-0.00407,   inf] (58), [-0.00407,   inf] (54), [-0.00407,   inf] (60), [-0.00406,   inf] (56), [-0.00406,   inf] (50), [-0.00406,   inf] (66), [-0.00406,   inf] (50), [-0.00406,   inf] (72), [-0.00406,   inf] (62), [-0.00406,   inf] (58), [-0.00406,   inf] (52), [-0.00406,   inf] (58), [-0.00406,   inf] (58), 
length of domains: 9395
Total time: 1.8487	 pickout: 0.1640	 decision: 0.6733	 get_bound: 0.9816	 add_domain: 0.0298
Current lb:-0.0040694475173950195
106694 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 124.85540175437927

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 64] [2, 64] [1, 763] [1, 725] [1, 67] [1, 65] [1, 861] [1, 757] [1, 724] [1, 757] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -26.65564727783203 with beta sum per layer: [0.0, 211.07205200195312, 197.38612365722656]
alpha/beta optimization time: 0.5904629230499268
This batch time : update_bounds func: 0.9864	 prepare: 0.2091	 bound: 0.5908	 transfer: 0.0384	 finalize: 0.1417
Accumulated time: update_bounds func: 61.7290	 prepare: 11.2121	 bound: 34.8551	 transfer: 0.0384	 finalize: 11.8998
batch bounding time:  0.9883880615234375
Current worst splitting domains [lb, ub] (depth):
[-0.00364,   inf] (52), [-0.00364,   inf] (52), [-0.00364,   inf] (60), [-0.00363,   inf] (56), [-0.00363,   inf] (62), [-0.00363,   inf] (54), [-0.00363,   inf] (56), [-0.00363,   inf] (56), [-0.00363,   inf] (70), [-0.00363,   inf] (56), [-0.00363,   inf] (60), [-0.00363,   inf] (52), [-0.00363,   inf] (58), [-0.00363,   inf] (62), [-0.00363,   inf] (44), [-0.00363,   inf] (70), [-0.00363,   inf] (56), [-0.00363,   inf] (60), [-0.00363,   inf] (66), [-0.00362,   inf] (66), 
length of domains: 8707
Total time: 2.1187	 pickout: 0.1674	 decision: 0.9319	 get_bound: 0.9919	 add_domain: 0.0274
Current lb:-0.003635406494140625
108742 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 127.01386713981628

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 68] [1, 763] [2, 64] [1, 65] [1, 725] [1, 725] [1, 65] [1, 65] [1, 485] [1, 725] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -27.3912410736084 with beta sum per layer: [0.0, 201.9283905029297, 205.95555114746094]
alpha/beta optimization time: 0.5904645919799805
This batch time : update_bounds func: 0.9868	 prepare: 0.2091	 bound: 0.5908	 transfer: 0.0386	 finalize: 0.1420
Accumulated time: update_bounds func: 62.7157	 prepare: 11.4213	 bound: 35.4459	 transfer: 0.0386	 finalize: 12.0418
batch bounding time:  0.9887793064117432
Current worst splitting domains [lb, ub] (depth):
[-0.00322,   inf] (52), [-0.00322,   inf] (60), [-0.00322,   inf] (64), [-0.00322,   inf] (50), [-0.00322,   inf] (50), [-0.00322,   inf] (56), [-0.00322,   inf] (48), [-0.00322,   inf] (56), [-0.00322,   inf] (66), [-0.00322,   inf] (52), [-0.00321,   inf] (66), [-0.00321,   inf] (66), [-0.00321,   inf] (68), [-0.00321,   inf] (48), [-0.00321,   inf] (58), [-0.00321,   inf] (40), [-0.00321,   inf] (58), [-0.00321,   inf] (56), [-0.00321,   inf] (68), [-0.00321,   inf] (72), 
length of domains: 7957
Total time: 2.0940	 pickout: 0.1695	 decision: 0.9104	 get_bound: 0.9923	 add_domain: 0.0218
Current lb:-0.003222227096557617
110790 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 129.14777064323425

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 876] [1, 757] [1, 485] [1, 925] [1, 873] [1, 725] [1, 721] [1, 65] [1, 65] [1, 721] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -28.94784164428711 with beta sum per layer: [0.0, 219.6260223388672, 196.21124267578125]
alpha/beta optimization time: 0.5871410369873047
This batch time : update_bounds func: 0.9832	 prepare: 0.2095	 bound: 0.5875	 transfer: 0.0373	 finalize: 0.1431
Accumulated time: update_bounds func: 63.6989	 prepare: 11.6307	 bound: 36.0333	 transfer: 0.0373	 finalize: 12.1849
batch bounding time:  0.9855847358703613
Current worst splitting domains [lb, ub] (depth):
[-0.00279,   inf] (54), [-0.00279,   inf] (64), [-0.00279,   inf] (64), [-0.00279,   inf] (46), [-0.00279,   inf] (56), [-0.00279,   inf] (60), [-0.00279,   inf] (52), [-0.00279,   inf] (52), [-0.00279,   inf] (60), [-0.00278,   inf] (54), [-0.00278,   inf] (66), [-0.00278,   inf] (54), [-0.00278,   inf] (62), [-0.00278,   inf] (58), [-0.00278,   inf] (46), [-0.00278,   inf] (50), [-0.00278,   inf] (56), [-0.00278,   inf] (56), [-0.00278,   inf] (66), [-0.00278,   inf] (62), 
length of domains: 7162
Total time: 2.0741	 pickout: 0.1698	 decision: 0.8963	 get_bound: 0.9893	 add_domain: 0.0186
Current lb:-0.002789619378745556
112838 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 131.26599287986755

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 861] [2, 64] [1, 484] [1, 869] [1, 917] [2, 4] [1, 869] [1, 861] [2, 4] [1, 873] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -29.999988555908203 with beta sum per layer: [0.0, 207.20486450195312, 199.49169921875]
alpha/beta optimization time: 0.5901234149932861
This batch time : update_bounds func: 0.9829	 prepare: 0.2096	 bound: 0.5905	 transfer: 0.0387	 finalize: 0.1383
Accumulated time: update_bounds func: 64.6819	 prepare: 11.8403	 bound: 36.6238	 transfer: 0.0387	 finalize: 12.3232
batch bounding time:  0.9849209785461426
Current worst splitting domains [lb, ub] (depth):
[-0.00238,   inf] (58), [-0.00238,   inf] (64), [-0.00238,   inf] (48), [-0.00238,   inf] (64), [-0.00238,   inf] (42), [-0.00238,   inf] (56), [-0.00238,   inf] (64), [-0.00238,   inf] (68), [-0.00237,   inf] (64), [-0.00237,   inf] (56), [-0.00237,   inf] (68), [-0.00237,   inf] (48), [-0.00237,   inf] (62), [-0.00237,   inf] (54), [-0.00237,   inf] (60), [-0.00237,   inf] (66), [-0.00237,   inf] (50), [-0.00237,   inf] (56), [-0.00237,   inf] (42), [-0.00237,   inf] (52), 
length of domains: 6313
Total time: 2.0700	 pickout: 0.1755	 decision: 0.8918	 get_bound: 0.9884	 add_domain: 0.0143
Current lb:-0.002379298210144043
114886 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 133.37764716148376

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 757] [1, 484] [1, 873] [1, 484] [1, 721] [1, 868] [1, 484] [1, 108] [1, 484] [2, 4] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -31.256126403808594 with beta sum per layer: [0.0, 217.81593322753906, 219.17031860351562]
alpha/beta optimization time: 0.5923871994018555
This batch time : update_bounds func: 0.9755	 prepare: 0.2077	 bound: 0.5927	 transfer: 0.0312	 finalize: 0.1381
Accumulated time: update_bounds func: 65.6574	 prepare: 12.0480	 bound: 37.2165	 transfer: 0.0312	 finalize: 12.4613
batch bounding time:  0.9775309562683105
Current worst splitting domains [lb, ub] (depth):
[-0.00199,   inf] (46), [-0.00199,   inf] (64), [-0.00198,   inf] (60), [-0.00198,   inf] (62), [-0.00198,   inf] (60), [-0.00198,   inf] (68), [-0.00198,   inf] (64), [-0.00198,   inf] (56), [-0.00198,   inf] (64), [-0.00198,   inf] (56), [-0.00198,   inf] (56), [-0.00198,   inf] (52), [-0.00198,   inf] (70), [-0.00198,   inf] (54), [-0.00198,   inf] (48), [-0.00198,   inf] (62), [-0.00198,   inf] (60), [-0.00198,   inf] (64), [-0.00198,   inf] (50), [-0.00198,   inf] (50), 
length of domains: 5349
Total time: 2.0103	 pickout: 0.1674	 decision: 0.8561	 get_bound: 0.9810	 add_domain: 0.0059
Current lb:-0.0019855499267578125
116934 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 135.43061470985413

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 721] [1, 725] [1, 917] [1, 725] [1, 917] [1, 869] [1, 484] [1, 65] [2, 64] [1, 725] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -31.047637939453125 with beta sum per layer: [0.0, 210.01968383789062, 192.53622436523438]
alpha/beta optimization time: 0.5634162425994873
This batch time : update_bounds func: 0.9308	 prepare: 0.2080	 bound: 0.5637	 transfer: 0.0155	 finalize: 0.1375
Accumulated time: update_bounds func: 66.5882	 prepare: 12.2560	 bound: 37.7802	 transfer: 0.0155	 finalize: 12.5988
batch bounding time:  0.9327950477600098
Current worst splitting domains [lb, ub] (depth):
[-0.00160,   inf] (56), [-0.00160,   inf] (62), [-0.00160,   inf] (64), [-0.00160,   inf] (60), [-0.00160,   inf] (52), [-0.00160,   inf] (58), [-0.00159,   inf] (52), [-0.00159,   inf] (48), [-0.00159,   inf] (72), [-0.00159,   inf] (64), [-0.00159,   inf] (58), [-0.00159,   inf] (68), [-0.00159,   inf] (72), [-0.00159,   inf] (56), [-0.00159,   inf] (64), [-0.00159,   inf] (56), [-0.00159,   inf] (64), [-0.00159,   inf] (58), [-0.00159,   inf] (60), [-0.00159,   inf] (58), 
length of domains: 4329
Total time: 1.9384	 pickout: 0.1705	 decision: 0.8303	 get_bound: 0.9362	 add_domain: 0.0015
Current lb:-0.0015961170429363847
118982 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 137.41177988052368

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 65] [1, 724] [2, 64] [1, 724] [1, 869] [1, 941] [1, 873] [1, 861] [1, 747] [1, 484] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -32.175140380859375 with beta sum per layer: [0.0, 207.88192749023438, 197.68035888671875]
alpha/beta optimization time: 0.5453653335571289
This batch time : update_bounds func: 1.0729	 prepare: 0.2081	 bound: 0.5457	 transfer: 0.0246	 finalize: 0.2892
Accumulated time: update_bounds func: 67.6610	 prepare: 12.4642	 bound: 38.3260	 transfer: 0.0246	 finalize: 12.8880
batch bounding time:  1.075334072113037
Current worst splitting domains [lb, ub] (depth):
[-0.00121,   inf] (68), [-0.00121,   inf] (64), [-0.00121,   inf] (56), [-0.00121,   inf] (54), [-0.00121,   inf] (66), [-0.00121,   inf] (60), [-0.00120,   inf] (42), [-0.00120,   inf] (56), [-0.00120,   inf] (50), [-0.00120,   inf] (60), [-0.00120,   inf] (70), [-0.00120,   inf] (54), [-0.00120,   inf] (62), [-0.00120,   inf] (54), [-0.00120,   inf] (66), [-0.00120,   inf] (62), [-0.00120,   inf] (56), [-0.00120,   inf] (50), [-0.00120,   inf] (64), [-0.00120,   inf] (60), 
length of domains: 3306
Total time: 2.0536	 pickout: 0.1726	 decision: 0.8009	 get_bound: 1.0791	 add_domain: 0.0011
Current lb:-0.0012069940567016602
121030 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 139.50678968429565

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 725] [1, 65] [1, 65] [1, 873] [1, 485] [1, 917] [1, 725] [1, 725] [1, 68] [2, 4] 
regular batch size: 2*1024, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -32.637359619140625 with beta sum per layer: [0.0, 215.854736328125, 217.2726593017578]
alpha/beta optimization time: 0.01889181137084961
This batch time : update_bounds func: 0.5340	 prepare: 0.2072	 bound: 0.0192	 transfer: 0.0410	 finalize: 0.2608
Accumulated time: update_bounds func: 68.1950	 prepare: 12.6714	 bound: 38.3451	 transfer: 0.0410	 finalize: 13.1488
batch bounding time:  0.5361864566802979
Current worst splitting domains [lb, ub] (depth):
[-0.00083,   inf] (58), [-0.00083,   inf] (52), [-0.00083,   inf] (68), [-0.00083,   inf] (52), [-0.00083,   inf] (60), [-0.00083,   inf] (62), [-0.00083,   inf] (54), [-0.00083,   inf] (68), [-0.00083,   inf] (54), [-0.00083,   inf] (60), [-0.00083,   inf] (64), [-0.00083,   inf] (58), [-0.00083,   inf] (52), [-0.00083,   inf] (62), [-0.00083,   inf] (56), [-0.00083,   inf] (50), [-0.00083,   inf] (50), [-0.00083,   inf] (50), [-0.00083,   inf] (58), [-0.00083,   inf] (54), 
length of domains: 2282
Total time: 1.3733	 pickout: 0.1755	 decision: 0.6570	 get_bound: 0.5398	 add_domain: 0.0010
Current lb:-0.0008313655853271484
123078 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 140.92070865631104

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 64] [1, 925] [1, 108] [1, 876] [1, 730] [2, 64] [1, 869] [1, 725] [1, 925] [1, 917] 
regular batch size: 2*1024, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -33.683319091796875 with beta sum per layer: [0.0, 211.53814697265625, 212.0523681640625]
alpha/beta optimization time: 0.018840312957763672
This batch time : update_bounds func: 0.4988	 prepare: 0.2100	 bound: 0.0191	 transfer: 0.0403	 finalize: 0.2236
Accumulated time: update_bounds func: 68.6938	 prepare: 12.8813	 bound: 38.3643	 transfer: 0.0403	 finalize: 13.3723
batch bounding time:  0.5006351470947266
Current worst splitting domains [lb, ub] (depth):
[-0.00047,   inf] (52), [-0.00047,   inf] (54), [-0.00047,   inf] (66), [-0.00047,   inf] (58), [-0.00047,   inf] (58), [-0.00047,   inf] (60), [-0.00047,   inf] (70), [-0.00047,   inf] (64), [-0.00047,   inf] (58), [-0.00047,   inf] (68), [-0.00046,   inf] (64), [-0.00046,   inf] (60), [-0.00046,   inf] (40), [-0.00046,   inf] (62), [-0.00046,   inf] (56), [-0.00046,   inf] (60), [-0.00046,   inf] (56), [-0.00046,   inf] (68), [-0.00046,   inf] (64), [-0.00046,   inf] (68), 
length of domains: 1258
Total time: 1.3414	 pickout: 0.1749	 decision: 0.6616	 get_bound: 0.5039	 add_domain: 0.0010
Current lb:-0.00046825408935546875
125126 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 142.30041098594666

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 873] [1, 65] [1, 485] [1, 725] [1, 725] [2, 64] [1, 725] [2, 64] [2, 4] [1, 724] 
regular batch size: 2*1024, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -33.813331604003906 with beta sum per layer: [0.0, 222.89573669433594, 189.2957000732422]
alpha/beta optimization time: 0.01977229118347168
This batch time : update_bounds func: 0.4302	 prepare: 0.2057	 bound: 0.0201	 transfer: 0.0114	 finalize: 0.1877
Accumulated time: update_bounds func: 69.1240	 prepare: 13.0870	 bound: 38.3843	 transfer: 0.0114	 finalize: 13.5600
batch bounding time:  0.4319305419921875
Current worst splitting domains [lb, ub] (depth):
[-0.00009,   inf] (60), [-0.00009,   inf] (50), [-0.00009,   inf] (48), [-0.00009,   inf] (54), [-0.00009,   inf] (62), [-0.00009,   inf] (58), [-0.00009,   inf] (50), [-0.00009,   inf] (64), [-0.00009,   inf] (66), [-0.00009,   inf] (60), [-0.00009,   inf] (48), [-0.00009,   inf] (68), [-0.00009,   inf] (58), [-0.00009,   inf] (62), [-0.00009,   inf] (60), [-0.00009,   inf] (60), [-0.00009,   inf] (60), [-0.00009,   inf] (70), [-0.00009,   inf] (54), [-0.00009,   inf] (64), 
length of domains: 234
Total time: 1.2938	 pickout: 0.1885	 decision: 0.6691	 get_bound: 0.4352	 add_domain: 0.0010
Current lb:-9.465217590332031e-05
127174 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 143.6331889629364

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([234, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([234, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 917] [1, 873] [1, 873] [1, 873] [1, 763] [1, 725] [1, 757] [2, 64] [1, 485] [2, 4] 
regular batch size: 2*234, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -7.9136810302734375 with beta sum per layer: [0.0, 50.22648620605469, 37.25865173339844]
alpha/beta optimization time: 0.010382652282714844
This batch time : update_bounds func: 0.0917	 prepare: 0.0480	 bound: 0.0107	 transfer: 0.0046	 finalize: 0.0273
Accumulated time: update_bounds func: 69.2156	 prepare: 13.1351	 bound: 38.3950	 transfer: 0.0046	 finalize: 13.5873
batch bounding time:  0.09207677841186523
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.3039	 pickout: 0.0502	 decision: 0.1607	 get_bound: 0.0928	 add_domain: 0.0002
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 143.95708847045898

Image 66 label 5 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 144.05611038208008
66 1.0000000116860974e-07
Result: image 66 verification success (with branch and bound)!
Wall time: 144.08815670013428

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 1): [66]
verification failure idx (total 0): []
final verified acc: 100.0%[1]
verifier is called on 1 examples.
total verified: 1
mean time [cnt:1] (excluding attack success): 144.05611038208008
