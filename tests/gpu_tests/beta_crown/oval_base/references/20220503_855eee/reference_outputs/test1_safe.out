Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: specify-target
  complete_verifier: bab
  enable_incomplete_verification: false
  get_crown_verified_acc: false
model:
  path: cifar_base.pth
  name: cifar_model_base
data:
  start: 16
  end: 17
  num_outputs: 10
  mean: [0.485, 0.456, 0.406]
  std: [0.225, 0.225, 0.225]
  pkl_path: base_100.pkl
  dataset: CIFAR
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: null
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 1024
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 60
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: fsb
    candidates: 1
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Tue May  3 01:26:08 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(3, 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(8, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Flatten()
  (5): Linear(in_features=1024, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=10, bias=True)
)
No epsilon defined!
Files already downloaded and verified
Overwrite epsilon that saved in .pkl file, they should be after normalized!
Task length: 1
saving results to Verified_ret_[cifar_model_base]_start=16_end=17_iter=20_b=1024_timeout=60_branching=fsb-min-1_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 16 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 6, correct label 6, image norm 2303.065185546875, logits tensor([-0.7841, -1.4301,  0.8538,  0.5919,  1.3325,  0.4675,  3.0616, -0.1100,
        -2.1666, -1.8167], device='cuda:0', grad_fn=<SelectBackward>)
##### [0:16] Tested against 4 ######
Model prediction is: tensor([[-0.7841, -1.4301,  0.8538,  0.5919,  1.3325,  0.4675,  3.0616, -0.1100,
         -2.1666, -1.8167]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-1.0462]], device='cuda:0') None
best_l after optimization: 0.7765178084373474 with beta sum per layer: []
alpha/beta optimization time: 7.156727313995361
initial alpha-CROWN bounds: tensor([[-0.7765]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.7765, device='cuda:0', grad_fn=<MinBackward1>)
-0.7765178084373474
layer 0 size torch.Size([2048]) unstable 550
layer 1 size torch.Size([1024]) unstable 306
layer 2 size torch.Size([100]) unstable 42
-----------------
# of unstable neurons: 898
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 8, 16, 16]) pre split depth:  6
batch:  torch.Size([1, 8, 16, 16]) post split depth:  6
splitting decisions: 
split level 0: [2, 46] 
split level 1: [2, 15] 
split level 2: [2, 30] 
split level 3: [2, 41] 
split level 4: [2, 57] 
split level 5: [1, 99] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: 0.5916836261749268 with beta sum per layer: [0.0, 7.23657751083374, 65.22845458984375]
alpha/beta optimization time: 0.2532041072845459
This batch time : update_bounds func: 0.2642	 prepare: 0.0056	 bound: 0.2535	 transfer: 0.0010	 finalize: 0.0039
Accumulated time: update_bounds func: 0.2642	 prepare: 0.0056	 bound: 0.2535	 transfer: 0.0010	 finalize: 0.0039
batch bounding time:  0.2644078731536865
Current worst splitting domains [lb, ub] (depth):
[-0.45228,   inf] (7), [-0.36521,   inf] (7), [-0.36456,   inf] (7), [-0.31907,   inf] (7), [-0.31744,   inf] (7), [-0.29952,   inf] (7), [-0.28660,   inf] (7), [-0.24104,   inf] (7), [-0.22544,   inf] (7), [-0.22322,   inf] (7), [-0.21461,   inf] (7), [-0.21399,   inf] (7), [-0.17913,   inf] (7), [-0.17847,   inf] (7), [-0.15578,   inf] (7), [-0.15367,   inf] (7), [-0.15297,   inf] (7), [-0.13582,   inf] (7), [-0.12693,   inf] (7), [-0.09369,   inf] (7), 
length of domains: 28
Total time: 0.3448	 pickout: 0.0009	 decision: 0.0712	 get_bound: 0.2718	 add_domain: 0.0010
Current lb:-0.45228180289268494
64 neurons visited
0 diving domains visited
Global ub: tensor([[inf]], device='cuda:0'), batch ub: inf
Cumulative time: 9.246524572372437

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([28, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([28, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 283] [2, 55] [1, 283] [2, 55] [1, 283] [1, 283] [2, 55] [2, 55] [2, 55] [2, 55] 
regular batch size: 2*28, diving batch size 1*0
best_l after optimization: 2.363497257232666 with beta sum per layer: [0.0, 4.188543319702148, 43.37806701660156]
alpha/beta optimization time: 0.24757003784179688
This batch time : update_bounds func: 0.2589	 prepare: 0.0066	 bound: 0.2479	 transfer: 0.0010	 finalize: 0.0033
Accumulated time: update_bounds func: 0.5231	 prepare: 0.0122	 bound: 0.5013	 transfer: 0.0010	 finalize: 0.0072
batch bounding time:  0.2590329647064209
Current worst splitting domains [lb, ub] (depth):
[-0.42621,   inf] (9), [-0.37151,   inf] (9), [-0.33775,   inf] (9), [-0.33476,   inf] (9), [-0.31301,   inf] (9), [-0.27965,   inf] (9), [-0.27760,   inf] (9), [-0.25550,   inf] (9), [-0.25484,   inf] (9), [-0.22530,   inf] (9), [-0.21748,   inf] (9), [-0.19840,   inf] (9), [-0.18625,   inf] (9), [-0.18064,   inf] (9), [-0.17480,   inf] (9), [-0.16868,   inf] (9), [-0.15198,   inf] (9), [-0.13111,   inf] (9), [-0.12444,   inf] (9), [-0.12318,   inf] (9), 
length of domains: 32
Total time: 0.2945	 pickout: 0.0043	 decision: 0.0301	 get_bound: 0.2591	 add_domain: 0.0010
Current lb:-0.42621350288391113
120 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.541482210159302

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([32, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([32, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 55] [2, 55] [1, 283] [2, 55] [2, 55] [1, 283] [2, 55] [2, 55] [1, 283] [2, 55] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: 2.8267269134521484 with beta sum per layer: [0.0, 4.726762294769287, 43.30675506591797]
alpha/beta optimization time: 0.24644207954406738
This batch time : update_bounds func: 0.2588	 prepare: 0.0072	 bound: 0.2467	 transfer: 0.0010	 finalize: 0.0038
Accumulated time: update_bounds func: 0.7819	 prepare: 0.0193	 bound: 0.7481	 transfer: 0.0010	 finalize: 0.0110
batch bounding time:  0.259002685546875
Current worst splitting domains [lb, ub] (depth):
[-0.40090,   inf] (11), [-0.34383,   inf] (11), [-0.31053,   inf] (11), [-0.30690,   inf] (11), [-0.28533,   inf] (11), [-0.27608,   inf] (11), [-0.24833,   inf] (11), [-0.24605,   inf] (11), [-0.22607,   inf] (11), [-0.22573,   inf] (11), [-0.21412,   inf] (11), [-0.19376,   inf] (11), [-0.19199,   inf] (11), [-0.18778,   inf] (11), [-0.16866,   inf] (11), [-0.15431,   inf] (11), [-0.13666,   inf] (11), [-0.13518,   inf] (11), [-0.13411,   inf] (11), [-0.13190,   inf] (11), 
length of domains: 39
Total time: 0.2984	 pickout: 0.0048	 decision: 0.0331	 get_bound: 0.2592	 add_domain: 0.0013
Current lb:-0.40089765191078186
184 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.840439081192017

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([39, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([39, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 804] [1, 804] [1, 804] [1, 282] [1, 282] [1, 804] [1, 282] [1, 604] [1, 282] [1, 804] 
regular batch size: 2*39, diving batch size 1*0
best_l after optimization: 8.657215118408203 with beta sum per layer: [0.0, 6.719692707061768, 50.15924835205078]
alpha/beta optimization time: 0.24827790260314941
This batch time : update_bounds func: 0.2626	 prepare: 0.0083	 bound: 0.2486	 transfer: 0.0011	 finalize: 0.0045
Accumulated time: update_bounds func: 1.0446	 prepare: 0.0276	 bound: 0.9966	 transfer: 0.0011	 finalize: 0.0154
batch bounding time:  0.2627854347229004
Current worst splitting domains [lb, ub] (depth):
[-0.37982,   inf] (13), [-0.36918,   inf] (13), [-0.32057,   inf] (13), [-0.31267,   inf] (13), [-0.29127,   inf] (13), [-0.28989,   inf] (13), [-0.27719,   inf] (13), [-0.26362,   inf] (13), [-0.26104,   inf] (13), [-0.25611,   inf] (13), [-0.25179,   inf] (13), [-0.24186,   inf] (13), [-0.22536,   inf] (13), [-0.20680,   inf] (13), [-0.20595,   inf] (13), [-0.19596,   inf] (13), [-0.19395,   inf] (13), [-0.18938,   inf] (13), [-0.18854,   inf] (13), [-0.18388,   inf] (13), 
length of domains: 67
Total time: 0.3079	 pickout: 0.0057	 decision: 0.0370	 get_bound: 0.2629	 add_domain: 0.0023
Current lb:-0.3798200190067291
262 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.14878225326538

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([67, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([67, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 282] [1, 282] [1, 282] [1, 282] [1, 282] [2, 2] [1, 282] [2, 2] [2, 2] [1, 282] 
regular batch size: 2*67, diving batch size 1*0
best_l after optimization: 7.366708755493164 with beta sum per layer: [0.0, 11.543346405029297, 76.95501708984375]
alpha/beta optimization time: 0.2779512405395508
This batch time : update_bounds func: 0.3053	 prepare: 0.0137	 bound: 0.2783	 transfer: 0.0017	 finalize: 0.0113
Accumulated time: update_bounds func: 1.3498	 prepare: 0.0413	 bound: 1.2749	 transfer: 0.0017	 finalize: 0.0267
batch bounding time:  0.30550360679626465
Current worst splitting domains [lb, ub] (depth):
[-0.36205,   inf] (15), [-0.35143,   inf] (15), [-0.32909,   inf] (15), [-0.31847,   inf] (15), [-0.29496,   inf] (15), [-0.28950,   inf] (15), [-0.28726,   inf] (15), [-0.28115,   inf] (15), [-0.27340,   inf] (15), [-0.27184,   inf] (15), [-0.25770,   inf] (15), [-0.25458,   inf] (15), [-0.24598,   inf] (15), [-0.24461,   inf] (15), [-0.24145,   inf] (15), [-0.23431,   inf] (15), [-0.22972,   inf] (15), [-0.22891,   inf] (15), [-0.21585,   inf] (15), [-0.21479,   inf] (15), 
length of domains: 103
Total time: 0.3733	 pickout: 0.0091	 decision: 0.0547	 get_bound: 0.3057	 add_domain: 0.0037
Current lb:-0.3620482385158539
396 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.523159742355347

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([103, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([103, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 98] [1, 98] [1, 98] [1, 98] [1, 98] [1, 98] [1, 98] [1, 98] [2, 3] [1, 98] 
regular batch size: 2*103, diving batch size 1*0
best_l after optimization: -8.707847595214844 with beta sum per layer: [0.0, 17.89205551147461, 113.5783920288086]
alpha/beta optimization time: 0.2905995845794678
This batch time : update_bounds func: 0.3469	 prepare: 0.0303	 bound: 0.2910	 transfer: 0.0050	 finalize: 0.0201
Accumulated time: update_bounds func: 1.6967	 prepare: 0.0716	 bound: 1.5658	 transfer: 0.0050	 finalize: 0.0468
batch bounding time:  0.3473987579345703
Current worst splitting domains [lb, ub] (depth):
[-0.33920,   inf] (17), [-0.33729,   inf] (17), [-0.32858,   inf] (17), [-0.32673,   inf] (17), [-0.30899,   inf] (17), [-0.29839,   inf] (17), [-0.29691,   inf] (17), [-0.28633,   inf] (17), [-0.27205,   inf] (17), [-0.27142,   inf] (17), [-0.26546,   inf] (17), [-0.26414,   inf] (17), [-0.26390,   inf] (17), [-0.26368,   inf] (17), [-0.25727,   inf] (17), [-0.25552,   inf] (17), [-0.25224,   inf] (17), [-0.24542,   inf] (17), [-0.23911,   inf] (17), [-0.23270,   inf] (17), 
length of domains: 140
Total time: 0.4741	 pickout: 0.0193	 decision: 0.1011	 get_bound: 0.3478	 add_domain: 0.0059
Current lb:-0.3392000198364258
602 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.998990535736084

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([140, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([140, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 604] [1, 604] [1, 604] [1, 604] [2, 2] [1, 604] [2, 2] [1, 604] [2, 2] [2, 2] 
regular batch size: 2*140, diving batch size 1*0
best_l after optimization: -7.761898040771484 with beta sum per layer: [0.0, 25.733531951904297, 147.3665008544922]
alpha/beta optimization time: 0.29608798027038574
This batch time : update_bounds func: 0.3698	 prepare: 0.0406	 bound: 0.2965	 transfer: 0.0073	 finalize: 0.0245
Accumulated time: update_bounds func: 2.0665	 prepare: 0.1122	 bound: 1.8623	 transfer: 0.0073	 finalize: 0.0714
batch bounding time:  0.3701655864715576
Current worst splitting domains [lb, ub] (depth):
[-0.32317,   inf] (19), [-0.32110,   inf] (19), [-0.31099,   inf] (19), [-0.30957,   inf] (19), [-0.30895,   inf] (19), [-0.30881,   inf] (19), [-0.30410,   inf] (19), [-0.30258,   inf] (19), [-0.29205,   inf] (19), [-0.28027,   inf] (19), [-0.28021,   inf] (19), [-0.27344,   inf] (19), [-0.26861,   inf] (19), [-0.26274,   inf] (19), [-0.25390,   inf] (19), [-0.25377,   inf] (19), [-0.24798,   inf] (19), [-0.24656,   inf] (19), [-0.24375,   inf] (19), [-0.24346,   inf] (19), 
length of domains: 137
Total time: 0.5352	 pickout: 0.0285	 decision: 0.1302	 get_bound: 0.3706	 add_domain: 0.0059
Current lb:-0.32316941022872925
882 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.536455631256104

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([137, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([137, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 2] [2, 2] [2, 2] [2, 2] [2, 2] [2, 2] [1, 852] [1, 852] [2, 3] [2, 3] 
regular batch size: 2*137, diving batch size 1*0
best_l after optimization: -8.770532608032227 with beta sum per layer: [0.0, 25.373485565185547, 110.86763000488281]
alpha/beta optimization time: 0.29512524604797363
This batch time : update_bounds func: 0.3631	 prepare: 0.0396	 bound: 0.2955	 transfer: 0.0044	 finalize: 0.0231
Accumulated time: update_bounds func: 2.4296	 prepare: 0.1518	 bound: 2.1578	 transfer: 0.0044	 finalize: 0.0944
batch bounding time:  0.3634629249572754
Current worst splitting domains [lb, ub] (depth):
[-0.30708,   inf] (21), [-0.30509,   inf] (21), [-0.29523,   inf] (21), [-0.29329,   inf] (21), [-0.29300,   inf] (21), [-0.29224,   inf] (21), [-0.28897,   inf] (21), [-0.28760,   inf] (21), [-0.27604,   inf] (21), [-0.27441,   inf] (21), [-0.26383,   inf] (21), [-0.25714,   inf] (21), [-0.25233,   inf] (21), [-0.25122,   inf] (21), [-0.24627,   inf] (21), [-0.23948,   inf] (21), [-0.22627,   inf] (21), [-0.22612,   inf] (21), [-0.22548,   inf] (21), [-0.22524,   inf] (21), 
length of domains: 122
Total time: 0.5218	 pickout: 0.0257	 decision: 0.1273	 get_bound: 0.3639	 add_domain: 0.0049
Current lb:-0.30708038806915283
1156 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.060472965240479

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([122, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([122, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 3] [2, 3] [2, 3] [2, 3] [2, 3] [2, 3] [2, 2] [2, 2] [2, 2] [2, 2] 
regular batch size: 2*122, diving batch size 1*0
best_l after optimization: 2.427279472351074 with beta sum per layer: [0.0, 23.07703971862793, 104.40966796875]
alpha/beta optimization time: 0.29448604583740234
This batch time : update_bounds func: 0.3544	 prepare: 0.0357	 bound: 0.2949	 transfer: 0.0023	 finalize: 0.0209
Accumulated time: update_bounds func: 2.7840	 prepare: 0.1875	 bound: 2.4526	 transfer: 0.0023	 finalize: 0.1154
batch bounding time:  0.35475659370422363
Current worst splitting domains [lb, ub] (depth):
[-0.27316,   inf] (23), [-0.27164,   inf] (23), [-0.26600,   inf] (23), [-0.26349,   inf] (23), [-0.25980,   inf] (23), [-0.25835,   inf] (23), [-0.25373,   inf] (23), [-0.25183,   inf] (23), [-0.25119,   inf] (23), [-0.25060,   inf] (23), [-0.22752,   inf] (23), [-0.22241,   inf] (23), [-0.21593,   inf] (23), [-0.21547,   inf] (23), [-0.21055,   inf] (23), [-0.20431,   inf] (23), [-0.18902,   inf] (23), [-0.18884,   inf] (23), [-0.18569,   inf] (23), [-0.18540,   inf] (23), 
length of domains: 137
Total time: 0.5003	 pickout: 0.0227	 decision: 0.1169	 get_bound: 0.3552	 add_domain: 0.0056
Current lb:-0.27315521240234375
1400 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.562783002853394

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([137, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([137, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 3] [2, 3] [2, 61] [2, 61] [2, 3] [2, 3] [2, 61] [2, 61] [2, 61] [2, 61] 
regular batch size: 2*137, diving batch size 1*0
best_l after optimization: -4.198511600494385 with beta sum per layer: [0.0, 29.353191375732422, 91.77174377441406]
alpha/beta optimization time: 0.2959892749786377
This batch time : update_bounds func: 0.4138	 prepare: 0.0398	 bound: 0.2963	 transfer: 0.0029	 finalize: 0.0741
Accumulated time: update_bounds func: 3.1978	 prepare: 0.2273	 bound: 2.7490	 transfer: 0.0029	 finalize: 0.1895
batch bounding time:  0.41426587104797363
Current worst splitting domains [lb, ub] (depth):
[-0.24306,   inf] (25), [-0.24075,   inf] (25), [-0.23155,   inf] (25), [-0.23098,   inf] (25), [-0.22953,   inf] (25), [-0.22881,   inf] (25), [-0.22870,   inf] (25), [-0.22767,   inf] (25), [-0.21805,   inf] (25), [-0.21600,   inf] (25), [-0.20629,   inf] (25), [-0.19922,   inf] (25), [-0.19617,   inf] (25), [-0.19209,   inf] (25), [-0.18785,   inf] (25), [-0.18198,   inf] (25), [-0.16997,   inf] (25), [-0.16947,   inf] (25), [-0.16364,   inf] (25), [-0.16259,   inf] (25), 
length of domains: 118
Total time: 0.5727	 pickout: 0.0255	 decision: 0.1275	 get_bound: 0.4147	 add_domain: 0.0049
Current lb:-0.24306166172027588
1674 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.138228178024292

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([118, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([118, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 75] [2, 75] [2, 61] [2, 75] [2, 61] [2, 75] [2, 75] [2, 75] [2, 61] [2, 61] 
regular batch size: 2*118, diving batch size 1*0
best_l after optimization: -5.456357955932617 with beta sum per layer: [0.0, 24.492673873901367, 67.21543884277344]
alpha/beta optimization time: 0.29619717597961426
This batch time : update_bounds func: 0.3545	 prepare: 0.0347	 bound: 0.2966	 transfer: 0.0023	 finalize: 0.0201
Accumulated time: update_bounds func: 3.5523	 prepare: 0.2619	 bound: 3.0455	 transfer: 0.0023	 finalize: 0.2096
batch bounding time:  0.35481691360473633
Current worst splitting domains [lb, ub] (depth):
[-0.22317,   inf] (27), [-0.22125,   inf] (27), [-0.21100,   inf] (27), [-0.20906,   inf] (27), [-0.20903,   inf] (27), [-0.20881,   inf] (27), [-0.20843,   inf] (27), [-0.20711,   inf] (27), [-0.19585,   inf] (27), [-0.19428,   inf] (27), [-0.17816,   inf] (27), [-0.17755,   inf] (27), [-0.17116,   inf] (27), [-0.16766,   inf] (27), [-0.16717,   inf] (27), [-0.16175,   inf] (27), [-0.14203,   inf] (27), [-0.14149,   inf] (27), [-0.14138,   inf] (27), [-0.14090,   inf] (27), 
length of domains: 93
Total time: 0.4933	 pickout: 0.0227	 decision: 0.1114	 get_bound: 0.3552	 add_domain: 0.0041
Current lb:-0.22317466139793396
1910 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.633670568466187

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([93, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([93, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 98] [2, 98] [2, 98] [2, 98] [2, 98] [2, 75] [2, 98] [2, 75] [2, 75] [2, 75] 
regular batch size: 2*93, diving batch size 1*0
best_l after optimization: 1.3929693698883057 with beta sum per layer: [0.0, 19.31087303161621, 45.725067138671875]
alpha/beta optimization time: 0.2902677059173584
This batch time : update_bounds func: 0.3363	 prepare: 0.0277	 bound: 0.2906	 transfer: 0.0020	 finalize: 0.0155
Accumulated time: update_bounds func: 3.8886	 prepare: 0.2896	 bound: 3.3362	 transfer: 0.0020	 finalize: 0.2251
batch bounding time:  0.3365509510040283
Current worst splitting domains [lb, ub] (depth):
[-0.19440,   inf] (29), [-0.19231,   inf] (29), [-0.18891,   inf] (29), [-0.18753,   inf] (29), [-0.18190,   inf] (29), [-0.18007,   inf] (29), [-0.17985,   inf] (29), [-0.17916,   inf] (29), [-0.17611,   inf] (29), [-0.17459,   inf] (29), [-0.15392,   inf] (29), [-0.14923,   inf] (29), [-0.14349,   inf] (29), [-0.14222,   inf] (29), [-0.13836,   inf] (29), [-0.13255,   inf] (29), [-0.11796,   inf] (29), [-0.11746,   inf] (29), [-0.11258,   inf] (29), [-0.11226,   inf] (29), 
length of domains: 79
Total time: 0.4492	 pickout: 0.0177	 decision: 0.0908	 get_bound: 0.3368	 add_domain: 0.0038
Current lb:-0.19440412521362305
2096 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.084209442138672

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([79, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([79, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 34] [2, 34] [2, 98] [2, 98] [2, 34] [2, 34] [2, 34] [2, 34] [2, 98] [2, 98] 
regular batch size: 2*79, diving batch size 1*0
best_l after optimization: 1.9771912097930908 with beta sum per layer: [0.0, 16.196773529052734, 27.318517684936523]
alpha/beta optimization time: 0.29258084297180176
This batch time : update_bounds func: 0.3330	 prepare: 0.0238	 bound: 0.2929	 transfer: 0.0019	 finalize: 0.0139
Accumulated time: update_bounds func: 4.2216	 prepare: 0.3135	 bound: 3.6291	 transfer: 0.0019	 finalize: 0.2390
batch bounding time:  0.33325767517089844
Current worst splitting domains [lb, ub] (depth):
[-0.17078,   inf] (31), [-0.16888,   inf] (31), [-0.15959,   inf] (31), [-0.15794,   inf] (31), [-0.15790,   inf] (31), [-0.15640,   inf] (31), [-0.15601,   inf] (31), [-0.15577,   inf] (31), [-0.14652,   inf] (31), [-0.14485,   inf] (31), [-0.13771,   inf] (31), [-0.12725,   inf] (31), [-0.12490,   inf] (31), [-0.12411,   inf] (31), [-0.11772,   inf] (31), [-0.11520,   inf] (31), [-0.11458,   inf] (31), [-0.10866,   inf] (31), [-0.09866,   inf] (31), [-0.09838,   inf] (31), 
length of domains: 89
Total time: 0.4317	 pickout: 0.0151	 decision: 0.0791	 get_bound: 0.3335	 add_domain: 0.0040
Current lb:-0.170782670378685
2254 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.51723313331604

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([89, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([89, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 852] [1, 852] [2, 34] [2, 34] [1, 852] [1, 852] [1, 852] [1, 852] [2, 34] [2, 34] 
regular batch size: 2*89, diving batch size 1*0
best_l after optimization: 6.590184688568115 with beta sum per layer: [0.0, 18.01190185546875, 19.79784393310547]
alpha/beta optimization time: 0.2913813591003418
This batch time : update_bounds func: 0.3359	 prepare: 0.0264	 bound: 0.2917	 transfer: 0.0020	 finalize: 0.0153
Accumulated time: update_bounds func: 4.5575	 prepare: 0.3399	 bound: 3.9208	 transfer: 0.0020	 finalize: 0.2544
batch bounding time:  0.3361847400665283
Current worst splitting domains [lb, ub] (depth):
[-0.15557,   inf] (33), [-0.15367,   inf] (33), [-0.14265,   inf] (33), [-0.14240,   inf] (33), [-0.14123,   inf] (33), [-0.14083,   inf] (33), [-0.14052,   inf] (33), [-0.14048,   inf] (33), [-0.13581,   inf] (33), [-0.13415,   inf] (33), [-0.12951,   inf] (33), [-0.12942,   inf] (33), [-0.12887,   inf] (33), [-0.12762,   inf] (33), [-0.12239,   inf] (33), [-0.12230,   inf] (33), [-0.12092,   inf] (33), [-0.11188,   inf] (33), [-0.10960,   inf] (33), [-0.10915,   inf] (33), 
length of domains: 134
Total time: 0.4464	 pickout: 0.0169	 decision: 0.0869	 get_bound: 0.3365	 add_domain: 0.0061
Current lb:-0.1555676907300949
2432 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.964917421340942

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([134, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([134, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 70] [2, 70] [2, 70] [2, 70] [2, 70] [2, 70] [2, 70] [2, 70] [2, 70] [2, 70] 
regular batch size: 2*134, diving batch size 1*0
best_l after optimization: -5.628627300262451 with beta sum per layer: [0.0, 28.13213348388672, 13.172303199768066]
alpha/beta optimization time: 0.29404139518737793
This batch time : update_bounds func: 0.3589	 prepare: 0.0390	 bound: 0.2944	 transfer: 0.0025	 finalize: 0.0223
Accumulated time: update_bounds func: 4.9163	 prepare: 0.3789	 bound: 4.2152	 transfer: 0.0025	 finalize: 0.2767
batch bounding time:  0.3591806888580322
Current worst splitting domains [lb, ub] (depth):
[-0.14340,   inf] (35), [-0.14195,   inf] (35), [-0.13074,   inf] (35), [-0.13022,   inf] (35), [-0.12926,   inf] (35), [-0.12891,   inf] (35), [-0.12874,   inf] (35), [-0.12858,   inf] (35), [-0.12375,   inf] (35), [-0.12248,   inf] (35), [-0.11755,   inf] (35), [-0.11719,   inf] (35), [-0.11692,   inf] (35), [-0.11603,   inf] (35), [-0.11045,   inf] (35), [-0.10941,   inf] (35), [-0.10934,   inf] (35), [-0.09940,   inf] (35), [-0.09685,   inf] (35), [-0.09622,   inf] (35), 
length of domains: 122
Total time: 0.5156	 pickout: 0.0252	 decision: 0.1251	 get_bound: 0.3596	 add_domain: 0.0057
Current lb:-0.14339540898799896
2700 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.482503652572632

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([122, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([122, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 97] [2, 97] [2, 97] [2, 97] [2, 97] [2, 97] [2, 97] [2, 97] [2, 97] [2, 97] 
regular batch size: 2*122, diving batch size 1*0
best_l after optimization: 0.06749093532562256 with beta sum per layer: [0.0, 24.37506103515625, 26.097003936767578]
alpha/beta optimization time: 0.2928001880645752
This batch time : update_bounds func: 0.3515	 prepare: 0.0351	 bound: 0.2932	 transfer: 0.0024	 finalize: 0.0200
Accumulated time: update_bounds func: 5.2678	 prepare: 0.4140	 bound: 4.5084	 transfer: 0.0024	 finalize: 0.2966
batch bounding time:  0.3518209457397461
Current worst splitting domains [lb, ub] (depth):
[-0.12280,   inf] (37), [-0.12144,   inf] (37), [-0.11007,   inf] (37), [-0.10940,   inf] (37), [-0.10874,   inf] (37), [-0.10804,   inf] (37), [-0.10787,   inf] (37), [-0.10776,   inf] (37), [-0.10272,   inf] (37), [-0.10168,   inf] (37), [-0.09672,   inf] (37), [-0.09653,   inf] (37), [-0.09640,   inf] (37), [-0.09541,   inf] (37), [-0.08939,   inf] (37), [-0.08895,   inf] (37), [-0.08858,   inf] (37), [-0.07895,   inf] (37), [-0.07634,   inf] (37), [-0.07581,   inf] (37), 
length of domains: 104
Total time: 0.4952	 pickout: 0.0225	 decision: 0.1155	 get_bound: 0.3522	 add_domain: 0.0050
Current lb:-0.122798390686512
2944 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.979772329330444

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([104, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([104, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 91] [1, 91] [1, 91] [1, 91] [1, 91] [1, 91] [1, 91] [1, 91] [1, 91] [1, 91] 
regular batch size: 2*104, diving batch size 1*0
best_l after optimization: 4.684017181396484 with beta sum per layer: [0.0, 24.087703704833984, 9.530763626098633]
alpha/beta optimization time: 0.2986171245574951
This batch time : update_bounds func: 0.3524	 prepare: 0.0299	 bound: 0.2990	 transfer: 0.0046	 finalize: 0.0184
Accumulated time: update_bounds func: 5.6203	 prepare: 0.4439	 bound: 4.8074	 transfer: 0.0046	 finalize: 0.3150
batch bounding time:  0.35277223587036133
Current worst splitting domains [lb, ub] (depth):
[-0.11307,   inf] (39), [-0.11151,   inf] (39), [-0.10022,   inf] (39), [-0.10004,   inf] (39), [-0.09883,   inf] (39), [-0.09869,   inf] (39), [-0.09866,   inf] (39), [-0.09849,   inf] (39), [-0.09342,   inf] (39), [-0.09237,   inf] (39), [-0.08755,   inf] (39), [-0.08729,   inf] (39), [-0.08718,   inf] (39), [-0.08582,   inf] (39), [-0.08426,   inf] (39), [-0.08396,   inf] (39), [-0.08052,   inf] (39), [-0.07956,   inf] (39), [-0.07872,   inf] (39), [-0.07291,   inf] (39), 
length of domains: 146
Total time: 0.4798	 pickout: 0.0195	 decision: 0.0998	 get_bound: 0.3531	 add_domain: 0.0075
Current lb:-0.11307225376367569
3152 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.461384057998657

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([146, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([146, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 281] [1, 281] [1, 281] [1, 281] [1, 281] [1, 281] [1, 281] [1, 281] [1, 281] [1, 281] 
regular batch size: 2*146, diving batch size 1*0
best_l after optimization: 6.396818161010742 with beta sum per layer: [0.0, 36.823692321777344, 8.278592109680176]
alpha/beta optimization time: 0.295957088470459
This batch time : update_bounds func: 0.4148	 prepare: 0.0430	 bound: 0.2963	 transfer: 0.0054	 finalize: 0.0253
Accumulated time: update_bounds func: 6.0351	 prepare: 0.4869	 bound: 5.1037	 transfer: 0.0054	 finalize: 0.3403
batch bounding time:  0.4152390956878662
Current worst splitting domains [lb, ub] (depth):
[-0.10058,   inf] (41), [-0.10029,   inf] (41), [-0.09873,   inf] (41), [-0.09608,   inf] (41), [-0.08786,   inf] (41), [-0.08779,   inf] (41), [-0.08751,   inf] (41), [-0.08741,   inf] (41), [-0.08714,   inf] (41), [-0.08593,   inf] (41), [-0.08590,   inf] (41), [-0.08560,   inf] (41), [-0.08444,   inf] (41), [-0.08334,   inf] (41), [-0.08331,   inf] (41), [-0.08307,   inf] (41), [-0.08146,   inf] (41), [-0.08057,   inf] (41), [-0.07901,   inf] (41), [-0.07695,   inf] (41), 
length of domains: 218
Total time: 0.5901	 pickout: 0.0273	 decision: 0.1353	 get_bound: 0.4157	 add_domain: 0.0118
Current lb:-0.10057856142520905
3444 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.053473949432373

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([218, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([218, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 595] [1, 595] [1, 595] [1, 595] [1, 595] [1, 595] [1, 595] [1, 595] [1, 595] [1, 595] 
regular batch size: 2*218, diving batch size 1*0
best_l after optimization: 7.312669277191162 with beta sum per layer: [0.0, 63.98097610473633, 8.656261444091797]
alpha/beta optimization time: 0.3122894763946533
This batch time : update_bounds func: 0.4223	 prepare: 0.0625	 bound: 0.3127	 transfer: 0.0093	 finalize: 0.0368
Accumulated time: update_bounds func: 6.4574	 prepare: 0.5494	 bound: 5.4164	 transfer: 0.0093	 finalize: 0.3772
batch bounding time:  0.4229111671447754
Current worst splitting domains [lb, ub] (depth):
[-0.08980,   inf] (43), [-0.08946,   inf] (43), [-0.08789,   inf] (43), [-0.08523,   inf] (43), [-0.08402,   inf] (43), [-0.08372,   inf] (43), [-0.08215,   inf] (43), [-0.07945,   inf] (43), [-0.07705,   inf] (43), [-0.07703,   inf] (43), [-0.07674,   inf] (43), [-0.07659,   inf] (43), [-0.07637,   inf] (43), [-0.07511,   inf] (43), [-0.07505,   inf] (43), [-0.07480,   inf] (43), [-0.07356,   inf] (43), [-0.07245,   inf] (43), [-0.07238,   inf] (43), [-0.07205,   inf] (43), 
length of domains: 273
Total time: 0.6741	 pickout: 0.0395	 decision: 0.1959	 get_bound: 0.4236	 add_domain: 0.0150
Current lb:-0.08980201929807663
3880 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.73085069656372

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([273, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([273, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 805] [1, 805] [1, 805] [1, 805] [1, 805] [1, 805] [1, 805] [1, 805] [1, 805] [1, 805] 
regular batch size: 2*273, diving batch size 1*0
best_l after optimization: 10.512351989746094 with beta sum per layer: [0.0, 88.29627990722656, 4.548778533935547]
alpha/beta optimization time: 0.32364654541015625
This batch time : update_bounds func: 0.4578	 prepare: 0.0783	 bound: 0.3241	 transfer: 0.0087	 finalize: 0.0455
Accumulated time: update_bounds func: 6.9152	 prepare: 0.6277	 bound: 5.7404	 transfer: 0.0087	 finalize: 0.4227
batch bounding time:  0.458432674407959
Current worst splitting domains [lb, ub] (depth):
[-0.08004,   inf] (45), [-0.07969,   inf] (45), [-0.07812,   inf] (45), [-0.07525,   inf] (45), [-0.07423,   inf] (45), [-0.07386,   inf] (45), [-0.07358,   inf] (45), [-0.07323,   inf] (45), [-0.07232,   inf] (45), [-0.07166,   inf] (45), [-0.06944,   inf] (45), [-0.06874,   inf] (45), [-0.06815,   inf] (45), [-0.06775,   inf] (45), [-0.06771,   inf] (45), [-0.06749,   inf] (45), [-0.06740,   inf] (45), [-0.06703,   inf] (45), [-0.06666,   inf] (45), [-0.06615,   inf] (45), 
length of domains: 388
Total time: 0.7732	 pickout: 0.0496	 decision: 0.2430	 get_bound: 0.4593	 add_domain: 0.0213
Current lb:-0.08004094660282135
4426 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.508052349090576

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([388, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([388, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1004] [1, 1004] [1, 1004] [1, 1004] [1, 1004] [1, 1004] [1, 1004] [1, 1004] [1, 1004] [1, 1004] 
regular batch size: 2*388, diving batch size 1*0
best_l after optimization: 14.162406921386719 with beta sum per layer: [0.0, 116.198974609375, 2.1947598457336426]
alpha/beta optimization time: 0.35535717010498047
This batch time : update_bounds func: 0.5896	 prepare: 0.1116	 bound: 0.3557	 transfer: 0.0140	 finalize: 0.0656
Accumulated time: update_bounds func: 7.5049	 prepare: 0.7394	 bound: 6.0962	 transfer: 0.0140	 finalize: 0.4882
batch bounding time:  0.5904300212860107
Current worst splitting domains [lb, ub] (depth):
[-0.07047,   inf] (47), [-0.07008,   inf] (47), [-0.06854,   inf] (47), [-0.06714,   inf] (47), [-0.06675,   inf] (47), [-0.06581,   inf] (47), [-0.06522,   inf] (47), [-0.06443,   inf] (47), [-0.06408,   inf] (47), [-0.06290,   inf] (47), [-0.06259,   inf] (47), [-0.06255,   inf] (47), [-0.06253,   inf] (47), [-0.06110,   inf] (47), [-0.06098,   inf] (47), [-0.06090,   inf] (47), [-0.06076,   inf] (47), [-0.06057,   inf] (47), [-0.05998,   inf] (47), [-0.05947,   inf] (47), 
length of domains: 590
Total time: 1.0308	 pickout: 0.0703	 decision: 0.3361	 get_bound: 0.5917	 add_domain: 0.0327
Current lb:-0.07046632468700409
5202 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 19.54475712776184

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([590, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([590, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 9] [2, 9] [2, 9] [2, 9] [2, 9] [2, 9] [2, 9] [2, 9] [2, 9] [2, 9] 
regular batch size: 2*590, diving batch size 1*0
best_l after optimization: -10.399815559387207 with beta sum per layer: [0.0, 161.0940399169922, 22.425769805908203]
alpha/beta optimization time: 0.4349207878112793
This batch time : update_bounds func: 0.7602	 prepare: 0.1633	 bound: 0.4353	 transfer: 0.0179	 finalize: 0.1409
Accumulated time: update_bounds func: 8.2651	 prepare: 0.9027	 bound: 6.5315	 transfer: 0.0179	 finalize: 0.6292
batch bounding time:  0.7615864276885986
Current worst splitting domains [lb, ub] (depth):
[-0.06215,   inf] (49), [-0.06179,   inf] (49), [-0.06029,   inf] (49), [-0.05891,   inf] (49), [-0.05856,   inf] (49), [-0.05757,   inf] (49), [-0.05706,   inf] (49), [-0.05606,   inf] (49), [-0.05570,   inf] (49), [-0.05481,   inf] (49), [-0.05451,   inf] (49), [-0.05436,   inf] (49), [-0.05424,   inf] (49), [-0.05290,   inf] (49), [-0.05283,   inf] (49), [-0.05281,   inf] (49), [-0.05247,   inf] (49), [-0.05246,   inf] (49), [-0.05163,   inf] (49), [-0.05103,   inf] (49), 
length of domains: 474
Total time: 1.4069	 pickout: 0.1074	 decision: 0.5095	 get_bound: 0.7637	 add_domain: 0.0263
Current lb:-0.06214737892150879
6382 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 20.962053298950195

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([474, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([474, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 843] [1, 843] [1, 843] [1, 843] [1, 843] [1, 843] [1, 843] [1, 843] [1, 843] [1, 843] 
regular batch size: 2*474, diving batch size 1*0
best_l after optimization: 12.766490936279297 with beta sum per layer: [0.0, 103.53034210205078, 0.0]
alpha/beta optimization time: 0.38567090034484863
This batch time : update_bounds func: 0.6039	 prepare: 0.1321	 bound: 0.3861	 transfer: 0.0054	 finalize: 0.0782
Accumulated time: update_bounds func: 8.8689	 prepare: 1.0347	 bound: 6.9175	 transfer: 0.0054	 finalize: 0.7074
batch bounding time:  0.6047117710113525
Current worst splitting domains [lb, ub] (depth):
[-0.05657,   inf] (51), [-0.05619,   inf] (51), [-0.05471,   inf] (51), [-0.05342,   inf] (51), [-0.05303,   inf] (51), [-0.05191,   inf] (51), [-0.05154,   inf] (51), [-0.05069,   inf] (51), [-0.05032,   inf] (51), [-0.04934,   inf] (51), [-0.04903,   inf] (51), [-0.04876,   inf] (51), [-0.04862,   inf] (51), [-0.04798,   inf] (51), [-0.04759,   inf] (51), [-0.04753,   inf] (51), [-0.04750,   inf] (51), [-0.04734,   inf] (51), [-0.04718,   inf] (51), [-0.04715,   inf] (51), 
length of domains: 705
Total time: 1.1445	 pickout: 0.0872	 decision: 0.4106	 get_bound: 0.6061	 add_domain: 0.0405
Current lb:-0.05657200515270233
7330 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 22.113460779190063

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([705, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([705, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 84] [2, 84] [2, 84] [2, 84] [2, 84] [2, 84] [2, 84] [2, 84] [2, 84] [2, 84] 
regular batch size: 2*705, diving batch size 1*0
best_l after optimization: -2.934321641921997 with beta sum per layer: [0.0, 118.33781433105469, 178.0460205078125]
alpha/beta optimization time: 0.4852430820465088
This batch time : update_bounds func: 0.8161	 prepare: 0.1947	 bound: 0.4856	 transfer: 0.0161	 finalize: 0.1165
Accumulated time: update_bounds func: 9.6850	 prepare: 1.2295	 bound: 7.4032	 transfer: 0.0161	 finalize: 0.8239
batch bounding time:  0.8174018859863281
Current worst splitting domains [lb, ub] (depth):
[-0.05382,   inf] (53), [-0.05342,   inf] (53), [-0.05193,   inf] (53), [-0.05072,   inf] (53), [-0.05034,   inf] (53), [-0.04923,   inf] (53), [-0.04886,   inf] (53), [-0.04791,   inf] (53), [-0.04750,   inf] (53), [-0.04664,   inf] (53), [-0.04628,   inf] (53), [-0.04611,   inf] (53), [-0.04597,   inf] (53), [-0.04481,   inf] (53), [-0.04479,   inf] (53), [-0.04472,   inf] (53), [-0.04463,   inf] (53), [-0.04453,   inf] (53), [-0.04441,   inf] (53), [-0.04423,   inf] (53), 
length of domains: 645
Total time: 1.6292	 pickout: 0.1302	 decision: 0.6408	 get_bound: 0.8196	 add_domain: 0.0386
Current lb:-0.05381898209452629
8740 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 23.755505323410034

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([645, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([645, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 497] [1, 497] [1, 497] [1, 497] [1, 497] [1, 497] [1, 497] [1, 497] [1, 497] [1, 497] 
regular batch size: 2*645, diving batch size 1*0
best_l after optimization: 3.010126829147339 with beta sum per layer: [0.0, 135.07298278808594, 0.0]
alpha/beta optimization time: 0.45633792877197266
This batch time : update_bounds func: 0.7674	 prepare: 0.1810	 bound: 0.4568	 transfer: 0.0167	 finalize: 0.1096
Accumulated time: update_bounds func: 10.4524	 prepare: 1.4105	 bound: 7.8599	 transfer: 0.0167	 finalize: 0.9335
batch bounding time:  0.7686145305633545
Current worst splitting domains [lb, ub] (depth):
[-0.05204,   inf] (55), [-0.05169,   inf] (55), [-0.05020,   inf] (55), [-0.04906,   inf] (55), [-0.04868,   inf] (55), [-0.04749,   inf] (55), [-0.04720,   inf] (55), [-0.04610,   inf] (55), [-0.04578,   inf] (55), [-0.04497,   inf] (55), [-0.04454,   inf] (55), [-0.04448,   inf] (55), [-0.04417,   inf] (55), [-0.04309,   inf] (55), [-0.04308,   inf] (55), [-0.04306,   inf] (55), [-0.04288,   inf] (55), [-0.04271,   inf] (55), [-0.04249,   inf] (55), [-0.04215,   inf] (55), 
length of domains: 615
Total time: 1.5220	 pickout: 0.1189	 decision: 0.5941	 get_bound: 0.7707	 add_domain: 0.0383
Current lb:-0.05203859880566597
10030 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 25.289512872695923

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([615, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([615, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1002] [1, 1002] [1, 1002] [1, 1002] [1, 1002] [1, 1002] [1, 1002] [1, 1002] [1, 1002] [1, 1002] 
regular batch size: 2*615, diving batch size 1*0
best_l after optimization: 1.6982474327087402 with beta sum per layer: [0.0, 121.81564331054688, 0.0]
alpha/beta optimization time: 0.4435713291168213
This batch time : update_bounds func: 0.7808	 prepare: 0.1708	 bound: 0.4440	 transfer: 0.0100	 finalize: 0.1533
Accumulated time: update_bounds func: 11.2332	 prepare: 1.5813	 bound: 8.3039	 transfer: 0.0100	 finalize: 1.0867
batch bounding time:  0.7819340229034424
Current worst splitting domains [lb, ub] (depth):
[-0.04787,   inf] (57), [-0.04775,   inf] (57), [-0.04636,   inf] (57), [-0.04493,   inf] (57), [-0.04482,   inf] (57), [-0.04346,   inf] (57), [-0.04336,   inf] (57), [-0.04184,   inf] (57), [-0.04174,   inf] (57), [-0.04073,   inf] (57), [-0.04063,   inf] (57), [-0.04037,   inf] (57), [-0.04032,   inf] (57), [-0.03923,   inf] (57), [-0.03898,   inf] (57), [-0.03895,   inf] (57), [-0.03889,   inf] (57), [-0.03884,   inf] (57), [-0.03800,   inf] (57), [-0.03789,   inf] (57), 
length of domains: 550
Total time: 1.4592	 pickout: 0.1170	 decision: 0.5243	 get_bound: 0.7838	 add_domain: 0.0341
Current lb:-0.04787201061844826
11260 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 26.759623765945435

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([550, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([550, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 856] [1, 856] [1, 856] [1, 856] [1, 856] [1, 856] [1, 856] [1, 856] [1, 856] [1, 856] 
regular batch size: 2*550, diving batch size 1*0
best_l after optimization: 7.404458999633789 with beta sum per layer: [0.0, 79.06764221191406, 0.0]
alpha/beta optimization time: 0.4187126159667969
This batch time : update_bounds func: 0.6706	 prepare: 0.1520	 bound: 0.4191	 transfer: 0.0071	 finalize: 0.0900
Accumulated time: update_bounds func: 11.9038	 prepare: 1.7332	 bound: 8.7230	 transfer: 0.0071	 finalize: 1.1768
batch bounding time:  0.671619176864624
Current worst splitting domains [lb, ub] (depth):
[-0.03832,   inf] (59), [-0.03824,   inf] (59), [-0.03790,   inf] (59), [-0.03789,   inf] (59), [-0.03679,   inf] (59), [-0.03623,   inf] (59), [-0.03543,   inf] (59), [-0.03535,   inf] (59), [-0.03502,   inf] (59), [-0.03500,   inf] (59), [-0.03402,   inf] (59), [-0.03387,   inf] (59), [-0.03329,   inf] (59), [-0.03311,   inf] (59), [-0.03225,   inf] (59), [-0.03220,   inf] (59), [-0.03180,   inf] (59), [-0.03179,   inf] (59), [-0.03122,   inf] (59), [-0.03115,   inf] (59), 
length of domains: 715
Total time: 1.3408	 pickout: 0.1028	 decision: 0.4715	 get_bound: 0.6733	 add_domain: 0.0932
Current lb:-0.03831786662340164
12360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 28.109447717666626

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([715, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([715, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1005] [1, 1005] [1, 1005] [1, 1005] [1, 1005] [1, 1005] [1, 1005] [1, 1005] [1, 1005] [1, 1005] 
regular batch size: 2*715, diving batch size 1*0
best_l after optimization: -7.303458213806152 with beta sum per layer: [0.0, 85.30525970458984, 0.0]
alpha/beta optimization time: 0.4846782684326172
This batch time : update_bounds func: 0.8121	 prepare: 0.1968	 bound: 0.4851	 transfer: 0.0076	 finalize: 0.1194
Accumulated time: update_bounds func: 12.7160	 prepare: 1.9300	 bound: 9.2080	 transfer: 0.0076	 finalize: 1.2961
batch bounding time:  0.8134453296661377
Current worst splitting domains [lb, ub] (depth):
[-0.03672,   inf] (61), [-0.03664,   inf] (61), [-0.03520,   inf] (61), [-0.03492,   inf] (61), [-0.03492,   inf] (61), [-0.03348,   inf] (61), [-0.03316,   inf] (61), [-0.03310,   inf] (61), [-0.03229,   inf] (61), [-0.03170,   inf] (61), [-0.03138,   inf] (61), [-0.03137,   inf] (61), [-0.03068,   inf] (61), [-0.03063,   inf] (61), [-0.03049,   inf] (61), [-0.02985,   inf] (61), [-0.02908,   inf] (61), [-0.02901,   inf] (61), [-0.02888,   inf] (61), [-0.02887,   inf] (61), 
length of domains: 615
Total time: 1.6442	 pickout: 0.1325	 decision: 0.6078	 get_bound: 0.8157	 add_domain: 0.0882
Current lb:-0.036723144352436066
13790 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 29.766728401184082

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([615, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([615, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1011] [1, 1011] [1, 1011] [1, 1011] [1, 1011] [1, 1011] [1, 1011] [1, 1011] [1, 1011] [1, 1011] 
regular batch size: 2*615, diving batch size 1*0
best_l after optimization: -0.10680645704269409 with beta sum per layer: [0.0, 62.647865295410156, 0.0]
alpha/beta optimization time: 0.439683198928833
This batch time : update_bounds func: 0.7199	 prepare: 0.1697	 bound: 0.4400	 transfer: 0.0069	 finalize: 0.1004
Accumulated time: update_bounds func: 13.4359	 prepare: 2.0997	 bound: 9.6481	 transfer: 0.0069	 finalize: 1.3965
batch bounding time:  0.7209765911102295
Current worst splitting domains [lb, ub] (depth):
[-0.02579,   inf] (63), [-0.02571,   inf] (63), [-0.02526,   inf] (63), [-0.02519,   inf] (63), [-0.02422,   inf] (63), [-0.02370,   inf] (63), [-0.02369,   inf] (63), [-0.02364,   inf] (63), [-0.02318,   inf] (63), [-0.02317,   inf] (63), [-0.02245,   inf] (63), [-0.02238,   inf] (63), [-0.02212,   inf] (63), [-0.02155,   inf] (63), [-0.02140,   inf] (63), [-0.02132,   inf] (63), [-0.02125,   inf] (63), [-0.02089,   inf] (63), [-0.02073,   inf] (63), [-0.02039,   inf] (63), 
length of domains: 520
Total time: 1.3962	 pickout: 0.1149	 decision: 0.5244	 get_bound: 0.7228	 add_domain: 0.0340
Current lb:-0.02578866481781006
15020 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 31.17454719543457

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([520, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([520, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 876] [1, 876] [1, 876] [1, 876] [1, 876] [1, 876] [1, 876] [1, 876] [1, 876] [1, 876] 
regular batch size: 2*520, diving batch size 1*0
best_l after optimization: -2.8266584873199463 with beta sum per layer: [0.0, 40.65760040283203, 0.0]
alpha/beta optimization time: 0.4061431884765625
This batch time : update_bounds func: 0.6437	 prepare: 0.1434	 bound: 0.4065	 transfer: 0.0058	 finalize: 0.0856
Accumulated time: update_bounds func: 14.0796	 prepare: 2.2432	 bound: 10.0546	 transfer: 0.0058	 finalize: 1.4821
batch bounding time:  0.6446573734283447
Current worst splitting domains [lb, ub] (depth):
[-0.01563,   inf] (65), [-0.01557,   inf] (65), [-0.01549,   inf] (65), [-0.01543,   inf] (65), [-0.01493,   inf] (65), [-0.01483,   inf] (65), [-0.01467,   inf] (65), [-0.01460,   inf] (65), [-0.01457,   inf] (65), [-0.01455,   inf] (65), [-0.01408,   inf] (65), [-0.01396,   inf] (65), [-0.01361,   inf] (65), [-0.01356,   inf] (65), [-0.01345,   inf] (65), [-0.01341,   inf] (65), [-0.01332,   inf] (65), [-0.01309,   inf] (65), [-0.01304,   inf] (65), [-0.01297,   inf] (65), 
length of domains: 295
Total time: 1.2459	 pickout: 0.0967	 decision: 0.4835	 get_bound: 0.6463	 add_domain: 0.0194
Current lb:-0.01563330926001072
16060 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 32.43015909194946

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([295, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([295, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1012] [1, 1012] [1, 1012] [1, 1012] [1, 1012] [1, 1012] [1, 1012] [1, 1012] [1, 1012] [1, 1012] 
regular batch size: 2*295, diving batch size 1*0
best_l after optimization: -12.305685043334961 with beta sum per layer: [0.0, 16.520416259765625, 0.0]
alpha/beta optimization time: 0.3207974433898926
This batch time : update_bounds func: 0.4565	 prepare: 0.0819	 bound: 0.3212	 transfer: 0.0040	 finalize: 0.0483
Accumulated time: update_bounds func: 14.5361	 prepare: 2.3251	 bound: 10.3757	 transfer: 0.0040	 finalize: 1.5304
batch bounding time:  0.4571089744567871
Current worst splitting domains [lb, ub] (depth):
[-0.01420,   inf] (67), [-0.01415,   inf] (67), [-0.01411,   inf] (67), [-0.01406,   inf] (67), [-0.01357,   inf] (67), [-0.01352,   inf] (67), [-0.01344,   inf] (67), [-0.01344,   inf] (67), [-0.01285,   inf] (67), [-0.01278,   inf] (67), [-0.01265,   inf] (67), [-0.01254,   inf] (67), [-0.01212,   inf] (67), [-0.01212,   inf] (67), [-0.01206,   inf] (67), [-0.01206,   inf] (67), [-0.01194,   inf] (67), [-0.01193,   inf] (67), [-0.01149,   inf] (67), [-0.01145,   inf] (67), 
length of domains: 233
Total time: 0.7877	 pickout: 0.0551	 decision: 0.2591	 get_bound: 0.4580	 add_domain: 0.0154
Current lb:-0.014202531427145004
16650 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 33.224254846572876

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([233, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([233, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 947] [1, 947] [1, 947] [1, 947] [1, 947] [1, 947] [1, 947] [1, 947] [1, 947] [1, 947] 
regular batch size: 2*233, diving batch size 1*0
best_l after optimization: -1.7218017578125 with beta sum per layer: [0.0, 13.573529243469238, 0.0]
alpha/beta optimization time: 0.3113253116607666
This batch time : update_bounds func: 0.4541	 prepare: 0.0659	 bound: 0.3117	 transfer: 0.0033	 finalize: 0.0385
Accumulated time: update_bounds func: 14.9902	 prepare: 2.3909	 bound: 10.6874	 transfer: 0.0033	 finalize: 1.5689
batch bounding time:  0.45455169677734375
Current worst splitting domains [lb, ub] (depth):
[-0.01070,   inf] (69), [-0.01056,   inf] (69), [-0.01007,   inf] (69), [-0.00987,   inf] (69), [-0.00970,   inf] (69), [-0.00955,   inf] (69), [-0.00953,   inf] (69), [-0.00945,   inf] (69), [-0.00908,   inf] (69), [-0.00899,   inf] (69), [-0.00877,   inf] (69), [-0.00864,   inf] (69), [-0.00861,   inf] (69), [-0.00840,   inf] (69), [-0.00806,   inf] (69), [-0.00799,   inf] (69), [-0.00793,   inf] (69), [-0.00787,   inf] (69), [-0.00760,   inf] (69), [-0.00757,   inf] (69), 
length of domains: 112
Total time: 0.7125	 pickout: 0.0429	 decision: 0.2066	 get_bound: 0.4553	 add_domain: 0.0077
Current lb:-0.010696075856685638
17116 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 33.94085502624512

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([112, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([112, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 981] [1, 981] [1, 981] [1, 981] [1, 981] [1, 981] [1, 981] [1, 981] [1, 981] [1, 981] 
regular batch size: 2*112, diving batch size 1*0
best_l after optimization: -1.8116743564605713 with beta sum per layer: [0.0, 5.835463523864746, 0.0]
alpha/beta optimization time: 0.291079044342041
This batch time : update_bounds func: 0.3450	 prepare: 0.0322	 bound: 0.2914	 transfer: 0.0022	 finalize: 0.0186
Accumulated time: update_bounds func: 15.3351	 prepare: 2.4231	 bound: 10.9789	 transfer: 0.0022	 finalize: 1.5875
batch bounding time:  0.34531140327453613
Current worst splitting domains [lb, ub] (depth):
[-0.00804,   inf] (71), [-0.00793,   inf] (71), [-0.00742,   inf] (71), [-0.00724,   inf] (71), [-0.00695,   inf] (71), [-0.00685,   inf] (71), [-0.00682,   inf] (71), [-0.00673,   inf] (71), [-0.00639,   inf] (71), [-0.00632,   inf] (71), [-0.00606,   inf] (71), [-0.00597,   inf] (71), [-0.00589,   inf] (71), [-0.00576,   inf] (71), [-0.00534,   inf] (71), [-0.00533,   inf] (71), [-0.00525,   inf] (71), [-0.00516,   inf] (71), [-0.00487,   inf] (71), [-0.00482,   inf] (71), 
length of domains: 62
Total time: 0.4780	 pickout: 0.0213	 decision: 0.1067	 get_bound: 0.3457	 add_domain: 0.0044
Current lb:-0.00803995132446289
17340 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 34.42103838920593

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([62, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([62, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 507] [1, 507] [1, 507] [1, 507] [1, 507] [1, 507] [1, 507] [1, 507] [1, 507] [1, 507] 
regular batch size: 2*62, diving batch size 1*0
best_l after optimization: -1.152253270149231 with beta sum per layer: [0.0, 1.7014045715332031, 0.0]
alpha/beta optimization time: 0.27819347381591797
This batch time : update_bounds func: 0.3093	 prepare: 0.0187	 bound: 0.2785	 transfer: 0.0017	 finalize: 0.0100
Accumulated time: update_bounds func: 15.6444	 prepare: 2.4418	 bound: 11.2574	 transfer: 0.0017	 finalize: 1.5975
batch bounding time:  0.30948829650878906
Current worst splitting domains [lb, ub] (depth):
[-0.00754,   inf] (73), [-0.00735,   inf] (73), [-0.00687,   inf] (73), [-0.00668,   inf] (73), [-0.00632,   inf] (73), [-0.00630,   inf] (73), [-0.00619,   inf] (73), [-0.00617,   inf] (73), [-0.00587,   inf] (73), [-0.00570,   inf] (73), [-0.00543,   inf] (73), [-0.00540,   inf] (73), [-0.00539,   inf] (73), [-0.00519,   inf] (73), [-0.00480,   inf] (73), [-0.00469,   inf] (73), [-0.00467,   inf] (73), [-0.00466,   inf] (73), [-0.00428,   inf] (73), [-0.00423,   inf] (73), 
length of domains: 52
Total time: 0.3915	 pickout: 0.0121	 decision: 0.0657	 get_bound: 0.3097	 add_domain: 0.0041
Current lb:-0.007544279098510742
17464 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 34.81351065635681

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([52, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([52, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 788] [1, 788] [1, 788] [1, 788] [1, 788] [1, 788] [1, 788] [1, 788] [1, 788] [1, 788] 
regular batch size: 2*52, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -0.8564841747283936 with beta sum per layer: [0.0, 1.0385665893554688, 0.0]
alpha/beta optimization time: 0.010896444320678711
This batch time : update_bounds func: 0.0373	 prepare: 0.0160	 bound: 0.0112	 transfer: 0.0015	 finalize: 0.0083
Accumulated time: update_bounds func: 15.6817	 prepare: 2.4578	 bound: 11.2687	 transfer: 0.0015	 finalize: 1.6058
batch bounding time:  0.037410736083984375
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.1049	 pickout: 0.0102	 decision: 0.0571	 get_bound: 0.0376	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 34.91952300071716

Image 16 label 4 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 34.982266902923584
16 1.0000000116860974e-07
Result: image 16 verification success (with branch and bound)!
Wall time: 35.01369857788086

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 1): [16]
verification failure idx (total 0): []
final verified acc: 100.0%[1]
verifier is called on 1 examples.
total verified: 1
mean time [cnt:1] (excluding attack success): 34.982266902923584
