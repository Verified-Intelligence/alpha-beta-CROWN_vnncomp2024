Experiments at Fri Nov  5 00:06:01 2021 on huan-Naples-server
Namespace(batch_size=64, beta_warmup=True, branching_candidates=3, branching_method='kfsb', branching_reduceop='min', complete_verifier='bab', conv_mode='patches', crown=False, data='CIFAR_ERAN', decision_thresh=0, deterministic=False, device='cuda', double_fp=False, end=581, epsilon=None, incomplete=True, init_iteration=100, intermediate_refinement_layers=[-1], iteration=20, load='eran_models/cifar_conv_big_pgd.pth', loss_reduction_func='sum', lp_test=None, lr_alpha=0.01, lr_beta=0.05, lr_decay=0.98, lr_init_alpha=0.1, lr_intermediate_beta=0.05, max_refinement_domains=1000, max_subproblems_list=200000, mip_multi_proc=None, mip_perneuron_refine_timeout=15, mip_refine_timeout=0.8, mip_threads=1, mode='verified-acc', model='cifar_conv_big', no_beta=False, no_joint_opt=False, no_warm=False, norm=inf, opt_bias=False, opt_coeffs=False, opt_intermediate_beta=False, optimizer='adam', pgd_order='before', record_lb=False, refinement_batch_size=-1, seed=100, share_slopes=False, solve_slope=True, start=580, timeout=180.0)
Sequential(
  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (5): ReLU()
  (6): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (7): ReLU()
  (8): Flatten()
  (9): Linear(in_features=4096, out_features=512, bias=True)
  (10): ReLU()
  (11): Linear(in_features=512, out_features=512, bias=True)
  (12): ReLU()
  (13): Linear(in_features=512, out_features=10, bias=True)
)
complete verification for verified accuracy, set decision_thresh to be 0
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([1000, 3, 32, 32]) torch.Size([1000]) torch.Size([1000])
X range: tensor(2.7537) tensor(-2.4291) tensor(0.0238)
Note runnerup label is empty here!
############################
epsilon after preprocession: tensor([[[[0.0388]],

         [[0.0393]],

         [[0.0390]]]]), data_max = tensor([[[[2.5141]],

         [[2.5968]],

         [[2.7537]]]]), data_min = tensor([[[[-2.4291]],

         [[-2.4183]],

         [[-2.2214]]]])
saving results to Verified_ret_[cifar_conv_big]_start=580_end=581_iter=20_b=64_int-beta=False_timeout=180.0_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 580 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label  4  correct label  4 logits tensor([-1.7239, -4.4812,  1.2682, -0.2974,  1.5516, -0.5039,  1.0932, -0.1089,
        -4.0056, -3.7354], grad_fn=<SelectBackward>)
##### PGD attack: True label: 4, Tested against: all others ######
pgd prediction: tensor([-1.6520, -4.4908,  1.3080, -0.2771,  1.5157, -0.4828,  1.1429, -0.2054,
        -3.9458, -3.6456], device='cuda:0', grad_fn=<SqueezeBackward1>)
attack margin tensor([3.1677, 6.0064, 0.2077, 1.7928,    inf, 1.9984, 0.3727, 1.7211, 5.4615,
        5.1613], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[-1.7239, -4.4812,  1.2682, -0.2974,  1.5516, -0.5039,  1.0932, -0.1089,
         -4.0056, -3.7354]], device='cuda:0', grad_fn=<AddBackward0>)
alpha-CROWN optimizable variables initialized.

all verified at 5th iter
best_l after optimization: -19.98105239868164 with beta sum per layer: []
optimal alpha/beta time: 6.083106279373169
initial alpha-CROWN bounds: tensor([[2.2547, 4.5475, 0.0117, 1.5166, 1.6858, 0.0054, 1.1650, 4.6152, 4.1792]],
       device='cuda:0', grad_fn=<AsStridedBackward>) None
verified with init bound!
incomplete verified success!
[[580.           0.           0.           7.05706596   0.
   -1.        ]]
final verified acc: 100.0%[1]
Total verification count: 1 total verified: 1
mean time [total:1]: 7.057065963745117
mean time [cnt:1]: 7.057065963745117
