Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_conv_big_pgd.pth
  name: cifar_conv_big
data:
  start: 444
  end: 445
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR_ERAN
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.00784313725
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 64
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 180
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 100
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:24:19 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (5): ReLU()
  (6): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (7): ReLU()
  (8): Flatten()
  (9): Linear(in_features=4096, out_features=512, bias=True)
  (10): ReLU()
  (11): Linear(in_features=512, out_features=512, bias=True)
  (12): ReLU()
  (13): Linear(in_features=512, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([1000, 3, 32, 32]) torch.Size([1000]) torch.Size([1000])
X range: tensor(2.7537) tensor(-2.4291) tensor(0.0238)
Note runnerup label is empty here!
############################
epsilon after preprocessing: tensor([[[[0.0388]],

         [[0.0393]],

         [[0.0390]]]]), data_max = tensor([[[[2.5141]],

         [[2.5968]],

         [[2.7537]]]]), data_min = tensor([[[[-2.4291]],

         [[-2.4183]],

         [[-2.2214]]]])
Task length: 1
saving results to Verified_ret_[cifar_conv_big]_start=444_end=445_iter=20_b=64_timeout=180_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 444 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 5, correct label 5, image norm 3492.8427734375, logits tensor([-1.5999, -4.6551, -0.2110,  1.0945, -1.4232,  1.1716, -2.0229,  0.1817,
         0.2937, -2.7910], device='cuda:0', grad_fn=<SelectBackward>)
Model prediction is: tensor([[-1.5999, -4.6551, -0.2110,  1.0945, -1.4232,  1.1716, -2.0229,  0.1817,
          0.2937, -2.7910]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 1.8136,  4.4798,  0.9978, -0.1655,  2.0426,  2.6546,  0.5381, -0.2522,
          3.0249]], device='cuda:0') None
best_l after optimization: -15.871564865112305 with beta sum per layer: []
alpha/beta optimization time: 22.772881031036377
initial alpha-CROWN bounds: tensor([[ 1.9283,  4.5781,  1.0227, -0.1513,  2.0844,  2.6847,  0.5628,  0.0064,
          3.1555]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.1513, device='cuda:0', grad_fn=<MinBackward1>)
##### [0:444] Tested against 3 ######
Model prediction is: tensor([[-1.5999, -4.6551, -0.2110,  1.0945, -1.4232,  1.1716, -2.0229,  0.1817,
          0.2937, -2.7910]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /16 start_node /17
setting alpha for layer /16 start_node /19
setting alpha for layer /16 start_node /21
setting alpha for layer /16 start_node /31
setting alpha for layer /16 start_node /33
not setting layer /16 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 32, 32, 32]) != torch.Size([2, 9, 1, 32, 32, 32]))
setting alpha for layer /18 start_node /19
setting alpha for layer /18 start_node /21
setting alpha for layer /18 start_node /31
setting alpha for layer /18 start_node /33
not setting layer /18 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /20 start_node /21
setting alpha for layer /20 start_node /31
setting alpha for layer /20 start_node /33
not setting layer /20 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 64, 16, 16]) != torch.Size([2, 9, 1, 64, 16, 16]))
setting alpha for layer /22 start_node /31
setting alpha for layer /22 start_node /33
not setting layer /22 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 64, 8, 8]) != torch.Size([2, 9, 1, 64, 8, 8]))
setting alpha for layer /32 start_node /33
not setting layer /32 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 512]) != torch.Size([2, 9, 1, 512]))
not setting layer /34 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 512]) != torch.Size([2, 9, 1, 512]))
0 /15 torch.Size([1, 32, 32, 32])
1 /17 torch.Size([1, 32, 16, 16])
2 /19 torch.Size([1, 64, 16, 16])
3 /21 torch.Size([1, 64, 8, 8])
4 /31 torch.Size([1, 512])
5 /33 torch.Size([1, 512])
best_l after optimization: 0.15133057534694672 with beta sum per layer: []
alpha/beta optimization time: 3.693525552749634
alpha-CROWN with fixed intermediate bounds: tensor([[-0.1513]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.15133057534694672
layer 0 size torch.Size([32768]) unstable 2213
layer 1 size torch.Size([8192]) unstable 103
layer 2 size torch.Size([16384]) unstable 1098
layer 3 size torch.Size([4096]) unstable 64
layer 4 size torch.Size([512]) unstable 24
layer 5 size torch.Size([512]) unstable 48
-----------------
# of unstable neurons: 3550
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 32, 32]) pre split depth:  2
batch:  torch.Size([1, 32, 32, 32]) post split depth:  2
splitting decisions: 
split level 0: [5, 280] 
split level 1: [4, 105] 
regular batch size: 2*2, diving batch size 1*0
best_l after optimization: 0.4978150427341461 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.017682451754808426, 0.0]
alpha/beta optimization time: 0.44344305992126465
This batch time : update_bounds func: 0.4486	 prepare: 0.0026	 bound: 0.4439	 transfer: 0.0015	 finalize: 0.0006
Accumulated time: update_bounds func: 0.4486	 prepare: 0.0026	 bound: 0.4439	 transfer: 0.0015	 finalize: 0.0006
batch bounding time:  0.44881534576416016
Current worst splitting domains [lb, ub] (depth):
[-0.12914,   inf] (3), [-0.12469,   inf] (3), [-0.12400,   inf] (3), [-0.12000,   inf] (3), 
length of domains: 4
Total time: 0.4865	 pickout: 0.0037	 decision: 0.0327	 get_bound: 0.4497	 add_domain: 0.0003
Current lb:-0.12913541495800018
4 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.102388858795166

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([4, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 218] [5, 218] [5, 218] [5, 218] 
regular batch size: 2*4, diving batch size 1*0
best_l after optimization: 0.9304265975952148 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.04421604052186012, 0.06594499945640564]
alpha/beta optimization time: 0.4567587375640869
This batch time : update_bounds func: 0.4662	 prepare: 0.0033	 bound: 0.4572	 transfer: 0.0044	 finalize: 0.0013
Accumulated time: update_bounds func: 0.9148	 prepare: 0.0059	 bound: 0.9011	 transfer: 0.0044	 finalize: 0.0019
batch bounding time:  0.4664483070373535
Current worst splitting domains [lb, ub] (depth):
[-0.12214,   inf] (5), [-0.12026,   inf] (5), [-0.11808,   inf] (5), [-0.11664,   inf] (5), [-0.11519,   inf] (5), [-0.11473,   inf] (5), [-0.11290,   inf] (5), [-0.11049,   inf] (5), 
length of domains: 8
Total time: 0.5205	 pickout: 0.0175	 decision: 0.0360	 get_bound: 0.4665	 add_domain: 0.0005
Current lb:-0.12213633954524994
12 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.623143672943115

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 116] [5, 116] [5, 116] [4, 292] [4, 292] [5, 116] [5, 116] [4, 292] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 1.7163143157958984 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.25492429733276367, 0.3816416263580322]
alpha/beta optimization time: 0.45314550399780273
This batch time : update_bounds func: 0.4649	 prepare: 0.0047	 bound: 0.4536	 transfer: 0.0042	 finalize: 0.0023
Accumulated time: update_bounds func: 1.3798	 prepare: 0.0106	 bound: 1.3547	 transfer: 0.0042	 finalize: 0.0043
batch bounding time:  0.4651925563812256
Current worst splitting domains [lb, ub] (depth):
[-0.11549,   inf] (7), [-0.11400,   inf] (7), [-0.11145,   inf] (7), [-0.11141,   inf] (7), [-0.11013,   inf] (7), [-0.10870,   inf] (7), [-0.10865,   inf] (7), [-0.10726,   inf] (7), [-0.10677,   inf] (7), [-0.10650,   inf] (7), [-0.10632,   inf] (7), [-0.10501,   inf] (7), [-0.10416,   inf] (7), [-0.10049,   inf] (7), [-0.10021,   inf] (7), [-0.09976,   inf] (7), 
length of domains: 16
Total time: 0.5455	 pickout: 0.0364	 decision: 0.0430	 get_bound: 0.4652	 add_domain: 0.0009
Current lb:-0.11548968404531479
28 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.16901421546936

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([16, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([16, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 10] [4, 292] [4, 292] [5, 10] [5, 116] [5, 116] [5, 10] [5, 10] [4, 292] [4, 292] 
regular batch size: 2*16, diving batch size 1*0
best_l after optimization: 3.1526174545288086 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.8270443081855774, 1.4891390800476074]
alpha/beta optimization time: 0.48044323921203613
This batch time : update_bounds func: 0.5057	 prepare: 0.0070	 bound: 0.4809	 transfer: 0.0134	 finalize: 0.0043
Accumulated time: update_bounds func: 1.8855	 prepare: 0.0176	 bound: 1.8356	 transfer: 0.0134	 finalize: 0.0085
batch bounding time:  0.5059294700622559
Current worst splitting domains [lb, ub] (depth):
[-0.10951,   inf] (9), [-0.10867,   inf] (9), [-0.10790,   inf] (9), [-0.10544,   inf] (9), [-0.10521,   inf] (9), [-0.10475,   inf] (9), [-0.10405,   inf] (9), [-0.10371,   inf] (9), [-0.10265,   inf] (9), [-0.10257,   inf] (9), [-0.10171,   inf] (9), [-0.10128,   inf] (9), [-0.10113,   inf] (9), [-0.10064,   inf] (9), [-0.10022,   inf] (9), [-0.10006,   inf] (9), [-0.09960,   inf] (9), [-0.09867,   inf] (9), [-0.09820,   inf] (9), [-0.09745,   inf] (9), 
length of domains: 32
Total time: 0.5646	 pickout: 0.0119	 decision: 0.0449	 get_bound: 0.5060	 add_domain: 0.0018
Current lb:-0.10951366275548935
60 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.734115362167358

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([32, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([32, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 292] [4, 292] [5, 10] [5, 10] [4, 292] [4, 292] [5, 10] [5, 10] [5, 10] [4, 292] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: 5.809975624084473 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 2.428636074066162, 3.9173641204833984]
alpha/beta optimization time: 0.5690329074859619
This batch time : update_bounds func: 0.6108	 prepare: 0.0130	 bound: 0.5695	 transfer: 0.0206	 finalize: 0.0075
Accumulated time: update_bounds func: 2.4963	 prepare: 0.0307	 bound: 2.4051	 transfer: 0.0206	 finalize: 0.0161
batch bounding time:  0.6111059188842773
Current worst splitting domains [lb, ub] (depth):
[-0.10337,   inf] (11), [-0.10298,   inf] (11), [-0.10168,   inf] (11), [-0.10116,   inf] (11), [-0.09940,   inf] (11), [-0.09934,   inf] (11), [-0.09934,   inf] (11), [-0.09926,   inf] (11), [-0.09845,   inf] (11), [-0.09845,   inf] (11), [-0.09793,   inf] (11), [-0.09745,   inf] (11), [-0.09702,   inf] (11), [-0.09696,   inf] (11), [-0.09671,   inf] (11), [-0.09638,   inf] (11), [-0.09616,   inf] (11), [-0.09585,   inf] (11), [-0.09544,   inf] (11), [-0.09514,   inf] (11), 
length of domains: 64
Total time: 0.6996	 pickout: 0.0202	 decision: 0.0646	 get_bound: 0.6112	 add_domain: 0.0036
Current lb:-0.10336935520172119
124 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.434788465499878

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 325] [5, 466] [5, 325] [5, 325] [4, 328] [5, 325] [5, 325] [5, 325] [5, 325] [5, 466] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.498233795166016 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 5.414494514465332, 13.027990341186523]
alpha/beta optimization time: 0.7896316051483154
This batch time : update_bounds func: 0.8616	 prepare: 0.0212	 bound: 0.7901	 transfer: 0.0356	 finalize: 0.0143
Accumulated time: update_bounds func: 3.3579	 prepare: 0.0519	 bound: 3.1951	 transfer: 0.0356	 finalize: 0.0304
batch bounding time:  0.861931562423706
Current worst splitting domains [lb, ub] (depth):
[-0.09802,   inf] (13), [-0.09784,   inf] (13), [-0.09631,   inf] (13), [-0.09568,   inf] (13), [-0.09514,   inf] (13), [-0.09405,   inf] (13), [-0.09400,   inf] (13), [-0.09379,   inf] (13), [-0.09364,   inf] (13), [-0.09312,   inf] (13), [-0.09299,   inf] (13), [-0.09235,   inf] (13), [-0.09231,   inf] (13), [-0.09148,   inf] (13), [-0.09147,   inf] (13), [-0.09141,   inf] (13), [-0.09124,   inf] (13), [-0.09111,   inf] (13), [-0.09079,   inf] (13), [-0.09076,   inf] (13), 
length of domains: 128
Total time: 1.0155	 pickout: 0.0410	 decision: 0.1045	 get_bound: 0.8621	 add_domain: 0.0079
Current lb:-0.09802050143480301
252 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.452141046524048

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 328] [5, 325] [4, 328] [5, 466] [4, 328] [5, 466] [4, 328] [5, 325] [4, 328] [5, 325] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.373212814331055 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 4.767167091369629, 7.407205104827881]
alpha/beta optimization time: 0.7922718524932861
This batch time : update_bounds func: 0.8649	 prepare: 0.0215	 bound: 0.7927	 transfer: 0.0351	 finalize: 0.0153
Accumulated time: update_bounds func: 4.2228	 prepare: 0.0733	 bound: 3.9879	 transfer: 0.0351	 finalize: 0.0457
batch bounding time:  0.8654162883758545
Current worst splitting domains [lb, ub] (depth):
[-0.09274,   inf] (15), [-0.09256,   inf] (15), [-0.09131,   inf] (15), [-0.09061,   inf] (15), [-0.08982,   inf] (15), [-0.08890,   inf] (15), [-0.08845,   inf] (15), [-0.08845,   inf] (15), [-0.08834,   inf] (15), [-0.08814,   inf] (15), [-0.08807,   inf] (15), [-0.08794,   inf] (15), [-0.08789,   inf] (15), [-0.08743,   inf] (15), [-0.08721,   inf] (15), [-0.08675,   inf] (15), [-0.08640,   inf] (15), [-0.08632,   inf] (15), [-0.08629,   inf] (15), [-0.08624,   inf] (15), 
length of domains: 192
Total time: 1.0179	 pickout: 0.0471	 decision: 0.0974	 get_bound: 0.8656	 add_domain: 0.0077
Current lb:-0.09273672103881836
380 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.472062349319458

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 37] [5, 37] [5, 336] [5, 37] [5, 37] [5, 336] [5, 37] [5, 37] [5, 336] [5, 37] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.990862846374512 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 3.9134981632232666, 6.69426155090332]
alpha/beta optimization time: 0.7888891696929932
This batch time : update_bounds func: 0.8657	 prepare: 0.0214	 bound: 0.7893	 transfer: 0.0405	 finalize: 0.0141
Accumulated time: update_bounds func: 5.0885	 prepare: 0.0947	 bound: 4.7772	 transfer: 0.0405	 finalize: 0.0598
batch bounding time:  0.8660385608673096
Current worst splitting domains [lb, ub] (depth):
[-0.08783,   inf] (17), [-0.08738,   inf] (17), [-0.08698,   inf] (17), [-0.08659,   inf] (17), [-0.08589,   inf] (17), [-0.08573,   inf] (17), [-0.08459,   inf] (17), [-0.08415,   inf] (17), [-0.08414,   inf] (17), [-0.08389,   inf] (17), [-0.08365,   inf] (17), [-0.08351,   inf] (17), [-0.08349,   inf] (17), [-0.08322,   inf] (17), [-0.08309,   inf] (17), [-0.08300,   inf] (17), [-0.08268,   inf] (17), [-0.08265,   inf] (17), [-0.08255,   inf] (17), [-0.08234,   inf] (17), 
length of domains: 256
Total time: 1.0159	 pickout: 0.0470	 decision: 0.0939	 get_bound: 0.8663	 add_domain: 0.0088
Current lb:-0.08783376216888428
508 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.489814043045044

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 336] [5, 336] [5, 336] [5, 37] [5, 336] [5, 336] [5, 336] [5, 336] [5, 37] [5, 336] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.621407508850098 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 4.23146915435791, 7.890279293060303]
alpha/beta optimization time: 0.7823491096496582
This batch time : update_bounds func: 0.8593	 prepare: 0.0217	 bound: 0.7828	 transfer: 0.0397	 finalize: 0.0147
Accumulated time: update_bounds func: 5.9477	 prepare: 0.1164	 bound: 5.5600	 transfer: 0.0397	 finalize: 0.0745
batch bounding time:  0.8596103191375732
Current worst splitting domains [lb, ub] (depth):
[-0.08311,   inf] (19), [-0.08264,   inf] (19), [-0.08224,   inf] (19), [-0.08129,   inf] (19), [-0.08116,   inf] (19), [-0.08115,   inf] (19), [-0.08107,   inf] (19), [-0.08014,   inf] (15), [-0.08008,   inf] (13), [-0.08007,   inf] (17), [-0.08005,   inf] (15), [-0.08004,   inf] (15), [-0.08001,   inf] (17), [-0.07998,   inf] (17), [-0.07996,   inf] (15), [-0.07986,   inf] (15), [-0.07985,   inf] (17), [-0.07978,   inf] (15), [-0.07976,   inf] (19), [-0.07972,   inf] (15), 
length of domains: 320
Total time: 1.0146	 pickout: 0.0543	 decision: 0.0923	 get_bound: 0.8598	 add_domain: 0.0082
Current lb:-0.08311095833778381
636 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.506314039230347

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 328] [5, 466] [5, 466] [5, 466] [5, 466] [4, 420] [4, 328] [4, 328] [5, 466] [5, 37] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.214781761169434 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 4.949653148651123, 9.34743595123291]
alpha/beta optimization time: 0.8055274486541748
This batch time : update_bounds func: 0.8819	 prepare: 0.0213	 bound: 0.8060	 transfer: 0.0399	 finalize: 0.0144
Accumulated time: update_bounds func: 6.8297	 prepare: 0.1377	 bound: 6.3659	 transfer: 0.0399	 finalize: 0.0889
batch bounding time:  0.8822572231292725
Current worst splitting domains [lb, ub] (depth):
[-0.07832,   inf] (21), [-0.07830,   inf] (17), [-0.07830,   inf] (13), [-0.07829,   inf] (17), [-0.07827,   inf] (13), [-0.07827,   inf] (19), [-0.07826,   inf] (19), [-0.07824,   inf] (19), [-0.07817,   inf] (15), [-0.07816,   inf] (17), [-0.07814,   inf] (19), [-0.07814,   inf] (15), [-0.07812,   inf] (13), [-0.07811,   inf] (21), [-0.07810,   inf] (17), [-0.07803,   inf] (17), [-0.07798,   inf] (17), [-0.07796,   inf] (17), [-0.07794,   inf] (17), [-0.07791,   inf] (13), 
length of domains: 384
Total time: 1.0336	 pickout: 0.0491	 decision: 0.0930	 get_bound: 0.8825	 add_domain: 0.0091
Current lb:-0.07831859588623047
764 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.54169487953186

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 395] [5, 37] [5, 466] [5, 37] [5, 466] [5, 466] [5, 336] [4, 328] [5, 336] [5, 37] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 8.998668670654297 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 5.995038032531738, 9.88043212890625]
alpha/beta optimization time: 0.7944369316101074
This batch time : update_bounds func: 0.8713	 prepare: 0.0213	 bound: 0.7949	 transfer: 0.0397	 finalize: 0.0150
Accumulated time: update_bounds func: 7.7009	 prepare: 0.1590	 bound: 7.1608	 transfer: 0.0397	 finalize: 0.1039
batch bounding time:  0.8716416358947754
Current worst splitting domains [lb, ub] (depth):
[-0.07684,   inf] (17), [-0.07684,   inf] (21), [-0.07678,   inf] (19), [-0.07677,   inf] (19), [-0.07675,   inf] (17), [-0.07672,   inf] (17), [-0.07671,   inf] (15), [-0.07670,   inf] (15), [-0.07667,   inf] (17), [-0.07665,   inf] (19), [-0.07664,   inf] (17), [-0.07663,   inf] (21), [-0.07658,   inf] (19), [-0.07658,   inf] (17), [-0.07656,   inf] (15), [-0.07653,   inf] (19), [-0.07652,   inf] (17), [-0.07651,   inf] (19), [-0.07645,   inf] (19), [-0.07644,   inf] (19), 
length of domains: 448
Total time: 1.0779	 pickout: 0.1053	 decision: 0.0923	 get_bound: 0.8718	 add_domain: 0.0084
Current lb:-0.07684311270713806
892 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.621281385421753

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 37] [4, 491] [4, 328] [4, 420] [5, 37] [5, 466] [4, 328] [5, 325] [4, 420] [5, 336] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 8.80177116394043 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 6.321255683898926, 9.942384719848633]
alpha/beta optimization time: 0.7877774238586426
This batch time : update_bounds func: 0.8657	 prepare: 0.0220	 bound: 0.7883	 transfer: 0.0405	 finalize: 0.0145
Accumulated time: update_bounds func: 8.5666	 prepare: 0.1810	 bound: 7.9491	 transfer: 0.0405	 finalize: 0.1183
batch bounding time:  0.8660476207733154
Current worst splitting domains [lb, ub] (depth):
[-0.07558,   inf] (19), [-0.07557,   inf] (17), [-0.07557,   inf] (17), [-0.07554,   inf] (15), [-0.07554,   inf] (15), [-0.07551,   inf] (15), [-0.07551,   inf] (15), [-0.07550,   inf] (15), [-0.07545,   inf] (17), [-0.07542,   inf] (13), [-0.07536,   inf] (19), [-0.07536,   inf] (19), [-0.07535,   inf] (23), [-0.07531,   inf] (19), [-0.07531,   inf] (17), [-0.07531,   inf] (21), [-0.07527,   inf] (17), [-0.07522,   inf] (17), [-0.07521,   inf] (17), [-0.07520,   inf] (23), 
length of domains: 512
Total time: 1.0801	 pickout: 0.0450	 decision: 0.1595	 get_bound: 0.8663	 add_domain: 0.0094
Current lb:-0.07557889074087143
1020 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.703267574310303

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 420] [5, 37] [5, 336] [4, 328] [5, 37] [5, 336] [4, 328] [4, 420] [5, 37] [4, 328] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 8.674515724182129 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 6.001909255981445, 12.542613983154297]
alpha/beta optimization time: 0.7936692237854004
This batch time : update_bounds func: 0.8717	 prepare: 0.0217	 bound: 0.7941	 transfer: 0.0403	 finalize: 0.0152
Accumulated time: update_bounds func: 9.4383	 prepare: 0.2027	 bound: 8.7432	 transfer: 0.0403	 finalize: 0.1336
batch bounding time:  0.8720870018005371
Current worst splitting domains [lb, ub] (depth):
[-0.07436,   inf] (17), [-0.07433,   inf] (17), [-0.07432,   inf] (19), [-0.07431,   inf] (19), [-0.07424,   inf] (21), [-0.07421,   inf] (17), [-0.07421,   inf] (15), [-0.07420,   inf] (19), [-0.07419,   inf] (19), [-0.07417,   inf] (15), [-0.07417,   inf] (21), [-0.07416,   inf] (13), [-0.07415,   inf] (21), [-0.07412,   inf] (19), [-0.07402,   inf] (17), [-0.07400,   inf] (15), [-0.07399,   inf] (19), [-0.07396,   inf] (19), [-0.07395,   inf] (19), [-0.07393,   inf] (17), 
length of domains: 576
Total time: 1.0319	 pickout: 0.0440	 decision: 0.1069	 get_bound: 0.8723	 add_domain: 0.0087
Current lb:-0.07436352968215942
1148 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.736999988555908

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 37] [5, 37] [4, 420] [4, 328] [4, 491] [5, 466] [5, 336] [5, 336] [5, 466] [5, 37] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 8.431469917297363 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 7.327215194702148, 12.368658065795898]
alpha/beta optimization time: 0.7889881134033203
This batch time : update_bounds func: 0.8681	 prepare: 0.0216	 bound: 0.7894	 transfer: 0.0420	 finalize: 0.0147
Accumulated time: update_bounds func: 10.3064	 prepare: 0.2243	 bound: 9.5326	 transfer: 0.0420	 finalize: 0.1483
batch bounding time:  0.8684213161468506
Current worst splitting domains [lb, ub] (depth):
[-0.07318,   inf] (17), [-0.07317,   inf] (19), [-0.07316,   inf] (17), [-0.07312,   inf] (19), [-0.07311,   inf] (17), [-0.07310,   inf] (17), [-0.07308,   inf] (19), [-0.07306,   inf] (17), [-0.07304,   inf] (15), [-0.07303,   inf] (17), [-0.07301,   inf] (15), [-0.07301,   inf] (15), [-0.07299,   inf] (19), [-0.07299,   inf] (19), [-0.07296,   inf] (15), [-0.07296,   inf] (21), [-0.07295,   inf] (21), [-0.07289,   inf] (19), [-0.07286,   inf] (19), [-0.07285,   inf] (19), 
length of domains: 640
Total time: 1.0133	 pickout: 0.0419	 decision: 0.0932	 get_bound: 0.8686	 add_domain: 0.0096
Current lb:-0.07317806035280228
1276 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.752199411392212

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 420] [4, 420] [5, 37] [4, 328] [5, 37] [5, 37] [4, 328] [5, 37] [4, 491] [5, 37] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 8.359503746032715 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 6.784228324890137, 11.735027313232422]
alpha/beta optimization time: 0.7974865436553955
This batch time : update_bounds func: 0.8888	 prepare: 0.0217	 bound: 0.7980	 transfer: 0.0525	 finalize: 0.0163
Accumulated time: update_bounds func: 11.1952	 prepare: 0.2460	 bound: 10.3306	 transfer: 0.0525	 finalize: 0.1646
batch bounding time:  0.8892676830291748
Current worst splitting domains [lb, ub] (depth):
[-0.07235,   inf] (17), [-0.07235,   inf] (21), [-0.07232,   inf] (19), [-0.07230,   inf] (13), [-0.07229,   inf] (19), [-0.07229,   inf] (15), [-0.07226,   inf] (25), [-0.07225,   inf] (17), [-0.07225,   inf] (15), [-0.07225,   inf] (17), [-0.07225,   inf] (15), [-0.07223,   inf] (17), [-0.07222,   inf] (13), [-0.07219,   inf] (17), [-0.07219,   inf] (19), [-0.07219,   inf] (17), [-0.07217,   inf] (19), [-0.07213,   inf] (17), [-0.07213,   inf] (21), [-0.07212,   inf] (21), 
length of domains: 704
Total time: 1.1068	 pickout: 0.1145	 decision: 0.0937	 get_bound: 0.8895	 add_domain: 0.0092
Current lb:-0.07235461473464966
1404 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.861586332321167

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 336] [4, 420] [5, 336] [5, 466] [5, 37] [5, 336] [5, 383] [5, 37] [5, 37] [5, 37] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 8.06383228302002 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 9.367012023925781, 13.076210021972656]
alpha/beta optimization time: 0.7891712188720703
This batch time : update_bounds func: 0.8808	 prepare: 0.0218	 bound: 0.7896	 transfer: 0.0535	 finalize: 0.0155
Accumulated time: update_bounds func: 12.0760	 prepare: 0.2678	 bound: 11.1202	 transfer: 0.0535	 finalize: 0.1801
batch bounding time:  0.881272554397583
Current worst splitting domains [lb, ub] (depth):
[-0.07156,   inf] (17), [-0.07156,   inf] (19), [-0.07156,   inf] (17), [-0.07156,   inf] (19), [-0.07156,   inf] (19), [-0.07151,   inf] (17), [-0.07149,   inf] (15), [-0.07149,   inf] (19), [-0.07148,   inf] (19), [-0.07144,   inf] (21), [-0.07144,   inf] (23), [-0.07143,   inf] (17), [-0.07143,   inf] (21), [-0.07142,   inf] (23), [-0.07142,   inf] (23), [-0.07140,   inf] (17), [-0.07140,   inf] (17), [-0.07139,   inf] (21), [-0.07139,   inf] (21), [-0.07137,   inf] (17), 
length of domains: 768
Total time: 1.0850	 pickout: 0.0996	 decision: 0.0937	 get_bound: 0.8815	 add_domain: 0.0102
Current lb:-0.07156437635421753
1532 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.949220657348633

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 37] [4, 420] [5, 336] [4, 420] [4, 491] [4, 328] [4, 328] [5, 466] [4, 328] [4, 491] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 8.012371063232422 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 8.941329956054688, 12.681536674499512]
alpha/beta optimization time: 0.8096630573272705
This batch time : update_bounds func: 0.9024	 prepare: 0.0216	 bound: 0.8101	 transfer: 0.0545	 finalize: 0.0158
Accumulated time: update_bounds func: 12.9784	 prepare: 0.2894	 bound: 11.9303	 transfer: 0.0545	 finalize: 0.1959
batch bounding time:  0.90277099609375
Current worst splitting domains [lb, ub] (depth):
[-0.07090,   inf] (15), [-0.07089,   inf] (25), [-0.07083,   inf] (19), [-0.07078,   inf] (19), [-0.07076,   inf] (21), [-0.07075,   inf] (19), [-0.07075,   inf] (17), [-0.07075,   inf] (19), [-0.07072,   inf] (19), [-0.07067,   inf] (25), [-0.07067,   inf] (19), [-0.07066,   inf] (13), [-0.07065,   inf] (23), [-0.07064,   inf] (19), [-0.07060,   inf] (17), [-0.07059,   inf] (15), [-0.07058,   inf] (21), [-0.07058,   inf] (15), [-0.07057,   inf] (19), [-0.07057,   inf] (17), 
length of domains: 832
Total time: 1.0581	 pickout: 0.0539	 decision: 0.0919	 get_bound: 0.9030	 add_domain: 0.0093
Current lb:-0.07089772075414658
1660 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 20.00934934616089

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 328] [5, 383] [4, 328] [4, 328] [4, 491] [4, 491] [5, 336] [4, 491] [4, 491] [5, 320] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.957118034362793 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 8.672050476074219, 15.004995346069336]
alpha/beta optimization time: 0.818450927734375
This batch time : update_bounds func: 0.9058	 prepare: 0.0217	 bound: 0.8189	 transfer: 0.0495	 finalize: 0.0153
Accumulated time: update_bounds func: 13.8842	 prepare: 0.3110	 bound: 12.7492	 transfer: 0.0495	 finalize: 0.2112
batch bounding time:  0.9061729907989502
Current worst splitting domains [lb, ub] (depth):
[-0.07004,   inf] (19), [-0.07004,   inf] (19), [-0.07003,   inf] (27), [-0.07003,   inf] (17), [-0.07002,   inf] (19), [-0.07001,   inf] (15), [-0.07000,   inf] (19), [-0.06997,   inf] (13), [-0.06995,   inf] (17), [-0.06994,   inf] (21), [-0.06994,   inf] (19), [-0.06994,   inf] (19), [-0.06994,   inf] (17), [-0.06993,   inf] (17), [-0.06990,   inf] (15), [-0.06989,   inf] (21), [-0.06985,   inf] (19), [-0.06985,   inf] (15), [-0.06985,   inf] (21), [-0.06984,   inf] (21), 
length of domains: 896
Total time: 1.0798	 pickout: 0.0686	 decision: 0.0944	 get_bound: 0.9064	 add_domain: 0.0105
Current lb:-0.07004135847091675
1788 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 21.094131469726562

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 336] [5, 466] [5, 503] [5, 336] [5, 336] [5, 336] [5, 336] [4, 420] [4, 328] [4, 358] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.88303279876709 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 6.281429767608643, 14.936467170715332]
alpha/beta optimization time: 0.805084228515625
This batch time : update_bounds func: 0.9662	 prepare: 0.0217	 bound: 0.8055	 transfer: 0.0489	 finalize: 0.0897
Accumulated time: update_bounds func: 14.8504	 prepare: 0.3327	 bound: 13.5548	 transfer: 0.0489	 finalize: 0.3009
batch bounding time:  0.9666023254394531
Current worst splitting domains [lb, ub] (depth):
[-0.06942,   inf] (17), [-0.06941,   inf] (19), [-0.06941,   inf] (15), [-0.06940,   inf] (19), [-0.06934,   inf] (19), [-0.06934,   inf] (13), [-0.06933,   inf] (19), [-0.06929,   inf] (19), [-0.06929,   inf] (21), [-0.06928,   inf] (19), [-0.06927,   inf] (19), [-0.06925,   inf] (17), [-0.06925,   inf] (17), [-0.06925,   inf] (19), [-0.06923,   inf] (19), [-0.06922,   inf] (19), [-0.06922,   inf] (17), [-0.06920,   inf] (13), [-0.06920,   inf] (15), [-0.06920,   inf] (21), 
length of domains: 960
Total time: 1.1396	 pickout: 0.0696	 decision: 0.0939	 get_bound: 0.9668	 add_domain: 0.0092
Current lb:-0.0694216936826706
1916 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 22.235777854919434

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 491] [4, 491] [4, 328] [4, 420] [5, 336] [4, 420] [4, 420] [5, 466] [4, 420] [5, 336] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.848481178283691 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 7.934117317199707, 14.28775405883789]
alpha/beta optimization time: 0.8244109153747559
This batch time : update_bounds func: 0.9198	 prepare: 0.0220	 bound: 0.8249	 transfer: 0.0504	 finalize: 0.0212
Accumulated time: update_bounds func: 15.7702	 prepare: 0.3547	 bound: 14.3797	 transfer: 0.0504	 finalize: 0.3221
batch bounding time:  0.9202759265899658
Current worst splitting domains [lb, ub] (depth):
[-0.06881,   inf] (17), [-0.06880,   inf] (17), [-0.06880,   inf] (13), [-0.06879,   inf] (25), [-0.06877,   inf] (23), [-0.06877,   inf] (17), [-0.06874,   inf] (21), [-0.06873,   inf] (17), [-0.06872,   inf] (23), [-0.06871,   inf] (21), [-0.06867,   inf] (19), [-0.06866,   inf] (17), [-0.06866,   inf] (21), [-0.06864,   inf] (19), [-0.06861,   inf] (17), [-0.06861,   inf] (19), [-0.06861,   inf] (25), [-0.06859,   inf] (17), [-0.06859,   inf] (21), [-0.06858,   inf] (23), 
length of domains: 1024
Total time: 1.1127	 pickout: 0.0864	 decision: 0.0960	 get_bound: 0.9205	 add_domain: 0.0098
Current lb:-0.06880834698677063
2044 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 23.35081958770752

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 37] [5, 336] [5, 466] [4, 420] [4, 395] [5, 37] [4, 420] [5, 37] [5, 383] [5, 383] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.782509803771973 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 7.581899642944336, 13.429988861083984]
alpha/beta optimization time: 0.8277232646942139
This batch time : update_bounds func: 0.9099	 prepare: 0.0408	 bound: 0.8282	 transfer: 0.0253	 finalize: 0.0150
Accumulated time: update_bounds func: 16.6802	 prepare: 0.3955	 bound: 15.2079	 transfer: 0.0253	 finalize: 0.3371
batch bounding time:  0.9102928638458252
Current worst splitting domains [lb, ub] (depth):
[-0.06819,   inf] (29), [-0.06819,   inf] (21), [-0.06817,   inf] (17), [-0.06815,   inf] (17), [-0.06814,   inf] (19), [-0.06814,   inf] (23), [-0.06813,   inf] (19), [-0.06812,   inf] (21), [-0.06812,   inf] (17), [-0.06809,   inf] (17), [-0.06808,   inf] (17), [-0.06807,   inf] (15), [-0.06806,   inf] (21), [-0.06805,   inf] (25), [-0.06805,   inf] (21), [-0.06803,   inf] (19), [-0.06803,   inf] (23), [-0.06803,   inf] (21), [-0.06803,   inf] (15), [-0.06798,   inf] (21), 
length of domains: 1088
Total time: 1.1027	 pickout: 0.0684	 decision: 0.1144	 get_bound: 0.9105	 add_domain: 0.0094
Current lb:-0.06819095462560654
2172 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 24.455596923828125

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 420] [4, 491] [5, 37] [5, 37] [4, 328] [5, 383] [4, 420] [4, 420] [5, 336] [5, 37] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.409109592437744 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 11.426971435546875, 15.753052711486816]
alpha/beta optimization time: 0.7846169471740723
This batch time : update_bounds func: 0.8737	 prepare: 0.0215	 bound: 0.7850	 transfer: 0.0513	 finalize: 0.0148
Accumulated time: update_bounds func: 17.5538	 prepare: 0.4169	 bound: 15.9929	 transfer: 0.0513	 finalize: 0.3519
batch bounding time:  0.8740444183349609
Current worst splitting domains [lb, ub] (depth):
[-0.06766,   inf] (21), [-0.06765,   inf] (19), [-0.06765,   inf] (21), [-0.06763,   inf] (19), [-0.06762,   inf] (21), [-0.06761,   inf] (23), [-0.06761,   inf] (19), [-0.06760,   inf] (21), [-0.06759,   inf] (21), [-0.06758,   inf] (25), [-0.06758,   inf] (21), [-0.06757,   inf] (19), [-0.06756,   inf] (19), [-0.06756,   inf] (21), [-0.06755,   inf] (17), [-0.06753,   inf] (15), [-0.06753,   inf] (21), [-0.06751,   inf] (19), [-0.06750,   inf] (17), [-0.06750,   inf] (15), 
length of domains: 1152
Total time: 1.0361	 pickout: 0.0592	 decision: 0.0932	 get_bound: 0.8743	 add_domain: 0.0094
Current lb:-0.06766185164451599
2300 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 25.49372673034668

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 420] [5, 336] [4, 420] [5, 466] [5, 383] [5, 383] [5, 37] [4, 491] [4, 395] [4, 420] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.614559173583984 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 8.816579818725586, 14.959152221679688]
alpha/beta optimization time: 0.7932162284851074
This batch time : update_bounds func: 0.8827	 prepare: 0.0216	 bound: 0.7937	 transfer: 0.0518	 finalize: 0.0153
Accumulated time: update_bounds func: 18.4366	 prepare: 0.4385	 bound: 16.7866	 transfer: 0.0518	 finalize: 0.3672
batch bounding time:  0.8831207752227783
Current worst splitting domains [lb, ub] (depth):
[-0.06724,   inf] (29), [-0.06722,   inf] (19), [-0.06722,   inf] (17), [-0.06722,   inf] (21), [-0.06722,   inf] (19), [-0.06722,   inf] (21), [-0.06721,   inf] (21), [-0.06720,   inf] (27), [-0.06719,   inf] (21), [-0.06718,   inf] (19), [-0.06718,   inf] (19), [-0.06717,   inf] (19), [-0.06717,   inf] (17), [-0.06716,   inf] (19), [-0.06714,   inf] (19), [-0.06714,   inf] (19), [-0.06713,   inf] (19), [-0.06713,   inf] (21), [-0.06711,   inf] (27), [-0.06711,   inf] (19), 
length of domains: 1216
Total time: 1.0485	 pickout: 0.0614	 decision: 0.0944	 get_bound: 0.8833	 add_domain: 0.0093
Current lb:-0.06723932921886444
2428 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 26.54431390762329

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 358] [4, 420] [5, 37] [4, 491] [5, 336] [4, 491] [4, 491] [4, 491] [4, 491] [5, 37] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.267045974731445 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 13.23778247833252, 16.898582458496094]
alpha/beta optimization time: 0.80208420753479
This batch time : update_bounds func: 0.8915	 prepare: 0.0218	 bound: 0.8025	 transfer: 0.0508	 finalize: 0.0151
Accumulated time: update_bounds func: 19.3280	 prepare: 0.4603	 bound: 17.5891	 transfer: 0.0508	 finalize: 0.3823
batch bounding time:  0.8918397426605225
Current worst splitting domains [lb, ub] (depth):
[-0.06674,   inf] (21), [-0.06673,   inf] (15), [-0.06672,   inf] (23), [-0.06671,   inf] (21), [-0.06669,   inf] (19), [-0.06669,   inf] (21), [-0.06668,   inf] (23), [-0.06668,   inf] (17), [-0.06667,   inf] (27), [-0.06666,   inf] (21), [-0.06666,   inf] (23), [-0.06664,   inf] (19), [-0.06663,   inf] (19), [-0.06662,   inf] (19), [-0.06662,   inf] (23), [-0.06661,   inf] (21), [-0.06660,   inf] (19), [-0.06660,   inf] (17), [-0.06659,   inf] (17), [-0.06658,   inf] (15), 
length of domains: 1280
Total time: 1.0749	 pickout: 0.0806	 decision: 0.0926	 get_bound: 0.8921	 add_domain: 0.0096
Current lb:-0.06673888862133026
2556 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 27.6213960647583

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 420] [4, 491] [5, 383] [4, 420] [4, 420] [4, 420] [4, 420] [4, 328] [4, 358] [4, 491] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.303308010101318 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 10.855399131774902, 15.9124174118042]
alpha/beta optimization time: 0.799121618270874
This batch time : update_bounds func: 0.8925	 prepare: 0.0216	 bound: 0.7996	 transfer: 0.0488	 finalize: 0.0221
Accumulated time: update_bounds func: 20.2205	 prepare: 0.4819	 bound: 18.3887	 transfer: 0.0488	 finalize: 0.4044
batch bounding time:  0.8929159641265869
Current worst splitting domains [lb, ub] (depth):
[-0.06623,   inf] (21), [-0.06622,   inf] (17), [-0.06621,   inf] (23), [-0.06621,   inf] (19), [-0.06620,   inf] (27), [-0.06620,   inf] (23), [-0.06620,   inf] (27), [-0.06620,   inf] (23), [-0.06620,   inf] (19), [-0.06619,   inf] (21), [-0.06618,   inf] (23), [-0.06618,   inf] (19), [-0.06617,   inf] (19), [-0.06616,   inf] (17), [-0.06615,   inf] (25), [-0.06612,   inf] (27), [-0.06611,   inf] (19), [-0.06611,   inf] (25), [-0.06611,   inf] (25), [-0.06611,   inf] (15), 
length of domains: 1344
Total time: 1.0552	 pickout: 0.0568	 decision: 0.0951	 get_bound: 0.8932	 add_domain: 0.0101
Current lb:-0.06622543185949326
2684 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 28.6788489818573

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 491] [4, 491] [5, 383] [5, 37] [4, 395] [4, 420] [5, 383] [5, 383] [5, 466] [5, 466] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.41963005065918 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 9.484949111938477, 14.631266593933105]
alpha/beta optimization time: 0.8025650978088379
This batch time : update_bounds func: 0.9020	 prepare: 0.0329	 bound: 0.8031	 transfer: 0.0493	 finalize: 0.0156
Accumulated time: update_bounds func: 21.1226	 prepare: 0.5149	 bound: 19.1919	 transfer: 0.0493	 finalize: 0.4200
batch bounding time:  0.9024319648742676
Current worst splitting domains [lb, ub] (depth):
[-0.06587,   inf] (21), [-0.06586,   inf] (15), [-0.06582,   inf] (15), [-0.06582,   inf] (21), [-0.06582,   inf] (25), [-0.06582,   inf] (17), [-0.06581,   inf] (23), [-0.06580,   inf] (19), [-0.06579,   inf] (17), [-0.06579,   inf] (21), [-0.06578,   inf] (17), [-0.06578,   inf] (17), [-0.06577,   inf] (17), [-0.06576,   inf] (21), [-0.06575,   inf] (31), [-0.06571,   inf] (23), [-0.06571,   inf] (17), [-0.06571,   inf] (17), [-0.06570,   inf] (23), [-0.06570,   inf] (21), 
length of domains: 1408
Total time: 1.0714	 pickout: 0.0556	 decision: 0.1033	 get_bound: 0.9027	 add_domain: 0.0099
Current lb:-0.06587183475494385
2812 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 29.75270938873291

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 420] [5, 466] [5, 466] [5, 466] [5, 320] [4, 328] [4, 395] [4, 420] [4, 328] [4, 491] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.097009658813477 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 11.277764320373535, 19.490337371826172]
alpha/beta optimization time: 0.7874047756195068
This batch time : update_bounds func: 0.8778	 prepare: 0.0215	 bound: 0.7878	 transfer: 0.0521	 finalize: 0.0159
Accumulated time: update_bounds func: 22.0004	 prepare: 0.5364	 bound: 19.9797	 transfer: 0.0521	 finalize: 0.4358
batch bounding time:  0.8782367706298828
Current worst splitting domains [lb, ub] (depth):
[-0.06545,   inf] (19), [-0.06544,   inf] (15), [-0.06544,   inf] (17), [-0.06544,   inf] (21), [-0.06543,   inf] (23), [-0.06541,   inf] (23), [-0.06540,   inf] (23), [-0.06539,   inf] (25), [-0.06537,   inf] (15), [-0.06537,   inf] (21), [-0.06536,   inf] (21), [-0.06536,   inf] (17), [-0.06534,   inf] (21), [-0.06533,   inf] (23), [-0.06533,   inf] (21), [-0.06533,   inf] (25), [-0.06531,   inf] (29), [-0.06531,   inf] (23), [-0.06530,   inf] (17), [-0.06530,   inf] (21), 
length of domains: 1471
Total time: 1.1263	 pickout: 0.0710	 decision: 0.1674	 get_bound: 0.8785	 add_domain: 0.0095
Current lb:-0.0654454156756401
2940 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 30.881271839141846

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 420] [4, 420] [5, 37] [4, 491] [5, 383] [4, 491] [4, 420] [5, 320] [5, 336] [4, 420] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.235044956207275 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 10.23870849609375, 18.29326820373535]
alpha/beta optimization time: 0.8021068572998047
This batch time : update_bounds func: 0.8917	 prepare: 0.0219	 bound: 0.8026	 transfer: 0.0505	 finalize: 0.0163
Accumulated time: update_bounds func: 22.8921	 prepare: 0.5583	 bound: 20.7823	 transfer: 0.0505	 finalize: 0.4522
batch bounding time:  0.8921632766723633
Current worst splitting domains [lb, ub] (depth):
[-0.06501,   inf] (21), [-0.06500,   inf] (23), [-0.06499,   inf] (23), [-0.06499,   inf] (23), [-0.06498,   inf] (19), [-0.06497,   inf] (19), [-0.06496,   inf] (25), [-0.06496,   inf] (17), [-0.06496,   inf] (23), [-0.06496,   inf] (21), [-0.06496,   inf] (17), [-0.06496,   inf] (19), [-0.06495,   inf] (19), [-0.06494,   inf] (25), [-0.06494,   inf] (17), [-0.06494,   inf] (21), [-0.06494,   inf] (23), [-0.06494,   inf] (17), [-0.06492,   inf] (17), [-0.06490,   inf] (27), 
length of domains: 1535
Total time: 1.0486	 pickout: 0.0538	 decision: 0.0926	 get_bound: 0.8924	 add_domain: 0.0098
Current lb:-0.06500719487667084
3068 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 31.932227849960327

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 491] [5, 383] [4, 359] [4, 491] [5, 37] [5, 466] [4, 395] [5, 336] [4, 395] [4, 420] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.122006416320801 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 9.955486297607422, 17.614070892333984]
alpha/beta optimization time: 0.7909884452819824
This batch time : update_bounds func: 0.8661	 prepare: 0.0217	 bound: 0.7915	 transfer: 0.0359	 finalize: 0.0166
Accumulated time: update_bounds func: 23.7582	 prepare: 0.5800	 bound: 21.5737	 transfer: 0.0359	 finalize: 0.4688
batch bounding time:  0.8664941787719727
Current worst splitting domains [lb, ub] (depth):
[-0.06458,   inf] (23), [-0.06457,   inf] (21), [-0.06457,   inf] (25), [-0.06456,   inf] (27), [-0.06456,   inf] (21), [-0.06456,   inf] (23), [-0.06456,   inf] (25), [-0.06455,   inf] (21), [-0.06455,   inf] (21), [-0.06454,   inf] (23), [-0.06454,   inf] (21), [-0.06453,   inf] (17), [-0.06452,   inf] (29), [-0.06451,   inf] (31), [-0.06451,   inf] (21), [-0.06450,   inf] (19), [-0.06450,   inf] (21), [-0.06449,   inf] (23), [-0.06449,   inf] (17), [-0.06448,   inf] (21), 
length of domains: 1599
Total time: 1.0576	 pickout: 0.0854	 decision: 0.0950	 get_bound: 0.8667	 add_domain: 0.0104
Current lb:-0.06457549333572388
3196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 32.99255061149597

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 383] [4, 491] [4, 359] [5, 503] [4, 491] [4, 358] [4, 491] [4, 491] [4, 420] [4, 420] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.967048645019531 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 11.806782722473145, 17.31624984741211]
alpha/beta optimization time: 0.8075265884399414
This batch time : update_bounds func: 0.8585	 prepare: 0.0217	 bound: 0.8080	 transfer: 0.0127	 finalize: 0.0157
Accumulated time: update_bounds func: 24.6167	 prepare: 0.6017	 bound: 22.3817	 transfer: 0.0127	 finalize: 0.4844
batch bounding time:  0.8589060306549072
Current worst splitting domains [lb, ub] (depth):
[-0.06427,   inf] (25), [-0.06426,   inf] (23), [-0.06426,   inf] (21), [-0.06426,   inf] (23), [-0.06425,   inf] (19), [-0.06425,   inf] (19), [-0.06424,   inf] (21), [-0.06424,   inf] (21), [-0.06424,   inf] (19), [-0.06423,   inf] (21), [-0.06420,   inf] (25), [-0.06420,   inf] (17), [-0.06419,   inf] (19), [-0.06419,   inf] (29), [-0.06419,   inf] (21), [-0.06418,   inf] (19), [-0.06418,   inf] (19), [-0.06417,   inf] (19), [-0.06417,   inf] (17), [-0.06417,   inf] (23), 
length of domains: 1662
Total time: 1.0148	 pickout: 0.0524	 decision: 0.0932	 get_bound: 0.8591	 add_domain: 0.0100
Current lb:-0.06426841020584106
3324 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 34.00969982147217

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 491] [4, 491] [5, 336] [4, 491] [5, 37] [5, 336] [5, 336] [4, 395] [5, 466] [4, 491] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.898131370544434 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 13.248172760009766, 18.44293975830078]
alpha/beta optimization time: 0.8180267810821533
This batch time : update_bounds func: 0.8917	 prepare: 0.0221	 bound: 0.8185	 transfer: 0.0354	 finalize: 0.0153
Accumulated time: update_bounds func: 25.5084	 prepare: 0.6238	 bound: 23.2002	 transfer: 0.0354	 finalize: 0.4997
batch bounding time:  0.892113208770752
Current worst splitting domains [lb, ub] (depth):
[-0.06396,   inf] (23), [-0.06396,   inf] (23), [-0.06396,   inf] (19), [-0.06395,   inf] (23), [-0.06395,   inf] (17), [-0.06395,   inf] (19), [-0.06394,   inf] (19), [-0.06393,   inf] (23), [-0.06391,   inf] (21), [-0.06391,   inf] (23), [-0.06391,   inf] (23), [-0.06390,   inf] (13), [-0.06389,   inf] (25), [-0.06389,   inf] (25), [-0.06389,   inf] (19), [-0.06388,   inf] (17), [-0.06388,   inf] (17), [-0.06388,   inf] (19), [-0.06388,   inf] (13), [-0.06388,   inf] (19), 
length of domains: 1726
Total time: 1.0502	 pickout: 0.0491	 decision: 0.0989	 get_bound: 0.8923	 add_domain: 0.0098
Current lb:-0.06396391987800598
3452 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 35.06215262413025

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 383] [4, 491] [5, 336] [5, 383] [4, 491] [5, 336] [5, 37] [4, 358] [4, 491] [4, 491] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.783275604248047 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 12.515474319458008, 19.87636947631836]
alpha/beta optimization time: 0.8010866641998291
This batch time : update_bounds func: 0.8909	 prepare: 0.0219	 bound: 0.8015	 transfer: 0.0515	 finalize: 0.0156
Accumulated time: update_bounds func: 26.3993	 prepare: 0.6457	 bound: 24.0018	 transfer: 0.0515	 finalize: 0.5153
batch bounding time:  0.8912608623504639
Current worst splitting domains [lb, ub] (depth):
[-0.06364,   inf] (29), [-0.06364,   inf] (25), [-0.06363,   inf] (27), [-0.06363,   inf] (15), [-0.06362,   inf] (19), [-0.06361,   inf] (19), [-0.06360,   inf] (21), [-0.06360,   inf] (27), [-0.06359,   inf] (19), [-0.06359,   inf] (23), [-0.06357,   inf] (19), [-0.06357,   inf] (21), [-0.06357,   inf] (19), [-0.06356,   inf] (23), [-0.06356,   inf] (21), [-0.06355,   inf] (27), [-0.06355,   inf] (23), [-0.06354,   inf] (21), [-0.06352,   inf] (21), [-0.06352,   inf] (19), 
length of domains: 1788
Total time: 1.0524	 pickout: 0.0581	 decision: 0.0931	 get_bound: 0.8915	 add_domain: 0.0097
Current lb:-0.06363891065120697
3580 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 36.11667728424072

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 359] [4, 491] [4, 420] [5, 336] [4, 328] [5, 336] [4, 491] [5, 383] [5, 37] [4, 395] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.789773464202881 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 13.492528915405273, 19.071819305419922]
alpha/beta optimization time: 0.7804317474365234
This batch time : update_bounds func: 0.8695	 prepare: 0.0217	 bound: 0.7809	 transfer: 0.0513	 finalize: 0.0153
Accumulated time: update_bounds func: 27.2688	 prepare: 0.6673	 bound: 24.7826	 transfer: 0.0513	 finalize: 0.5305
batch bounding time:  0.8698551654815674
Current worst splitting domains [lb, ub] (depth):
[-0.06332,   inf] (19), [-0.06331,   inf] (25), [-0.06331,   inf] (21), [-0.06330,   inf] (17), [-0.06330,   inf] (23), [-0.06330,   inf] (21), [-0.06329,   inf] (19), [-0.06329,   inf] (21), [-0.06328,   inf] (21), [-0.06328,   inf] (19), [-0.06328,   inf] (15), [-0.06327,   inf] (19), [-0.06327,   inf] (27), [-0.06326,   inf] (25), [-0.06323,   inf] (21), [-0.06323,   inf] (23), [-0.06323,   inf] (19), [-0.06322,   inf] (17), [-0.06322,   inf] (21), [-0.06322,   inf] (17), 
length of domains: 1851
Total time: 1.0226	 pickout: 0.0482	 decision: 0.0943	 get_bound: 0.8701	 add_domain: 0.0100
Current lb:-0.06331759691238403
3708 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 37.14147996902466

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 336] [4, 491] [4, 359] [5, 37] [4, 359] [4, 420] [4, 420] [4, 420] [4, 359] [4, 328] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.981561660766602 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 10.299437522888184, 18.803112030029297]
alpha/beta optimization time: 0.7840297222137451
This batch time : update_bounds func: 0.9692	 prepare: 0.0222	 bound: 0.7845	 transfer: 0.0516	 finalize: 0.1105
Accumulated time: update_bounds func: 28.2379	 prepare: 0.6895	 bound: 25.5671	 transfer: 0.0516	 finalize: 0.6410
batch bounding time:  0.9696002006530762
Current worst splitting domains [lb, ub] (depth):
[-0.06296,   inf] (21), [-0.06296,   inf] (23), [-0.06296,   inf] (27), [-0.06295,   inf] (23), [-0.06294,   inf] (25), [-0.06294,   inf] (19), [-0.06294,   inf] (21), [-0.06294,   inf] (27), [-0.06293,   inf] (25), [-0.06292,   inf] (23), [-0.06292,   inf] (19), [-0.06292,   inf] (29), [-0.06291,   inf] (21), [-0.06291,   inf] (31), [-0.06290,   inf] (23), [-0.06290,   inf] (21), [-0.06290,   inf] (19), [-0.06290,   inf] (21), [-0.06289,   inf] (23), [-0.06289,   inf] (15), 
length of domains: 1914
Total time: 1.1323	 pickout: 0.0591	 decision: 0.0936	 get_bound: 0.9698	 add_domain: 0.0098
Current lb:-0.06296224892139435
3836 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 38.276686906814575

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 491] [4, 395] [4, 491] [4, 395] [5, 389] [5, 336] [4, 420] [4, 420] [4, 491] [5, 383] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.540755271911621 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 16.43507194519043, 20.7933349609375]
alpha/beta optimization time: 0.781749963760376
This batch time : update_bounds func: 0.8725	 prepare: 0.0219	 bound: 0.7822	 transfer: 0.0517	 finalize: 0.0163
Accumulated time: update_bounds func: 29.1105	 prepare: 0.7114	 bound: 26.3493	 transfer: 0.0517	 finalize: 0.6573
batch bounding time:  0.8729314804077148
Current worst splitting domains [lb, ub] (depth):
[-0.06271,   inf] (23), [-0.06270,   inf] (27), [-0.06270,   inf] (21), [-0.06270,   inf] (25), [-0.06269,   inf] (19), [-0.06269,   inf] (19), [-0.06268,   inf] (19), [-0.06268,   inf] (19), [-0.06268,   inf] (25), [-0.06267,   inf] (19), [-0.06266,   inf] (25), [-0.06266,   inf] (17), [-0.06265,   inf] (17), [-0.06265,   inf] (21), [-0.06264,   inf] (23), [-0.06264,   inf] (29), [-0.06264,   inf] (23), [-0.06264,   inf] (21), [-0.06264,   inf] (19), [-0.06263,   inf] (21), 
length of domains: 1978
Total time: 1.0289	 pickout: 0.0510	 decision: 0.0947	 get_bound: 0.8732	 add_domain: 0.0101
Current lb:-0.06271065026521683
3964 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 39.308027505874634

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 383] [5, 503] [4, 420] [4, 395] [4, 420] [5, 336] [5, 37] [4, 420] [4, 248] [5, 37] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.773045539855957 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 12.290513038635254, 19.00171661376953]
alpha/beta optimization time: 0.7889072895050049
This batch time : update_bounds func: 0.8803	 prepare: 0.0218	 bound: 0.7894	 transfer: 0.0522	 finalize: 0.0164
Accumulated time: update_bounds func: 29.9907	 prepare: 0.7332	 bound: 27.1387	 transfer: 0.0522	 finalize: 0.6737
batch bounding time:  0.880640983581543
Current worst splitting domains [lb, ub] (depth):
[-0.06240,   inf] (19), [-0.06240,   inf] (21), [-0.06240,   inf] (33), [-0.06240,   inf] (19), [-0.06240,   inf] (29), [-0.06239,   inf] (35), [-0.06238,   inf] (21), [-0.06238,   inf] (21), [-0.06237,   inf] (19), [-0.06236,   inf] (19), [-0.06236,   inf] (23), [-0.06236,   inf] (17), [-0.06236,   inf] (23), [-0.06236,   inf] (23), [-0.06235,   inf] (23), [-0.06235,   inf] (21), [-0.06234,   inf] (19), [-0.06233,   inf] (19), [-0.06233,   inf] (21), [-0.06233,   inf] (21), 
length of domains: 2042
Total time: 1.0453	 pickout: 0.0613	 decision: 0.0931	 get_bound: 0.8809	 add_domain: 0.0101
Current lb:-0.06240487098693848
4092 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 40.35559272766113

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 328] [4, 359] [5, 389] [4, 328] [5, 320] [5, 408] [4, 491] [5, 466] [4, 420] [5, 37] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.497076034545898 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 13.360712051391602, 22.37900161743164]
alpha/beta optimization time: 0.7824161052703857
This batch time : update_bounds func: 0.8685	 prepare: 0.0217	 bound: 0.7829	 transfer: 0.0482	 finalize: 0.0153
Accumulated time: update_bounds func: 30.8592	 prepare: 0.7549	 bound: 27.9215	 transfer: 0.0482	 finalize: 0.6890
batch bounding time:  0.868891716003418
Current worst splitting domains [lb, ub] (depth):
[-0.06214,   inf] (19), [-0.06214,   inf] (25), [-0.06214,   inf] (27), [-0.06214,   inf] (23), [-0.06213,   inf] (21), [-0.06213,   inf] (25), [-0.06212,   inf] (25), [-0.06212,   inf] (23), [-0.06212,   inf] (19), [-0.06212,   inf] (23), [-0.06211,   inf] (15), [-0.06210,   inf] (23), [-0.06210,   inf] (21), [-0.06209,   inf] (19), [-0.06209,   inf] (19), [-0.06209,   inf] (21), [-0.06208,   inf] (21), [-0.06207,   inf] (19), [-0.06207,   inf] (19), [-0.06207,   inf] (31), 
length of domains: 2105
Total time: 1.0254	 pickout: 0.0510	 decision: 0.0946	 get_bound: 0.8691	 add_domain: 0.0107
Current lb:-0.062144093215465546
4220 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 41.38339567184448

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 466] [5, 383] [5, 473] [4, 491] [4, 491] [5, 320] [4, 395] [4, 491] [5, 37] [4, 491] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.673116207122803 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 10.836671829223633, 20.19676971435547]
alpha/beta optimization time: 0.7890281677246094
This batch time : update_bounds func: 0.8796	 prepare: 0.0217	 bound: 0.7895	 transfer: 0.0519	 finalize: 0.0161
Accumulated time: update_bounds func: 31.7389	 prepare: 0.7767	 bound: 28.7110	 transfer: 0.0519	 finalize: 0.7052
batch bounding time:  0.880033016204834
Current worst splitting domains [lb, ub] (depth):
[-0.06181,   inf] (23), [-0.06181,   inf] (19), [-0.06181,   inf] (27), [-0.06181,   inf] (21), [-0.06180,   inf] (19), [-0.06179,   inf] (15), [-0.06179,   inf] (23), [-0.06179,   inf] (23), [-0.06179,   inf] (19), [-0.06179,   inf] (21), [-0.06178,   inf] (25), [-0.06177,   inf] (21), [-0.06177,   inf] (21), [-0.06177,   inf] (13), [-0.06176,   inf] (25), [-0.06176,   inf] (19), [-0.06176,   inf] (21), [-0.06175,   inf] (23), [-0.06175,   inf] (29), [-0.06175,   inf] (23), 
length of domains: 2168
Total time: 1.0372	 pickout: 0.0539	 decision: 0.0928	 get_bound: 0.8803	 add_domain: 0.0101
Current lb:-0.06181246042251587
4348 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 42.42279863357544

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 383] [5, 336] [5, 320] [4, 420] [5, 37] [4, 328] [5, 383] [4, 359] [5, 336] [4, 358] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.5937724113464355 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 13.634688377380371, 21.161832809448242]
alpha/beta optimization time: 0.7885429859161377
This batch time : update_bounds func: 0.8782	 prepare: 0.0220	 bound: 0.7890	 transfer: 0.0512	 finalize: 0.0157
Accumulated time: update_bounds func: 32.6171	 prepare: 0.7986	 bound: 29.5000	 transfer: 0.0512	 finalize: 0.7208
batch bounding time:  0.8786149024963379
Current worst splitting domains [lb, ub] (depth):
[-0.06157,   inf] (27), [-0.06157,   inf] (21), [-0.06157,   inf] (23), [-0.06157,   inf] (29), [-0.06157,   inf] (25), [-0.06156,   inf] (23), [-0.06156,   inf] (23), [-0.06156,   inf] (29), [-0.06155,   inf] (25), [-0.06155,   inf] (23), [-0.06155,   inf] (23), [-0.06154,   inf] (19), [-0.06153,   inf] (19), [-0.06153,   inf] (25), [-0.06153,   inf] (21), [-0.06152,   inf] (23), [-0.06151,   inf] (25), [-0.06151,   inf] (15), [-0.06151,   inf] (19), [-0.06150,   inf] (23), 
length of domains: 2231
Total time: 1.0360	 pickout: 0.0515	 decision: 0.0944	 get_bound: 0.8789	 add_domain: 0.0112
Current lb:-0.0615716278553009
4476 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 43.461252212524414

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 420] [4, 420] [4, 395] [5, 473] [5, 383] [4, 491] [4, 359] [4, 358] [4, 491] [4, 359] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.668151378631592 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 10.249471664428711, 18.754169464111328]
alpha/beta optimization time: 0.8173422813415527
This batch time : update_bounds func: 0.9086	 prepare: 0.0217	 bound: 0.8178	 transfer: 0.0526	 finalize: 0.0161
Accumulated time: update_bounds func: 33.5257	 prepare: 0.8203	 bound: 30.3178	 transfer: 0.0526	 finalize: 0.7369
batch bounding time:  0.9090375900268555
Current worst splitting domains [lb, ub] (depth):
[-0.06137,   inf] (21), [-0.06136,   inf] (21), [-0.06136,   inf] (25), [-0.06136,   inf] (19), [-0.06136,   inf] (27), [-0.06134,   inf] (19), [-0.06133,   inf] (25), [-0.06133,   inf] (17), [-0.06132,   inf] (33), [-0.06132,   inf] (25), [-0.06132,   inf] (23), [-0.06132,   inf] (21), [-0.06131,   inf] (21), [-0.06131,   inf] (21), [-0.06131,   inf] (21), [-0.06131,   inf] (23), [-0.06131,   inf] (27), [-0.06129,   inf] (23), [-0.06129,   inf] (19), [-0.06129,   inf] (27), 
length of domains: 2293
Total time: 1.0608	 pickout: 0.0476	 decision: 0.0937	 get_bound: 0.9093	 add_domain: 0.0103
Current lb:-0.061365701258182526
4604 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 44.52442383766174

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 358] [4, 491] [4, 395] [4, 420] [4, 420] [4, 420] [4, 491] [4, 328] [5, 389] [4, 395] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.2835187911987305 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 16.060129165649414, 20.209068298339844]
alpha/beta optimization time: 0.8105869293212891
This batch time : update_bounds func: 0.8976	 prepare: 0.0219	 bound: 0.8111	 transfer: 0.0486	 finalize: 0.0157
Accumulated time: update_bounds func: 34.4233	 prepare: 0.8423	 bound: 31.1289	 transfer: 0.0486	 finalize: 0.7526
batch bounding time:  0.8980352878570557
Current worst splitting domains [lb, ub] (depth):
[-0.06110,   inf] (25), [-0.06110,   inf] (21), [-0.06109,   inf] (23), [-0.06108,   inf] (29), [-0.06108,   inf] (17), [-0.06108,   inf] (19), [-0.06107,   inf] (19), [-0.06107,   inf] (25), [-0.06107,   inf] (23), [-0.06106,   inf] (23), [-0.06106,   inf] (17), [-0.06106,   inf] (25), [-0.06106,   inf] (21), [-0.06105,   inf] (21), [-0.06104,   inf] (25), [-0.06103,   inf] (21), [-0.06103,   inf] (23), [-0.06103,   inf] (21), [-0.06103,   inf] (23), [-0.06103,   inf] (23), 
length of domains: 2354
Total time: 1.1886	 pickout: 0.0629	 decision: 0.0977	 get_bound: 0.8983	 add_domain: 0.1297
Current lb:-0.061099737882614136
4732 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 45.71538782119751

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [4, 491] [5, 383] [5, 320] [5, 336] [4, 420] [5, 37] [5, 383] [4, 491] [4, 395] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.627403259277344 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 11.443778991699219, 18.867408752441406]
alpha/beta optimization time: 0.7914588451385498
This batch time : update_bounds func: 0.8751	 prepare: 0.0225	 bound: 0.7919	 transfer: 0.0443	 finalize: 0.0160
Accumulated time: update_bounds func: 35.2985	 prepare: 0.8647	 bound: 31.9208	 transfer: 0.0443	 finalize: 0.7686
batch bounding time:  0.8755199909210205
Current worst splitting domains [lb, ub] (depth):
[-0.06092,   inf] (21), [-0.06091,   inf] (17), [-0.06091,   inf] (23), [-0.06091,   inf] (21), [-0.06090,   inf] (27), [-0.06089,   inf] (19), [-0.06089,   inf] (21), [-0.06089,   inf] (31), [-0.06088,   inf] (19), [-0.06088,   inf] (25), [-0.06088,   inf] (23), [-0.06087,   inf] (21), [-0.06087,   inf] (21), [-0.06087,   inf] (29), [-0.06087,   inf] (19), [-0.06086,   inf] (21), [-0.06086,   inf] (23), [-0.06085,   inf] (27), [-0.06085,   inf] (31), [-0.06084,   inf] (23), 
length of domains: 2416
Total time: 1.0403	 pickout: 0.0612	 decision: 0.0933	 get_bound: 0.8757	 add_domain: 0.0100
Current lb:-0.06091982498764992
4860 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 46.75790309906006

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 466] [5, 336] [4, 491] [4, 491] [4, 358] [5, 37] [4, 491] [4, 358] [5, 336] [5, 383] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.368721961975098 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 15.41247844696045, 21.343454360961914]
alpha/beta optimization time: 0.7925636768341064
This batch time : update_bounds func: 0.8790	 prepare: 0.0218	 bound: 0.7930	 transfer: 0.0485	 finalize: 0.0153
Accumulated time: update_bounds func: 36.1775	 prepare: 0.8865	 bound: 32.7138	 transfer: 0.0485	 finalize: 0.7839
batch bounding time:  0.8794083595275879
Current worst splitting domains [lb, ub] (depth):
[-0.06069,   inf] (23), [-0.06069,   inf] (25), [-0.06069,   inf] (29), [-0.06068,   inf] (19), [-0.06068,   inf] (17), [-0.06068,   inf] (25), [-0.06067,   inf] (25), [-0.06067,   inf] (29), [-0.06067,   inf] (21), [-0.06067,   inf] (23), [-0.06066,   inf] (21), [-0.06065,   inf] (17), [-0.06065,   inf] (21), [-0.06065,   inf] (29), [-0.06065,   inf] (25), [-0.06065,   inf] (19), [-0.06064,   inf] (17), [-0.06064,   inf] (25), [-0.06064,   inf] (29), [-0.06064,   inf] (25), 
length of domains: 2479
Total time: 1.0344	 pickout: 0.0489	 decision: 0.0948	 get_bound: 0.8796	 add_domain: 0.0111
Current lb:-0.06069290637969971
4988 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 47.79461312294006

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 383] [4, 359] [4, 395] [5, 336] [5, 37] [4, 491] [4, 491] [4, 359] [5, 466] [5, 383] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.331096649169922 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 13.945003509521484, 20.120773315429688]
alpha/beta optimization time: 0.796811580657959
This batch time : update_bounds func: 0.8871	 prepare: 0.0217	 bound: 0.7973	 transfer: 0.0518	 finalize: 0.0159
Accumulated time: update_bounds func: 37.0646	 prepare: 0.9082	 bound: 33.5111	 transfer: 0.0518	 finalize: 0.7999
batch bounding time:  0.887479305267334
Current worst splitting domains [lb, ub] (depth):
[-0.06047,   inf] (27), [-0.06047,   inf] (21), [-0.06047,   inf] (23), [-0.06047,   inf] (19), [-0.06047,   inf] (27), [-0.06046,   inf] (21), [-0.06045,   inf] (29), [-0.06045,   inf] (25), [-0.06044,   inf] (23), [-0.06043,   inf] (23), [-0.06043,   inf] (27), [-0.06042,   inf] (25), [-0.06042,   inf] (29), [-0.06041,   inf] (23), [-0.06041,   inf] (21), [-0.06041,   inf] (19), [-0.06040,   inf] (27), [-0.06040,   inf] (21), [-0.06040,   inf] (21), [-0.06039,   inf] (19), 
length of domains: 2540
Total time: 1.0423	 pickout: 0.0515	 decision: 0.0930	 get_bound: 0.8877	 add_domain: 0.0101
Current lb:-0.060470521450042725
5116 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 48.839406967163086

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 420] [4, 420] [4, 491] [5, 336] [4, 395] [4, 420] [4, 358] [4, 395] [4, 491] [4, 395] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.446693420410156 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 12.356237411499023, 21.53352928161621]
alpha/beta optimization time: 0.8000106811523438
This batch time : update_bounds func: 0.8863	 prepare: 0.0218	 bound: 0.8004	 transfer: 0.0484	 finalize: 0.0152
Accumulated time: update_bounds func: 37.9509	 prepare: 0.9300	 bound: 34.3115	 transfer: 0.0484	 finalize: 0.8150
batch bounding time:  0.8866660594940186
Current worst splitting domains [lb, ub] (depth):
[-0.06020,   inf] (19), [-0.06020,   inf] (23), [-0.06020,   inf] (27), [-0.06019,   inf] (19), [-0.06018,   inf] (27), [-0.06018,   inf] (19), [-0.06017,   inf] (25), [-0.06017,   inf] (27), [-0.06017,   inf] (31), [-0.06016,   inf] (19), [-0.06016,   inf] (25), [-0.06016,   inf] (21), [-0.06016,   inf] (27), [-0.06015,   inf] (27), [-0.06015,   inf] (21), [-0.06013,   inf] (25), [-0.06013,   inf] (23), [-0.06013,   inf] (19), [-0.06013,   inf] (19), [-0.06013,   inf] (17), 
length of domains: 2602
Total time: 1.0527	 pickout: 0.0491	 decision: 0.1060	 get_bound: 0.8869	 add_domain: 0.0108
Current lb:-0.06020092964172363
5244 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 49.89449191093445

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 37] [4, 359] [5, 320] [5, 37] [4, 358] [4, 328] [4, 395] [5, 320] [4, 359] [5, 336] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.416172027587891 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 13.222647666931152, 22.835205078125]
alpha/beta optimization time: 0.7959256172180176
This batch time : update_bounds func: 0.8870	 prepare: 0.0217	 bound: 0.7964	 transfer: 0.0516	 finalize: 0.0170
Accumulated time: update_bounds func: 38.8379	 prepare: 0.9517	 bound: 35.1079	 transfer: 0.0516	 finalize: 0.8320
batch bounding time:  0.8874411582946777
Current worst splitting domains [lb, ub] (depth):
[-0.05995,   inf] (23), [-0.05995,   inf] (25), [-0.05995,   inf] (25), [-0.05995,   inf] (29), [-0.05995,   inf] (33), [-0.05995,   inf] (21), [-0.05994,   inf] (21), [-0.05994,   inf] (23), [-0.05993,   inf] (25), [-0.05992,   inf] (23), [-0.05992,   inf] (27), [-0.05992,   inf] (21), [-0.05991,   inf] (19), [-0.05991,   inf] (21), [-0.05991,   inf] (19), [-0.05991,   inf] (19), [-0.05990,   inf] (21), [-0.05990,   inf] (21), [-0.05989,   inf] (21), [-0.05989,   inf] (23), 
length of domains: 2666
Total time: 1.0528	 pickout: 0.0617	 decision: 0.0932	 get_bound: 0.8877	 add_domain: 0.0102
Current lb:-0.0599500946700573
5372 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 50.949462890625

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 383] [5, 383] [5, 383] [5, 320] [4, 358] [4, 491] [4, 491] [4, 420] [5, 383] [4, 491] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.4153242111206055 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 14.473793029785156, 19.000816345214844]
alpha/beta optimization time: 0.7931094169616699
This batch time : update_bounds func: 0.8866	 prepare: 0.0220	 bound: 0.7936	 transfer: 0.0489	 finalize: 0.0217
Accumulated time: update_bounds func: 39.7245	 prepare: 0.9737	 bound: 35.9015	 transfer: 0.0489	 finalize: 0.8537
batch bounding time:  0.8869986534118652
Current worst splitting domains [lb, ub] (depth):
[-0.05974,   inf] (21), [-0.05974,   inf] (21), [-0.05974,   inf] (27), [-0.05973,   inf] (21), [-0.05972,   inf] (27), [-0.05972,   inf] (19), [-0.05972,   inf] (21), [-0.05971,   inf] (19), [-0.05971,   inf] (21), [-0.05971,   inf] (21), [-0.05970,   inf] (17), [-0.05970,   inf] (25), [-0.05970,   inf] (21), [-0.05970,   inf] (29), [-0.05970,   inf] (31), [-0.05969,   inf] (25), [-0.05969,   inf] (23), [-0.05969,   inf] (27), [-0.05968,   inf] (23), [-0.05968,   inf] (21), 
length of domains: 2729
Total time: 1.0407	 pickout: 0.0461	 decision: 0.0956	 get_bound: 0.8872	 add_domain: 0.0118
Current lb:-0.059744417667388916
5500 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 51.9924693107605

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 420] [4, 420] [4, 358] [4, 491] [4, 358] [5, 336] [5, 383] [4, 491] [4, 491] [4, 491] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.115389823913574 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 15.483272552490234, 24.992809295654297]
alpha/beta optimization time: 0.8325202465057373
This batch time : update_bounds func: 0.9338	 prepare: 0.0332	 bound: 0.8331	 transfer: 0.0447	 finalize: 0.0224
Accumulated time: update_bounds func: 40.6583	 prepare: 1.0069	 bound: 36.7345	 transfer: 0.0447	 finalize: 0.8761
batch bounding time:  0.9342186450958252
Current worst splitting domains [lb, ub] (depth):
[-0.05954,   inf] (25), [-0.05953,   inf] (23), [-0.05952,   inf] (23), [-0.05952,   inf] (25), [-0.05952,   inf] (19), [-0.05952,   inf] (29), [-0.05952,   inf] (33), [-0.05952,   inf] (39), [-0.05952,   inf] (19), [-0.05952,   inf] (23), [-0.05951,   inf] (25), [-0.05951,   inf] (21), [-0.05951,   inf] (25), [-0.05951,   inf] (27), [-0.05950,   inf] (29), [-0.05950,   inf] (23), [-0.05950,   inf] (21), [-0.05950,   inf] (27), [-0.05950,   inf] (23), [-0.05950,   inf] (25), 
length of domains: 2791
Total time: 1.1142	 pickout: 0.0657	 decision: 0.1032	 get_bound: 0.9344	 add_domain: 0.0108
Current lb:-0.059536129236221313
5628 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 53.109617471694946

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 395] [5, 383] [4, 420] [4, 359] [5, 336] [5, 503] [5, 503] [5, 473] [5, 336] [4, 491] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.164960861206055 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 11.61505126953125, 20.695709228515625]
alpha/beta optimization time: 0.8562185764312744
This batch time : update_bounds func: 0.9657	 prepare: 0.0337	 bound: 0.8568	 transfer: 0.0531	 finalize: 0.0218
Accumulated time: update_bounds func: 41.6240	 prepare: 1.0406	 bound: 37.5913	 transfer: 0.0531	 finalize: 0.8979
batch bounding time:  0.9661087989807129
Current worst splitting domains [lb, ub] (depth):
[-0.05936,   inf] (37), [-0.05935,   inf] (29), [-0.05935,   inf] (21), [-0.05935,   inf] (17), [-0.05935,   inf] (25), [-0.05935,   inf] (23), [-0.05935,   inf] (21), [-0.05935,   inf] (25), [-0.05935,   inf] (21), [-0.05934,   inf] (21), [-0.05934,   inf] (19), [-0.05934,   inf] (21), [-0.05934,   inf] (19), [-0.05934,   inf] (27), [-0.05934,   inf] (27), [-0.05934,   inf] (21), [-0.05933,   inf] (21), [-0.05933,   inf] (25), [-0.05933,   inf] (25), [-0.05933,   inf] (27), 
length of domains: 2849
Total time: 1.2670	 pickout: 0.0691	 decision: 0.2201	 get_bound: 0.9664	 add_domain: 0.0114
Current lb:-0.05935664474964142
5756 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 54.379032611846924

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 395] [4, 359] [4, 491] [5, 37] [5, 320] [4, 359] [4, 358] [5, 383] [4, 420] [4, 420] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.251494407653809 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 12.834796905517578, 21.81517791748047]
alpha/beta optimization time: 0.8283329010009766
This batch time : update_bounds func: 0.9301	 prepare: 0.0335	 bound: 0.8289	 transfer: 0.0448	 finalize: 0.0225
Accumulated time: update_bounds func: 42.5542	 prepare: 1.0740	 bound: 38.4203	 transfer: 0.0448	 finalize: 0.9204
batch bounding time:  0.930570125579834
Current worst splitting domains [lb, ub] (depth):
[-0.05917,   inf] (25), [-0.05917,   inf] (17), [-0.05917,   inf] (37), [-0.05917,   inf] (27), [-0.05916,   inf] (25), [-0.05916,   inf] (21), [-0.05915,   inf] (25), [-0.05914,   inf] (21), [-0.05913,   inf] (19), [-0.05913,   inf] (19), [-0.05913,   inf] (29), [-0.05913,   inf] (25), [-0.05913,   inf] (29), [-0.05912,   inf] (27), [-0.05912,   inf] (21), [-0.05912,   inf] (23), [-0.05911,   inf] (31), [-0.05911,   inf] (23), [-0.05911,   inf] (21), [-0.05911,   inf] (19), 
length of domains: 2911
Total time: 1.1088	 pickout: 0.0635	 decision: 0.1038	 get_bound: 0.9308	 add_domain: 0.0107
Current lb:-0.05917258560657501
5884 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 55.49020195007324

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 491] [5, 37] [4, 359] [4, 491] [4, 491] [4, 491] [5, 383] [4, 420] [4, 491] [5, 37] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.289643287658691 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 13.706292152404785, 21.352205276489258]
alpha/beta optimization time: 0.8113048076629639
This batch time : update_bounds func: 0.8984	 prepare: 0.0226	 bound: 0.8118	 transfer: 0.0482	 finalize: 0.0153
Accumulated time: update_bounds func: 43.4525	 prepare: 1.0966	 bound: 39.2321	 transfer: 0.0482	 finalize: 0.9356
batch bounding time:  0.8987939357757568
Current worst splitting domains [lb, ub] (depth):
[-0.05899,   inf] (25), [-0.05899,   inf] (23), [-0.05898,   inf] (19), [-0.05897,   inf] (31), [-0.05897,   inf] (21), [-0.05896,   inf] (19), [-0.05895,   inf] (25), [-0.05894,   inf] (27), [-0.05894,   inf] (23), [-0.05893,   inf] (21), [-0.05893,   inf] (31), [-0.05893,   inf] (25), [-0.05893,   inf] (33), [-0.05893,   inf] (33), [-0.05893,   inf] (25), [-0.05892,   inf] (27), [-0.05891,   inf] (21), [-0.05891,   inf] (23), [-0.05891,   inf] (19), [-0.05891,   inf] (27), 
length of domains: 2973
Total time: 1.0693	 pickout: 0.0556	 decision: 0.1035	 get_bound: 0.8990	 add_domain: 0.0112
Current lb:-0.05898899585008621
6012 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 56.56195664405823

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 389] [5, 383] [5, 37] [5, 320] [4, 491] [5, 336] [5, 383] [5, 383] [5, 383] [4, 491] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.9720234870910645 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 12.772496223449707, 23.702800750732422]
alpha/beta optimization time: 0.7899556159973145
This batch time : update_bounds func: 0.8783	 prepare: 0.0219	 bound: 0.7904	 transfer: 0.0494	 finalize: 0.0162
Accumulated time: update_bounds func: 44.3309	 prepare: 1.1185	 bound: 40.0225	 transfer: 0.0494	 finalize: 0.9519
batch bounding time:  0.8788022994995117
Current worst splitting domains [lb, ub] (depth):
[-0.05876,   inf] (27), [-0.05876,   inf] (19), [-0.05875,   inf] (27), [-0.05875,   inf] (27), [-0.05875,   inf] (33), [-0.05875,   inf] (29), [-0.05875,   inf] (21), [-0.05875,   inf] (29), [-0.05875,   inf] (19), [-0.05874,   inf] (21), [-0.05874,   inf] (23), [-0.05873,   inf] (21), [-0.05873,   inf] (27), [-0.05873,   inf] (25), [-0.05872,   inf] (21), [-0.05872,   inf] (21), [-0.05872,   inf] (25), [-0.05871,   inf] (27), [-0.05870,   inf] (21), [-0.05869,   inf] (31), 
length of domains: 3032
Total time: 1.0357	 pickout: 0.0523	 decision: 0.0939	 get_bound: 0.8790	 add_domain: 0.0105
Current lb:-0.05875861644744873
6140 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 57.600404024124146

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 383] [4, 420] [4, 359] [5, 320] [5, 389] [4, 420] [4, 420] [4, 358] [4, 420] [4, 420] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.212222576141357 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 14.539960861206055, 21.254501342773438]
alpha/beta optimization time: 0.8026204109191895
This batch time : update_bounds func: 0.8929	 prepare: 0.0219	 bound: 0.8031	 transfer: 0.0504	 finalize: 0.0170
Accumulated time: update_bounds func: 45.2238	 prepare: 1.1404	 bound: 40.8256	 transfer: 0.0504	 finalize: 0.9689
batch bounding time:  0.893333911895752
Current worst splitting domains [lb, ub] (depth):
[-0.05858,   inf] (25), [-0.05858,   inf] (23), [-0.05857,   inf] (29), [-0.05857,   inf] (23), [-0.05857,   inf] (27), [-0.05857,   inf] (25), [-0.05857,   inf] (23), [-0.05857,   inf] (23), [-0.05857,   inf] (21), [-0.05857,   inf] (33), [-0.05857,   inf] (25), [-0.05857,   inf] (23), [-0.05856,   inf] (29), [-0.05856,   inf] (29), [-0.05856,   inf] (25), [-0.05856,   inf] (33), [-0.05855,   inf] (21), [-0.05855,   inf] (19), [-0.05855,   inf] (19), [-0.05855,   inf] (23), 
length of domains: 3093
Total time: 1.0876	 pickout: 0.0851	 decision: 0.0953	 get_bound: 0.8936	 add_domain: 0.0136
Current lb:-0.05857670307159424
6268 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 58.6913685798645

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 395] [4, 420] [4, 359] [4, 491] [4, 358] [4, 359] [5, 383] [5, 383] [4, 395] [4, 359] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.0159196853637695 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 14.59149169921875, 22.077526092529297]
alpha/beta optimization time: 0.806706428527832
This batch time : update_bounds func: 0.8957	 prepare: 0.0221	 bound: 0.8072	 transfer: 0.0499	 finalize: 0.0161
Accumulated time: update_bounds func: 46.1195	 prepare: 1.1625	 bound: 41.6328	 transfer: 0.0499	 finalize: 0.9850
batch bounding time:  0.8962662220001221
Current worst splitting domains [lb, ub] (depth):
[-0.05843,   inf] (21), [-0.05842,   inf] (25), [-0.05842,   inf] (17), [-0.05842,   inf] (23), [-0.05842,   inf] (23), [-0.05842,   inf] (19), [-0.05842,   inf] (23), [-0.05841,   inf] (25), [-0.05841,   inf] (23), [-0.05841,   inf] (19), [-0.05840,   inf] (23), [-0.05840,   inf] (21), [-0.05840,   inf] (19), [-0.05840,   inf] (23), [-0.05840,   inf] (21), [-0.05839,   inf] (21), [-0.05839,   inf] (23), [-0.05839,   inf] (25), [-0.05839,   inf] (23), [-0.05839,   inf] (27), 
length of domains: 3155
Total time: 1.0558	 pickout: 0.0553	 decision: 0.0933	 get_bound: 0.8965	 add_domain: 0.0107
Current lb:-0.05842554569244385
6396 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 59.74955916404724

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 358] [4, 358] [5, 336] [5, 383] [4, 491] [4, 491] [5, 383] [5, 320] [5, 383] [4, 420] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.04155158996582 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 16.837230682373047, 21.91374969482422]
alpha/beta optimization time: 0.7883617877960205
This batch time : update_bounds func: 0.8757	 prepare: 0.0222	 bound: 0.7888	 transfer: 0.0488	 finalize: 0.0155
Accumulated time: update_bounds func: 46.9953	 prepare: 1.1847	 bound: 42.4216	 transfer: 0.0488	 finalize: 1.0004
batch bounding time:  0.8762338161468506
Current worst splitting domains [lb, ub] (depth):
[-0.05827,   inf] (29), [-0.05827,   inf] (21), [-0.05827,   inf] (23), [-0.05827,   inf] (21), [-0.05826,   inf] (25), [-0.05826,   inf] (19), [-0.05826,   inf] (31), [-0.05826,   inf] (23), [-0.05826,   inf] (19), [-0.05825,   inf] (29), [-0.05825,   inf] (21), [-0.05825,   inf] (23), [-0.05825,   inf] (23), [-0.05824,   inf] (19), [-0.05823,   inf] (33), [-0.05823,   inf] (21), [-0.05823,   inf] (21), [-0.05822,   inf] (29), [-0.05822,   inf] (23), [-0.05822,   inf] (25), 
length of domains: 3218
Total time: 1.0319	 pickout: 0.0477	 decision: 0.0964	 get_bound: 0.8765	 add_domain: 0.0113
Current lb:-0.05826851725578308
6524 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 60.78397750854492

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 389] [4, 491] [4, 491] [4, 420] [4, 491] [5, 336] [4, 248] [5, 383] [4, 420] [5, 389] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.953757286071777 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 15.489904403686523, 23.596086502075195]
alpha/beta optimization time: 0.7838613986968994
This batch time : update_bounds func: 0.8732	 prepare: 0.0218	 bound: 0.7843	 transfer: 0.0504	 finalize: 0.0164
Accumulated time: update_bounds func: 47.8685	 prepare: 1.2065	 bound: 43.2060	 transfer: 0.0504	 finalize: 1.0168
batch bounding time:  0.8736798763275146
Current worst splitting domains [lb, ub] (depth):
[-0.05810,   inf] (21), [-0.05810,   inf] (21), [-0.05810,   inf] (23), [-0.05809,   inf] (23), [-0.05809,   inf] (17), [-0.05809,   inf] (27), [-0.05809,   inf] (23), [-0.05809,   inf] (21), [-0.05809,   inf] (21), [-0.05808,   inf] (21), [-0.05807,   inf] (21), [-0.05806,   inf] (23), [-0.05806,   inf] (23), [-0.05806,   inf] (21), [-0.05806,   inf] (25), [-0.05806,   inf] (29), [-0.05805,   inf] (21), [-0.05804,   inf] (21), [-0.05804,   inf] (23), [-0.05803,   inf] (21), 
length of domains: 3279
Total time: 1.0312	 pickout: 0.0534	 decision: 0.0934	 get_bound: 0.8739	 add_domain: 0.0105
Current lb:-0.05810137093067169
6652 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 61.817872285842896

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 358] [4, 491] [4, 395] [4, 359] [5, 336] [4, 491] [4, 491] [4, 420] [4, 395] [4, 491] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.918828010559082 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 16.74411964416504, 25.40842056274414]
alpha/beta optimization time: 0.7857208251953125
This batch time : update_bounds func: 0.8726	 prepare: 0.0218	 bound: 0.7862	 transfer: 0.0486	 finalize: 0.0155
Accumulated time: update_bounds func: 48.7411	 prepare: 1.2283	 bound: 43.9921	 transfer: 0.0486	 finalize: 1.0323
batch bounding time:  0.8730089664459229
Current worst splitting domains [lb, ub] (depth):
[-0.05790,   inf] (23), [-0.05790,   inf] (23), [-0.05790,   inf] (19), [-0.05790,   inf] (21), [-0.05790,   inf] (23), [-0.05789,   inf] (27), [-0.05789,   inf] (23), [-0.05789,   inf] (19), [-0.05789,   inf] (17), [-0.05789,   inf] (23), [-0.05789,   inf] (27), [-0.05789,   inf] (23), [-0.05788,   inf] (19), [-0.05788,   inf] (23), [-0.05788,   inf] (21), [-0.05788,   inf] (27), [-0.05788,   inf] (31), [-0.05786,   inf] (21), [-0.05785,   inf] (29), [-0.05785,   inf] (31), 
length of domains: 3341
Total time: 1.1866	 pickout: 0.0560	 decision: 0.2461	 get_bound: 0.8732	 add_domain: 0.0112
Current lb:-0.05790489912033081
6780 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 63.00763821601868

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 395] [5, 383] [5, 466] [4, 420] [5, 383] [4, 358] [5, 383] [5, 37] [5, 336] [4, 359] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.824306488037109 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 12.947088241577148, 23.488155364990234]
alpha/beta optimization time: 0.7819242477416992
This batch time : update_bounds func: 0.8699	 prepare: 0.0225	 bound: 0.7824	 transfer: 0.0484	 finalize: 0.0162
Accumulated time: update_bounds func: 49.6110	 prepare: 1.2508	 bound: 44.7745	 transfer: 0.0484	 finalize: 1.0485
batch bounding time:  0.8703200817108154
Current worst splitting domains [lb, ub] (depth):
[-0.05774,   inf] (19), [-0.05774,   inf] (33), [-0.05774,   inf] (25), [-0.05774,   inf] (27), [-0.05774,   inf] (29), [-0.05774,   inf] (25), [-0.05773,   inf] (23), [-0.05773,   inf] (35), [-0.05773,   inf] (23), [-0.05773,   inf] (35), [-0.05773,   inf] (31), [-0.05772,   inf] (21), [-0.05772,   inf] (23), [-0.05772,   inf] (25), [-0.05770,   inf] (21), [-0.05770,   inf] (25), [-0.05770,   inf] (23), [-0.05770,   inf] (25), [-0.05769,   inf] (27), [-0.05769,   inf] (29), 
length of domains: 3400
Total time: 1.0256	 pickout: 0.0517	 decision: 0.0930	 get_bound: 0.8705	 add_domain: 0.0104
Current lb:-0.05774414539337158
6908 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 64.03579568862915

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 491] [5, 473] [5, 383] [4, 248] [4, 395] [5, 320] [5, 383] [5, 408] [4, 358] [5, 503] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.130455493927002 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 13.720636367797852, 21.651813507080078]
alpha/beta optimization time: 0.7823765277862549
This batch time : update_bounds func: 0.8725	 prepare: 0.0221	 bound: 0.7829	 transfer: 0.0516	 finalize: 0.0155
Accumulated time: update_bounds func: 50.4835	 prepare: 1.2729	 bound: 45.5574	 transfer: 0.0516	 finalize: 1.0640
batch bounding time:  0.8729188442230225
Current worst splitting domains [lb, ub] (depth):
[-0.05758,   inf] (25), [-0.05758,   inf] (27), [-0.05758,   inf] (35), [-0.05758,   inf] (29), [-0.05757,   inf] (27), [-0.05757,   inf] (27), [-0.05757,   inf] (25), [-0.05757,   inf] (19), [-0.05757,   inf] (23), [-0.05757,   inf] (23), [-0.05756,   inf] (25), [-0.05756,   inf] (19), [-0.05756,   inf] (25), [-0.05756,   inf] (29), [-0.05756,   inf] (19), [-0.05756,   inf] (25), [-0.05755,   inf] (29), [-0.05755,   inf] (23), [-0.05755,   inf] (25), [-0.05755,   inf] (27), 
length of domains: 3462
Total time: 1.0390	 pickout: 0.0585	 decision: 0.0954	 get_bound: 0.8732	 add_domain: 0.0119
Current lb:-0.05758306384086609
7036 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 65.07744884490967

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 395] [4, 358] [5, 503] [4, 420] [4, 420] [4, 491] [5, 383] [4, 491] [5, 383] [5, 383] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.881148338317871 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 16.043743133544922, 23.56073760986328]
alpha/beta optimization time: 0.7838211059570312
This batch time : update_bounds func: 0.8715	 prepare: 0.0217	 bound: 0.7843	 transfer: 0.0461	 finalize: 0.0189
Accumulated time: update_bounds func: 51.3550	 prepare: 1.2946	 bound: 46.3417	 transfer: 0.0461	 finalize: 1.0829
batch bounding time:  0.8719730377197266
Current worst splitting domains [lb, ub] (depth):
[-0.05742,   inf] (29), [-0.05742,   inf] (27), [-0.05742,   inf] (23), [-0.05742,   inf] (19), [-0.05741,   inf] (21), [-0.05741,   inf] (33), [-0.05741,   inf] (25), [-0.05741,   inf] (29), [-0.05741,   inf] (23), [-0.05740,   inf] (21), [-0.05739,   inf] (25), [-0.05739,   inf] (31), [-0.05739,   inf] (23), [-0.05739,   inf] (31), [-0.05738,   inf] (31), [-0.05738,   inf] (23), [-0.05738,   inf] (27), [-0.05738,   inf] (21), [-0.05738,   inf] (27), [-0.05738,   inf] (23), 
length of domains: 3522
Total time: 1.0376	 pickout: 0.0597	 decision: 0.0939	 get_bound: 0.8722	 add_domain: 0.0117
Current lb:-0.0574236661195755
7164 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 66.11804747581482

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 503] [4, 359] [5, 383] [4, 420] [4, 420] [5, 389] [4, 248] [4, 358] [4, 358] [4, 420] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.853967666625977 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 15.27032470703125, 20.961807250976562]
alpha/beta optimization time: 0.7808058261871338
This batch time : update_bounds func: 0.8675	 prepare: 0.0218	 bound: 0.7813	 transfer: 0.0487	 finalize: 0.0154
Accumulated time: update_bounds func: 52.2225	 prepare: 1.3164	 bound: 47.1230	 transfer: 0.0487	 finalize: 1.0983
batch bounding time:  0.8678879737854004
Current worst splitting domains [lb, ub] (depth):
[-0.05726,   inf] (15), [-0.05725,   inf] (25), [-0.05725,   inf] (21), [-0.05725,   inf] (27), [-0.05724,   inf] (27), [-0.05724,   inf] (25), [-0.05724,   inf] (23), [-0.05724,   inf] (23), [-0.05723,   inf] (23), [-0.05723,   inf] (25), [-0.05723,   inf] (23), [-0.05723,   inf] (35), [-0.05723,   inf] (31), [-0.05722,   inf] (25), [-0.05722,   inf] (23), [-0.05722,   inf] (23), [-0.05722,   inf] (23), [-0.05722,   inf] (27), [-0.05722,   inf] (25), [-0.05722,   inf] (25), 
length of domains: 3580
Total time: 1.0261	 pickout: 0.0499	 decision: 0.0965	 get_bound: 0.8681	 add_domain: 0.0115
Current lb:-0.0572570264339447
7292 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 67.1465528011322

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 466] [4, 358] [4, 420] [4, 358] [4, 358] [5, 383] [5, 383] [4, 358] [4, 491] [5, 320] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.80093240737915 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 17.072731018066406, 23.044939041137695]
alpha/beta optimization time: 0.7842979431152344
This batch time : update_bounds func: 0.8715	 prepare: 0.0221	 bound: 0.7848	 transfer: 0.0482	 finalize: 0.0160
Accumulated time: update_bounds func: 53.0940	 prepare: 1.3385	 bound: 47.9077	 transfer: 0.0482	 finalize: 1.1143
batch bounding time:  0.8718581199645996
Current worst splitting domains [lb, ub] (depth):
[-0.05711,   inf] (39), [-0.05711,   inf] (27), [-0.05711,   inf] (27), [-0.05711,   inf] (17), [-0.05711,   inf] (23), [-0.05710,   inf] (27), [-0.05710,   inf] (25), [-0.05710,   inf] (21), [-0.05710,   inf] (23), [-0.05710,   inf] (33), [-0.05709,   inf] (17), [-0.05709,   inf] (29), [-0.05709,   inf] (29), [-0.05708,   inf] (21), [-0.05708,   inf] (23), [-0.05708,   inf] (21), [-0.05707,   inf] (33), [-0.05707,   inf] (25), [-0.05707,   inf] (21), [-0.05706,   inf] (23), 
length of domains: 3641
Total time: 1.0318	 pickout: 0.0558	 decision: 0.0933	 get_bound: 0.8721	 add_domain: 0.0106
Current lb:-0.057114243507385254
7420 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 68.18249654769897

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 389] [4, 395] [4, 358] [5, 466] [5, 383] [4, 358] [4, 358] [4, 491] [4, 491] [4, 359] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.750192642211914 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 15.95199203491211, 24.92842674255371]
alpha/beta optimization time: 0.8228740692138672
This batch time : update_bounds func: 0.9167	 prepare: 0.0218	 bound: 0.8234	 transfer: 0.0494	 finalize: 0.0217
Accumulated time: update_bounds func: 54.0107	 prepare: 1.3603	 bound: 48.7311	 transfer: 0.0494	 finalize: 1.1360
batch bounding time:  0.9171347618103027
Current worst splitting domains [lb, ub] (depth):
[-0.05695,   inf] (25), [-0.05695,   inf] (21), [-0.05695,   inf] (29), [-0.05695,   inf] (31), [-0.05695,   inf] (21), [-0.05694,   inf] (19), [-0.05694,   inf] (21), [-0.05694,   inf] (27), [-0.05693,   inf] (21), [-0.05693,   inf] (23), [-0.05693,   inf] (25), [-0.05692,   inf] (25), [-0.05692,   inf] (23), [-0.05692,   inf] (27), [-0.05692,   inf] (23), [-0.05692,   inf] (21), [-0.05692,   inf] (29), [-0.05692,   inf] (31), [-0.05691,   inf] (23), [-0.05691,   inf] (19), 
length of domains: 3699
Total time: 1.0858	 pickout: 0.0612	 decision: 0.0954	 get_bound: 0.9174	 add_domain: 0.0118
Current lb:-0.056952476501464844
7548 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 69.27087831497192

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 395] [4, 420] [4, 359] [5, 503] [4, 420] [5, 37] [4, 358] [4, 359] [4, 358] [5, 383] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.68248176574707 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 16.243385314941406, 27.852214813232422]
alpha/beta optimization time: 0.8048763275146484
This batch time : update_bounds func: 0.9086	 prepare: 0.0343	 bound: 0.8055	 transfer: 0.0521	 finalize: 0.0162
Accumulated time: update_bounds func: 54.9193	 prepare: 1.3945	 bound: 49.5367	 transfer: 0.0521	 finalize: 1.1522
batch bounding time:  0.9089980125427246
Current worst splitting domains [lb, ub] (depth):
[-0.05682,   inf] (21), [-0.05682,   inf] (21), [-0.05682,   inf] (31), [-0.05682,   inf] (27), [-0.05681,   inf] (15), [-0.05681,   inf] (33), [-0.05681,   inf] (25), [-0.05681,   inf] (23), [-0.05680,   inf] (27), [-0.05680,   inf] (23), [-0.05680,   inf] (23), [-0.05679,   inf] (21), [-0.05679,   inf] (21), [-0.05678,   inf] (25), [-0.05678,   inf] (21), [-0.05677,   inf] (25), [-0.05677,   inf] (27), [-0.05676,   inf] (33), [-0.05676,   inf] (21), [-0.05676,   inf] (27), 
length of domains: 3758
Total time: 1.1029	 pickout: 0.0782	 decision: 0.1052	 get_bound: 0.9092	 add_domain: 0.0102
Current lb:-0.05682113394141197
7676 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 70.37657523155212

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 491] [4, 420] [5, 473] [4, 358] [5, 466] [5, 389] [4, 491] [4, 358] [5, 383] [4, 395] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.331927299499512 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 13.037744522094727, 27.47823715209961]
alpha/beta optimization time: 0.8000798225402832
This batch time : update_bounds func: 0.8910	 prepare: 0.0225	 bound: 0.8006	 transfer: 0.0517	 finalize: 0.0157
Accumulated time: update_bounds func: 55.8103	 prepare: 1.4170	 bound: 50.3372	 transfer: 0.0517	 finalize: 1.1679
batch bounding time:  0.8914577960968018
Current worst splitting domains [lb, ub] (depth):
[-0.05667,   inf] (23), [-0.05667,   inf] (25), [-0.05667,   inf] (29), [-0.05667,   inf] (25), [-0.05667,   inf] (23), [-0.05667,   inf] (23), [-0.05667,   inf] (21), [-0.05666,   inf] (21), [-0.05666,   inf] (21), [-0.05666,   inf] (19), [-0.05666,   inf] (23), [-0.05665,   inf] (33), [-0.05665,   inf] (29), [-0.05665,   inf] (21), [-0.05665,   inf] (19), [-0.05665,   inf] (21), [-0.05664,   inf] (21), [-0.05664,   inf] (17), [-0.05664,   inf] (31), [-0.05664,   inf] (25), 
length of domains: 3812
Total time: 1.0583	 pickout: 0.0572	 decision: 0.0978	 get_bound: 0.8917	 add_domain: 0.0116
Current lb:-0.05667361617088318
7804 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 71.43779921531677

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 383] [4, 491] [4, 248] [4, 395] [4, 491] [5, 383] [4, 420] [4, 420] [4, 420] [4, 420] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.90440034866333 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 14.249271392822266, 22.42737579345703]
alpha/beta optimization time: 0.789379358291626
This batch time : update_bounds func: 0.8771	 prepare: 0.0219	 bound: 0.7898	 transfer: 0.0488	 finalize: 0.0161
Accumulated time: update_bounds func: 56.6874	 prepare: 1.4390	 bound: 51.1270	 transfer: 0.0488	 finalize: 1.1840
batch bounding time:  0.8774898052215576
Current worst splitting domains [lb, ub] (depth):
[-0.05655,   inf] (29), [-0.05655,   inf] (31), [-0.05655,   inf] (29), [-0.05655,   inf] (21), [-0.05654,   inf] (33), [-0.05654,   inf] (25), [-0.05653,   inf] (25), [-0.05653,   inf] (27), [-0.05653,   inf] (17), [-0.05653,   inf] (25), [-0.05652,   inf] (29), [-0.05652,   inf] (21), [-0.05652,   inf] (23), [-0.05652,   inf] (31), [-0.05652,   inf] (29), [-0.05652,   inf] (19), [-0.05652,   inf] (23), [-0.05652,   inf] (27), [-0.05651,   inf] (25), [-0.05651,   inf] (25), 
length of domains: 3873
Total time: 1.2177	 pickout: 0.0576	 decision: 0.2719	 get_bound: 0.8777	 add_domain: 0.0105
Current lb:-0.05654913932085037
7932 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 72.65809941291809

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 383] [5, 473] [4, 359] [4, 358] [5, 473] [5, 383] [5, 383] [4, 358] [5, 336] [4, 491] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.86602783203125 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 11.823142051696777, 22.38199234008789]
alpha/beta optimization time: 0.8122329711914062
This batch time : update_bounds func: 0.8999	 prepare: 0.0218	 bound: 0.8127	 transfer: 0.0484	 finalize: 0.0158
Accumulated time: update_bounds func: 57.5873	 prepare: 1.4607	 bound: 51.9398	 transfer: 0.0484	 finalize: 1.1997
batch bounding time:  0.900383472442627
Current worst splitting domains [lb, ub] (depth):
[-0.05644,   inf] (21), [-0.05644,   inf] (29), [-0.05644,   inf] (27), [-0.05644,   inf] (19), [-0.05644,   inf] (25), [-0.05643,   inf] (27), [-0.05643,   inf] (23), [-0.05643,   inf] (31), [-0.05642,   inf] (23), [-0.05642,   inf] (23), [-0.05642,   inf] (21), [-0.05642,   inf] (29), [-0.05642,   inf] (23), [-0.05642,   inf] (31), [-0.05642,   inf] (29), [-0.05642,   inf] (29), [-0.05642,   inf] (21), [-0.05641,   inf] (35), [-0.05641,   inf] (27), [-0.05641,   inf] (25), 
length of domains: 3934
Total time: 1.0622	 pickout: 0.0565	 decision: 0.0945	 get_bound: 0.9006	 add_domain: 0.0106
Current lb:-0.056439220905303955
8060 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 73.72295045852661

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 420] [5, 320] [4, 358] [5, 336] [4, 358] [4, 359] [5, 383] [5, 320] [4, 491] [5, 383] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.5384416580200195 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 16.526779174804688, 24.834781646728516]
alpha/beta optimization time: 0.7893691062927246
This batch time : update_bounds func: 0.8769	 prepare: 0.0221	 bound: 0.7898	 transfer: 0.0484	 finalize: 0.0162
Accumulated time: update_bounds func: 58.4642	 prepare: 1.4828	 bound: 52.7296	 transfer: 0.0484	 finalize: 1.2159
batch bounding time:  0.8773002624511719
Current worst splitting domains [lb, ub] (depth):
[-0.05631,   inf] (37), [-0.05631,   inf] (33), [-0.05631,   inf] (21), [-0.05631,   inf] (25), [-0.05630,   inf] (23), [-0.05630,   inf] (27), [-0.05630,   inf] (31), [-0.05630,   inf] (25), [-0.05630,   inf] (35), [-0.05630,   inf] (27), [-0.05629,   inf] (25), [-0.05629,   inf] (23), [-0.05629,   inf] (27), [-0.05629,   inf] (33), [-0.05629,   inf] (23), [-0.05628,   inf] (21), [-0.05628,   inf] (19), [-0.05628,   inf] (25), [-0.05627,   inf] (27), [-0.05627,   inf] (17), 
length of domains: 3991
Total time: 1.0392	 pickout: 0.0547	 decision: 0.0963	 get_bound: 0.8775	 add_domain: 0.0106
Current lb:-0.05631092190742493
8188 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 74.7649564743042

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 395] [5, 473] [5, 383] [4, 395] [4, 358] [4, 358] [4, 358] [4, 491] [5, 473] [4, 358] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.308404445648193 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 19.577857971191406, 29.768566131591797]
alpha/beta optimization time: 0.814983606338501
This batch time : update_bounds func: 0.9031	 prepare: 0.0226	 bound: 0.8155	 transfer: 0.0483	 finalize: 0.0155
Accumulated time: update_bounds func: 59.3673	 prepare: 1.5055	 bound: 53.5451	 transfer: 0.0483	 finalize: 1.2314
batch bounding time:  0.9035453796386719
Current worst splitting domains [lb, ub] (depth):
[-0.05617,   inf] (23), [-0.05617,   inf] (33), [-0.05616,   inf] (27), [-0.05616,   inf] (21), [-0.05616,   inf] (23), [-0.05616,   inf] (23), [-0.05616,   inf] (25), [-0.05616,   inf] (27), [-0.05615,   inf] (33), [-0.05615,   inf] (23), [-0.05614,   inf] (25), [-0.05614,   inf] (23), [-0.05614,   inf] (19), [-0.05614,   inf] (25), [-0.05614,   inf] (21), [-0.05614,   inf] (25), [-0.05613,   inf] (27), [-0.05613,   inf] (23), [-0.05613,   inf] (41), [-0.05613,   inf] (35), 
length of domains: 4043
Total time: 1.0641	 pickout: 0.0560	 decision: 0.0943	 get_bound: 0.9038	 add_domain: 0.0100
Current lb:-0.05616801977157593
8316 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 75.83173847198486

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 383] [5, 503] [4, 491] [4, 491] [5, 383] [5, 383] [5, 383] [5, 389] [5, 473] [5, 383] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.518013954162598 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 15.030881881713867, 25.030845642089844]
alpha/beta optimization time: 0.7832925319671631
This batch time : update_bounds func: 0.8706	 prepare: 0.0221	 bound: 0.7838	 transfer: 0.0483	 finalize: 0.0160
Accumulated time: update_bounds func: 60.2380	 prepare: 1.5275	 bound: 54.3288	 transfer: 0.0483	 finalize: 1.2474
batch bounding time:  0.8710482120513916
Current worst splitting domains [lb, ub] (depth):
[-0.05604,   inf] (29), [-0.05604,   inf] (23), [-0.05604,   inf] (21), [-0.05603,   inf] (23), [-0.05602,   inf] (19), [-0.05602,   inf] (27), [-0.05602,   inf] (23), [-0.05601,   inf] (23), [-0.05601,   inf] (25), [-0.05601,   inf] (41), [-0.05600,   inf] (25), [-0.05600,   inf] (23), [-0.05600,   inf] (27), [-0.05600,   inf] (35), [-0.05600,   inf] (19), [-0.05599,   inf] (15), [-0.05599,   inf] (31), [-0.05599,   inf] (23), [-0.05599,   inf] (31), [-0.05598,   inf] (27), 
length of domains: 4099
Total time: 1.0689	 pickout: 0.0918	 decision: 0.0954	 get_bound: 0.8713	 add_domain: 0.0105
Current lb:-0.056037306785583496
8444 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 76.90326738357544

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 358] [4, 395] [4, 491] [5, 383] [5, 37] [5, 473] [4, 420] [5, 383] [5, 383] [4, 395] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.668013095855713 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 15.988452911376953, 24.933029174804688]
alpha/beta optimization time: 0.7839534282684326
This batch time : update_bounds func: 0.8749	 prepare: 0.0222	 bound: 0.7844	 transfer: 0.0515	 finalize: 0.0154
Accumulated time: update_bounds func: 61.1128	 prepare: 1.5497	 bound: 55.1133	 transfer: 0.0515	 finalize: 1.2628
batch bounding time:  0.8752570152282715
Current worst splitting domains [lb, ub] (depth):
[-0.05589,   inf] (29), [-0.05589,   inf] (37), [-0.05588,   inf] (25), [-0.05588,   inf] (35), [-0.05588,   inf] (31), [-0.05587,   inf] (21), [-0.05587,   inf] (27), [-0.05587,   inf] (31), [-0.05587,   inf] (27), [-0.05587,   inf] (21), [-0.05586,   inf] (23), [-0.05585,   inf] (27), [-0.05585,   inf] (25), [-0.05585,   inf] (29), [-0.05585,   inf] (23), [-0.05585,   inf] (23), [-0.05584,   inf] (25), [-0.05583,   inf] (21), [-0.05583,   inf] (21), [-0.05583,   inf] (33), 
length of domains: 4158
Total time: 1.0389	 pickout: 0.0594	 decision: 0.0933	 get_bound: 0.8755	 add_domain: 0.0106
Current lb:-0.055889129638671875
8572 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 77.9448676109314

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 491] [4, 395] [4, 395] [5, 320] [4, 359] [4, 358] [4, 359] [5, 473] [5, 383] [4, 491] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.58225154876709 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 16.948413848876953, 23.63735580444336]
alpha/beta optimization time: 0.7857074737548828
This batch time : update_bounds func: 0.8739	 prepare: 0.0222	 bound: 0.7862	 transfer: 0.0490	 finalize: 0.0160
Accumulated time: update_bounds func: 61.9867	 prepare: 1.5719	 bound: 55.8995	 transfer: 0.0490	 finalize: 1.2789
batch bounding time:  0.8743252754211426
Current worst splitting domains [lb, ub] (depth):
[-0.05575,   inf] (39), [-0.05575,   inf] (23), [-0.05575,   inf] (23), [-0.05575,   inf] (23), [-0.05575,   inf] (25), [-0.05574,   inf] (25), [-0.05574,   inf] (25), [-0.05574,   inf] (23), [-0.05573,   inf] (29), [-0.05573,   inf] (23), [-0.05573,   inf] (29), [-0.05573,   inf] (23), [-0.05572,   inf] (27), [-0.05572,   inf] (21), [-0.05572,   inf] (21), [-0.05572,   inf] (25), [-0.05571,   inf] (31), [-0.05571,   inf] (31), [-0.05571,   inf] (27), [-0.05570,   inf] (21), 
length of domains: 4215
Total time: 1.0392	 pickout: 0.0578	 decision: 0.0962	 get_bound: 0.8746	 add_domain: 0.0106
Current lb:-0.05575242638587952
8700 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 78.98673105239868

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 473] [4, 491] [4, 395] [4, 491] [5, 383] [5, 383] [5, 383] [5, 383] [4, 358] [4, 491] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.350487232208252 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 14.976022720336914, 25.19455909729004]
alpha/beta optimization time: 0.8028059005737305
This batch time : update_bounds func: 0.8945	 prepare: 0.0219	 bound: 0.8033	 transfer: 0.0503	 finalize: 0.0177
Accumulated time: update_bounds func: 62.8812	 prepare: 1.5939	 bound: 56.7028	 transfer: 0.0503	 finalize: 1.2966
batch bounding time:  0.8949408531188965
Current worst splitting domains [lb, ub] (depth):
[-0.05561,   inf] (19), [-0.05561,   inf] (21), [-0.05561,   inf] (33), [-0.05560,   inf] (19), [-0.05560,   inf] (21), [-0.05560,   inf] (21), [-0.05560,   inf] (21), [-0.05560,   inf] (25), [-0.05559,   inf] (29), [-0.05559,   inf] (25), [-0.05559,   inf] (27), [-0.05558,   inf] (29), [-0.05558,   inf] (29), [-0.05558,   inf] (23), [-0.05558,   inf] (23), [-0.05558,   inf] (21), [-0.05558,   inf] (25), [-0.05557,   inf] (29), [-0.05557,   inf] (31), [-0.05557,   inf] (33), 
length of domains: 4271
Total time: 1.0565	 pickout: 0.0536	 decision: 0.0952	 get_bound: 0.8952	 add_domain: 0.0124
Current lb:-0.05560675263404846
8828 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 80.04729628562927

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 491] [4, 420] [5, 389] [4, 420] [4, 491] [4, 358] [4, 491] [4, 358] [4, 358] [4, 359] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.5650224685668945 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 19.78831672668457, 25.182764053344727]
alpha/beta optimization time: 0.7944536209106445
This batch time : update_bounds func: 0.8823	 prepare: 0.0224	 bound: 0.7950	 transfer: 0.0484	 finalize: 0.0161
Accumulated time: update_bounds func: 63.7635	 prepare: 1.6163	 bound: 57.4977	 transfer: 0.0484	 finalize: 1.3126
batch bounding time:  0.8827009201049805
Current worst splitting domains [lb, ub] (depth):
[-0.05549,   inf] (25), [-0.05548,   inf] (29), [-0.05548,   inf] (23), [-0.05547,   inf] (25), [-0.05547,   inf] (29), [-0.05547,   inf] (21), [-0.05547,   inf] (29), [-0.05546,   inf] (41), [-0.05546,   inf] (31), [-0.05546,   inf] (23), [-0.05545,   inf] (29), [-0.05545,   inf] (31), [-0.05545,   inf] (21), [-0.05545,   inf] (23), [-0.05545,   inf] (31), [-0.05545,   inf] (27), [-0.05544,   inf] (29), [-0.05544,   inf] (23), [-0.05543,   inf] (25), [-0.05543,   inf] (29), 
length of domains: 4330
Total time: 1.0567	 pickout: 0.0645	 decision: 0.0984	 get_bound: 0.8829	 add_domain: 0.0108
Current lb:-0.05548681691288948
8956 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 81.1065137386322

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 491] [5, 320] [5, 383] [4, 359] [4, 358] [4, 358] [5, 389] [5, 408] [4, 420] [4, 420] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.433097839355469 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 15.298705101013184, 26.359630584716797]
alpha/beta optimization time: 0.789625883102417
This batch time : update_bounds func: 0.8730	 prepare: 0.0219	 bound: 0.7902	 transfer: 0.0445	 finalize: 0.0151
Accumulated time: update_bounds func: 64.6365	 prepare: 1.6382	 bound: 58.2880	 transfer: 0.0445	 finalize: 1.3277
batch bounding time:  0.8733401298522949
Current worst splitting domains [lb, ub] (depth):
[-0.05536,   inf] (21), [-0.05536,   inf] (23), [-0.05535,   inf] (29), [-0.05535,   inf] (27), [-0.05535,   inf] (35), [-0.05534,   inf] (19), [-0.05534,   inf] (25), [-0.05534,   inf] (31), [-0.05534,   inf] (21), [-0.05534,   inf] (21), [-0.05534,   inf] (25), [-0.05533,   inf] (21), [-0.05533,   inf] (27), [-0.05533,   inf] (21), [-0.05533,   inf] (39), [-0.05533,   inf] (23), [-0.05533,   inf] (21), [-0.05533,   inf] (25), [-0.05533,   inf] (23), [-0.05532,   inf] (21), 
length of domains: 4386
Total time: 1.1155	 pickout: 0.1356	 decision: 0.0957	 get_bound: 0.8736	 add_domain: 0.0106
Current lb:-0.05535578727722168
9084 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 82.22475099563599

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 420] [4, 359] [5, 320] [4, 358] [5, 473] [5, 37] [5, 383] [5, 320] [4, 420] [4, 420] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.535378456115723 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 15.382201194763184, 26.881160736083984]
alpha/beta optimization time: 0.82415771484375
This batch time : update_bounds func: 0.8782	 prepare: 0.0219	 bound: 0.8246	 transfer: 0.0155	 finalize: 0.0158
Accumulated time: update_bounds func: 65.5146	 prepare: 1.6601	 bound: 59.1126	 transfer: 0.0155	 finalize: 1.3435
batch bounding time:  0.8785555362701416
Current worst splitting domains [lb, ub] (depth):
[-0.05525,   inf] (31), [-0.05525,   inf] (21), [-0.05525,   inf] (23), [-0.05525,   inf] (23), [-0.05525,   inf] (21), [-0.05525,   inf] (27), [-0.05524,   inf] (25), [-0.05524,   inf] (27), [-0.05524,   inf] (25), [-0.05524,   inf] (25), [-0.05523,   inf] (27), [-0.05523,   inf] (25), [-0.05523,   inf] (21), [-0.05523,   inf] (25), [-0.05523,   inf] (41), [-0.05523,   inf] (33), [-0.05523,   inf] (29), [-0.05522,   inf] (33), [-0.05522,   inf] (29), [-0.05522,   inf] (21), 
length of domains: 4445
Total time: 1.2300	 pickout: 0.0504	 decision: 0.2903	 get_bound: 0.8788	 add_domain: 0.0104
Current lb:-0.05524980649352074
9212 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 83.45727300643921

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 248] [4, 420] [5, 383] [4, 491] [4, 359] [4, 491] [4, 358] [4, 248] [4, 395] [4, 420] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.505847930908203 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 13.647541999816895, 24.377037048339844]
alpha/beta optimization time: 0.787846565246582
This batch time : update_bounds func: 0.8515	 prepare: 0.0222	 bound: 0.7883	 transfer: 0.0247	 finalize: 0.0159
Accumulated time: update_bounds func: 66.3661	 prepare: 1.6822	 bound: 59.9009	 transfer: 0.0247	 finalize: 1.3594
batch bounding time:  0.8519177436828613
Current worst splitting domains [lb, ub] (depth):
[-0.05515,   inf] (23), [-0.05515,   inf] (29), [-0.05514,   inf] (23), [-0.05514,   inf] (21), [-0.05514,   inf] (37), [-0.05514,   inf] (19), [-0.05514,   inf] (21), [-0.05513,   inf] (25), [-0.05513,   inf] (21), [-0.05513,   inf] (19), [-0.05513,   inf] (31), [-0.05513,   inf] (25), [-0.05513,   inf] (25), [-0.05512,   inf] (31), [-0.05512,   inf] (27), [-0.05512,   inf] (23), [-0.05512,   inf] (35), [-0.05512,   inf] (35), [-0.05512,   inf] (29), [-0.05512,   inf] (29), 
length of domains: 4503
Total time: 1.0013	 pickout: 0.0445	 decision: 0.0941	 get_bound: 0.8521	 add_domain: 0.0106
Current lb:-0.05514753982424736
9340 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 84.46096444129944

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 383] [5, 320] [5, 383] [4, 491] [5, 503] [5, 37] [4, 420] [5, 473] [4, 420] [5, 37] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.490310192108154 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 14.314698219299316, 26.193416595458984]
alpha/beta optimization time: 0.7892141342163086
This batch time : update_bounds func: 0.8732	 prepare: 0.0219	 bound: 0.7897	 transfer: 0.0454	 finalize: 0.0158
Accumulated time: update_bounds func: 67.2394	 prepare: 1.7041	 bound: 60.6906	 transfer: 0.0454	 finalize: 1.3752
batch bounding time:  0.8736085891723633
Current worst splitting domains [lb, ub] (depth):
[-0.05503,   inf] (25), [-0.05503,   inf] (25), [-0.05503,   inf] (21), [-0.05502,   inf] (21), [-0.05502,   inf] (21), [-0.05502,   inf] (21), [-0.05502,   inf] (33), [-0.05502,   inf] (25), [-0.05502,   inf] (25), [-0.05502,   inf] (35), [-0.05502,   inf] (41), [-0.05502,   inf] (23), [-0.05501,   inf] (29), [-0.05501,   inf] (31), [-0.05501,   inf] (31), [-0.05501,   inf] (31), [-0.05501,   inf] (27), [-0.05500,   inf] (25), [-0.05500,   inf] (33), [-0.05500,   inf] (25), 
length of domains: 4561
Total time: 1.0250	 pickout: 0.0454	 decision: 0.0954	 get_bound: 0.8738	 add_domain: 0.0104
Current lb:-0.055028170347213745
9468 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 85.48850226402283

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 383] [5, 383] [5, 37] [4, 491] [4, 491] [4, 491] [4, 359] [4, 358] [4, 420] [4, 359] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.3306884765625 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 18.466270446777344, 28.500144958496094]
alpha/beta optimization time: 0.7959327697753906
This batch time : update_bounds func: 0.8628	 prepare: 0.0220	 bound: 0.7964	 transfer: 0.0278	 finalize: 0.0162
Accumulated time: update_bounds func: 68.1021	 prepare: 1.7262	 bound: 61.4870	 transfer: 0.0278	 finalize: 1.3914
batch bounding time:  0.8631958961486816
Current worst splitting domains [lb, ub] (depth):
[-0.05493,   inf] (25), [-0.05493,   inf] (23), [-0.05492,   inf] (31), [-0.05492,   inf] (27), [-0.05492,   inf] (27), [-0.05491,   inf] (35), [-0.05491,   inf] (37), [-0.05491,   inf] (43), [-0.05491,   inf] (23), [-0.05491,   inf] (27), [-0.05491,   inf] (23), [-0.05490,   inf] (29), [-0.05490,   inf] (23), [-0.05490,   inf] (29), [-0.05490,   inf] (23), [-0.05490,   inf] (27), [-0.05490,   inf] (25), [-0.05490,   inf] (19), [-0.05490,   inf] (23), [-0.05490,   inf] (23), 
length of domains: 4620
Total time: 1.0137	 pickout: 0.0457	 decision: 0.0939	 get_bound: 0.8634	 add_domain: 0.0106
Current lb:-0.0549270361661911
9596 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 86.50455522537231

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 359] [4, 491] [4, 395] [4, 358] [5, 320] [5, 294] [4, 359] [5, 294] [4, 491] [5, 503] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.198480129241943 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 16.302215576171875, 27.59981346130371]
alpha/beta optimization time: 0.793137788772583
This batch time : update_bounds func: 0.8897	 prepare: 0.0218	 bound: 0.7936	 transfer: 0.0517	 finalize: 0.0222
Accumulated time: update_bounds func: 68.9919	 prepare: 1.7480	 bound: 62.2806	 transfer: 0.0517	 finalize: 1.4136
batch bounding time:  0.8901815414428711
Current worst splitting domains [lb, ub] (depth):
[-0.05483,   inf] (23), [-0.05483,   inf] (25), [-0.05482,   inf] (25), [-0.05482,   inf] (19), [-0.05480,   inf] (23), [-0.05480,   inf] (21), [-0.05480,   inf] (21), [-0.05480,   inf] (29), [-0.05480,   inf] (27), [-0.05479,   inf] (23), [-0.05479,   inf] (23), [-0.05479,   inf] (17), [-0.05479,   inf] (21), [-0.05479,   inf] (27), [-0.05479,   inf] (23), [-0.05479,   inf] (25), [-0.05478,   inf] (15), [-0.05478,   inf] (19), [-0.05478,   inf] (29), [-0.05478,   inf] (29), 
length of domains: 4676
Total time: 1.0663	 pickout: 0.0687	 decision: 0.0959	 get_bound: 0.8904	 add_domain: 0.0112
Current lb:-0.05482956022024155
9724 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 87.5736620426178

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 491] [5, 320] [5, 383] [5, 37] [4, 491] [4, 359] [4, 420] [4, 395] [5, 383] [4, 491] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.639052391052246 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 14.145854949951172, 24.589679718017578]
alpha/beta optimization time: 0.8104510307312012
This batch time : update_bounds func: 0.9121	 prepare: 0.0335	 bound: 0.8110	 transfer: 0.0509	 finalize: 0.0161
Accumulated time: update_bounds func: 69.9039	 prepare: 1.7815	 bound: 63.0916	 transfer: 0.0509	 finalize: 1.4297
batch bounding time:  0.9124724864959717
Current worst splitting domains [lb, ub] (depth):
[-0.05469,   inf] (19), [-0.05469,   inf] (27), [-0.05469,   inf] (29), [-0.05469,   inf] (23), [-0.05469,   inf] (21), [-0.05469,   inf] (31), [-0.05469,   inf] (29), [-0.05469,   inf] (23), [-0.05469,   inf] (21), [-0.05469,   inf] (21), [-0.05469,   inf] (21), [-0.05468,   inf] (25), [-0.05468,   inf] (23), [-0.05468,   inf] (25), [-0.05468,   inf] (39), [-0.05468,   inf] (35), [-0.05468,   inf] (29), [-0.05468,   inf] (25), [-0.05468,   inf] (21), [-0.05467,   inf] (29), 
length of domains: 4736
Total time: 1.0823	 pickout: 0.0539	 decision: 0.1052	 get_bound: 0.9127	 add_domain: 0.0105
Current lb:-0.054694369435310364
9852 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 88.65837383270264

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 37] [4, 358] [4, 420] [5, 383] [5, 466] [5, 389] [5, 389] [4, 491] [4, 491] [4, 359] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.176910877227783 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 17.22317123413086, 29.328372955322266]
alpha/beta optimization time: 0.7861275672912598
This batch time : update_bounds func: 0.8767	 prepare: 0.0220	 bound: 0.7866	 transfer: 0.0518	 finalize: 0.0159
Accumulated time: update_bounds func: 70.7807	 prepare: 1.8035	 bound: 63.8782	 transfer: 0.0518	 finalize: 1.4456
batch bounding time:  0.8771679401397705
Current worst splitting domains [lb, ub] (depth):
[-0.05459,   inf] (31), [-0.05459,   inf] (29), [-0.05459,   inf] (37), [-0.05459,   inf] (23), [-0.05458,   inf] (35), [-0.05458,   inf] (25), [-0.05458,   inf] (25), [-0.05458,   inf] (25), [-0.05457,   inf] (23), [-0.05457,   inf] (25), [-0.05457,   inf] (21), [-0.05456,   inf] (29), [-0.05456,   inf] (35), [-0.05456,   inf] (23), [-0.05456,   inf] (39), [-0.05456,   inf] (23), [-0.05456,   inf] (23), [-0.05456,   inf] (31), [-0.05456,   inf] (19), [-0.05456,   inf] (23), 
length of domains: 4791
Total time: 1.0281	 pickout: 0.0449	 decision: 0.0956	 get_bound: 0.8774	 add_domain: 0.0101
Current lb:-0.054589152336120605
9980 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 89.68919968605042

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 503] [5, 320] [4, 262] [4, 358] [5, 473] [4, 358] [5, 389] [4, 491] [4, 358] [4, 395] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.1579389572143555 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 15.882844924926758, 27.904125213623047]
alpha/beta optimization time: 0.7850501537322998
This batch time : update_bounds func: 0.8750	 prepare: 0.0220	 bound: 0.7855	 transfer: 0.0510	 finalize: 0.0161
Accumulated time: update_bounds func: 71.6557	 prepare: 1.8255	 bound: 64.6637	 transfer: 0.0510	 finalize: 1.4616
batch bounding time:  0.8754334449768066
Current worst splitting domains [lb, ub] (depth):
[-0.05447,   inf] (21), [-0.05447,   inf] (23), [-0.05447,   inf] (25), [-0.05447,   inf] (29), [-0.05447,   inf] (25), [-0.05447,   inf] (31), [-0.05447,   inf] (23), [-0.05447,   inf] (25), [-0.05446,   inf] (27), [-0.05446,   inf] (27), [-0.05446,   inf] (21), [-0.05445,   inf] (21), [-0.05445,   inf] (27), [-0.05445,   inf] (21), [-0.05445,   inf] (31), [-0.05445,   inf] (23), [-0.05444,   inf] (29), [-0.05444,   inf] (21), [-0.05443,   inf] (23), [-0.05443,   inf] (19), 
length of domains: 4842
Total time: 1.0278	 pickout: 0.0478	 decision: 0.0938	 get_bound: 0.8757	 add_domain: 0.0105
Current lb:-0.05447244644165039
10108 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 90.71966862678528

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 491] [4, 491] [4, 491] [4, 358] [5, 383] [5, 389] [5, 383] [4, 358] [4, 358] [4, 358] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.493260860443115 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 16.999149322509766, 26.376056671142578]
alpha/beta optimization time: 0.7853713035583496
This batch time : update_bounds func: 0.8750	 prepare: 0.0218	 bound: 0.7858	 transfer: 0.0510	 finalize: 0.0159
Accumulated time: update_bounds func: 72.5307	 prepare: 1.8473	 bound: 65.4495	 transfer: 0.0510	 finalize: 1.4776
batch bounding time:  0.8753781318664551
Current worst splitting domains [lb, ub] (depth):
[-0.05436,   inf] (23), [-0.05436,   inf] (25), [-0.05436,   inf] (27), [-0.05436,   inf] (31), [-0.05436,   inf] (29), [-0.05435,   inf] (43), [-0.05435,   inf] (21), [-0.05435,   inf] (23), [-0.05435,   inf] (25), [-0.05435,   inf] (21), [-0.05435,   inf] (23), [-0.05434,   inf] (23), [-0.05434,   inf] (33), [-0.05434,   inf] (19), [-0.05434,   inf] (23), [-0.05434,   inf] (25), [-0.05434,   inf] (21), [-0.05434,   inf] (25), [-0.05434,   inf] (25), [-0.05433,   inf] (23), 
length of domains: 4900
Total time: 1.0570	 pickout: 0.0750	 decision: 0.0960	 get_bound: 0.8756	 add_domain: 0.0104
Current lb:-0.05436022952198982
10236 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 91.77923822402954

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 491] [4, 358] [5, 389] [5, 503] [4, 358] [5, 294] [4, 491] [4, 491] [5, 320] [4, 420] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.120891094207764 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 15.897212982177734, 29.24359130859375]
alpha/beta optimization time: 0.7890691757202148
This batch time : update_bounds func: 0.8784	 prepare: 0.0222	 bound: 0.7895	 transfer: 0.0505	 finalize: 0.0158
Accumulated time: update_bounds func: 73.4091	 prepare: 1.8695	 bound: 66.2391	 transfer: 0.0505	 finalize: 1.4934
batch bounding time:  0.8788249492645264
Current worst splitting domains [lb, ub] (depth):
[-0.05426,   inf] (31), [-0.05426,   inf] (29), [-0.05426,   inf] (25), [-0.05426,   inf] (21), [-0.05425,   inf] (21), [-0.05425,   inf] (25), [-0.05425,   inf] (27), [-0.05425,   inf] (27), [-0.05425,   inf] (25), [-0.05425,   inf] (21), [-0.05425,   inf] (27), [-0.05425,   inf] (27), [-0.05425,   inf] (29), [-0.05425,   inf] (17), [-0.05425,   inf] (21), [-0.05424,   inf] (25), [-0.05424,   inf] (25), [-0.05424,   inf] (23), [-0.05424,   inf] (33), [-0.05423,   inf] (35), 
length of domains: 4953
Total time: 1.0382	 pickout: 0.0548	 decision: 0.0941	 get_bound: 0.8790	 add_domain: 0.0102
Current lb:-0.0542597621679306
10364 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 92.82002854347229

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 248] [4, 420] [4, 358] [4, 491] [4, 358] [5, 383] [4, 358] [4, 358] [4, 358] [4, 420] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.2570648193359375 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 17.302045822143555, 27.192649841308594]
alpha/beta optimization time: 0.7899997234344482
This batch time : update_bounds func: 0.8777	 prepare: 0.0220	 bound: 0.7905	 transfer: 0.0484	 finalize: 0.0164
Accumulated time: update_bounds func: 74.2868	 prepare: 1.8916	 bound: 67.0295	 transfer: 0.0484	 finalize: 1.5097
batch bounding time:  0.8781030178070068
Current worst splitting domains [lb, ub] (depth):
[-0.05416,   inf] (27), [-0.05416,   inf] (25), [-0.05415,   inf] (29), [-0.05415,   inf] (21), [-0.05415,   inf] (25), [-0.05415,   inf] (21), [-0.05415,   inf] (29), [-0.05415,   inf] (29), [-0.05415,   inf] (31), [-0.05414,   inf] (23), [-0.05414,   inf] (27), [-0.05414,   inf] (25), [-0.05414,   inf] (27), [-0.05413,   inf] (29), [-0.05413,   inf] (23), [-0.05413,   inf] (25), [-0.05412,   inf] (23), [-0.05412,   inf] (23), [-0.05411,   inf] (27), [-0.05411,   inf] (27), 
length of domains: 5008
Total time: 1.2517	 pickout: 0.0744	 decision: 0.0964	 get_bound: 0.8783	 add_domain: 0.2027
Current lb:-0.054156344383955
10492 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 94.07460761070251

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 395] [4, 491] [4, 358] [5, 37] [5, 320] [4, 491] [4, 358] [5, 503] [5, 503] [4, 395] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.085916042327881 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 21.091564178466797, 26.826797485351562]
alpha/beta optimization time: 0.7843880653381348
This batch time : update_bounds func: 0.8717	 prepare: 0.0219	 bound: 0.7849	 transfer: 0.0482	 finalize: 0.0162
Accumulated time: update_bounds func: 75.1585	 prepare: 1.9135	 bound: 67.8144	 transfer: 0.0482	 finalize: 1.5260
batch bounding time:  0.8720855712890625
Current worst splitting domains [lb, ub] (depth):
[-0.05404,   inf] (25), [-0.05404,   inf] (29), [-0.05404,   inf] (29), [-0.05404,   inf] (23), [-0.05403,   inf] (23), [-0.05403,   inf] (31), [-0.05403,   inf] (29), [-0.05403,   inf] (37), [-0.05403,   inf] (35), [-0.05403,   inf] (31), [-0.05402,   inf] (29), [-0.05402,   inf] (37), [-0.05402,   inf] (23), [-0.05402,   inf] (27), [-0.05401,   inf] (31), [-0.05401,   inf] (23), [-0.05401,   inf] (23), [-0.05401,   inf] (39), [-0.05401,   inf] (37), [-0.05401,   inf] (29), 
length of domains: 5060
Total time: 1.0319	 pickout: 0.0551	 decision: 0.0943	 get_bound: 0.8723	 add_domain: 0.0102
Current lb:-0.05404013395309448
10620 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 95.10964155197144

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [4, 395] [5, 320] [5, 383] [4, 491] [5, 473] [4, 358] [5, 389] [5, 389] [4, 358] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.261311054229736 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 14.456048011779785, 23.730152130126953]
alpha/beta optimization time: 0.7914724349975586
This batch time : update_bounds func: 0.8758	 prepare: 0.0227	 bound: 0.7920	 transfer: 0.0445	 finalize: 0.0162
Accumulated time: update_bounds func: 76.0344	 prepare: 1.9362	 bound: 68.6063	 transfer: 0.0445	 finalize: 1.5422
batch bounding time:  0.8763101100921631
Current worst splitting domains [lb, ub] (depth):
[-0.05394,   inf] (29), [-0.05394,   inf] (31), [-0.05393,   inf] (23), [-0.05393,   inf] (25), [-0.05393,   inf] (25), [-0.05393,   inf] (29), [-0.05393,   inf] (29), [-0.05393,   inf] (23), [-0.05393,   inf] (33), [-0.05393,   inf] (35), [-0.05392,   inf] (35), [-0.05392,   inf] (29), [-0.05392,   inf] (31), [-0.05392,   inf] (21), [-0.05392,   inf] (21), [-0.05391,   inf] (21), [-0.05391,   inf] (29), [-0.05391,   inf] (27), [-0.05391,   inf] (17), [-0.05391,   inf] (25), 
length of domains: 5115
Total time: 1.0397	 pickout: 0.0549	 decision: 0.0960	 get_bound: 0.8766	 add_domain: 0.0122
Current lb:-0.05393917113542557
10748 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 96.15240049362183

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 389] [5, 503] [5, 383] [5, 383] [4, 358] [5, 503] [5, 389] [4, 491] [4, 359] [5, 389] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.962193965911865 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 14.814225196838379, 29.1984920501709]
alpha/beta optimization time: 0.824195146560669
This batch time : update_bounds func: 0.9330	 prepare: 0.0325	 bound: 0.8250	 transfer: 0.0522	 finalize: 0.0227
Accumulated time: update_bounds func: 76.9673	 prepare: 1.9687	 bound: 69.4313	 transfer: 0.0522	 finalize: 1.5649
batch bounding time:  0.9334578514099121
Current worst splitting domains [lb, ub] (depth):
[-0.05383,   inf] (21), [-0.05383,   inf] (17), [-0.05383,   inf] (25), [-0.05383,   inf] (21), [-0.05383,   inf] (21), [-0.05383,   inf] (25), [-0.05383,   inf] (27), [-0.05383,   inf] (21), [-0.05382,   inf] (33), [-0.05382,   inf] (23), [-0.05382,   inf] (35), [-0.05382,   inf] (25), [-0.05382,   inf] (33), [-0.05382,   inf] (27), [-0.05382,   inf] (25), [-0.05382,   inf] (31), [-0.05381,   inf] (25), [-0.05381,   inf] (29), [-0.05381,   inf] (37), [-0.05381,   inf] (29), 
length of domains: 5166
Total time: 1.1126	 pickout: 0.0705	 decision: 0.0976	 get_bound: 0.9337	 add_domain: 0.0108
Current lb:-0.05383431166410446
10876 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 97.26774597167969

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 37] [5, 336] [4, 395] [4, 491] [4, 491] [4, 359] [4, 358] [4, 491] [5, 408] [5, 383] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.870037078857422 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 19.399229049682617, 31.00579833984375]
alpha/beta optimization time: 0.8119590282440186
This batch time : update_bounds func: 0.8988	 prepare: 0.0221	 bound: 0.8124	 transfer: 0.0483	 finalize: 0.0156
Accumulated time: update_bounds func: 77.8662	 prepare: 1.9908	 bound: 70.2437	 transfer: 0.0483	 finalize: 1.5805
batch bounding time:  0.8992674350738525
Current worst splitting domains [lb, ub] (depth):
[-0.05374,   inf] (45), [-0.05374,   inf] (31), [-0.05373,   inf] (21), [-0.05373,   inf] (21), [-0.05373,   inf] (29), [-0.05373,   inf] (23), [-0.05373,   inf] (29), [-0.05373,   inf] (33), [-0.05373,   inf] (31), [-0.05372,   inf] (25), [-0.05372,   inf] (19), [-0.05372,   inf] (23), [-0.05372,   inf] (27), [-0.05371,   inf] (23), [-0.05371,   inf] (33), [-0.05371,   inf] (25), [-0.05371,   inf] (21), [-0.05370,   inf] (23), [-0.05370,   inf] (29), [-0.05369,   inf] (21), 
length of domains: 5215
Total time: 1.0774	 pickout: 0.0714	 decision: 0.0957	 get_bound: 0.8995	 add_domain: 0.0109
Current lb:-0.053736716508865356
11004 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 98.34795331954956

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 248] [5, 389] [4, 491] [4, 491] [4, 359] [4, 491] [5, 389] [5, 473] [5, 473] [4, 358] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.947317123413086 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 13.198081970214844, 32.166534423828125]
alpha/beta optimization time: 0.787184476852417
This batch time : update_bounds func: 0.8758	 prepare: 0.0224	 bound: 0.7877	 transfer: 0.0487	 finalize: 0.0166
Accumulated time: update_bounds func: 78.7420	 prepare: 2.0132	 bound: 71.0314	 transfer: 0.0487	 finalize: 1.5971
batch bounding time:  0.8762373924255371
Current worst splitting domains [lb, ub] (depth):
[-0.05362,   inf] (29), [-0.05362,   inf] (27), [-0.05362,   inf] (21), [-0.05362,   inf] (31), [-0.05362,   inf] (25), [-0.05362,   inf] (21), [-0.05362,   inf] (23), [-0.05361,   inf] (29), [-0.05361,   inf] (19), [-0.05361,   inf] (29), [-0.05361,   inf] (33), [-0.05361,   inf] (21), [-0.05361,   inf] (23), [-0.05361,   inf] (21), [-0.05361,   inf] (23), [-0.05361,   inf] (27), [-0.05360,   inf] (29), [-0.05360,   inf] (21), [-0.05360,   inf] (21), [-0.05360,   inf] (29), 
length of domains: 5265
Total time: 1.0379	 pickout: 0.0561	 decision: 0.0946	 get_bound: 0.8765	 add_domain: 0.0107
Current lb:-0.05362158641219139
11132 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 99.38897156715393

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [4, 358] [4, 491] [5, 503] [4, 420] [4, 491] [5, 383] [5, 320] [5, 336] [4, 358] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.042380332946777 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 17.689403533935547, 30.168392181396484]
alpha/beta optimization time: 0.8138377666473389
This batch time : update_bounds func: 0.9250	 prepare: 0.0454	 bound: 0.8146	 transfer: 0.0483	 finalize: 0.0159
Accumulated time: update_bounds func: 79.6670	 prepare: 2.0586	 bound: 71.8460	 transfer: 0.0483	 finalize: 1.6130
batch bounding time:  0.9254240989685059
Current worst splitting domains [lb, ub] (depth):
[-0.05353,   inf] (27), [-0.05353,   inf] (25), [-0.05353,   inf] (27), [-0.05353,   inf] (29), [-0.05352,   inf] (19), [-0.05352,   inf] (23), [-0.05352,   inf] (27), [-0.05352,   inf] (25), [-0.05352,   inf] (31), [-0.05351,   inf] (35), [-0.05351,   inf] (19), [-0.05351,   inf] (39), [-0.05350,   inf] (25), [-0.05350,   inf] (31), [-0.05350,   inf] (27), [-0.05350,   inf] (29), [-0.05349,   inf] (25), [-0.05349,   inf] (25), [-0.05349,   inf] (23), [-0.05349,   inf] (33), 
length of domains: 5320
Total time: 1.0962	 pickout: 0.0566	 decision: 0.1026	 get_bound: 0.9257	 add_domain: 0.0114
Current lb:-0.05353151261806488
11260 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 100.48793482780457

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 358] [4, 358] [5, 320] [5, 389] [5, 37] [4, 491] [4, 358] [5, 383] [5, 503] [5, 503] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.903776168823242 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 14.900358200073242, 29.050798416137695]
alpha/beta optimization time: 0.7995893955230713
This batch time : update_bounds func: 0.9039	 prepare: 0.0347	 bound: 0.8001	 transfer: 0.0516	 finalize: 0.0168
Accumulated time: update_bounds func: 80.5709	 prepare: 2.0933	 bound: 72.6460	 transfer: 0.0516	 finalize: 1.6298
batch bounding time:  0.9043397903442383
Current worst splitting domains [lb, ub] (depth):
[-0.05344,   inf] (29), [-0.05344,   inf] (31), [-0.05344,   inf] (25), [-0.05344,   inf] (33), [-0.05343,   inf] (21), [-0.05343,   inf] (27), [-0.05343,   inf] (27), [-0.05343,   inf] (25), [-0.05343,   inf] (25), [-0.05342,   inf] (23), [-0.05342,   inf] (31), [-0.05342,   inf] (33), [-0.05342,   inf] (35), [-0.05342,   inf] (29), [-0.05342,   inf] (33), [-0.05341,   inf] (23), [-0.05341,   inf] (23), [-0.05341,   inf] (29), [-0.05341,   inf] (27), [-0.05341,   inf] (29), 
length of domains: 5372
Total time: 1.0666	 pickout: 0.0514	 decision: 0.1003	 get_bound: 0.9046	 add_domain: 0.0103
Current lb:-0.053440868854522705
11388 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 101.55728769302368

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [4, 395] [4, 358] [5, 320] [4, 491] [4, 358] [4, 358] [4, 358] [5, 383] [4, 358] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.940471649169922 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 18.885929107666016, 29.756772994995117]
alpha/beta optimization time: 0.7814550399780273
This batch time : update_bounds func: 0.8681	 prepare: 0.0219	 bound: 0.7819	 transfer: 0.0483	 finalize: 0.0156
Accumulated time: update_bounds func: 81.4390	 prepare: 2.1152	 bound: 73.4279	 transfer: 0.0483	 finalize: 1.6454
batch bounding time:  0.8684792518615723
Current worst splitting domains [lb, ub] (depth):
[-0.05333,   inf] (25), [-0.05333,   inf] (25), [-0.05333,   inf] (21), [-0.05332,   inf] (23), [-0.05332,   inf] (23), [-0.05332,   inf] (29), [-0.05332,   inf] (31), [-0.05332,   inf] (31), [-0.05332,   inf] (45), [-0.05332,   inf] (21), [-0.05332,   inf] (29), [-0.05332,   inf] (25), [-0.05331,   inf] (27), [-0.05331,   inf] (23), [-0.05331,   inf] (25), [-0.05331,   inf] (23), [-0.05331,   inf] (29), [-0.05331,   inf] (31), [-0.05331,   inf] (27), [-0.05331,   inf] (25), 
length of domains: 5424
Total time: 1.0247	 pickout: 0.0496	 decision: 0.0954	 get_bound: 0.8687	 add_domain: 0.0110
Current lb:-0.0533347949385643
11516 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 102.58463311195374

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 491] [4, 420] [4, 420] [4, 491] [4, 358] [4, 358] [4, 395] [4, 248] [5, 496] [4, 491] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.831841468811035 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 17.287410736083984, 28.297531127929688]
alpha/beta optimization time: 0.7905051708221436
This batch time : update_bounds func: 0.8780	 prepare: 0.0219	 bound: 0.7910	 transfer: 0.0484	 finalize: 0.0164
Accumulated time: update_bounds func: 82.3170	 prepare: 2.1371	 bound: 74.2189	 transfer: 0.0484	 finalize: 1.6617
batch bounding time:  0.8784010410308838
Current worst splitting domains [lb, ub] (depth):
[-0.05323,   inf] (29), [-0.05323,   inf] (31), [-0.05323,   inf] (21), [-0.05323,   inf] (25), [-0.05322,   inf] (29), [-0.05322,   inf] (31), [-0.05322,   inf] (23), [-0.05322,   inf] (25), [-0.05322,   inf] (25), [-0.05322,   inf] (19), [-0.05321,   inf] (25), [-0.05321,   inf] (27), [-0.05320,   inf] (23), [-0.05320,   inf] (21), [-0.05320,   inf] (23), [-0.05320,   inf] (31), [-0.05320,   inf] (29), [-0.05320,   inf] (29), [-0.05320,   inf] (25), [-0.05320,   inf] (23), 
length of domains: 5473
Total time: 1.0369	 pickout: 0.0548	 decision: 0.0934	 get_bound: 0.8786	 add_domain: 0.0100
Current lb:-0.05323082208633423
11644 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 103.62405133247375

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 389] [5, 320] [4, 420] [4, 491] [4, 359] [5, 320] [4, 395] [4, 395] [4, 358] [5, 37] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.0301361083984375 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 16.84646224975586, 28.961936950683594]
alpha/beta optimization time: 0.789534330368042
This batch time : update_bounds func: 0.8799	 prepare: 0.0221	 bound: 0.7900	 transfer: 0.0516	 finalize: 0.0157
Accumulated time: update_bounds func: 83.1969	 prepare: 2.1592	 bound: 75.0089	 transfer: 0.0516	 finalize: 1.6775
batch bounding time:  0.8802838325500488
Current worst splitting domains [lb, ub] (depth):
[-0.05314,   inf] (35), [-0.05314,   inf] (25), [-0.05313,   inf] (35), [-0.05313,   inf] (23), [-0.05313,   inf] (33), [-0.05313,   inf] (33), [-0.05313,   inf] (27), [-0.05313,   inf] (37), [-0.05312,   inf] (27), [-0.05312,   inf] (27), [-0.05311,   inf] (25), [-0.05311,   inf] (29), [-0.05311,   inf] (27), [-0.05311,   inf] (29), [-0.05311,   inf] (23), [-0.05310,   inf] (35), [-0.05310,   inf] (25), [-0.05310,   inf] (23), [-0.05310,   inf] (23), [-0.05310,   inf] (31), 
length of domains: 5525
Total time: 1.0412	 pickout: 0.0533	 decision: 0.0964	 get_bound: 0.8805	 add_domain: 0.0111
Current lb:-0.05313754081726074
11772 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 104.667977809906

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 503] [4, 491] [4, 359] [5, 383] [5, 389] [5, 320] [4, 395] [5, 408] [5, 320] [4, 358] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.963466644287109 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 14.455740928649902, 28.0299072265625]
alpha/beta optimization time: 0.7917613983154297
This batch time : update_bounds func: 0.8764	 prepare: 0.0221	 bound: 0.7922	 transfer: 0.0453	 finalize: 0.0162
Accumulated time: update_bounds func: 84.0733	 prepare: 2.1814	 bound: 75.8011	 transfer: 0.0453	 finalize: 1.6936
batch bounding time:  0.8767907619476318
Current worst splitting domains [lb, ub] (depth):
[-0.05304,   inf] (27), [-0.05304,   inf] (27), [-0.05304,   inf] (23), [-0.05303,   inf] (23), [-0.05303,   inf] (33), [-0.05303,   inf] (27), [-0.05303,   inf] (27), [-0.05303,   inf] (19), [-0.05303,   inf] (21), [-0.05303,   inf] (23), [-0.05302,   inf] (19), [-0.05302,   inf] (27), [-0.05302,   inf] (25), [-0.05302,   inf] (35), [-0.05302,   inf] (25), [-0.05302,   inf] (23), [-0.05302,   inf] (21), [-0.05302,   inf] (23), [-0.05302,   inf] (33), [-0.05302,   inf] (19), 
length of domains: 5576
Total time: 1.0359	 pickout: 0.0547	 decision: 0.0938	 get_bound: 0.8770	 add_domain: 0.0104
Current lb:-0.053037479519844055
11900 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 105.70663022994995

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 358] [5, 389] [4, 491] [4, 491] [5, 408] [5, 389] [5, 320] [4, 491] [4, 420] [4, 491] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.614924430847168 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 15.838570594787598, 32.75932693481445]
alpha/beta optimization time: 0.8009889125823975
This batch time : update_bounds func: 0.8874	 prepare: 0.0220	 bound: 0.8014	 transfer: 0.0480	 finalize: 0.0155
Accumulated time: update_bounds func: 84.9606	 prepare: 2.2034	 bound: 76.6026	 transfer: 0.0480	 finalize: 1.7091
batch bounding time:  0.8878011703491211
Current worst splitting domains [lb, ub] (depth):
[-0.05295,   inf] (23), [-0.05295,   inf] (41), [-0.05295,   inf] (25), [-0.05295,   inf] (27), [-0.05295,   inf] (29), [-0.05295,   inf] (31), [-0.05295,   inf] (35), [-0.05295,   inf] (23), [-0.05295,   inf] (21), [-0.05295,   inf] (27), [-0.05294,   inf] (21), [-0.05294,   inf] (45), [-0.05294,   inf] (37), [-0.05294,   inf] (23), [-0.05294,   inf] (35), [-0.05294,   inf] (31), [-0.05294,   inf] (25), [-0.05293,   inf] (25), [-0.05293,   inf] (37), [-0.05293,   inf] (27), 
length of domains: 5625
Total time: 1.2596	 pickout: 0.0470	 decision: 0.0967	 get_bound: 0.8880	 add_domain: 0.2279
Current lb:-0.05295371636748314
12028 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 106.96922183036804

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 383] [5, 294] [4, 358] [4, 491] [5, 473] [4, 395] [5, 408] [5, 383] [5, 383] [4, 358] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.931845664978027 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 18.91486358642578, 24.609966278076172]
alpha/beta optimization time: 0.8082945346832275
This batch time : update_bounds func: 0.9110	 prepare: 0.0222	 bound: 0.8088	 transfer: 0.0503	 finalize: 0.0292
Accumulated time: update_bounds func: 85.8716	 prepare: 2.2256	 bound: 77.4114	 transfer: 0.0503	 finalize: 1.7383
batch bounding time:  0.9114720821380615
Current worst splitting domains [lb, ub] (depth):
[-0.05287,   inf] (21), [-0.05286,   inf] (27), [-0.05286,   inf] (27), [-0.05286,   inf] (27), [-0.05286,   inf] (25), [-0.05286,   inf] (23), [-0.05286,   inf] (29), [-0.05285,   inf] (23), [-0.05285,   inf] (27), [-0.05285,   inf] (33), [-0.05285,   inf] (31), [-0.05285,   inf] (27), [-0.05285,   inf] (27), [-0.05285,   inf] (29), [-0.05285,   inf] (29), [-0.05284,   inf] (23), [-0.05284,   inf] (29), [-0.05284,   inf] (25), [-0.05284,   inf] (27), [-0.05284,   inf] (21), 
length of domains: 5678
Total time: 1.0840	 pickout: 0.0655	 decision: 0.0941	 get_bound: 0.9118	 add_domain: 0.0125
Current lb:-0.052866265177726746
12156 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 108.0568675994873

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 491] [4, 359] [4, 358] [5, 389] [5, 383] [4, 491] [5, 320] [4, 491] [4, 358] [5, 320] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.133832931518555 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 12.164529800415039, 25.545249938964844]
alpha/beta optimization time: 0.7950584888458252
This batch time : update_bounds func: 0.8971	 prepare: 0.0339	 bound: 0.7957	 transfer: 0.0452	 finalize: 0.0220
Accumulated time: update_bounds func: 86.7687	 prepare: 2.2594	 bound: 78.2070	 transfer: 0.0452	 finalize: 1.7602
batch bounding time:  0.8975436687469482
Current worst splitting domains [lb, ub] (depth):
[-0.05278,   inf] (29), [-0.05278,   inf] (21), [-0.05277,   inf] (31), [-0.05277,   inf] (23), [-0.05277,   inf] (35), [-0.05277,   inf] (27), [-0.05277,   inf] (21), [-0.05276,   inf] (35), [-0.05276,   inf] (21), [-0.05276,   inf] (27), [-0.05276,   inf] (25), [-0.05276,   inf] (29), [-0.05276,   inf] (29), [-0.05276,   inf] (27), [-0.05276,   inf] (39), [-0.05276,   inf] (21), [-0.05276,   inf] (19), [-0.05276,   inf] (31), [-0.05276,   inf] (23), [-0.05275,   inf] (29), 
length of domains: 5731
Total time: 1.0996	 pickout: 0.0830	 decision: 0.1064	 get_bound: 0.8978	 add_domain: 0.0124
Current lb:-0.052776724100112915
12284 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 109.15932154655457

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [4, 491] [5, 389] [4, 491] [5, 503] [4, 358] [5, 466] [5, 503] [5, 336] [4, 358] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.795620441436768 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 20.48048210144043, 31.018680572509766]
alpha/beta optimization time: 0.818030595779419
This batch time : update_bounds func: 0.9183	 prepare: 0.0338	 bound: 0.8186	 transfer: 0.0491	 finalize: 0.0164
Accumulated time: update_bounds func: 87.6870	 prepare: 2.2933	 bound: 79.0256	 transfer: 0.0491	 finalize: 1.7766
batch bounding time:  0.9188501834869385
Current worst splitting domains [lb, ub] (depth):
[-0.05269,   inf] (23), [-0.05269,   inf] (19), [-0.05269,   inf] (23), [-0.05269,   inf] (21), [-0.05269,   inf] (25), [-0.05268,   inf] (27), [-0.05268,   inf] (41), [-0.05268,   inf] (23), [-0.05268,   inf] (27), [-0.05268,   inf] (29), [-0.05268,   inf] (29), [-0.05268,   inf] (31), [-0.05268,   inf] (25), [-0.05267,   inf] (25), [-0.05267,   inf] (33), [-0.05267,   inf] (27), [-0.05267,   inf] (33), [-0.05267,   inf] (37), [-0.05267,   inf] (21), [-0.05267,   inf] (27), 
length of domains: 5786
Total time: 1.0918	 pickout: 0.0568	 decision: 0.1051	 get_bound: 0.9191	 add_domain: 0.0108
Current lb:-0.05269163101911545
12412 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 110.25405430793762

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 491] [5, 37] [4, 491] [4, 420] [4, 358] [5, 503] [4, 395] [5, 383] [5, 503] [5, 389] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.013195037841797 with beta sum per layer: [0.0, 0.0, 0.0, 0.14723211526870728, 14.663481712341309, 24.655445098876953]
alpha/beta optimization time: 0.7883193492889404
This batch time : update_bounds func: 0.8771	 prepare: 0.0231	 bound: 0.7888	 transfer: 0.0491	 finalize: 0.0156
Accumulated time: update_bounds func: 88.5641	 prepare: 2.3164	 bound: 79.8144	 transfer: 0.0491	 finalize: 1.7923
batch bounding time:  0.8774988651275635
Current worst splitting domains [lb, ub] (depth):
[-0.05261,   inf] (25), [-0.05261,   inf] (27), [-0.05261,   inf] (29), [-0.05260,   inf] (29), [-0.05260,   inf] (19), [-0.05260,   inf] (29), [-0.05260,   inf] (23), [-0.05260,   inf] (19), [-0.05260,   inf] (31), [-0.05260,   inf] (23), [-0.05260,   inf] (23), [-0.05259,   inf] (33), [-0.05259,   inf] (33), [-0.05259,   inf] (33), [-0.05259,   inf] (35), [-0.05259,   inf] (23), [-0.05259,   inf] (29), [-0.05259,   inf] (25), [-0.05259,   inf] (23), [-0.05258,   inf] (25), 
length of domains: 5838
Total time: 1.0405	 pickout: 0.0551	 decision: 0.0961	 get_bound: 0.8777	 add_domain: 0.0115
Current lb:-0.052608393132686615
12540 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 111.29714727401733

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 248] [4, 248] [5, 473] [4, 359] [5, 336] [4, 420] [4, 358] [4, 328] [5, 320] [5, 383] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.991673469543457 with beta sum per layer: [0.0, 0.0, 0.0, 0.19954869151115417, 14.691593170166016, 29.192495346069336]
alpha/beta optimization time: 0.8362348079681396
This batch time : update_bounds func: 0.9253	 prepare: 0.0225	 bound: 0.8367	 transfer: 0.0492	 finalize: 0.0164
Accumulated time: update_bounds func: 89.4894	 prepare: 2.3389	 bound: 80.6511	 transfer: 0.0492	 finalize: 1.8087
batch bounding time:  0.9257018566131592
Current worst splitting domains [lb, ub] (depth):
[-0.05252,   inf] (33), [-0.05251,   inf] (25), [-0.05251,   inf] (27), [-0.05251,   inf] (31), [-0.05251,   inf] (21), [-0.05251,   inf] (27), [-0.05251,   inf] (21), [-0.05251,   inf] (23), [-0.05251,   inf] (29), [-0.05250,   inf] (27), [-0.05250,   inf] (31), [-0.05250,   inf] (21), [-0.05250,   inf] (25), [-0.05249,   inf] (23), [-0.05249,   inf] (33), [-0.05249,   inf] (27), [-0.05249,   inf] (23), [-0.05248,   inf] (25), [-0.05248,   inf] (23), [-0.05248,   inf] (35), 
length of domains: 5891
Total time: 1.1234	 pickout: 0.0916	 decision: 0.0955	 get_bound: 0.9259	 add_domain: 0.0104
Current lb:-0.052515119314193726
12668 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 112.42312359809875

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 358] [4, 491] [4, 358] [5, 503] [5, 336] [4, 420] [4, 491] [4, 491] [5, 473] [5, 389] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.7411065101623535 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 19.263378143310547, 30.588069915771484]
alpha/beta optimization time: 0.8131241798400879
This batch time : update_bounds func: 0.8979	 prepare: 0.0224	 bound: 0.8136	 transfer: 0.0459	 finalize: 0.0155
Accumulated time: update_bounds func: 90.3874	 prepare: 2.3612	 bound: 81.4647	 transfer: 0.0459	 finalize: 1.8242
batch bounding time:  0.8983652591705322
Current worst splitting domains [lb, ub] (depth):
[-0.05241,   inf] (23), [-0.05241,   inf] (21), [-0.05240,   inf] (31), [-0.05240,   inf] (25), [-0.05240,   inf] (43), [-0.05240,   inf] (21), [-0.05240,   inf] (21), [-0.05240,   inf] (43), [-0.05240,   inf] (33), [-0.05240,   inf] (39), [-0.05240,   inf] (41), [-0.05240,   inf] (27), [-0.05240,   inf] (33), [-0.05239,   inf] (29), [-0.05239,   inf] (25), [-0.05239,   inf] (33), [-0.05239,   inf] (21), [-0.05239,   inf] (23), [-0.05239,   inf] (33), [-0.05239,   inf] (25), 
length of domains: 5941
Total time: 1.0631	 pickout: 0.0568	 decision: 0.0965	 get_bound: 0.8986	 add_domain: 0.0112
Current lb:-0.05240523815155029
12796 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 113.48923659324646

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 383] [4, 420] [5, 320] [4, 395] [4, 262] [5, 37] [4, 491] [5, 294] [5, 389] [5, 473] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.423360347747803 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 17.646381378173828, 29.572221755981445]
alpha/beta optimization time: 0.7957429885864258
This batch time : update_bounds func: 0.8847	 prepare: 0.0225	 bound: 0.7962	 transfer: 0.0492	 finalize: 0.0164
Accumulated time: update_bounds func: 91.2721	 prepare: 2.3838	 bound: 82.2610	 transfer: 0.0492	 finalize: 1.8406
batch bounding time:  0.885143518447876
Current worst splitting domains [lb, ub] (depth):
[-0.05234,   inf] (21), [-0.05234,   inf] (27), [-0.05233,   inf] (21), [-0.05233,   inf] (21), [-0.05233,   inf] (21), [-0.05233,   inf] (21), [-0.05233,   inf] (33), [-0.05233,   inf] (35), [-0.05233,   inf] (31), [-0.05233,   inf] (17), [-0.05232,   inf] (27), [-0.05232,   inf] (37), [-0.05232,   inf] (29), [-0.05232,   inf] (27), [-0.05232,   inf] (21), [-0.05232,   inf] (23), [-0.05231,   inf] (39), [-0.05231,   inf] (29), [-0.05231,   inf] (25), [-0.05231,   inf] (31), 
length of domains: 5990
Total time: 1.0544	 pickout: 0.0649	 decision: 0.0936	 get_bound: 0.8854	 add_domain: 0.0105
Current lb:-0.05233580619096756
12924 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 114.54636526107788

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 491] [4, 358] [4, 491] [4, 491] [4, 420] [4, 358] [4, 420] [5, 408] [5, 503] [5, 336] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.580094337463379 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 15.963382720947266, 30.467117309570312]
alpha/beta optimization time: 0.805253267288208
This batch time : update_bounds func: 0.8960	 prepare: 0.0224	 bound: 0.8057	 transfer: 0.0518	 finalize: 0.0156
Accumulated time: update_bounds func: 92.1681	 prepare: 2.4061	 bound: 83.0667	 transfer: 0.0518	 finalize: 1.8562
batch bounding time:  0.896470308303833
Current worst splitting domains [lb, ub] (depth):
[-0.05226,   inf] (31), [-0.05226,   inf] (35), [-0.05226,   inf] (27), [-0.05226,   inf] (33), [-0.05225,   inf] (41), [-0.05225,   inf] (31), [-0.05225,   inf] (25), [-0.05225,   inf] (21), [-0.05225,   inf] (27), [-0.05225,   inf] (23), [-0.05225,   inf] (39), [-0.05224,   inf] (29), [-0.05224,   inf] (21), [-0.05224,   inf] (29), [-0.05224,   inf] (19), [-0.05224,   inf] (35), [-0.05224,   inf] (21), [-0.05224,   inf] (29), [-0.05224,   inf] (23), [-0.05223,   inf] (39), 
length of domains: 6036
Total time: 1.0724	 pickout: 0.0679	 decision: 0.0966	 get_bound: 0.8967	 add_domain: 0.0111
Current lb:-0.05226019024848938
13052 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 115.62161993980408

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 395] [5, 389] [4, 358] [5, 473] [5, 408] [4, 359] [4, 395] [4, 358] [5, 503] [4, 358] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.424661636352539 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 15.490204811096191, 32.161415100097656]
alpha/beta optimization time: 0.7959933280944824
This batch time : update_bounds func: 0.8873	 prepare: 0.0221	 bound: 0.7965	 transfer: 0.0517	 finalize: 0.0166
Accumulated time: update_bounds func: 93.0554	 prepare: 2.4282	 bound: 83.8632	 transfer: 0.0517	 finalize: 1.8728
batch bounding time:  0.8877353668212891
Current worst splitting domains [lb, ub] (depth):
[-0.05217,   inf] (33), [-0.05217,   inf] (17), [-0.05217,   inf] (37), [-0.05217,   inf] (47), [-0.05217,   inf] (23), [-0.05217,   inf] (31), [-0.05217,   inf] (33), [-0.05216,   inf] (27), [-0.05216,   inf] (25), [-0.05216,   inf] (27), [-0.05216,   inf] (23), [-0.05216,   inf] (33), [-0.05216,   inf] (29), [-0.05216,   inf] (29), [-0.05216,   inf] (25), [-0.05216,   inf] (29), [-0.05216,   inf] (37), [-0.05215,   inf] (21), [-0.05215,   inf] (27), [-0.05215,   inf] (25), 
length of domains: 6083
Total time: 1.0394	 pickout: 0.0473	 decision: 0.0942	 get_bound: 0.8880	 add_domain: 0.0099
Current lb:-0.0521748811006546
13180 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 116.6637954711914

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 248] [5, 336] [5, 408] [5, 456] [4, 491] [5, 389] [5, 473] [4, 358] [5, 383] [4, 359] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.977604389190674 with beta sum per layer: [0.0, 0.0, 0.0, 0.44150620698928833, 14.500259399414062, 29.703678131103516]
alpha/beta optimization time: 0.8040540218353271
This batch time : update_bounds func: 0.8914	 prepare: 0.0225	 bound: 0.8045	 transfer: 0.0484	 finalize: 0.0156
Accumulated time: update_bounds func: 93.9469	 prepare: 2.4507	 bound: 84.6677	 transfer: 0.0484	 finalize: 1.8885
batch bounding time:  0.8918609619140625
Current worst splitting domains [lb, ub] (depth):
[-0.05210,   inf] (31), [-0.05209,   inf] (23), [-0.05209,   inf] (33), [-0.05209,   inf] (25), [-0.05209,   inf] (25), [-0.05209,   inf] (31), [-0.05208,   inf] (27), [-0.05208,   inf] (27), [-0.05208,   inf] (25), [-0.05208,   inf] (23), [-0.05208,   inf] (31), [-0.05208,   inf] (19), [-0.05208,   inf] (31), [-0.05208,   inf] (31), [-0.05208,   inf] (27), [-0.05208,   inf] (23), [-0.05208,   inf] (19), [-0.05208,   inf] (21), [-0.05207,   inf] (25), [-0.05207,   inf] (21), 
length of domains: 6138
Total time: 1.0544	 pickout: 0.0542	 decision: 0.0964	 get_bound: 0.8921	 add_domain: 0.0117
Current lb:-0.05209627002477646
13308 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 117.72081136703491

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 359] [4, 491] [4, 359] [4, 358] [4, 359] [5, 473] [4, 358] [5, 503] [5, 383] [5, 383] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.801385879516602 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 14.415660858154297, 31.244924545288086]
alpha/beta optimization time: 0.793351411819458
This batch time : update_bounds func: 0.8785	 prepare: 0.0221	 bound: 0.7938	 transfer: 0.0457	 finalize: 0.0164
Accumulated time: update_bounds func: 94.8254	 prepare: 2.4728	 bound: 85.4616	 transfer: 0.0457	 finalize: 1.9049
batch bounding time:  0.8789269924163818
Current worst splitting domains [lb, ub] (depth):
[-0.05202,   inf] (31), [-0.05202,   inf] (21), [-0.05202,   inf] (29), [-0.05202,   inf] (31), [-0.05202,   inf] (27), [-0.05202,   inf] (23), [-0.05202,   inf] (31), [-0.05202,   inf] (27), [-0.05202,   inf] (25), [-0.05202,   inf] (21), [-0.05201,   inf] (21), [-0.05201,   inf] (23), [-0.05201,   inf] (25), [-0.05201,   inf] (27), [-0.05201,   inf] (25), [-0.05201,   inf] (19), [-0.05201,   inf] (27), [-0.05200,   inf] (25), [-0.05200,   inf] (25), [-0.05200,   inf] (35), 
length of domains: 6190
Total time: 1.0369	 pickout: 0.0535	 decision: 0.0939	 get_bound: 0.8791	 add_domain: 0.0103
Current lb:-0.05202461779117584
13436 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 118.76030993461609

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [4, 420] [5, 320] [4, 359] [4, 358] [4, 491] [5, 389] [4, 395] [5, 383] [4, 420] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.598116397857666 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 15.491586685180664, 29.280502319335938]
alpha/beta optimization time: 0.7909677028656006
This batch time : update_bounds func: 0.8782	 prepare: 0.0221	 bound: 0.7914	 transfer: 0.0486	 finalize: 0.0156
Accumulated time: update_bounds func: 95.7037	 prepare: 2.4949	 bound: 86.2530	 transfer: 0.0486	 finalize: 1.9205
batch bounding time:  0.8786559104919434
Current worst splitting domains [lb, ub] (depth):
[-0.05195,   inf] (37), [-0.05195,   inf] (33), [-0.05195,   inf] (25), [-0.05195,   inf] (31), [-0.05195,   inf] (25), [-0.05195,   inf] (31), [-0.05195,   inf] (37), [-0.05195,   inf] (23), [-0.05195,   inf] (31), [-0.05195,   inf] (27), [-0.05195,   inf] (35), [-0.05195,   inf] (27), [-0.05195,   inf] (37), [-0.05195,   inf] (21), [-0.05194,   inf] (31), [-0.05194,   inf] (23), [-0.05194,   inf] (23), [-0.05194,   inf] (31), [-0.05194,   inf] (23), [-0.05194,   inf] (21), 
length of domains: 6241
Total time: 1.0442	 pickout: 0.0573	 decision: 0.0964	 get_bound: 0.8789	 add_domain: 0.0117
Current lb:-0.051954805850982666
13564 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 119.8072247505188

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 389] [5, 389] [5, 383] [4, 359] [4, 420] [5, 389] [5, 408] [4, 420] [5, 503] [4, 358] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.45351505279541 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 16.856281280517578, 30.282512664794922]
alpha/beta optimization time: 0.7863342761993408
This batch time : update_bounds func: 1.1415	 prepare: 0.0221	 bound: 0.7868	 transfer: 0.0484	 finalize: 0.2837
Accumulated time: update_bounds func: 96.8451	 prepare: 2.5170	 bound: 87.0398	 transfer: 0.0484	 finalize: 2.2042
batch bounding time:  1.141969919204712
Current worst splitting domains [lb, ub] (depth):
[-0.05188,   inf] (31), [-0.05188,   inf] (25), [-0.05187,   inf] (23), [-0.05187,   inf] (31), [-0.05187,   inf] (37), [-0.05187,   inf] (27), [-0.05187,   inf] (39), [-0.05187,   inf] (29), [-0.05187,   inf] (33), [-0.05187,   inf] (23), [-0.05187,   inf] (27), [-0.05187,   inf] (29), [-0.05187,   inf] (29), [-0.05187,   inf] (33), [-0.05186,   inf] (23), [-0.05186,   inf] (29), [-0.05186,   inf] (23), [-0.05186,   inf] (23), [-0.05185,   inf] (33), [-0.05185,   inf] (23), 
length of domains: 6287
Total time: 1.2984	 pickout: 0.0514	 decision: 0.0949	 get_bound: 1.1422	 add_domain: 0.0100
Current lb:-0.05187661945819855
13692 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 121.10849618911743

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 503] [5, 383] [4, 358] [4, 248] [4, 359] [5, 503] [5, 389] [4, 420] [5, 473] [5, 383] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.105646133422852 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 13.24283218383789, 26.885459899902344]
alpha/beta optimization time: 0.7887415885925293
This batch time : update_bounds func: 0.8769	 prepare: 0.0221	 bound: 0.7892	 transfer: 0.0485	 finalize: 0.0157
Accumulated time: update_bounds func: 97.7220	 prepare: 2.5392	 bound: 87.8290	 transfer: 0.0485	 finalize: 2.2198
batch bounding time:  0.8772623538970947
Current worst splitting domains [lb, ub] (depth):
[-0.05180,   inf] (29), [-0.05179,   inf] (29), [-0.05179,   inf] (19), [-0.05179,   inf] (41), [-0.05179,   inf] (31), [-0.05179,   inf] (39), [-0.05179,   inf] (27), [-0.05179,   inf] (25), [-0.05178,   inf] (21), [-0.05178,   inf] (27), [-0.05178,   inf] (33), [-0.05178,   inf] (23), [-0.05178,   inf] (25), [-0.05178,   inf] (29), [-0.05178,   inf] (23), [-0.05178,   inf] (31), [-0.05178,   inf] (27), [-0.05177,   inf] (33), [-0.05177,   inf] (29), [-0.05177,   inf] (43), 
length of domains: 6344
Total time: 1.0523	 pickout: 0.0691	 decision: 0.0948	 get_bound: 0.8775	 add_domain: 0.0109
Current lb:-0.051797688007354736
13820 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 122.16346526145935

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [5, 389] [5, 37] [5, 496] [5, 320] [4, 420] [4, 358] [4, 358] [4, 420] [5, 320] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.481387615203857 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 19.456562042236328, 31.873836517333984]
alpha/beta optimization time: 0.8066065311431885
This batch time : update_bounds func: 0.8942	 prepare: 0.0222	 bound: 0.8071	 transfer: 0.0484	 finalize: 0.0160
Accumulated time: update_bounds func: 98.6162	 prepare: 2.5614	 bound: 88.6361	 transfer: 0.0484	 finalize: 2.2359
batch bounding time:  0.894627571105957
Current worst splitting domains [lb, ub] (depth):
[-0.05172,   inf] (27), [-0.05172,   inf] (27), [-0.05172,   inf] (21), [-0.05172,   inf] (25), [-0.05172,   inf] (35), [-0.05171,   inf] (25), [-0.05171,   inf] (27), [-0.05171,   inf] (29), [-0.05171,   inf] (25), [-0.05171,   inf] (29), [-0.05170,   inf] (21), [-0.05170,   inf] (29), [-0.05170,   inf] (31), [-0.05170,   inf] (35), [-0.05170,   inf] (21), [-0.05170,   inf] (31), [-0.05170,   inf] (25), [-0.05169,   inf] (33), [-0.05169,   inf] (21), [-0.05169,   inf] (31), 
length of domains: 6395
Total time: 1.0547	 pickout: 0.0530	 decision: 0.0963	 get_bound: 0.8949	 add_domain: 0.0105
Current lb:-0.05172086879611015
13948 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 123.22084069252014

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 389] [4, 358] [4, 420] [4, 358] [4, 359] [5, 320] [4, 420] [4, 358] [5, 389] [5, 320] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.051137924194336 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 12.264328956604004, 26.53448486328125]
alpha/beta optimization time: 0.8203291893005371
This batch time : update_bounds func: 0.9086	 prepare: 0.0221	 bound: 0.8208	 transfer: 0.0486	 finalize: 0.0158
Accumulated time: update_bounds func: 99.5248	 prepare: 2.5835	 bound: 89.4569	 transfer: 0.0486	 finalize: 2.2517
batch bounding time:  0.9089882373809814
Current worst splitting domains [lb, ub] (depth):
[-0.05165,   inf] (25), [-0.05165,   inf] (51), [-0.05165,   inf] (25), [-0.05165,   inf] (27), [-0.05165,   inf] (31), [-0.05165,   inf] (23), [-0.05164,   inf] (27), [-0.05164,   inf] (23), [-0.05164,   inf] (27), [-0.05164,   inf] (31), [-0.05164,   inf] (43), [-0.05163,   inf] (25), [-0.05163,   inf] (27), [-0.05163,   inf] (35), [-0.05163,   inf] (29), [-0.05163,   inf] (25), [-0.05163,   inf] (35), [-0.05163,   inf] (25), [-0.05162,   inf] (25), [-0.05162,   inf] (31), 
length of domains: 6449
Total time: 1.0635	 pickout: 0.0481	 decision: 0.0955	 get_bound: 0.9092	 add_domain: 0.0108
Current lb:-0.05164831876754761
14076 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 124.28714990615845

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 389] [4, 359] [5, 383] [4, 358] [5, 320] [5, 383] [4, 358] [4, 491] [5, 503] [5, 503] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.857568740844727 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 15.94167423248291, 27.32607650756836]
alpha/beta optimization time: 0.7903978824615479
This batch time : update_bounds func: 0.8782	 prepare: 0.0221	 bound: 0.7908	 transfer: 0.0484	 finalize: 0.0164
Accumulated time: update_bounds func: 100.4030	 prepare: 2.6056	 bound: 90.2477	 transfer: 0.0484	 finalize: 2.2681
batch bounding time:  0.8786275386810303
Current worst splitting domains [lb, ub] (depth):
[-0.05157,   inf] (27), [-0.05157,   inf] (25), [-0.05157,   inf] (29), [-0.05157,   inf] (31), [-0.05156,   inf] (23), [-0.05156,   inf] (25), [-0.05156,   inf] (23), [-0.05155,   inf] (27), [-0.05155,   inf] (27), [-0.05155,   inf] (29), [-0.05155,   inf] (23), [-0.05155,   inf] (27), [-0.05155,   inf] (25), [-0.05155,   inf] (23), [-0.05155,   inf] (39), [-0.05155,   inf] (29), [-0.05155,   inf] (27), [-0.05155,   inf] (21), [-0.05155,   inf] (39), [-0.05155,   inf] (29), 
length of domains: 6502
Total time: 1.0386	 pickout: 0.0528	 decision: 0.0962	 get_bound: 0.8789	 add_domain: 0.0108
Current lb:-0.05156621336936951
14204 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 125.32840204238892

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 358] [5, 383] [5, 503] [5, 503] [4, 491] [5, 389] [4, 491] [4, 359] [4, 420] [5, 320] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.527830600738525 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 14.53902816772461, 31.26144027709961]
alpha/beta optimization time: 0.8081381320953369
This batch time : update_bounds func: 0.8962	 prepare: 0.0223	 bound: 0.8086	 transfer: 0.0484	 finalize: 0.0156
Accumulated time: update_bounds func: 101.2991	 prepare: 2.6279	 bound: 91.0563	 transfer: 0.0484	 finalize: 2.2837
batch bounding time:  0.8965916633605957
Current worst splitting domains [lb, ub] (depth):
[-0.05149,   inf] (39), [-0.05149,   inf] (31), [-0.05149,   inf] (23), [-0.05149,   inf] (25), [-0.05149,   inf] (19), [-0.05148,   inf] (21), [-0.05148,   inf] (23), [-0.05148,   inf] (23), [-0.05148,   inf] (29), [-0.05148,   inf] (21), [-0.05148,   inf] (21), [-0.05148,   inf] (27), [-0.05148,   inf] (31), [-0.05148,   inf] (23), [-0.05148,   inf] (35), [-0.05147,   inf] (29), [-0.05147,   inf] (35), [-0.05147,   inf] (21), [-0.05147,   inf] (23), [-0.05147,   inf] (21), 
length of domains: 6548
Total time: 1.0539	 pickout: 0.0528	 decision: 0.0943	 get_bound: 0.8968	 add_domain: 0.0100
Current lb:-0.051486313343048096
14332 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 126.38566493988037

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 473] [4, 359] [5, 383] [5, 320] [4, 420] [4, 491] [5, 383] [5, 383] [5, 320] [4, 420] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.761620044708252 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 14.929930686950684, 28.872150421142578]
alpha/beta optimization time: 0.8007650375366211
This batch time : update_bounds func: 0.9012	 prepare: 0.0220	 bound: 0.8012	 transfer: 0.0474	 finalize: 0.0302
Accumulated time: update_bounds func: 102.2004	 prepare: 2.6499	 bound: 91.8575	 transfer: 0.0474	 finalize: 2.3139
batch bounding time:  0.9018852710723877
Current worst splitting domains [lb, ub] (depth):
[-0.05143,   inf] (31), [-0.05143,   inf] (35), [-0.05143,   inf] (25), [-0.05143,   inf] (23), [-0.05142,   inf] (25), [-0.05142,   inf] (33), [-0.05142,   inf] (23), [-0.05142,   inf] (31), [-0.05142,   inf] (35), [-0.05142,   inf] (23), [-0.05142,   inf] (39), [-0.05142,   inf] (21), [-0.05142,   inf] (35), [-0.05141,   inf] (33), [-0.05141,   inf] (27), [-0.05141,   inf] (33), [-0.05141,   inf] (27), [-0.05141,   inf] (19), [-0.05141,   inf] (31), [-0.05141,   inf] (21), 
length of domains: 6600
Total time: 1.0933	 pickout: 0.0831	 decision: 0.0964	 get_bound: 0.9023	 add_domain: 0.0115
Current lb:-0.051429539918899536
14460 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 127.4816517829895

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 358] [5, 389] [5, 383] [4, 359] [5, 383] [5, 503] [4, 491] [5, 320] [4, 395] [4, 491] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.7122697830200195 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 15.710111618041992, 32.08735275268555]
alpha/beta optimization time: 0.7916548252105713
This batch time : update_bounds func: 0.8802	 prepare: 0.0221	 bound: 0.7921	 transfer: 0.0486	 finalize: 0.0169
Accumulated time: update_bounds func: 103.0806	 prepare: 2.6720	 bound: 92.6497	 transfer: 0.0486	 finalize: 2.3308
batch bounding time:  0.8806846141815186
Current worst splitting domains [lb, ub] (depth):
[-0.05136,   inf] (27), [-0.05136,   inf] (47), [-0.05135,   inf] (27), [-0.05135,   inf] (23), [-0.05135,   inf] (23), [-0.05135,   inf] (31), [-0.05134,   inf] (27), [-0.05134,   inf] (23), [-0.05134,   inf] (27), [-0.05134,   inf] (25), [-0.05134,   inf] (23), [-0.05134,   inf] (27), [-0.05134,   inf] (29), [-0.05134,   inf] (33), [-0.05133,   inf] (35), [-0.05133,   inf] (35), [-0.05133,   inf] (23), [-0.05133,   inf] (31), [-0.05133,   inf] (29), [-0.05133,   inf] (25), 
length of domains: 6651
Total time: 1.0432	 pickout: 0.0570	 decision: 0.0949	 get_bound: 0.8809	 add_domain: 0.0104
Current lb:-0.05135650932788849
14588 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 128.52773261070251

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 358] [5, 456] [4, 358] [5, 383] [5, 383] [4, 248] [4, 358] [5, 383] [4, 359] [4, 358] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.7899603843688965 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 18.544139862060547, 28.597057342529297]
alpha/beta optimization time: 0.795520544052124
This batch time : update_bounds func: 0.8844	 prepare: 0.0225	 bound: 0.7960	 transfer: 0.0488	 finalize: 0.0166
Accumulated time: update_bounds func: 103.9650	 prepare: 2.6945	 bound: 93.4457	 transfer: 0.0488	 finalize: 2.3474
batch bounding time:  0.884789228439331
Current worst splitting domains [lb, ub] (depth):
[-0.05127,   inf] (31), [-0.05127,   inf] (33), [-0.05127,   inf] (37), [-0.05127,   inf] (31), [-0.05127,   inf] (27), [-0.05127,   inf] (29), [-0.05126,   inf] (29), [-0.05126,   inf] (43), [-0.05126,   inf] (27), [-0.05126,   inf] (41), [-0.05126,   inf] (45), [-0.05126,   inf] (25), [-0.05126,   inf] (37), [-0.05126,   inf] (21), [-0.05126,   inf] (29), [-0.05125,   inf] (23), [-0.05125,   inf] (29), [-0.05125,   inf] (27), [-0.05125,   inf] (31), [-0.05125,   inf] (23), 
length of domains: 6704
Total time: 1.0448	 pickout: 0.0526	 decision: 0.0967	 get_bound: 0.8850	 add_domain: 0.0105
Current lb:-0.05127130448818207
14716 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 129.57532167434692

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [4, 359] [5, 473] [5, 503] [5, 383] [5, 320] [4, 248] [5, 294] [5, 473] [4, 262] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.800990581512451 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 13.625007629394531, 26.137157440185547]
alpha/beta optimization time: 0.8196537494659424
This batch time : update_bounds func: 0.9115	 prepare: 0.0227	 bound: 0.8202	 transfer: 0.0517	 finalize: 0.0166
Accumulated time: update_bounds func: 104.8765	 prepare: 2.7172	 bound: 94.2658	 transfer: 0.0517	 finalize: 2.3640
batch bounding time:  0.911961555480957
Current worst splitting domains [lb, ub] (depth):
[-0.05119,   inf] (25), [-0.05119,   inf] (27), [-0.05119,   inf] (21), [-0.05119,   inf] (23), [-0.05119,   inf] (35), [-0.05119,   inf] (25), [-0.05119,   inf] (31), [-0.05119,   inf] (25), [-0.05119,   inf] (27), [-0.05119,   inf] (25), [-0.05119,   inf] (27), [-0.05118,   inf] (33), [-0.05118,   inf] (21), [-0.05118,   inf] (35), [-0.05118,   inf] (25), [-0.05118,   inf] (35), [-0.05118,   inf] (43), [-0.05118,   inf] (29), [-0.05118,   inf] (29), [-0.05118,   inf] (31), 
length of domains: 6754
Total time: 1.0745	 pickout: 0.0563	 decision: 0.0954	 get_bound: 0.9122	 add_domain: 0.0107
Current lb:-0.051192671060562134
14844 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 130.65286231040955

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 358] [4, 395] [4, 420] [4, 491] [5, 408] [4, 395] [5, 389] [4, 358] [4, 359] [5, 383] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.44426155090332 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 17.074817657470703, 32.570072174072266]
alpha/beta optimization time: 0.8049371242523193
This batch time : update_bounds func: 0.8906	 prepare: 0.0222	 bound: 0.8054	 transfer: 0.0462	 finalize: 0.0163
Accumulated time: update_bounds func: 105.7671	 prepare: 2.7394	 bound: 95.0712	 transfer: 0.0462	 finalize: 2.3803
batch bounding time:  0.8910088539123535
Current worst splitting domains [lb, ub] (depth):
[-0.05113,   inf] (31), [-0.05113,   inf] (27), [-0.05113,   inf] (41), [-0.05113,   inf] (37), [-0.05112,   inf] (39), [-0.05112,   inf] (31), [-0.05112,   inf] (31), [-0.05112,   inf] (33), [-0.05112,   inf] (21), [-0.05112,   inf] (23), [-0.05112,   inf] (25), [-0.05112,   inf] (29), [-0.05112,   inf] (27), [-0.05112,   inf] (31), [-0.05112,   inf] (41), [-0.05112,   inf] (27), [-0.05111,   inf] (29), [-0.05111,   inf] (23), [-0.05111,   inf] (21), [-0.05111,   inf] (23), 
length of domains: 6803
Total time: 1.0536	 pickout: 0.0551	 decision: 0.0970	 get_bound: 0.8912	 add_domain: 0.0103
Current lb:-0.05113145709037781
14972 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 131.709557056427

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [4, 358] [5, 294] [5, 473] [5, 496] [4, 358] [4, 420] [5, 320] [4, 491] [4, 491] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.724809646606445 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 16.3134822845459, 27.75768280029297]
alpha/beta optimization time: 0.7954144477844238
This batch time : update_bounds func: 0.8845	 prepare: 0.0227	 bound: 0.7959	 transfer: 0.0488	 finalize: 0.0166
Accumulated time: update_bounds func: 106.6516	 prepare: 2.7621	 bound: 95.8671	 transfer: 0.0488	 finalize: 2.3969
batch bounding time:  0.8849291801452637
Current worst splitting domains [lb, ub] (depth):
[-0.05106,   inf] (25), [-0.05106,   inf] (31), [-0.05106,   inf] (21), [-0.05105,   inf] (21), [-0.05105,   inf] (27), [-0.05105,   inf] (23), [-0.05105,   inf] (23), [-0.05104,   inf] (29), [-0.05104,   inf] (37), [-0.05104,   inf] (27), [-0.05104,   inf] (35), [-0.05104,   inf] (27), [-0.05104,   inf] (31), [-0.05103,   inf] (27), [-0.05103,   inf] (33), [-0.05103,   inf] (41), [-0.05103,   inf] (29), [-0.05103,   inf] (27), [-0.05103,   inf] (19), [-0.05103,   inf] (29), 
length of domains: 6854
Total time: 1.0517	 pickout: 0.0601	 decision: 0.0957	 get_bound: 0.8852	 add_domain: 0.0107
Current lb:-0.05106018856167793
15100 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 132.76413822174072

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 383] [4, 359] [5, 336] [4, 491] [4, 395] [5, 383] [5, 383] [4, 359] [5, 503] [4, 359] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.6739654541015625 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 14.455501556396484, 30.046388626098633]
alpha/beta optimization time: 0.7963988780975342
This batch time : update_bounds func: 0.8907	 prepare: 0.0224	 bound: 0.7970	 transfer: 0.0544	 finalize: 0.0165
Accumulated time: update_bounds func: 107.5423	 prepare: 2.7845	 bound: 96.6641	 transfer: 0.0544	 finalize: 2.4134
batch bounding time:  0.8911182880401611
Current worst splitting domains [lb, ub] (depth):
[-0.05097,   inf] (27), [-0.05097,   inf] (29), [-0.05097,   inf] (29), [-0.05097,   inf] (33), [-0.05096,   inf] (23), [-0.05096,   inf] (23), [-0.05096,   inf] (25), [-0.05096,   inf] (37), [-0.05096,   inf] (25), [-0.05096,   inf] (35), [-0.05096,   inf] (35), [-0.05096,   inf] (37), [-0.05096,   inf] (25), [-0.05096,   inf] (41), [-0.05096,   inf] (21), [-0.05096,   inf] (23), [-0.05096,   inf] (43), [-0.05096,   inf] (31), [-0.05096,   inf] (25), [-0.05095,   inf] (31), 
length of domains: 6904
Total time: 1.0978	 pickout: 0.1001	 decision: 0.0959	 get_bound: 0.8914	 add_domain: 0.0105
Current lb:-0.050968050956726074
15228 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 133.86482858657837

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 383] [5, 389] [4, 420] [4, 359] [4, 420] [5, 383] [5, 383] [5, 473] [4, 420] [4, 359] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.526205062866211 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 17.19668197631836, 30.449386596679688]
alpha/beta optimization time: 0.7912263870239258
This batch time : update_bounds func: 0.8757	 prepare: 0.0222	 bound: 0.7917	 transfer: 0.0449	 finalize: 0.0165
Accumulated time: update_bounds func: 108.4179	 prepare: 2.8067	 bound: 97.4558	 transfer: 0.0449	 finalize: 2.4299
batch bounding time:  0.8760957717895508
Current worst splitting domains [lb, ub] (depth):
[-0.05091,   inf] (33), [-0.05091,   inf] (33), [-0.05091,   inf] (23), [-0.05091,   inf] (23), [-0.05091,   inf] (29), [-0.05091,   inf] (25), [-0.05090,   inf] (23), [-0.05090,   inf] (29), [-0.05090,   inf] (29), [-0.05090,   inf] (21), [-0.05090,   inf] (25), [-0.05090,   inf] (25), [-0.05090,   inf] (23), [-0.05090,   inf] (49), [-0.05089,   inf] (35), [-0.05089,   inf] (31), [-0.05089,   inf] (31), [-0.05089,   inf] (27), [-0.05089,   inf] (33), [-0.05089,   inf] (27), 
length of domains: 6952
Total time: 1.0492	 pickout: 0.0684	 decision: 0.0942	 get_bound: 0.8763	 add_domain: 0.0103
Current lb:-0.05091002583503723
15356 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 134.9168725013733

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 473] [5, 389] [4, 359] [5, 383] [5, 473] [5, 383] [4, 491] [5, 383] [5, 389] [5, 466] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.615303039550781 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 16.096294403076172, 27.89175033569336]
alpha/beta optimization time: 0.791386604309082
This batch time : update_bounds func: 0.8822	 prepare: 0.0222	 bound: 0.7919	 transfer: 0.0519	 finalize: 0.0158
Accumulated time: update_bounds func: 109.3002	 prepare: 2.8289	 bound: 98.2477	 transfer: 0.0519	 finalize: 2.4457
batch bounding time:  0.8826608657836914
Current worst splitting domains [lb, ub] (depth):
[-0.05085,   inf] (27), [-0.05085,   inf] (31), [-0.05085,   inf] (21), [-0.05085,   inf] (37), [-0.05085,   inf] (23), [-0.05085,   inf] (33), [-0.05085,   inf] (23), [-0.05084,   inf] (21), [-0.05084,   inf] (33), [-0.05084,   inf] (25), [-0.05084,   inf] (35), [-0.05084,   inf] (29), [-0.05084,   inf] (27), [-0.05084,   inf] (27), [-0.05084,   inf] (21), [-0.05084,   inf] (31), [-0.05084,   inf] (29), [-0.05083,   inf] (27), [-0.05083,   inf] (25), [-0.05083,   inf] (27), 
length of domains: 7002
Total time: 1.3260	 pickout: 0.0590	 decision: 0.0973	 get_bound: 0.8829	 add_domain: 0.2867
Current lb:-0.05084827542304993
15484 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 136.24580931663513

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 395] [5, 389] [4, 420] [5, 473] [4, 395] [5, 503] [4, 491] [4, 491] [5, 320] [4, 358] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.509852409362793 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 14.610837936401367, 30.94430160522461]
alpha/beta optimization time: 0.7900259494781494
This batch time : update_bounds func: 0.8787	 prepare: 0.0222	 bound: 0.7905	 transfer: 0.0489	 finalize: 0.0166
Accumulated time: update_bounds func: 110.1789	 prepare: 2.8512	 bound: 99.0382	 transfer: 0.0489	 finalize: 2.4623
batch bounding time:  0.8791766166687012
Current worst splitting domains [lb, ub] (depth):
[-0.05078,   inf] (25), [-0.05078,   inf] (29), [-0.05078,   inf] (23), [-0.05078,   inf] (31), [-0.05078,   inf] (33), [-0.05078,   inf] (35), [-0.05078,   inf] (25), [-0.05078,   inf] (25), [-0.05078,   inf] (23), [-0.05078,   inf] (35), [-0.05078,   inf] (31), [-0.05078,   inf] (35), [-0.05078,   inf] (23), [-0.05078,   inf] (37), [-0.05078,   inf] (25), [-0.05077,   inf] (23), [-0.05077,   inf] (27), [-0.05077,   inf] (31), [-0.05077,   inf] (25), [-0.05077,   inf] (29), 
length of domains: 7052
Total time: 1.0394	 pickout: 0.0547	 decision: 0.0950	 get_bound: 0.8794	 add_domain: 0.0104
Current lb:-0.05078446865081787
15612 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 137.28805541992188

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 383] [5, 320] [5, 383] [4, 359] [4, 359] [5, 473] [4, 491] [5, 383] [4, 358] [5, 408] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.4729533195495605 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 16.144710540771484, 29.079814910888672]
alpha/beta optimization time: 0.7825748920440674
This batch time : update_bounds func: 0.8726	 prepare: 0.0225	 bound: 0.7831	 transfer: 0.0507	 finalize: 0.0159
Accumulated time: update_bounds func: 111.0515	 prepare: 2.8736	 bound: 99.8213	 transfer: 0.0507	 finalize: 2.4781
batch bounding time:  0.8731660842895508
Current worst splitting domains [lb, ub] (depth):
[-0.05073,   inf] (27), [-0.05073,   inf] (29), [-0.05072,   inf] (27), [-0.05072,   inf] (27), [-0.05072,   inf] (25), [-0.05072,   inf] (29), [-0.05072,   inf] (31), [-0.05072,   inf] (31), [-0.05072,   inf] (23), [-0.05072,   inf] (25), [-0.05072,   inf] (31), [-0.05072,   inf] (29), [-0.05072,   inf] (33), [-0.05071,   inf] (37), [-0.05071,   inf] (25), [-0.05071,   inf] (27), [-0.05071,   inf] (21), [-0.05071,   inf] (29), [-0.05071,   inf] (21), [-0.05071,   inf] (23), 
length of domains: 7100
Total time: 1.0424	 pickout: 0.0583	 decision: 0.0987	 get_bound: 0.8734	 add_domain: 0.0120
Current lb:-0.050729960203170776
15740 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 138.33374214172363

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 389] [5, 473] [5, 503] [4, 358] [4, 358] [5, 473] [4, 358] [4, 359] [4, 491] [4, 491] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.49595832824707 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 23.066909790039062, 30.56938934326172]
alpha/beta optimization time: 0.7928967475891113
This batch time : update_bounds func: 0.8820	 prepare: 0.0227	 bound: 0.7934	 transfer: 0.0485	 finalize: 0.0170
Accumulated time: update_bounds func: 111.9335	 prepare: 2.8963	 bound: 100.6147	 transfer: 0.0485	 finalize: 2.4951
batch bounding time:  0.8824474811553955
Current worst splitting domains [lb, ub] (depth):
[-0.05067,   inf] (29), [-0.05066,   inf] (23), [-0.05066,   inf] (27), [-0.05066,   inf] (31), [-0.05066,   inf] (25), [-0.05066,   inf] (31), [-0.05066,   inf] (29), [-0.05066,   inf] (23), [-0.05066,   inf] (25), [-0.05066,   inf] (35), [-0.05065,   inf] (23), [-0.05065,   inf] (25), [-0.05065,   inf] (31), [-0.05065,   inf] (41), [-0.05065,   inf] (27), [-0.05065,   inf] (25), [-0.05065,   inf] (23), [-0.05065,   inf] (31), [-0.05065,   inf] (29), [-0.05065,   inf] (27), 
length of domains: 7149
Total time: 1.0604	 pickout: 0.0693	 decision: 0.0977	 get_bound: 0.8827	 add_domain: 0.0107
Current lb:-0.05066545680165291
15868 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 139.39712285995483

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 389] [5, 383] [4, 395] [5, 389] [5, 383] [5, 503] [5, 389] [5, 383] [4, 359] [5, 473] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.395063400268555 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 16.08008575439453, 29.31500244140625]
alpha/beta optimization time: 0.7883138656616211
This batch time : update_bounds func: 0.8715	 prepare: 0.0218	 bound: 0.7888	 transfer: 0.0449	 finalize: 0.0157
Accumulated time: update_bounds func: 112.8050	 prepare: 2.9182	 bound: 101.4034	 transfer: 0.0449	 finalize: 2.5108
batch bounding time:  0.8719758987426758
Current worst splitting domains [lb, ub] (depth):
[-0.05060,   inf] (25), [-0.05060,   inf] (25), [-0.05060,   inf] (27), [-0.05060,   inf] (33), [-0.05060,   inf] (31), [-0.05059,   inf] (31), [-0.05059,   inf] (23), [-0.05059,   inf] (27), [-0.05059,   inf] (31), [-0.05059,   inf] (25), [-0.05058,   inf] (37), [-0.05058,   inf] (25), [-0.05058,   inf] (29), [-0.05058,   inf] (21), [-0.05058,   inf] (23), [-0.05058,   inf] (25), [-0.05058,   inf] (25), [-0.05058,   inf] (29), [-0.05058,   inf] (27), [-0.05058,   inf] (21), 
length of domains: 7196
Total time: 1.0365	 pickout: 0.0572	 decision: 0.0950	 get_bound: 0.8722	 add_domain: 0.0121
Current lb:-0.05060166120529175
15996 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 140.43666529655457

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 420] [5, 383] [5, 473] [5, 389] [4, 420] [4, 358] [5, 383] [4, 359] [5, 503] [5, 383] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.778542995452881 with beta sum per layer: [0.0, 0.0, 0.0, 0.10440043359994888, 16.351682662963867, 30.613616943359375]
alpha/beta optimization time: 0.8021595478057861
This batch time : update_bounds func: 0.8958	 prepare: 0.0225	 bound: 0.8026	 transfer: 0.0535	 finalize: 0.0168
Accumulated time: update_bounds func: 113.7008	 prepare: 2.9407	 bound: 102.2061	 transfer: 0.0535	 finalize: 2.5276
batch bounding time:  0.8961930274963379
Current worst splitting domains [lb, ub] (depth):
[-0.05052,   inf] (35), [-0.05052,   inf] (25), [-0.05052,   inf] (39), [-0.05052,   inf] (21), [-0.05052,   inf] (39), [-0.05051,   inf] (21), [-0.05051,   inf] (25), [-0.05051,   inf] (39), [-0.05051,   inf] (19), [-0.05051,   inf] (27), [-0.05051,   inf] (21), [-0.05051,   inf] (29), [-0.05051,   inf] (17), [-0.05051,   inf] (31), [-0.05051,   inf] (25), [-0.05050,   inf] (25), [-0.05050,   inf] (23), [-0.05050,   inf] (21), [-0.05050,   inf] (25), [-0.05050,   inf] (29), 
length of domains: 7251
Total time: 1.0513	 pickout: 0.0492	 decision: 0.0946	 get_bound: 0.8964	 add_domain: 0.0110
Current lb:-0.05052226781845093
16124 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 141.4905207157135

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 389] [4, 420] [4, 395] [4, 358] [4, 358] [4, 491] [5, 383] [5, 473] [5, 37] [4, 358] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.308692932128906 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 15.196910858154297, 31.003015518188477]
alpha/beta optimization time: 0.812821626663208
This batch time : update_bounds func: 0.8999	 prepare: 0.0222	 bound: 0.8133	 transfer: 0.0459	 finalize: 0.0180
Accumulated time: update_bounds func: 114.6007	 prepare: 2.9629	 bound: 103.0194	 transfer: 0.0459	 finalize: 2.5456
batch bounding time:  0.9004168510437012
Current worst splitting domains [lb, ub] (depth):
[-0.05045,   inf] (33), [-0.05045,   inf] (35), [-0.05045,   inf] (29), [-0.05045,   inf] (47), [-0.05045,   inf] (33), [-0.05044,   inf] (31), [-0.05044,   inf] (33), [-0.05044,   inf] (29), [-0.05044,   inf] (25), [-0.05044,   inf] (23), [-0.05044,   inf] (29), [-0.05044,   inf] (31), [-0.05043,   inf] (21), [-0.05043,   inf] (31), [-0.05043,   inf] (27), [-0.05043,   inf] (31), [-0.05043,   inf] (27), [-0.05043,   inf] (29), [-0.05043,   inf] (27), [-0.05043,   inf] (25), 
length of domains: 7295
Total time: 1.0599	 pickout: 0.0513	 decision: 0.0954	 get_bound: 0.9007	 add_domain: 0.0124
Current lb:-0.05045115947723389
16252 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 142.554945230484

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 389] [5, 473] [4, 420] [4, 248] [5, 473] [4, 358] [4, 420] [4, 358] [4, 358] [5, 383] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.4789228439331055 with beta sum per layer: [0.0, 0.0, 0.0, 0.36866503953933716, 17.119535446166992, 28.582717895507812]
alpha/beta optimization time: 0.8072082996368408
This batch time : update_bounds func: 0.8964	 prepare: 0.0228	 bound: 0.8077	 transfer: 0.0489	 finalize: 0.0166
Accumulated time: update_bounds func: 115.4971	 prepare: 2.9856	 bound: 103.8271	 transfer: 0.0489	 finalize: 2.5622
batch bounding time:  0.8967897891998291
Current worst splitting domains [lb, ub] (depth):
[-0.05038,   inf] (23), [-0.05038,   inf] (29), [-0.05038,   inf] (29), [-0.05038,   inf] (37), [-0.05038,   inf] (31), [-0.05038,   inf] (23), [-0.05038,   inf] (39), [-0.05038,   inf] (33), [-0.05038,   inf] (23), [-0.05038,   inf] (21), [-0.05038,   inf] (35), [-0.05037,   inf] (33), [-0.05037,   inf] (37), [-0.05037,   inf] (23), [-0.05037,   inf] (31), [-0.05037,   inf] (35), [-0.05037,   inf] (27), [-0.05037,   inf] (29), [-0.05037,   inf] (25), [-0.05037,   inf] (29), 
length of domains: 7342
Total time: 1.0990	 pickout: 0.0951	 decision: 0.0961	 get_bound: 0.8970	 add_domain: 0.0108
Current lb:-0.050382763147354126
16380 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 143.65691804885864

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 358] [4, 359] [4, 358] [5, 473] [5, 503] [5, 383] [4, 358] [4, 491] [4, 358] [4, 491] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.386089324951172 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 17.663198471069336, 32.07942199707031]
alpha/beta optimization time: 0.7923333644866943
This batch time : update_bounds func: 0.8814	 prepare: 0.0225	 bound: 0.7928	 transfer: 0.0486	 finalize: 0.0171
Accumulated time: update_bounds func: 116.3785	 prepare: 3.0081	 bound: 104.6199	 transfer: 0.0486	 finalize: 2.5792
batch bounding time:  0.881821870803833
Current worst splitting domains [lb, ub] (depth):
[-0.05033,   inf] (25), [-0.05032,   inf] (25), [-0.05032,   inf] (27), [-0.05032,   inf] (31), [-0.05032,   inf] (37), [-0.05032,   inf] (21), [-0.05032,   inf] (29), [-0.05032,   inf] (47), [-0.05032,   inf] (29), [-0.05032,   inf] (21), [-0.05032,   inf] (29), [-0.05031,   inf] (29), [-0.05031,   inf] (23), [-0.05031,   inf] (33), [-0.05031,   inf] (25), [-0.05031,   inf] (25), [-0.05031,   inf] (29), [-0.05031,   inf] (29), [-0.05031,   inf] (25), [-0.05031,   inf] (27), 
length of domains: 7392
Total time: 1.0442	 pickout: 0.0556	 decision: 0.0956	 get_bound: 0.8821	 add_domain: 0.0109
Current lb:-0.050325941294431686
16508 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 144.70395946502686

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 383] [4, 420] [4, 395] [5, 320] [4, 359] [4, 420] [4, 420] [5, 456] [4, 395] [4, 420] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.583010673522949 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 12.36978530883789, 30.7596435546875]
alpha/beta optimization time: 0.7874507904052734
This batch time : update_bounds func: 0.8756	 prepare: 0.0224	 bound: 0.7879	 transfer: 0.0486	 finalize: 0.0163
Accumulated time: update_bounds func: 117.2541	 prepare: 3.0306	 bound: 105.4078	 transfer: 0.0486	 finalize: 2.5955
batch bounding time:  0.8760638236999512
Current worst splitting domains [lb, ub] (depth):
[-0.05027,   inf] (29), [-0.05027,   inf] (25), [-0.05027,   inf] (29), [-0.05027,   inf] (35), [-0.05027,   inf] (21), [-0.05027,   inf] (27), [-0.05027,   inf] (27), [-0.05027,   inf] (31), [-0.05027,   inf] (27), [-0.05026,   inf] (23), [-0.05026,   inf] (33), [-0.05026,   inf] (27), [-0.05026,   inf] (29), [-0.05026,   inf] (37), [-0.05026,   inf] (47), [-0.05026,   inf] (39), [-0.05026,   inf] (35), [-0.05025,   inf] (29), [-0.05025,   inf] (35), [-0.05025,   inf] (33), 
length of domains: 7443
Total time: 1.0446	 pickout: 0.0592	 decision: 0.0982	 get_bound: 0.8763	 add_domain: 0.0109
Current lb:-0.05027121305465698
16636 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 145.75162935256958

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 395] [4, 491] [5, 473] [4, 359] [4, 491] [4, 358] [4, 359] [5, 389] [4, 358] [4, 358] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.2558088302612305 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 14.66073989868164, 30.52065658569336]
alpha/beta optimization time: 0.7872471809387207
This batch time : update_bounds func: 0.8796	 prepare: 0.0225	 bound: 0.7877	 transfer: 0.0516	 finalize: 0.0174
Accumulated time: update_bounds func: 118.1338	 prepare: 3.0531	 bound: 106.1955	 transfer: 0.0516	 finalize: 2.6129
batch bounding time:  0.8801088333129883
Current worst splitting domains [lb, ub] (depth):
[-0.05021,   inf] (23), [-0.05021,   inf] (35), [-0.05021,   inf] (25), [-0.05021,   inf] (35), [-0.05021,   inf] (21), [-0.05021,   inf] (33), [-0.05021,   inf] (29), [-0.05020,   inf] (41), [-0.05020,   inf] (39), [-0.05020,   inf] (37), [-0.05020,   inf] (23), [-0.05020,   inf] (31), [-0.05020,   inf] (35), [-0.05020,   inf] (37), [-0.05020,   inf] (31), [-0.05020,   inf] (31), [-0.05019,   inf] (21), [-0.05019,   inf] (31), [-0.05019,   inf] (21), [-0.05019,   inf] (31), 
length of domains: 7489
Total time: 1.0379	 pickout: 0.0530	 decision: 0.0939	 get_bound: 0.8803	 add_domain: 0.0106
Current lb:-0.05021023750305176
16764 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 146.79305768013

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 491] [5, 389] [5, 389] [5, 408] [4, 420] [4, 420] [5, 503] [4, 395] [4, 455] [4, 262] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.206914901733398 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 17.38399887084961, 33.14390563964844]
alpha/beta optimization time: 0.7982501983642578
This batch time : update_bounds func: 0.8883	 prepare: 0.0234	 bound: 0.7988	 transfer: 0.0494	 finalize: 0.0162
Accumulated time: update_bounds func: 119.0220	 prepare: 3.0765	 bound: 106.9943	 transfer: 0.0494	 finalize: 2.6291
batch bounding time:  0.888831615447998
Current worst splitting domains [lb, ub] (depth):
[-0.05015,   inf] (35), [-0.05015,   inf] (37), [-0.05015,   inf] (21), [-0.05014,   inf] (27), [-0.05014,   inf] (25), [-0.05014,   inf] (39), [-0.05014,   inf] (29), [-0.05014,   inf] (37), [-0.05014,   inf] (23), [-0.05014,   inf] (31), [-0.05014,   inf] (37), [-0.05013,   inf] (27), [-0.05013,   inf] (25), [-0.05013,   inf] (31), [-0.05013,   inf] (29), [-0.05013,   inf] (37), [-0.05013,   inf] (31), [-0.05013,   inf] (23), [-0.05013,   inf] (25), [-0.05013,   inf] (27), 
length of domains: 7536
Total time: 1.0861	 pickout: 0.0872	 decision: 0.0980	 get_bound: 0.8891	 add_domain: 0.0119
Current lb:-0.05015040934085846
16892 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 147.88263988494873

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 359] [4, 359] [4, 420] [4, 358] [5, 383] [5, 389] [5, 320] [5, 473] [5, 383] [5, 389] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.2785844802856445 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 13.924429893493652, 31.382596969604492]
alpha/beta optimization time: 0.8453493118286133
This batch time : update_bounds func: 0.9429	 prepare: 0.0232	 bound: 0.8458	 transfer: 0.0499	 finalize: 0.0234
Accumulated time: update_bounds func: 119.9649	 prepare: 3.0997	 bound: 107.8401	 transfer: 0.0499	 finalize: 2.6525
batch bounding time:  0.9433498382568359
Current worst splitting domains [lb, ub] (depth):
[-0.05008,   inf] (27), [-0.05008,   inf] (37), [-0.05008,   inf] (27), [-0.05007,   inf] (39), [-0.05007,   inf] (21), [-0.05007,   inf] (25), [-0.05007,   inf] (27), [-0.05007,   inf] (31), [-0.05007,   inf] (27), [-0.05007,   inf] (27), [-0.05007,   inf] (31), [-0.05007,   inf] (27), [-0.05006,   inf] (31), [-0.05006,   inf] (33), [-0.05006,   inf] (23), [-0.05006,   inf] (37), [-0.05006,   inf] (33), [-0.05006,   inf] (31), [-0.05006,   inf] (29), [-0.05006,   inf] (37), 
length of domains: 7582
Total time: 1.1053	 pickout: 0.0546	 decision: 0.0960	 get_bound: 0.9436	 add_domain: 0.0111
Current lb:-0.05008111521601677
17020 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 148.99119639396667

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 358] [5, 389] [4, 395] [5, 473] [4, 358] [5, 320] [4, 359] [5, 389] [4, 358] [5, 383] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.486174583435059 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 15.11000919342041, 29.312335968017578]
alpha/beta optimization time: 0.7967045307159424
This batch time : update_bounds func: 0.8850	 prepare: 0.0223	 bound: 0.7972	 transfer: 0.0491	 finalize: 0.0158
Accumulated time: update_bounds func: 120.8499	 prepare: 3.1221	 bound: 108.6373	 transfer: 0.0491	 finalize: 2.6684
batch bounding time:  0.8854010105133057
Current worst splitting domains [lb, ub] (depth):
[-0.05001,   inf] (43), [-0.05001,   inf] (25), [-0.05001,   inf] (27), [-0.05001,   inf] (33), [-0.05001,   inf] (27), [-0.05001,   inf] (25), [-0.05001,   inf] (29), [-0.05001,   inf] (39), [-0.05000,   inf] (35), [-0.05000,   inf] (25), [-0.05000,   inf] (33), [-0.05000,   inf] (29), [-0.05000,   inf] (23), [-0.05000,   inf] (23), [-0.05000,   inf] (35), [-0.05000,   inf] (31), [-0.04999,   inf] (29), [-0.04999,   inf] (25), [-0.04999,   inf] (37), [-0.04999,   inf] (31), 
length of domains: 7630
Total time: 1.0670	 pickout: 0.0641	 decision: 0.0970	 get_bound: 0.8856	 add_domain: 0.0203
Current lb:-0.050008624792099
17148 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 150.06262397766113

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 294] [4, 359] [5, 320] [4, 395] [5, 383] [5, 383] [5, 473] [5, 473] [4, 248] [5, 383] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.092940807342529 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 16.757915496826172, 33.3018798828125]
alpha/beta optimization time: 0.8202753067016602
This batch time : update_bounds func: 0.9155	 prepare: 0.0223	 bound: 0.8208	 transfer: 0.0490	 finalize: 0.0231
Accumulated time: update_bounds func: 121.7654	 prepare: 3.1443	 bound: 109.4581	 transfer: 0.0490	 finalize: 2.6915
batch bounding time:  0.9159834384918213
Current worst splitting domains [lb, ub] (depth):
[-0.04995,   inf] (27), [-0.04995,   inf] (25), [-0.04995,   inf] (33), [-0.04995,   inf] (23), [-0.04995,   inf] (35), [-0.04995,   inf] (21), [-0.04995,   inf] (29), [-0.04995,   inf] (25), [-0.04995,   inf] (29), [-0.04995,   inf] (23), [-0.04995,   inf] (39), [-0.04995,   inf] (31), [-0.04994,   inf] (23), [-0.04994,   inf] (23), [-0.04994,   inf] (31), [-0.04994,   inf] (33), [-0.04994,   inf] (25), [-0.04994,   inf] (35), [-0.04994,   inf] (33), [-0.04994,   inf] (25), 
length of domains: 7673
Total time: 1.1307	 pickout: 0.1089	 decision: 0.0950	 get_bound: 0.9162	 add_domain: 0.0106
Current lb:-0.04995428025722504
17276 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 151.19633412361145

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 503] [5, 383] [5, 473] [4, 491] [5, 473] [4, 420] [5, 320] [5, 383] [4, 358] [4, 420] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.722792148590088 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 14.043718338012695, 29.97062873840332]
alpha/beta optimization time: 0.8024489879608154
This batch time : update_bounds func: 0.9037	 prepare: 0.0346	 bound: 0.8031	 transfer: 0.0486	 finalize: 0.0158
Accumulated time: update_bounds func: 122.6691	 prepare: 3.1789	 bound: 110.2612	 transfer: 0.0486	 finalize: 2.7073
batch bounding time:  0.9040975570678711
Current worst splitting domains [lb, ub] (depth):
[-0.04989,   inf] (27), [-0.04989,   inf] (29), [-0.04989,   inf] (27), [-0.04989,   inf] (25), [-0.04989,   inf] (21), [-0.04989,   inf] (33), [-0.04989,   inf] (25), [-0.04988,   inf] (25), [-0.04988,   inf] (29), [-0.04988,   inf] (27), [-0.04988,   inf] (35), [-0.04988,   inf] (33), [-0.04988,   inf] (31), [-0.04988,   inf] (35), [-0.04988,   inf] (25), [-0.04988,   inf] (25), [-0.04988,   inf] (29), [-0.04988,   inf] (21), [-0.04988,   inf] (21), [-0.04987,   inf] (35), 
length of domains: 7727
Total time: 1.0774	 pickout: 0.0570	 decision: 0.1049	 get_bound: 0.9043	 add_domain: 0.0112
Current lb:-0.04989427328109741
17404 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 152.2767312526703

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 358] [5, 320] [4, 358] [4, 358] [4, 358] [5, 408] [4, 491] [5, 383] [5, 389] [4, 359] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.307122230529785 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 18.029586791992188, 31.774215698242188]
alpha/beta optimization time: 0.8094112873077393
This batch time : update_bounds func: 0.8982	 prepare: 0.0225	 bound: 0.8099	 transfer: 0.0488	 finalize: 0.0166
Accumulated time: update_bounds func: 123.5673	 prepare: 3.2014	 bound: 111.0710	 transfer: 0.0488	 finalize: 2.7239
batch bounding time:  0.8986680507659912
Current worst splitting domains [lb, ub] (depth):
[-0.04982,   inf] (33), [-0.04982,   inf] (29), [-0.04982,   inf] (31), [-0.04982,   inf] (27), [-0.04982,   inf] (21), [-0.04982,   inf] (29), [-0.04982,   inf] (23), [-0.04981,   inf] (25), [-0.04981,   inf] (39), [-0.04981,   inf] (25), [-0.04981,   inf] (17), [-0.04981,   inf] (29), [-0.04980,   inf] (25), [-0.04980,   inf] (23), [-0.04980,   inf] (27), [-0.04980,   inf] (23), [-0.04980,   inf] (25), [-0.04980,   inf] (33), [-0.04980,   inf] (25), [-0.04979,   inf] (21), 
length of domains: 7775
Total time: 1.3780	 pickout: 0.0546	 decision: 0.4139	 get_bound: 0.8989	 add_domain: 0.0106
Current lb:-0.04982101917266846
17532 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 153.65788340568542

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 420] [5, 320] [5, 503] [4, 358] [4, 491] [5, 389] [4, 491] [4, 491] [4, 262] [5, 383] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.394083023071289 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 18.46481704711914, 33.94613265991211]
alpha/beta optimization time: 0.7873687744140625
This batch time : update_bounds func: 0.8758	 prepare: 0.0225	 bound: 0.7878	 transfer: 0.0484	 finalize: 0.0167
Accumulated time: update_bounds func: 124.4431	 prepare: 3.2239	 bound: 111.8589	 transfer: 0.0484	 finalize: 2.7406
batch bounding time:  0.8762717247009277
Current worst splitting domains [lb, ub] (depth):
[-0.04975,   inf] (25), [-0.04975,   inf] (25), [-0.04975,   inf] (29), [-0.04975,   inf] (29), [-0.04975,   inf] (31), [-0.04975,   inf] (35), [-0.04975,   inf] (35), [-0.04975,   inf] (27), [-0.04974,   inf] (29), [-0.04974,   inf] (29), [-0.04974,   inf] (25), [-0.04974,   inf] (29), [-0.04974,   inf] (21), [-0.04974,   inf] (35), [-0.04973,   inf] (27), [-0.04973,   inf] (27), [-0.04973,   inf] (27), [-0.04973,   inf] (27), [-0.04973,   inf] (33), [-0.04973,   inf] (33), 
length of domains: 7828
Total time: 1.0303	 pickout: 0.0483	 decision: 0.0946	 get_bound: 0.8765	 add_domain: 0.0108
Current lb:-0.049750640988349915
17660 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:530: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(eps_temp / std).reshape(1, -1, 1, 1)

Cumulative time: 154.6914517879486

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 383] [4, 395] [5, 503] [5, 473] [5, 503] [4, 359] [5, 389] [4, 395] [4, 358] [4, 359] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.417962074279785 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 20.343582153320312, 31.78046226501465]
alpha/beta optimization time: 0.7941029071807861
This batch time : update_bounds func: 0.9090	 prepare: 0.0453	 bound: 0.7948	 transfer: 0.0517	 finalize: 0.0164
Accumulated time: update_bounds func: 125.3521	 prepare: 3.2692	 bound: 112.6537	 transfer: 0.0517	 finalize: 2.7570
batch bounding time:  0.9094362258911133
Current worst splitting domains [lb, ub] (depth):
[-0.04969,   inf] (33), [-0.04969,   inf] (27), [-0.04969,   inf] (25), [-0.04968,   inf] (23), [-0.04968,   inf] (25), [-0.04968,   inf] (29), [-0.04968,   inf] (31), [-0.04968,   inf] (35), [-0.04968,   inf] (31), [-0.04968,   inf] (29), [-0.04968,   inf] (25), [-0.04968,   inf] (23), [-0.04968,   inf] (43), [-0.04968,   inf] (31), [-0.04968,   inf] (25), [-0.04968,   inf] (45), [-0.04968,   inf] (27), [-0.04968,   inf] (31), [-0.04968,   inf] (33), [-0.04968,   inf] (37), 
length of domains: 7878
Total time: 1.0709	 pickout: 0.0497	 decision: 0.1009	 get_bound: 0.9097	 add_domain: 0.0107
Current lb:-0.04968954250216484
17788 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Time out!!!!!!!!
Image 444 label 3 verification end, final lower bound -0.04968954250216484, upper bound inf, time: 156.16648840904236
444 -0.04968954250216484
Result: image 444 verification failure (with branch and bound).
Wall time: 181.11353850364685

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 0): []
verification failure idx (total 1): [444]
final verified acc: 0.0%[1]
verifier is called on 1 examples.
total verified: 0
mean time [cnt:1] (excluding attack success): 180.9973487854004
