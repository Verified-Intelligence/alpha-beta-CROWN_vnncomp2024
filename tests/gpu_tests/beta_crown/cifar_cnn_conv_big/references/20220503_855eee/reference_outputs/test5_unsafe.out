Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_conv_big_pgd.pth
  name: cifar_conv_big
data:
  start: 684
  end: 685
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR_ERAN
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.00784313725
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 64
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 180
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 100
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:27:27 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (5): ReLU()
  (6): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (7): ReLU()
  (8): Flatten()
  (9): Linear(in_features=4096, out_features=512, bias=True)
  (10): ReLU()
  (11): Linear(in_features=512, out_features=512, bias=True)
  (12): ReLU()
  (13): Linear(in_features=512, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([1000, 3, 32, 32]) torch.Size([1000]) torch.Size([1000])
X range: tensor(2.7537) tensor(-2.4291) tensor(0.0238)
Note runnerup label is empty here!
############################
epsilon after preprocessing: tensor([[[[0.0388]],

         [[0.0393]],

         [[0.0390]]]]), data_max = tensor([[[[2.5141]],

         [[2.5968]],

         [[2.7537]]]]), data_min = tensor([[[[-2.4291]],

         [[-2.4183]],

         [[-2.2214]]]])
Task length: 1
saving results to Verified_ret_[cifar_conv_big]_start=684_end=685_iter=20_b=64_timeout=180_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 684 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 9, correct label 9, image norm 4011.632080078125, logits tensor([-3.1791,  1.4580, -2.0244, -0.6869, -1.3472, -1.7468, -0.6753, -2.2091,
        -3.5900,  1.7185], device='cuda:0', grad_fn=<SelectBackward>)
Model prediction is: tensor([[-3.1791,  1.4580, -2.0244, -0.6869, -1.3472, -1.7468, -0.6753, -2.2091,
         -3.5900,  1.7185]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 3.8497, -0.4175,  2.8212,  1.5338,  2.1282,  2.6211,  1.5672,  2.8813,
          4.1090]], device='cuda:0') None
best_l after optimization: -21.780309677124023 with beta sum per layer: []
alpha/beta optimization time: 22.362724781036377
initial alpha-CROWN bounds: tensor([[ 3.9193, -0.3500,  2.8891,  1.6011,  2.2162,  2.7038,  1.6500,  2.9630,
          4.1878]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.3500, device='cuda:0', grad_fn=<MinBackward1>)
##### [0:684] Tested against 1 ######
Model prediction is: tensor([[-3.1791,  1.4580, -2.0244, -0.6869, -1.3472, -1.7468, -0.6753, -2.2091,
         -3.5900,  1.7185]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /16 start_node /17
setting alpha for layer /16 start_node /19
setting alpha for layer /16 start_node /21
setting alpha for layer /16 start_node /31
setting alpha for layer /16 start_node /33
not setting layer /16 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 32, 32, 32]) != torch.Size([2, 9, 1, 32, 32, 32]))
setting alpha for layer /18 start_node /19
setting alpha for layer /18 start_node /21
setting alpha for layer /18 start_node /31
setting alpha for layer /18 start_node /33
not setting layer /18 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /20 start_node /21
setting alpha for layer /20 start_node /31
setting alpha for layer /20 start_node /33
not setting layer /20 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 64, 16, 16]) != torch.Size([2, 9, 1, 64, 16, 16]))
setting alpha for layer /22 start_node /31
setting alpha for layer /22 start_node /33
not setting layer /22 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 64, 8, 8]) != torch.Size([2, 9, 1, 64, 8, 8]))
setting alpha for layer /32 start_node /33
not setting layer /32 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 512]) != torch.Size([2, 9, 1, 512]))
not setting layer /34 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 512]) != torch.Size([2, 9, 1, 512]))
0 /15 torch.Size([1, 32, 32, 32])
1 /17 torch.Size([1, 32, 16, 16])
2 /19 torch.Size([1, 64, 16, 16])
3 /21 torch.Size([1, 64, 8, 8])
4 /31 torch.Size([1, 512])
5 /33 torch.Size([1, 512])
best_l after optimization: 0.3500267267227173 with beta sum per layer: []
alpha/beta optimization time: 3.78987717628479
alpha-CROWN with fixed intermediate bounds: tensor([[-0.3500]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.3500267267227173
layer 0 size torch.Size([32768]) unstable 2064
layer 1 size torch.Size([8192]) unstable 64
layer 2 size torch.Size([16384]) unstable 845
layer 3 size torch.Size([4096]) unstable 72
layer 4 size torch.Size([512]) unstable 24
layer 5 size torch.Size([512]) unstable 48
-----------------
# of unstable neurons: 3117
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 32, 32]) pre split depth:  2
batch:  torch.Size([1, 32, 32, 32]) post split depth:  2
splitting decisions: 
split level 0: [4, 395] 
split level 1: [5, 175] 
regular batch size: 2*2, diving batch size 1*0
best_l after optimization: 1.0255517959594727 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.1701878309249878, 0.03125924989581108]
alpha/beta optimization time: 0.43018031120300293
This batch time : update_bounds func: 0.4359	 prepare: 0.0026	 bound: 0.4306	 transfer: 0.0021	 finalize: 0.0007
Accumulated time: update_bounds func: 0.4359	 prepare: 0.0026	 bound: 0.4306	 transfer: 0.0021	 finalize: 0.0007
batch bounding time:  0.4361228942871094
Current worst splitting domains [lb, ub] (depth):
[-0.27863,   inf] (3), [-0.27273,   inf] (3), [-0.24222,   inf] (3), [-0.23197,   inf] (3), 
length of domains: 4
Total time: 0.4726	 pickout: 0.0020	 decision: 0.0331	 get_bound: 0.4371	 add_domain: 0.0004
Current lb:-0.27862539887428284
4 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.190280437469482

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([4, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 32] [5, 32] [5, 32] [5, 32] 
regular batch size: 2*4, diving batch size 1*0
best_l after optimization: 1.6230638027191162 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.24032911658287048, 0.9286243915557861]
alpha/beta optimization time: 0.452847957611084
This batch time : update_bounds func: 0.4610	 prepare: 0.0032	 bound: 0.4533	 transfer: 0.0032	 finalize: 0.0013
Accumulated time: update_bounds func: 0.8970	 prepare: 0.0058	 bound: 0.8839	 transfer: 0.0032	 finalize: 0.0019
batch bounding time:  0.46123290061950684
Current worst splitting domains [lb, ub] (depth):
[-0.26180,   inf] (5), [-0.25503,   inf] (5), [-0.21916,   inf] (5), [-0.20901,   inf] (5), [-0.17605,   inf] (5), [-0.17594,   inf] (5), [-0.16425,   inf] (5), [-0.16181,   inf] (5), 
length of domains: 8
Total time: 0.4987	 pickout: 0.0034	 decision: 0.0335	 get_bound: 0.4613	 add_domain: 0.0005
Current lb:-0.26180222630500793
12 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.689227819442749

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 292] [5, 292] [5, 292] [4, 358] [5, 245] [5, 245] [5, 245] [5, 245] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 2.8038930892944336 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.6038079857826233, 3.749295234680176]
alpha/beta optimization time: 0.45978617668151855
This batch time : update_bounds func: 0.4720	 prepare: 0.0045	 bound: 0.4602	 transfer: 0.0048	 finalize: 0.0024
Accumulated time: update_bounds func: 1.3690	 prepare: 0.0103	 bound: 1.3440	 transfer: 0.0048	 finalize: 0.0043
batch bounding time:  0.47226977348327637
Current worst splitting domains [lb, ub] (depth):
[-0.24799,   inf] (7), [-0.24251,   inf] (7), [-0.22738,   inf] (7), [-0.22134,   inf] (7), [-0.20712,   inf] (7), [-0.19483,   inf] (7), [-0.17673,   inf] (7), [-0.16401,   inf] (7), [-0.16134,   inf] (7), [-0.16092,   inf] (7), [-0.14986,   inf] (7), [-0.14865,   inf] (7), [-0.14067,   inf] (7), [-0.14001,   inf] (7), [-0.11251,   inf] (7), [-0.10801,   inf] (7), 
length of domains: 16
Total time: 0.5342	 pickout: 0.0205	 decision: 0.0405	 get_bound: 0.4723	 add_domain: 0.0009
Current lb:-0.2479933649301529
28 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.223728179931641

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([16, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([16, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 245] [5, 245] [5, 245] [5, 245] [5, 245] [5, 245] [5, 245] [5, 292] [5, 292] [5, 292] 
regular batch size: 2*16, diving batch size 1*0
best_l after optimization: 4.836768627166748 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.2958258390426636, 8.746365547180176]
alpha/beta optimization time: 0.47367429733276367
This batch time : update_bounds func: 0.4968	 prepare: 0.0067	 bound: 0.4741	 transfer: 0.0116	 finalize: 0.0043
Accumulated time: update_bounds func: 1.8658	 prepare: 0.0170	 bound: 1.8182	 transfer: 0.0116	 finalize: 0.0086
batch bounding time:  0.4970409870147705
Current worst splitting domains [lb, ub] (depth):
[-0.23370,   inf] (9), [-0.22706,   inf] (9), [-0.22085,   inf] (9), [-0.21999,   inf] (9), [-0.21094,   inf] (9), [-0.20592,   inf] (9), [-0.20438,   inf] (9), [-0.20215,   inf] (9), [-0.19269,   inf] (9), [-0.18203,   inf] (9), [-0.17701,   inf] (9), [-0.16071,   inf] (9), [-0.15469,   inf] (9), [-0.14888,   inf] (9), [-0.14748,   inf] (9), [-0.14576,   inf] (9), [-0.14560,   inf] (9), [-0.13494,   inf] (9), [-0.13371,   inf] (9), [-0.12682,   inf] (9), 
length of domains: 32
Total time: 0.5753	 pickout: 0.0319	 decision: 0.0445	 get_bound: 0.4971	 add_domain: 0.0018
Current lb:-0.23369647562503815
60 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.799459457397461

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([32, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([32, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 205] [5, 15] [5, 15] [4, 354] [4, 123] [5, 15] [4, 123] [5, 15] [5, 15] [5, 15] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: 8.207980155944824 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 5.029031276702881, 21.040498733520508]
alpha/beta optimization time: 0.5653572082519531
This batch time : update_bounds func: 0.6047	 prepare: 0.0113	 bound: 0.5658	 transfer: 0.0196	 finalize: 0.0078
Accumulated time: update_bounds func: 2.4705	 prepare: 0.0283	 bound: 2.3839	 transfer: 0.0196	 finalize: 0.0165
batch bounding time:  0.6049473285675049
Current worst splitting domains [lb, ub] (depth):
[-0.22364,   inf] (11), [-0.21286,   inf] (11), [-0.20912,   inf] (11), [-0.20780,   inf] (11), [-0.20653,   inf] (11), [-0.20167,   inf] (11), [-0.19490,   inf] (11), [-0.19148,   inf] (11), [-0.18893,   inf] (11), [-0.18873,   inf] (11), [-0.18724,   inf] (11), [-0.18347,   inf] (11), [-0.18194,   inf] (11), [-0.17772,   inf] (11), [-0.17750,   inf] (11), [-0.17487,   inf] (11), [-0.16871,   inf] (11), [-0.16181,   inf] (11), [-0.16117,   inf] (11), [-0.14672,   inf] (11), 
length of domains: 64
Total time: 0.6933	 pickout: 0.0183	 decision: 0.0663	 get_bound: 0.6051	 add_domain: 0.0036
Current lb:-0.22363586723804474
124 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.493677854537964

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 123] [4, 354] [5, 15] [4, 123] [4, 358] [4, 358] [5, 15] [4, 123] [5, 15] [4, 123] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 12.808633804321289 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 18.672502517700195, 51.281089782714844]
alpha/beta optimization time: 0.7938616275787354
This batch time : update_bounds func: 0.8669	 prepare: 0.0204	 bound: 0.7943	 transfer: 0.0367	 finalize: 0.0152
Accumulated time: update_bounds func: 3.3374	 prepare: 0.0487	 bound: 3.1782	 transfer: 0.0367	 finalize: 0.0316
batch bounding time:  0.8672010898590088
Current worst splitting domains [lb, ub] (depth):
[-0.20864,   inf] (13), [-0.20360,   inf] (13), [-0.20201,   inf] (13), [-0.19475,   inf] (13), [-0.19452,   inf] (13), [-0.19433,   inf] (13), [-0.19080,   inf] (13), [-0.18980,   inf] (13), [-0.18924,   inf] (13), [-0.18128,   inf] (13), [-0.17683,   inf] (13), [-0.17576,   inf] (13), [-0.17395,   inf] (13), [-0.17386,   inf] (13), [-0.17097,   inf] (13), [-0.17047,   inf] (13), [-0.16947,   inf] (13), [-0.16913,   inf] (13), [-0.16698,   inf] (13), [-0.16645,   inf] (13), 
length of domains: 123
Total time: 1.0221	 pickout: 0.0464	 decision: 0.1004	 get_bound: 0.8674	 add_domain: 0.0078
Current lb:-0.20864123106002808
252 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.517526388168335

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 15] [5, 15] [4, 123] [5, 205] [5, 205] [5, 205] [4, 123] [4, 123] [4, 354] [5, 205] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 11.41640567779541 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 21.286502838134766, 42.13086700439453]
alpha/beta optimization time: 0.7938113212585449
This batch time : update_bounds func: 0.8617	 prepare: 0.0208	 bound: 0.7943	 transfer: 0.0314	 finalize: 0.0149
Accumulated time: update_bounds func: 4.1991	 prepare: 0.0695	 bound: 3.9725	 transfer: 0.0314	 finalize: 0.0465
batch bounding time:  0.862246036529541
Current worst splitting domains [lb, ub] (depth):
[-0.19466,   inf] (15), [-0.18975,   inf] (15), [-0.18931,   inf] (15), [-0.18868,   inf] (15), [-0.18513,   inf] (15), [-0.18392,   inf] (15), [-0.18360,   inf] (15), [-0.18299,   inf] (15), [-0.18199,   inf] (15), [-0.17864,   inf] (15), [-0.17781,   inf] (15), [-0.17702,   inf] (15), [-0.17375,   inf] (15), [-0.17340,   inf] (15), [-0.16905,   inf] (15), [-0.16418,   inf] (15), [-0.16418,   inf] (15), [-0.16195,   inf] (15), [-0.16063,   inf] (15), [-0.15755,   inf] (15), 
length of domains: 174
Total time: 1.0025	 pickout: 0.0405	 decision: 0.0922	 get_bound: 0.8626	 add_domain: 0.0072
Current lb:-0.19466125965118408
380 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.521978616714478

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 358] [4, 358] [4, 358] [5, 205] [5, 205] [4, 354] [4, 123] [4, 123] [4, 358] [5, 205] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 11.409717559814453 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 27.418115615844727, 38.715293884277344]
alpha/beta optimization time: 0.8120296001434326
This batch time : update_bounds func: 0.8880	 prepare: 0.0208	 bound: 0.8125	 transfer: 0.0399	 finalize: 0.0145
Accumulated time: update_bounds func: 5.0871	 prepare: 0.0902	 bound: 4.7850	 transfer: 0.0399	 finalize: 0.0610
batch bounding time:  0.8883323669433594
Current worst splitting domains [lb, ub] (depth):
[-0.18417,   inf] (17), [-0.17941,   inf] (17), [-0.17864,   inf] (17), [-0.17797,   inf] (17), [-0.17386,   inf] (17), [-0.17340,   inf] (17), [-0.17135,   inf] (17), [-0.17043,   inf] (17), [-0.16957,   inf] (17), [-0.16730,   inf] (17), [-0.16725,   inf] (17), [-0.16615,   inf] (17), [-0.16553,   inf] (17), [-0.16459,   inf] (17), [-0.16133,   inf] (17), [-0.16014,   inf] (17), [-0.15799,   inf] (17), [-0.15591,   inf] (17), [-0.15373,   inf] (17), [-0.15116,   inf] (17), 
length of domains: 231
Total time: 1.0342	 pickout: 0.0444	 decision: 0.0929	 get_bound: 0.8885	 add_domain: 0.0082
Current lb:-0.18416529893875122
508 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.557883739471436

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 354] [4, 354] [4, 354] [5, 260] [5, 260] [5, 260] [4, 354] [4, 358] [4, 354] [4, 358] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 11.048883438110352 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 43.224464416503906, 30.443618774414062]
alpha/beta optimization time: 0.7873215675354004
This batch time : update_bounds func: 0.8650	 prepare: 0.0209	 bound: 0.7877	 transfer: 0.0406	 finalize: 0.0154
Accumulated time: update_bounds func: 5.9521	 prepare: 0.1112	 bound: 5.5727	 transfer: 0.0406	 finalize: 0.0764
batch bounding time:  0.8653864860534668
Current worst splitting domains [lb, ub] (depth):
[-0.17445,   inf] (19), [-0.16936,   inf] (19), [-0.16886,   inf] (19), [-0.16856,   inf] (19), [-0.16446,   inf] (19), [-0.16418,   inf] (19), [-0.16059,   inf] (19), [-0.16025,   inf] (19), [-0.15979,   inf] (19), [-0.15666,   inf] (19), [-0.15662,   inf] (19), [-0.15651,   inf] (19), [-0.15601,   inf] (19), [-0.15541,   inf] (19), [-0.15105,   inf] (19), [-0.14988,   inf] (19), [-0.14831,   inf] (19), [-0.14590,   inf] (19), [-0.14301,   inf] (19), [-0.14271,   inf] (19), 
length of domains: 290
Total time: 1.0134	 pickout: 0.0472	 decision: 0.0926	 get_bound: 0.8656	 add_domain: 0.0081
Current lb:-0.1744484156370163
636 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.573183298110962

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 260] [5, 260] [5, 260] [4, 358] [4, 358] [4, 358] [5, 260] [5, 260] [5, 260] [5, 260] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.018285751342773 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 27.253110885620117, 55.87194061279297]
alpha/beta optimization time: 0.7909348011016846
This batch time : update_bounds func: 0.8666	 prepare: 0.0200	 bound: 0.7914	 transfer: 0.0402	 finalize: 0.0146
Accumulated time: update_bounds func: 6.8187	 prepare: 0.1312	 bound: 6.3641	 transfer: 0.0402	 finalize: 0.0911
batch bounding time:  0.8668875694274902
Current worst splitting domains [lb, ub] (depth):
[-0.16520,   inf] (21), [-0.16032,   inf] (21), [-0.16004,   inf] (21), [-0.15983,   inf] (21), [-0.15605,   inf] (21), [-0.15567,   inf] (21), [-0.15174,   inf] (21), [-0.15091,   inf] (21), [-0.15069,   inf] (21), [-0.14804,   inf] (21), [-0.14763,   inf] (21), [-0.14753,   inf] (21), [-0.14690,   inf] (21), [-0.14624,   inf] (21), [-0.14219,   inf] (21), [-0.14146,   inf] (21), [-0.14092,   inf] (21), [-0.13710,   inf] (21), [-0.13468,   inf] (21), [-0.13324,   inf] (21), 
length of domains: 330
Total time: 1.0156	 pickout: 0.0480	 decision: 0.0926	 get_bound: 0.8671	 add_domain: 0.0078
Current lb:-0.16520090401172638
764 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.5907301902771

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 22] [4, 22] [4, 22] [4, 22] [4, 22] [4, 22] [4, 22] [4, 22] [4, 22] [4, 22] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.869720458984375 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 51.58405303955078, 25.542316436767578]
alpha/beta optimization time: 0.7982022762298584
This batch time : update_bounds func: 0.8771	 prepare: 0.0209	 bound: 0.7987	 transfer: 0.0406	 finalize: 0.0165
Accumulated time: update_bounds func: 7.6957	 prepare: 0.1521	 bound: 7.1627	 transfer: 0.0406	 finalize: 0.1076
batch bounding time:  0.8774623870849609
Current worst splitting domains [lb, ub] (depth):
[-0.15831,   inf] (23), [-0.15491,   inf] (23), [-0.15286,   inf] (23), [-0.15276,   inf] (23), [-0.15018,   inf] (23), [-0.14827,   inf] (23), [-0.14716,   inf] (23), [-0.14369,   inf] (23), [-0.14310,   inf] (23), [-0.14297,   inf] (23), [-0.14086,   inf] (23), [-0.14043,   inf] (23), [-0.13983,   inf] (23), [-0.13956,   inf] (23), [-0.13595,   inf] (23), [-0.13521,   inf] (23), [-0.13344,   inf] (23), [-0.13097,   inf] (23), [-0.12884,   inf] (23), [-0.12750,   inf] (23), 
length of domains: 370
Total time: 1.0258	 pickout: 0.0482	 decision: 0.0923	 get_bound: 0.8777	 add_domain: 0.0076
Current lb:-0.15831349790096283
892 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.6186044216156

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 120] [5, 120] [5, 120] [5, 120] [4, 31] [4, 31] [5, 120] [5, 120] [4, 31] [4, 31] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.527795314788818 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 43.328041076660156, 33.97428894042969]
alpha/beta optimization time: 0.7978999614715576
This batch time : update_bounds func: 0.9441	 prepare: 0.0205	 bound: 0.7983	 transfer: 0.0404	 finalize: 0.0838
Accumulated time: update_bounds func: 8.6399	 prepare: 0.1726	 bound: 7.9611	 transfer: 0.0404	 finalize: 0.1913
batch bounding time:  0.944462776184082
Current worst splitting domains [lb, ub] (depth):
[-0.15329,   inf] (25), [-0.14989,   inf] (25), [-0.14792,   inf] (25), [-0.14788,   inf] (25), [-0.14316,   inf] (25), [-0.14314,   inf] (25), [-0.14212,   inf] (25), [-0.13918,   inf] (25), [-0.13707,   inf] (25), [-0.13579,   inf] (25), [-0.13509,   inf] (25), [-0.13422,   inf] (25), [-0.13376,   inf] (25), [-0.13320,   inf] (25), [-0.13156,   inf] (25), [-0.13033,   inf] (25), [-0.12782,   inf] (25), [-0.12661,   inf] (25), [-0.12429,   inf] (25), [-0.12311,   inf] (25), 
length of domains: 408
Total time: 1.1224	 pickout: 0.0779	 decision: 0.0923	 get_bound: 0.9447	 add_domain: 0.0075
Current lb:-0.1532859355211258
1020 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.742865800857544

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 135] [4, 31] [5, 135] [4, 31] [5, 120] [5, 120] [4, 31] [4, 31] [5, 120] [4, 31] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.582878112792969 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 28.98274040222168, 48.17536926269531]
alpha/beta optimization time: 0.7986624240875244
This batch time : update_bounds func: 0.8771	 prepare: 0.0208	 bound: 0.7991	 transfer: 0.0413	 finalize: 0.0155
Accumulated time: update_bounds func: 9.5170	 prepare: 0.1935	 bound: 8.7602	 transfer: 0.0413	 finalize: 0.2068
batch bounding time:  0.8774535655975342
Current worst splitting domains [lb, ub] (depth):
[-0.14862,   inf] (27), [-0.14588,   inf] (27), [-0.14470,   inf] (27), [-0.14316,   inf] (27), [-0.14307,   inf] (27), [-0.14071,   inf] (27), [-0.13837,   inf] (27), [-0.13835,   inf] (27), [-0.13522,   inf] (27), [-0.13492,   inf] (27), [-0.13276,   inf] (27), [-0.13061,   inf] (27), [-0.12946,   inf] (27), [-0.12944,   inf] (27), [-0.12943,   inf] (27), [-0.12839,   inf] (27), [-0.12817,   inf] (27), [-0.12334,   inf] (27), [-0.12328,   inf] (27), [-0.12279,   inf] (27), 
length of domains: 432
Total time: 1.0211	 pickout: 0.0432	 decision: 0.0934	 get_bound: 0.8777	 add_domain: 0.0068
Current lb:-0.14861589670181274
1148 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.766072034835815

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 291] [5, 291] [5, 135] [5, 291] [5, 135] [5, 291] [5, 135] [4, 402] [5, 503] [5, 503] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.56258773803711 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 23.05035972595215, 40.0113525390625]
alpha/beta optimization time: 0.8018343448638916
This batch time : update_bounds func: 0.8794	 prepare: 0.0207	 bound: 0.8023	 transfer: 0.0402	 finalize: 0.0158
Accumulated time: update_bounds func: 10.3964	 prepare: 0.2142	 bound: 9.5625	 transfer: 0.0402	 finalize: 0.2226
batch bounding time:  0.879741907119751
Current worst splitting domains [lb, ub] (depth):
[-0.14455,   inf] (29), [-0.14173,   inf] (29), [-0.13982,   inf] (29), [-0.13908,   inf] (29), [-0.13828,   inf] (29), [-0.13686,   inf] (29), [-0.13653,   inf] (29), [-0.13626,   inf] (29), [-0.13362,   inf] (29), [-0.13221,   inf] (29), [-0.13198,   inf] (29), [-0.13164,   inf] (29), [-0.13164,   inf] (29), [-0.13077,   inf] (29), [-0.12798,   inf] (29), [-0.12773,   inf] (29), [-0.12619,   inf] (29), [-0.12460,   inf] (29), [-0.12450,   inf] (29), [-0.12344,   inf] (29), 
length of domains: 479
Total time: 1.0256	 pickout: 0.0440	 decision: 0.0930	 get_bound: 0.8800	 add_domain: 0.0086
Current lb:-0.14455240964889526
1276 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.79359483718872

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 485] [5, 503] [5, 503] [5, 485] [5, 291] [5, 503] [5, 485] [5, 291] [5, 291] [5, 135] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 11.131359100341797 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 10.147284507751465, 51.04875183105469]
alpha/beta optimization time: 0.7968244552612305
This batch time : update_bounds func: 0.8738	 prepare: 0.0209	 bound: 0.7972	 transfer: 0.0402	 finalize: 0.0151
Accumulated time: update_bounds func: 11.2702	 prepare: 0.2351	 bound: 10.3597	 transfer: 0.0402	 finalize: 0.2377
batch bounding time:  0.8741557598114014
Current worst splitting domains [lb, ub] (depth):
[-0.14087,   inf] (31), [-0.13761,   inf] (31), [-0.13611,   inf] (31), [-0.13542,   inf] (31), [-0.13438,   inf] (31), [-0.13293,   inf] (31), [-0.13291,   inf] (31), [-0.13226,   inf] (31), [-0.12970,   inf] (31), [-0.12752,   inf] (31), [-0.12724,   inf] (31), [-0.12722,   inf] (31), [-0.12662,   inf] (31), [-0.12579,   inf] (31), [-0.12483,   inf] (31), [-0.12454,   inf] (31), [-0.12407,   inf] (31), [-0.12392,   inf] (31), [-0.12365,   inf] (31), [-0.12299,   inf] (31), 
length of domains: 537
Total time: 1.0234	 pickout: 0.0416	 decision: 0.0943	 get_bound: 0.8744	 add_domain: 0.0131
Current lb:-0.1408710479736328
1404 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.819026708602905

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 503] [5, 485] [5, 485] [5, 503] [5, 503] [5, 485] [5, 503] [5, 503] [5, 485] [5, 503] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.477810859680176 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 7.424707412719727, 59.27522659301758]
alpha/beta optimization time: 0.8024442195892334
This batch time : update_bounds func: 0.8798	 prepare: 0.0208	 bound: 0.8029	 transfer: 0.0403	 finalize: 0.0155
Accumulated time: update_bounds func: 12.1499	 prepare: 0.2559	 bound: 11.1626	 transfer: 0.0403	 finalize: 0.2532
batch bounding time:  0.8801167011260986
Current worst splitting domains [lb, ub] (depth):
[-0.13714,   inf] (33), [-0.13396,   inf] (33), [-0.13215,   inf] (33), [-0.13183,   inf] (33), [-0.13062,   inf] (33), [-0.12913,   inf] (33), [-0.12892,   inf] (33), [-0.12829,   inf] (33), [-0.12598,   inf] (33), [-0.12366,   inf] (33), [-0.12348,   inf] (33), [-0.12338,   inf] (33), [-0.12311,   inf] (33), [-0.12201,   inf] (33), [-0.12104,   inf] (33), [-0.12060,   inf] (33), [-0.12054,   inf] (33), [-0.12032,   inf] (33), [-0.11947,   inf] (33), [-0.11924,   inf] (33), 
length of domains: 595
Total time: 1.0305	 pickout: 0.0475	 decision: 0.0921	 get_bound: 0.8803	 add_domain: 0.0105
Current lb:-0.13713723421096802
1532 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.851317167282104

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 31] [4, 31] [5, 291] [4, 31] [5, 485] [5, 291] [4, 31] [5, 485] [5, 503] [5, 485] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 8.71725082397461 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 10.805195808410645, 60.808013916015625]
alpha/beta optimization time: 0.7937784194946289
This batch time : update_bounds func: 0.8720	 prepare: 0.0220	 bound: 0.7942	 transfer: 0.0403	 finalize: 0.0152
Accumulated time: update_bounds func: 13.0220	 prepare: 0.2779	 bound: 11.9568	 transfer: 0.0403	 finalize: 0.2684
batch bounding time:  0.8724050521850586
Current worst splitting domains [lb, ub] (depth):
[-0.13421,   inf] (35), [-0.13108,   inf] (35), [-0.12867,   inf] (35), [-0.12852,   inf] (35), [-0.12691,   inf] (35), [-0.12585,   inf] (35), [-0.12568,   inf] (35), [-0.12468,   inf] (35), [-0.12228,   inf] (35), [-0.12004,   inf] (35), [-0.11977,   inf] (35), [-0.11941,   inf] (35), [-0.11931,   inf] (35), [-0.11804,   inf] (35), [-0.11729,   inf] (35), [-0.11721,   inf] (35), [-0.11691,   inf] (35), [-0.11678,   inf] (35), [-0.11586,   inf] (35), [-0.11550,   inf] (35), 
length of domains: 641
Total time: 1.0294	 pickout: 0.0531	 decision: 0.0929	 get_bound: 0.8726	 add_domain: 0.0107
Current lb:-0.1342095583677292
1660 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 19.882867336273193

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 103] [5, 504] [5, 504] [5, 103] [5, 103] [5, 504] [5, 103] [5, 103] [5, 103] [5, 103] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.826458930969238 with beta sum per layer: [0.0, 0.0, 0.0, 3.8860347270965576, 11.403786659240723, 54.61335754394531]
alpha/beta optimization time: 0.7970855236053467
This batch time : update_bounds func: 0.8849	 prepare: 0.0213	 bound: 0.7975	 transfer: 0.0495	 finalize: 0.0161
Accumulated time: update_bounds func: 13.9069	 prepare: 0.2992	 bound: 12.7543	 transfer: 0.0495	 finalize: 0.2845
batch bounding time:  0.8852241039276123
Current worst splitting domains [lb, ub] (depth):
[-0.13117,   inf] (37), [-0.12858,   inf] (37), [-0.12604,   inf] (37), [-0.12537,   inf] (37), [-0.12404,   inf] (37), [-0.12342,   inf] (37), [-0.12238,   inf] (37), [-0.12176,   inf] (37), [-0.11933,   inf] (37), [-0.11705,   inf] (37), [-0.11660,   inf] (37), [-0.11633,   inf] (37), [-0.11630,   inf] (37), [-0.11595,   inf] (37), [-0.11496,   inf] (37), [-0.11411,   inf] (37), [-0.11410,   inf] (37), [-0.11390,   inf] (37), [-0.11352,   inf] (37), [-0.11248,   inf] (37), 
length of domains: 669
Total time: 1.0690	 pickout: 0.0817	 decision: 0.0933	 get_bound: 0.8854	 add_domain: 0.0086
Current lb:-0.13116717338562012
1788 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 20.954062461853027

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 504] [5, 103] [5, 103] [5, 504] [5, 504] [5, 103] [5, 504] [5, 232] [5, 504] [5, 504] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.840592384338379 with beta sum per layer: [0.0, 0.0, 0.0, 24.226682662963867, 10.652745246887207, 46.46635055541992]
alpha/beta optimization time: 0.7934699058532715
This batch time : update_bounds func: 0.8809	 prepare: 0.0212	 bound: 0.7939	 transfer: 0.0493	 finalize: 0.0154
Accumulated time: update_bounds func: 14.7877	 prepare: 0.3204	 bound: 13.5482	 transfer: 0.0493	 finalize: 0.2999
batch bounding time:  0.8812322616577148
Current worst splitting domains [lb, ub] (depth):
[-0.12842,   inf] (39), [-0.12550,   inf] (39), [-0.12298,   inf] (39), [-0.12255,   inf] (39), [-0.12157,   inf] (39), [-0.12029,   inf] (39), [-0.11967,   inf] (39), [-0.11926,   inf] (39), [-0.11688,   inf] (39), [-0.11463,   inf] (39), [-0.11403,   inf] (39), [-0.11318,   inf] (39), [-0.11309,   inf] (39), [-0.11174,   inf] (39), [-0.11165,   inf] (39), [-0.11157,   inf] (39), [-0.11142,   inf] (39), [-0.11074,   inf] (39), [-0.11062,   inf] (39), [-0.10957,   inf] (39), 
length of domains: 703
Total time: 1.0327	 pickout: 0.0496	 decision: 0.0922	 get_bound: 0.8814	 add_domain: 0.0095
Current lb:-0.12841679155826569
1916 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 21.989272117614746

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 232] [4, 417] [5, 232] [3, 1244] [5, 232] [3, 1244] [3, 1244] [5, 504] [3, 3035] [3, 3035] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.895486831665039 with beta sum per layer: [0.0, 0.0, 0.0, 44.170433044433594, 12.292396545410156, 42.21098709106445]
alpha/beta optimization time: 0.8100292682647705
This batch time : update_bounds func: 0.8981	 prepare: 0.0222	 bound: 0.8105	 transfer: 0.0490	 finalize: 0.0160
Accumulated time: update_bounds func: 15.6858	 prepare: 0.3426	 bound: 14.3587	 transfer: 0.0490	 finalize: 0.3159
batch bounding time:  0.8984675407409668
Current worst splitting domains [lb, ub] (depth):
[-0.12594,   inf] (41), [-0.12267,   inf] (41), [-0.12060,   inf] (41), [-0.12034,   inf] (41), [-0.11902,   inf] (41), [-0.11797,   inf] (41), [-0.11753,   inf] (41), [-0.11678,   inf] (41), [-0.11483,   inf] (41), [-0.11418,   inf] (41), [-0.11207,   inf] (41), [-0.11201,   inf] (41), [-0.11189,   inf] (41), [-0.11074,   inf] (41), [-0.11026,   inf] (41), [-0.11025,   inf] (41), [-0.10876,   inf] (41), [-0.10873,   inf] (41), [-0.10865,   inf] (41), [-0.10862,   inf] (41), 
length of domains: 759
Total time: 1.1321	 pickout: 0.0717	 decision: 0.1498	 get_bound: 0.8987	 add_domain: 0.0119
Current lb:-0.12594366073608398
2044 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 23.123449087142944

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 377] [5, 232] [5, 377] [4, 269] [3, 3035] [5, 232] [5, 232] [3, 3035] [4, 269] [5, 232] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.39482593536377 with beta sum per layer: [0.0, 0.0, 0.0, 70.7856216430664, 7.585569381713867, 44.06549072265625]
alpha/beta optimization time: 0.7954246997833252
This batch time : update_bounds func: 0.8997	 prepare: 0.0222	 bound: 0.7959	 transfer: 0.0544	 finalize: 0.0268
Accumulated time: update_bounds func: 16.5856	 prepare: 0.3649	 bound: 15.1546	 transfer: 0.0544	 finalize: 0.3427
batch bounding time:  0.9001274108886719
Current worst splitting domains [lb, ub] (depth):
[-0.12364,   inf] (43), [-0.12027,   inf] (43), [-0.11822,   inf] (43), [-0.11709,   inf] (43), [-0.11649,   inf] (43), [-0.11571,   inf] (43), [-0.11511,   inf] (43), [-0.11428,   inf] (43), [-0.11330,   inf] (43), [-0.11172,   inf] (43), [-0.11137,   inf] (43), [-0.11132,   inf] (43), [-0.10951,   inf] (43), [-0.10934,   inf] (43), [-0.10919,   inf] (43), [-0.10789,   inf] (43), [-0.10686,   inf] (43), [-0.10657,   inf] (43), [-0.10622,   inf] (43), [-0.10607,   inf] (43), 
length of domains: 817
Total time: 1.0488	 pickout: 0.0436	 decision: 0.0925	 get_bound: 0.9003	 add_domain: 0.0124
Current lb:-0.12363815307617188
2172 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 24.17433786392212

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 1244] [5, 377] [3, 1244] [5, 232] [5, 377] [5, 377] [5, 377] [5, 377] [5, 377] [5, 377] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 8.852630615234375 with beta sum per layer: [0.0, 0.0, 0.0, 69.55484771728516, 8.529582977294922, 52.382816314697266]
alpha/beta optimization time: 0.7957568168640137
This batch time : update_bounds func: 0.8870	 prepare: 0.0225	 bound: 0.7962	 transfer: 0.0523	 finalize: 0.0156
Accumulated time: update_bounds func: 17.4726	 prepare: 0.3873	 bound: 15.9508	 transfer: 0.0523	 finalize: 0.3583
batch bounding time:  0.8874061107635498
Current worst splitting domains [lb, ub] (depth):
[-0.12150,   inf] (45), [-0.11785,   inf] (45), [-0.11592,   inf] (45), [-0.11587,   inf] (45), [-0.11476,   inf] (45), [-0.11416,   inf] (45), [-0.11325,   inf] (45), [-0.11277,   inf] (45), [-0.11188,   inf] (45), [-0.11073,   inf] (45), [-0.10985,   inf] (45), [-0.10934,   inf] (45), [-0.10901,   inf] (45), [-0.10868,   inf] (45), [-0.10705,   inf] (45), [-0.10688,   inf] (45), [-0.10664,   inf] (45), [-0.10551,   inf] (45), [-0.10475,   inf] (45), [-0.10468,   inf] (45), 
length of domains: 876
Total time: 1.0733	 pickout: 0.0785	 decision: 0.0939	 get_bound: 0.8876	 add_domain: 0.0133
Current lb:-0.12150198221206665
2300 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 25.24966859817505

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3035] [3, 3035] [3, 3035] [3, 3035] [5, 377] [3, 1244] [3, 3035] [3, 3035] [3, 1244] [3, 1244] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.156806945800781 with beta sum per layer: [0.0, 0.0, 0.0, 79.89251708984375, 7.033117294311523, 39.63930892944336]
alpha/beta optimization time: 0.7976725101470947
This batch time : update_bounds func: 0.8860	 prepare: 0.0222	 bound: 0.7981	 transfer: 0.0490	 finalize: 0.0162
Accumulated time: update_bounds func: 18.3586	 prepare: 0.4095	 bound: 16.7489	 transfer: 0.0490	 finalize: 0.3746
batch bounding time:  0.8863558769226074
Current worst splitting domains [lb, ub] (depth):
[-0.11936,   inf] (47), [-0.11645,   inf] (47), [-0.11554,   inf] (47), [-0.11349,   inf] (47), [-0.11319,   inf] (47), [-0.11313,   inf] (47), [-0.11244,   inf] (47), [-0.11224,   inf] (47), [-0.11129,   inf] (47), [-0.11090,   inf] (47), [-0.11050,   inf] (47), [-0.11029,   inf] (47), [-0.11001,   inf] (47), [-0.10846,   inf] (47), [-0.10791,   inf] (47), [-0.10789,   inf] (47), [-0.10718,   inf] (47), [-0.10695,   inf] (47), [-0.10682,   inf] (47), [-0.10665,   inf] (47), 
length of domains: 938
Total time: 1.0359	 pickout: 0.0434	 decision: 0.0927	 get_bound: 0.8866	 add_domain: 0.0133
Current lb:-0.11935921013355255
2428 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 26.28751230239868

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 417] [4, 417] [3, 1244] [4, 417] [4, 417] [3, 1244] [3, 3035] [5, 329] [4, 417] [4, 417] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.18181037902832 with beta sum per layer: [0.0, 0.0, 0.0, 101.21286010742188, 17.334285736083984, 20.759859085083008]
alpha/beta optimization time: 0.7903459072113037
This batch time : update_bounds func: 0.8784	 prepare: 0.0226	 bound: 0.7908	 transfer: 0.0489	 finalize: 0.0156
Accumulated time: update_bounds func: 19.2370	 prepare: 0.4322	 bound: 17.5397	 transfer: 0.0489	 finalize: 0.3902
batch bounding time:  0.878838300704956
Current worst splitting domains [lb, ub] (depth):
[-0.11732,   inf] (49), [-0.11409,   inf] (49), [-0.11350,   inf] (49), [-0.11140,   inf] (49), [-0.11106,   inf] (49), [-0.11070,   inf] (49), [-0.11036,   inf] (49), [-0.11035,   inf] (49), [-0.10909,   inf] (49), [-0.10804,   inf] (49), [-0.10786,   inf] (49), [-0.10778,   inf] (49), [-0.10760,   inf] (49), [-0.10756,   inf] (49), [-0.10739,   inf] (49), [-0.10656,   inf] (49), [-0.10595,   inf] (49), [-0.10557,   inf] (49), [-0.10538,   inf] (49), [-0.10523,   inf] (49), 
length of domains: 993
Total time: 1.0695	 pickout: 0.0827	 decision: 0.0939	 get_bound: 0.8790	 add_domain: 0.0138
Current lb:-0.1173243522644043
2556 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 27.35922074317932

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 329] [5, 329] [5, 329] [5, 329] [5, 329] [5, 329] [4, 402] [4, 402] [5, 329] [5, 329] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.662741661071777 with beta sum per layer: [0.0, 0.0, 0.0, 114.67918395996094, 6.737015247344971, 23.74837875366211]
alpha/beta optimization time: 0.7960238456726074
This batch time : update_bounds func: 0.8846	 prepare: 0.0225	 bound: 0.7965	 transfer: 0.0490	 finalize: 0.0163
Accumulated time: update_bounds func: 20.1217	 prepare: 0.4546	 bound: 18.3362	 transfer: 0.0490	 finalize: 0.4065
batch bounding time:  0.8850157260894775
Current worst splitting domains [lb, ub] (depth):
[-0.11546,   inf] (51), [-0.11222,   inf] (51), [-0.11160,   inf] (51), [-0.10960,   inf] (51), [-0.10920,   inf] (51), [-0.10878,   inf] (51), [-0.10806,   inf] (51), [-0.10804,   inf] (51), [-0.10721,   inf] (51), [-0.10619,   inf] (51), [-0.10597,   inf] (51), [-0.10569,   inf] (51), [-0.10566,   inf] (51), [-0.10519,   inf] (51), [-0.10513,   inf] (51), [-0.10510,   inf] (51), [-0.10460,   inf] (51), [-0.10419,   inf] (51), [-0.10418,   inf] (51), [-0.10386,   inf] (51), 
length of domains: 1025
Total time: 1.0369	 pickout: 0.0478	 decision: 0.0929	 get_bound: 0.8852	 add_domain: 0.0109
Current lb:-0.11546143144369125
2684 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 28.39836287498474

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 94] [5, 94] [3, 3628] [5, 94] [5, 94] [3, 3628] [5, 94] [5, 94] [5, 94] [3, 3618] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 8.792760848999023 with beta sum per layer: [0.0, 0.0, 0.0, 109.30810546875, 3.972674608230591, 28.74724769592285]
alpha/beta optimization time: 0.7821533679962158
This batch time : update_bounds func: 0.8695	 prepare: 0.0225	 bound: 0.7826	 transfer: 0.0489	 finalize: 0.0151
Accumulated time: update_bounds func: 20.9912	 prepare: 0.4771	 bound: 19.1188	 transfer: 0.0489	 finalize: 0.4216
batch bounding time:  0.8699114322662354
Current worst splitting domains [lb, ub] (depth):
[-0.11390,   inf] (53), [-0.11064,   inf] (53), [-0.10934,   inf] (53), [-0.10929,   inf] (53), [-0.10800,   inf] (53), [-0.10761,   inf] (53), [-0.10650,   inf] (53), [-0.10649,   inf] (53), [-0.10635,   inf] (53), [-0.10633,   inf] (53), [-0.10562,   inf] (53), [-0.10437,   inf] (53), [-0.10413,   inf] (53), [-0.10405,   inf] (53), [-0.10390,   inf] (53), [-0.10386,   inf] (53), [-0.10328,   inf] (53), [-0.10317,   inf] (53), [-0.10279,   inf] (53), [-0.10246,   inf] (53), 
length of domains: 1076
Total time: 1.0256	 pickout: 0.0472	 decision: 0.0941	 get_bound: 0.8701	 add_domain: 0.0142
Current lb:-0.11390435695648193
2812 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 29.425985097885132

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 380] [3, 674] [5, 94] [5, 94] [5, 323] [2, 11399] [5, 94] [5, 94] [4, 269] [4, 269] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 8.0509033203125 with beta sum per layer: [0.0, 0.0, 1.801918864250183, 108.40365600585938, 13.387251853942871, 23.947986602783203]
alpha/beta optimization time: 0.7911036014556885
This batch time : update_bounds func: 0.9376	 prepare: 0.0231	 bound: 0.7916	 transfer: 0.0491	 finalize: 0.0735
Accumulated time: update_bounds func: 21.9288	 prepare: 0.5002	 bound: 19.9104	 transfer: 0.0491	 finalize: 0.4951
batch bounding time:  0.9380018711090088
Current worst splitting domains [lb, ub] (depth):
[-0.11293,   inf] (55), [-0.10867,   inf] (55), [-0.10861,   inf] (55), [-0.10775,   inf] (55), [-0.10768,   inf] (55), [-0.10719,   inf] (55), [-0.10612,   inf] (55), [-0.10497,   inf] (55), [-0.10491,   inf] (55), [-0.10490,   inf] (55), [-0.10469,   inf] (55), [-0.10466,   inf] (55), [-0.10463,   inf] (55), [-0.10341,   inf] (55), [-0.10250,   inf] (55), [-0.10240,   inf] (55), [-0.10228,   inf] (55), [-0.10224,   inf] (55), [-0.10163,   inf] (55), [-0.10153,   inf] (55), 
length of domains: 1125
Total time: 1.0940	 pickout: 0.0483	 decision: 0.0941	 get_bound: 0.9382	 add_domain: 0.0134
Current lb:-0.11293494701385498
2940 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 30.522403955459595

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 656] [3, 3628] [3, 3628] [5, 380] [5, 380] [3, 674] [5, 380] [5, 380] [5, 380] [5, 380] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 8.252853393554688 with beta sum per layer: [0.0, 0.0, 2.920804023742676, 104.00146484375, 6.628227233886719, 28.79094886779785]
alpha/beta optimization time: 0.7892608642578125
This batch time : update_bounds func: 0.8756	 prepare: 0.0234	 bound: 0.7898	 transfer: 0.0461	 finalize: 0.0159
Accumulated time: update_bounds func: 22.8044	 prepare: 0.5236	 bound: 20.7002	 transfer: 0.0461	 finalize: 0.5110
batch bounding time:  0.8760397434234619
Current worst splitting domains [lb, ub] (depth):
[-0.11122,   inf] (57), [-0.11090,   inf] (57), [-0.10687,   inf] (57), [-0.10680,   inf] (57), [-0.10666,   inf] (57), [-0.10659,   inf] (57), [-0.10656,   inf] (57), [-0.10650,   inf] (57), [-0.10537,   inf] (57), [-0.10515,   inf] (57), [-0.10432,   inf] (57), [-0.10402,   inf] (57), [-0.10400,   inf] (57), [-0.10396,   inf] (57), [-0.10377,   inf] (57), [-0.10374,   inf] (57), [-0.10291,   inf] (57), [-0.10260,   inf] (57), [-0.10169,   inf] (57), [-0.10137,   inf] (57), 
length of domains: 1167
Total time: 1.0324	 pickout: 0.0477	 decision: 0.0942	 get_bound: 0.8763	 add_domain: 0.0142
Current lb:-0.11122119426727295
3068 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 31.55724787712097

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 674] [5, 323] [3, 2128] [3, 3618] [3, 656] [3, 656] [3, 656] [3, 656] [3, 3618] [3, 656] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.369625091552734 with beta sum per layer: [0.0, 0.0, 0.8529647588729858, 91.9323501586914, 5.450157165527344, 21.923320770263672]
alpha/beta optimization time: 0.7962422370910645
This batch time : update_bounds func: 0.8860	 prepare: 0.0237	 bound: 0.7967	 transfer: 0.0490	 finalize: 0.0162
Accumulated time: update_bounds func: 23.6905	 prepare: 0.5473	 bound: 21.4969	 transfer: 0.0490	 finalize: 0.5272
batch bounding time:  0.8863906860351562
Current worst splitting domains [lb, ub] (depth):
[-0.11004,   inf] (59), [-0.10943,   inf] (59), [-0.10877,   inf] (59), [-0.10519,   inf] (59), [-0.10505,   inf] (59), [-0.10497,   inf] (59), [-0.10487,   inf] (59), [-0.10482,   inf] (59), [-0.10477,   inf] (59), [-0.10471,   inf] (59), [-0.10466,   inf] (59), [-0.10463,   inf] (59), [-0.10455,   inf] (59), [-0.10454,   inf] (59), [-0.10448,   inf] (59), [-0.10344,   inf] (59), [-0.10343,   inf] (59), [-0.10339,   inf] (59), [-0.10311,   inf] (59), [-0.10308,   inf] (59), 
length of domains: 1216
Total time: 1.0482	 pickout: 0.0530	 decision: 0.0944	 get_bound: 0.8866	 add_domain: 0.0142
Current lb:-0.1100396141409874
3196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 32.60799288749695

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3628] [3, 3628] [3, 3628] [3, 674] [3, 674] [3, 2128] [3, 2128] [5, 380] [5, 380] [5, 380] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 8.584352493286133 with beta sum per layer: [0.0, 0.0, 0.4828457832336426, 102.2446517944336, 5.4873785972595215, 20.470781326293945]
alpha/beta optimization time: 0.7962274551391602
This batch time : update_bounds func: 0.8847	 prepare: 0.0230	 bound: 0.7967	 transfer: 0.0489	 finalize: 0.0157
Accumulated time: update_bounds func: 24.5752	 prepare: 0.5702	 bound: 22.2936	 transfer: 0.0489	 finalize: 0.5429
batch bounding time:  0.8850975036621094
Current worst splitting domains [lb, ub] (depth):
[-0.10819,   inf] (61), [-0.10803,   inf] (61), [-0.10752,   inf] (61), [-0.10737,   inf] (61), [-0.10672,   inf] (61), [-0.10661,   inf] (61), [-0.10380,   inf] (61), [-0.10375,   inf] (61), [-0.10370,   inf] (61), [-0.10364,   inf] (61), [-0.10361,   inf] (61), [-0.10353,   inf] (61), [-0.10352,   inf] (61), [-0.10349,   inf] (61), [-0.10346,   inf] (61), [-0.10336,   inf] (61), [-0.10327,   inf] (61), [-0.10318,   inf] (61), [-0.10314,   inf] (61), [-0.10304,   inf] (61), 
length of domains: 1257
Total time: 1.0430	 pickout: 0.0502	 decision: 0.0940	 get_bound: 0.8853	 add_domain: 0.0135
Current lb:-0.10819387435913086
3324 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 33.6534218788147

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 674] [3, 674] [5, 323] [5, 323] [3, 2128] [3, 2128] [5, 323] [5, 323] [3, 2128] [3, 2128] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 8.62946605682373 with beta sum per layer: [0.0, 0.0, 0.4798683524131775, 97.76533508300781, 4.017640590667725, 15.674098014831543]
alpha/beta optimization time: 0.7988114356994629
This batch time : update_bounds func: 0.8880	 prepare: 0.0232	 bound: 0.7993	 transfer: 0.0490	 finalize: 0.0161
Accumulated time: update_bounds func: 25.4632	 prepare: 0.5935	 bound: 23.0929	 transfer: 0.0490	 finalize: 0.5591
batch bounding time:  0.8883991241455078
Current worst splitting domains [lb, ub] (depth):
[-0.10663,   inf] (63), [-0.10648,   inf] (63), [-0.10638,   inf] (63), [-0.10623,   inf] (63), [-0.10569,   inf] (63), [-0.10556,   inf] (63), [-0.10506,   inf] (63), [-0.10496,   inf] (63), [-0.10475,   inf] (63), [-0.10463,   inf] (63), [-0.10291,   inf] (63), [-0.10285,   inf] (63), [-0.10271,   inf] (63), [-0.10264,   inf] (63), [-0.10206,   inf] (63), [-0.10201,   inf] (63), [-0.10187,   inf] (63), [-0.10172,   inf] (63), [-0.10172,   inf] (63), [-0.10167,   inf] (63), 
length of domains: 1300
Total time: 1.0675	 pickout: 0.0709	 decision: 0.0940	 get_bound: 0.8886	 add_domain: 0.0139
Current lb:-0.10663031041622162
3452 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 34.72327208518982

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 2128] [3, 2128] [3, 2128] [3, 2128] [3, 2128] [3, 2128] [3, 37] [5, 323] [5, 323] [5, 323] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 8.442642211914062 with beta sum per layer: [0.0, 0.0, 0.9554693102836609, 82.32772827148438, 2.761248826980591, 12.555374145507812]
alpha/beta optimization time: 0.8204762935638428
This batch time : update_bounds func: 0.9177	 prepare: 0.0236	 bound: 0.8210	 transfer: 0.0497	 finalize: 0.0230
Accumulated time: update_bounds func: 26.3809	 prepare: 0.6171	 bound: 23.9139	 transfer: 0.0497	 finalize: 0.5821
batch bounding time:  0.9181702136993408
Current worst splitting domains [lb, ub] (depth):
[-0.10506,   inf] (65), [-0.10492,   inf] (65), [-0.10465,   inf] (65), [-0.10460,   inf] (65), [-0.10454,   inf] (65), [-0.10450,   inf] (65), [-0.10444,   inf] (65), [-0.10438,   inf] (65), [-0.10407,   inf] (65), [-0.10393,   inf] (65), [-0.10387,   inf] (65), [-0.10387,   inf] (65), [-0.10376,   inf] (65), [-0.10375,   inf] (65), [-0.10374,   inf] (65), [-0.10364,   inf] (65), [-0.10130,   inf] (65), [-0.10124,   inf] (65), [-0.10118,   inf] (65), [-0.10111,   inf] (65), 
length of domains: 1344
Total time: 1.0732	 pickout: 0.0461	 decision: 0.0928	 get_bound: 0.9184	 add_domain: 0.0159
Current lb:-0.10505720227956772
3580 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 35.79920148849487

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 37] [3, 37] [3, 37] [3, 37] [3, 37] [3, 37] [3, 37] [3, 37] [3, 37] [5, 323] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 8.487651824951172 with beta sum per layer: [0.0, 0.0, 0.0, 89.4776382446289, 0.871423602104187, 14.289360046386719]
alpha/beta optimization time: 0.8410232067108154
This batch time : update_bounds func: 0.9486	 prepare: 0.0350	 bound: 0.8416	 transfer: 0.0493	 finalize: 0.0222
Accumulated time: update_bounds func: 27.3295	 prepare: 0.6521	 bound: 24.7555	 transfer: 0.0493	 finalize: 0.6043
batch bounding time:  0.9490952491760254
Current worst splitting domains [lb, ub] (depth):
[-0.10398,   inf] (67), [-0.10386,   inf] (67), [-0.10360,   inf] (67), [-0.10354,   inf] (67), [-0.10348,   inf] (67), [-0.10346,   inf] (67), [-0.10340,   inf] (67), [-0.10334,   inf] (67), [-0.10305,   inf] (67), [-0.10298,   inf] (67), [-0.10279,   inf] (67), [-0.10278,   inf] (67), [-0.10268,   inf] (67), [-0.10267,   inf] (67), [-0.10266,   inf] (67), [-0.10256,   inf] (67), [-0.10075,   inf] (67), [-0.10043,   inf] (67), [-0.10028,   inf] (67), [-0.10024,   inf] (67), 
length of domains: 1390
Total time: 1.2089	 pickout: 0.1376	 decision: 0.1050	 get_bound: 0.9493	 add_domain: 0.0169
Current lb:-0.1039750874042511
3708 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 37.01038575172424

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 439] [5, 439] [5, 439] [5, 439] [5, 439] [5, 439] [5, 439] [5, 439] [5, 439] [5, 439] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.072615623474121 with beta sum per layer: [0.0, 0.0, 0.0, 126.95719909667969, 0.20009160041809082, 34.77864456176758]
alpha/beta optimization time: 0.8357243537902832
This batch time : update_bounds func: 0.9356	 prepare: 0.0352	 bound: 0.8363	 transfer: 0.0468	 finalize: 0.0170
Accumulated time: update_bounds func: 28.2651	 prepare: 0.6873	 bound: 25.5918	 transfer: 0.0468	 finalize: 0.6212
batch bounding time:  0.9359755516052246
Current worst splitting domains [lb, ub] (depth):
[-0.10282,   inf] (69), [-0.10270,   inf] (69), [-0.10246,   inf] (69), [-0.10240,   inf] (69), [-0.10234,   inf] (69), [-0.10233,   inf] (69), [-0.10226,   inf] (69), [-0.10220,   inf] (69), [-0.10190,   inf] (69), [-0.10182,   inf] (69), [-0.10164,   inf] (69), [-0.10163,   inf] (69), [-0.10154,   inf] (69), [-0.10152,   inf] (69), [-0.10151,   inf] (69), [-0.10141,   inf] (69), [-0.09947,   inf] (69), [-0.09913,   inf] (69), [-0.09909,   inf] (69), [-0.09905,   inf] (69), 
length of domains: 1406
Total time: 1.1128	 pickout: 0.0627	 decision: 0.1026	 get_bound: 0.9362	 add_domain: 0.0112
Current lb:-0.10281902551651001
3836 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 38.12576866149902

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3618] [3, 3618] [3, 3618] [3, 3618] [3, 3618] [3, 3618] [3, 3618] [3, 3618] [3, 3618] [3, 3618] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 12.482742309570312 with beta sum per layer: [0.0, 0.0, 0.21792900562286377, 101.04646301269531, 0.004305655602365732, 2.5911335945129395]
alpha/beta optimization time: 0.8171377182006836
This batch time : update_bounds func: 0.9055	 prepare: 0.0230	 bound: 0.8176	 transfer: 0.0487	 finalize: 0.0157
Accumulated time: update_bounds func: 29.1706	 prepare: 0.7103	 bound: 26.4095	 transfer: 0.0487	 finalize: 0.6369
batch bounding time:  0.9059298038482666
Current worst splitting domains [lb, ub] (depth):
[-0.10111,   inf] (71), [-0.10109,   inf] (71), [-0.10098,   inf] (71), [-0.10098,   inf] (71), [-0.10074,   inf] (71), [-0.10074,   inf] (71), [-0.10069,   inf] (71), [-0.10067,   inf] (71), [-0.10062,   inf] (71), [-0.10060,   inf] (71), [-0.10060,   inf] (71), [-0.10059,   inf] (71), [-0.10053,   inf] (71), [-0.10052,   inf] (71), [-0.10048,   inf] (71), [-0.10048,   inf] (71), [-0.10025,   inf] (71), [-0.10017,   inf] (71), [-0.10013,   inf] (71), [-0.10003,   inf] (71), 
length of domains: 1470
Total time: 1.1416	 pickout: 0.0541	 decision: 0.1623	 get_bound: 0.9062	 add_domain: 0.0191
Current lb:-0.10110880434513092
3964 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 39.269639015197754

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 269] [4, 269] [4, 269] [4, 269] [2, 11399] [2, 11399] [2, 11399] [2, 11399] [2, 11399] [2, 11399] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.453778266906738 with beta sum per layer: [0.0, 0.0, 1.8781183958053589, 72.26493835449219, 5.853131294250488, 13.64384937286377]
alpha/beta optimization time: 0.7971572875976562
This batch time : update_bounds func: 0.8860	 prepare: 0.0231	 bound: 0.7976	 transfer: 0.0487	 finalize: 0.0161
Accumulated time: update_bounds func: 30.0566	 prepare: 0.7335	 bound: 27.2071	 transfer: 0.0487	 finalize: 0.6530
batch bounding time:  0.8863909244537354
Current worst splitting domains [lb, ub] (depth):
[-0.09984,   inf] (73), [-0.09982,   inf] (73), [-0.09971,   inf] (73), [-0.09970,   inf] (73), [-0.09960,   inf] (73), [-0.09959,   inf] (73), [-0.09953,   inf] (73), [-0.09951,   inf] (73), [-0.09947,   inf] (73), [-0.09946,   inf] (73), [-0.09946,   inf] (73), [-0.09944,   inf] (73), [-0.09937,   inf] (73), [-0.09937,   inf] (73), [-0.09933,   inf] (73), [-0.09933,   inf] (73), [-0.09900,   inf] (73), [-0.09892,   inf] (73), [-0.09888,   inf] (73), [-0.09878,   inf] (73), 
length of domains: 1519
Total time: 1.0420	 pickout: 0.0465	 decision: 0.0928	 get_bound: 0.8866	 add_domain: 0.0161
Current lb:-0.0998372882604599
4092 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 40.31402063369751

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 11399] [2, 11399] [2, 11399] [2, 11399] [4, 269] [4, 269] [4, 269] [4, 269] [4, 269] [4, 269] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.815824508666992 with beta sum per layer: [0.0, 0.0, 6.783690929412842, 40.228515625, 6.241154193878174, 10.382474899291992]
alpha/beta optimization time: 0.8031303882598877
This batch time : update_bounds func: 0.8872	 prepare: 0.0233	 bound: 0.8036	 transfer: 0.0446	 finalize: 0.0152
Accumulated time: update_bounds func: 30.9438	 prepare: 0.7568	 bound: 28.0107	 transfer: 0.0446	 finalize: 0.6682
batch bounding time:  0.8876128196716309
Current worst splitting domains [lb, ub] (depth):
[-0.09870,   inf] (75), [-0.09869,   inf] (75), [-0.09858,   inf] (75), [-0.09857,   inf] (75), [-0.09832,   inf] (75), [-0.09832,   inf] (75), [-0.09824,   inf] (75), [-0.09823,   inf] (75), [-0.09820,   inf] (75), [-0.09818,   inf] (75), [-0.09818,   inf] (75), [-0.09817,   inf] (75), [-0.09809,   inf] (75), [-0.09809,   inf] (75), [-0.09806,   inf] (75), [-0.09806,   inf] (75), [-0.09783,   inf] (75), [-0.09773,   inf] (75), [-0.09768,   inf] (75), [-0.09763,   inf] (65), 
length of domains: 1571
Total time: 1.0528	 pickout: 0.0534	 decision: 0.0936	 get_bound: 0.8878	 add_domain: 0.0180
Current lb:-0.09869611263275146
4220 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 41.369298696517944

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 11380] [2, 11380] [2, 11380] [2, 11380] [2, 11380] [2, 11380] [2, 11380] [2, 11380] [2, 11380] [2, 11380] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.86544132232666 with beta sum per layer: [0.0, 0.0, 3.860659122467041, 68.16560363769531, 1.901132345199585, 9.41369915008545]
alpha/beta optimization time: 0.8012969493865967
This batch time : update_bounds func: 0.8950	 prepare: 0.0241	 bound: 0.8018	 transfer: 0.0525	 finalize: 0.0162
Accumulated time: update_bounds func: 31.8387	 prepare: 0.7809	 bound: 28.8125	 transfer: 0.0525	 finalize: 0.6844
batch bounding time:  0.8953502178192139
Current worst splitting domains [lb, ub] (depth):
[-0.09743,   inf] (77), [-0.09739,   inf] (77), [-0.09732,   inf] (77), [-0.09726,   inf] (77), [-0.09725,   inf] (67), [-0.09725,   inf] (75), [-0.09724,   inf] (71), [-0.09724,   inf] (65), [-0.09724,   inf] (63), [-0.09723,   inf] (71), [-0.09722,   inf] (65), [-0.09721,   inf] (75), [-0.09721,   inf] (65), [-0.09720,   inf] (71), [-0.09720,   inf] (67), [-0.09720,   inf] (67), [-0.09719,   inf] (77), [-0.09718,   inf] (67), [-0.09718,   inf] (61), [-0.09717,   inf] (71), 
length of domains: 1624
Total time: 1.0572	 pickout: 0.0510	 decision: 0.0937	 get_bound: 0.8957	 add_domain: 0.0169
Current lb:-0.09743358939886093
4348 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 42.428775787353516

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3805] [3, 3805] [3, 3805] [3, 3805] [3, 3628] [2, 11380] [4, 269] [3, 674] [3, 656] [2, 11399] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.416619300842285 with beta sum per layer: [0.0, 0.0, 2.6699368953704834, 82.85591125488281, 5.767340660095215, 6.362847328186035]
alpha/beta optimization time: 0.8156445026397705
This batch time : update_bounds func: 0.9063	 prepare: 0.0237	 bound: 0.8161	 transfer: 0.0504	 finalize: 0.0157
Accumulated time: update_bounds func: 32.7451	 prepare: 0.8046	 bound: 29.6286	 transfer: 0.0504	 finalize: 0.7001
batch bounding time:  0.906712532043457
Current worst splitting domains [lb, ub] (depth):
[-0.09694,   inf] (67), [-0.09693,   inf] (71), [-0.09693,   inf] (63), [-0.09693,   inf] (71), [-0.09692,   inf] (71), [-0.09692,   inf] (77), [-0.09691,   inf] (71), [-0.09691,   inf] (63), [-0.09691,   inf] (65), [-0.09691,   inf] (77), [-0.09691,   inf] (65), [-0.09691,   inf] (77), [-0.09690,   inf] (69), [-0.09690,   inf] (71), [-0.09690,   inf] (75), [-0.09690,   inf] (67), [-0.09689,   inf] (65), [-0.09689,   inf] (71), [-0.09688,   inf] (71), [-0.09687,   inf] (77), 
length of domains: 1679
Total time: 1.0802	 pickout: 0.0613	 decision: 0.0939	 get_bound: 0.9069	 add_domain: 0.0180
Current lb:-0.09693796932697296
4476 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 43.511510133743286

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 439] [4, 269] [3, 656] [4, 269] [4, 269] [3, 3805] [4, 269] [3, 656] [2, 11399] [3, 3805] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.510550498962402 with beta sum per layer: [0.0, 0.0, 4.4914350509643555, 89.75242614746094, 5.884227752685547, 5.696979522705078]
alpha/beta optimization time: 0.8038537502288818
This batch time : update_bounds func: 0.8935	 prepare: 0.0239	 bound: 0.8044	 transfer: 0.0486	 finalize: 0.0162
Accumulated time: update_bounds func: 33.6385	 prepare: 0.8285	 bound: 30.4330	 transfer: 0.0486	 finalize: 0.7163
batch bounding time:  0.8938839435577393
Current worst splitting domains [lb, ub] (depth):
[-0.09673,   inf] (69), [-0.09673,   inf] (69), [-0.09673,   inf] (65), [-0.09673,   inf] (71), [-0.09672,   inf] (63), [-0.09671,   inf] (77), [-0.09670,   inf] (75), [-0.09670,   inf] (71), [-0.09670,   inf] (75), [-0.09670,   inf] (65), [-0.09669,   inf] (75), [-0.09669,   inf] (69), [-0.09668,   inf] (59), [-0.09668,   inf] (69), [-0.09668,   inf] (77), [-0.09667,   inf] (75), [-0.09667,   inf] (75), [-0.09667,   inf] (65), [-0.09666,   inf] (67), [-0.09666,   inf] (69), 
length of domains: 1736
Total time: 1.0530	 pickout: 0.0478	 decision: 0.0936	 get_bound: 0.8941	 add_domain: 0.0175
Current lb:-0.09673261642456055
4604 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 44.56698822975159

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 323] [5, 323] [3, 37] [2, 11399] [5, 439] [3, 3805] [2, 11380] [4, 269] [2, 11380] [5, 323] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 8.71362590789795 with beta sum per layer: [0.0, 0.0, 4.1954145431518555, 83.64883422851562, 2.53287672996521, 13.355555534362793]
alpha/beta optimization time: 0.8001456260681152
This batch time : update_bounds func: 0.8862	 prepare: 0.0236	 bound: 0.8006	 transfer: 0.0459	 finalize: 0.0158
Accumulated time: update_bounds func: 34.5248	 prepare: 0.8521	 bound: 31.2336	 transfer: 0.0459	 finalize: 0.7321
batch bounding time:  0.8866291046142578
Current worst splitting domains [lb, ub] (depth):
[-0.09647,   inf] (75), [-0.09647,   inf] (69), [-0.09647,   inf] (71), [-0.09646,   inf] (75), [-0.09645,   inf] (67), [-0.09645,   inf] (59), [-0.09645,   inf] (67), [-0.09644,   inf] (75), [-0.09643,   inf] (67), [-0.09643,   inf] (67), [-0.09642,   inf] (65), [-0.09642,   inf] (73), [-0.09642,   inf] (77), [-0.09642,   inf] (77), [-0.09641,   inf] (71), [-0.09641,   inf] (73), [-0.09641,   inf] (61), [-0.09641,   inf] (61), [-0.09641,   inf] (65), [-0.09640,   inf] (75), 
length of domains: 1784
Total time: 1.0523	 pickout: 0.0548	 decision: 0.0947	 get_bound: 0.8869	 add_domain: 0.0160
Current lb:-0.0964716374874115
4732 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 45.62169790267944

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 11380] [5, 323] [2, 11399] [2, 11380] [5, 439] [3, 2128] [5, 323] [2, 11380] [5, 439] [5, 323] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 8.830484390258789 with beta sum per layer: [0.0, 0.0, 3.5921759605407715, 93.77278900146484, 2.328573703765869, 16.039756774902344]
alpha/beta optimization time: 0.8034763336181641
This batch time : update_bounds func: 0.9823	 prepare: 0.0237	 bound: 0.8040	 transfer: 0.0449	 finalize: 0.1094
Accumulated time: update_bounds func: 35.5071	 prepare: 0.8758	 bound: 32.0376	 transfer: 0.0449	 finalize: 0.8415
batch bounding time:  0.9827837944030762
Current worst splitting domains [lb, ub] (depth):
[-0.09622,   inf] (75), [-0.09621,   inf] (59), [-0.09621,   inf] (71), [-0.09621,   inf] (59), [-0.09621,   inf] (61), [-0.09620,   inf] (65), [-0.09620,   inf] (65), [-0.09619,   inf] (65), [-0.09619,   inf] (61), [-0.09618,   inf] (67), [-0.09618,   inf] (67), [-0.09618,   inf] (65), [-0.09617,   inf] (67), [-0.09617,   inf] (65), [-0.09617,   inf] (59), [-0.09617,   inf] (77), [-0.09616,   inf] (61), [-0.09616,   inf] (71), [-0.09616,   inf] (73), [-0.09616,   inf] (71), 
length of domains: 1831
Total time: 1.1443	 pickout: 0.0505	 decision: 0.0949	 get_bound: 0.9830	 add_domain: 0.0158
Current lb:-0.09622476249933243
4860 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 46.768425941467285

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 11380] [5, 94] [2, 11399] [3, 674] [3, 2128] [3, 37] [3, 37] [5, 323] [3, 2128] [3, 37] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.331071853637695 with beta sum per layer: [0.0, 0.0, 2.4105477333068848, 156.84408569335938, 2.887876510620117, 10.520817756652832]
alpha/beta optimization time: 0.8097021579742432
This batch time : update_bounds func: 0.8760	 prepare: 0.0238	 bound: 0.8102	 transfer: 0.0253	 finalize: 0.0164
Accumulated time: update_bounds func: 36.3831	 prepare: 0.8995	 bound: 32.8478	 transfer: 0.0253	 finalize: 0.8578
batch bounding time:  0.8764011859893799
Current worst splitting domains [lb, ub] (depth):
[-0.09600,   inf] (67), [-0.09600,   inf] (77), [-0.09599,   inf] (77), [-0.09598,   inf] (79), [-0.09598,   inf] (79), [-0.09598,   inf] (73), [-0.09598,   inf] (77), [-0.09598,   inf] (59), [-0.09597,   inf] (59), [-0.09597,   inf] (71), [-0.09597,   inf] (61), [-0.09597,   inf] (77), [-0.09596,   inf] (59), [-0.09596,   inf] (63), [-0.09596,   inf] (65), [-0.09596,   inf] (67), [-0.09596,   inf] (65), [-0.09596,   inf] (67), [-0.09596,   inf] (77), [-0.09596,   inf] (73), 
length of domains: 1885
Total time: 1.0311	 pickout: 0.0446	 decision: 0.0933	 get_bound: 0.8766	 add_domain: 0.0167
Current lb:-0.09599719941616058
4988 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 47.80187511444092

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 37] [3, 3805] [3, 3805] [4, 292] [4, 292] [3, 3805] [3, 3805] [3, 674] [5, 323] [2, 11399] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.69479751586914 with beta sum per layer: [0.0, 0.0, 2.1427764892578125, 105.57426452636719, 6.977071762084961, 12.162521362304688]
alpha/beta optimization time: 0.8015131950378418
This batch time : update_bounds func: 0.8948	 prepare: 0.0242	 bound: 0.8020	 transfer: 0.0520	 finalize: 0.0162
Accumulated time: update_bounds func: 37.2779	 prepare: 0.9237	 bound: 33.6498	 transfer: 0.0520	 finalize: 0.8740
batch bounding time:  0.8952016830444336
Current worst splitting domains [lb, ub] (depth):
[-0.09583,   inf] (67), [-0.09583,   inf] (79), [-0.09583,   inf] (67), [-0.09582,   inf] (73), [-0.09581,   inf] (67), [-0.09581,   inf] (79), [-0.09581,   inf] (77), [-0.09581,   inf] (77), [-0.09581,   inf] (69), [-0.09581,   inf] (71), [-0.09580,   inf] (69), [-0.09580,   inf] (73), [-0.09580,   inf] (63), [-0.09580,   inf] (67), [-0.09579,   inf] (77), [-0.09579,   inf] (67), [-0.09579,   inf] (71), [-0.09579,   inf] (73), [-0.09578,   inf] (67), [-0.09578,   inf] (79), 
length of domains: 1936
Total time: 1.0579	 pickout: 0.0501	 decision: 0.0957	 get_bound: 0.8954	 add_domain: 0.0166
Current lb:-0.09583432227373123
5116 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 48.86220383644104

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 439] [4, 292] [3, 37] [3, 3805] [3, 37] [4, 292] [3, 3805] [3, 3805] [5, 439] [2, 11399] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.841423988342285 with beta sum per layer: [0.0, 0.0, 4.036005973815918, 107.25877380371094, 6.70151424407959, 11.804863929748535]
alpha/beta optimization time: 0.7974498271942139
This batch time : update_bounds func: 0.8909	 prepare: 0.0237	 bound: 0.7979	 transfer: 0.0521	 finalize: 0.0167
Accumulated time: update_bounds func: 38.1688	 prepare: 0.9474	 bound: 34.4477	 transfer: 0.0521	 finalize: 0.8907
batch bounding time:  0.8912878036499023
Current worst splitting domains [lb, ub] (depth):
[-0.09564,   inf] (69), [-0.09564,   inf] (53), [-0.09564,   inf] (59), [-0.09564,   inf] (79), [-0.09563,   inf] (71), [-0.09563,   inf] (67), [-0.09563,   inf] (77), [-0.09563,   inf] (71), [-0.09562,   inf] (73), [-0.09562,   inf] (67), [-0.09562,   inf] (79), [-0.09562,   inf] (77), [-0.09562,   inf] (67), [-0.09561,   inf] (67), [-0.09561,   inf] (73), [-0.09561,   inf] (51), [-0.09561,   inf] (79), [-0.09561,   inf] (73), [-0.09560,   inf] (79), [-0.09560,   inf] (73), 
length of domains: 1988
Total time: 1.0543	 pickout: 0.0514	 decision: 0.0946	 get_bound: 0.8915	 add_domain: 0.0168
Current lb:-0.09564203023910522
5244 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 49.918962240219116

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 439] [4, 417] [5, 380] [4, 292] [2, 11399] [3, 37] [3, 3805] [2, 11399] [3, 3805] [3, 37] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.01624870300293 with beta sum per layer: [0.0, 0.0, 3.136852741241455, 127.03163146972656, 9.79006576538086, 15.713590621948242]
alpha/beta optimization time: 0.8143458366394043
This batch time : update_bounds func: 0.9109	 prepare: 0.0236	 bound: 0.8148	 transfer: 0.0492	 finalize: 0.0229
Accumulated time: update_bounds func: 39.0797	 prepare: 0.9710	 bound: 35.2626	 transfer: 0.0492	 finalize: 0.9136
batch bounding time:  0.9113080501556396
Current worst splitting domains [lb, ub] (depth):
[-0.09552,   inf] (77), [-0.09551,   inf] (77), [-0.09551,   inf] (69), [-0.09551,   inf] (63), [-0.09551,   inf] (79), [-0.09551,   inf] (63), [-0.09550,   inf] (65), [-0.09550,   inf] (77), [-0.09550,   inf] (73), [-0.09550,   inf] (67), [-0.09550,   inf] (51), [-0.09550,   inf] (79), [-0.09549,   inf] (67), [-0.09549,   inf] (73), [-0.09549,   inf] (73), [-0.09549,   inf] (57), [-0.09549,   inf] (73), [-0.09549,   inf] (79), [-0.09549,   inf] (77), [-0.09549,   inf] (73), 
length of domains: 2037
Total time: 1.0980	 pickout: 0.0736	 decision: 0.0952	 get_bound: 0.9116	 add_domain: 0.0177
Current lb:-0.09551532566547394
5372 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 51.01969075202942

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3805] [3, 3805] [2, 11399] [3, 3628] [4, 292] [3, 656] [3, 2128] [3, 3805] [2, 11380] [5, 323] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.20627212524414 with beta sum per layer: [0.0, 0.0, 4.255591869354248, 93.2388916015625, 12.416439056396484, 9.616945266723633]
alpha/beta optimization time: 0.8204607963562012
This batch time : update_bounds func: 0.9240	 prepare: 0.0367	 bound: 0.8211	 transfer: 0.0491	 finalize: 0.0167
Accumulated time: update_bounds func: 40.0037	 prepare: 1.0077	 bound: 36.0837	 transfer: 0.0491	 finalize: 0.9303
batch bounding time:  0.9244208335876465
Current worst splitting domains [lb, ub] (depth):
[-0.09538,   inf] (79), [-0.09538,   inf] (69), [-0.09538,   inf] (67), [-0.09538,   inf] (63), [-0.09538,   inf] (69), [-0.09538,   inf] (71), [-0.09538,   inf] (73), [-0.09538,   inf] (77), [-0.09538,   inf] (65), [-0.09538,   inf] (77), [-0.09538,   inf] (79), [-0.09537,   inf] (67), [-0.09537,   inf] (59), [-0.09537,   inf] (59), [-0.09537,   inf] (69), [-0.09536,   inf] (79), [-0.09536,   inf] (77), [-0.09536,   inf] (77), [-0.09536,   inf] (63), [-0.09535,   inf] (57), 
length of domains: 2094
Total time: 1.1044	 pickout: 0.0582	 decision: 0.1042	 get_bound: 0.9246	 add_domain: 0.0174
Current lb:-0.09538453817367554
5500 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 52.126524925231934

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 292] [2, 11399] [5, 323] [3, 656] [2, 11399] [2, 11399] [3, 3805] [3, 3805] [3, 656] [3, 3805] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.047115325927734 with beta sum per layer: [0.0, 0.0, 4.819382667541504, 73.31290435791016, 13.43908977508545, 14.383628845214844]
alpha/beta optimization time: 0.8417010307312012
This batch time : update_bounds func: 0.9295	 prepare: 0.0240	 bound: 0.8422	 transfer: 0.0461	 finalize: 0.0167
Accumulated time: update_bounds func: 40.9332	 prepare: 1.0317	 bound: 36.9259	 transfer: 0.0461	 finalize: 0.9470
batch bounding time:  0.929889440536499
Current worst splitting domains [lb, ub] (depth):
[-0.09527,   inf] (77), [-0.09526,   inf] (77), [-0.09526,   inf] (69), [-0.09526,   inf] (61), [-0.09526,   inf] (49), [-0.09525,   inf] (77), [-0.09525,   inf] (69), [-0.09524,   inf] (79), [-0.09524,   inf] (77), [-0.09524,   inf] (63), [-0.09524,   inf] (79), [-0.09524,   inf] (79), [-0.09524,   inf] (73), [-0.09524,   inf] (67), [-0.09524,   inf] (77), [-0.09523,   inf] (57), [-0.09522,   inf] (79), [-0.09522,   inf] (67), [-0.09522,   inf] (67), [-0.09522,   inf] (79), 
length of domains: 2146
Total time: 1.0928	 pickout: 0.0494	 decision: 0.0963	 get_bound: 0.9301	 add_domain: 0.0170
Current lb:-0.09526586532592773
5628 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 53.222208976745605

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3805] [3, 3805] [5, 439] [3, 3618] [3, 674] [3, 3805] [2, 11399] [4, 292] [3, 3805] [5, 380] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 8.303346633911133 with beta sum per layer: [0.0, 0.0, 4.737732887268066, 94.29452514648438, 12.369573593139648, 15.936942100524902]
alpha/beta optimization time: 0.8219239711761475
This batch time : update_bounds func: 0.9160	 prepare: 0.0243	 bound: 0.8224	 transfer: 0.0521	 finalize: 0.0167
Accumulated time: update_bounds func: 41.8492	 prepare: 1.0561	 bound: 37.7483	 transfer: 0.0521	 finalize: 0.9637
batch bounding time:  0.9164149761199951
Current worst splitting domains [lb, ub] (depth):
[-0.09514,   inf] (79), [-0.09514,   inf] (81), [-0.09514,   inf] (71), [-0.09513,   inf] (51), [-0.09513,   inf] (67), [-0.09513,   inf] (67), [-0.09513,   inf] (61), [-0.09512,   inf] (77), [-0.09512,   inf] (71), [-0.09512,   inf] (79), [-0.09512,   inf] (61), [-0.09512,   inf] (77), [-0.09512,   inf] (67), [-0.09511,   inf] (63), [-0.09511,   inf] (61), [-0.09511,   inf] (63), [-0.09511,   inf] (79), [-0.09511,   inf] (81), [-0.09511,   inf] (81), [-0.09510,   inf] (79), 
length of domains: 2193
Total time: 1.0846	 pickout: 0.0566	 decision: 0.0955	 get_bound: 0.9166	 add_domain: 0.0159
Current lb:-0.09514341503381729
5756 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 54.30939698219299

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 292] [5, 43] [4, 417] [5, 94] [5, 439] [5, 323] [5, 380] [3, 3805] [3, 3618] [4, 292] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 8.816180229187012 with beta sum per layer: [0.0, 0.0, 3.2514805793762207, 114.29266357421875, 11.711764335632324, 17.91812515258789]
alpha/beta optimization time: 0.8074970245361328
This batch time : update_bounds func: 0.8961	 prepare: 0.0244	 bound: 0.8080	 transfer: 0.0472	 finalize: 0.0161
Accumulated time: update_bounds func: 42.7453	 prepare: 1.0804	 bound: 38.5563	 transfer: 0.0472	 finalize: 0.9798
batch bounding time:  0.8964970111846924
Current worst splitting domains [lb, ub] (depth):
[-0.09501,   inf] (79), [-0.09500,   inf] (67), [-0.09500,   inf] (77), [-0.09500,   inf] (63), [-0.09500,   inf] (69), [-0.09500,   inf] (53), [-0.09499,   inf] (77), [-0.09499,   inf] (69), [-0.09499,   inf] (81), [-0.09499,   inf] (69), [-0.09498,   inf] (71), [-0.09498,   inf] (77), [-0.09498,   inf] (79), [-0.09498,   inf] (73), [-0.09498,   inf] (55), [-0.09498,   inf] (67), [-0.09497,   inf] (61), [-0.09497,   inf] (73), [-0.09497,   inf] (59), [-0.09497,   inf] (73), 
length of domains: 2241
Total time: 1.1691	 pickout: 0.0708	 decision: 0.1846	 get_bound: 0.8967	 add_domain: 0.0170
Current lb:-0.0950060486793518
5884 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 55.481348752975464

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 292] [5, 439] [3, 3805] [5, 439] [4, 269] [5, 94] [3, 3805] [5, 439] [5, 43] [5, 439] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.461860656738281 with beta sum per layer: [0.0, 0.0, 4.493480205535889, 117.47892761230469, 10.1807861328125, 17.704769134521484]
alpha/beta optimization time: 0.8037412166595459
This batch time : update_bounds func: 0.8926	 prepare: 0.0244	 bound: 0.8042	 transfer: 0.0470	 finalize: 0.0165
Accumulated time: update_bounds func: 43.6379	 prepare: 1.1048	 bound: 39.3605	 transfer: 0.0470	 finalize: 0.9962
batch bounding time:  0.8929755687713623
Current worst splitting domains [lb, ub] (depth):
[-0.09484,   inf] (67), [-0.09484,   inf] (63), [-0.09483,   inf] (77), [-0.09483,   inf] (77), [-0.09483,   inf] (73), [-0.09483,   inf] (49), [-0.09483,   inf] (59), [-0.09483,   inf] (69), [-0.09482,   inf] (69), [-0.09482,   inf] (69), [-0.09482,   inf] (69), [-0.09482,   inf] (79), [-0.09481,   inf] (79), [-0.09481,   inf] (79), [-0.09481,   inf] (69), [-0.09480,   inf] (69), [-0.09480,   inf] (49), [-0.09480,   inf] (57), [-0.09480,   inf] (69), [-0.09479,   inf] (59), 
length of domains: 2291
Total time: 1.0535	 pickout: 0.0491	 decision: 0.0947	 get_bound: 0.8932	 add_domain: 0.0165
Current lb:-0.09483904391527176
6012 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 56.537527561187744

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 439] [2, 11399] [3, 3805] [3, 3805] [3, 3805] [5, 329] [3, 674] [5, 439] [5, 439] [5, 439] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.767358779907227 with beta sum per layer: [0.0, 0.0, 5.176682472229004, 104.35337829589844, 10.57151985168457, 16.22775650024414]
alpha/beta optimization time: 0.7986712455749512
This batch time : update_bounds func: 0.8655	 prepare: 0.0241	 bound: 0.7992	 transfer: 0.0261	 finalize: 0.0158
Accumulated time: update_bounds func: 44.5034	 prepare: 1.1289	 bound: 40.1597	 transfer: 0.0261	 finalize: 1.0120
batch bounding time:  0.8659698963165283
Current worst splitting domains [lb, ub] (depth):
[-0.09469,   inf] (79), [-0.09469,   inf] (75), [-0.09469,   inf] (79), [-0.09468,   inf] (57), [-0.09468,   inf] (69), [-0.09468,   inf] (73), [-0.09468,   inf] (73), [-0.09467,   inf] (73), [-0.09467,   inf] (79), [-0.09467,   inf] (69), [-0.09467,   inf] (79), [-0.09466,   inf] (73), [-0.09466,   inf] (61), [-0.09466,   inf] (81), [-0.09466,   inf] (71), [-0.09466,   inf] (77), [-0.09466,   inf] (75), [-0.09466,   inf] (69), [-0.09466,   inf] (75), [-0.09465,   inf] (79), 
length of domains: 2345
Total time: 1.0281	 pickout: 0.0489	 decision: 0.0944	 get_bound: 0.8662	 add_domain: 0.0185
Current lb:-0.09468863904476166
6140 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 57.56817317008972

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 292] [2, 11380] [4, 292] [5, 94] [3, 3618] [4, 269] [4, 269] [4, 269] [4, 292] [5, 439] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.395751953125 with beta sum per layer: [0.0, 0.0, 3.6328976154327393, 112.39962768554688, 11.384692192077637, 16.96173095703125]
alpha/beta optimization time: 0.8157856464385986
This batch time : update_bounds func: 0.9066	 prepare: 0.0244	 bound: 0.8163	 transfer: 0.0491	 finalize: 0.0165
Accumulated time: update_bounds func: 45.4100	 prepare: 1.1533	 bound: 40.9759	 transfer: 0.0491	 finalize: 1.0285
batch bounding time:  0.9070439338684082
Current worst splitting domains [lb, ub] (depth):
[-0.09460,   inf] (71), [-0.09460,   inf] (79), [-0.09460,   inf] (75), [-0.09459,   inf] (53), [-0.09459,   inf] (69), [-0.09459,   inf] (75), [-0.09459,   inf] (73), [-0.09459,   inf] (79), [-0.09459,   inf] (81), [-0.09459,   inf] (75), [-0.09459,   inf] (75), [-0.09459,   inf] (75), [-0.09458,   inf] (79), [-0.09458,   inf] (79), [-0.09458,   inf] (81), [-0.09458,   inf] (69), [-0.09458,   inf] (51), [-0.09458,   inf] (61), [-0.09458,   inf] (73), [-0.09457,   inf] (69), 
length of domains: 2399
Total time: 1.0792	 pickout: 0.0602	 decision: 0.0943	 get_bound: 0.9073	 add_domain: 0.0174
Current lb:-0.09459735453128815
6268 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 58.64985370635986

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 269] [4, 292] [2, 11380] [5, 329] [5, 439] [2, 11380] [3, 3805] [4, 292] [5, 43] [2, 11380] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 8.630757331848145 with beta sum per layer: [0.0, 0.0, 4.690573215484619, 102.66853332519531, 13.339120864868164, 14.961503982543945]
alpha/beta optimization time: 0.7970812320709229
This batch time : update_bounds func: 0.8872	 prepare: 0.0241	 bound: 0.7976	 transfer: 0.0486	 finalize: 0.0165
Accumulated time: update_bounds func: 46.2972	 prepare: 1.1773	 bound: 41.7735	 transfer: 0.0486	 finalize: 1.0451
batch bounding time:  0.8875973224639893
Current worst splitting domains [lb, ub] (depth):
[-0.09450,   inf] (69), [-0.09450,   inf] (71), [-0.09450,   inf] (75), [-0.09449,   inf] (61), [-0.09449,   inf] (81), [-0.09449,   inf] (79), [-0.09448,   inf] (69), [-0.09448,   inf] (53), [-0.09448,   inf] (75), [-0.09448,   inf] (79), [-0.09448,   inf] (75), [-0.09448,   inf] (65), [-0.09448,   inf] (67), [-0.09448,   inf] (57), [-0.09447,   inf] (57), [-0.09447,   inf] (75), [-0.09447,   inf] (73), [-0.09447,   inf] (73), [-0.09447,   inf] (67), [-0.09447,   inf] (79), 
length of domains: 2452
Total time: 1.0784	 pickout: 0.0745	 decision: 0.0949	 get_bound: 0.8878	 add_domain: 0.0213
Current lb:-0.0944972038269043
6396 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 59.731664180755615

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 439] [3, 3618] [2, 11380] [3, 37] [5, 43] [4, 292] [5, 439] [4, 417] [2, 11380] [4, 292] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.116436958312988 with beta sum per layer: [0.0, 0.0, 5.642210006713867, 93.08106994628906, 9.678129196166992, 19.45549201965332]
alpha/beta optimization time: 0.7964825630187988
This batch time : update_bounds func: 0.8913	 prepare: 0.0255	 bound: 0.7970	 transfer: 0.0518	 finalize: 0.0166
Accumulated time: update_bounds func: 47.1885	 prepare: 1.2028	 bound: 42.5705	 transfer: 0.0518	 finalize: 1.0617
batch bounding time:  0.8917057514190674
Current worst splitting domains [lb, ub] (depth):
[-0.09441,   inf] (69), [-0.09440,   inf] (75), [-0.09440,   inf] (73), [-0.09440,   inf] (79), [-0.09440,   inf] (81), [-0.09440,   inf] (81), [-0.09440,   inf] (57), [-0.09440,   inf] (69), [-0.09439,   inf] (55), [-0.09439,   inf] (69), [-0.09439,   inf] (79), [-0.09439,   inf] (61), [-0.09439,   inf] (79), [-0.09439,   inf] (51), [-0.09438,   inf] (79), [-0.09438,   inf] (69), [-0.09438,   inf] (73), [-0.09438,   inf] (79), [-0.09438,   inf] (81), [-0.09438,   inf] (75), 
length of domains: 2505
Total time: 1.0543	 pickout: 0.0484	 decision: 0.0967	 get_bound: 0.8919	 add_domain: 0.0172
Current lb:-0.09440501034259796
6524 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 60.7886061668396

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3618] [2, 11380] [3, 3805] [4, 292] [5, 43] [5, 43] [5, 323] [5, 439] [4, 302] [5, 439] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.43754768371582 with beta sum per layer: [0.0, 0.0, 4.876276016235352, 96.43824768066406, 10.386402130126953, 17.9998779296875]
alpha/beta optimization time: 0.8022847175598145
This batch time : update_bounds func: 0.8923	 prepare: 0.0241	 bound: 0.8028	 transfer: 0.0490	 finalize: 0.0160
Accumulated time: update_bounds func: 48.0808	 prepare: 1.2270	 bound: 43.3732	 transfer: 0.0490	 finalize: 1.0777
batch bounding time:  0.8927276134490967
Current worst splitting domains [lb, ub] (depth):
[-0.09431,   inf] (79), [-0.09431,   inf] (75), [-0.09431,   inf] (69), [-0.09431,   inf] (69), [-0.09430,   inf] (69), [-0.09430,   inf] (65), [-0.09430,   inf] (75), [-0.09430,   inf] (81), [-0.09429,   inf] (73), [-0.09429,   inf] (75), [-0.09429,   inf] (79), [-0.09429,   inf] (61), [-0.09429,   inf] (75), [-0.09428,   inf] (81), [-0.09428,   inf] (75), [-0.09428,   inf] (61), [-0.09428,   inf] (75), [-0.09428,   inf] (73), [-0.09428,   inf] (69), [-0.09428,   inf] (61), 
length of domains: 2561
Total time: 1.0603	 pickout: 0.0526	 decision: 0.0958	 get_bound: 0.8929	 add_domain: 0.0190
Current lb:-0.09431193023920059
6652 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 61.85176086425781

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 292] [2, 11380] [5, 439] [5, 439] [3, 3618] [3, 2128] [3, 3805] [5, 43] [4, 269] [2, 11380] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.072200775146484 with beta sum per layer: [0.0, 0.0, 3.3977813720703125, 118.97268676757812, 8.160623550415039, 15.779476165771484]
alpha/beta optimization time: 0.8008723258972168
This batch time : update_bounds func: 0.9981	 prepare: 0.0241	 bound: 0.8014	 transfer: 0.0522	 finalize: 0.1201
Accumulated time: update_bounds func: 49.0789	 prepare: 1.2510	 bound: 44.1746	 transfer: 0.0522	 finalize: 1.1977
batch bounding time:  0.9985430240631104
Current worst splitting domains [lb, ub] (depth):
[-0.09422,   inf] (79), [-0.09422,   inf] (69), [-0.09422,   inf] (65), [-0.09422,   inf] (75), [-0.09421,   inf] (81), [-0.09421,   inf] (81), [-0.09421,   inf] (55), [-0.09421,   inf] (79), [-0.09421,   inf] (61), [-0.09421,   inf] (71), [-0.09421,   inf] (61), [-0.09421,   inf] (69), [-0.09421,   inf] (71), [-0.09421,   inf] (79), [-0.09421,   inf] (79), [-0.09420,   inf] (81), [-0.09420,   inf] (75), [-0.09420,   inf] (71), [-0.09420,   inf] (81), [-0.09419,   inf] (81), 
length of domains: 2617
Total time: 1.1951	 pickout: 0.0803	 decision: 0.0985	 get_bound: 0.9988	 add_domain: 0.0175
Current lb:-0.09422314912080765
6780 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 63.04924440383911

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 292] [3, 2128] [3, 2128] [2, 11380] [5, 43] [5, 43] [3, 3628] [4, 292] [3, 37] [4, 269] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.912919044494629 with beta sum per layer: [0.0, 0.0, 3.317322015762329, 91.38304901123047, 10.363136291503906, 14.783685684204102]
alpha/beta optimization time: 0.8304076194763184
This batch time : update_bounds func: 0.9206	 prepare: 0.0247	 bound: 0.8309	 transfer: 0.0485	 finalize: 0.0161
Accumulated time: update_bounds func: 49.9995	 prepare: 1.2757	 bound: 45.0055	 transfer: 0.0485	 finalize: 1.2139
batch bounding time:  0.9210617542266846
Current worst splitting domains [lb, ub] (depth):
[-0.09414,   inf] (79), [-0.09414,   inf] (79), [-0.09413,   inf] (45), [-0.09413,   inf] (61), [-0.09413,   inf] (69), [-0.09413,   inf] (67), [-0.09413,   inf] (73), [-0.09413,   inf] (79), [-0.09413,   inf] (59), [-0.09412,   inf] (65), [-0.09412,   inf] (71), [-0.09412,   inf] (43), [-0.09412,   inf] (47), [-0.09412,   inf] (75), [-0.09412,   inf] (75), [-0.09412,   inf] (61), [-0.09411,   inf] (75), [-0.09411,   inf] (75), [-0.09411,   inf] (75), [-0.09411,   inf] (65), 
length of domains: 2674
Total time: 1.0831	 pickout: 0.0481	 decision: 0.0950	 get_bound: 0.9213	 add_domain: 0.0187
Current lb:-0.09413599967956543
6908 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 64.1351466178894

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 292] [4, 292] [5, 377] [5, 439] [5, 439] [2, 11399] [3, 3805] [4, 292] [5, 380] [3, 2128] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 8.884075164794922 with beta sum per layer: [0.0, 0.0, 5.977012634277344, 88.45813751220703, 13.046686172485352, 18.66741943359375]
alpha/beta optimization time: 0.7953109741210938
This batch time : update_bounds func: 0.8857	 prepare: 0.0243	 bound: 0.7958	 transfer: 0.0484	 finalize: 0.0168
Accumulated time: update_bounds func: 50.8852	 prepare: 1.3000	 bound: 45.8012	 transfer: 0.0484	 finalize: 1.2307
batch bounding time:  0.8860650062561035
Current worst splitting domains [lb, ub] (depth):
[-0.09404,   inf] (79), [-0.09404,   inf] (79), [-0.09404,   inf] (73), [-0.09403,   inf] (63), [-0.09403,   inf] (79), [-0.09403,   inf] (67), [-0.09402,   inf] (81), [-0.09402,   inf] (65), [-0.09402,   inf] (69), [-0.09402,   inf] (73), [-0.09402,   inf] (73), [-0.09402,   inf] (73), [-0.09402,   inf] (73), [-0.09402,   inf] (61), [-0.09401,   inf] (83), [-0.09401,   inf] (69), [-0.09401,   inf] (79), [-0.09401,   inf] (81), [-0.09401,   inf] (71), [-0.09401,   inf] (49), 
length of domains: 2726
Total time: 1.0522	 pickout: 0.0549	 decision: 0.0941	 get_bound: 0.8863	 add_domain: 0.0169
Current lb:-0.09403657913208008
7036 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 65.18985199928284

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 292] [4, 292] [3, 37] [3, 656] [4, 292] [5, 439] [5, 43] [3, 2128] [3, 3618] [3, 3805] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.445202827453613 with beta sum per layer: [0.0, 0.0, 6.615257263183594, 82.22200775146484, 13.3021240234375, 16.381181716918945]
alpha/beta optimization time: 0.8364810943603516
This batch time : update_bounds func: 0.9271	 prepare: 0.0250	 bound: 0.8370	 transfer: 0.0485	 finalize: 0.0160
Accumulated time: update_bounds func: 51.8123	 prepare: 1.3250	 bound: 46.6382	 transfer: 0.0485	 finalize: 1.2467
batch bounding time:  0.9274692535400391
Current worst splitting domains [lb, ub] (depth):
[-0.09394,   inf] (67), [-0.09393,   inf] (79), [-0.09393,   inf] (79), [-0.09393,   inf] (49), [-0.09393,   inf] (43), [-0.09393,   inf] (67), [-0.09393,   inf] (81), [-0.09393,   inf] (83), [-0.09393,   inf] (79), [-0.09392,   inf] (75), [-0.09392,   inf] (65), [-0.09392,   inf] (69), [-0.09392,   inf] (79), [-0.09392,   inf] (69), [-0.09392,   inf] (75), [-0.09392,   inf] (75), [-0.09392,   inf] (69), [-0.09392,   inf] (79), [-0.09391,   inf] (65), [-0.09391,   inf] (75), 
length of domains: 2781
Total time: 1.0889	 pickout: 0.0478	 decision: 0.0949	 get_bound: 0.9277	 add_domain: 0.0185
Current lb:-0.09393501281738281
7164 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 66.28125596046448

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 439] [4, 292] [4, 292] [3, 674] [5, 232] [5, 439] [5, 43] [2, 14025] [4, 292] [2, 11380] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.765459060668945 with beta sum per layer: [0.0, 0.0, 6.345864295959473, 96.34955596923828, 9.581977844238281, 17.49296760559082]
alpha/beta optimization time: 0.7997114658355713
This batch time : update_bounds func: 0.8902	 prepare: 0.0241	 bound: 0.8002	 transfer: 0.0486	 finalize: 0.0169
Accumulated time: update_bounds func: 52.7025	 prepare: 1.3491	 bound: 47.4384	 transfer: 0.0486	 finalize: 1.2636
batch bounding time:  0.890587329864502
Current worst splitting domains [lb, ub] (depth):
[-0.09386,   inf] (67), [-0.09386,   inf] (69), [-0.09386,   inf] (53), [-0.09386,   inf] (75), [-0.09386,   inf] (81), [-0.09386,   inf] (69), [-0.09385,   inf] (71), [-0.09385,   inf] (79), [-0.09385,   inf] (75), [-0.09385,   inf] (75), [-0.09385,   inf] (67), [-0.09385,   inf] (79), [-0.09385,   inf] (73), [-0.09385,   inf] (57), [-0.09385,   inf] (39), [-0.09384,   inf] (83), [-0.09384,   inf] (53), [-0.09384,   inf] (79), [-0.09384,   inf] (65), [-0.09384,   inf] (79), 
length of domains: 2836
Total time: 1.0536	 pickout: 0.0513	 decision: 0.0940	 get_bound: 0.8908	 add_domain: 0.0175
Current lb:-0.09386346489191055
7292 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 67.33738470077515

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 323] [3, 3618] [5, 329] [3, 3805] [5, 43] [3, 3618] [3, 37] [4, 292] [2, 11380] [2, 11380] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.133838653564453 with beta sum per layer: [0.0, 0.0, 7.285671234130859, 95.14814758300781, 11.536371231079102, 16.77120590209961]
alpha/beta optimization time: 0.8223276138305664
This batch time : update_bounds func: 0.9358	 prepare: 0.0504	 bound: 0.8231	 transfer: 0.0456	 finalize: 0.0159
Accumulated time: update_bounds func: 53.6382	 prepare: 1.3995	 bound: 48.2615	 transfer: 0.0456	 finalize: 1.2795
batch bounding time:  0.9361655712127686
Current worst splitting domains [lb, ub] (depth):
[-0.09378,   inf] (69), [-0.09377,   inf] (69), [-0.09377,   inf] (73), [-0.09377,   inf] (79), [-0.09377,   inf] (67), [-0.09377,   inf] (75), [-0.09377,   inf] (49), [-0.09376,   inf] (55), [-0.09376,   inf] (79), [-0.09376,   inf] (75), [-0.09376,   inf] (75), [-0.09376,   inf] (67), [-0.09375,   inf] (71), [-0.09375,   inf] (61), [-0.09375,   inf] (65), [-0.09375,   inf] (69), [-0.09375,   inf] (81), [-0.09374,   inf] (65), [-0.09374,   inf] (81), [-0.09374,   inf] (75), 
length of domains: 2893
Total time: 1.1078	 pickout: 0.0527	 decision: 0.0998	 get_bound: 0.9364	 add_domain: 0.0189
Current lb:-0.09377666562795639
7420 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 68.44765853881836

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3618] [2, 11399] [3, 3805] [4, 292] [5, 439] [3, 3805] [3, 674] [4, 417] [4, 292] [2, 11380] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.559061050415039 with beta sum per layer: [0.0, 0.0, 5.918198585510254, 77.86454772949219, 11.015312194824219, 18.92221450805664]
alpha/beta optimization time: 0.7952554225921631
This batch time : update_bounds func: 0.8855	 prepare: 0.0242	 bound: 0.7957	 transfer: 0.0485	 finalize: 0.0167
Accumulated time: update_bounds func: 54.5237	 prepare: 1.4237	 bound: 49.0572	 transfer: 0.0485	 finalize: 1.2961
batch bounding time:  0.8858873844146729
Current worst splitting domains [lb, ub] (depth):
[-0.09369,   inf] (47), [-0.09369,   inf] (79), [-0.09369,   inf] (79), [-0.09369,   inf] (75), [-0.09369,   inf] (83), [-0.09369,   inf] (79), [-0.09369,   inf] (81), [-0.09368,   inf] (69), [-0.09368,   inf] (71), [-0.09368,   inf] (73), [-0.09368,   inf] (77), [-0.09368,   inf] (79), [-0.09368,   inf] (71), [-0.09367,   inf] (79), [-0.09367,   inf] (83), [-0.09367,   inf] (81), [-0.09367,   inf] (81), [-0.09367,   inf] (79), [-0.09367,   inf] (83), [-0.09367,   inf] (81), 
length of domains: 2951
Total time: 1.0704	 pickout: 0.0718	 decision: 0.0943	 get_bound: 0.8861	 add_domain: 0.0182
Current lb:-0.09369191527366638
7548 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 69.52103590965271

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 31] [4, 292] [4, 292] [2, 11380] [2, 7846] [4, 292] [5, 43] [3, 3618] [3, 3805] [3, 3805] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 8.857131958007812 with beta sum per layer: [0.0, 0.0, 7.118993282318115, 95.60360717773438, 12.167952537536621, 20.7376651763916]
alpha/beta optimization time: 0.8242671489715576
This batch time : update_bounds func: 0.9142	 prepare: 0.0283	 bound: 0.8249	 transfer: 0.0448	 finalize: 0.0158
Accumulated time: update_bounds func: 55.4379	 prepare: 1.4520	 bound: 49.8821	 transfer: 0.0448	 finalize: 1.3120
batch bounding time:  0.9145703315734863
Current worst splitting domains [lb, ub] (depth):
[-0.09360,   inf] (83), [-0.09360,   inf] (57), [-0.09360,   inf] (79), [-0.09360,   inf] (75), [-0.09359,   inf] (71), [-0.09359,   inf] (77), [-0.09359,   inf] (65), [-0.09359,   inf] (79), [-0.09359,   inf] (79), [-0.09359,   inf] (81), [-0.09359,   inf] (63), [-0.09358,   inf] (65), [-0.09358,   inf] (83), [-0.09358,   inf] (55), [-0.09358,   inf] (61), [-0.09358,   inf] (65), [-0.09358,   inf] (77), [-0.09358,   inf] (65), [-0.09357,   inf] (71), [-0.09357,   inf] (81), 
length of domains: 3004
Total time: 1.0764	 pickout: 0.0479	 decision: 0.0950	 get_bound: 0.9148	 add_domain: 0.0186
Current lb:-0.09360027313232422
7676 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 70.6005425453186

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 7846] [4, 302] [4, 292] [2, 11380] [3, 37] [4, 292] [3, 2128] [4, 292] [4, 292] [5, 43] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.452552795410156 with beta sum per layer: [0.0, 0.0, 8.91621208190918, 106.59430694580078, 12.447470664978027, 14.232847213745117]
alpha/beta optimization time: 0.7978236675262451
This batch time : update_bounds func: 0.9879	 prepare: 0.0253	 bound: 0.7983	 transfer: 0.0295	 finalize: 0.1344
Accumulated time: update_bounds func: 56.4258	 prepare: 1.4773	 bound: 50.6805	 transfer: 0.0295	 finalize: 1.4463
batch bounding time:  0.9883475303649902
Current worst splitting domains [lb, ub] (depth):
[-0.09353,   inf] (77), [-0.09353,   inf] (79), [-0.09353,   inf] (67), [-0.09352,   inf] (81), [-0.09352,   inf] (83), [-0.09352,   inf] (71), [-0.09352,   inf] (57), [-0.09352,   inf] (83), [-0.09351,   inf] (65), [-0.09351,   inf] (71), [-0.09351,   inf] (49), [-0.09350,   inf] (71), [-0.09350,   inf] (71), [-0.09350,   inf] (81), [-0.09350,   inf] (81), [-0.09350,   inf] (69), [-0.09350,   inf] (81), [-0.09350,   inf] (77), [-0.09350,   inf] (63), [-0.09350,   inf] (83), 
length of domains: 3061
Total time: 1.1523	 pickout: 0.0519	 decision: 0.0940	 get_bound: 0.9886	 add_domain: 0.0178
Current lb:-0.09352699667215347
7804 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 71.75530099868774

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 292] [4, 292] [5, 439] [5, 43] [2, 7846] [3, 3618] [3, 656] [2, 7846] [3, 674] [3, 3805] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.006563186645508 with beta sum per layer: [0.0, 0.0, 9.019279479980469, 106.96295166015625, 11.704840660095215, 18.56232261657715]
alpha/beta optimization time: 0.8241591453552246
This batch time : update_bounds func: 0.9170	 prepare: 0.0243	 bound: 0.8247	 transfer: 0.0516	 finalize: 0.0160
Accumulated time: update_bounds func: 57.3427	 prepare: 1.5016	 bound: 51.5051	 transfer: 0.0516	 finalize: 1.4623
batch bounding time:  0.9173901081085205
Current worst splitting domains [lb, ub] (depth):
[-0.09344,   inf] (51), [-0.09344,   inf] (83), [-0.09343,   inf] (57), [-0.09343,   inf] (63), [-0.09343,   inf] (65), [-0.09343,   inf] (63), [-0.09343,   inf] (45), [-0.09343,   inf] (61), [-0.09343,   inf] (71), [-0.09343,   inf] (79), [-0.09342,   inf] (81), [-0.09342,   inf] (71), [-0.09342,   inf] (73), [-0.09342,   inf] (79), [-0.09342,   inf] (79), [-0.09342,   inf] (77), [-0.09342,   inf] (71), [-0.09342,   inf] (67), [-0.09342,   inf] (59), [-0.09342,   inf] (79), 
length of domains: 3114
Total time: 1.0775	 pickout: 0.0452	 decision: 0.0960	 get_bound: 0.9176	 add_domain: 0.0187
Current lb:-0.09344173222780228
7932 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 72.83559679985046

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 402] [2, 7846] [4, 302] [3, 656] [5, 323] [3, 677] [5, 232] [3, 37] [3, 3618] [4, 292] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.410265922546387 with beta sum per layer: [0.0, 0.0, 10.560314178466797, 98.00108337402344, 11.351037979125977, 16.70197868347168]
alpha/beta optimization time: 0.8227198123931885
This batch time : update_bounds func: 0.9106	 prepare: 0.0243	 bound: 0.8232	 transfer: 0.0462	 finalize: 0.0165
Accumulated time: update_bounds func: 58.2533	 prepare: 1.5259	 bound: 52.3283	 transfer: 0.0462	 finalize: 1.4788
batch bounding time:  0.9109888076782227
Current worst splitting domains [lb, ub] (depth):
[-0.09337,   inf] (75), [-0.09336,   inf] (63), [-0.09336,   inf] (81), [-0.09335,   inf] (81), [-0.09335,   inf] (63), [-0.09335,   inf] (59), [-0.09335,   inf] (71), [-0.09335,   inf] (75), [-0.09335,   inf] (77), [-0.09335,   inf] (71), [-0.09335,   inf] (75), [-0.09335,   inf] (59), [-0.09335,   inf] (71), [-0.09335,   inf] (83), [-0.09335,   inf] (77), [-0.09334,   inf] (55), [-0.09334,   inf] (61), [-0.09334,   inf] (79), [-0.09334,   inf] (83), [-0.09334,   inf] (79), 
length of domains: 3170
Total time: 1.0812	 pickout: 0.0541	 decision: 0.0981	 get_bound: 0.9112	 add_domain: 0.0178
Current lb:-0.09336566925048828
8060 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 73.91945028305054

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 43] [3, 3618] [5, 43] [5, 43] [3, 656] [4, 302] [3, 3618] [5, 43] [2, 11380] [3, 3805] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.8875732421875 with beta sum per layer: [0.0, 0.0, 7.020656108856201, 101.32283020019531, 9.255620002746582, 17.52582550048828]
alpha/beta optimization time: 0.8208858966827393
This batch time : update_bounds func: 0.8860	 prepare: 0.0244	 bound: 0.8214	 transfer: 0.0239	 finalize: 0.0158
Accumulated time: update_bounds func: 59.1393	 prepare: 1.5503	 bound: 53.1497	 transfer: 0.0239	 finalize: 1.4946
batch bounding time:  0.8864607810974121
Current worst splitting domains [lb, ub] (depth):
[-0.09329,   inf] (77), [-0.09329,   inf] (77), [-0.09329,   inf] (83), [-0.09329,   inf] (83), [-0.09329,   inf] (75), [-0.09329,   inf] (83), [-0.09329,   inf] (83), [-0.09329,   inf] (71), [-0.09329,   inf] (57), [-0.09329,   inf] (81), [-0.09328,   inf] (75), [-0.09328,   inf] (59), [-0.09328,   inf] (71), [-0.09328,   inf] (67), [-0.09328,   inf] (69), [-0.09328,   inf] (75), [-0.09328,   inf] (75), [-0.09328,   inf] (83), [-0.09328,   inf] (73), [-0.09327,   inf] (67), 
length of domains: 3229
Total time: 1.0560	 pickout: 0.0554	 decision: 0.0945	 get_bound: 0.8867	 add_domain: 0.0194
Current lb:-0.09329342842102051
8188 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 74.97803950309753

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 11380] [4, 292] [2, 7846] [2, 11386] [2, 11380] [2, 14025] [2, 7846] [4, 269] [5, 380] [5, 43] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.979423522949219 with beta sum per layer: [0.0, 0.0, 9.671487808227539, 104.721923828125, 9.68087100982666, 13.473910331726074]
alpha/beta optimization time: 0.8133077621459961
This batch time : update_bounds func: 0.9071	 prepare: 0.0246	 bound: 0.8138	 transfer: 0.0516	 finalize: 0.0167
Accumulated time: update_bounds func: 60.0465	 prepare: 1.5749	 bound: 53.9635	 transfer: 0.0516	 finalize: 1.5114
batch bounding time:  0.9075274467468262
Current worst splitting domains [lb, ub] (depth):
[-0.09322,   inf] (75), [-0.09322,   inf] (71), [-0.09322,   inf] (85), [-0.09322,   inf] (59), [-0.09322,   inf] (53), [-0.09321,   inf] (49), [-0.09321,   inf] (77), [-0.09321,   inf] (77), [-0.09321,   inf] (75), [-0.09321,   inf] (79), [-0.09321,   inf] (57), [-0.09321,   inf] (71), [-0.09321,   inf] (83), [-0.09321,   inf] (63), [-0.09320,   inf] (65), [-0.09320,   inf] (63), [-0.09320,   inf] (77), [-0.09320,   inf] (71), [-0.09320,   inf] (85), [-0.09320,   inf] (71), 
length of domains: 3288
Total time: 1.0769	 pickout: 0.0567	 decision: 0.0938	 get_bound: 0.9077	 add_domain: 0.0186
Current lb:-0.0932168960571289
8316 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 76.05733489990234

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 11380] [4, 269] [3, 677] [5, 94] [5, 329] [4, 417] [4, 292] [4, 292] [2, 11380] [4, 292] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.706131935119629 with beta sum per layer: [0.0, 0.0, 5.4944167137146, 115.78123474121094, 10.233621597290039, 19.91859245300293]
alpha/beta optimization time: 0.8077423572540283
This batch time : update_bounds func: 0.8954	 prepare: 0.0245	 bound: 0.8082	 transfer: 0.0463	 finalize: 0.0160
Accumulated time: update_bounds func: 60.9419	 prepare: 1.5994	 bound: 54.7717	 transfer: 0.0463	 finalize: 1.5274
batch bounding time:  0.8958570957183838
Current worst splitting domains [lb, ub] (depth):
[-0.09315,   inf] (61), [-0.09315,   inf] (77), [-0.09314,   inf] (77), [-0.09314,   inf] (77), [-0.09314,   inf] (81), [-0.09314,   inf] (71), [-0.09314,   inf] (73), [-0.09314,   inf] (77), [-0.09314,   inf] (83), [-0.09314,   inf] (71), [-0.09314,   inf] (83), [-0.09313,   inf] (81), [-0.09313,   inf] (75), [-0.09313,   inf] (71), [-0.09313,   inf] (77), [-0.09313,   inf] (83), [-0.09313,   inf] (75), [-0.09313,   inf] (59), [-0.09312,   inf] (63), [-0.09312,   inf] (41), 
length of domains: 3349
Total time: 1.0646	 pickout: 0.0525	 decision: 0.0962	 get_bound: 0.8961	 add_domain: 0.0198
Current lb:-0.09314632415771484
8444 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 77.12462258338928

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3805] [4, 292] [3, 3805] [4, 292] [5, 43] [3, 3805] [3, 3618] [4, 292] [2, 14025] [4, 269] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.015750885009766 with beta sum per layer: [0.0, 0.0, 8.746906280517578, 95.6961441040039, 11.011757850646973, 15.864316940307617]
alpha/beta optimization time: 0.795569896697998
This batch time : update_bounds func: 0.8645	 prepare: 0.0245	 bound: 0.7961	 transfer: 0.0270	 finalize: 0.0166
Accumulated time: update_bounds func: 61.8064	 prepare: 1.6239	 bound: 55.5678	 transfer: 0.0270	 finalize: 1.5439
batch bounding time:  0.8648905754089355
Current worst splitting domains [lb, ub] (depth):
[-0.09307,   inf] (77), [-0.09307,   inf] (77), [-0.09306,   inf] (81), [-0.09306,   inf] (77), [-0.09306,   inf] (75), [-0.09306,   inf] (75), [-0.09306,   inf] (77), [-0.09306,   inf] (75), [-0.09306,   inf] (77), [-0.09306,   inf] (77), [-0.09305,   inf] (71), [-0.09305,   inf] (51), [-0.09305,   inf] (71), [-0.09305,   inf] (77), [-0.09305,   inf] (83), [-0.09305,   inf] (71), [-0.09305,   inf] (81), [-0.09304,   inf] (81), [-0.09304,   inf] (71), [-0.09304,   inf] (65), 
length of domains: 3410
Total time: 1.0346	 pickout: 0.0564	 decision: 0.0944	 get_bound: 0.8651	 add_domain: 0.0187
Current lb:-0.09306810051202774
8572 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 78.16174721717834

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 292] [4, 292] [5, 43] [3, 3805] [2, 11380] [5, 43] [4, 292] [2, 11380] [3, 3805] [4, 292] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.698135375976562 with beta sum per layer: [0.0, 0.0, 6.950531959533691, 111.18008422851562, 10.592815399169922, 13.081938743591309]
alpha/beta optimization time: 0.8612070083618164
This batch time : update_bounds func: 0.9641	 prepare: 0.0374	 bound: 0.8618	 transfer: 0.0484	 finalize: 0.0159
Accumulated time: update_bounds func: 62.7705	 prepare: 1.6613	 bound: 56.4296	 transfer: 0.0484	 finalize: 1.5599
batch bounding time:  0.9645030498504639
Current worst splitting domains [lb, ub] (depth):
[-0.09300,   inf] (77), [-0.09300,   inf] (81), [-0.09300,   inf] (63), [-0.09300,   inf] (75), [-0.09300,   inf] (59), [-0.09300,   inf] (85), [-0.09299,   inf] (81), [-0.09299,   inf] (77), [-0.09299,   inf] (75), [-0.09299,   inf] (77), [-0.09299,   inf] (75), [-0.09299,   inf] (77), [-0.09299,   inf] (77), [-0.09299,   inf] (63), [-0.09299,   inf] (77), [-0.09299,   inf] (75), [-0.09298,   inf] (77), [-0.09298,   inf] (81), [-0.09298,   inf] (65), [-0.09298,   inf] (77), 
length of domains: 3470
Total time: 1.1482	 pickout: 0.0522	 decision: 0.1112	 get_bound: 0.9647	 add_domain: 0.0200
Current lb:-0.09299718588590622
8700 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 79.31259512901306

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 292] [5, 43] [5, 439] [2, 11380] [3, 2128] [3, 677] [5, 43] [3, 3805] [2, 11380] [4, 292] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.346251487731934 with beta sum per layer: [0.0, 0.0, 6.563686847686768, 93.24308776855469, 8.690593719482422, 18.86001205444336]
alpha/beta optimization time: 0.8157570362091064
This batch time : update_bounds func: 0.9031	 prepare: 0.0246	 bound: 0.8162	 transfer: 0.0445	 finalize: 0.0173
Accumulated time: update_bounds func: 63.6735	 prepare: 1.6859	 bound: 57.2459	 transfer: 0.0445	 finalize: 1.5772
batch bounding time:  0.9034867286682129
Current worst splitting domains [lb, ub] (depth):
[-0.09293,   inf] (75), [-0.09293,   inf] (75), [-0.09293,   inf] (77), [-0.09293,   inf] (69), [-0.09293,   inf] (71), [-0.09292,   inf] (77), [-0.09292,   inf] (77), [-0.09292,   inf] (83), [-0.09292,   inf] (81), [-0.09292,   inf] (81), [-0.09292,   inf] (73), [-0.09292,   inf] (77), [-0.09292,   inf] (71), [-0.09292,   inf] (85), [-0.09292,   inf] (81), [-0.09292,   inf] (75), [-0.09291,   inf] (45), [-0.09291,   inf] (69), [-0.09291,   inf] (47), [-0.09291,   inf] (73), 
length of domains: 3528
Total time: 1.0707	 pickout: 0.0539	 decision: 0.0943	 get_bound: 0.9037	 add_domain: 0.0188
Current lb:-0.09292936325073242
8828 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 80.3860137462616

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 11380] [5, 43] [4, 292] [2, 11399] [4, 269] [2, 11380] [4, 292] [3, 677] [5, 43] [5, 43] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.647253036499023 with beta sum per layer: [0.0, 0.0, 6.595119476318359, 102.8555908203125, 9.588271141052246, 13.660621643066406]
alpha/beta optimization time: 0.8135130405426025
This batch time : update_bounds func: 1.0360	 prepare: 0.0254	 bound: 0.8141	 transfer: 0.0487	 finalize: 0.0161
Accumulated time: update_bounds func: 64.7096	 prepare: 1.7112	 bound: 58.0599	 transfer: 0.0487	 finalize: 1.5933
batch bounding time:  1.0364224910736084
Current worst splitting domains [lb, ub] (depth):
[-0.09287,   inf] (61), [-0.09287,   inf] (77), [-0.09287,   inf] (83), [-0.09287,   inf] (83), [-0.09287,   inf] (71), [-0.09287,   inf] (81), [-0.09286,   inf] (71), [-0.09286,   inf] (71), [-0.09286,   inf] (77), [-0.09286,   inf] (71), [-0.09286,   inf] (85), [-0.09286,   inf] (69), [-0.09286,   inf] (77), [-0.09286,   inf] (75), [-0.09285,   inf] (77), [-0.09285,   inf] (81), [-0.09285,   inf] (81), [-0.09285,   inf] (77), [-0.09285,   inf] (63), [-0.09285,   inf] (67), 
length of domains: 3587
Total time: 1.2073	 pickout: 0.0566	 decision: 0.0955	 get_bound: 1.0367	 add_domain: 0.0185
Current lb:-0.09287238121032715
8956 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 81.59620976448059

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 37] [5, 43] [2, 14025] [3, 677] [3, 2128] [5, 43] [4, 269] [4, 269] [3, 3805] [4, 269] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.744269371032715 with beta sum per layer: [0.0, 0.0, 6.784924030303955, 104.14260864257812, 9.240096092224121, 17.072261810302734]
alpha/beta optimization time: 0.8253788948059082
This batch time : update_bounds func: 0.9167	 prepare: 0.0247	 bound: 0.8259	 transfer: 0.0488	 finalize: 0.0169
Accumulated time: update_bounds func: 65.6263	 prepare: 1.7359	 bound: 58.8858	 transfer: 0.0488	 finalize: 1.6102
batch bounding time:  0.9171180725097656
Current worst splitting domains [lb, ub] (depth):
[-0.09281,   inf] (77), [-0.09281,   inf] (61), [-0.09281,   inf] (81), [-0.09281,   inf] (69), [-0.09281,   inf] (71), [-0.09281,   inf] (85), [-0.09281,   inf] (81), [-0.09281,   inf] (75), [-0.09281,   inf] (81), [-0.09281,   inf] (81), [-0.09280,   inf] (59), [-0.09280,   inf] (83), [-0.09280,   inf] (69), [-0.09280,   inf] (71), [-0.09280,   inf] (67), [-0.09280,   inf] (83), [-0.09280,   inf] (61), [-0.09280,   inf] (77), [-0.09280,   inf] (77), [-0.09280,   inf] (81), 
length of domains: 3644
Total time: 1.0903	 pickout: 0.0591	 decision: 0.0957	 get_bound: 0.9173	 add_domain: 0.0182
Current lb:-0.09281450510025024
9084 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 82.68941926956177

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3805] [3, 674] [5, 43] [2, 11399] [4, 269] [2, 11386] [5, 43] [2, 11380] [5, 43] [5, 43] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.079683303833008 with beta sum per layer: [0.0, 0.0, 7.284913539886475, 102.466796875, 10.313276290893555, 15.57748794555664]
alpha/beta optimization time: 0.8203799724578857
This batch time : update_bounds func: 0.9147	 prepare: 0.0246	 bound: 0.8209	 transfer: 0.0516	 finalize: 0.0163
Accumulated time: update_bounds func: 66.5409	 prepare: 1.7605	 bound: 59.7067	 transfer: 0.0516	 finalize: 1.6264
batch bounding time:  0.9150826930999756
Current worst splitting domains [lb, ub] (depth):
[-0.09275,   inf] (77), [-0.09275,   inf] (73), [-0.09275,   inf] (75), [-0.09275,   inf] (71), [-0.09275,   inf] (75), [-0.09275,   inf] (77), [-0.09275,   inf] (71), [-0.09275,   inf] (81), [-0.09275,   inf] (71), [-0.09274,   inf] (57), [-0.09274,   inf] (77), [-0.09274,   inf] (67), [-0.09274,   inf] (83), [-0.09274,   inf] (65), [-0.09274,   inf] (71), [-0.09274,   inf] (71), [-0.09274,   inf] (77), [-0.09274,   inf] (75), [-0.09274,   inf] (85), [-0.09274,   inf] (55), 
length of domains: 3704
Total time: 1.0813	 pickout: 0.0539	 decision: 0.0935	 get_bound: 0.9153	 add_domain: 0.0186
Current lb:-0.09274935722351074
9212 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 83.77334022521973

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 292] [3, 3618] [2, 11380] [3, 2128] [2, 11380] [3, 3805] [4, 269] [5, 43] [3, 3628] [5, 323] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.488523483276367 with beta sum per layer: [0.0, 0.0, 9.370231628417969, 108.93228149414062, 10.500574111938477, 14.695188522338867]
alpha/beta optimization time: 0.8025393486022949
This batch time : update_bounds func: 0.8939	 prepare: 0.0246	 bound: 0.8030	 transfer: 0.0490	 finalize: 0.0168
Accumulated time: update_bounds func: 67.4348	 prepare: 1.7851	 bound: 60.5097	 transfer: 0.0490	 finalize: 1.6433
batch bounding time:  0.8942685127258301
Current worst splitting domains [lb, ub] (depth):
[-0.09270,   inf] (81), [-0.09270,   inf] (75), [-0.09270,   inf] (65), [-0.09270,   inf] (81), [-0.09270,   inf] (59), [-0.09270,   inf] (63), [-0.09270,   inf] (85), [-0.09270,   inf] (83), [-0.09270,   inf] (53), [-0.09270,   inf] (65), [-0.09270,   inf] (59), [-0.09270,   inf] (69), [-0.09269,   inf] (79), [-0.09269,   inf] (85), [-0.09269,   inf] (77), [-0.09269,   inf] (77), [-0.09269,   inf] (71), [-0.09269,   inf] (77), [-0.09269,   inf] (75), [-0.09269,   inf] (77), 
length of domains: 3760
Total time: 1.0633	 pickout: 0.0553	 decision: 0.0950	 get_bound: 0.8945	 add_domain: 0.0185
Current lb:-0.09270481765270233
9340 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 84.83941698074341

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 43] [2, 11380] [3, 3618] [5, 43] [3, 2128] [5, 323] [2, 11365] [2, 11386] [5, 329] [3, 674] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.418380737304688 with beta sum per layer: [0.0, 0.0, 8.20600700378418, 105.12564849853516, 6.994142532348633, 17.159469604492188]
alpha/beta optimization time: 0.8075783252716064
This batch time : update_bounds func: 0.8985	 prepare: 0.0245	 bound: 0.8081	 transfer: 0.0484	 finalize: 0.0163
Accumulated time: update_bounds func: 68.3333	 prepare: 1.8096	 bound: 61.3178	 transfer: 0.0484	 finalize: 1.6595
batch bounding time:  0.8989253044128418
Current worst splitting domains [lb, ub] (depth):
[-0.09265,   inf] (83), [-0.09265,   inf] (77), [-0.09265,   inf] (77), [-0.09265,   inf] (77), [-0.09264,   inf] (63), [-0.09264,   inf] (63), [-0.09264,   inf] (77), [-0.09264,   inf] (75), [-0.09264,   inf] (67), [-0.09264,   inf] (75), [-0.09264,   inf] (75), [-0.09264,   inf] (51), [-0.09264,   inf] (83), [-0.09264,   inf] (83), [-0.09264,   inf] (81), [-0.09264,   inf] (57), [-0.09263,   inf] (79), [-0.09263,   inf] (71), [-0.09263,   inf] (49), [-0.09263,   inf] (77), 
length of domains: 3816
Total time: 1.0668	 pickout: 0.0552	 decision: 0.0939	 get_bound: 0.8992	 add_domain: 0.0185
Current lb:-0.09264695644378662
9468 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 85.90907120704651

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 7846] [4, 292] [3, 3805] [4, 292] [3, 656] [3, 656] [4, 292] [2, 11380] [2, 11399] [5, 43] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.434356689453125 with beta sum per layer: [0.0, 0.0, 10.827136993408203, 100.64070129394531, 8.721513748168945, 14.633960723876953]
alpha/beta optimization time: 0.825270414352417
This batch time : update_bounds func: 0.9195	 prepare: 0.0247	 bound: 0.8259	 transfer: 0.0517	 finalize: 0.0167
Accumulated time: update_bounds func: 69.2527	 prepare: 1.8342	 bound: 62.1436	 transfer: 0.0517	 finalize: 1.6763
batch bounding time:  0.9198703765869141
Current worst splitting domains [lb, ub] (depth):
[-0.09259,   inf] (61), [-0.09259,   inf] (83), [-0.09259,   inf] (75), [-0.09258,   inf] (75), [-0.09258,   inf] (75), [-0.09258,   inf] (81), [-0.09258,   inf] (65), [-0.09258,   inf] (81), [-0.09258,   inf] (81), [-0.09257,   inf] (85), [-0.09257,   inf] (83), [-0.09257,   inf] (77), [-0.09257,   inf] (83), [-0.09257,   inf] (81), [-0.09257,   inf] (77), [-0.09257,   inf] (71), [-0.09257,   inf] (85), [-0.09257,   inf] (77), [-0.09257,   inf] (85), [-0.09256,   inf] (71), 
length of domains: 3874
Total time: 1.0854	 pickout: 0.0500	 decision: 0.0964	 get_bound: 0.9201	 add_domain: 0.0188
Current lb:-0.09258883446455002
9596 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 86.99720191955566

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 656] [2, 14025] [2, 11380] [2, 11380] [5, 43] [5, 43] [3, 674] [5, 43] [5, 43] [2, 11365] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.180660247802734 with beta sum per layer: [0.0, 0.0, 11.466506958007812, 94.4332504272461, 6.41749906539917, 14.263113975524902]
alpha/beta optimization time: 0.818842887878418
This batch time : update_bounds func: 0.9125	 prepare: 0.0272	 bound: 0.8194	 transfer: 0.0483	 finalize: 0.0162
Accumulated time: update_bounds func: 70.1652	 prepare: 1.8615	 bound: 62.9630	 transfer: 0.0483	 finalize: 1.6925
batch bounding time:  0.912935733795166
Current worst splitting domains [lb, ub] (depth):
[-0.09252,   inf] (75), [-0.09252,   inf] (77), [-0.09252,   inf] (67), [-0.09252,   inf] (77), [-0.09252,   inf] (77), [-0.09252,   inf] (71), [-0.09252,   inf] (71), [-0.09251,   inf] (85), [-0.09251,   inf] (71), [-0.09251,   inf] (85), [-0.09251,   inf] (81), [-0.09251,   inf] (81), [-0.09251,   inf] (81), [-0.09251,   inf] (67), [-0.09251,   inf] (63), [-0.09250,   inf] (63), [-0.09250,   inf] (75), [-0.09250,   inf] (77), [-0.09250,   inf] (83), [-0.09250,   inf] (77), 
length of domains: 3935
Total time: 1.0894	 pickout: 0.0613	 decision: 0.0955	 get_bound: 0.9132	 add_domain: 0.0194
Current lb:-0.0925193727016449
9724 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 88.08928918838501

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 11380] [4, 292] [3, 2128] [3, 3805] [4, 292] [4, 269] [4, 269] [2, 7846] [4, 269] [2, 11386] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.654945373535156 with beta sum per layer: [0.0, 0.0, 13.454736709594727, 116.537109375, 8.373708724975586, 13.168099403381348]
alpha/beta optimization time: 0.8038411140441895
This batch time : update_bounds func: 0.8946	 prepare: 0.0249	 bound: 0.8043	 transfer: 0.0484	 finalize: 0.0166
Accumulated time: update_bounds func: 71.0598	 prepare: 1.8863	 bound: 63.7674	 transfer: 0.0484	 finalize: 1.7091
batch bounding time:  0.8950166702270508
Current worst splitting domains [lb, ub] (depth):
[-0.09246,   inf] (67), [-0.09246,   inf] (65), [-0.09246,   inf] (77), [-0.09246,   inf] (73), [-0.09246,   inf] (77), [-0.09246,   inf] (85), [-0.09246,   inf] (81), [-0.09246,   inf] (83), [-0.09245,   inf] (77), [-0.09245,   inf] (77), [-0.09245,   inf] (85), [-0.09245,   inf] (57), [-0.09245,   inf] (85), [-0.09245,   inf] (39), [-0.09245,   inf] (75), [-0.09245,   inf] (75), [-0.09245,   inf] (81), [-0.09245,   inf] (61), [-0.09245,   inf] (75), [-0.09245,   inf] (63), 
length of domains: 3992
Total time: 1.0638	 pickout: 0.0539	 decision: 0.0960	 get_bound: 0.8953	 add_domain: 0.0186
Current lb:-0.09245824813842773
9852 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 89.15577960014343

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3618] [5, 323] [5, 43] [4, 269] [5, 43] [2, 11365] [5, 43] [2, 14025] [3, 3805] [4, 292] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.502737045288086 with beta sum per layer: [0.0, 0.0, 10.274991989135742, 113.24240112304688, 9.129755973815918, 16.37040901184082]
alpha/beta optimization time: 0.8086388111114502
This batch time : update_bounds func: 0.8994	 prepare: 0.0244	 bound: 0.8091	 transfer: 0.0485	 finalize: 0.0161
Accumulated time: update_bounds func: 71.9592	 prepare: 1.9107	 bound: 64.5765	 transfer: 0.0485	 finalize: 1.7252
batch bounding time:  0.8998146057128906
Current worst splitting domains [lb, ub] (depth):
[-0.09240,   inf] (65), [-0.09240,   inf] (85), [-0.09240,   inf] (77), [-0.09240,   inf] (73), [-0.09240,   inf] (83), [-0.09240,   inf] (77), [-0.09240,   inf] (65), [-0.09239,   inf] (85), [-0.09239,   inf] (71), [-0.09239,   inf] (79), [-0.09239,   inf] (71), [-0.09239,   inf] (75), [-0.09239,   inf] (67), [-0.09239,   inf] (77), [-0.09238,   inf] (71), [-0.09238,   inf] (75), [-0.09238,   inf] (61), [-0.09238,   inf] (67), [-0.09238,   inf] (81), [-0.09238,   inf] (85), 
length of domains: 4049
Total time: 1.0941	 pickout: 0.0811	 decision: 0.0947	 get_bound: 0.9000	 add_domain: 0.0182
Current lb:-0.09240412712097168
9980 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 90.25264716148376

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 380] [2, 7846] [2, 14025] [5, 43] [3, 677] [4, 292] [3, 674] [2, 11386] [2, 11399] [5, 43] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 8.71829605102539 with beta sum per layer: [0.0, 0.0, 8.173162460327148, 98.1009292602539, 6.8783369064331055, 21.624975204467773]
alpha/beta optimization time: 0.8000118732452393
This batch time : update_bounds func: 1.0460	 prepare: 0.0248	 bound: 0.8005	 transfer: 0.0482	 finalize: 0.1720
Accumulated time: update_bounds func: 73.0052	 prepare: 1.9355	 bound: 65.3770	 transfer: 0.0482	 finalize: 1.8972
batch bounding time:  1.046506404876709
Current worst splitting domains [lb, ub] (depth):
[-0.09234,   inf] (65), [-0.09234,   inf] (63), [-0.09233,   inf] (79), [-0.09233,   inf] (77), [-0.09233,   inf] (77), [-0.09233,   inf] (59), [-0.09233,   inf] (77), [-0.09233,   inf] (79), [-0.09233,   inf] (77), [-0.09233,   inf] (63), [-0.09232,   inf] (81), [-0.09232,   inf] (83), [-0.09232,   inf] (79), [-0.09232,   inf] (55), [-0.09232,   inf] (77), [-0.09232,   inf] (67), [-0.09232,   inf] (83), [-0.09232,   inf] (61), [-0.09232,   inf] (63), [-0.09232,   inf] (73), 
length of domains: 4103
Total time: 1.2146	 pickout: 0.0541	 decision: 0.0959	 get_bound: 1.0468	 add_domain: 0.0179
Current lb:-0.09233713150024414
10108 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 91.46998858451843

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 323] [3, 656] [5, 43] [4, 292] [3, 3805] [5, 323] [2, 11380] [5, 43] [2, 11380] [3, 37] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 8.905333518981934 with beta sum per layer: [0.0, 0.0, 7.830381870269775, 120.28704833984375, 6.5686869621276855, 20.34099769592285]
alpha/beta optimization time: 0.8023691177368164
This batch time : update_bounds func: 0.8968	 prepare: 0.0247	 bound: 0.8029	 transfer: 0.0516	 finalize: 0.0172
Accumulated time: update_bounds func: 73.9020	 prepare: 1.9602	 bound: 66.1799	 transfer: 0.0516	 finalize: 1.9145
batch bounding time:  0.8972983360290527
Current worst splitting domains [lb, ub] (depth):
[-0.09227,   inf] (63), [-0.09227,   inf] (31), [-0.09227,   inf] (67), [-0.09227,   inf] (67), [-0.09227,   inf] (79), [-0.09226,   inf] (77), [-0.09226,   inf] (71), [-0.09226,   inf] (45), [-0.09226,   inf] (73), [-0.09226,   inf] (83), [-0.09226,   inf] (73), [-0.09226,   inf] (79), [-0.09226,   inf] (73), [-0.09226,   inf] (85), [-0.09226,   inf] (77), [-0.09225,   inf] (79), [-0.09225,   inf] (73), [-0.09225,   inf] (79), [-0.09225,   inf] (67), [-0.09225,   inf] (85), 
length of domains: 4157
Total time: 1.0690	 pickout: 0.0597	 decision: 0.0942	 get_bound: 0.8975	 add_domain: 0.0175
Current lb:-0.09227192401885986
10236 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 92.54183745384216

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 37] [5, 291] [2, 7846] [5, 439] [2, 11386] [2, 11380] [2, 11399] [5, 377] [4, 269] [2, 14025] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.480609893798828 with beta sum per layer: [0.0, 0.0, 11.226486206054688, 99.74559020996094, 6.561887741088867, 18.066389083862305]
alpha/beta optimization time: 0.7984750270843506
This batch time : update_bounds func: 0.8897	 prepare: 0.0247	 bound: 0.7990	 transfer: 0.0486	 finalize: 0.0170
Accumulated time: update_bounds func: 74.7917	 prepare: 1.9848	 bound: 66.9789	 transfer: 0.0486	 finalize: 1.9315
batch bounding time:  0.8900842666625977
Current worst splitting domains [lb, ub] (depth):
[-0.09221,   inf] (73), [-0.09221,   inf] (73), [-0.09221,   inf] (79), [-0.09221,   inf] (73), [-0.09221,   inf] (59), [-0.09221,   inf] (67), [-0.09220,   inf] (65), [-0.09220,   inf] (77), [-0.09220,   inf] (79), [-0.09220,   inf] (85), [-0.09220,   inf] (79), [-0.09220,   inf] (79), [-0.09220,   inf] (85), [-0.09220,   inf] (67), [-0.09219,   inf] (63), [-0.09219,   inf] (67), [-0.09219,   inf] (79), [-0.09219,   inf] (75), [-0.09219,   inf] (41), [-0.09219,   inf] (71), 
length of domains: 4213
Total time: 1.0671	 pickout: 0.0615	 decision: 0.0970	 get_bound: 0.8903	 add_domain: 0.0183
Current lb:-0.09221100807189941
10364 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 93.61166858673096

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 11380] [5, 43] [5, 43] [5, 43] [5, 380] [5, 439] [3, 674] [3, 3805] [5, 43] [2, 11365] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.654722213745117 with beta sum per layer: [0.0, 0.0, 9.064043045043945, 124.320068359375, 4.107994556427002, 19.671741485595703]
alpha/beta optimization time: 0.8036041259765625
This batch time : update_bounds func: 0.8950	 prepare: 0.0252	 bound: 0.8041	 transfer: 0.0482	 finalize: 0.0171
Accumulated time: update_bounds func: 75.6867	 prepare: 2.0100	 bound: 67.7830	 transfer: 0.0482	 finalize: 1.9485
batch bounding time:  0.8954849243164062
Current worst splitting domains [lb, ub] (depth):
[-0.09215,   inf] (45), [-0.09215,   inf] (41), [-0.09214,   inf] (79), [-0.09214,   inf] (73), [-0.09214,   inf] (79), [-0.09214,   inf] (73), [-0.09214,   inf] (45), [-0.09214,   inf] (71), [-0.09214,   inf] (71), [-0.09214,   inf] (39), [-0.09214,   inf] (57), [-0.09213,   inf] (57), [-0.09213,   inf] (53), [-0.09213,   inf] (73), [-0.09213,   inf] (73), [-0.09213,   inf] (73), [-0.09213,   inf] (79), [-0.09213,   inf] (67), [-0.09213,   inf] (79), [-0.09213,   inf] (75), 
length of domains: 4270
Total time: 1.0654	 pickout: 0.0571	 decision: 0.0942	 get_bound: 0.8957	 add_domain: 0.0184
Current lb:-0.09214794635772705
10492 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 94.68004941940308

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 232] [5, 232] [5, 43] [4, 269] [2, 7846] [5, 43] [4, 402] [4, 269] [4, 417] [5, 504] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.818500518798828 with beta sum per layer: [0.0, 0.0, 9.027647972106934, 107.4434814453125, 5.230607032775879, 19.974870681762695]
alpha/beta optimization time: 0.7985696792602539
This batch time : update_bounds func: 0.8894	 prepare: 0.0246	 bound: 0.7991	 transfer: 0.0484	 finalize: 0.0169
Accumulated time: update_bounds func: 76.5761	 prepare: 2.0346	 bound: 68.5821	 transfer: 0.0484	 finalize: 1.9655
batch bounding time:  0.8898177146911621
Current worst splitting domains [lb, ub] (depth):
[-0.09209,   inf] (75), [-0.09209,   inf] (73), [-0.09209,   inf] (69), [-0.09209,   inf] (77), [-0.09209,   inf] (73), [-0.09209,   inf] (83), [-0.09209,   inf] (55), [-0.09208,   inf] (71), [-0.09208,   inf] (71), [-0.09208,   inf] (77), [-0.09208,   inf] (79), [-0.09208,   inf] (55), [-0.09208,   inf] (73), [-0.09208,   inf] (49), [-0.09208,   inf] (75), [-0.09208,   inf] (73), [-0.09207,   inf] (73), [-0.09207,   inf] (73), [-0.09207,   inf] (83), [-0.09207,   inf] (77), 
length of domains: 4327
Total time: 1.0658	 pickout: 0.0611	 decision: 0.0966	 get_bound: 0.8900	 add_domain: 0.0181
Current lb:-0.09209330379962921
10620 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 95.74853038787842

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 43] [4, 269] [4, 269] [2, 11380] [5, 43] [2, 11386] [3, 674] [2, 11399] [4, 269] [3, 3805] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.329314231872559 with beta sum per layer: [0.0, 0.0, 8.228607177734375, 122.47504425048828, 6.029406547546387, 14.31080436706543]
alpha/beta optimization time: 0.7993624210357666
This batch time : update_bounds func: 0.8862	 prepare: 0.0245	 bound: 0.7999	 transfer: 0.0445	 finalize: 0.0169
Accumulated time: update_bounds func: 77.4622	 prepare: 2.0592	 bound: 69.3819	 transfer: 0.0445	 finalize: 1.9824
batch bounding time:  0.8865749835968018
Current worst splitting domains [lb, ub] (depth):
[-0.09203,   inf] (73), [-0.09203,   inf] (71), [-0.09203,   inf] (79), [-0.09203,   inf] (83), [-0.09203,   inf] (71), [-0.09203,   inf] (41), [-0.09203,   inf] (85), [-0.09203,   inf] (73), [-0.09203,   inf] (83), [-0.09203,   inf] (73), [-0.09203,   inf] (77), [-0.09203,   inf] (79), [-0.09202,   inf] (79), [-0.09202,   inf] (77), [-0.09202,   inf] (79), [-0.09202,   inf] (75), [-0.09202,   inf] (79), [-0.09202,   inf] (77), [-0.09202,   inf] (73), [-0.09202,   inf] (77), 
length of domains: 4387
Total time: 1.0655	 pickout: 0.0656	 decision: 0.0943	 get_bound: 0.8868	 add_domain: 0.0189
Current lb:-0.09203433990478516
10748 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 96.81666612625122

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 11380] [3, 2128] [2, 7846] [2, 11386] [4, 269] [3, 3035] [2, 7846] [5, 43] [2, 14025] [2, 11380] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.180021286010742 with beta sum per layer: [0.0, 0.0, 12.756946563720703, 101.72096252441406, 2.6307051181793213, 20.228897094726562]
alpha/beta optimization time: 0.8002805709838867
This batch time : update_bounds func: 0.8911	 prepare: 0.0245	 bound: 0.8008	 transfer: 0.0486	 finalize: 0.0167
Accumulated time: update_bounds func: 78.3533	 prepare: 2.0837	 bound: 70.1827	 transfer: 0.0486	 finalize: 1.9991
batch bounding time:  0.8914670944213867
Current worst splitting domains [lb, ub] (depth):
[-0.09198,   inf] (83), [-0.09198,   inf] (77), [-0.09198,   inf] (77), [-0.09198,   inf] (65), [-0.09198,   inf] (79), [-0.09198,   inf] (77), [-0.09198,   inf] (71), [-0.09198,   inf] (85), [-0.09198,   inf] (51), [-0.09197,   inf] (71), [-0.09197,   inf] (79), [-0.09197,   inf] (49), [-0.09197,   inf] (53), [-0.09197,   inf] (71), [-0.09197,   inf] (77), [-0.09197,   inf] (73), [-0.09197,   inf] (73), [-0.09197,   inf] (83), [-0.09197,   inf] (67), [-0.09197,   inf] (65), 
length of domains: 4448
Total time: 1.0720	 pickout: 0.0652	 decision: 0.0959	 get_bound: 0.8917	 add_domain: 0.0192
Current lb:-0.09198081493377686
10876 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 97.89153170585632

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 11386] [3, 3805] [5, 43] [2, 11399] [5, 43] [2, 11380] [2, 11399] [2, 14025] [3, 674] [3, 3618] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.99667739868164 with beta sum per layer: [0.0, 0.0, 13.941006660461426, 81.34690856933594, 5.7411956787109375, 14.132177352905273]
alpha/beta optimization time: 0.7986633777618408
This batch time : update_bounds func: 0.8897	 prepare: 0.0245	 bound: 0.7992	 transfer: 0.0485	 finalize: 0.0171
Accumulated time: update_bounds func: 79.2430	 prepare: 2.1082	 bound: 70.9819	 transfer: 0.0485	 finalize: 2.0161
batch bounding time:  0.8900880813598633
Current worst splitting domains [lb, ub] (depth):
[-0.09193,   inf] (73), [-0.09193,   inf] (79), [-0.09193,   inf] (79), [-0.09193,   inf] (63), [-0.09193,   inf] (73), [-0.09192,   inf] (85), [-0.09192,   inf] (83), [-0.09192,   inf] (79), [-0.09192,   inf] (87), [-0.09192,   inf] (65), [-0.09192,   inf] (85), [-0.09192,   inf] (73), [-0.09192,   inf] (77), [-0.09192,   inf] (69), [-0.09192,   inf] (65), [-0.09192,   inf] (73), [-0.09191,   inf] (79), [-0.09191,   inf] (79), [-0.09191,   inf] (87), [-0.09191,   inf] (77), 
length of domains: 4505
Total time: 1.0616	 pickout: 0.0584	 decision: 0.0945	 get_bound: 0.8903	 add_domain: 0.0184
Current lb:-0.09192880243062973
11004 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 98.9557135105133

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 11380] [2, 7846] [2, 11386] [3, 37] [2, 11380] [3, 677] [2, 14025] [5, 43] [3, 677] [5, 323] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.062084197998047 with beta sum per layer: [0.0, 0.0, 10.501633644104004, 96.59246826171875, 4.599730014801025, 13.82339096069336]
alpha/beta optimization time: 0.7979593276977539
This batch time : update_bounds func: 0.8890	 prepare: 0.0247	 bound: 0.7985	 transfer: 0.0485	 finalize: 0.0168
Accumulated time: update_bounds func: 80.1319	 prepare: 2.1329	 bound: 71.7804	 transfer: 0.0485	 finalize: 2.0330
batch bounding time:  0.8893799781799316
Current worst splitting domains [lb, ub] (depth):
[-0.09188,   inf] (85), [-0.09188,   inf] (73), [-0.09188,   inf] (77), [-0.09188,   inf] (83), [-0.09188,   inf] (55), [-0.09188,   inf] (73), [-0.09188,   inf] (79), [-0.09187,   inf] (83), [-0.09187,   inf] (67), [-0.09187,   inf] (77), [-0.09187,   inf] (59), [-0.09187,   inf] (73), [-0.09187,   inf] (73), [-0.09187,   inf] (59), [-0.09187,   inf] (73), [-0.09187,   inf] (79), [-0.09187,   inf] (79), [-0.09186,   inf] (83), [-0.09186,   inf] (51), [-0.09186,   inf] (65), 
length of domains: 4563
Total time: 1.0730	 pickout: 0.0684	 decision: 0.0960	 get_bound: 0.8896	 add_domain: 0.0190
Current lb:-0.0918794497847557
11132 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 100.0314633846283

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 7846] [4, 269] [5, 43] [2, 11365] [3, 674] [5, 43] [5, 43] [2, 14025] [2, 11399] [3, 3805] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.82227897644043 with beta sum per layer: [0.0, 0.0, 15.161966323852539, 97.46577453613281, 5.833697319030762, 16.076000213623047]
alpha/beta optimization time: 0.8105332851409912
This batch time : update_bounds func: 0.9057	 prepare: 0.0247	 bound: 0.8110	 transfer: 0.0522	 finalize: 0.0173
Accumulated time: update_bounds func: 81.0376	 prepare: 2.1576	 bound: 72.5914	 transfer: 0.0522	 finalize: 2.0502
batch bounding time:  0.9061563014984131
Current worst splitting domains [lb, ub] (depth):
[-0.09184,   inf] (87), [-0.09184,   inf] (73), [-0.09184,   inf] (73), [-0.09184,   inf] (67), [-0.09184,   inf] (87), [-0.09183,   inf] (63), [-0.09183,   inf] (63), [-0.09183,   inf] (79), [-0.09183,   inf] (43), [-0.09183,   inf] (75), [-0.09183,   inf] (63), [-0.09183,   inf] (73), [-0.09183,   inf] (73), [-0.09183,   inf] (49), [-0.09183,   inf] (85), [-0.09183,   inf] (73), [-0.09183,   inf] (61), [-0.09182,   inf] (65), [-0.09182,   inf] (87), [-0.09182,   inf] (79), 
length of domains: 4622
Total time: 1.0727	 pickout: 0.0532	 decision: 0.0944	 get_bound: 0.9064	 add_domain: 0.0187
Current lb:-0.09183847904205322
11260 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 101.10712718963623

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 677] [2, 11380] [5, 43] [5, 439] [2, 14025] [3, 37] [3, 37] [5, 43] [3, 1244] [2, 11380] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.134969711303711 with beta sum per layer: [0.0, 0.0, 6.986468315124512, 83.75555419921875, 7.055015563964844, 21.700288772583008]
alpha/beta optimization time: 0.8047974109649658
This batch time : update_bounds func: 0.8975	 prepare: 0.0251	 bound: 0.8053	 transfer: 0.0490	 finalize: 0.0176
Accumulated time: update_bounds func: 81.9351	 prepare: 2.1827	 bound: 73.3967	 transfer: 0.0490	 finalize: 2.0678
batch bounding time:  0.8978943824768066
Current worst splitting domains [lb, ub] (depth):
[-0.09179,   inf] (79), [-0.09179,   inf] (77), [-0.09179,   inf] (67), [-0.09179,   inf] (65), [-0.09179,   inf] (73), [-0.09179,   inf] (73), [-0.09179,   inf] (55), [-0.09178,   inf] (83), [-0.09178,   inf] (65), [-0.09178,   inf] (51), [-0.09178,   inf] (77), [-0.09178,   inf] (77), [-0.09178,   inf] (77), [-0.09178,   inf] (85), [-0.09178,   inf] (79), [-0.09178,   inf] (85), [-0.09178,   inf] (87), [-0.09178,   inf] (87), [-0.09177,   inf] (75), [-0.09177,   inf] (83), 
length of domains: 4678
Total time: 1.3295	 pickout: 0.1029	 decision: 0.1106	 get_bound: 0.8981	 add_domain: 0.2179
Current lb:-0.0917898565530777
11388 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 102.43952107429504

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 11386] [3, 3805] [5, 439] [3, 656] [4, 269] [2, 11380] [4, 269] [2, 11386] [5, 380] [5, 94] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.18449592590332 with beta sum per layer: [0.0, 0.0, 17.495128631591797, 94.37202453613281, 4.202136039733887, 13.361784934997559]
alpha/beta optimization time: 0.83074951171875
This batch time : update_bounds func: 0.9241	 prepare: 0.0249	 bound: 0.8314	 transfer: 0.0502	 finalize: 0.0171
Accumulated time: update_bounds func: 82.8592	 prepare: 2.2076	 bound: 74.2282	 transfer: 0.0502	 finalize: 2.0849
batch bounding time:  0.9246180057525635
Current worst splitting domains [lb, ub] (depth):
[-0.09173,   inf] (57), [-0.09173,   inf] (77), [-0.09173,   inf] (79), [-0.09173,   inf] (43), [-0.09172,   inf] (73), [-0.09172,   inf] (77), [-0.09172,   inf] (71), [-0.09172,   inf] (71), [-0.09172,   inf] (73), [-0.09172,   inf] (83), [-0.09172,   inf] (63), [-0.09172,   inf] (75), [-0.09172,   inf] (71), [-0.09172,   inf] (67), [-0.09172,   inf] (85), [-0.09172,   inf] (77), [-0.09172,   inf] (73), [-0.09172,   inf] (63), [-0.09172,   inf] (79), [-0.09172,   inf] (83), 
length of domains: 4736
Total time: 1.0946	 pickout: 0.0542	 decision: 0.0965	 get_bound: 0.9248	 add_domain: 0.0190
Current lb:-0.09172797203063965
11516 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 103.5369918346405

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 2128] [5, 43] [5, 43] [5, 232] [3, 37] [5, 43] [2, 11399] [2, 11399] [2, 11380] [2, 14025] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.139098167419434 with beta sum per layer: [0.0, 0.0, 14.38106632232666, 90.85781860351562, 6.10134744644165, 18.054601669311523]
alpha/beta optimization time: 0.8093283176422119
This batch time : update_bounds func: 0.9069	 prepare: 0.0249	 bound: 0.8098	 transfer: 0.0489	 finalize: 0.0228
Accumulated time: update_bounds func: 83.7662	 prepare: 2.2325	 bound: 75.0380	 transfer: 0.0489	 finalize: 2.1077
batch bounding time:  0.9073913097381592
Current worst splitting domains [lb, ub] (depth):
[-0.09169,   inf] (79), [-0.09169,   inf] (77), [-0.09169,   inf] (45), [-0.09169,   inf] (65), [-0.09169,   inf] (79), [-0.09169,   inf] (67), [-0.09169,   inf] (77), [-0.09169,   inf] (77), [-0.09168,   inf] (69), [-0.09168,   inf] (67), [-0.09168,   inf] (87), [-0.09168,   inf] (69), [-0.09168,   inf] (85), [-0.09168,   inf] (87), [-0.09168,   inf] (73), [-0.09168,   inf] (73), [-0.09168,   inf] (79), [-0.09168,   inf] (73), [-0.09167,   inf] (79), [-0.09167,   inf] (71), 
length of domains: 4797
Total time: 1.0859	 pickout: 0.0589	 decision: 0.0976	 get_bound: 0.9076	 add_domain: 0.0217
Current lb:-0.09168993681669235
11644 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 104.62586832046509

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 14025] [5, 43] [5, 377] [5, 439] [2, 11386] [5, 323] [3, 3805] [3, 3805] [5, 439] [5, 439] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.227808952331543 with beta sum per layer: [0.0, 0.0, 15.069805145263672, 93.14722442626953, 5.197348117828369, 18.504823684692383]
alpha/beta optimization time: 0.819840669631958
This batch time : update_bounds func: 0.9179	 prepare: 0.0248	 bound: 0.8204	 transfer: 0.0488	 finalize: 0.0235
Accumulated time: update_bounds func: 84.6841	 prepare: 2.2573	 bound: 75.8584	 transfer: 0.0488	 finalize: 2.1313
batch bounding time:  0.9183835983276367
Current worst splitting domains [lb, ub] (depth):
[-0.09165,   inf] (79), [-0.09165,   inf] (71), [-0.09165,   inf] (79), [-0.09165,   inf] (69), [-0.09165,   inf] (87), [-0.09165,   inf] (79), [-0.09165,   inf] (67), [-0.09165,   inf] (41), [-0.09164,   inf] (69), [-0.09164,   inf] (77), [-0.09164,   inf] (85), [-0.09164,   inf] (83), [-0.09164,   inf] (77), [-0.09164,   inf] (63), [-0.09164,   inf] (87), [-0.09164,   inf] (77), [-0.09164,   inf] (69), [-0.09164,   inf] (87), [-0.09164,   inf] (67), [-0.09164,   inf] (73), 
length of domains: 4850
Total time: 1.1016	 pickout: 0.0665	 decision: 0.0963	 get_bound: 0.9186	 add_domain: 0.0201
Current lb:-0.09164784848690033
11772 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 105.73039984703064

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 43] [3, 2128] [2, 11386] [4, 269] [3, 677] [2, 11386] [3, 674] [3, 1244] [2, 11399] [3, 3805] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.678890228271484 with beta sum per layer: [0.0, 0.0, 16.798494338989258, 93.89847564697266, 4.939845085144043, 9.877364158630371]
alpha/beta optimization time: 0.8137111663818359
This batch time : update_bounds func: 0.9200	 prepare: 0.0373	 bound: 0.8143	 transfer: 0.0517	 finalize: 0.0162
Accumulated time: update_bounds func: 85.6042	 prepare: 2.2946	 bound: 76.6727	 transfer: 0.0517	 finalize: 2.1475
batch bounding time:  0.9204533100128174
Current worst splitting domains [lb, ub] (depth):
[-0.09162,   inf] (83), [-0.09162,   inf] (75), [-0.09162,   inf] (87), [-0.09162,   inf] (75), [-0.09162,   inf] (63), [-0.09162,   inf] (57), [-0.09161,   inf] (83), [-0.09161,   inf] (71), [-0.09161,   inf] (79), [-0.09161,   inf] (65), [-0.09161,   inf] (73), [-0.09161,   inf] (79), [-0.09161,   inf] (75), [-0.09161,   inf] (85), [-0.09161,   inf] (85), [-0.09160,   inf] (77), [-0.09160,   inf] (85), [-0.09160,   inf] (79), [-0.09160,   inf] (85), [-0.09160,   inf] (73), 
length of domains: 4911
Total time: 1.1152	 pickout: 0.0672	 decision: 0.1070	 get_bound: 0.9207	 add_domain: 0.0203
Current lb:-0.0916185975074768
11900 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 106.84832906723022

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 11365] [2, 14025] [3, 677] [2, 11380] [5, 439] [3, 674] [2, 14025] [3, 2128] [2, 11386] [5, 323] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.056499481201172 with beta sum per layer: [0.0, 0.0, 16.855876922607422, 109.69306945800781, 4.3697404861450195, 14.41325569152832]
alpha/beta optimization time: 0.8296122550964355
This batch time : update_bounds func: 0.9244	 prepare: 0.0247	 bound: 0.8301	 transfer: 0.0520	 finalize: 0.0170
Accumulated time: update_bounds func: 86.5286	 prepare: 2.3194	 bound: 77.5028	 transfer: 0.0520	 finalize: 2.1645
batch bounding time:  0.9248275756835938
Current worst splitting domains [lb, ub] (depth):
[-0.09157,   inf] (79), [-0.09157,   inf] (83), [-0.09157,   inf] (69), [-0.09157,   inf] (75), [-0.09157,   inf] (71), [-0.09157,   inf] (77), [-0.09157,   inf] (79), [-0.09157,   inf] (73), [-0.09157,   inf] (85), [-0.09157,   inf] (79), [-0.09157,   inf] (69), [-0.09157,   inf] (77), [-0.09157,   inf] (73), [-0.09156,   inf] (85), [-0.09156,   inf] (83), [-0.09156,   inf] (85), [-0.09156,   inf] (81), [-0.09156,   inf] (65), [-0.09156,   inf] (85), [-0.09156,   inf] (79), 
length of domains: 4968
Total time: 1.0999	 pickout: 0.0615	 decision: 0.0944	 get_bound: 0.9250	 add_domain: 0.0189
Current lb:-0.09157252311706543
12028 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 107.95093655586243

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 14025] [2, 14025] [3, 656] [2, 11380] [4, 269] [3, 3805] [5, 43] [2, 11380] [2, 7846] [4, 292] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.463547706604004 with beta sum per layer: [0.0, 0.0, 17.615291595458984, 94.48434448242188, 4.896341323852539, 16.693714141845703]
alpha/beta optimization time: 0.7968583106994629
This batch time : update_bounds func: 0.8864	 prepare: 0.0245	 bound: 0.7974	 transfer: 0.0482	 finalize: 0.0159
Accumulated time: update_bounds func: 87.4150	 prepare: 2.3439	 bound: 78.3002	 transfer: 0.0482	 finalize: 2.1804
batch bounding time:  0.8868772983551025
Current worst splitting domains [lb, ub] (depth):
[-0.09154,   inf] (75), [-0.09153,   inf] (83), [-0.09153,   inf] (67), [-0.09153,   inf] (83), [-0.09153,   inf] (85), [-0.09153,   inf] (65), [-0.09153,   inf] (65), [-0.09153,   inf] (65), [-0.09153,   inf] (79), [-0.09153,   inf] (57), [-0.09153,   inf] (71), [-0.09153,   inf] (87), [-0.09153,   inf] (67), [-0.09152,   inf] (77), [-0.09152,   inf] (73), [-0.09152,   inf] (75), [-0.09152,   inf] (79), [-0.09152,   inf] (81), [-0.09152,   inf] (65), [-0.09152,   inf] (61), 
length of domains: 5028
Total time: 1.0636	 pickout: 0.0597	 decision: 0.0968	 get_bound: 0.8871	 add_domain: 0.0200
Current lb:-0.09153730422258377
12156 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 109.01733374595642

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 11380] [2, 7846] [3, 674] [2, 7846] [2, 11365] [3, 3618] [5, 323] [5, 323] [5, 43] [5, 380] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.273604393005371 with beta sum per layer: [0.0, 0.0, 17.625612258911133, 117.91444396972656, 6.309433937072754, 9.011484146118164]
alpha/beta optimization time: 0.8024210929870605
This batch time : update_bounds func: 0.8969	 prepare: 0.0251	 bound: 0.8029	 transfer: 0.0513	 finalize: 0.0171
Accumulated time: update_bounds func: 88.3119	 prepare: 2.3690	 bound: 79.1031	 transfer: 0.0513	 finalize: 2.1975
batch bounding time:  0.8973424434661865
Current worst splitting domains [lb, ub] (depth):
[-0.09149,   inf] (73), [-0.09149,   inf] (69), [-0.09149,   inf] (69), [-0.09149,   inf] (53), [-0.09149,   inf] (79), [-0.09149,   inf] (65), [-0.09149,   inf] (77), [-0.09149,   inf] (57), [-0.09148,   inf] (37), [-0.09148,   inf] (77), [-0.09148,   inf] (83), [-0.09148,   inf] (77), [-0.09148,   inf] (61), [-0.09148,   inf] (77), [-0.09148,   inf] (51), [-0.09148,   inf] (87), [-0.09148,   inf] (79), [-0.09148,   inf] (73), [-0.09148,   inf] (71), [-0.09148,   inf] (73), 
length of domains: 5088
Total time: 1.0698	 pickout: 0.0589	 decision: 0.0942	 get_bound: 0.8976	 add_domain: 0.0191
Current lb:-0.0914909839630127
12284 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 110.08991169929504

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 37] [3, 3628] [4, 269] [5, 323] [2, 7846] [5, 380] [3, 3805] [5, 380] [3, 3035] [3, 3805] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.815893173217773 with beta sum per layer: [0.0, 0.0, 13.408950805664062, 96.44502258300781, 6.637961387634277, 14.533760070800781]
alpha/beta optimization time: 0.806114912033081
This batch time : update_bounds func: 0.8959	 prepare: 0.0245	 bound: 0.8066	 transfer: 0.0484	 finalize: 0.0161
Accumulated time: update_bounds func: 89.2078	 prepare: 2.3934	 bound: 79.9097	 transfer: 0.0484	 finalize: 2.2136
batch bounding time:  0.8963327407836914
Current worst splitting domains [lb, ub] (depth):
[-0.09144,   inf] (79), [-0.09144,   inf] (85), [-0.09143,   inf] (61), [-0.09143,   inf] (83), [-0.09143,   inf] (69), [-0.09143,   inf] (79), [-0.09143,   inf] (83), [-0.09143,   inf] (31), [-0.09143,   inf] (85), [-0.09143,   inf] (79), [-0.09143,   inf] (79), [-0.09143,   inf] (79), [-0.09143,   inf] (83), [-0.09143,   inf] (83), [-0.09143,   inf] (85), [-0.09143,   inf] (79), [-0.09143,   inf] (77), [-0.09142,   inf] (87), [-0.09142,   inf] (79), [-0.09142,   inf] (61), 
length of domains: 5145
Total time: 1.0649	 pickout: 0.0524	 decision: 0.0965	 get_bound: 0.8966	 add_domain: 0.0194
Current lb:-0.09143781661987305
12412 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 111.1575858592987

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 292] [2, 7846] [3, 37] [2, 11365] [4, 269] [2, 7846] [2, 14025] [5, 503] [2, 14025] [4, 292] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.325284004211426 with beta sum per layer: [0.0, 0.0, 22.815425872802734, 88.88251495361328, 4.381009101867676, 10.352762222290039]
alpha/beta optimization time: 0.8350081443786621
This batch time : update_bounds func: 0.9259	 prepare: 0.0249	 bound: 0.8355	 transfer: 0.0483	 finalize: 0.0169
Accumulated time: update_bounds func: 90.1337	 prepare: 2.4183	 bound: 80.7452	 transfer: 0.0483	 finalize: 2.2305
batch bounding time:  0.9262902736663818
Current worst splitting domains [lb, ub] (depth):
[-0.09140,   inf] (79), [-0.09140,   inf] (67), [-0.09140,   inf] (79), [-0.09140,   inf] (55), [-0.09140,   inf] (73), [-0.09140,   inf] (81), [-0.09139,   inf] (79), [-0.09139,   inf] (87), [-0.09139,   inf] (77), [-0.09139,   inf] (77), [-0.09139,   inf] (79), [-0.09139,   inf] (83), [-0.09139,   inf] (75), [-0.09139,   inf] (77), [-0.09139,   inf] (63), [-0.09139,   inf] (51), [-0.09139,   inf] (65), [-0.09139,   inf] (79), [-0.09139,   inf] (77), [-0.09139,   inf] (85), 
length of domains: 5205
Total time: 1.1179	 pickout: 0.0775	 decision: 0.0942	 get_bound: 0.9265	 add_domain: 0.0196
Current lb:-0.09139704704284668
12540 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 112.27811479568481

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 14025] [3, 3805] [2, 11386] [3, 37] [4, 269] [2, 14025] [4, 292] [3, 677] [5, 43] [3, 3805] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.268901824951172 with beta sum per layer: [0.0, 0.0, 16.215930938720703, 96.71421813964844, 3.799051523208618, 10.467693328857422]
alpha/beta optimization time: 0.8014335632324219
This batch time : update_bounds func: 0.8915	 prepare: 0.0248	 bound: 0.8019	 transfer: 0.0484	 finalize: 0.0159
Accumulated time: update_bounds func: 91.0252	 prepare: 2.4431	 bound: 81.5471	 transfer: 0.0484	 finalize: 2.2464
batch bounding time:  0.8918585777282715
Current worst splitting domains [lb, ub] (depth):
[-0.09136,   inf] (75), [-0.09136,   inf] (81), [-0.09136,   inf] (73), [-0.09136,   inf] (73), [-0.09136,   inf] (79), [-0.09136,   inf] (61), [-0.09136,   inf] (77), [-0.09135,   inf] (85), [-0.09135,   inf] (79), [-0.09135,   inf] (73), [-0.09135,   inf] (77), [-0.09135,   inf] (73), [-0.09135,   inf] (69), [-0.09135,   inf] (73), [-0.09135,   inf] (77), [-0.09135,   inf] (85), [-0.09135,   inf] (81), [-0.09134,   inf] (59), [-0.09134,   inf] (85), [-0.09134,   inf] (61), 
length of domains: 5265
Total time: 1.0703	 pickout: 0.0620	 decision: 0.0961	 get_bound: 0.8921	 add_domain: 0.0201
Current lb:-0.09135961532592773
12668 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 113.35116052627563

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 14025] [5, 43] [2, 11380] [5, 43] [2, 14025] [3, 3618] [5, 43] [2, 14025] [2, 7846] [2, 11380] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.597264289855957 with beta sum per layer: [0.0, 0.0, 14.113872528076172, 116.13463592529297, 7.686849117279053, 16.187198638916016]
alpha/beta optimization time: 0.8099219799041748
This batch time : update_bounds func: 0.9009	 prepare: 0.0250	 bound: 0.8104	 transfer: 0.0478	 finalize: 0.0171
Accumulated time: update_bounds func: 91.9260	 prepare: 2.4682	 bound: 82.3575	 transfer: 0.0478	 finalize: 2.2635
batch bounding time:  0.9012901782989502
Current worst splitting domains [lb, ub] (depth):
[-0.09131,   inf] (79), [-0.09131,   inf] (81), [-0.09131,   inf] (59), [-0.09131,   inf] (79), [-0.09131,   inf] (81), [-0.09131,   inf] (67), [-0.09130,   inf] (71), [-0.09130,   inf] (65), [-0.09130,   inf] (71), [-0.09130,   inf] (81), [-0.09130,   inf] (73), [-0.09130,   inf] (65), [-0.09130,   inf] (65), [-0.09130,   inf] (81), [-0.09130,   inf] (75), [-0.09130,   inf] (77), [-0.09130,   inf] (83), [-0.09130,   inf] (71), [-0.09130,   inf] (77), [-0.09130,   inf] (79), 
length of domains: 5322
Total time: 1.0745	 pickout: 0.0605	 decision: 0.0938	 get_bound: 0.9015	 add_domain: 0.0187
Current lb:-0.09131213277578354
12796 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 114.42843818664551

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 292] [3, 1236] [3, 2128] [2, 7846] [2, 7846] [3, 37] [3, 2128] [5, 323] [3, 37] [2, 14025] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.600997924804688 with beta sum per layer: [0.0, 0.0, 19.9910888671875, 106.37799072265625, 4.189031600952148, 13.787375450134277]
alpha/beta optimization time: 0.7983224391937256
This batch time : update_bounds func: 0.8884	 prepare: 0.0249	 bound: 0.7988	 transfer: 0.0482	 finalize: 0.0161
Accumulated time: update_bounds func: 92.8145	 prepare: 2.4931	 bound: 83.1563	 transfer: 0.0482	 finalize: 2.2796
batch bounding time:  0.888852596282959
Current worst splitting domains [lb, ub] (depth):
[-0.09127,   inf] (85), [-0.09127,   inf] (77), [-0.09127,   inf] (73), [-0.09127,   inf] (73), [-0.09127,   inf] (63), [-0.09127,   inf] (77), [-0.09127,   inf] (61), [-0.09127,   inf] (77), [-0.09127,   inf] (73), [-0.09127,   inf] (81), [-0.09127,   inf] (73), [-0.09127,   inf] (87), [-0.09127,   inf] (75), [-0.09127,   inf] (85), [-0.09127,   inf] (87), [-0.09127,   inf] (67), [-0.09127,   inf] (63), [-0.09127,   inf] (85), [-0.09126,   inf] (65), [-0.09126,   inf] (67), 
length of domains: 5376
Total time: 1.2814	 pickout: 0.0659	 decision: 0.3071	 get_bound: 0.8891	 add_domain: 0.0192
Current lb:-0.09127306938171387
12924 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 115.71286582946777

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 14025] [5, 43] [2, 11380] [3, 3805] [5, 439] [3, 3618] [5, 323] [5, 43] [4, 269] [2, 7846] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.751802444458008 with beta sum per layer: [0.0, 0.0, 15.694747924804688, 100.13590240478516, 5.7158308029174805, 14.000480651855469]
alpha/beta optimization time: 0.8544008731842041
This batch time : update_bounds func: 0.9483	 prepare: 0.0259	 bound: 0.8549	 transfer: 0.0487	 finalize: 0.0184
Accumulated time: update_bounds func: 93.7628	 prepare: 2.5190	 bound: 84.0112	 transfer: 0.0487	 finalize: 2.2980
batch bounding time:  0.9487543106079102
Current worst splitting domains [lb, ub] (depth):
[-0.09123,   inf] (67), [-0.09123,   inf] (81), [-0.09123,   inf] (67), [-0.09123,   inf] (69), [-0.09123,   inf] (87), [-0.09123,   inf] (81), [-0.09123,   inf] (73), [-0.09123,   inf] (79), [-0.09123,   inf] (73), [-0.09122,   inf] (79), [-0.09122,   inf] (79), [-0.09122,   inf] (81), [-0.09122,   inf] (85), [-0.09122,   inf] (77), [-0.09122,   inf] (77), [-0.09122,   inf] (69), [-0.09122,   inf] (73), [-0.09122,   inf] (85), [-0.09122,   inf] (77), [-0.09122,   inf] (73), 
length of domains: 5433
Total time: 1.1631	 pickout: 0.0990	 decision: 0.0952	 get_bound: 0.9490	 add_domain: 0.0198
Current lb:-0.09122967720031738
13052 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 116.87886452674866

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 37] [2, 7846] [5, 323] [4, 269] [2, 7846] [2, 7846] [2, 11380] [2, 11386] [5, 43] [4, 292] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.769682884216309 with beta sum per layer: [0.0, 0.0, 16.910964965820312, 129.48458862304688, 7.360474586486816, 12.701290130615234]
alpha/beta optimization time: 0.8437018394470215
This batch time : update_bounds func: 0.9299	 prepare: 0.0249	 bound: 0.8442	 transfer: 0.0443	 finalize: 0.0161
Accumulated time: update_bounds func: 94.6927	 prepare: 2.5439	 bound: 84.8554	 transfer: 0.0443	 finalize: 2.3140
batch bounding time:  0.930309534072876
Current worst splitting domains [lb, ub] (depth):
[-0.09119,   inf] (73), [-0.09119,   inf] (85), [-0.09119,   inf] (85), [-0.09119,   inf] (77), [-0.09119,   inf] (89), [-0.09119,   inf] (79), [-0.09119,   inf] (75), [-0.09119,   inf] (67), [-0.09119,   inf] (85), [-0.09119,   inf] (65), [-0.09119,   inf] (75), [-0.09119,   inf] (69), [-0.09119,   inf] (81), [-0.09119,   inf] (81), [-0.09119,   inf] (73), [-0.09119,   inf] (73), [-0.09118,   inf] (59), [-0.09118,   inf] (89), [-0.09118,   inf] (85), [-0.09118,   inf] (79), 
length of domains: 5489
Total time: 1.1112	 pickout: 0.0640	 decision: 0.0967	 get_bound: 0.9305	 add_domain: 0.0199
Current lb:-0.09119129180908203
13180 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 117.99314641952515

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3618] [3, 677] [2, 7846] [5, 43] [2, 6483] [2, 11386] [2, 11380] [5, 323] [2, 11386] [3, 656] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.798128128051758 with beta sum per layer: [0.0, 0.0, 19.96465301513672, 108.69183349609375, 3.2311620712280273, 8.610946655273438]
alpha/beta optimization time: 0.8011939525604248
This batch time : update_bounds func: 0.8930	 prepare: 0.0255	 bound: 0.8017	 transfer: 0.0485	 finalize: 0.0169
Accumulated time: update_bounds func: 95.5857	 prepare: 2.5693	 bound: 85.6571	 transfer: 0.0485	 finalize: 2.3309
batch bounding time:  0.8934311866760254
Current worst splitting domains [lb, ub] (depth):
[-0.09116,   inf] (75), [-0.09116,   inf] (75), [-0.09115,   inf] (85), [-0.09115,   inf] (75), [-0.09115,   inf] (77), [-0.09115,   inf] (79), [-0.09115,   inf] (73), [-0.09115,   inf] (77), [-0.09115,   inf] (67), [-0.09115,   inf] (89), [-0.09115,   inf] (67), [-0.09115,   inf] (77), [-0.09115,   inf] (65), [-0.09114,   inf] (85), [-0.09114,   inf] (81), [-0.09114,   inf] (87), [-0.09114,   inf] (81), [-0.09114,   inf] (81), [-0.09114,   inf] (67), [-0.09114,   inf] (39), 
length of domains: 5552
Total time: 1.0834	 pickout: 0.0746	 decision: 0.0950	 get_bound: 0.8937	 add_domain: 0.0202
Current lb:-0.0911557674407959
13308 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 119.07918071746826

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 11380] [2, 11380] [2, 14025] [2, 11380] [5, 43] [4, 292] [2, 11380] [2, 14025] [5, 323] [2, 7607] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.69282054901123 with beta sum per layer: [0.0, 0.0, 19.928096771240234, 117.72880554199219, 3.6921486854553223, 14.622159957885742]
alpha/beta optimization time: 0.7976455688476562
This batch time : update_bounds func: 0.8842	 prepare: 0.0246	 bound: 0.7981	 transfer: 0.0447	 finalize: 0.0163
Accumulated time: update_bounds func: 96.4699	 prepare: 2.5939	 bound: 86.4553	 transfer: 0.0447	 finalize: 2.3472
batch bounding time:  0.8845846652984619
Current worst splitting domains [lb, ub] (depth):
[-0.09112,   inf] (65), [-0.09111,   inf] (65), [-0.09111,   inf] (79), [-0.09111,   inf] (89), [-0.09111,   inf] (73), [-0.09111,   inf] (81), [-0.09111,   inf] (85), [-0.09111,   inf] (73), [-0.09111,   inf] (77), [-0.09111,   inf] (73), [-0.09111,   inf] (63), [-0.09111,   inf] (69), [-0.09111,   inf] (81), [-0.09111,   inf] (77), [-0.09111,   inf] (65), [-0.09111,   inf] (59), [-0.09111,   inf] (75), [-0.09111,   inf] (73), [-0.09111,   inf] (65), [-0.09110,   inf] (79), 
length of domains: 5609
Total time: 1.0673	 pickout: 0.0659	 decision: 0.0966	 get_bound: 0.8848	 add_domain: 0.0200
Current lb:-0.09111595153808594
13436 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 120.14953708648682

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 417] [3, 2128] [4, 292] [2, 7607] [3, 37] [2, 7846] [2, 11386] [2, 11380] [2, 14025] [4, 417] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.634339332580566 with beta sum per layer: [0.0, 0.0, 16.672855377197266, 119.76945495605469, 11.438167572021484, 11.904784202575684]
alpha/beta optimization time: 0.8022603988647461
This batch time : update_bounds func: 0.8942	 prepare: 0.0252	 bound: 0.8028	 transfer: 0.0486	 finalize: 0.0172
Accumulated time: update_bounds func: 97.3641	 prepare: 2.6191	 bound: 87.2580	 transfer: 0.0486	 finalize: 2.3644
batch bounding time:  0.894636869430542
Current worst splitting domains [lb, ub] (depth):
[-0.09107,   inf] (79), [-0.09107,   inf] (69), [-0.09107,   inf] (69), [-0.09107,   inf] (67), [-0.09107,   inf] (85), [-0.09107,   inf] (65), [-0.09107,   inf] (67), [-0.09107,   inf] (73), [-0.09107,   inf] (77), [-0.09107,   inf] (85), [-0.09107,   inf] (77), [-0.09107,   inf] (79), [-0.09107,   inf] (69), [-0.09107,   inf] (77), [-0.09107,   inf] (81), [-0.09106,   inf] (73), [-0.09106,   inf] (87), [-0.09106,   inf] (63), [-0.09106,   inf] (81), [-0.09106,   inf] (87), 
length of domains: 5667
Total time: 1.0755	 pickout: 0.0668	 decision: 0.0947	 get_bound: 0.8949	 add_domain: 0.0190
Current lb:-0.0910748690366745
13564 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 121.22775554656982

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 292] [4, 269] [3, 37] [5, 323] [2, 7846] [4, 302] [5, 323] [2, 11380] [2, 11380] [2, 14025] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.23180866241455 with beta sum per layer: [0.0, 0.0, 19.924442291259766, 117.67048645019531, 3.922783374786377, 11.678609848022461]
alpha/beta optimization time: 0.800572395324707
This batch time : update_bounds func: 0.8910	 prepare: 0.0248	 bound: 0.8011	 transfer: 0.0484	 finalize: 0.0163
Accumulated time: update_bounds func: 98.2551	 prepare: 2.6439	 bound: 88.0591	 transfer: 0.0484	 finalize: 2.3807
batch bounding time:  0.8914480209350586
Current worst splitting domains [lb, ub] (depth):
[-0.09104,   inf] (65), [-0.09104,   inf] (65), [-0.09104,   inf] (77), [-0.09104,   inf] (85), [-0.09104,   inf] (81), [-0.09103,   inf] (67), [-0.09103,   inf] (77), [-0.09103,   inf] (69), [-0.09103,   inf] (73), [-0.09103,   inf] (79), [-0.09103,   inf] (69), [-0.09103,   inf] (67), [-0.09103,   inf] (79), [-0.09103,   inf] (81), [-0.09103,   inf] (77), [-0.09103,   inf] (67), [-0.09103,   inf] (87), [-0.09103,   inf] (73), [-0.09102,   inf] (69), [-0.09102,   inf] (59), 
length of domains: 5727
Total time: 1.0714	 pickout: 0.0629	 decision: 0.0962	 get_bound: 0.8917	 add_domain: 0.0206
Current lb:-0.09103751182556152
13692 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 122.30195546150208

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3805] [3, 37] [5, 43] [2, 11365] [2, 7846] [5, 323] [5, 43] [4, 269] [2, 11380] [2, 11386] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.884079933166504 with beta sum per layer: [0.0, 0.0, 21.38947296142578, 104.39994812011719, 5.384101390838623, 12.962483406066895]
alpha/beta optimization time: 0.8027725219726562
This batch time : update_bounds func: 0.8957	 prepare: 0.0249	 bound: 0.8033	 transfer: 0.0501	 finalize: 0.0169
Accumulated time: update_bounds func: 99.1509	 prepare: 2.6688	 bound: 88.8624	 transfer: 0.0501	 finalize: 2.3976
batch bounding time:  0.8961520195007324
Current worst splitting domains [lb, ub] (depth):
[-0.09099,   inf] (89), [-0.09099,   inf] (75), [-0.09099,   inf] (81), [-0.09099,   inf] (69), [-0.09099,   inf] (75), [-0.09099,   inf] (81), [-0.09099,   inf] (69), [-0.09099,   inf] (57), [-0.09099,   inf] (79), [-0.09099,   inf] (79), [-0.09099,   inf] (75), [-0.09099,   inf] (65), [-0.09099,   inf] (65), [-0.09099,   inf] (85), [-0.09099,   inf] (81), [-0.09099,   inf] (61), [-0.09099,   inf] (89), [-0.09099,   inf] (67), [-0.09098,   inf] (81), [-0.09098,   inf] (81), 
length of domains: 5784
Total time: 1.0668	 pickout: 0.0571	 decision: 0.0941	 get_bound: 0.8964	 add_domain: 0.0192
Current lb:-0.09099411964416504
13820 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 123.3714849948883

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 11365] [2, 11380] [5, 43] [3, 37] [2, 11380] [2, 14025] [2, 11399] [4, 302] [4, 292] [2, 11386] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.43886947631836 with beta sum per layer: [0.0, 0.0, 16.679073333740234, 107.05966186523438, 3.3825764656066895, 13.715265274047852]
alpha/beta optimization time: 0.7942044734954834
This batch time : update_bounds func: 0.8846	 prepare: 0.0249	 bound: 0.7947	 transfer: 0.0483	 finalize: 0.0163
Accumulated time: update_bounds func: 100.0355	 prepare: 2.6937	 bound: 89.6570	 transfer: 0.0483	 finalize: 2.4140
batch bounding time:  0.8850209712982178
Current worst splitting domains [lb, ub] (depth):
[-0.09096,   inf] (71), [-0.09096,   inf] (85), [-0.09096,   inf] (59), [-0.09096,   inf] (81), [-0.09095,   inf] (81), [-0.09095,   inf] (81), [-0.09095,   inf] (69), [-0.09095,   inf] (69), [-0.09095,   inf] (47), [-0.09095,   inf] (67), [-0.09095,   inf] (89), [-0.09095,   inf] (81), [-0.09095,   inf] (65), [-0.09095,   inf] (85), [-0.09095,   inf] (77), [-0.09095,   inf] (85), [-0.09095,   inf] (75), [-0.09095,   inf] (85), [-0.09095,   inf] (81), [-0.09095,   inf] (77), 
length of domains: 5838
Total time: 1.0723	 pickout: 0.0714	 decision: 0.0963	 get_bound: 0.8853	 add_domain: 0.0194
Current lb:-0.0909581184387207
13948 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 124.44658255577087

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 37] [3, 677] [4, 302] [2, 11365] [2, 11365] [3, 1236] [5, 439] [5, 439] [5, 377] [5, 439] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.064653396606445 with beta sum per layer: [0.0, 0.0, 18.76628303527832, 117.73258972167969, 2.882534980773926, 13.980598449707031]
alpha/beta optimization time: 0.7989487648010254
This batch time : update_bounds func: 0.8903	 prepare: 0.0248	 bound: 0.7994	 transfer: 0.0485	 finalize: 0.0171
Accumulated time: update_bounds func: 100.9258	 prepare: 2.7185	 bound: 90.4565	 transfer: 0.0485	 finalize: 2.4311
batch bounding time:  0.8907701969146729
Current worst splitting domains [lb, ub] (depth):
[-0.09093,   inf] (79), [-0.09093,   inf] (75), [-0.09092,   inf] (79), [-0.09092,   inf] (85), [-0.09092,   inf] (85), [-0.09092,   inf] (75), [-0.09092,   inf] (77), [-0.09092,   inf] (87), [-0.09092,   inf] (77), [-0.09092,   inf] (73), [-0.09092,   inf] (89), [-0.09092,   inf] (87), [-0.09092,   inf] (89), [-0.09092,   inf] (81), [-0.09092,   inf] (73), [-0.09092,   inf] (81), [-0.09092,   inf] (73), [-0.09092,   inf] (81), [-0.09092,   inf] (55), [-0.09092,   inf] (75), 
length of domains: 5896
Total time: 1.0658	 pickout: 0.0609	 decision: 0.0948	 get_bound: 0.8910	 add_domain: 0.0191
Current lb:-0.09092545509338379
14076 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 125.51537704467773

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 14025] [2, 11380] [4, 292] [2, 11365] [2, 11386] [2, 11380] [5, 43] [2, 7846] [5, 43] [2, 11380] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.540834426879883 with beta sum per layer: [0.0, 0.0, 17.86067008972168, 100.4020767211914, 6.3645734786987305, 10.914173126220703]
alpha/beta optimization time: 0.8054835796356201
This batch time : update_bounds func: 0.8966	 prepare: 0.0253	 bound: 0.8060	 transfer: 0.0485	 finalize: 0.0164
Accumulated time: update_bounds func: 101.8224	 prepare: 2.7438	 bound: 91.2625	 transfer: 0.0485	 finalize: 2.4475
batch bounding time:  0.8970751762390137
Current worst splitting domains [lb, ub] (depth):
[-0.09089,   inf] (81), [-0.09089,   inf] (81), [-0.09088,   inf] (85), [-0.09088,   inf] (77), [-0.09088,   inf] (85), [-0.09088,   inf] (41), [-0.09088,   inf] (77), [-0.09088,   inf] (75), [-0.09088,   inf] (85), [-0.09088,   inf] (85), [-0.09088,   inf] (85), [-0.09088,   inf] (69), [-0.09088,   inf] (85), [-0.09088,   inf] (85), [-0.09088,   inf] (85), [-0.09087,   inf] (79), [-0.09087,   inf] (79), [-0.09087,   inf] (85), [-0.09087,   inf] (81), [-0.09087,   inf] (77), 
length of domains: 5958
Total time: 1.0993	 pickout: 0.0853	 decision: 0.0958	 get_bound: 0.8973	 add_domain: 0.0209
Current lb:-0.09088774025440216
14204 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 126.617915391922

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 43] [2, 7846] [2, 11365] [3, 3618] [2, 11386] [4, 402] [5, 43] [4, 417] [2, 7846] [2, 11365] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.190923690795898 with beta sum per layer: [0.0, 0.0, 26.23600196838379, 107.81407165527344, 4.1895952224731445, 12.276721954345703]
alpha/beta optimization time: 0.80328369140625
This batch time : update_bounds func: 0.8980	 prepare: 0.0248	 bound: 0.8038	 transfer: 0.0518	 finalize: 0.0171
Accumulated time: update_bounds func: 102.7204	 prepare: 2.7687	 bound: 92.0663	 transfer: 0.0518	 finalize: 2.4645
batch bounding time:  0.8984148502349854
Current worst splitting domains [lb, ub] (depth):
[-0.09085,   inf] (75), [-0.09085,   inf] (85), [-0.09085,   inf] (75), [-0.09085,   inf] (61), [-0.09085,   inf] (89), [-0.09085,   inf] (73), [-0.09084,   inf] (67), [-0.09084,   inf] (75), [-0.09084,   inf] (67), [-0.09084,   inf] (87), [-0.09084,   inf] (75), [-0.09084,   inf] (85), [-0.09084,   inf] (81), [-0.09084,   inf] (73), [-0.09084,   inf] (85), [-0.09084,   inf] (79), [-0.09084,   inf] (65), [-0.09084,   inf] (65), [-0.09084,   inf] (85), [-0.09084,   inf] (85), 
length of domains: 6017
Total time: 1.0726	 pickout: 0.0598	 decision: 0.0946	 get_bound: 0.8986	 add_domain: 0.0196
Current lb:-0.09084596484899521
14332 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 127.69361352920532

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 11380] [2, 11386] [5, 43] [3, 37] [3, 677] [3, 3805] [5, 439] [3, 3805] [5, 323] [2, 11365] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.249524116516113 with beta sum per layer: [0.0, 0.0, 18.971370697021484, 87.94586944580078, 4.66028356552124, 13.212799072265625]
alpha/beta optimization time: 0.797675371170044
This batch time : update_bounds func: 0.8916	 prepare: 0.0246	 bound: 0.7982	 transfer: 0.0519	 finalize: 0.0165
Accumulated time: update_bounds func: 103.6120	 prepare: 2.7933	 bound: 92.8644	 transfer: 0.0519	 finalize: 2.4810
batch bounding time:  0.8919999599456787
Current worst splitting domains [lb, ub] (depth):
[-0.09082,   inf] (87), [-0.09082,   inf] (71), [-0.09081,   inf] (79), [-0.09081,   inf] (75), [-0.09081,   inf] (73), [-0.09081,   inf] (69), [-0.09081,   inf] (53), [-0.09081,   inf] (81), [-0.09081,   inf] (75), [-0.09081,   inf] (79), [-0.09081,   inf] (81), [-0.09081,   inf] (85), [-0.09081,   inf] (67), [-0.09081,   inf] (33), [-0.09081,   inf] (81), [-0.09081,   inf] (77), [-0.09081,   inf] (79), [-0.09081,   inf] (85), [-0.09081,   inf] (79), [-0.09081,   inf] (65), 
length of domains: 6076
Total time: 1.3142	 pickout: 0.0534	 decision: 0.3482	 get_bound: 0.8922	 add_domain: 0.0203
Current lb:-0.09081524610519409
14460 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 129.01062202453613

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 7846] [3, 37] [2, 14025] [2, 11380] [2, 11380] [3, 37] [5, 329] [2, 7846] [2, 14025] [4, 292] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.427332878112793 with beta sum per layer: [0.0, 0.0, 19.500852584838867, 115.05119323730469, 3.813708782196045, 10.496313095092773]
alpha/beta optimization time: 0.8546288013458252
This batch time : update_bounds func: 0.9460	 prepare: 0.0247	 bound: 0.8551	 transfer: 0.0484	 finalize: 0.0172
Accumulated time: update_bounds func: 104.5580	 prepare: 2.8180	 bound: 93.7196	 transfer: 0.0484	 finalize: 2.4982
batch bounding time:  0.9464442729949951
Current worst splitting domains [lb, ub] (depth):
[-0.09078,   inf] (81), [-0.09078,   inf] (81), [-0.09078,   inf] (75), [-0.09078,   inf] (85), [-0.09078,   inf] (83), [-0.09078,   inf] (87), [-0.09078,   inf] (85), [-0.09078,   inf] (79), [-0.09078,   inf] (85), [-0.09078,   inf] (79), [-0.09078,   inf] (69), [-0.09078,   inf] (61), [-0.09078,   inf] (89), [-0.09078,   inf] (73), [-0.09078,   inf] (81), [-0.09078,   inf] (69), [-0.09078,   inf] (87), [-0.09078,   inf] (61), [-0.09078,   inf] (79), [-0.09078,   inf] (79), 
length of domains: 6135
Total time: 1.1496	 pickout: 0.0889	 decision: 0.0945	 get_bound: 0.9467	 add_domain: 0.0195
Current lb:-0.09078336507081985
14588 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 130.16309475898743

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 43] [5, 43] [2, 11380] [2, 11365] [2, 11386] [3, 677] [2, 14025] [4, 292] [2, 7846] [2, 14025] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.432103157043457 with beta sum per layer: [0.0, 0.0, 15.05640697479248, 84.2048568725586, 5.510184288024902, 12.142727851867676]
alpha/beta optimization time: 0.8453865051269531
This batch time : update_bounds func: 0.9484	 prepare: 0.0246	 bound: 0.8459	 transfer: 0.0541	 finalize: 0.0234
Accumulated time: update_bounds func: 105.5064	 prepare: 2.8426	 bound: 94.5654	 transfer: 0.0541	 finalize: 2.5216
batch bounding time:  0.9488308429718018
Current worst splitting domains [lb, ub] (depth):
[-0.09075,   inf] (85), [-0.09075,   inf] (87), [-0.09075,   inf] (73), [-0.09075,   inf] (75), [-0.09075,   inf] (81), [-0.09075,   inf] (85), [-0.09075,   inf] (67), [-0.09075,   inf] (85), [-0.09075,   inf] (77), [-0.09075,   inf] (87), [-0.09075,   inf] (75), [-0.09075,   inf] (67), [-0.09075,   inf] (75), [-0.09075,   inf] (65), [-0.09075,   inf] (79), [-0.09075,   inf] (81), [-0.09075,   inf] (77), [-0.09074,   inf] (67), [-0.09074,   inf] (81), [-0.09074,   inf] (71), 
length of domains: 6196
Total time: 1.1329	 pickout: 0.0674	 decision: 0.0957	 get_bound: 0.9491	 add_domain: 0.0206
Current lb:-0.09075355529785156
14716 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 131.29882645606995

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 7846] [3, 677] [2, 11380] [2, 11380] [2, 11365] [2, 11386] [5, 323] [2, 11365] [2, 14025] [2, 7846] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.90346908569336 with beta sum per layer: [0.0, 0.0, 19.930591583251953, 110.8874282836914, 4.604243278503418, 10.986631393432617]
alpha/beta optimization time: 0.8216068744659424
This batch time : update_bounds func: 0.9159	 prepare: 0.0247	 bound: 0.8221	 transfer: 0.0518	 finalize: 0.0170
Accumulated time: update_bounds func: 106.4223	 prepare: 2.8673	 bound: 95.3875	 transfer: 0.0518	 finalize: 2.5386
batch bounding time:  0.9163320064544678
Current worst splitting domains [lb, ub] (depth):
[-0.09073,   inf] (81), [-0.09073,   inf] (69), [-0.09073,   inf] (73), [-0.09072,   inf] (45), [-0.09072,   inf] (89), [-0.09072,   inf] (79), [-0.09072,   inf] (65), [-0.09072,   inf] (69), [-0.09072,   inf] (67), [-0.09072,   inf] (81), [-0.09072,   inf] (73), [-0.09072,   inf] (81), [-0.09072,   inf] (89), [-0.09072,   inf] (79), [-0.09072,   inf] (79), [-0.09072,   inf] (85), [-0.09072,   inf] (63), [-0.09072,   inf] (89), [-0.09072,   inf] (79), [-0.09072,   inf] (67), 
length of domains: 6254
Total time: 1.0835	 pickout: 0.0516	 decision: 0.0958	 get_bound: 0.9166	 add_domain: 0.0196
Current lb:-0.09072613716125488
14844 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 132.38504552841187

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 7846] [3, 3628] [3, 3618] [5, 377] [2, 6483] [2, 11386] [3, 3805] [2, 11399] [3, 37] [2, 7846] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.402898788452148 with beta sum per layer: [0.0, 0.0, 13.210931777954102, 112.715576171875, 3.0254597663879395, 13.373170852661133]
alpha/beta optimization time: 0.802863359451294
This batch time : update_bounds func: 0.8919	 prepare: 0.0247	 bound: 0.8034	 transfer: 0.0463	 finalize: 0.0170
Accumulated time: update_bounds func: 107.3142	 prepare: 2.8920	 bound: 96.1910	 transfer: 0.0463	 finalize: 2.5556
batch bounding time:  0.8924102783203125
Current worst splitting domains [lb, ub] (depth):
[-0.09069,   inf] (89), [-0.09069,   inf] (85), [-0.09069,   inf] (89), [-0.09069,   inf] (85), [-0.09069,   inf] (67), [-0.09069,   inf] (87), [-0.09069,   inf] (85), [-0.09069,   inf] (67), [-0.09069,   inf] (79), [-0.09069,   inf] (77), [-0.09069,   inf] (79), [-0.09069,   inf] (67), [-0.09069,   inf] (67), [-0.09069,   inf] (81), [-0.09069,   inf] (65), [-0.09069,   inf] (89), [-0.09069,   inf] (73), [-0.09069,   inf] (85), [-0.09069,   inf] (73), [-0.09068,   inf] (81), 
length of domains: 6314
Total time: 1.1037	 pickout: 0.0920	 decision: 0.0958	 get_bound: 0.8926	 add_domain: 0.0232
Current lb:-0.09069143235683441
14972 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 133.49150586128235

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 677] [3, 677] [3, 677] [2, 11386] [5, 323] [3, 677] [2, 11365] [5, 439] [2, 11386] [2, 14025] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.40261459350586 with beta sum per layer: [0.0, 0.0, 17.113306045532227, 111.04502868652344, 5.402417182922363, 13.645465850830078]
alpha/beta optimization time: 0.8150436878204346
This batch time : update_bounds func: 0.9235	 prepare: 0.0416	 bound: 0.8156	 transfer: 0.0486	 finalize: 0.0170
Accumulated time: update_bounds func: 108.2377	 prepare: 2.9336	 bound: 97.0065	 transfer: 0.0486	 finalize: 2.5726
batch bounding time:  0.9239392280578613
Current worst splitting domains [lb, ub] (depth):
[-0.09066,   inf] (69), [-0.09066,   inf] (77), [-0.09066,   inf] (89), [-0.09066,   inf] (79), [-0.09066,   inf] (79), [-0.09065,   inf] (81), [-0.09065,   inf] (89), [-0.09065,   inf] (67), [-0.09065,   inf] (75), [-0.09065,   inf] (65), [-0.09065,   inf] (79), [-0.09065,   inf] (83), [-0.09065,   inf] (85), [-0.09065,   inf] (75), [-0.09065,   inf] (89), [-0.09065,   inf] (79), [-0.09065,   inf] (69), [-0.09065,   inf] (75), [-0.09065,   inf] (85), [-0.09065,   inf] (75), 
length of domains: 6370
Total time: 1.1194	 pickout: 0.0556	 decision: 0.1207	 get_bound: 0.9242	 add_domain: 0.0190
Current lb:-0.09065756946802139
15100 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 134.61368584632874

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 439] [5, 43] [2, 6483] [2, 14025] [4, 292] [2, 11386] [2, 7607] [2, 11399] [2, 11380] [5, 380] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.252392768859863 with beta sum per layer: [0.0, 0.0, 18.51629066467285, 114.3687744140625, 5.6179609298706055, 11.628093719482422]
alpha/beta optimization time: 0.7952470779418945
This batch time : update_bounds func: 0.8825	 prepare: 0.0244	 bound: 0.7957	 transfer: 0.0457	 finalize: 0.0163
Accumulated time: update_bounds func: 109.1202	 prepare: 2.9580	 bound: 97.8022	 transfer: 0.0457	 finalize: 2.5888
batch bounding time:  0.8829774856567383
Current worst splitting domains [lb, ub] (depth):
[-0.09062,   inf] (75), [-0.09062,   inf] (73), [-0.09062,   inf] (73), [-0.09062,   inf] (83), [-0.09062,   inf] (79), [-0.09062,   inf] (79), [-0.09062,   inf] (69), [-0.09062,   inf] (85), [-0.09062,   inf] (85), [-0.09062,   inf] (87), [-0.09062,   inf] (73), [-0.09062,   inf] (65), [-0.09062,   inf] (85), [-0.09062,   inf] (77), [-0.09061,   inf] (65), [-0.09061,   inf] (69), [-0.09061,   inf] (75), [-0.09061,   inf] (89), [-0.09061,   inf] (79), [-0.09061,   inf] (81), 
length of domains: 6430
Total time: 1.0567	 pickout: 0.0573	 decision: 0.0956	 get_bound: 0.8832	 add_domain: 0.0205
Current lb:-0.0906214788556099
15228 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 135.67360830307007

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 11380] [3, 3805] [3, 37] [3, 677] [2, 7846] [2, 11386] [5, 323] [2, 7846] [2, 7846] [2, 7846] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.329116821289062 with beta sum per layer: [0.0, 0.0, 21.403125762939453, 92.26834869384766, 4.540655136108398, 8.470548629760742]
alpha/beta optimization time: 0.7992682456970215
This batch time : update_bounds func: 0.8905	 prepare: 0.0246	 bound: 0.7998	 transfer: 0.0486	 finalize: 0.0170
Accumulated time: update_bounds func: 110.0107	 prepare: 2.9826	 bound: 98.6020	 transfer: 0.0486	 finalize: 2.6059
batch bounding time:  0.890887975692749
Current worst splitting domains [lb, ub] (depth):
[-0.09059,   inf] (87), [-0.09059,   inf] (75), [-0.09059,   inf] (87), [-0.09059,   inf] (87), [-0.09059,   inf] (75), [-0.09059,   inf] (67), [-0.09059,   inf] (73), [-0.09059,   inf] (71), [-0.09059,   inf] (85), [-0.09059,   inf] (81), [-0.09058,   inf] (77), [-0.09058,   inf] (85), [-0.09058,   inf] (81), [-0.09058,   inf] (63), [-0.09058,   inf] (89), [-0.09058,   inf] (89), [-0.09058,   inf] (81), [-0.09058,   inf] (73), [-0.09058,   inf] (85), [-0.09058,   inf] (79), 
length of domains: 6490
Total time: 1.0617	 pickout: 0.0570	 decision: 0.0940	 get_bound: 0.8911	 add_domain: 0.0196
Current lb:-0.09059008955955505
15356 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 136.7380883693695

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 677] [2, 11380] [2, 11365] [3, 677] [2, 11380] [5, 439] [3, 3805] [3, 3618] [2, 7846] [2, 11386] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.582744598388672 with beta sum per layer: [0.0, 0.0, 19.83837890625, 114.41314697265625, 2.658552408218384, 8.042556762695312]
alpha/beta optimization time: 0.799950122833252
This batch time : update_bounds func: 0.8904	 prepare: 0.0247	 bound: 0.8005	 transfer: 0.0486	 finalize: 0.0163
Accumulated time: update_bounds func: 110.9011	 prepare: 3.0073	 bound: 99.4025	 transfer: 0.0486	 finalize: 2.6221
batch bounding time:  0.8908071517944336
Current worst splitting domains [lb, ub] (depth):
[-0.09056,   inf] (77), [-0.09056,   inf] (79), [-0.09056,   inf] (75), [-0.09056,   inf] (69), [-0.09056,   inf] (69), [-0.09056,   inf] (81), [-0.09056,   inf] (79), [-0.09056,   inf] (79), [-0.09056,   inf] (87), [-0.09056,   inf] (71), [-0.09056,   inf] (79), [-0.09056,   inf] (87), [-0.09055,   inf] (87), [-0.09055,   inf] (81), [-0.09055,   inf] (79), [-0.09055,   inf] (77), [-0.09055,   inf] (63), [-0.09055,   inf] (81), [-0.09055,   inf] (83), [-0.09055,   inf] (79), 
length of domains: 6550
Total time: 1.0678	 pickout: 0.0602	 decision: 0.0957	 get_bound: 0.8910	 add_domain: 0.0209
Current lb:-0.0905606746673584
15484 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 137.80870008468628

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 14025] [4, 292] [2, 11380] [3, 2128] [4, 269] [2, 11365] [2, 14025] [4, 292] [2, 7846] [3, 37] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.212752342224121 with beta sum per layer: [0.0, 0.0, 17.592269897460938, 114.1698989868164, 11.288305282592773, 12.930427551269531]
alpha/beta optimization time: 0.8066201210021973
This batch time : update_bounds func: 0.8983	 prepare: 0.0251	 bound: 0.8072	 transfer: 0.0485	 finalize: 0.0171
Accumulated time: update_bounds func: 111.7994	 prepare: 3.0324	 bound: 100.2097	 transfer: 0.0485	 finalize: 2.6392
batch bounding time:  0.8987433910369873
Current worst splitting domains [lb, ub] (depth):
[-0.09053,   inf] (67), [-0.09053,   inf] (85), [-0.09053,   inf] (87), [-0.09053,   inf] (79), [-0.09053,   inf] (67), [-0.09053,   inf] (69), [-0.09053,   inf] (89), [-0.09053,   inf] (91), [-0.09053,   inf] (67), [-0.09053,   inf] (79), [-0.09053,   inf] (77), [-0.09053,   inf] (87), [-0.09053,   inf] (69), [-0.09053,   inf] (67), [-0.09053,   inf] (65), [-0.09053,   inf] (47), [-0.09053,   inf] (73), [-0.09053,   inf] (79), [-0.09052,   inf] (89), [-0.09052,   inf] (77), 
length of domains: 6606
Total time: 1.0756	 pickout: 0.0626	 decision: 0.0951	 get_bound: 0.8990	 add_domain: 0.0189
Current lb:-0.09053337574005127
15612 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 138.88711881637573

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 2128] [2, 11386] [2, 11386] [2, 11386] [5, 439] [3, 2128] [3, 677] [2, 14025] [5, 323] [2, 11386] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.108978271484375 with beta sum per layer: [0.0, 0.0, 19.10024642944336, 114.08049774169922, 3.9334163665771484, 14.503738403320312]
alpha/beta optimization time: 0.820411205291748
This batch time : update_bounds func: 0.9108	 prepare: 0.0245	 bound: 0.8209	 transfer: 0.0488	 finalize: 0.0163
Accumulated time: update_bounds func: 112.7102	 prepare: 3.0569	 bound: 101.0306	 transfer: 0.0488	 finalize: 2.6555
batch bounding time:  0.9112584590911865
Current worst splitting domains [lb, ub] (depth):
[-0.09050,   inf] (71), [-0.09050,   inf] (79), [-0.09050,   inf] (81), [-0.09050,   inf] (81), [-0.09050,   inf] (79), [-0.09050,   inf] (55), [-0.09050,   inf] (71), [-0.09050,   inf] (73), [-0.09050,   inf] (41), [-0.09050,   inf] (81), [-0.09050,   inf] (67), [-0.09050,   inf] (75), [-0.09050,   inf] (75), [-0.09050,   inf] (87), [-0.09050,   inf] (81), [-0.09050,   inf] (79), [-0.09050,   inf] (67), [-0.09050,   inf] (81), [-0.09050,   inf] (89), [-0.09050,   inf] (75), 
length of domains: 6659
Total time: 1.0828	 pickout: 0.0554	 decision: 0.0957	 get_bound: 0.9115	 add_domain: 0.0202
Current lb:-0.09050464630126953
15740 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 139.97306394577026

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 439] [2, 14025] [2, 14025] [5, 43] [2, 11365] [5, 94] [5, 43] [3, 3805] [5, 103] [5, 43] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.027718544006348 with beta sum per layer: [0.0, 0.0, 20.63212013244629, 111.19778442382812, 3.5487470626831055, 13.482722282409668]
alpha/beta optimization time: 0.8153226375579834
This batch time : update_bounds func: 0.9101	 prepare: 0.0249	 bound: 0.8158	 transfer: 0.0517	 finalize: 0.0173
Accumulated time: update_bounds func: 113.6203	 prepare: 3.0817	 bound: 101.8464	 transfer: 0.0517	 finalize: 2.6727
batch bounding time:  0.9105846881866455
Current worst splitting domains [lb, ub] (depth):
[-0.09047,   inf] (87), [-0.09047,   inf] (67), [-0.09047,   inf] (85), [-0.09047,   inf] (89), [-0.09047,   inf] (81), [-0.09047,   inf] (75), [-0.09047,   inf] (85), [-0.09047,   inf] (79), [-0.09047,   inf] (89), [-0.09047,   inf] (61), [-0.09047,   inf] (67), [-0.09047,   inf] (69), [-0.09047,   inf] (71), [-0.09047,   inf] (81), [-0.09047,   inf] (81), [-0.09047,   inf] (79), [-0.09047,   inf] (89), [-0.09047,   inf] (89), [-0.09047,   inf] (89), [-0.09046,   inf] (69), 
length of domains: 6717
Total time: 1.0891	 pickout: 0.0629	 decision: 0.0953	 get_bound: 0.9108	 add_domain: 0.0201
Current lb:-0.09047269821166992
15868 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 141.06592059135437

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 11386] [5, 439] [2, 7846] [2, 7607] [2, 7846] [2, 11380] [2, 7846] [2, 7846] [2, 7607] [4, 417] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.259355545043945 with beta sum per layer: [0.0, 0.0, 19.3753719329834, 88.90827178955078, 4.297028541564941, 12.378744125366211]
alpha/beta optimization time: 0.8065884113311768
This batch time : update_bounds func: 0.8974	 prepare: 0.0248	 bound: 0.8071	 transfer: 0.0487	 finalize: 0.0164
Accumulated time: update_bounds func: 114.5177	 prepare: 3.1066	 bound: 102.6535	 transfer: 0.0487	 finalize: 2.6891
batch bounding time:  0.8979043960571289
Current worst splitting domains [lb, ub] (depth):
[-0.09044,   inf] (87), [-0.09044,   inf] (69), [-0.09044,   inf] (53), [-0.09044,   inf] (79), [-0.09044,   inf] (65), [-0.09044,   inf] (77), [-0.09044,   inf] (77), [-0.09044,   inf] (63), [-0.09043,   inf] (87), [-0.09043,   inf] (79), [-0.09043,   inf] (75), [-0.09043,   inf] (77), [-0.09043,   inf] (81), [-0.09043,   inf] (71), [-0.09043,   inf] (67), [-0.09043,   inf] (65), [-0.09043,   inf] (75), [-0.09043,   inf] (81), [-0.09043,   inf] (83), [-0.09043,   inf] (87), 
length of domains: 6775
Total time: 1.0761	 pickout: 0.0623	 decision: 0.0952	 get_bound: 0.8981	 add_domain: 0.0205
Current lb:-0.09043708443641663
15996 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 142.14521145820618

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 7846] [3, 2128] [5, 329] [2, 14025] [3, 3618] [3, 3805] [5, 43] [3, 3618] [2, 7846] [2, 14025] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.186619758605957 with beta sum per layer: [0.0, 0.0, 15.976509094238281, 90.76776885986328, 3.4018006324768066, 18.007976531982422]
alpha/beta optimization time: 0.8009965419769287
This batch time : update_bounds func: 1.1577	 prepare: 0.0248	 bound: 0.8015	 transfer: 0.0519	 finalize: 0.2790
Accumulated time: update_bounds func: 115.6754	 prepare: 3.1314	 bound: 103.4550	 transfer: 0.0519	 finalize: 2.9681
batch bounding time:  1.1581945419311523
Current worst splitting domains [lb, ub] (depth):
[-0.09041,   inf] (75), [-0.09041,   inf] (85), [-0.09041,   inf] (73), [-0.09041,   inf] (81), [-0.09041,   inf] (89), [-0.09041,   inf] (81), [-0.09041,   inf] (67), [-0.09041,   inf] (69), [-0.09041,   inf] (69), [-0.09041,   inf] (79), [-0.09041,   inf] (65), [-0.09041,   inf] (79), [-0.09041,   inf] (79), [-0.09040,   inf] (81), [-0.09040,   inf] (75), [-0.09040,   inf] (75), [-0.09040,   inf] (81), [-0.09040,   inf] (85), [-0.09040,   inf] (73), [-0.09040,   inf] (79), 
length of domains: 6830
Total time: 1.3393	 pickout: 0.0669	 decision: 0.0951	 get_bound: 1.1584	 add_domain: 0.0189
Current lb:-0.09041071683168411
16124 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 143.48780035972595

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 11380] [2, 11365] [3, 3618] [2, 7846] [2, 7607] [2, 7846] [5, 323] [4, 269] [5, 439] [3, 3805] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.102374076843262 with beta sum per layer: [0.0, 0.0, 19.978479385375977, 95.73685455322266, 7.581567287445068, 14.49882984161377]
alpha/beta optimization time: 0.7951643466949463
This batch time : update_bounds func: 0.8894	 prepare: 0.0250	 bound: 0.7957	 transfer: 0.0517	 finalize: 0.0164
Accumulated time: update_bounds func: 116.5649	 prepare: 3.1564	 bound: 104.2507	 transfer: 0.0517	 finalize: 2.9845
batch bounding time:  0.8898937702178955
Current worst splitting domains [lb, ub] (depth):
[-0.09038,   inf] (61), [-0.09038,   inf] (77), [-0.09038,   inf] (67), [-0.09038,   inf] (89), [-0.09038,   inf] (81), [-0.09038,   inf] (89), [-0.09038,   inf] (75), [-0.09038,   inf] (75), [-0.09038,   inf] (87), [-0.09038,   inf] (77), [-0.09038,   inf] (75), [-0.09038,   inf] (65), [-0.09037,   inf] (67), [-0.09037,   inf] (77), [-0.09037,   inf] (75), [-0.09037,   inf] (87), [-0.09037,   inf] (87), [-0.09037,   inf] (81), [-0.09037,   inf] (73), [-0.09037,   inf] (89), 
length of domains: 6884
Total time: 1.0969	 pickout: 0.0900	 decision: 0.0963	 get_bound: 0.8901	 add_domain: 0.0204
Current lb:-0.09038031101226807
16252 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 144.5877194404602

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 417] [4, 292] [5, 439] [3, 677] [2, 14025] [2, 11365] [2, 11380] [2, 11380] [2, 11365] [3, 3805] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.45092487335205 with beta sum per layer: [0.0, 0.0, 16.753070831298828, 102.00250244140625, 6.2691330909729, 11.914623260498047]
alpha/beta optimization time: 0.806438684463501
This batch time : update_bounds func: 0.8973	 prepare: 0.0246	 bound: 0.8069	 transfer: 0.0485	 finalize: 0.0169
Accumulated time: update_bounds func: 117.4622	 prepare: 3.1811	 bound: 105.0576	 transfer: 0.0485	 finalize: 3.0014
batch bounding time:  0.8977642059326172
Current worst splitting domains [lb, ub] (depth):
[-0.09035,   inf] (85), [-0.09035,   inf] (81), [-0.09035,   inf] (79), [-0.09035,   inf] (87), [-0.09034,   inf] (69), [-0.09034,   inf] (79), [-0.09034,   inf] (73), [-0.09034,   inf] (73), [-0.09034,   inf] (89), [-0.09034,   inf] (79), [-0.09034,   inf] (51), [-0.09034,   inf] (87), [-0.09034,   inf] (89), [-0.09034,   inf] (87), [-0.09034,   inf] (87), [-0.09034,   inf] (79), [-0.09034,   inf] (69), [-0.09034,   inf] (81), [-0.09034,   inf] (83), [-0.09034,   inf] (83), 
length of domains: 6941
Total time: 1.0694	 pickout: 0.0579	 decision: 0.0940	 get_bound: 0.8980	 add_domain: 0.0195
Current lb:-0.09034717082977295
16380 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 145.65997529029846

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 11386] [5, 43] [2, 14025] [3, 677] [5, 439] [5, 43] [2, 14025] [3, 37] [3, 677] [2, 7846] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.079580307006836 with beta sum per layer: [0.0, 0.0, 20.914703369140625, 110.68668365478516, 4.346301555633545, 12.157609939575195]
alpha/beta optimization time: 0.805173397064209
This batch time : update_bounds func: 0.8990	 prepare: 0.0248	 bound: 0.8057	 transfer: 0.0518	 finalize: 0.0163
Accumulated time: update_bounds func: 118.3612	 prepare: 3.2059	 bound: 105.8633	 transfer: 0.0518	 finalize: 3.0177
batch bounding time:  0.8994600772857666
Current worst splitting domains [lb, ub] (depth):
[-0.09032,   inf] (69), [-0.09032,   inf] (81), [-0.09032,   inf] (79), [-0.09032,   inf] (87), [-0.09032,   inf] (75), [-0.09032,   inf] (81), [-0.09031,   inf] (89), [-0.09031,   inf] (85), [-0.09031,   inf] (83), [-0.09031,   inf] (81), [-0.09031,   inf] (87), [-0.09031,   inf] (87), [-0.09031,   inf] (71), [-0.09031,   inf] (77), [-0.09031,   inf] (77), [-0.09031,   inf] (79), [-0.09031,   inf] (67), [-0.09031,   inf] (79), [-0.09031,   inf] (75), [-0.09031,   inf] (73), 
length of domains: 6997
Total time: 1.0713	 pickout: 0.0555	 decision: 0.0957	 get_bound: 0.8997	 add_domain: 0.0204
Current lb:-0.0903160572052002
16508 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 146.73420453071594

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3618] [4, 292] [2, 7846] [2, 11365] [5, 43] [2, 7607] [2, 7607] [2, 11386] [2, 11365] [2, 7607] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.038475036621094 with beta sum per layer: [0.0, 0.0, 16.09056854248047, 101.74424743652344, 8.194709777832031, 11.38628101348877]
alpha/beta optimization time: 0.801422119140625
This batch time : update_bounds func: 0.8928	 prepare: 0.0248	 bound: 0.8019	 transfer: 0.0487	 finalize: 0.0170
Accumulated time: update_bounds func: 119.2539	 prepare: 3.2307	 bound: 106.6652	 transfer: 0.0487	 finalize: 3.0347
batch bounding time:  0.8932011127471924
Current worst splitting domains [lb, ub] (depth):
[-0.09029,   inf] (63), [-0.09029,   inf] (83), [-0.09029,   inf] (47), [-0.09029,   inf] (79), [-0.09029,   inf] (79), [-0.09029,   inf] (85), [-0.09029,   inf] (61), [-0.09028,   inf] (81), [-0.09028,   inf] (81), [-0.09028,   inf] (77), [-0.09028,   inf] (55), [-0.09028,   inf] (75), [-0.09028,   inf] (87), [-0.09028,   inf] (81), [-0.09028,   inf] (89), [-0.09028,   inf] (77), [-0.09028,   inf] (89), [-0.09028,   inf] (75), [-0.09028,   inf] (67), [-0.09028,   inf] (59), 
length of domains: 7057
Total time: 1.0654	 pickout: 0.0572	 decision: 0.0951	 get_bound: 0.8934	 add_domain: 0.0197
Current lb:-0.09028743952512741
16636 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 147.80240964889526

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 323] [2, 14025] [5, 377] [2, 14025] [2, 7846] [3, 677] [3, 37] [4, 292] [4, 292] [3, 3805] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.428024291992188 with beta sum per layer: [0.0, 0.0, 22.590377807617188, 98.5383071899414, 6.343800067901611, 14.768671035766602]
alpha/beta optimization time: 0.8466668128967285
This batch time : update_bounds func: 0.9495	 prepare: 0.0247	 bound: 0.8473	 transfer: 0.0540	 finalize: 0.0230
Accumulated time: update_bounds func: 120.2034	 prepare: 3.2554	 bound: 107.5125	 transfer: 0.0540	 finalize: 3.0577
batch bounding time:  0.9499566555023193
Current worst splitting domains [lb, ub] (depth):
[-0.09026,   inf] (83), [-0.09026,   inf] (63), [-0.09026,   inf] (61), [-0.09026,   inf] (79), [-0.09026,   inf] (73), [-0.09026,   inf] (81), [-0.09026,   inf] (87), [-0.09026,   inf] (77), [-0.09026,   inf] (65), [-0.09026,   inf] (89), [-0.09026,   inf] (75), [-0.09026,   inf] (73), [-0.09026,   inf] (75), [-0.09026,   inf] (79), [-0.09026,   inf] (81), [-0.09026,   inf] (69), [-0.09025,   inf] (77), [-0.09025,   inf] (83), [-0.09025,   inf] (59), [-0.09025,   inf] (77), 
length of domains: 7114
Total time: 1.1184	 pickout: 0.0501	 decision: 0.0954	 get_bound: 0.9502	 add_domain: 0.0226
Current lb:-0.09026157855987549
16764 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 148.92379903793335

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 7846] [5, 380] [5, 323] [2, 11386] [4, 417] [4, 292] [2, 7607] [3, 3805] [5, 380] [3, 677] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.203080177307129 with beta sum per layer: [0.0, 0.0, 25.064128875732422, 117.0154800415039, 8.569735527038574, 10.065227508544922]
alpha/beta optimization time: 0.8329281806945801
This batch time : update_bounds func: 0.9409	 prepare: 0.0380	 bound: 0.8335	 transfer: 0.0519	 finalize: 0.0171
Accumulated time: update_bounds func: 121.1443	 prepare: 3.2934	 bound: 108.3460	 transfer: 0.0519	 finalize: 3.0747
batch bounding time:  0.941307544708252
Current worst splitting domains [lb, ub] (depth):
[-0.09023,   inf] (83), [-0.09023,   inf] (87), [-0.09023,   inf] (77), [-0.09023,   inf] (81), [-0.09023,   inf] (87), [-0.09023,   inf] (81), [-0.09023,   inf] (75), [-0.09022,   inf] (69), [-0.09022,   inf] (65), [-0.09022,   inf] (79), [-0.09022,   inf] (81), [-0.09022,   inf] (89), [-0.09022,   inf] (91), [-0.09022,   inf] (65), [-0.09022,   inf] (79), [-0.09022,   inf] (87), [-0.09022,   inf] (77), [-0.09022,   inf] (85), [-0.09022,   inf] (79), [-0.09022,   inf] (83), 
length of domains: 7169
Total time: 1.1324	 pickout: 0.0654	 decision: 0.1060	 get_bound: 0.9415	 add_domain: 0.0194
Current lb:-0.09022808074951172
16892 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 150.05937886238098

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 677] [2, 11386] [2, 7846] [5, 43] [2, 11365] [2, 7846] [2, 11380] [5, 439] [5, 439] [4, 292] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.18143081665039 with beta sum per layer: [0.0, 0.0, 15.944866180419922, 124.27059936523438, 3.3751096725463867, 12.83705997467041]
alpha/beta optimization time: 0.8067867755889893
This batch time : update_bounds func: 0.8976	 prepare: 0.0248	 bound: 0.8073	 transfer: 0.0486	 finalize: 0.0163
Accumulated time: update_bounds func: 122.0419	 prepare: 3.3182	 bound: 109.1533	 transfer: 0.0486	 finalize: 3.0911
batch bounding time:  0.8980376720428467
Current worst splitting domains [lb, ub] (depth):
[-0.09020,   inf] (81), [-0.09020,   inf] (87), [-0.09020,   inf] (83), [-0.09020,   inf] (79), [-0.09020,   inf] (81), [-0.09020,   inf] (79), [-0.09020,   inf] (83), [-0.09020,   inf] (83), [-0.09020,   inf] (61), [-0.09020,   inf] (89), [-0.09020,   inf] (89), [-0.09020,   inf] (79), [-0.09020,   inf] (79), [-0.09020,   inf] (87), [-0.09020,   inf] (77), [-0.09020,   inf] (81), [-0.09020,   inf] (83), [-0.09019,   inf] (57), [-0.09019,   inf] (81), [-0.09019,   inf] (83), 
length of domains: 7229
Total time: 1.0657	 pickout: 0.0494	 decision: 0.0972	 get_bound: 0.8983	 add_domain: 0.0208
Current lb:-0.09019878506660461
17020 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 151.12793469429016

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 292] [2, 11365] [2, 14025] [2, 11386] [3, 677] [4, 292] [2, 7846] [3, 677] [4, 417] [2, 6483] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.221856117248535 with beta sum per layer: [0.0, 0.0, 21.20201301574707, 102.63583374023438, 6.353004455566406, 9.80781078338623]
alpha/beta optimization time: 0.8099620342254639
This batch time : update_bounds func: 0.9159	 prepare: 0.0253	 bound: 0.8105	 transfer: 0.0564	 finalize: 0.0232
Accumulated time: update_bounds func: 122.9578	 prepare: 3.3435	 bound: 109.9639	 transfer: 0.0564	 finalize: 3.1143
batch bounding time:  0.9163639545440674
Current worst splitting domains [lb, ub] (depth):
[-0.09018,   inf] (87), [-0.09018,   inf] (67), [-0.09018,   inf] (63), [-0.09018,   inf] (61), [-0.09018,   inf] (61), [-0.09018,   inf] (79), [-0.09018,   inf] (87), [-0.09018,   inf] (55), [-0.09017,   inf] (67), [-0.09017,   inf] (83), [-0.09017,   inf] (89), [-0.09017,   inf] (57), [-0.09017,   inf] (87), [-0.09017,   inf] (81), [-0.09017,   inf] (71), [-0.09017,   inf] (87), [-0.09017,   inf] (69), [-0.09017,   inf] (91), [-0.09017,   inf] (83), [-0.09017,   inf] (81), 
length of domains: 7289
Total time: 1.1054	 pickout: 0.0735	 decision: 0.0954	 get_bound: 0.9166	 add_domain: 0.0200
Current lb:-0.09017825126647949
17148 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 152.23631286621094

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 11365] [5, 323] [3, 3628] [5, 439] [5, 439] [2, 7846] [2, 11365] [5, 94] [3, 3618] [3, 677] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.055545806884766 with beta sum per layer: [0.0, 0.0, 21.617795944213867, 101.16365051269531, 3.4161291122436523, 11.833674430847168]
alpha/beta optimization time: 0.8081104755401611
This batch time : update_bounds func: 0.8988	 prepare: 0.0250	 bound: 0.8086	 transfer: 0.0487	 finalize: 0.0161
Accumulated time: update_bounds func: 123.8566	 prepare: 3.3685	 bound: 110.7725	 transfer: 0.0487	 finalize: 3.1304
batch bounding time:  0.8993008136749268
Current worst splitting domains [lb, ub] (depth):
[-0.09014,   inf] (73), [-0.09014,   inf] (73), [-0.09014,   inf] (73), [-0.09014,   inf] (89), [-0.09014,   inf] (79), [-0.09014,   inf] (73), [-0.09014,   inf] (91), [-0.09014,   inf] (63), [-0.09014,   inf] (49), [-0.09014,   inf] (67), [-0.09014,   inf] (87), [-0.09014,   inf] (81), [-0.09014,   inf] (79), [-0.09014,   inf] (83), [-0.09014,   inf] (79), [-0.09013,   inf] (79), [-0.09013,   inf] (83), [-0.09013,   inf] (63), [-0.09013,   inf] (83), [-0.09013,   inf] (85), 
length of domains: 7348
Total time: 1.0748	 pickout: 0.0573	 decision: 0.0967	 get_bound: 0.8995	 add_domain: 0.0213
Current lb:-0.09014129638671875
17276 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 153.31438207626343

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3805] [3, 3805] [3, 3618] [2, 7607] [2, 11386] [4, 417] [2, 14025] [3, 3628] [4, 292] [5, 439] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.630699157714844 with beta sum per layer: [0.0, 0.0, 19.975479125976562, 110.51779174804688, 10.20673656463623, 10.4901123046875]
alpha/beta optimization time: 0.8113276958465576
This batch time : update_bounds func: 0.9074	 prepare: 0.0254	 bound: 0.8118	 transfer: 0.0523	 finalize: 0.0173/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:530: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(eps_temp / std).reshape(1, -1, 1, 1)

Accumulated time: update_bounds func: 124.7640	 prepare: 3.3939	 bound: 111.5844	 transfer: 0.0523	 finalize: 3.1477
batch bounding time:  0.9080870151519775
Current worst splitting domains [lb, ub] (depth):
[-0.09011,   inf] (77), [-0.09011,   inf] (79), [-0.09011,   inf] (83), [-0.09011,   inf] (81), [-0.09011,   inf] (87), [-0.09011,   inf] (83), [-0.09011,   inf] (89), [-0.09011,   inf] (69), [-0.09011,   inf] (79), [-0.09010,   inf] (87), [-0.09010,   inf] (87), [-0.09010,   inf] (77), [-0.09010,   inf] (79), [-0.09010,   inf] (81), [-0.09010,   inf] (65), [-0.09010,   inf] (81), [-0.09010,   inf] (81), [-0.09010,   inf] (83), [-0.09010,   inf] (67), [-0.09010,   inf] (83), 
length of domains: 7405
Total time: 1.0803	 pickout: 0.0566	 decision: 0.0960	 get_bound: 0.9085	 add_domain: 0.0192
Current lb:-0.09010811150074005
17404 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 154.39763951301575

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 11380] [2, 11386] [2, 7846] [5, 43] [2, 7846] [2, 11386] [2, 6483] [2, 11399] [2, 11386] [2, 7607] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.20068359375 with beta sum per layer: [0.0, 0.0, 21.11615753173828, 119.14349365234375, 6.080781936645508, 9.225019454956055]
alpha/beta optimization time: 0.8473033905029297
This batch time : update_bounds func: 0.9389	 prepare: 0.0252	 bound: 0.8478	 transfer: 0.0487	 finalize: 0.0166
Accumulated time: update_bounds func: 125.7029	 prepare: 3.4191	 bound: 112.4322	 transfer: 0.0487	 finalize: 3.1643
batch bounding time:  0.9393787384033203
Current worst splitting domains [lb, ub] (depth):
[-0.09008,   inf] (87), [-0.09008,   inf] (79), [-0.09008,   inf] (73), [-0.09008,   inf] (81), [-0.09008,   inf] (77), [-0.09008,   inf] (79), [-0.09008,   inf] (79), [-0.09008,   inf] (73), [-0.09008,   inf] (89), [-0.09007,   inf] (89), [-0.09007,   inf] (75), [-0.09007,   inf] (81), [-0.09007,   inf] (69), [-0.09007,   inf] (87), [-0.09007,   inf] (87), [-0.09007,   inf] (69), [-0.09007,   inf] (83), [-0.09007,   inf] (85), [-0.09007,   inf] (71), [-0.09007,   inf] (81), 
length of domains: 7465
Total time: 1.1123	 pickout: 0.0544	 decision: 0.0970	 get_bound: 0.9396	 add_domain: 0.0212
Current lb:-0.09007852524518967
17532 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 155.51276445388794

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 11365] [2, 11386] [4, 292] [4, 292] [2, 7846] [5, 43] [2, 7846] [3, 3805] [2, 6483] [2, 6483] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.799179077148438 with beta sum per layer: [0.0, 0.0, 25.631128311157227, 111.54469299316406, 7.7548041343688965, 9.648330688476562]
alpha/beta optimization time: 0.8097519874572754
This batch time : update_bounds func: 0.9019	 prepare: 0.0255	 bound: 0.8103	 transfer: 0.0487	 finalize: 0.0170
Accumulated time: update_bounds func: 126.6048	 prepare: 3.4446	 bound: 113.2424	 transfer: 0.0487	 finalize: 3.1813
batch bounding time:  0.9023168087005615
Current worst splitting domains [lb, ub] (depth):
[-0.09005,   inf] (87), [-0.09005,   inf] (89), [-0.09005,   inf] (87), [-0.09005,   inf] (89), [-0.09005,   inf] (71), [-0.09005,   inf] (63), [-0.09005,   inf] (69), [-0.09005,   inf] (87), [-0.09005,   inf] (89), [-0.09005,   inf] (91), [-0.09005,   inf] (79), [-0.09005,   inf] (77), [-0.09005,   inf] (75), [-0.09005,   inf] (91), [-0.09005,   inf] (83), [-0.09005,   inf] (87), [-0.09005,   inf] (77), [-0.09005,   inf] (77), [-0.09004,   inf] (69), [-0.09004,   inf] (89), 
length of domains: 7522
Total time: 1.0755	 pickout: 0.0573	 decision: 0.0960	 get_bound: 0.9026	 add_domain: 0.0197
Current lb:-0.090053029358387
17660 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Time out!!!!!!!!
Image 684 label 1 verification end, final lower bound -0.090053029358387, upper bound inf, time: 156.94029879570007
684 -0.090053029358387
Result: image 684 verification failure (with branch and bound).
Wall time: 181.43844890594482

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 0): []
verification failure idx (total 1): [684]
final verified acc: 0.0%[1]
verifier is called on 1 examples.
total verified: 0
mean time [cnt:1] (excluding attack success): 181.30750370025635
