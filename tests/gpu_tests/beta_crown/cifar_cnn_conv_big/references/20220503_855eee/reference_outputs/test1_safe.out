Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_conv_big_pgd.pth
  name: cifar_conv_big
data:
  start: 799
  end: 800
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR_ERAN
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.00784313725
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 64
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 180
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 100
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:17:35 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (5): ReLU()
  (6): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (7): ReLU()
  (8): Flatten()
  (9): Linear(in_features=4096, out_features=512, bias=True)
  (10): ReLU()
  (11): Linear(in_features=512, out_features=512, bias=True)
  (12): ReLU()
  (13): Linear(in_features=512, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([1000, 3, 32, 32]) torch.Size([1000]) torch.Size([1000])
X range: tensor(2.7537) tensor(-2.4291) tensor(0.0238)
Note runnerup label is empty here!
############################
epsilon after preprocessing: tensor([[[[0.0388]],

         [[0.0393]],

         [[0.0390]]]]), data_max = tensor([[[[2.5141]],

         [[2.5968]],

         [[2.7537]]]]), data_min = tensor([[[[-2.4291]],

         [[-2.4183]],

         [[-2.2214]]]])
Task length: 1
saving results to Verified_ret_[cifar_conv_big]_start=799_end=800_iter=20_b=64_timeout=180_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 799 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 2, correct label 2, image norm 1159.88818359375, logits tensor([ 0.1283, -4.3792,  1.1080, -0.3748,  0.8383, -0.3994,  0.5362, -0.8684,
        -0.6296, -2.9523], device='cuda:0', grad_fn=<SelectBackward>)
##### PGD attack: True label: 2, Tested against: ['all'] ######
pgd prediction: tensor([ 0.1147, -4.3516,  1.0385, -0.4128,  0.8393, -0.4300,  0.4445, -0.8132,
        -0.5630, -2.8861], device='cuda:0', grad_fn=<SqueezeBackward1>)
attack margin tensor([0.9239, 5.3902,    inf, 1.4513, 0.1992, 1.4685, 0.5941, 1.8518, 1.6015,
        3.9246], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[ 0.1283, -4.3792,  1.1080, -0.3748,  0.8383, -0.3994,  0.5362, -0.8684,
         -0.6296, -2.9523]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-0.5292,  2.0461,  0.4434, -0.3655,  0.3011, -0.4660,  0.2229, -0.3569,
          1.5652]], device='cuda:0') None
best_l after optimization: -5.318389892578125 with beta sum per layer: []
alpha/beta optimization time: 24.060237407684326
initial alpha-CROWN bounds: tensor([[-0.2706,  2.4875,  0.6265, -0.2460,  0.5481, -0.2370,  0.4911, -0.0062,
          1.9251]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.2706, device='cuda:0', grad_fn=<MinBackward1>)
Sorted order for labels to verify: [4, 6, 0, 3, 5, 8, 7, 9, 1, 2]
##### [0:799] Tested against 4 ######
Model prediction is: tensor([[ 0.1283, -4.3792,  1.1080, -0.3748,  0.8383, -0.3994,  0.5362, -0.8684,
         -0.6296, -2.9523]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /16 start_node /17
setting alpha for layer /16 start_node /19
setting alpha for layer /16 start_node /21
setting alpha for layer /16 start_node /31
setting alpha for layer /16 start_node /33
not setting layer /16 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 32, 32, 32]) != torch.Size([2, 9, 1, 32, 32, 32]))
setting alpha for layer /18 start_node /19
setting alpha for layer /18 start_node /21
setting alpha for layer /18 start_node /31
setting alpha for layer /18 start_node /33
not setting layer /18 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /20 start_node /21
setting alpha for layer /20 start_node /31
setting alpha for layer /20 start_node /33
not setting layer /20 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 64, 16, 16]) != torch.Size([2, 9, 1, 64, 16, 16]))
setting alpha for layer /22 start_node /31
setting alpha for layer /22 start_node /33
not setting layer /22 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 64, 8, 8]) != torch.Size([2, 9, 1, 64, 8, 8]))
setting alpha for layer /32 start_node /33
not setting layer /32 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 512]) != torch.Size([2, 9, 1, 512]))
not setting layer /34 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 512]) != torch.Size([2, 9, 1, 512]))
0 /15 torch.Size([1, 32, 32, 32])
1 /17 torch.Size([1, 32, 16, 16])
2 /19 torch.Size([1, 64, 16, 16])
3 /21 torch.Size([1, 64, 8, 8])
4 /31 torch.Size([1, 512])
5 /33 torch.Size([1, 512])
best_l after optimization: 0.2459709644317627 with beta sum per layer: []
alpha/beta optimization time: 3.2985880374908447
alpha-CROWN with fixed intermediate bounds: tensor([[-0.2460]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.2459709644317627
layer 0 size torch.Size([32768]) unstable 2329
layer 1 size torch.Size([8192]) unstable 149
layer 2 size torch.Size([16384]) unstable 1656
layer 3 size torch.Size([4096]) unstable 118
layer 4 size torch.Size([512]) unstable 63
layer 5 size torch.Size([512]) unstable 120
-----------------
# of unstable neurons: 4435
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 32, 32]) pre split depth:  2
batch:  torch.Size([1, 32, 32, 32]) post split depth:  2
splitting decisions: 
split level 0: [5, 178] 
split level 1: [5, 210] 
regular batch size: 2*2, diving batch size 1*0
best_l after optimization: 0.7471106052398682 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.17139506340026855]
alpha/beta optimization time: 0.4437699317932129
This batch time : update_bounds func: 0.4490	 prepare: 0.0026	 bound: 0.4442	 transfer: 0.0015	 finalize: 0.0006
Accumulated time: update_bounds func: 0.4490	 prepare: 0.0026	 bound: 0.4442	 transfer: 0.0015	 finalize: 0.0006
batch bounding time:  0.4491419792175293
Current worst splitting domains [lb, ub] (depth):
[-0.21272,   inf] (3), [-0.18863,   inf] (3), [-0.17725,   inf] (3), [-0.16852,   inf] (3), 
length of domains: 4
Total time: 0.4887	 pickout: 0.0061	 decision: 0.0323	 get_bound: 0.4501	 add_domain: 0.0003
Current lb:-0.2127167284488678
4 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.734290361404419

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([4, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 112] [5, 112] [5, 112] [5, 112] 
regular batch size: 2*4, diving batch size 1*0
best_l after optimization: 1.3237130641937256 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.46127092838287354]
alpha/beta optimization time: 0.44741058349609375
This batch time : update_bounds func: 0.4544	 prepare: 0.0032	 bound: 0.4478	 transfer: 0.0021	 finalize: 0.0013
Accumulated time: update_bounds func: 0.9034	 prepare: 0.0057	 bound: 0.8921	 transfer: 0.0021	 finalize: 0.0019
batch bounding time:  0.45464444160461426
Current worst splitting domains [lb, ub] (depth):
[-0.19572,   inf] (5), [-0.18803,   inf] (5), [-0.17120,   inf] (5), [-0.16493,   inf] (5), [-0.15909,   inf] (5), [-0.15103,   inf] (5), [-0.15102,   inf] (5), [-0.14268,   inf] (5), 
length of domains: 8
Total time: 0.4919	 pickout: 0.0032	 decision: 0.0336	 get_bound: 0.4547	 add_domain: 0.0005
Current lb:-0.19571849703788757
12 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.2264487743377686

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 275] [5, 431] [5, 275] [5, 431] [5, 431] [5, 275] [5, 275] [5, 275] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 2.3169970512390137 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 1.4250156879425049]
alpha/beta optimization time: 0.4695429801940918
This batch time : update_bounds func: 0.4815	 prepare: 0.0050	 bound: 0.4700	 transfer: 0.0034	 finalize: 0.0030
Accumulated time: update_bounds func: 1.3849	 prepare: 0.0108	 bound: 1.3621	 transfer: 0.0034	 finalize: 0.0049
batch bounding time:  0.48171305656433105
Current worst splitting domains [lb, ub] (depth):
[-0.18005,   inf] (7), [-0.17948,   inf] (7), [-0.17195,   inf] (7), [-0.15578,   inf] (7), [-0.15552,   inf] (7), [-0.15373,   inf] (7), [-0.14956,   inf] (7), [-0.14593,   inf] (7), [-0.13555,   inf] (7), [-0.13496,   inf] (7), [-0.13399,   inf] (7), [-0.13223,   inf] (7), [-0.12984,   inf] (7), [-0.12780,   inf] (7), [-0.12335,   inf] (7), [-0.10729,   inf] (7), 
length of domains: 16
Total time: 0.5348	 pickout: 0.0078	 decision: 0.0444	 get_bound: 0.4818	 add_domain: 0.0009
Current lb:-0.18004746735095978
28 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.7616236209869385

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([16, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([16, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 431] [5, 431] [5, 275] [5, 431] [5, 275] [5, 431] [5, 275] [5, 275] [5, 150] [5, 431] 
regular batch size: 2*16, diving batch size 1*0
best_l after optimization: 3.966958522796631 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 4.495100498199463]
alpha/beta optimization time: 0.4805128574371338
This batch time : update_bounds func: 0.5055	 prepare: 0.0098	 bound: 0.4810	 transfer: 0.0106	 finalize: 0.0040
Accumulated time: update_bounds func: 1.8904	 prepare: 0.0206	 bound: 1.8431	 transfer: 0.0106	 finalize: 0.0089
batch bounding time:  0.5057599544525146
Current worst splitting domains [lb, ub] (depth):
[-0.16427,   inf] (9), [-0.16420,   inf] (9), [-0.15670,   inf] (9), [-0.15354,   inf] (9), [-0.15054,   inf] (9), [-0.14713,   inf] (9), [-0.14134,   inf] (9), [-0.14036,   inf] (9), [-0.13921,   inf] (9), [-0.13482,   inf] (9), [-0.13453,   inf] (9), [-0.13155,   inf] (9), [-0.13048,   inf] (9), [-0.12857,   inf] (9), [-0.12498,   inf] (9), [-0.12366,   inf] (9), [-0.12171,   inf] (9), [-0.12138,   inf] (9), [-0.11919,   inf] (9), [-0.11840,   inf] (9), 
length of domains: 32
Total time: 0.5769	 pickout: 0.0173	 decision: 0.0520	 get_bound: 0.5058	 add_domain: 0.0017
Current lb:-0.1642749011516571
60 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.338922739028931

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([32, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([32, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 239] [5, 239] [5, 239] [5, 150] [5, 150] [5, 239] [5, 239] [5, 239] [5, 150] [5, 150] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: 6.743589401245117 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 9.871252059936523]
alpha/beta optimization time: 0.5566644668579102
This batch time : update_bounds func: 0.5954	 prepare: 0.0110	 bound: 0.5571	 transfer: 0.0199	 finalize: 0.0072
Accumulated time: update_bounds func: 2.4858	 prepare: 0.0316	 bound: 2.4001	 transfer: 0.0199	 finalize: 0.0161
batch bounding time:  0.5956273078918457
Current worst splitting domains [lb, ub] (depth):
[-0.14911,   inf] (11), [-0.14908,   inf] (11), [-0.14881,   inf] (11), [-0.14873,   inf] (11), [-0.14167,   inf] (11), [-0.14118,   inf] (11), [-0.13815,   inf] (11), [-0.13695,   inf] (11), [-0.13566,   inf] (11), [-0.13188,   inf] (11), [-0.13173,   inf] (11), [-0.13146,   inf] (11), [-0.12741,   inf] (11), [-0.12582,   inf] (11), [-0.12567,   inf] (11), [-0.12502,   inf] (11), [-0.12408,   inf] (11), [-0.12174,   inf] (11), [-0.12057,   inf] (11), [-0.11972,   inf] (11), 
length of domains: 63
Total time: 0.6805	 pickout: 0.0203	 decision: 0.0611	 get_bound: 0.5957	 add_domain: 0.0034
Current lb:-0.14910806715488434
124 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.020348072052002

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([63, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([63, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 150] [5, 150] [5, 150] [5, 150] [5, 150] [5, 150] [5, 239] [5, 239] [5, 239] [5, 239] 
regular batch size: 2*63, diving batch size 1*0
best_l after optimization: 11.085765838623047 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.5868675708770752, 23.47963523864746]
alpha/beta optimization time: 0.7839579582214355
This batch time : update_bounds func: 0.8605	 prepare: 0.0201	 bound: 0.7844	 transfer: 0.0414	 finalize: 0.0142
Accumulated time: update_bounds func: 3.3464	 prepare: 0.0518	 bound: 3.1845	 transfer: 0.0414	 finalize: 0.0303
batch bounding time:  0.8608717918395996
Current worst splitting domains [lb, ub] (depth):
[-0.13448,   inf] (13), [-0.13413,   inf] (13), [-0.13401,   inf] (13), [-0.13381,   inf] (13), [-0.13233,   inf] (13), [-0.13222,   inf] (13), [-0.13173,   inf] (13), [-0.13131,   inf] (13), [-0.12715,   inf] (13), [-0.12616,   inf] (13), [-0.12449,   inf] (13), [-0.12379,   inf] (13), [-0.12368,   inf] (13), [-0.12228,   inf] (13), [-0.12170,   inf] (13), [-0.12167,   inf] (13), [-0.12114,   inf] (13), [-0.11995,   inf] (13), [-0.11777,   inf] (13), [-0.11684,   inf] (13), 
length of domains: 122
Total time: 1.0106	 pickout: 0.0420	 decision: 0.1001	 get_bound: 0.8611	 add_domain: 0.0074
Current lb:-0.13447773456573486
250 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.032805919647217

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 17] [5, 17] [5, 17] [5, 17] [5, 17] [5, 17] [5, 17] [5, 17] [5, 17] [5, 17] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 12.122781753540039 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 10.370138168334961]
alpha/beta optimization time: 0.8139200210571289
This batch time : update_bounds func: 0.8919	 prepare: 0.0206	 bound: 0.8144	 transfer: 0.0412	 finalize: 0.0153
Accumulated time: update_bounds func: 4.2382	 prepare: 0.0724	 bound: 3.9989	 transfer: 0.0412	 finalize: 0.0456
batch bounding time:  0.8923125267028809
Current worst splitting domains [lb, ub] (depth):
[-0.12057,   inf] (15), [-0.11990,   inf] (15), [-0.11966,   inf] (15), [-0.11958,   inf] (15), [-0.11918,   inf] (15), [-0.11868,   inf] (15), [-0.11867,   inf] (15), [-0.11865,   inf] (15), [-0.11860,   inf] (15), [-0.11836,   inf] (15), [-0.11801,   inf] (15), [-0.11767,   inf] (15), [-0.11665,   inf] (15), [-0.11664,   inf] (15), [-0.11619,   inf] (15), [-0.11577,   inf] (15), [-0.11325,   inf] (15), [-0.11236,   inf] (15), [-0.11119,   inf] (15), [-0.11115,   inf] (15), 
length of domains: 186
Total time: 1.0420	 pickout: 0.0491	 decision: 0.0927	 get_bound: 0.8925	 add_domain: 0.0076
Current lb:-0.12057416886091232
378 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.076750040054321

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 219] [4, 302] [4, 302] [5, 219] [5, 219] [4, 302] [5, 219] [5, 219] [5, 219] [4, 302] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 11.566672325134277 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.02498582936823368, 7.9111104011535645]
alpha/beta optimization time: 0.8024613857269287
This batch time : update_bounds func: 0.8944	 prepare: 0.0205	 bound: 0.8029	 transfer: 0.0505	 finalize: 0.0202
Accumulated time: update_bounds func: 5.1326	 prepare: 0.0929	 bound: 4.8018	 transfer: 0.0505	 finalize: 0.0658
batch bounding time:  0.894794225692749
Current worst splitting domains [lb, ub] (depth):
[-0.10814,   inf] (17), [-0.10747,   inf] (17), [-0.10725,   inf] (17), [-0.10725,   inf] (17), [-0.10715,   inf] (17), [-0.10659,   inf] (17), [-0.10651,   inf] (17), [-0.10648,   inf] (17), [-0.10642,   inf] (17), [-0.10594,   inf] (17), [-0.10588,   inf] (17), [-0.10557,   inf] (17), [-0.10551,   inf] (17), [-0.10519,   inf] (17), [-0.10476,   inf] (17), [-0.10466,   inf] (17), [-0.10453,   inf] (17), [-0.10444,   inf] (17), [-0.10443,   inf] (17), [-0.10373,   inf] (17), 
length of domains: 250
Total time: 1.0479	 pickout: 0.0508	 decision: 0.0930	 get_bound: 0.8950	 add_domain: 0.0091
Current lb:-0.1081446036696434
506 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.126553058624268

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 302] [5, 219] [5, 219] [4, 302] [4, 302] [4, 302] [4, 302] [4, 302] [5, 219] [5, 219] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.453523635864258 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.1315097212791443, 9.566978454589844]
alpha/beta optimization time: 0.7932682037353516
This batch time : update_bounds func: 0.8898	 prepare: 0.0322	 bound: 0.7938	 transfer: 0.0488	 finalize: 0.0147
Accumulated time: update_bounds func: 6.0224	 prepare: 0.1251	 bound: 5.5956	 transfer: 0.0488	 finalize: 0.0804
batch bounding time:  0.8901305198669434
Current worst splitting domains [lb, ub] (depth):
[-0.09553,   inf] (19), [-0.09491,   inf] (19), [-0.09483,   inf] (19), [-0.09468,   inf] (19), [-0.09460,   inf] (19), [-0.09409,   inf] (19), [-0.09408,   inf] (19), [-0.09408,   inf] (19), [-0.09395,   inf] (19), [-0.09360,   inf] (19), [-0.09340,   inf] (19), [-0.09332,   inf] (19), [-0.09324,   inf] (19), [-0.09287,   inf] (19), [-0.09283,   inf] (19), [-0.09281,   inf] (19), [-0.09277,   inf] (19), [-0.09266,   inf] (19), [-0.09265,   inf] (19), [-0.09259,   inf] (19), 
length of domains: 314
Total time: 1.0487	 pickout: 0.0485	 decision: 0.1014	 get_bound: 0.8903	 add_domain: 0.0084
Current lb:-0.09553259611129761
634 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.177090883255005

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 475] [5, 475] [5, 475] [5, 475] [5, 475] [5, 475] [5, 475] [5, 475] [5, 475] [5, 475] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.612203121185303 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.1962718963623047, 13.813570976257324]
alpha/beta optimization time: 0.7826137542724609
This batch time : update_bounds func: 0.8683	 prepare: 0.0212	 bound: 0.7830	 transfer: 0.0497	 finalize: 0.0139
Accumulated time: update_bounds func: 6.8907	 prepare: 0.1463	 bound: 6.3787	 transfer: 0.0497	 finalize: 0.0944
batch bounding time:  0.8686559200286865
Current worst splitting domains [lb, ub] (depth):
[-0.08973,   inf] (15), [-0.08969,   inf] (13), [-0.08969,   inf] (19), [-0.08952,   inf] (13), [-0.08937,   inf] (19), [-0.08931,   inf] (15), [-0.08927,   inf] (19), [-0.08912,   inf] (15), [-0.08903,   inf] (17), [-0.08896,   inf] (13), [-0.08889,   inf] (19), [-0.08880,   inf] (13), [-0.08880,   inf] (13), [-0.08879,   inf] (15), [-0.08875,   inf] (17), [-0.08874,   inf] (19), [-0.08870,   inf] (17), [-0.08866,   inf] (17), [-0.08857,   inf] (17), [-0.08854,   inf] (13), 
length of domains: 375
Total time: 1.0186	 pickout: 0.0484	 decision: 0.0924	 get_bound: 0.8689	 add_domain: 0.0089
Current lb:-0.08972979336977005
762 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.197525978088379

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 475] [5, 475] [5, 219] [5, 17] [5, 219] [5, 475] [5, 475] [5, 475] [5, 475] [5, 475] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.6447296142578125 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.22291025519371033, 17.314067840576172]
alpha/beta optimization time: 0.8166472911834717
This batch time : update_bounds func: 0.9099	 prepare: 0.0208	 bound: 0.8171	 transfer: 0.0505	 finalize: 0.0211
Accumulated time: update_bounds func: 7.8006	 prepare: 0.1671	 bound: 7.1958	 transfer: 0.0505	 finalize: 0.1155
batch bounding time:  0.9102590084075928
Current worst splitting domains [lb, ub] (depth):
[-0.08547,   inf] (13), [-0.08535,   inf] (15), [-0.08530,   inf] (19), [-0.08510,   inf] (17), [-0.08505,   inf] (13), [-0.08505,   inf] (17), [-0.08502,   inf] (17), [-0.08499,   inf] (17), [-0.08493,   inf] (15), [-0.08473,   inf] (17), [-0.08470,   inf] (15), [-0.08469,   inf] (19), [-0.08469,   inf] (17), [-0.08465,   inf] (17), [-0.08465,   inf] (15), [-0.08465,   inf] (15), [-0.08463,   inf] (13), [-0.08458,   inf] (19), [-0.08442,   inf] (19), [-0.08441,   inf] (17), 
length of domains: 434
Total time: 1.0566	 pickout: 0.0461	 decision: 0.0916	 get_bound: 0.9105	 add_domain: 0.0084
Current lb:-0.08547322452068329
890 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.25594162940979

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 431] [5, 475] [5, 475] [5, 219] [5, 17] [5, 219] [4, 302] [5, 219] [4, 302] [5, 219] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.32022762298584 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.10674603283405304, 19.359115600585938]
alpha/beta optimization time: 0.805722713470459
This batch time : update_bounds func: 0.9022	 prepare: 0.0319	 bound: 0.8062	 transfer: 0.0493	 finalize: 0.0144
Accumulated time: update_bounds func: 8.7028	 prepare: 0.1990	 bound: 8.0020	 transfer: 0.0493	 finalize: 0.1299
batch bounding time:  0.9025824069976807
Current worst splitting domains [lb, ub] (depth):
[-0.08224,   inf] (21), [-0.08223,   inf] (21), [-0.08219,   inf] (21), [-0.08216,   inf] (21), [-0.08213,   inf] (17), [-0.08211,   inf] (15), [-0.08208,   inf] (19), [-0.08202,   inf] (17), [-0.08195,   inf] (19), [-0.08190,   inf] (13), [-0.08189,   inf] (13), [-0.08186,   inf] (15), [-0.08181,   inf] (19), [-0.08170,   inf] (21), [-0.08167,   inf] (17), [-0.08165,   inf] (17), [-0.08163,   inf] (19), [-0.08157,   inf] (17), [-0.08154,   inf] (13), [-0.08147,   inf] (17), 
length of domains: 490
Total time: 1.1526	 pickout: 0.0502	 decision: 0.1910	 get_bound: 0.9028	 add_domain: 0.0086
Current lb:-0.08224230259656906
1018 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.410425901412964

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 460] [5, 218] [5, 460] [5, 460] [4, 302] [5, 475] [5, 219] [5, 475] [5, 475] [5, 17] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.774740695953369 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.038624946027994156, 15.657245635986328]
alpha/beta optimization time: 0.7790920734405518
This batch time : update_bounds func: 0.8690	 prepare: 0.0214	 bound: 0.7795	 transfer: 0.0526	 finalize: 0.0151
Accumulated time: update_bounds func: 9.5718	 prepare: 0.2204	 bound: 8.7815	 transfer: 0.0526	 finalize: 0.1450
batch bounding time:  0.8694074153900146
Current worst splitting domains [lb, ub] (depth):
[-0.07967,   inf] (21), [-0.07966,   inf] (19), [-0.07964,   inf] (17), [-0.07960,   inf] (21), [-0.07949,   inf] (17), [-0.07947,   inf] (19), [-0.07944,   inf] (13), [-0.07943,   inf] (19), [-0.07942,   inf] (19), [-0.07939,   inf] (19), [-0.07936,   inf] (21), [-0.07934,   inf] (15), [-0.07932,   inf] (21), [-0.07931,   inf] (21), [-0.07931,   inf] (17), [-0.07921,   inf] (21), [-0.07906,   inf] (15), [-0.07905,   inf] (15), [-0.07900,   inf] (17), [-0.07899,   inf] (15), 
length of domains: 546
Total time: 1.0145	 pickout: 0.0449	 decision: 0.0916	 get_bound: 0.8696	 add_domain: 0.0083
Current lb:-0.07967285066843033
1146 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.427056550979614

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 460] [5, 475] [5, 475] [5, 460] [5, 475] [5, 219] [5, 17] [5, 475] [5, 475] [5, 219] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.6703290939331055 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.11544891446828842, 19.026348114013672]
alpha/beta optimization time: 0.7817115783691406
This batch time : update_bounds func: 0.8702	 prepare: 0.0214	 bound: 0.7821	 transfer: 0.0514	 finalize: 0.0149
Accumulated time: update_bounds func: 10.4421	 prepare: 0.2418	 bound: 9.5637	 transfer: 0.0514	 finalize: 0.1599
batch bounding time:  0.8706297874450684
Current worst splitting domains [lb, ub] (depth):
[-0.07697,   inf] (17), [-0.07691,   inf] (21), [-0.07691,   inf] (21), [-0.07686,   inf] (17), [-0.07684,   inf] (13), [-0.07682,   inf] (19), [-0.07676,   inf] (13), [-0.07676,   inf] (15), [-0.07674,   inf] (19), [-0.07673,   inf] (19), [-0.07669,   inf] (17), [-0.07666,   inf] (19), [-0.07665,   inf] (21), [-0.07664,   inf] (21), [-0.07663,   inf] (17), [-0.07658,   inf] (21), [-0.07651,   inf] (21), [-0.07647,   inf] (19), [-0.07635,   inf] (15), [-0.07625,   inf] (21), 
length of domains: 603
Total time: 1.0259	 pickout: 0.0508	 decision: 0.0949	 get_bound: 0.8708	 add_domain: 0.0093
Current lb:-0.07696641236543655
1274 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.454796314239502

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 302] [5, 460] [5, 218] [5, 475] [5, 431] [5, 475] [5, 17] [5, 431] [5, 475] [5, 475] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.806140422821045 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.1324741095304489, 22.130603790283203]
alpha/beta optimization time: 0.7990319728851318
This batch time : update_bounds func: 0.8835	 prepare: 0.0211	 bound: 0.7995	 transfer: 0.0470	 finalize: 0.0156
Accumulated time: update_bounds func: 11.3256	 prepare: 0.2629	 bound: 10.3631	 transfer: 0.0470	 finalize: 0.1755
batch bounding time:  0.8838934898376465
Current worst splitting domains [lb, ub] (depth):
[-0.07450,   inf] (21), [-0.07449,   inf] (17), [-0.07439,   inf] (19), [-0.07439,   inf] (19), [-0.07430,   inf] (21), [-0.07424,   inf] (15), [-0.07424,   inf] (13), [-0.07423,   inf] (19), [-0.07420,   inf] (15), [-0.07419,   inf] (19), [-0.07418,   inf] (21), [-0.07416,   inf] (15), [-0.07413,   inf] (17), [-0.07399,   inf] (15), [-0.07399,   inf] (17), [-0.07389,   inf] (19), [-0.07387,   inf] (21), [-0.07383,   inf] (15), [-0.07381,   inf] (21), [-0.07373,   inf] (17), 
length of domains: 656
Total time: 1.0309	 pickout: 0.0467	 decision: 0.0918	 get_bound: 0.8841	 add_domain: 0.0082
Current lb:-0.0744965448975563
1402 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.48784899711609

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 460] [5, 475] [5, 475] [5, 475] [5, 320] [5, 475] [5, 17] [5, 475] [4, 302] [5, 219] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.98055362701416 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.12981684505939484, 17.91960906982422]
alpha/beta optimization time: 0.7818810939788818
This batch time : update_bounds func: 0.8715	 prepare: 0.0215	 bound: 0.7823	 transfer: 0.0523	 finalize: 0.0150
Accumulated time: update_bounds func: 12.1971	 prepare: 0.2844	 bound: 11.1454	 transfer: 0.0523	 finalize: 0.1905
batch bounding time:  0.8718903064727783
Current worst splitting domains [lb, ub] (depth):
[-0.07202,   inf] (19), [-0.07192,   inf] (15), [-0.07191,   inf] (23), [-0.07190,   inf] (17), [-0.07190,   inf] (21), [-0.07183,   inf] (21), [-0.07181,   inf] (19), [-0.07179,   inf] (15), [-0.07176,   inf] (15), [-0.07168,   inf] (15), [-0.07165,   inf] (15), [-0.07160,   inf] (19), [-0.07156,   inf] (17), [-0.07153,   inf] (23), [-0.07153,   inf] (21), [-0.07153,   inf] (15), [-0.07152,   inf] (17), [-0.07152,   inf] (19), [-0.07151,   inf] (21), [-0.07149,   inf] (15), 
length of domains: 708
Total time: 1.0174	 pickout: 0.0429	 decision: 0.0930	 get_bound: 0.8721	 add_domain: 0.0094
Current lb:-0.07202401012182236
1530 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.50747299194336

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 475] [5, 431] [5, 460] [5, 475] [5, 218] [5, 218] [5, 475] [4, 302] [5, 219] [5, 475] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.922726154327393 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.3485605716705322, 17.506179809570312]
alpha/beta optimization time: 0.7814667224884033
This batch time : update_bounds func: 0.8679	 prepare: 0.0214	 bound: 0.7819	 transfer: 0.0487	 finalize: 0.0156
Accumulated time: update_bounds func: 13.0650	 prepare: 0.3058	 bound: 11.9274	 transfer: 0.0487	 finalize: 0.2060
batch bounding time:  0.8682377338409424
Current worst splitting domains [lb, ub] (depth):
[-0.07031,   inf] (19), [-0.07030,   inf] (17), [-0.07029,   inf] (21), [-0.07027,   inf] (19), [-0.07021,   inf] (17), [-0.07021,   inf] (23), [-0.07020,   inf] (17), [-0.07005,   inf] (23), [-0.07004,   inf] (15), [-0.07001,   inf] (23), [-0.07001,   inf] (15), [-0.06999,   inf] (17), [-0.06997,   inf] (17), [-0.06993,   inf] (21), [-0.06989,   inf] (23), [-0.06988,   inf] (23), [-0.06986,   inf] (21), [-0.06984,   inf] (21), [-0.06984,   inf] (23), [-0.06984,   inf] (19), 
length of domains: 765
Total time: 1.0131	 pickout: 0.0427	 decision: 0.0932	 get_bound: 0.8685	 add_domain: 0.0086
Current lb:-0.0703086331486702
1658 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 19.522486686706543

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 475] [5, 219] [5, 460] [5, 475] [5, 219] [5, 320] [4, 302] [5, 320] [5, 475] [5, 320] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.8596673011779785 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.4447728991508484, 18.675674438476562]
alpha/beta optimization time: 0.8116753101348877
This batch time : update_bounds func: 0.8984	 prepare: 0.0221	 bound: 0.8122	 transfer: 0.0485	 finalize: 0.0150
Accumulated time: update_bounds func: 13.9634	 prepare: 0.3279	 bound: 12.7395	 transfer: 0.0485	 finalize: 0.2211
batch bounding time:  0.8988165855407715
Current worst splitting domains [lb, ub] (depth):
[-0.06835,   inf] (23), [-0.06833,   inf] (19), [-0.06832,   inf] (21), [-0.06830,   inf] (17), [-0.06829,   inf] (17), [-0.06826,   inf] (21), [-0.06824,   inf] (17), [-0.06824,   inf] (15), [-0.06818,   inf] (21), [-0.06815,   inf] (15), [-0.06814,   inf] (17), [-0.06807,   inf] (19), [-0.06806,   inf] (23), [-0.06805,   inf] (23), [-0.06805,   inf] (17), [-0.06804,   inf] (17), [-0.06800,   inf] (17), [-0.06792,   inf] (19), [-0.06791,   inf] (21), [-0.06789,   inf] (21), 
length of domains: 819
Total time: 1.0623	 pickout: 0.0581	 decision: 0.0958	 get_bound: 0.8990	 add_domain: 0.0094
Current lb:-0.06834723800420761
1786 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 20.58695673942566

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [5, 475] [5, 218] [4, 302] [4, 302] [5, 218] [5, 475] [5, 475] [5, 218] [4, 302] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.00239372253418 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.06005184352397919, 17.870349884033203]
alpha/beta optimization time: 0.7786211967468262
This batch time : update_bounds func: 0.9183	 prepare: 0.0216	 bound: 0.7791	 transfer: 0.0483	 finalize: 0.0689
Accumulated time: update_bounds func: 14.8817	 prepare: 0.3495	 bound: 13.5186	 transfer: 0.0483	 finalize: 0.2899
batch bounding time:  0.9186995029449463
Current worst splitting domains [lb, ub] (depth):
[-0.06645,   inf] (17), [-0.06645,   inf] (15), [-0.06641,   inf] (17), [-0.06641,   inf] (17), [-0.06637,   inf] (15), [-0.06635,   inf] (19), [-0.06634,   inf] (23), [-0.06634,   inf] (15), [-0.06631,   inf] (19), [-0.06630,   inf] (21), [-0.06628,   inf] (19), [-0.06626,   inf] (23), [-0.06623,   inf] (23), [-0.06623,   inf] (21), [-0.06619,   inf] (19), [-0.06613,   inf] (15), [-0.06612,   inf] (19), [-0.06612,   inf] (21), [-0.06602,   inf] (17), [-0.06601,   inf] (19), 
length of domains: 874
Total time: 1.0694	 pickout: 0.0494	 decision: 0.0926	 get_bound: 0.9189	 add_domain: 0.0085
Current lb:-0.0664546862244606
1914 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 21.658875703811646

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 475] [4, 302] [5, 219] [4, 302] [5, 475] [5, 475] [5, 218] [5, 219] [5, 475] [5, 218] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.283494472503662 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.22041690349578857, 22.572898864746094]
alpha/beta optimization time: 0.782198429107666
This batch time : update_bounds func: 0.8718	 prepare: 0.0215	 bound: 0.7826	 transfer: 0.0514	 finalize: 0.0151
Accumulated time: update_bounds func: 15.7535	 prepare: 0.3711	 bound: 14.3012	 transfer: 0.0514	 finalize: 0.3051
batch bounding time:  0.8721706867218018
Current worst splitting domains [lb, ub] (depth):
[-0.06413,   inf] (23), [-0.06402,   inf] (17), [-0.06401,   inf] (21), [-0.06400,   inf] (19), [-0.06394,   inf] (19), [-0.06392,   inf] (21), [-0.06392,   inf] (21), [-0.06390,   inf] (19), [-0.06390,   inf] (21), [-0.06388,   inf] (19), [-0.06386,   inf] (23), [-0.06386,   inf] (19), [-0.06382,   inf] (17), [-0.06381,   inf] (19), [-0.06376,   inf] (19), [-0.06374,   inf] (19), [-0.06373,   inf] (21), [-0.06372,   inf] (19), [-0.06360,   inf] (19), [-0.06359,   inf] (19), 
length of domains: 921
Total time: 1.0178	 pickout: 0.0446	 decision: 0.0927	 get_bound: 0.8724	 add_domain: 0.0081
Current lb:-0.064127616584301
2042 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 22.678892374038696

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [4, 302] [5, 218] [5, 460] [5, 219] [5, 218] [5, 218] [4, 302] [5, 460] [5, 219] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.229161262512207 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.5031302571296692, 21.924001693725586]
alpha/beta optimization time: 0.7851488590240479
This batch time : update_bounds func: 0.8791	 prepare: 0.0217	 bound: 0.7857	 transfer: 0.0548	 finalize: 0.0164
Accumulated time: update_bounds func: 16.6325	 prepare: 0.3927	 bound: 15.0869	 transfer: 0.0548	 finalize: 0.3215
batch bounding time:  0.8795435428619385
Current worst splitting domains [lb, ub] (depth):
[-0.06256,   inf] (21), [-0.06256,   inf] (19), [-0.06254,   inf] (17), [-0.06250,   inf] (21), [-0.06243,   inf] (25), [-0.06241,   inf] (21), [-0.06240,   inf] (25), [-0.06236,   inf] (25), [-0.06234,   inf] (25), [-0.06233,   inf] (25), [-0.06229,   inf] (23), [-0.06228,   inf] (15), [-0.06227,   inf] (19), [-0.06226,   inf] (19), [-0.06221,   inf] (25), [-0.06212,   inf] (23), [-0.06210,   inf] (21), [-0.06196,   inf] (19), [-0.06193,   inf] (17), [-0.06191,   inf] (21), 
length of domains: 974
Total time: 1.0249	 pickout: 0.0417	 decision: 0.0945	 get_bound: 0.8798	 add_domain: 0.0089
Current lb:-0.06256210058927536
2170 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 23.7065851688385

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 218] [5, 475] [5, 475] [5, 218] [5, 460] [5, 320] [5, 320] [5, 320] [5, 320] [5, 320] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.069546222686768 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.22510981559753418, 17.72785186767578]
alpha/beta optimization time: 0.8573973178863525
This batch time : update_bounds func: 0.9525	 prepare: 0.0222	 bound: 0.8579	 transfer: 0.0495	 finalize: 0.0216
Accumulated time: update_bounds func: 17.5850	 prepare: 0.4149	 bound: 15.9448	 transfer: 0.0495	 finalize: 0.3432
batch bounding time:  0.9529542922973633
Current worst splitting domains [lb, ub] (depth):
[-0.06100,   inf] (19), [-0.06094,   inf] (23), [-0.06093,   inf] (23), [-0.06090,   inf] (23), [-0.06088,   inf] (19), [-0.06087,   inf] (19), [-0.06080,   inf] (23), [-0.06078,   inf] (17), [-0.06078,   inf] (23), [-0.06073,   inf] (25), [-0.06071,   inf] (21), [-0.06069,   inf] (23), [-0.06067,   inf] (25), [-0.06067,   inf] (19), [-0.06065,   inf] (17), [-0.06062,   inf] (19), [-0.06062,   inf] (17), [-0.06056,   inf] (17), [-0.06053,   inf] (25), [-0.06051,   inf] (23), 
length of domains: 1028
Total time: 1.1193	 pickout: 0.0557	 decision: 0.1008	 get_bound: 0.9532	 add_domain: 0.0095
Current lb:-0.06099655479192734
2298 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 24.828256130218506

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 219] [5, 320] [5, 320] [5, 320] [5, 475] [5, 219] [5, 460] [4, 302] [5, 218] [5, 218] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.0141401290893555 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.2089807689189911, 17.189247131347656]
alpha/beta optimization time: 0.8495872020721436
This batch time : update_bounds func: 0.9579	 prepare: 0.0330	 bound: 0.8502	 transfer: 0.0506	 finalize: 0.0236
Accumulated time: update_bounds func: 18.5429	 prepare: 0.4479	 bound: 16.7950	 transfer: 0.0506	 finalize: 0.3667
batch bounding time:  0.9583604335784912
Current worst splitting domains [lb, ub] (depth):
[-0.05953,   inf] (19), [-0.05952,   inf] (19), [-0.05951,   inf] (17), [-0.05948,   inf] (23), [-0.05947,   inf] (17), [-0.05946,   inf] (17), [-0.05946,   inf] (23), [-0.05943,   inf] (21), [-0.05941,   inf] (25), [-0.05940,   inf] (25), [-0.05939,   inf] (19), [-0.05930,   inf] (17), [-0.05928,   inf] (21), [-0.05926,   inf] (25), [-0.05926,   inf] (25), [-0.05924,   inf] (21), [-0.05919,   inf] (21), [-0.05917,   inf] (19), [-0.05917,   inf] (23), [-0.05915,   inf] (19), 
length of domains: 1086
Total time: 1.1366	 pickout: 0.0630	 decision: 0.1044	 get_bound: 0.9586	 add_domain: 0.0106
Current lb:-0.059529196470975876
2426 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 25.9676673412323

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 475] [5, 219] [5, 475] [5, 320] [4, 302] [5, 431] [5, 320] [5, 218] [5, 218] [5, 320] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.76711368560791 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.16345801949501038, 20.84577751159668]
alpha/beta optimization time: 0.8485937118530273
This batch time : update_bounds func: 0.9533	 prepare: 0.0332	 bound: 0.8492	 transfer: 0.0484	 finalize: 0.0213
Accumulated time: update_bounds func: 19.4962	 prepare: 0.4811	 bound: 17.6442	 transfer: 0.0484	 finalize: 0.3881
batch bounding time:  0.9536371231079102
Current worst splitting domains [lb, ub] (depth):
[-0.05818,   inf] (19), [-0.05814,   inf] (23), [-0.05813,   inf] (23), [-0.05813,   inf] (25), [-0.05813,   inf] (21), [-0.05811,   inf] (23), [-0.05809,   inf] (23), [-0.05809,   inf] (19), [-0.05808,   inf] (19), [-0.05804,   inf] (23), [-0.05802,   inf] (21), [-0.05801,   inf] (19), [-0.05798,   inf] (23), [-0.05798,   inf] (21), [-0.05798,   inf] (17), [-0.05798,   inf] (25), [-0.05792,   inf] (25), [-0.05792,   inf] (19), [-0.05789,   inf] (19), [-0.05789,   inf] (17), 
length of domains: 1141
Total time: 1.1392	 pickout: 0.0725	 decision: 0.1030	 get_bound: 0.9539	 add_domain: 0.0097
Current lb:-0.0581798255443573
2554 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 27.10920548439026

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 219] [5, 320] [5, 460] [5, 460] [5, 218] [5, 320] [5, 320] [4, 302] [5, 219] [5, 320] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.686119556427002 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.07359174638986588, 19.780227661132812]
alpha/beta optimization time: 0.8451628684997559
This batch time : update_bounds func: 0.9457	 prepare: 0.0330	 bound: 0.8457	 transfer: 0.0446	 finalize: 0.0219
Accumulated time: update_bounds func: 20.4419	 prepare: 0.5141	 bound: 18.4899	 transfer: 0.0446	 finalize: 0.4099
batch bounding time:  0.94608473777771
Current worst splitting domains [lb, ub] (depth):
[-0.05686,   inf] (23), [-0.05683,   inf] (21), [-0.05680,   inf] (25), [-0.05680,   inf] (25), [-0.05678,   inf] (19), [-0.05670,   inf] (25), [-0.05668,   inf] (21), [-0.05667,   inf] (19), [-0.05663,   inf] (17), [-0.05661,   inf] (21), [-0.05661,   inf] (19), [-0.05661,   inf] (21), [-0.05660,   inf] (23), [-0.05660,   inf] (17), [-0.05659,   inf] (19), [-0.05654,   inf] (25), [-0.05652,   inf] (25), [-0.05649,   inf] (23), [-0.05649,   inf] (17), [-0.05648,   inf] (19), 
length of domains: 1200
Total time: 1.1277	 pickout: 0.0675	 decision: 0.1042	 get_bound: 0.9463	 add_domain: 0.0097
Current lb:-0.05686495825648308
2682 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 28.238980293273926

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [5, 460] [5, 218] [5, 218] [5, 475] [5, 218] [5, 218] [5, 219] [5, 17] [5, 460] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.442597389221191 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.18933433294296265, 21.56757926940918]
alpha/beta optimization time: 0.8471448421478271
This batch time : update_bounds func: 0.9514	 prepare: 0.0330	 bound: 0.8477	 transfer: 0.0482	 finalize: 0.0213
Accumulated time: update_bounds func: 21.3933	 prepare: 0.5471	 bound: 19.3377	 transfer: 0.0482	 finalize: 0.4312
batch bounding time:  0.9517555236816406
Current worst splitting domains [lb, ub] (depth):
[-0.05545,   inf] (23), [-0.05540,   inf] (17), [-0.05540,   inf] (23), [-0.05539,   inf] (21), [-0.05539,   inf] (25), [-0.05538,   inf] (19), [-0.05536,   inf] (13), [-0.05535,   inf] (21), [-0.05534,   inf] (21), [-0.05533,   inf] (25), [-0.05526,   inf] (23), [-0.05526,   inf] (17), [-0.05524,   inf] (21), [-0.05521,   inf] (21), [-0.05519,   inf] (25), [-0.05515,   inf] (19), [-0.05512,   inf] (23), [-0.05509,   inf] (21), [-0.05506,   inf] (23), [-0.05501,   inf] (17), 
length of domains: 1256
Total time: 1.1209	 pickout: 0.0560	 decision: 0.1033	 get_bound: 0.9520	 add_domain: 0.0096
Current lb:-0.0554487518966198
2810 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 29.362117767333984

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [4, 302] [5, 320] [5, 320] [5, 218] [5, 219] [4, 53] [5, 320] [5, 460] [5, 320] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.366569519042969 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.15258532762527466, 19.230327606201172]
alpha/beta optimization time: 0.8839230537414551
This batch time : update_bounds func: 0.9903	 prepare: 0.0337	 bound: 0.8845	 transfer: 0.0491	 finalize: 0.0224
Accumulated time: update_bounds func: 22.3836	 prepare: 0.5808	 bound: 20.2221	 transfer: 0.0491	 finalize: 0.4537
batch bounding time:  0.9908039569854736
Current worst splitting domains [lb, ub] (depth):
[-0.05391,   inf] (23), [-0.05389,   inf] (23), [-0.05388,   inf] (21), [-0.05388,   inf] (21), [-0.05386,   inf] (23), [-0.05380,   inf] (21), [-0.05379,   inf] (21), [-0.05378,   inf] (23), [-0.05378,   inf] (23), [-0.05377,   inf] (23), [-0.05377,   inf] (23), [-0.05376,   inf] (23), [-0.05376,   inf] (27), [-0.05370,   inf] (23), [-0.05367,   inf] (19), [-0.05365,   inf] (23), [-0.05363,   inf] (19), [-0.05363,   inf] (19), [-0.05362,   inf] (19), [-0.05362,   inf] (21), 
length of domains: 1312
Total time: 1.2886	 pickout: 0.1024	 decision: 0.1856	 get_bound: 0.9910	 add_domain: 0.0096
Current lb:-0.05390695482492447
2938 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 30.653157234191895

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [5, 218] [5, 218] [5, 218] [5, 320] [5, 218] [5, 218] [5, 320] [5, 320] [5, 320] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.2229838371276855 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.14636947214603424, 19.371688842773438]
alpha/beta optimization time: 0.8308584690093994
This batch time : update_bounds func: 0.9304	 prepare: 0.0336	 bound: 0.8314	 transfer: 0.0487	 finalize: 0.0162
Accumulated time: update_bounds func: 23.3140	 prepare: 0.6145	 bound: 21.0536	 transfer: 0.0487	 finalize: 0.4699
batch bounding time:  0.9308183193206787
Current worst splitting domains [lb, ub] (depth):
[-0.05282,   inf] (17), [-0.05278,   inf] (23), [-0.05278,   inf] (21), [-0.05275,   inf] (23), [-0.05273,   inf] (27), [-0.05271,   inf] (19), [-0.05270,   inf] (19), [-0.05265,   inf] (27), [-0.05264,   inf] (23), [-0.05263,   inf] (21), [-0.05260,   inf] (19), [-0.05260,   inf] (25), [-0.05259,   inf] (21), [-0.05258,   inf] (23), [-0.05256,   inf] (27), [-0.05255,   inf] (19), [-0.05252,   inf] (19), [-0.05250,   inf] (23), [-0.05250,   inf] (19), [-0.05249,   inf] (23), 
length of domains: 1368
Total time: 1.1349	 pickout: 0.0909	 decision: 0.1035	 get_bound: 0.9310	 add_domain: 0.0094
Current lb:-0.05281892418861389
3066 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 31.790955543518066

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 475] [5, 320] [5, 218] [5, 320] [5, 271] [5, 219] [5, 475] [5, 271] [5, 218] [5, 218] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.111790180206299 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.09635020792484283, 21.38749885559082]
alpha/beta optimization time: 0.7933592796325684
This batch time : update_bounds func: 0.8814	 prepare: 0.0218	 bound: 0.7938	 transfer: 0.0478	 finalize: 0.0174
Accumulated time: update_bounds func: 24.1954	 prepare: 0.6363	 bound: 21.8474	 transfer: 0.0478	 finalize: 0.4873
batch bounding time:  0.8818159103393555
Current worst splitting domains [lb, ub] (depth):
[-0.05157,   inf] (23), [-0.05157,   inf] (23), [-0.05156,   inf] (25), [-0.05154,   inf] (25), [-0.05154,   inf] (19), [-0.05154,   inf] (21), [-0.05153,   inf] (27), [-0.05151,   inf] (21), [-0.05146,   inf] (13), [-0.05144,   inf] (21), [-0.05140,   inf] (23), [-0.05136,   inf] (27), [-0.05136,   inf] (25), [-0.05134,   inf] (23), [-0.05131,   inf] (21), [-0.05131,   inf] (25), [-0.05126,   inf] (19), [-0.05125,   inf] (23), [-0.05122,   inf] (25), [-0.05121,   inf] (25), 
length of domains: 1424
Total time: 1.0510	 pickout: 0.0638	 decision: 0.0948	 get_bound: 0.8821	 add_domain: 0.0103
Current lb:-0.05156710743904114
3194 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 32.84480834007263

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [5, 320] [5, 460] [5, 460] [4, 302] [5, 460] [5, 271] [5, 460] [5, 475] [5, 320] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 4.1557464599609375 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.10968169569969177, 18.172183990478516]
alpha/beta optimization time: 0.7863190174102783
This batch time : update_bounds func: 0.8733	 prepare: 0.0220	 bound: 0.7868	 transfer: 0.0483	 finalize: 0.0158
Accumulated time: update_bounds func: 25.0686	 prepare: 0.6583	 bound: 22.6342	 transfer: 0.0483	 finalize: 0.5031
batch bounding time:  0.8736495971679688
Current worst splitting domains [lb, ub] (depth):
[-0.05056,   inf] (17), [-0.05054,   inf] (19), [-0.05054,   inf] (27), [-0.05051,   inf] (23), [-0.05047,   inf] (25), [-0.05045,   inf] (25), [-0.05043,   inf] (19), [-0.05043,   inf] (23), [-0.05043,   inf] (19), [-0.05040,   inf] (21), [-0.05039,   inf] (25), [-0.05037,   inf] (19), [-0.05034,   inf] (23), [-0.05032,   inf] (19), [-0.05029,   inf] (25), [-0.05027,   inf] (23), [-0.05022,   inf] (17), [-0.05021,   inf] (27), [-0.05018,   inf] (19), [-0.05016,   inf] (27), 
length of domains: 1483
Total time: 1.0354	 pickout: 0.0579	 decision: 0.0940	 get_bound: 0.8739	 add_domain: 0.0096
Current lb:-0.050555288791656494
3322 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 33.882347106933594

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 219] [5, 219] [5, 271] [5, 460] [5, 460] [5, 320] [5, 219] [5, 320] [5, 475] [5, 218] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 3.8001794815063477 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.5175645351409912, 21.826221466064453]
alpha/beta optimization time: 0.7889730930328369
This batch time : update_bounds func: 0.8762	 prepare: 0.0224	 bound: 0.7894	 transfer: 0.0482	 finalize: 0.0158
Accumulated time: update_bounds func: 25.9449	 prepare: 0.6807	 bound: 23.4236	 transfer: 0.0482	 finalize: 0.5189
batch bounding time:  0.8766095638275146
Current worst splitting domains [lb, ub] (depth):
[-0.04955,   inf] (27), [-0.04952,   inf] (21), [-0.04950,   inf] (23), [-0.04949,   inf] (25), [-0.04948,   inf] (21), [-0.04947,   inf] (27), [-0.04947,   inf] (17), [-0.04946,   inf] (21), [-0.04946,   inf] (21), [-0.04943,   inf] (19), [-0.04938,   inf] (19), [-0.04937,   inf] (23), [-0.04936,   inf] (19), [-0.04935,   inf] (23), [-0.04935,   inf] (27), [-0.04934,   inf] (19), [-0.04930,   inf] (25), [-0.04929,   inf] (21), [-0.04928,   inf] (25), [-0.04927,   inf] (23), 
length of domains: 1542
Total time: 1.0442	 pickout: 0.0638	 decision: 0.0939	 get_bound: 0.8768	 add_domain: 0.0096
Current lb:-0.049546074122190475
3450 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 34.928760051727295

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 271] [5, 460] [5, 218] [5, 460] [5, 218] [5, 271] [5, 475] [5, 218] [5, 218] [5, 219] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 3.941309690475464 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.2276405543088913, 20.88688850402832]
alpha/beta optimization time: 0.8035092353820801
This batch time : update_bounds func: 0.8905	 prepare: 0.0222	 bound: 0.8040	 transfer: 0.0483	 finalize: 0.0157
Accumulated time: update_bounds func: 26.8354	 prepare: 0.7029	 bound: 24.2276	 transfer: 0.0483	 finalize: 0.5345
batch bounding time:  0.8909051418304443
Current worst splitting domains [lb, ub] (depth):
[-0.04853,   inf] (23), [-0.04853,   inf] (19), [-0.04852,   inf] (21), [-0.04852,   inf] (19), [-0.04850,   inf] (19), [-0.04850,   inf] (23), [-0.04850,   inf] (23), [-0.04849,   inf] (21), [-0.04847,   inf] (23), [-0.04845,   inf] (23), [-0.04844,   inf] (23), [-0.04843,   inf] (23), [-0.04843,   inf] (25), [-0.04842,   inf] (19), [-0.04836,   inf] (21), [-0.04834,   inf] (25), [-0.04834,   inf] (21), [-0.04834,   inf] (25), [-0.04832,   inf] (25), [-0.04832,   inf] (17), 
length of domains: 1601
Total time: 1.0519	 pickout: 0.0578	 decision: 0.0933	 get_bound: 0.8911	 add_domain: 0.0096
Current lb:-0.04853113368153572
3578 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 35.98287630081177

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 460] [5, 219] [5, 320] [5, 219] [5, 475] [5, 320] [5, 320] [5, 218] [5, 218] [5, 320] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 3.7137815952301025 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.12678447365760803, 21.23363494873047]
alpha/beta optimization time: 0.7888858318328857
This batch time : update_bounds func: 0.8768	 prepare: 0.0221	 bound: 0.7894	 transfer: 0.0494	 finalize: 0.0155
Accumulated time: update_bounds func: 27.7122	 prepare: 0.7250	 bound: 25.0170	 transfer: 0.0494	 finalize: 0.5500
batch bounding time:  0.877190113067627
Current worst splitting domains [lb, ub] (depth):
[-0.04774,   inf] (25), [-0.04772,   inf] (21), [-0.04772,   inf] (21), [-0.04772,   inf] (21), [-0.04771,   inf] (23), [-0.04770,   inf] (21), [-0.04770,   inf] (23), [-0.04768,   inf] (21), [-0.04768,   inf] (25), [-0.04767,   inf] (23), [-0.04766,   inf] (23), [-0.04765,   inf] (27), [-0.04764,   inf] (27), [-0.04764,   inf] (23), [-0.04762,   inf] (27), [-0.04761,   inf] (21), [-0.04761,   inf] (25), [-0.04761,   inf] (21), [-0.04756,   inf] (13), [-0.04754,   inf] (19), 
length of domains: 1660
Total time: 1.0363	 pickout: 0.0546	 decision: 0.0948	 get_bound: 0.8774	 add_domain: 0.0095
Current lb:-0.04773689806461334
3706 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 37.0213897228241

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 460] [5, 320] [5, 460] [5, 460] [5, 460] [5, 460] [5, 218] [5, 218] [5, 218] [5, 460] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 3.5547382831573486 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.04434353858232498, 23.18539047241211]
alpha/beta optimization time: 0.8189020156860352
This batch time : update_bounds func: 0.9947	 prepare: 0.0220	 bound: 0.8193	 transfer: 0.0482	 finalize: 0.1048
Accumulated time: update_bounds func: 28.7069	 prepare: 0.7469	 bound: 25.8363	 transfer: 0.0482	 finalize: 0.6548
batch bounding time:  0.995136022567749
Current worst splitting domains [lb, ub] (depth):
[-0.04692,   inf] (21), [-0.04690,   inf] (19), [-0.04690,   inf] (23), [-0.04690,   inf] (21), [-0.04687,   inf] (27), [-0.04686,   inf] (19), [-0.04686,   inf] (23), [-0.04686,   inf] (25), [-0.04684,   inf] (19), [-0.04680,   inf] (25), [-0.04679,   inf] (27), [-0.04678,   inf] (23), [-0.04675,   inf] (23), [-0.04672,   inf] (27), [-0.04671,   inf] (25), [-0.04671,   inf] (21), [-0.04667,   inf] (27), [-0.04666,   inf] (25), [-0.04666,   inf] (21), [-0.04665,   inf] (19), 
length of domains: 1713
Total time: 1.1523	 pickout: 0.0542	 decision: 0.0935	 get_bound: 0.9954	 add_domain: 0.0091
Current lb:-0.04691699147224426
3834 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 38.17585754394531

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 460] [4, 53] [5, 320] [5, 460] [5, 271] [5, 219] [5, 320] [5, 460] [5, 460] [5, 460] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 3.444471836090088 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.7052270174026489, 22.93886947631836]
alpha/beta optimization time: 0.7935938835144043
This batch time : update_bounds func: 0.8809	 prepare: 0.0222	 bound: 0.7941	 transfer: 0.0482	 finalize: 0.0159
Accumulated time: update_bounds func: 29.5878	 prepare: 0.7691	 bound: 26.6304	 transfer: 0.0482	 finalize: 0.6708
batch bounding time:  0.881317138671875
Current worst splitting domains [lb, ub] (depth):
[-0.04598,   inf] (23), [-0.04598,   inf] (23), [-0.04596,   inf] (19), [-0.04594,   inf] (27), [-0.04594,   inf] (25), [-0.04591,   inf] (23), [-0.04591,   inf] (21), [-0.04590,   inf] (23), [-0.04589,   inf] (23), [-0.04589,   inf] (21), [-0.04588,   inf] (27), [-0.04584,   inf] (21), [-0.04584,   inf] (17), [-0.04582,   inf] (21), [-0.04581,   inf] (23), [-0.04579,   inf] (19), [-0.04579,   inf] (23), [-0.04577,   inf] (25), [-0.04576,   inf] (19), [-0.04575,   inf] (19), 
length of domains: 1770
Total time: 1.0837	 pickout: 0.0969	 decision: 0.0958	 get_bound: 0.8815	 add_domain: 0.0094
Current lb:-0.045978933572769165
3962 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 39.261887073516846

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 218] [5, 218] [5, 219] [5, 271] [5, 320] [5, 460] [5, 460] [5, 460] [5, 460] [5, 218] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 3.2912204265594482 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.1335158795118332, 24.145641326904297]
alpha/beta optimization time: 0.7878994941711426
This batch time : update_bounds func: 0.8713	 prepare: 0.0221	 bound: 0.7884	 transfer: 0.0444	 finalize: 0.0160
Accumulated time: update_bounds func: 30.4591	 prepare: 0.7912	 bound: 27.4188	 transfer: 0.0444	 finalize: 0.6868
batch bounding time:  0.8716981410980225
Current worst splitting domains [lb, ub] (depth):
[-0.04506,   inf] (19), [-0.04505,   inf] (21), [-0.04501,   inf] (25), [-0.04500,   inf] (21), [-0.04499,   inf] (23), [-0.04499,   inf] (19), [-0.04498,   inf] (25), [-0.04492,   inf] (21), [-0.04492,   inf] (27), [-0.04491,   inf] (25), [-0.04490,   inf] (21), [-0.04489,   inf] (27), [-0.04489,   inf] (23), [-0.04488,   inf] (23), [-0.04485,   inf] (27), [-0.04484,   inf] (21), [-0.04482,   inf] (21), [-0.04480,   inf] (21), [-0.04475,   inf] (21), [-0.04475,   inf] (19), 
length of domains: 1821
Total time: 1.0656	 pickout: 0.0913	 decision: 0.0934	 get_bound: 0.8719	 add_domain: 0.0091
Current lb:-0.04505874961614609
4090 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 40.32999634742737

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 219] [5, 320] [5, 271] [5, 460] [5, 460] [5, 219] [5, 320] [5, 218] [4, 53] [5, 460] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 3.0273866653442383 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.9458490610122681, 25.503942489624023]
alpha/beta optimization time: 0.7829101085662842
This batch time : update_bounds func: 0.8697	 prepare: 0.0220	 bound: 0.7833	 transfer: 0.0485	 finalize: 0.0154
Accumulated time: update_bounds func: 31.3289	 prepare: 0.8133	 bound: 28.2021	 transfer: 0.0485	 finalize: 0.7022
batch bounding time:  0.8701200485229492
Current worst splitting domains [lb, ub] (depth):
[-0.04397,   inf] (29), [-0.04394,   inf] (25), [-0.04392,   inf] (23), [-0.04392,   inf] (21), [-0.04389,   inf] (19), [-0.04385,   inf] (27), [-0.04382,   inf] (25), [-0.04380,   inf] (25), [-0.04378,   inf] (23), [-0.04378,   inf] (29), [-0.04376,   inf] (21), [-0.04375,   inf] (25), [-0.04375,   inf] (23), [-0.04373,   inf] (25), [-0.04373,   inf] (25), [-0.04373,   inf] (21), [-0.04372,   inf] (29), [-0.04372,   inf] (19), [-0.04371,   inf] (21), [-0.04368,   inf] (25), 
length of domains: 1868
Total time: 1.0309	 pickout: 0.0564	 decision: 0.0946	 get_bound: 0.8703	 add_domain: 0.0095
Current lb:-0.04397144168615341
4218 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 41.363561391830444

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 53] [5, 460] [5, 320] [5, 320] [5, 219] [5, 271] [5, 460] [5, 460] [4, 324] [4, 31] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 2.7683544158935547 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.4774588346481323, 24.005970001220703]
alpha/beta optimization time: 0.7864267826080322
This batch time : update_bounds func: 0.8696	 prepare: 0.0221	 bound: 0.7869	 transfer: 0.0442	 finalize: 0.0161
Accumulated time: update_bounds func: 32.1985	 prepare: 0.8354	 bound: 28.9890	 transfer: 0.0442	 finalize: 0.7183
batch bounding time:  0.8701279163360596
Current worst splitting domains [lb, ub] (depth):
[-0.04305,   inf] (19), [-0.04303,   inf] (19), [-0.04303,   inf] (21), [-0.04302,   inf] (23), [-0.04301,   inf] (25), [-0.04294,   inf] (19), [-0.04293,   inf] (27), [-0.04292,   inf] (25), [-0.04291,   inf] (29), [-0.04290,   inf] (19), [-0.04288,   inf] (23), [-0.04287,   inf] (21), [-0.04287,   inf] (23), [-0.04282,   inf] (23), [-0.04281,   inf] (27), [-0.04281,   inf] (23), [-0.04281,   inf] (27), [-0.04279,   inf] (25), [-0.04278,   inf] (15), [-0.04277,   inf] (23), 
length of domains: 1908
Total time: 1.0531	 pickout: 0.0808	 decision: 0.0935	 get_bound: 0.8703	 add_domain: 0.0084
Current lb:-0.04304775595664978
4346 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 42.41917395591736

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 475] [5, 219] [5, 460] [5, 218] [5, 320] [5, 219] [5, 271] [5, 460] [5, 424] [4, 302] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 2.7545459270477295 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.3541111648082733, 24.63408851623535]
alpha/beta optimization time: 0.7948050498962402
This batch time : update_bounds func: 0.8885	 prepare: 0.0224	 bound: 0.7953	 transfer: 0.0535	 finalize: 0.0169
Accumulated time: update_bounds func: 33.0870	 prepare: 0.8578	 bound: 29.7843	 transfer: 0.0535	 finalize: 0.7352
batch bounding time:  0.8889527320861816
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (27), [-0.04220,   inf] (21), [-0.04219,   inf] (21), [-0.04218,   inf] (25), [-0.04218,   inf] (27), [-0.04217,   inf] (23), [-0.04216,   inf] (23), [-0.04213,   inf] (25), [-0.04212,   inf] (27), [-0.04211,   inf] (25), [-0.04210,   inf] (27), [-0.04210,   inf] (21), [-0.04210,   inf] (27), [-0.04206,   inf] (29), [-0.04202,   inf] (19), [-0.04202,   inf] (25), [-0.04201,   inf] (29), [-0.04201,   inf] (23), [-0.04200,   inf] (23), [-0.04199,   inf] (21), 
length of domains: 1955
Total time: 1.0582	 pickout: 0.0628	 decision: 0.0955	 get_bound: 0.8892	 add_domain: 0.0107
Current lb:-0.0422024130821228
4474 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 43.48063278198242

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [5, 218] [5, 320] [4, 109] [5, 271] [5, 460] [4, 302] [5, 320] [5, 271] [5, 460] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 2.5339088439941406 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.19956722855567932, 21.425777435302734]
alpha/beta optimization time: 0.801382303237915
This batch time : update_bounds func: 0.8874	 prepare: 0.0224	 bound: 0.8018	 transfer: 0.0467	 finalize: 0.0159
Accumulated time: update_bounds func: 33.9744	 prepare: 0.8802	 bound: 30.5861	 transfer: 0.0467	 finalize: 0.7511
batch bounding time:  0.8877766132354736
Current worst splitting domains [lb, ub] (depth):
[-0.04142,   inf] (23), [-0.04141,   inf] (29), [-0.04140,   inf] (23), [-0.04139,   inf] (29), [-0.04139,   inf] (23), [-0.04136,   inf] (27), [-0.04135,   inf] (23), [-0.04133,   inf] (19), [-0.04133,   inf] (29), [-0.04132,   inf] (19), [-0.04131,   inf] (25), [-0.04130,   inf] (29), [-0.04129,   inf] (23), [-0.04128,   inf] (29), [-0.04128,   inf] (21), [-0.04127,   inf] (25), [-0.04127,   inf] (27), [-0.04127,   inf] (23), [-0.04125,   inf] (23), [-0.04125,   inf] (19), 
length of domains: 1997
Total time: 1.0446	 pickout: 0.0538	 decision: 0.0941	 get_bound: 0.8880	 add_domain: 0.0086
Current lb:-0.04141976684331894
4602 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 44.527587890625

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 218] [5, 424] [5, 320] [4, 53] [4, 324] [5, 424] [5, 460] [5, 219] [4, 31] [5, 219] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 2.4302964210510254 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.6830917000770569, 22.068824768066406]
alpha/beta optimization time: 0.7884230613708496
This batch time : update_bounds func: 0.8777	 prepare: 0.0224	 bound: 0.7889	 transfer: 0.0499	 finalize: 0.0154
Accumulated time: update_bounds func: 34.8521	 prepare: 0.9026	 bound: 31.3750	 transfer: 0.0499	 finalize: 0.7665
batch bounding time:  0.8781466484069824
Current worst splitting domains [lb, ub] (depth):
[-0.04087,   inf] (23), [-0.04087,   inf] (25), [-0.04085,   inf] (27), [-0.04085,   inf] (21), [-0.04084,   inf] (21), [-0.04084,   inf] (25), [-0.04084,   inf] (29), [-0.04083,   inf] (19), [-0.04083,   inf] (25), [-0.04083,   inf] (25), [-0.04083,   inf] (23), [-0.04082,   inf] (19), [-0.04081,   inf] (21), [-0.04080,   inf] (29), [-0.04079,   inf] (25), [-0.04078,   inf] (25), [-0.04077,   inf] (23), [-0.04076,   inf] (25), [-0.04075,   inf] (21), [-0.04075,   inf] (13), 
length of domains: 2032
Total time: 1.0330	 pickout: 0.0536	 decision: 0.0929	 get_bound: 0.8784	 add_domain: 0.0082
Current lb:-0.04087141901254654
4730 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 45.563493728637695

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 218] [5, 460] [5, 271] [5, 460] [5, 460] [5, 271] [4, 31] [5, 219] [5, 460] [5, 460] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 2.2804908752441406 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.8732408285140991, 28.073184967041016]
alpha/beta optimization time: 0.7882356643676758
This batch time : update_bounds func: 0.8759	 prepare: 0.0226	 bound: 0.7887	 transfer: 0.0481	 finalize: 0.0160
Accumulated time: update_bounds func: 35.7280	 prepare: 0.9253	 bound: 32.1637	 transfer: 0.0481	 finalize: 0.7825
batch bounding time:  0.8762094974517822
Current worst splitting domains [lb, ub] (depth):
[-0.04027,   inf] (19), [-0.04024,   inf] (25), [-0.04024,   inf] (19), [-0.04023,   inf] (25), [-0.04023,   inf] (23), [-0.04021,   inf] (29), [-0.04018,   inf] (23), [-0.04018,   inf] (27), [-0.04018,   inf] (21), [-0.04015,   inf] (27), [-0.04015,   inf] (25), [-0.04013,   inf] (27), [-0.04013,   inf] (27), [-0.04012,   inf] (23), [-0.04012,   inf] (27), [-0.04009,   inf] (23), [-0.04008,   inf] (25), [-0.04007,   inf] (29), [-0.04007,   inf] (25), [-0.04005,   inf] (27), 
length of domains: 2069
Total time: 1.1369	 pickout: 0.0488	 decision: 0.2035	 get_bound: 0.8764	 add_domain: 0.0081
Current lb:-0.04026557505130768
4858 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 46.70279121398926

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 219] [5, 460] [5, 219] [5, 271] [5, 320] [4, 53] [4, 324] [5, 271] [5, 218] [5, 271] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 2.424406051635742 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.2348593771457672, 22.857868194580078]
alpha/beta optimization time: 0.8060405254364014
This batch time : update_bounds func: 0.8942	 prepare: 0.0224	 bound: 0.8065	 transfer: 0.0485	 finalize: 0.0163
Accumulated time: update_bounds func: 36.6221	 prepare: 0.9477	 bound: 32.9702	 transfer: 0.0485	 finalize: 0.7988
batch bounding time:  0.894582986831665
Current worst splitting domains [lb, ub] (depth):
[-0.03964,   inf] (21), [-0.03964,   inf] (19), [-0.03963,   inf] (25), [-0.03963,   inf] (27), [-0.03961,   inf] (25), [-0.03961,   inf] (21), [-0.03959,   inf] (21), [-0.03959,   inf] (23), [-0.03957,   inf] (25), [-0.03955,   inf] (23), [-0.03954,   inf] (27), [-0.03952,   inf] (23), [-0.03952,   inf] (25), [-0.03951,   inf] (21), [-0.03950,   inf] (21), [-0.03950,   inf] (23), [-0.03947,   inf] (25), [-0.03945,   inf] (21), [-0.03944,   inf] (23), [-0.03943,   inf] (19), 
length of domains: 2109
Total time: 1.0506	 pickout: 0.0529	 decision: 0.0944	 get_bound: 0.8948	 add_domain: 0.0085
Current lb:-0.039637092500925064
4986 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 47.75611448287964

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 460] [4, 53] [5, 320] [5, 271] [5, 460] [5, 218] [5, 218] [5, 460] [5, 460] [5, 460] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 2.2460174560546875 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.8414484858512878, 27.205589294433594]
alpha/beta optimization time: 0.782280445098877
This batch time : update_bounds func: 0.8692	 prepare: 0.0223	 bound: 0.7828	 transfer: 0.0482	 finalize: 0.0155
Accumulated time: update_bounds func: 37.4913	 prepare: 0.9700	 bound: 33.7530	 transfer: 0.0482	 finalize: 0.8143
batch bounding time:  0.8695662021636963
Current worst splitting domains [lb, ub] (depth):
[-0.03894,   inf] (27), [-0.03893,   inf] (27), [-0.03892,   inf] (27), [-0.03890,   inf] (25), [-0.03890,   inf] (29), [-0.03890,   inf] (19), [-0.03889,   inf] (21), [-0.03888,   inf] (23), [-0.03888,   inf] (21), [-0.03886,   inf] (29), [-0.03886,   inf] (29), [-0.03885,   inf] (25), [-0.03885,   inf] (21), [-0.03884,   inf] (25), [-0.03883,   inf] (25), [-0.03883,   inf] (27), [-0.03882,   inf] (25), [-0.03882,   inf] (25), [-0.03882,   inf] (23), [-0.03881,   inf] (23), 
length of domains: 2150
Total time: 1.0303	 pickout: 0.0558	 decision: 0.0954	 get_bound: 0.8698	 add_domain: 0.0094
Current lb:-0.03893822431564331
5114 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 48.78900146484375

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 460] [5, 271] [4, 109] [5, 460] [5, 424] [5, 219] [5, 460] [5, 218] [4, 31] [5, 424] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 2.0772082805633545 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.7810533046722412, 27.192455291748047]
alpha/beta optimization time: 0.7873587608337402
This batch time : update_bounds func: 0.8747	 prepare: 0.0223	 bound: 0.7878	 transfer: 0.0481	 finalize: 0.0161
Accumulated time: update_bounds func: 38.3660	 prepare: 0.9922	 bound: 34.5408	 transfer: 0.0481	 finalize: 0.8305
batch bounding time:  0.8751335144042969
Current worst splitting domains [lb, ub] (depth):
[-0.03843,   inf] (13), [-0.03841,   inf] (29), [-0.03841,   inf] (27), [-0.03840,   inf] (25), [-0.03839,   inf] (25), [-0.03839,   inf] (27), [-0.03839,   inf] (25), [-0.03834,   inf] (25), [-0.03834,   inf] (23), [-0.03834,   inf] (27), [-0.03834,   inf] (25), [-0.03829,   inf] (23), [-0.03828,   inf] (27), [-0.03828,   inf] (27), [-0.03827,   inf] (23), [-0.03827,   inf] (27), [-0.03827,   inf] (23), [-0.03826,   inf] (23), [-0.03824,   inf] (21), [-0.03824,   inf] (23), 
length of domains: 2186
Total time: 1.0310	 pickout: 0.0539	 decision: 0.0934	 get_bound: 0.8754	 add_domain: 0.0083
Current lb:-0.03842756897211075
5242 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 49.822845458984375

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 150] [5, 424] [4, 109] [5, 460] [5, 271] [4, 109] [5, 320] [5, 460] [5, 320] [5, 271] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 2.0852537155151367 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.6644176840782166, 26.421344757080078]
alpha/beta optimization time: 0.7839617729187012
This batch time : update_bounds func: 0.8715	 prepare: 0.0221	 bound: 0.7844	 transfer: 0.0484	 finalize: 0.0154
Accumulated time: update_bounds func: 39.2375	 prepare: 1.0143	 bound: 35.3252	 transfer: 0.0484	 finalize: 0.8458
batch bounding time:  0.8718724250793457
Current worst splitting domains [lb, ub] (depth):
[-0.03783,   inf] (29), [-0.03783,   inf] (19), [-0.03781,   inf] (21), [-0.03781,   inf] (29), [-0.03781,   inf] (21), [-0.03779,   inf] (19), [-0.03777,   inf] (29), [-0.03777,   inf] (21), [-0.03776,   inf] (29), [-0.03774,   inf] (23), [-0.03772,   inf] (23), [-0.03772,   inf] (21), [-0.03769,   inf] (23), [-0.03768,   inf] (25), [-0.03767,   inf] (25), [-0.03767,   inf] (25), [-0.03766,   inf] (23), [-0.03765,   inf] (29), [-0.03765,   inf] (23), [-0.03763,   inf] (21), 
length of domains: 2222
Total time: 1.0315	 pickout: 0.0573	 decision: 0.0938	 get_bound: 0.8721	 add_domain: 0.0083
Current lb:-0.03783223778009415
5370 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 50.85721778869629

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 53] [5, 219] [5, 218] [4, 31] [5, 460] [5, 219] [5, 424] [5, 460] [5, 424] [5, 320] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 2.15981125831604 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.7627037763595581, 27.6326904296875]
alpha/beta optimization time: 0.7834420204162598
This batch time : update_bounds func: 0.8713	 prepare: 0.0221	 bound: 0.7839	 transfer: 0.0486	 finalize: 0.0162
Accumulated time: update_bounds func: 40.1088	 prepare: 1.0364	 bound: 36.1091	 transfer: 0.0486	 finalize: 0.8620
batch bounding time:  0.8717005252838135
Current worst splitting domains [lb, ub] (depth):
[-0.03728,   inf] (25), [-0.03726,   inf] (21), [-0.03726,   inf] (25), [-0.03725,   inf] (27), [-0.03725,   inf] (27), [-0.03724,   inf] (27), [-0.03722,   inf] (27), [-0.03721,   inf] (23), [-0.03721,   inf] (29), [-0.03721,   inf] (25), [-0.03720,   inf] (27), [-0.03720,   inf] (27), [-0.03720,   inf] (27), [-0.03718,   inf] (23), [-0.03717,   inf] (21), [-0.03715,   inf] (21), [-0.03715,   inf] (27), [-0.03713,   inf] (23), [-0.03711,   inf] (21), [-0.03710,   inf] (23), 
length of domains: 2268
Total time: 1.0632	 pickout: 0.0876	 decision: 0.0947	 get_bound: 0.8719	 add_domain: 0.0090
Current lb:-0.03728140890598297
5498 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 51.922964096069336

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 460] [5, 460] [5, 320] [4, 390] [5, 460] [5, 424] [5, 424] [5, 460] [5, 424] [5, 320] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 1.8990638256072998 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.42325687408447266, 28.716514587402344]
alpha/beta optimization time: 0.8005421161651611
This batch time : update_bounds func: 0.8884	 prepare: 0.0224	 bound: 0.8010	 transfer: 0.0485	 finalize: 0.0161
Accumulated time: update_bounds func: 40.9972	 prepare: 1.0588	 bound: 36.9101	 transfer: 0.0485	 finalize: 0.8781
batch bounding time:  0.888803243637085
Current worst splitting domains [lb, ub] (depth):
[-0.03677,   inf] (27), [-0.03677,   inf] (25), [-0.03674,   inf] (27), [-0.03673,   inf] (21), [-0.03673,   inf] (21), [-0.03673,   inf] (19), [-0.03672,   inf] (23), [-0.03671,   inf] (23), [-0.03671,   inf] (31), [-0.03670,   inf] (23), [-0.03669,   inf] (27), [-0.03668,   inf] (25), [-0.03667,   inf] (27), [-0.03667,   inf] (25), [-0.03666,   inf] (23), [-0.03665,   inf] (31), [-0.03662,   inf] (29), [-0.03661,   inf] (21), [-0.03661,   inf] (25), [-0.03661,   inf] (25), 
length of domains: 2300
Total time: 1.0663	 pickout: 0.0758	 decision: 0.0936	 get_bound: 0.8890	 add_domain: 0.0079
Current lb:-0.0367686003446579
5626 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 52.99202275276184

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 460] [5, 271] [5, 271] [5, 460] [5, 320] [5, 219] [5, 218] [5, 460] [4, 31] [5, 218] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 1.8565113544464111 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.8181465268135071, 25.668306350708008]
alpha/beta optimization time: 0.8103961944580078
This batch time : update_bounds func: 0.8982	 prepare: 0.0226	 bound: 0.8109	 transfer: 0.0488	 finalize: 0.0156
Accumulated time: update_bounds func: 41.8954	 prepare: 1.0814	 bound: 37.7210	 transfer: 0.0488	 finalize: 0.8937
batch bounding time:  0.8986151218414307
Current worst splitting domains [lb, ub] (depth):
[-0.03636,   inf] (23), [-0.03635,   inf] (25), [-0.03634,   inf] (25), [-0.03634,   inf] (31), [-0.03634,   inf] (25), [-0.03633,   inf] (23), [-0.03631,   inf] (23), [-0.03631,   inf] (25), [-0.03630,   inf] (23), [-0.03629,   inf] (21), [-0.03629,   inf] (29), [-0.03628,   inf] (27), [-0.03628,   inf] (29), [-0.03628,   inf] (29), [-0.03625,   inf] (21), [-0.03624,   inf] (27), [-0.03622,   inf] (31), [-0.03619,   inf] (21), [-0.03618,   inf] (25), [-0.03618,   inf] (27), 
length of domains: 2336
Total time: 1.1607	 pickout: 0.0523	 decision: 0.0943	 get_bound: 0.8988	 add_domain: 0.1152
Current lb:-0.036358729004859924
5754 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 54.15554618835449

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 460] [5, 460] [5, 271] [5, 424] [5, 460] [5, 320] [5, 460] [5, 460] [5, 218] [5, 218] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 2.059748888015747 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.6522864103317261, 26.024490356445312]
alpha/beta optimization time: 0.7912018299102783
This batch time : update_bounds func: 0.8803	 prepare: 0.0225	 bound: 0.7917	 transfer: 0.0488	 finalize: 0.0169
Accumulated time: update_bounds func: 42.7757	 prepare: 1.1039	 bound: 38.5126	 transfer: 0.0488	 finalize: 0.9106
batch bounding time:  0.8807406425476074
Current worst splitting domains [lb, ub] (depth):
[-0.03574,   inf] (21), [-0.03572,   inf] (23), [-0.03572,   inf] (25), [-0.03571,   inf] (23), [-0.03570,   inf] (25), [-0.03570,   inf] (21), [-0.03568,   inf] (23), [-0.03567,   inf] (25), [-0.03566,   inf] (25), [-0.03566,   inf] (21), [-0.03565,   inf] (29), [-0.03565,   inf] (25), [-0.03565,   inf] (27), [-0.03564,   inf] (23), [-0.03560,   inf] (23), [-0.03560,   inf] (25), [-0.03560,   inf] (23), [-0.03559,   inf] (27), [-0.03558,   inf] (21), [-0.03557,   inf] (29), 
length of domains: 2376
Total time: 1.0373	 pickout: 0.0544	 decision: 0.0934	 get_bound: 0.8810	 add_domain: 0.0086
Current lb:-0.035736411809921265
5882 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 55.19537830352783

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 218] [5, 320] [5, 320] [4, 53] [5, 460] [5, 460] [5, 218] [5, 320] [5, 320] [5, 218] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 1.800504207611084 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.6959421634674072, 26.996614456176758]
alpha/beta optimization time: 0.7930338382720947
This batch time : update_bounds func: 0.8811	 prepare: 0.0221	 bound: 0.7935	 transfer: 0.0486	 finalize: 0.0155
Accumulated time: update_bounds func: 43.6569	 prepare: 1.1260	 bound: 39.3061	 transfer: 0.0486	 finalize: 0.9261
batch bounding time:  0.8815393447875977
Current worst splitting domains [lb, ub] (depth):
[-0.03520,   inf] (29), [-0.03518,   inf] (27), [-0.03517,   inf] (25), [-0.03516,   inf] (27), [-0.03516,   inf] (19), [-0.03515,   inf] (25), [-0.03513,   inf] (27), [-0.03510,   inf] (29), [-0.03508,   inf] (23), [-0.03508,   inf] (23), [-0.03507,   inf] (25), [-0.03507,   inf] (25), [-0.03506,   inf] (23), [-0.03505,   inf] (29), [-0.03504,   inf] (25), [-0.03503,   inf] (25), [-0.03503,   inf] (21), [-0.03502,   inf] (21), [-0.03502,   inf] (27), [-0.03502,   inf] (25), 
length of domains: 2414
Total time: 1.0303	 pickout: 0.0470	 decision: 0.0929	 get_bound: 0.8818	 add_domain: 0.0087
Current lb:-0.035196755081415176
6010 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 56.228541135787964

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 424] [4, 109] [5, 320] [4, 53] [4, 302] [5, 460] [5, 460] [5, 424] [5, 320] [5, 218] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 1.4944908618927002 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.8354963064193726, 26.95513916015625]
alpha/beta optimization time: 0.7815706729888916
This batch time : update_bounds func: 0.8674	 prepare: 0.0223	 bound: 0.7820	 transfer: 0.0466	 finalize: 0.0161
Accumulated time: update_bounds func: 44.5243	 prepare: 1.1483	 bound: 40.0882	 transfer: 0.0466	 finalize: 0.9422
batch bounding time:  0.8678147792816162
Current worst splitting domains [lb, ub] (depth):
[-0.03453,   inf] (27), [-0.03453,   inf] (27), [-0.03453,   inf] (23), [-0.03452,   inf] (25), [-0.03452,   inf] (27), [-0.03451,   inf] (31), [-0.03451,   inf] (25), [-0.03451,   inf] (27), [-0.03450,   inf] (21), [-0.03450,   inf] (29), [-0.03448,   inf] (23), [-0.03448,   inf] (23), [-0.03447,   inf] (31), [-0.03447,   inf] (19), [-0.03446,   inf] (27), [-0.03444,   inf] (27), [-0.03444,   inf] (23), [-0.03441,   inf] (25), [-0.03440,   inf] (23), [-0.03438,   inf] (27), 
length of domains: 2447
Total time: 1.0217	 pickout: 0.0493	 decision: 0.0960	 get_bound: 0.8680	 add_domain: 0.0084
Current lb:-0.034534256905317307
6138 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 57.25297737121582

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 271] [5, 271] [5, 218] [5, 320] [5, 271] [4, 31] [4, 109] [5, 424] [5, 460] [5, 271] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 1.4640108346939087 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.2713563442230225, 28.748416900634766]
alpha/beta optimization time: 0.7796831130981445
This batch time : update_bounds func: 0.8470	 prepare: 0.0224	 bound: 0.7802	 transfer: 0.0280	 finalize: 0.0160
Accumulated time: update_bounds func: 45.3713	 prepare: 1.1707	 bound: 40.8683	 transfer: 0.0280	 finalize: 0.9582
batch bounding time:  0.8474011421203613
Current worst splitting domains [lb, ub] (depth):
[-0.03395,   inf] (25), [-0.03395,   inf] (27), [-0.03394,   inf] (27), [-0.03394,   inf] (27), [-0.03394,   inf] (29), [-0.03393,   inf] (21), [-0.03393,   inf] (31), [-0.03392,   inf] (23), [-0.03392,   inf] (25), [-0.03391,   inf] (23), [-0.03391,   inf] (21), [-0.03391,   inf] (25), [-0.03389,   inf] (27), [-0.03389,   inf] (21), [-0.03389,   inf] (23), [-0.03388,   inf] (25), [-0.03388,   inf] (29), [-0.03388,   inf] (31), [-0.03388,   inf] (23), [-0.03387,   inf] (27), 
length of domains: 2477
Total time: 1.0062	 pickout: 0.0572	 decision: 0.0934	 get_bound: 0.8476	 add_domain: 0.0080
Current lb:-0.03395337983965874
6266 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 58.26179504394531

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 271] [4, 390] [5, 424] [5, 271] [4, 53] [5, 460] [4, 31] [5, 460] [5, 460] [5, 320] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 1.3110792636871338 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.6292376518249512, 26.520957946777344]
alpha/beta optimization time: 0.8168823719024658
This batch time : update_bounds func: 0.9151	 prepare: 0.0227	 bound: 0.8174	 transfer: 0.0519	 finalize: 0.0228
Accumulated time: update_bounds func: 46.2865	 prepare: 1.1934	 bound: 41.6857	 transfer: 0.0519	 finalize: 0.9810
batch bounding time:  0.9156539440155029
Current worst splitting domains [lb, ub] (depth):
[-0.03344,   inf] (21), [-0.03342,   inf] (25), [-0.03341,   inf] (19), [-0.03341,   inf] (17), [-0.03341,   inf] (31), [-0.03339,   inf] (27), [-0.03339,   inf] (31), [-0.03338,   inf] (23), [-0.03338,   inf] (29), [-0.03336,   inf] (29), [-0.03335,   inf] (27), [-0.03335,   inf] (29), [-0.03332,   inf] (31), [-0.03331,   inf] (27), [-0.03330,   inf] (29), [-0.03328,   inf] (31), [-0.03327,   inf] (25), [-0.03327,   inf] (25), [-0.03325,   inf] (27), [-0.03322,   inf] (23), 
length of domains: 2501
Total time: 1.0725	 pickout: 0.0493	 decision: 0.0957	 get_bound: 0.9159	 add_domain: 0.0116
Current lb:-0.03343525156378746
6394 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 59.33779168128967

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [5, 460] [5, 218] [4, 302] [5, 424] [5, 271] [4, 390] [5, 218] [5, 424] [5, 424] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 1.3147263526916504 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.4264227151870728, 26.877479553222656]
alpha/beta optimization time: 0.8535561561584473
This batch time : update_bounds func: 0.9669	 prepare: 0.0341	 bound: 0.8542	 transfer: 0.0556	 finalize: 0.0224
Accumulated time: update_bounds func: 47.2533	 prepare: 1.2275	 bound: 42.5399	 transfer: 0.0556	 finalize: 1.0034
batch bounding time:  0.9672651290893555
Current worst splitting domains [lb, ub] (depth):
[-0.03281,   inf] (21), [-0.03281,   inf] (29), [-0.03280,   inf] (31), [-0.03280,   inf] (27), [-0.03279,   inf] (13), [-0.03278,   inf] (27), [-0.03277,   inf] (25), [-0.03275,   inf] (31), [-0.03275,   inf] (27), [-0.03275,   inf] (23), [-0.03274,   inf] (29), [-0.03274,   inf] (23), [-0.03273,   inf] (15), [-0.03272,   inf] (27), [-0.03272,   inf] (27), [-0.03271,   inf] (21), [-0.03271,   inf] (29), [-0.03270,   inf] (29), [-0.03270,   inf] (29), [-0.03270,   inf] (23), 
length of domains: 2531
Total time: 1.1404	 pickout: 0.0592	 decision: 0.1056	 get_bound: 0.9675	 add_domain: 0.0082
Current lb:-0.03280766308307648
6522 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 60.48136568069458

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 218] [4, 31] [4, 53] [5, 271] [5, 475] [5, 271] [5, 320] [4, 390] [5, 271] [5, 460] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 1.4966912269592285 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.6343177556991577, 29.654279708862305]
alpha/beta optimization time: 0.8001151084899902
This batch time : update_bounds func: 0.8965	 prepare: 0.0225	 bound: 0.8006	 transfer: 0.0496	 finalize: 0.0232
Accumulated time: update_bounds func: 48.1498	 prepare: 1.2500	 bound: 43.3405	 transfer: 0.0496	 finalize: 1.0266
batch bounding time:  0.8972418308258057
Current worst splitting domains [lb, ub] (depth):
[-0.03227,   inf] (17), [-0.03226,   inf] (31), [-0.03225,   inf] (19), [-0.03225,   inf] (29), [-0.03224,   inf] (27), [-0.03224,   inf] (21), [-0.03223,   inf] (25), [-0.03220,   inf] (31), [-0.03220,   inf] (27), [-0.03219,   inf] (23), [-0.03218,   inf] (25), [-0.03218,   inf] (27), [-0.03216,   inf] (23), [-0.03216,   inf] (27), [-0.03215,   inf] (27), [-0.03212,   inf] (25), [-0.03212,   inf] (25), [-0.03211,   inf] (19), [-0.03209,   inf] (29), [-0.03209,   inf] (25), 
length of domains: 2564
Total time: 1.0649	 pickout: 0.0618	 decision: 0.0960	 get_bound: 0.8978	 add_domain: 0.0093
Current lb:-0.03227279335260391
6650 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 61.54911136627197

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 219] [4, 390] [4, 302] [5, 271] [5, 424] [5, 218] [4, 109] [4, 390] [5, 271] [4, 53] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 1.5665919780731201 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 2.2231831550598145, 26.360107421875]
alpha/beta optimization time: 0.7977595329284668
This batch time : update_bounds func: 0.8997	 prepare: 0.0360	 bound: 0.7986	 transfer: 0.0485	 finalize: 0.0161
Accumulated time: update_bounds func: 49.0495	 prepare: 1.2861	 bound: 44.1391	 transfer: 0.0485	 finalize: 1.0427
batch bounding time:  0.9001104831695557
Current worst splitting domains [lb, ub] (depth):
[-0.03170,   inf] (29), [-0.03169,   inf] (25), [-0.03169,   inf] (25), [-0.03167,   inf] (27), [-0.03167,   inf] (21), [-0.03167,   inf] (29), [-0.03166,   inf] (29), [-0.03166,   inf] (19), [-0.03165,   inf] (23), [-0.03165,   inf] (23), [-0.03164,   inf] (25), [-0.03163,   inf] (25), [-0.03162,   inf] (27), [-0.03161,   inf] (25), [-0.03159,   inf] (25), [-0.03158,   inf] (25), [-0.03156,   inf] (31), [-0.03154,   inf] (21), [-0.03153,   inf] (31), [-0.03153,   inf] (23), 
length of domains: 2603
Total time: 1.0747	 pickout: 0.0585	 decision: 0.1057	 get_bound: 0.9004	 add_domain: 0.0101
Current lb:-0.031702592968940735
6778 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 62.62660789489746

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 390] [5, 271] [5, 460] [4, 53] [5, 460] [5, 424] [5, 424] [5, 219] [4, 53] [5, 218] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 1.3985694646835327 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.1823663711547852, 25.5765380859375]
alpha/beta optimization time: 0.8175041675567627
This batch time : update_bounds func: 1.0336	 prepare: 0.0224	 bound: 0.8180	 transfer: 0.0496	 finalize: 0.1430
Accumulated time: update_bounds func: 50.0830	 prepare: 1.3085	 bound: 44.9572	 transfer: 0.0496	 finalize: 1.1857
batch bounding time:  1.0340161323547363
Current worst splitting domains [lb, ub] (depth):
[-0.03128,   inf] (27), [-0.03126,   inf] (29), [-0.03126,   inf] (29), [-0.03125,   inf] (29), [-0.03124,   inf] (27), [-0.03124,   inf] (21), [-0.03124,   inf] (25), [-0.03122,   inf] (27), [-0.03122,   inf] (21), [-0.03122,   inf] (27), [-0.03121,   inf] (25), [-0.03121,   inf] (31), [-0.03121,   inf] (23), [-0.03121,   inf] (25), [-0.03120,   inf] (23), [-0.03120,   inf] (23), [-0.03119,   inf] (27), [-0.03118,   inf] (25), [-0.03118,   inf] (23), [-0.03117,   inf] (27), 
length of domains: 2639
Total time: 1.2085	 pickout: 0.0719	 decision: 0.0940	 get_bound: 1.0343	 add_domain: 0.0084
Current lb:-0.03127517178654671
6906 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 63.83785271644592

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 109] [4, 390] [5, 271] [5, 424] [5, 424] [5, 460] [5, 460] [5, 271] [5, 218] [4, 109] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 1.3291699886322021 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.9625104069709778, 26.892911911010742]
alpha/beta optimization time: 0.8036885261535645
This batch time : update_bounds func: 0.8910	 prepare: 0.0223	 bound: 0.8043	 transfer: 0.0485	 finalize: 0.0155
Accumulated time: update_bounds func: 50.9740	 prepare: 1.3307	 bound: 45.7614	 transfer: 0.0485	 finalize: 1.2012
batch bounding time:  0.8914380073547363
Current worst splitting domains [lb, ub] (depth):
[-0.03092,   inf] (25), [-0.03091,   inf] (19), [-0.03090,   inf] (31), [-0.03090,   inf] (25), [-0.03089,   inf] (27), [-0.03088,   inf] (21), [-0.03088,   inf] (31), [-0.03088,   inf] (31), [-0.03088,   inf] (21), [-0.03087,   inf] (25), [-0.03087,   inf] (27), [-0.03086,   inf] (31), [-0.03086,   inf] (27), [-0.03085,   inf] (25), [-0.03084,   inf] (31), [-0.03084,   inf] (29), [-0.03083,   inf] (25), [-0.03079,   inf] (29), [-0.03079,   inf] (29), [-0.03077,   inf] (23), 
length of domains: 2675
Total time: 1.0681	 pickout: 0.0618	 decision: 0.1052	 get_bound: 0.8917	 add_domain: 0.0095
Current lb:-0.030917171388864517
7034 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 64.90867447853088

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [5, 219] [4, 31] [5, 460] [5, 271] [5, 460] [5, 424] [5, 419] [5, 218] [5, 218] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 1.141892671585083 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.2119026184082031, 27.052852630615234]
alpha/beta optimization time: 0.7964186668395996
This batch time : update_bounds func: 0.8845	 prepare: 0.0225	 bound: 0.7969	 transfer: 0.0481	 finalize: 0.0166
Accumulated time: update_bounds func: 51.8585	 prepare: 1.3532	 bound: 46.5583	 transfer: 0.0481	 finalize: 1.2178
batch bounding time:  0.8848941326141357
Current worst splitting domains [lb, ub] (depth):
[-0.03041,   inf] (29), [-0.03041,   inf] (27), [-0.03039,   inf] (21), [-0.03039,   inf] (29), [-0.03038,   inf] (27), [-0.03038,   inf] (27), [-0.03037,   inf] (23), [-0.03036,   inf] (23), [-0.03035,   inf] (29), [-0.03032,   inf] (27), [-0.03031,   inf] (31), [-0.03031,   inf] (31), [-0.03031,   inf] (25), [-0.03030,   inf] (27), [-0.03030,   inf] (25), [-0.03030,   inf] (25), [-0.03029,   inf] (25), [-0.03027,   inf] (17), [-0.03027,   inf] (25), [-0.03026,   inf] (29), 
length of domains: 2702
Total time: 1.0605	 pickout: 0.0707	 decision: 0.0955	 get_bound: 0.8851	 add_domain: 0.0092
Current lb:-0.0304105281829834
7162 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 65.97208786010742

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 424] [5, 320] [5, 218] [5, 424] [4, 53] [4, 109] [5, 218] [5, 218] [4, 390] [4, 274] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 1.2525503635406494 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.5924170017242432, 25.262794494628906]
alpha/beta optimization time: 0.8043680191040039
This batch time : update_bounds func: 0.8902	 prepare: 0.0247	 bound: 0.8048	 transfer: 0.0445	 finalize: 0.0157
Accumulated time: update_bounds func: 52.7487	 prepare: 1.3779	 bound: 47.3632	 transfer: 0.0445	 finalize: 1.2335
batch bounding time:  0.8906257152557373
Current worst splitting domains [lb, ub] (depth):
[-0.02997,   inf] (29), [-0.02996,   inf] (29), [-0.02995,   inf] (17), [-0.02995,   inf] (25), [-0.02995,   inf] (23), [-0.02993,   inf] (29), [-0.02993,   inf] (27), [-0.02992,   inf] (27), [-0.02992,   inf] (23), [-0.02992,   inf] (29), [-0.02992,   inf] (25), [-0.02991,   inf] (33), [-0.02991,   inf] (29), [-0.02991,   inf] (27), [-0.02989,   inf] (25), [-0.02989,   inf] (27), [-0.02988,   inf] (25), [-0.02988,   inf] (25), [-0.02987,   inf] (29), [-0.02986,   inf] (27), 
length of domains: 2740
Total time: 1.0491	 pickout: 0.0514	 decision: 0.0981	 get_bound: 0.8909	 add_domain: 0.0086
Current lb:-0.029965832829475403
7290 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 67.02420949935913

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 424] [5, 424] [5, 219] [5, 460] [4, 31] [4, 31] [5, 271] [4, 109] [5, 460] [5, 424] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 1.0051475763320923 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.3218101263046265, 28.628671646118164]
alpha/beta optimization time: 0.7889902591705322
This batch time : update_bounds func: 0.8769	 prepare: 0.0225	 bound: 0.7894	 transfer: 0.0484	 finalize: 0.0161
Accumulated time: update_bounds func: 53.6256	 prepare: 1.4004	 bound: 48.1526	 transfer: 0.0484	 finalize: 1.2496
batch bounding time:  0.8773515224456787
Current worst splitting domains [lb, ub] (depth):
[-0.02955,   inf] (25), [-0.02955,   inf] (25), [-0.02954,   inf] (27), [-0.02953,   inf] (29), [-0.02953,   inf] (25), [-0.02952,   inf] (21), [-0.02952,   inf] (23), [-0.02951,   inf] (31), [-0.02950,   inf] (27), [-0.02950,   inf] (25), [-0.02950,   inf] (21), [-0.02949,   inf] (25), [-0.02949,   inf] (27), [-0.02948,   inf] (21), [-0.02948,   inf] (25), [-0.02948,   inf] (27), [-0.02948,   inf] (27), [-0.02947,   inf] (27), [-0.02947,   inf] (29), [-0.02947,   inf] (21), 
length of domains: 2765
Total time: 1.0369	 pickout: 0.0559	 decision: 0.0958	 get_bound: 0.8776	 add_domain: 0.0076
Current lb:-0.02954617515206337
7418 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 68.06395101547241

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 271] [5, 460] [4, 311] [5, 424] [4, 390] [5, 460] [5, 218] [4, 444] [5, 424] [5, 460] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 1.0791316032409668 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.4072976112365723, 25.753103256225586]
alpha/beta optimization time: 0.7786846160888672
This batch time : update_bounds func: 0.8705	 prepare: 0.0225	 bound: 0.7791	 transfer: 0.0518	 finalize: 0.0166
Accumulated time: update_bounds func: 54.4961	 prepare: 1.4229	 bound: 48.9318	 transfer: 0.0518	 finalize: 1.2662
batch bounding time:  0.870934009552002
Current worst splitting domains [lb, ub] (depth):
[-0.02924,   inf] (29), [-0.02923,   inf] (27), [-0.02923,   inf] (31), [-0.02922,   inf] (21), [-0.02922,   inf] (27), [-0.02922,   inf] (33), [-0.02922,   inf] (27), [-0.02920,   inf] (29), [-0.02919,   inf] (21), [-0.02917,   inf] (31), [-0.02917,   inf] (29), [-0.02916,   inf] (27), [-0.02916,   inf] (25), [-0.02916,   inf] (29), [-0.02916,   inf] (21), [-0.02916,   inf] (25), [-0.02914,   inf] (25), [-0.02913,   inf] (21), [-0.02912,   inf] (17), [-0.02912,   inf] (31), 
length of domains: 2793
Total time: 1.0202	 pickout: 0.0470	 decision: 0.0940	 get_bound: 0.8712	 add_domain: 0.0081
Current lb:-0.029236696660518646
7546 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 69.08735489845276

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 271] [5, 271] [4, 31] [5, 460] [4, 109] [4, 31] [4, 109] [5, 424] [5, 460] [4, 31] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 1.0458848476409912 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.4351754188537598, 27.33133316040039]
alpha/beta optimization time: 0.7784841060638428
This batch time : update_bounds func: 0.8661	 prepare: 0.0229	 bound: 0.7789	 transfer: 0.0483	 finalize: 0.0154
Accumulated time: update_bounds func: 55.3622	 prepare: 1.4458	 bound: 49.7107	 transfer: 0.0483	 finalize: 1.2817
batch bounding time:  0.8664665222167969
Current worst splitting domains [lb, ub] (depth):
[-0.02888,   inf] (21), [-0.02888,   inf] (31), [-0.02887,   inf] (25), [-0.02886,   inf] (25), [-0.02886,   inf] (17), [-0.02886,   inf] (15), [-0.02886,   inf] (19), [-0.02886,   inf] (25), [-0.02886,   inf] (27), [-0.02885,   inf] (29), [-0.02885,   inf] (29), [-0.02884,   inf] (23), [-0.02884,   inf] (29), [-0.02884,   inf] (25), [-0.02882,   inf] (21), [-0.02882,   inf] (25), [-0.02882,   inf] (25), [-0.02881,   inf] (23), [-0.02881,   inf] (25), [-0.02880,   inf] (25), 
length of domains: 2821
Total time: 1.0259	 pickout: 0.0540	 decision: 0.0961	 get_bound: 0.8667	 add_domain: 0.0091
Current lb:-0.028878582641482353
7674 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 70.11646938323975

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 218] [4, 31] [4, 31] [5, 424] [5, 219] [4, 31] [5, 219] [5, 271] [5, 271] [4, 390] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.9903429746627808 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.2021005153656006, 26.680686950683594]
alpha/beta optimization time: 0.7859585285186768
This batch time : update_bounds func: 0.8750	 prepare: 0.0227	 bound: 0.7864	 transfer: 0.0485	 finalize: 0.0168
Accumulated time: update_bounds func: 56.2372	 prepare: 1.4685	 bound: 50.4971	 transfer: 0.0485	 finalize: 1.2985
batch bounding time:  0.8754119873046875
Current worst splitting domains [lb, ub] (depth):
[-0.02848,   inf] (25), [-0.02848,   inf] (19), [-0.02847,   inf] (27), [-0.02846,   inf] (25), [-0.02846,   inf] (31), [-0.02846,   inf] (27), [-0.02844,   inf] (31), [-0.02844,   inf] (23), [-0.02843,   inf] (27), [-0.02843,   inf] (27), [-0.02843,   inf] (23), [-0.02842,   inf] (25), [-0.02840,   inf] (23), [-0.02840,   inf] (25), [-0.02840,   inf] (25), [-0.02839,   inf] (25), [-0.02839,   inf] (29), [-0.02838,   inf] (27), [-0.02838,   inf] (25), [-0.02837,   inf] (21), 
length of domains: 2844
Total time: 1.0324	 pickout: 0.0556	 decision: 0.0936	 get_bound: 0.8756	 add_domain: 0.0075
Current lb:-0.028477368876338005
7802 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 71.15181279182434

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [4, 324] [4, 109] [4, 109] [4, 390] [4, 311] [4, 390] [5, 460] [5, 271] [5, 460] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 1.1350739002227783 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.222504734992981, 24.18204116821289]
alpha/beta optimization time: 0.7821993827819824
This batch time : update_bounds func: 0.8696	 prepare: 0.0224	 bound: 0.7827	 transfer: 0.0484	 finalize: 0.0157
Accumulated time: update_bounds func: 57.1067	 prepare: 1.4909	 bound: 51.2798	 transfer: 0.0484	 finalize: 1.3141
batch bounding time:  0.8700821399688721
Current worst splitting domains [lb, ub] (depth):
[-0.02808,   inf] (29), [-0.02807,   inf] (23), [-0.02807,   inf] (21), [-0.02807,   inf] (21), [-0.02807,   inf] (27), [-0.02806,   inf] (23), [-0.02806,   inf] (29), [-0.02804,   inf] (23), [-0.02804,   inf] (31), [-0.02801,   inf] (29), [-0.02801,   inf] (23), [-0.02800,   inf] (23), [-0.02800,   inf] (25), [-0.02800,   inf] (29), [-0.02799,   inf] (21), [-0.02798,   inf] (25), [-0.02797,   inf] (27), [-0.02796,   inf] (27), [-0.02796,   inf] (23), [-0.02796,   inf] (25), 
length of domains: 2876
Total time: 1.0274	 pickout: 0.0525	 decision: 0.0950	 get_bound: 0.8703	 add_domain: 0.0096
Current lb:-0.028078127652406693
7930 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 72.18215918540955

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 424] [5, 218] [5, 460] [5, 218] [4, 274] [5, 218] [5, 271] [5, 218] [5, 424] [4, 444] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 1.1496179103851318 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.7531429529190063, 24.159015655517578]
alpha/beta optimization time: 0.781937837600708
This batch time : update_bounds func: 0.8739	 prepare: 0.0230	 bound: 0.7824	 transfer: 0.0517	 finalize: 0.0163
Accumulated time: update_bounds func: 57.9806	 prepare: 1.5139	 bound: 52.0622	 transfer: 0.0517	 finalize: 1.3304
batch bounding time:  0.8742811679840088
Current worst splitting domains [lb, ub] (depth):
[-0.02772,   inf] (29), [-0.02772,   inf] (25), [-0.02771,   inf] (23), [-0.02771,   inf] (25), [-0.02771,   inf] (25), [-0.02770,   inf] (25), [-0.02769,   inf] (29), [-0.02769,   inf] (27), [-0.02769,   inf] (31), [-0.02769,   inf] (29), [-0.02769,   inf] (27), [-0.02768,   inf] (27), [-0.02768,   inf] (25), [-0.02767,   inf] (23), [-0.02767,   inf] (27), [-0.02767,   inf] (29), [-0.02766,   inf] (31), [-0.02765,   inf] (25), [-0.02765,   inf] (21), [-0.02765,   inf] (25), 
length of domains: 2910
Total time: 1.1540	 pickout: 0.0558	 decision: 0.2152	 get_bound: 0.8745	 add_domain: 0.0085
Current lb:-0.027722176164388657
8058 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 73.33907651901245

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 424] [4, 109] [5, 460] [5, 460] [4, 109] [4, 390] [5, 424] [5, 271] [5, 424] [4, 109] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 1.1637561321258545 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.8992626667022705, 22.960718154907227]
alpha/beta optimization time: 0.7952761650085449
This batch time : update_bounds func: 0.8840	 prepare: 0.0229	 bound: 0.7957	 transfer: 0.0483	 finalize: 0.0165
Accumulated time: update_bounds func: 58.8646	 prepare: 1.5368	 bound: 52.8579	 transfer: 0.0483	 finalize: 1.3470
batch bounding time:  0.8843705654144287
Current worst splitting domains [lb, ub] (depth):
[-0.02743,   inf] (29), [-0.02743,   inf] (27), [-0.02742,   inf] (27), [-0.02742,   inf] (27), [-0.02742,   inf] (29), [-0.02742,   inf] (23), [-0.02741,   inf] (23), [-0.02739,   inf] (21), [-0.02738,   inf] (27), [-0.02737,   inf] (27), [-0.02736,   inf] (33), [-0.02736,   inf] (29), [-0.02736,   inf] (17), [-0.02733,   inf] (29), [-0.02733,   inf] (25), [-0.02733,   inf] (29), [-0.02732,   inf] (23), [-0.02732,   inf] (27), [-0.02730,   inf] (29), [-0.02730,   inf] (21), 
length of domains: 2940
Total time: 1.0682	 pickout: 0.0813	 decision: 0.0942	 get_bound: 0.8846	 add_domain: 0.0081
Current lb:-0.02742907404899597
8186 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 74.41002798080444

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 271] [5, 320] [5, 271] [5, 320] [5, 271] [5, 218] [5, 218] [5, 460] [5, 271] [5, 271] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 1.2710340023040771 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.8734386563301086, 23.628604888916016]
alpha/beta optimization time: 0.7866570949554443
This batch time : update_bounds func: 0.8740	 prepare: 0.0223	 bound: 0.7871	 transfer: 0.0484	 finalize: 0.0157
Accumulated time: update_bounds func: 59.7386	 prepare: 1.5591	 bound: 53.6450	 transfer: 0.0484	 finalize: 1.3627
batch bounding time:  0.8744173049926758
Current worst splitting domains [lb, ub] (depth):
[-0.02706,   inf] (23), [-0.02705,   inf] (29), [-0.02705,   inf] (25), [-0.02704,   inf] (29), [-0.02703,   inf] (29), [-0.02703,   inf] (27), [-0.02703,   inf] (29), [-0.02702,   inf] (33), [-0.02702,   inf] (27), [-0.02701,   inf] (21), [-0.02701,   inf] (25), [-0.02701,   inf] (29), [-0.02701,   inf] (29), [-0.02701,   inf] (29), [-0.02700,   inf] (17), [-0.02700,   inf] (31), [-0.02700,   inf] (25), [-0.02699,   inf] (23), [-0.02699,   inf] (21), [-0.02699,   inf] (25), 
length of domains: 2972
Total time: 1.0343	 pickout: 0.0559	 decision: 0.0946	 get_bound: 0.8746	 add_domain: 0.0091
Current lb:-0.027056381106376648
8314 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 75.44709801673889

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 109] [5, 424] [5, 218] [5, 424] [4, 109] [4, 109] [5, 424] [5, 419] [5, 460] [5, 460] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.991668701171875 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.7556852102279663, 28.771390914916992]
alpha/beta optimization time: 0.823800802230835
This batch time : update_bounds func: 0.9126	 prepare: 0.0229	 bound: 0.8243	 transfer: 0.0485	 finalize: 0.0163
Accumulated time: update_bounds func: 60.6512	 prepare: 1.5820	 bound: 54.4693	 transfer: 0.0485	 finalize: 1.3790
batch bounding time:  0.9129745960235596
Current worst splitting domains [lb, ub] (depth):
[-0.02673,   inf] (27), [-0.02672,   inf] (27), [-0.02672,   inf] (27), [-0.02672,   inf] (27), [-0.02671,   inf] (29), [-0.02671,   inf] (23), [-0.02670,   inf] (23), [-0.02670,   inf] (33), [-0.02669,   inf] (27), [-0.02669,   inf] (23), [-0.02668,   inf] (23), [-0.02668,   inf] (31), [-0.02668,   inf] (23), [-0.02667,   inf] (31), [-0.02666,   inf] (33), [-0.02666,   inf] (23), [-0.02666,   inf] (23), [-0.02665,   inf] (31), [-0.02665,   inf] (23), [-0.02664,   inf] (25), 
length of domains: 3001
Total time: 1.0690	 pickout: 0.0527	 decision: 0.0952	 get_bound: 0.9132	 add_domain: 0.0079
Current lb:-0.026726052165031433
8442 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 76.51908278465271

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 324] [4, 109] [5, 271] [5, 271] [5, 424] [5, 460] [4, 31] [4, 53] [4, 109] [5, 460] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.9053905010223389 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.2716073989868164, 26.213037490844727]
alpha/beta optimization time: 0.8089046478271484
This batch time : update_bounds func: 0.8961	 prepare: 0.0223	 bound: 0.8094	 transfer: 0.0483	 finalize: 0.0157
Accumulated time: update_bounds func: 61.5473	 prepare: 1.6043	 bound: 55.2787	 transfer: 0.0483	 finalize: 1.3947
batch bounding time:  0.8965075016021729
Current worst splitting domains [lb, ub] (depth):
[-0.02638,   inf] (23), [-0.02638,   inf] (31), [-0.02637,   inf] (27), [-0.02636,   inf] (27), [-0.02636,   inf] (27), [-0.02635,   inf] (27), [-0.02633,   inf] (25), [-0.02633,   inf] (25), [-0.02632,   inf] (23), [-0.02632,   inf] (31), [-0.02632,   inf] (25), [-0.02631,   inf] (29), [-0.02631,   inf] (27), [-0.02629,   inf] (29), [-0.02629,   inf] (27), [-0.02629,   inf] (27), [-0.02629,   inf] (27), [-0.02628,   inf] (27), [-0.02627,   inf] (23), [-0.02626,   inf] (23), 
length of domains: 3028
Total time: 1.0526	 pickout: 0.0523	 decision: 0.0947	 get_bound: 0.8967	 add_domain: 0.0090
Current lb:-0.026380330324172974
8570 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 77.57466268539429

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 324] [5, 419] [5, 271] [4, 274] [5, 320] [5, 320] [5, 218] [5, 271] [5, 320] [4, 31] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 1.0821783542633057 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.30477380752563477, 20.20948028564453]
alpha/beta optimization time: 0.7863757610321045
This batch time : update_bounds func: 0.8734	 prepare: 0.0223	 bound: 0.7868	 transfer: 0.0470	 finalize: 0.0167
Accumulated time: update_bounds func: 62.4206	 prepare: 1.6267	 bound: 56.0655	 transfer: 0.0470	 finalize: 1.4114
batch bounding time:  0.8737752437591553
Current worst splitting domains [lb, ub] (depth):
[-0.02598,   inf] (27), [-0.02597,   inf] (25), [-0.02596,   inf] (29), [-0.02595,   inf] (29), [-0.02593,   inf] (29), [-0.02593,   inf] (31), [-0.02592,   inf] (25), [-0.02591,   inf] (29), [-0.02590,   inf] (23), [-0.02590,   inf] (27), [-0.02589,   inf] (23), [-0.02589,   inf] (15), [-0.02589,   inf] (27), [-0.02588,   inf] (23), [-0.02587,   inf] (21), [-0.02587,   inf] (29), [-0.02587,   inf] (27), [-0.02586,   inf] (17), [-0.02586,   inf] (29), [-0.02586,   inf] (25), 
length of domains: 3062
Total time: 1.0261	 pickout: 0.0504	 decision: 0.0933	 get_bound: 0.8740	 add_domain: 0.0085
Current lb:-0.025979168713092804
8698 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 78.60355305671692

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 390] [5, 320] [5, 271] [5, 424] [5, 424] [5, 419] [5, 424] [5, 424] [5, 460] [5, 424] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.7456516027450562 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.0485728979110718, 25.732362747192383]
alpha/beta optimization time: 0.782954216003418
This batch time : update_bounds func: 0.8716	 prepare: 0.0224	 bound: 0.7834	 transfer: 0.0485	 finalize: 0.0159
Accumulated time: update_bounds func: 63.2922	 prepare: 1.6491	 bound: 56.8490	 transfer: 0.0485	 finalize: 1.4273
batch bounding time:  0.8720505237579346
Current worst splitting domains [lb, ub] (depth):
[-0.02563,   inf] (21), [-0.02563,   inf] (23), [-0.02561,   inf] (23), [-0.02561,   inf] (21), [-0.02560,   inf] (27), [-0.02560,   inf] (21), [-0.02559,   inf] (27), [-0.02558,   inf] (25), [-0.02557,   inf] (29), [-0.02557,   inf] (29), [-0.02556,   inf] (25), [-0.02555,   inf] (21), [-0.02554,   inf] (29), [-0.02553,   inf] (27), [-0.02553,   inf] (27), [-0.02553,   inf] (29), [-0.02553,   inf] (31), [-0.02552,   inf] (27), [-0.02551,   inf] (27), [-0.02550,   inf] (23), 
length of domains: 3087
Total time: 1.0644	 pickout: 0.0903	 decision: 0.0939	 get_bound: 0.8723	 add_domain: 0.0079
Current lb:-0.025632057338953018
8826 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 79.67121005058289

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 460] [5, 460] [5, 460] [5, 460] [4, 274] [5, 460] [5, 271] [5, 460] [4, 31] [5, 424] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 1.013346552848816 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.6223177909851074, 24.35818099975586]
alpha/beta optimization time: 0.8030991554260254
This batch time : update_bounds func: 0.8914	 prepare: 0.0224	 bound: 0.8036	 transfer: 0.0486	 finalize: 0.0164
Accumulated time: update_bounds func: 64.1837	 prepare: 1.6715	 bound: 57.6525	 transfer: 0.0486	 finalize: 1.4437
batch bounding time:  0.8918125629425049
Current worst splitting domains [lb, ub] (depth):
[-0.02525,   inf] (31), [-0.02525,   inf] (31), [-0.02525,   inf] (31), [-0.02524,   inf] (31), [-0.02524,   inf] (31), [-0.02523,   inf] (23), [-0.02523,   inf] (25), [-0.02523,   inf] (33), [-0.02523,   inf] (25), [-0.02522,   inf] (29), [-0.02522,   inf] (27), [-0.02522,   inf] (25), [-0.02521,   inf] (27), [-0.02520,   inf] (23), [-0.02520,   inf] (25), [-0.02519,   inf] (29), [-0.02519,   inf] (33), [-0.02519,   inf] (29), [-0.02516,   inf] (21), [-0.02516,   inf] (23), 
length of domains: 3114
Total time: 1.0407	 pickout: 0.0458	 decision: 0.0949	 get_bound: 0.8920	 add_domain: 0.0080
Current lb:-0.025253117084503174
8954 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 80.71490550041199

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 419] [4, 444] [5, 419] [4, 31] [5, 424] [5, 320] [5, 218] [5, 419] [4, 324] [5, 424] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.8641992807388306 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.8896481990814209, 20.253154754638672]
alpha/beta optimization time: 0.7969162464141846
This batch time : update_bounds func: 0.8884	 prepare: 0.0223	 bound: 0.7974	 transfer: 0.0517	 finalize: 0.0165
Accumulated time: update_bounds func: 65.0721	 prepare: 1.6939	 bound: 58.4499	 transfer: 0.0517	 finalize: 1.4602
batch bounding time:  0.8888204097747803
Current worst splitting domains [lb, ub] (depth):
[-0.02492,   inf] (27), [-0.02491,   inf] (23), [-0.02490,   inf] (27), [-0.02490,   inf] (27), [-0.02489,   inf] (21), [-0.02489,   inf] (21), [-0.02489,   inf] (27), [-0.02489,   inf] (23), [-0.02488,   inf] (23), [-0.02488,   inf] (21), [-0.02487,   inf] (19), [-0.02486,   inf] (33), [-0.02486,   inf] (27), [-0.02486,   inf] (27), [-0.02486,   inf] (15), [-0.02485,   inf] (27), [-0.02484,   inf] (25), [-0.02484,   inf] (23), [-0.02484,   inf] (27), [-0.02484,   inf] (23), 
length of domains: 3140
Total time: 1.0411	 pickout: 0.0502	 decision: 0.0938	 get_bound: 0.8890	 add_domain: 0.0080
Current lb:-0.02491866424679756
9082 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 81.75892925262451

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [4, 31] [5, 320] [4, 109] [4, 288] [5, 218] [5, 460] [4, 31] [5, 320] [5, 218] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.7926720380783081 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.3425379991531372, 25.30487060546875]
alpha/beta optimization time: 0.7881464958190918
This batch time : update_bounds func: 0.8761	 prepare: 0.0227	 bound: 0.7886	 transfer: 0.0484	 finalize: 0.0159
Accumulated time: update_bounds func: 65.9481	 prepare: 1.7165	 bound: 59.2385	 transfer: 0.0484	 finalize: 1.4760
batch bounding time:  0.8765039443969727
Current worst splitting domains [lb, ub] (depth):
[-0.02459,   inf] (23), [-0.02458,   inf] (31), [-0.02458,   inf] (25), [-0.02456,   inf] (21), [-0.02455,   inf] (33), [-0.02454,   inf] (29), [-0.02454,   inf] (27), [-0.02452,   inf] (27), [-0.02452,   inf] (25), [-0.02451,   inf] (25), [-0.02450,   inf] (23), [-0.02449,   inf] (29), [-0.02449,   inf] (27), [-0.02448,   inf] (23), [-0.02447,   inf] (27), [-0.02446,   inf] (29), [-0.02445,   inf] (27), [-0.02445,   inf] (31), [-0.02444,   inf] (25), [-0.02443,   inf] (29), 
length of domains: 3161
Total time: 1.1798	 pickout: 0.0629	 decision: 0.2319	 get_bound: 0.8767	 add_domain: 0.0083
Current lb:-0.02458629570901394
9210 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 82.94174289703369

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 31] [5, 424] [5, 218] [5, 218] [5, 419] [5, 271] [5, 271] [5, 271] [4, 109] [5, 218] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.7096036076545715 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.0304594039916992, 20.993915557861328]
alpha/beta optimization time: 0.7923030853271484
This batch time : update_bounds func: 0.8853	 prepare: 0.0227	 bound: 0.7928	 transfer: 0.0527	 finalize: 0.0166
Accumulated time: update_bounds func: 66.8334	 prepare: 1.7392	 bound: 60.0313	 transfer: 0.0527	 finalize: 1.4927
batch bounding time:  0.8857183456420898
Current worst splitting domains [lb, ub] (depth):
[-0.02412,   inf] (31), [-0.02411,   inf] (29), [-0.02410,   inf] (29), [-0.02410,   inf] (27), [-0.02410,   inf] (25), [-0.02407,   inf] (33), [-0.02407,   inf] (21), [-0.02406,   inf] (29), [-0.02406,   inf] (27), [-0.02406,   inf] (25), [-0.02406,   inf] (27), [-0.02406,   inf] (23), [-0.02405,   inf] (25), [-0.02405,   inf] (29), [-0.02405,   inf] (25), [-0.02405,   inf] (25), [-0.02405,   inf] (29), [-0.02404,   inf] (33), [-0.02404,   inf] (27), [-0.02404,   inf] (25), 
length of domains: 3187
Total time: 1.0460	 pickout: 0.0572	 decision: 0.0949	 get_bound: 0.8859	 add_domain: 0.0079
Current lb:-0.024116739630699158
9338 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 83.9905366897583

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 419] [4, 53] [5, 424] [4, 53] [5, 320] [5, 419] [5, 460] [5, 424] [4, 109] [5, 460] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.908761203289032 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.8471398949623108, 21.41434669494629]
alpha/beta optimization time: 0.8034327030181885
This batch time : update_bounds func: 0.8879	 prepare: 0.0224	 bound: 0.8039	 transfer: 0.0446	 finalize: 0.0157
Accumulated time: update_bounds func: 67.7214	 prepare: 1.7616	 bound: 60.8352	 transfer: 0.0446	 finalize: 1.5084
batch bounding time:  0.8883533477783203
Current worst splitting domains [lb, ub] (depth):
[-0.02373,   inf] (27), [-0.02373,   inf] (33), [-0.02373,   inf] (27), [-0.02372,   inf] (23), [-0.02372,   inf] (23), [-0.02372,   inf] (31), [-0.02371,   inf] (29), [-0.02371,   inf] (21), [-0.02369,   inf] (25), [-0.02368,   inf] (25), [-0.02368,   inf] (33), [-0.02368,   inf] (29), [-0.02366,   inf] (23), [-0.02366,   inf] (23), [-0.02365,   inf] (23), [-0.02365,   inf] (29), [-0.02365,   inf] (25), [-0.02364,   inf] (33), [-0.02362,   inf] (29), [-0.02362,   inf] (33), 
length of domains: 3214
Total time: 1.0463	 pickout: 0.0540	 decision: 0.0955	 get_bound: 0.8886	 add_domain: 0.0082
Current lb:-0.023731008172035217
9466 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 85.03975820541382

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 53] [4, 31] [4, 109] [5, 218] [5, 320] [5, 424] [5, 424] [5, 218] [4, 390] [4, 311] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.603766143321991 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.1190398931503296, 21.208768844604492]
alpha/beta optimization time: 0.7853598594665527
This batch time : update_bounds func: 0.8735	 prepare: 0.0225	 bound: 0.7858	 transfer: 0.0484	 finalize: 0.0164
Accumulated time: update_bounds func: 68.5949	 prepare: 1.7841	 bound: 61.6210	 transfer: 0.0484	 finalize: 1.5247
batch bounding time:  0.873934268951416
Current worst splitting domains [lb, ub] (depth):
[-0.02333,   inf] (29), [-0.02333,   inf] (29), [-0.02332,   inf] (25), [-0.02331,   inf] (31), [-0.02331,   inf] (33), [-0.02330,   inf] (33), [-0.02330,   inf] (29), [-0.02330,   inf] (27), [-0.02329,   inf] (25), [-0.02329,   inf] (29), [-0.02329,   inf] (23), [-0.02329,   inf] (23), [-0.02328,   inf] (27), [-0.02327,   inf] (29), [-0.02327,   inf] (27), [-0.02326,   inf] (31), [-0.02326,   inf] (25), [-0.02326,   inf] (29), [-0.02326,   inf] (21), [-0.02325,   inf] (25), 
length of domains: 3230
Total time: 1.0293	 pickout: 0.0520	 decision: 0.0958	 get_bound: 0.8742	 add_domain: 0.0074
Current lb:-0.023326493799686432
9594 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 86.07264542579651

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 271] [4, 31] [4, 53] [5, 419] [5, 419] [5, 419] [5, 424] [5, 271] [5, 320] [5, 271] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.620919942855835 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.25067099928855896, 22.995222091674805]
alpha/beta optimization time: 0.8005702495574951
This batch time : update_bounds func: 0.8893	 prepare: 0.0228	 bound: 0.8011	 transfer: 0.0485	 finalize: 0.0165
Accumulated time: update_bounds func: 69.4842	 prepare: 1.8069	 bound: 62.4221	 transfer: 0.0485	 finalize: 1.5412
batch bounding time:  0.8897407054901123
Current worst splitting domains [lb, ub] (depth):
[-0.02302,   inf] (29), [-0.02301,   inf] (25), [-0.02300,   inf] (29), [-0.02298,   inf] (25), [-0.02298,   inf] (25), [-0.02298,   inf] (27), [-0.02297,   inf] (31), [-0.02297,   inf] (31), [-0.02294,   inf] (27), [-0.02294,   inf] (25), [-0.02293,   inf] (31), [-0.02291,   inf] (15), [-0.02290,   inf] (31), [-0.02290,   inf] (25), [-0.02290,   inf] (27), [-0.02289,   inf] (31), [-0.02289,   inf] (23), [-0.02288,   inf] (25), [-0.02288,   inf] (35), [-0.02288,   inf] (29), 
length of domains: 3253
Total time: 1.0472	 pickout: 0.0545	 decision: 0.0947	 get_bound: 0.8900	 add_domain: 0.0079
Current lb:-0.02301643416285515
9722 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 87.12313675880432

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 274] [4, 109] [5, 271] [5, 218] [5, 271] [4, 324] [4, 53] [5, 419] [5, 271] [5, 320] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.596145510673523 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.440910816192627, 25.07642364501953]
alpha/beta optimization time: 0.818389892578125
This batch time : update_bounds func: 0.9056	 prepare: 0.0226	 bound: 0.8188	 transfer: 0.0483	 finalize: 0.0154
Accumulated time: update_bounds func: 70.3897	 prepare: 1.8294	 bound: 63.2409	 transfer: 0.0483	 finalize: 1.5566
batch bounding time:  0.9059524536132812
Current worst splitting domains [lb, ub] (depth):
[-0.02263,   inf] (29), [-0.02263,   inf] (21), [-0.02263,   inf] (35), [-0.02263,   inf] (25), [-0.02262,   inf] (25), [-0.02262,   inf] (25), [-0.02261,   inf] (19), [-0.02261,   inf] (21), [-0.02261,   inf] (23), [-0.02260,   inf] (29), [-0.02260,   inf] (31), [-0.02260,   inf] (33), [-0.02260,   inf] (25), [-0.02259,   inf] (25), [-0.02259,   inf] (31), [-0.02259,   inf] (25), [-0.02258,   inf] (23), [-0.02258,   inf] (35), [-0.02258,   inf] (25), [-0.02257,   inf] (31), 
length of domains: 3273
Total time: 1.0634	 pickout: 0.0537	 decision: 0.0950	 get_bound: 0.9062	 add_domain: 0.0086
Current lb:-0.022631946951150894
9850 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 88.18958353996277

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 271] [5, 460] [5, 371] [4, 444] [4, 53] [4, 324] [5, 218] [5, 218] [4, 53] [5, 424] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.616829514503479 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.5853734016418457, 19.06580352783203]
alpha/beta optimization time: 0.8225812911987305
This batch time : update_bounds func: 0.9188	 prepare: 0.0226	 bound: 0.8231	 transfer: 0.0516	 finalize: 0.0211
Accumulated time: update_bounds func: 71.3085	 prepare: 1.8520	 bound: 64.0640	 transfer: 0.0516	 finalize: 1.5778
batch bounding time:  0.9194760322570801
Current worst splitting domains [lb, ub] (depth):
[-0.02232,   inf] (25), [-0.02231,   inf] (23), [-0.02231,   inf] (27), [-0.02230,   inf] (25), [-0.02229,   inf] (31), [-0.02227,   inf] (21), [-0.02227,   inf] (27), [-0.02227,   inf] (31), [-0.02226,   inf] (35), [-0.02225,   inf] (29), [-0.02225,   inf] (21), [-0.02224,   inf] (27), [-0.02224,   inf] (27), [-0.02224,   inf] (25), [-0.02223,   inf] (33), [-0.02223,   inf] (33), [-0.02222,   inf] (27), [-0.02221,   inf] (25), [-0.02221,   inf] (25), [-0.02221,   inf] (25), 
length of domains: 3292
Total time: 1.0953	 pickout: 0.0664	 decision: 0.0943	 get_bound: 0.9199	 add_domain: 0.0146
Current lb:-0.02232000231742859
9978 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 89.2893283367157

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 390] [5, 218] [4, 109] [5, 460] [4, 31] [5, 460] [5, 271] [5, 424] [5, 106] [5, 424] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.6248266696929932 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.7884364724159241, 21.326597213745117]
alpha/beta optimization time: 0.8045909404754639
This batch time : update_bounds func: 0.8918	 prepare: 0.0223	 bound: 0.8051	 transfer: 0.0484	 finalize: 0.0156
Accumulated time: update_bounds func: 72.2004	 prepare: 1.8743	 bound: 64.8690	 transfer: 0.0484	 finalize: 1.5934
batch bounding time:  0.8922348022460938
Current worst splitting domains [lb, ub] (depth):
[-0.02197,   inf] (21), [-0.02197,   inf] (25), [-0.02195,   inf] (29), [-0.02194,   inf] (29), [-0.02192,   inf] (29), [-0.02192,   inf] (23), [-0.02192,   inf] (29), [-0.02190,   inf] (31), [-0.02190,   inf] (25), [-0.02190,   inf] (31), [-0.02189,   inf] (29), [-0.02188,   inf] (21), [-0.02188,   inf] (29), [-0.02188,   inf] (25), [-0.02186,   inf] (23), [-0.02186,   inf] (31), [-0.02186,   inf] (33), [-0.02185,   inf] (27), [-0.02185,   inf] (29), [-0.02185,   inf] (33), 
length of domains: 3311
Total time: 1.0432	 pickout: 0.0464	 decision: 0.0967	 get_bound: 0.8925	 add_domain: 0.0076
Current lb:-0.021966133266687393
10106 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 90.33541440963745

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 218] [5, 460] [4, 53] [5, 424] [5, 271] [4, 53] [5, 424] [4, 324] [4, 31] [4, 53] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.42546796798706055 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.1929503679275513, 23.62576675415039]
alpha/beta optimization time: 0.7833681106567383
This batch time : update_bounds func: 0.8719	 prepare: 0.0223	 bound: 0.7838	 transfer: 0.0490	 finalize: 0.0164
Accumulated time: update_bounds func: 73.0723	 prepare: 1.8966	 bound: 65.6529	 transfer: 0.0490	 finalize: 1.6097
batch bounding time:  0.8723440170288086
Current worst splitting domains [lb, ub] (depth):
[-0.02160,   inf] (29), [-0.02160,   inf] (25), [-0.02159,   inf] (17), [-0.02158,   inf] (33), [-0.02158,   inf] (25), [-0.02156,   inf] (23), [-0.02156,   inf] (31), [-0.02156,   inf] (29), [-0.02156,   inf] (29), [-0.02156,   inf] (27), [-0.02155,   inf] (29), [-0.02155,   inf] (25), [-0.02155,   inf] (35), [-0.02154,   inf] (29), [-0.02154,   inf] (33), [-0.02154,   inf] (29), [-0.02153,   inf] (23), [-0.02152,   inf] (25), [-0.02152,   inf] (29), [-0.02152,   inf] (27), 
length of domains: 3321
Total time: 1.0210	 pickout: 0.0458	 decision: 0.0959	 get_bound: 0.8726	 add_domain: 0.0068
Current lb:-0.021601002663373947
10234 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 91.359708070755

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 53] [5, 218] [5, 219] [5, 419] [5, 320] [5, 218] [4, 31] [5, 424] [5, 424] [5, 320] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.748393714427948 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.9182835817337036, 20.15662956237793]
alpha/beta optimization time: 0.801628589630127
This batch time : update_bounds func: 0.8909	 prepare: 0.0227	 bound: 0.8021	 transfer: 0.0487	 finalize: 0.0168
Accumulated time: update_bounds func: 73.9632	 prepare: 1.9193	 bound: 66.4550	 transfer: 0.0487	 finalize: 1.6266
batch bounding time:  0.8914289474487305
Current worst splitting domains [lb, ub] (depth):
[-0.02133,   inf] (29), [-0.02133,   inf] (27), [-0.02133,   inf] (33), [-0.02132,   inf] (23), [-0.02132,   inf] (23), [-0.02132,   inf] (31), [-0.02132,   inf] (27), [-0.02130,   inf] (23), [-0.02130,   inf] (21), [-0.02130,   inf] (25), [-0.02129,   inf] (21), [-0.02128,   inf] (27), [-0.02128,   inf] (29), [-0.02127,   inf] (21), [-0.02127,   inf] (31), [-0.02126,   inf] (33), [-0.02125,   inf] (27), [-0.02125,   inf] (29), [-0.02124,   inf] (27), [-0.02124,   inf] (29), 
length of domains: 3343
Total time: 1.0418	 pickout: 0.0473	 decision: 0.0952	 get_bound: 0.8917	 add_domain: 0.0077
Current lb:-0.02133362367749214
10362 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 92.40541291236877

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 271] [5, 460] [4, 109] [5, 218] [5, 218] [4, 53] [5, 424] [5, 218] [4, 31] [5, 218] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.5689181089401245 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.8311299085617065, 24.476516723632812]
alpha/beta optimization time: 0.810786247253418
This batch time : update_bounds func: 0.9019	 prepare: 0.0225	 bound: 0.8112	 transfer: 0.0518	 finalize: 0.0159
Accumulated time: update_bounds func: 74.8651	 prepare: 1.9418	 bound: 67.2662	 transfer: 0.0518	 finalize: 1.6425
batch bounding time:  0.9022531509399414
Current worst splitting domains [lb, ub] (depth):
[-0.02100,   inf] (33), [-0.02099,   inf] (23), [-0.02099,   inf] (25), [-0.02098,   inf] (27), [-0.02098,   inf] (33), [-0.02098,   inf] (29), [-0.02097,   inf] (23), [-0.02097,   inf] (35), [-0.02096,   inf] (33), [-0.02095,   inf] (29), [-0.02095,   inf] (27), [-0.02093,   inf] (29), [-0.02093,   inf] (27), [-0.02092,   inf] (29), [-0.02092,   inf] (19), [-0.02092,   inf] (29), [-0.02091,   inf] (29), [-0.02091,   inf] (25), [-0.02090,   inf] (29), [-0.02090,   inf] (29), 
length of domains: 3366
Total time: 1.1994	 pickout: 0.0465	 decision: 0.2417	 get_bound: 0.9025	 add_domain: 0.0087
Current lb:-0.020995348691940308
10490 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 93.60776543617249

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 419] [5, 320] [5, 320] [4, 311] [4, 109] [5, 271] [5, 218] [4, 31] [4, 31] [5, 424] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.4788397550582886 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.2346723079681396, 19.02365493774414]
alpha/beta optimization time: 0.8001394271850586
This batch time : update_bounds func: 0.8899	 prepare: 0.0231	 bound: 0.8006	 transfer: 0.0489	 finalize: 0.0168
Accumulated time: update_bounds func: 75.7550	 prepare: 1.9649	 bound: 68.0668	 transfer: 0.0489	 finalize: 1.6593
batch bounding time:  0.8903405666351318
Current worst splitting domains [lb, ub] (depth):
[-0.02066,   inf] (33), [-0.02066,   inf] (31), [-0.02065,   inf] (21), [-0.02065,   inf] (27), [-0.02065,   inf] (27), [-0.02064,   inf] (23), [-0.02063,   inf] (31), [-0.02063,   inf] (25), [-0.02062,   inf] (35), [-0.02062,   inf] (23), [-0.02062,   inf] (23), [-0.02062,   inf] (33), [-0.02062,   inf] (29), [-0.02062,   inf] (27), [-0.02061,   inf] (27), [-0.02060,   inf] (25), [-0.02059,   inf] (33), [-0.02058,   inf] (35), [-0.02058,   inf] (31), [-0.02058,   inf] (25), 
length of domains: 3384
Total time: 1.0461	 pickout: 0.0538	 decision: 0.0941	 get_bound: 0.8906	 add_domain: 0.0075
Current lb:-0.020662300288677216
10618 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 94.65689492225647

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 53] [4, 31] [5, 460] [5, 460] [5, 320] [5, 460] [5, 419] [5, 460] [4, 390] [5, 320] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.5632051825523376 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.9567213654518127, 22.124677658081055]
alpha/beta optimization time: 0.7826054096221924
This batch time : update_bounds func: 0.8713	 prepare: 0.0224	 bound: 0.7830	 transfer: 0.0487	 finalize: 0.0160
Accumulated time: update_bounds func: 76.6263	 prepare: 1.9873	 bound: 68.8499	 transfer: 0.0487	 finalize: 1.6753
batch bounding time:  0.871715784072876
Current worst splitting domains [lb, ub] (depth):
[-0.02038,   inf] (33), [-0.02038,   inf] (33), [-0.02038,   inf] (35), [-0.02038,   inf] (23), [-0.02038,   inf] (33), [-0.02037,   inf] (19), [-0.02037,   inf] (25), [-0.02036,   inf] (25), [-0.02036,   inf] (31), [-0.02036,   inf] (27), [-0.02036,   inf] (33), [-0.02035,   inf] (23), [-0.02035,   inf] (31), [-0.02035,   inf] (33), [-0.02034,   inf] (35), [-0.02034,   inf] (23), [-0.02033,   inf] (31), [-0.02033,   inf] (27), [-0.02031,   inf] (29), [-0.02030,   inf] (25), 
length of domains: 3404
Total time: 1.0259	 pickout: 0.0523	 decision: 0.0940	 get_bound: 0.8719	 add_domain: 0.0076
Current lb:-0.020384531468153
10746 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 95.6857361793518

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 390] [5, 419] [5, 106] [5, 460] [4, 390] [5, 218] [5, 218] [5, 218] [4, 31] [5, 460] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.6867476105690002 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.5421574115753174, 20.10700225830078]
alpha/beta optimization time: 0.7834615707397461
This batch time : update_bounds func: 0.8720	 prepare: 0.0224	 bound: 0.7839	 transfer: 0.0486	 finalize: 0.0166
Accumulated time: update_bounds func: 77.4983	 prepare: 2.0097	 bound: 69.6338	 transfer: 0.0486	 finalize: 1.6919
batch bounding time:  0.8723702430725098
Current worst splitting domains [lb, ub] (depth):
[-0.02012,   inf] (25), [-0.02012,   inf] (31), [-0.02012,   inf] (27), [-0.02011,   inf] (31), [-0.02011,   inf] (29), [-0.02011,   inf] (35), [-0.02011,   inf] (29), [-0.02010,   inf] (27), [-0.02009,   inf] (19), [-0.02008,   inf] (21), [-0.02007,   inf] (25), [-0.02007,   inf] (29), [-0.02007,   inf] (15), [-0.02006,   inf] (25), [-0.02006,   inf] (29), [-0.02006,   inf] (29), [-0.02006,   inf] (21), [-0.02003,   inf] (21), [-0.02003,   inf] (31), [-0.02003,   inf] (23), 
length of domains: 3430
Total time: 1.0287	 pickout: 0.0526	 decision: 0.0953	 get_bound: 0.8726	 add_domain: 0.0082
Current lb:-0.02012462168931961
10874 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 96.71740198135376

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 460] [5, 419] [4, 53] [5, 424] [5, 424] [4, 390] [5, 424] [4, 109] [5, 219] [5, 460] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.3885958790779114 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.5424368977546692, 22.943084716796875]
alpha/beta optimization time: 0.7966101169586182
This batch time : update_bounds func: 0.8813	 prepare: 0.0224	 bound: 0.7971	 transfer: 0.0448	 finalize: 0.0167
Accumulated time: update_bounds func: 78.3796	 prepare: 2.0321	 bound: 70.4309	 transfer: 0.0448	 finalize: 1.7085
batch bounding time:  0.8817555904388428
Current worst splitting domains [lb, ub] (depth):
[-0.01986,   inf] (27), [-0.01986,   inf] (33), [-0.01985,   inf] (31), [-0.01985,   inf] (33), [-0.01985,   inf] (25), [-0.01985,   inf] (29), [-0.01985,   inf] (31), [-0.01983,   inf] (27), [-0.01982,   inf] (31), [-0.01982,   inf] (29), [-0.01981,   inf] (23), [-0.01980,   inf] (25), [-0.01980,   inf] (21), [-0.01980,   inf] (23), [-0.01980,   inf] (17), [-0.01978,   inf] (27), [-0.01977,   inf] (25), [-0.01977,   inf] (27), [-0.01976,   inf] (27), [-0.01976,   inf] (17), 
length of domains: 3445
Total time: 1.0354	 pickout: 0.0518	 decision: 0.0945	 get_bound: 0.8820	 add_domain: 0.0071
Current lb:-0.019862979650497437
11002 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 97.7557270526886

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [4, 31] [4, 324] [4, 31] [5, 460] [4, 274] [5, 419] [4, 390] [5, 424] [5, 424] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.4770420789718628 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.7278662919998169, 25.17223358154297]
alpha/beta optimization time: 0.7989859580993652
This batch time : update_bounds func: 0.8908	 prepare: 0.0247	 bound: 0.7995	 transfer: 0.0493	 finalize: 0.0169
Accumulated time: update_bounds func: 79.2704	 prepare: 2.0569	 bound: 71.2303	 transfer: 0.0493	 finalize: 1.7254
batch bounding time:  0.891298770904541
Current worst splitting domains [lb, ub] (depth):
[-0.01957,   inf] (27), [-0.01956,   inf] (27), [-0.01956,   inf] (25), [-0.01954,   inf] (21), [-0.01954,   inf] (23), [-0.01953,   inf] (21), [-0.01953,   inf] (23), [-0.01953,   inf] (27), [-0.01952,   inf] (27), [-0.01952,   inf] (21), [-0.01952,   inf] (29), [-0.01952,   inf] (23), [-0.01952,   inf] (25), [-0.01951,   inf] (27), [-0.01951,   inf] (35), [-0.01950,   inf] (29), [-0.01950,   inf] (31), [-0.01949,   inf] (31), [-0.01949,   inf] (31), [-0.01948,   inf] (21), 
length of domains: 3464
Total time: 1.0563	 pickout: 0.0580	 decision: 0.0968	 get_bound: 0.8916	 add_domain: 0.0099
Current lb:-0.019571423530578613
11130 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 98.81547570228577

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [4, 4] [5, 271] [5, 218] [5, 460] [5, 218] [5, 460] [5, 320] [4, 390] [5, 218] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.3952617645263672 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.807276725769043, 19.318506240844727]
alpha/beta optimization time: 0.813572883605957
This batch time : update_bounds func: 0.9121	 prepare: 0.0228	 bound: 0.8140	 transfer: 0.0519	 finalize: 0.0229
Accumulated time: update_bounds func: 80.1825	 prepare: 2.0796	 bound: 72.0444	 transfer: 0.0519	 finalize: 1.7483
batch bounding time:  0.912489652633667
Current worst splitting domains [lb, ub] (depth):
[-0.01931,   inf] (25), [-0.01931,   inf] (25), [-0.01930,   inf] (25), [-0.01930,   inf] (31), [-0.01929,   inf] (33), [-0.01929,   inf] (23), [-0.01929,   inf] (31), [-0.01928,   inf] (23), [-0.01927,   inf] (27), [-0.01927,   inf] (27), [-0.01927,   inf] (27), [-0.01925,   inf] (23), [-0.01925,   inf] (31), [-0.01923,   inf] (31), [-0.01923,   inf] (27), [-0.01923,   inf] (31), [-0.01922,   inf] (25), [-0.01922,   inf] (23), [-0.01922,   inf] (31), [-0.01922,   inf] (21), 
length of domains: 3484
Total time: 1.0919	 pickout: 0.0685	 decision: 0.1025	 get_bound: 0.9127	 add_domain: 0.0081
Current lb:-0.019308805465698242
11258 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 99.91041707992554

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 460] [5, 218] [5, 320] [5, 424] [5, 419] [5, 460] [4, 274] [4, 31] [4, 324] [4, 324] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.11842325329780579 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.5252628326416016, 25.124267578125]
alpha/beta optimization time: 0.7920031547546387
This batch time : update_bounds func: 0.8808	 prepare: 0.0226	 bound: 0.7925	 transfer: 0.0482	 finalize: 0.0160
Accumulated time: update_bounds func: 81.0633	 prepare: 2.1023	 bound: 72.8369	 transfer: 0.0482	 finalize: 1.7643
batch bounding time:  0.881218671798706
Current worst splitting domains [lb, ub] (depth):
[-0.01896,   inf] (29), [-0.01896,   inf] (27), [-0.01896,   inf] (21), [-0.01896,   inf] (33), [-0.01896,   inf] (25), [-0.01895,   inf] (27), [-0.01895,   inf] (27), [-0.01894,   inf] (23), [-0.01894,   inf] (25), [-0.01894,   inf] (25), [-0.01893,   inf] (23), [-0.01893,   inf] (31), [-0.01892,   inf] (23), [-0.01892,   inf] (25), [-0.01891,   inf] (29), [-0.01891,   inf] (35), [-0.01891,   inf] (31), [-0.01891,   inf] (23), [-0.01891,   inf] (19), [-0.01891,   inf] (25), 
length of domains: 3497
Total time: 1.0574	 pickout: 0.0746	 decision: 0.0944	 get_bound: 0.8815	 add_domain: 0.0070
Current lb:-0.01896435022354126
11386 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 100.97119688987732

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 424] [5, 320] [5, 218] [4, 53] [5, 460] [5, 424] [4, 324] [5, 320] [5, 320] [4, 324] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.25271984934806824 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.1706180572509766, 24.13153839111328]
alpha/beta optimization time: 0.7847545146942139
This batch time : update_bounds func: 0.8727	 prepare: 0.0226	 bound: 0.7852	 transfer: 0.0485	 finalize: 0.0160
Accumulated time: update_bounds func: 81.9360	 prepare: 2.1249	 bound: 73.6221	 transfer: 0.0485	 finalize: 1.7803
batch bounding time:  0.873161792755127
Current worst splitting domains [lb, ub] (depth):
[-0.01873,   inf] (33), [-0.01872,   inf] (23), [-0.01872,   inf] (29), [-0.01872,   inf] (25), [-0.01871,   inf] (21), [-0.01871,   inf] (21), [-0.01871,   inf] (17), [-0.01871,   inf] (27), [-0.01871,   inf] (31), [-0.01870,   inf] (33), [-0.01870,   inf] (17), [-0.01869,   inf] (33), [-0.01869,   inf] (33), [-0.01869,   inf] (19), [-0.01868,   inf] (29), [-0.01868,   inf] (29), [-0.01868,   inf] (31), [-0.01867,   inf] (23), [-0.01867,   inf] (29), [-0.01866,   inf] (29), 
length of domains: 3507
Total time: 1.0261	 pickout: 0.0486	 decision: 0.0966	 get_bound: 0.8734	 add_domain: 0.0076
Current lb:-0.018726080656051636
11514 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 102.000563621521

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 106] [5, 460] [4, 53] [4, 324] [4, 53] [5, 460] [5, 219] [5, 271] [5, 106] [5, 371] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.23723961412906647 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.507999837398529, 21.383647918701172]
alpha/beta optimization time: 0.8041272163391113
This batch time : update_bounds func: 0.8905	 prepare: 0.0228	 bound: 0.8046	 transfer: 0.0457	 finalize: 0.0168
Accumulated time: update_bounds func: 82.8264	 prepare: 2.1477	 bound: 74.4267	 transfer: 0.0457	 finalize: 1.7971
batch bounding time:  0.890862226486206
Current worst splitting domains [lb, ub] (depth):
[-0.01848,   inf] (25), [-0.01848,   inf] (19), [-0.01847,   inf] (29), [-0.01847,   inf] (33), [-0.01846,   inf] (25), [-0.01846,   inf] (25), [-0.01845,   inf] (29), [-0.01845,   inf] (27), [-0.01845,   inf] (25), [-0.01844,   inf] (29), [-0.01844,   inf] (29), [-0.01844,   inf] (29), [-0.01844,   inf] (25), [-0.01844,   inf] (27), [-0.01843,   inf] (19), [-0.01843,   inf] (27), [-0.01843,   inf] (27), [-0.01842,   inf] (27), [-0.01842,   inf] (23), [-0.01842,   inf] (23), 
length of domains: 3519
Total time: 1.0502	 pickout: 0.0569	 decision: 0.0951	 get_bound: 0.8911	 add_domain: 0.0070
Current lb:-0.01848100870847702
11642 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 103.05375528335571

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 460] [5, 219] [5, 424] [5, 106] [4, 53] [5, 460] [4, 274] [5, 271] [5, 271] [5, 424] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.12089448422193527 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.6270412802696228, 19.593303680419922]
alpha/beta optimization time: 0.7848243713378906
This batch time : update_bounds func: 0.8740	 prepare: 0.0225	 bound: 0.7853	 transfer: 0.0485	 finalize: 0.0161
Accumulated time: update_bounds func: 83.7004	 prepare: 2.1702	 bound: 75.2120	 transfer: 0.0485	 finalize: 1.8132
batch bounding time:  0.8744168281555176
Current worst splitting domains [lb, ub] (depth):
[-0.01826,   inf] (29), [-0.01826,   inf] (27), [-0.01825,   inf] (31), [-0.01824,   inf] (27), [-0.01824,   inf] (27), [-0.01823,   inf] (27), [-0.01823,   inf] (25), [-0.01823,   inf] (29), [-0.01823,   inf] (19), [-0.01820,   inf] (25), [-0.01820,   inf] (27), [-0.01819,   inf] (31), [-0.01819,   inf] (27), [-0.01819,   inf] (23), [-0.01819,   inf] (29), [-0.01817,   inf] (31), [-0.01817,   inf] (31), [-0.01816,   inf] (25), [-0.01816,   inf] (29), [-0.01815,   inf] (33), 
length of domains: 3538
Total time: 1.0317	 pickout: 0.0553	 decision: 0.0942	 get_bound: 0.8747	 add_domain: 0.0075
Current lb:-0.01825603097677231
11770 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 104.08864521980286

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 424] [4, 444] [5, 271] [4, 390] [5, 320] [5, 271] [5, 320] [5, 424] [5, 218] [5, 460] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.35278409719467163 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.762451171875, 17.960620880126953]
alpha/beta optimization time: 0.8088510036468506
This batch time : update_bounds func: 0.8941	 prepare: 0.0226	 bound: 0.8093	 transfer: 0.0447	 finalize: 0.0170
Accumulated time: update_bounds func: 84.5945	 prepare: 2.1928	 bound: 76.0213	 transfer: 0.0447	 finalize: 1.8302
batch bounding time:  0.8945057392120361
Current worst splitting domains [lb, ub] (depth):
[-0.01795,   inf] (31), [-0.01795,   inf] (27), [-0.01795,   inf] (35), [-0.01795,   inf] (25), [-0.01794,   inf] (29), [-0.01794,   inf] (33), [-0.01794,   inf] (31), [-0.01794,   inf] (31), [-0.01793,   inf] (29), [-0.01793,   inf] (23), [-0.01793,   inf] (29), [-0.01793,   inf] (31), [-0.01792,   inf] (29), [-0.01792,   inf] (27), [-0.01790,   inf] (23), [-0.01790,   inf] (25), [-0.01790,   inf] (31), [-0.01790,   inf] (25), [-0.01789,   inf] (29), [-0.01788,   inf] (27), 
length of domains: 3553
Total time: 1.2184	 pickout: 0.0581	 decision: 0.2583	 get_bound: 0.8947	 add_domain: 0.0072
Current lb:-0.01795259490609169
11898 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 105.31005358695984

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 424] [4, 109] [4, 31] [4, 109] [4, 53] [5, 419] [4, 53] [4, 31] [4, 31] [5, 320] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.18192829191684723 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.5356349349021912, 22.089860916137695]
alpha/beta optimization time: 0.7858586311340332
This batch time : update_bounds func: 0.8755	 prepare: 0.0233	 bound: 0.7863	 transfer: 0.0484	 finalize: 0.0169
Accumulated time: update_bounds func: 85.4700	 prepare: 2.2161	 bound: 76.8077	 transfer: 0.0484	 finalize: 1.8471
batch bounding time:  0.8758978843688965
Current worst splitting domains [lb, ub] (depth):
[-0.01775,   inf] (25), [-0.01775,   inf] (27), [-0.01774,   inf] (27), [-0.01774,   inf] (31), [-0.01774,   inf] (27), [-0.01773,   inf] (27), [-0.01773,   inf] (29), [-0.01771,   inf] (33), [-0.01771,   inf] (29), [-0.01770,   inf] (29), [-0.01770,   inf] (31), [-0.01770,   inf] (21), [-0.01770,   inf] (25), [-0.01769,   inf] (33), [-0.01768,   inf] (19), [-0.01768,   inf] (27), [-0.01768,   inf] (29), [-0.01768,   inf] (21), [-0.01767,   inf] (25), [-0.01767,   inf] (27), 
length of domains: 3570
Total time: 1.0301	 pickout: 0.0521	 decision: 0.0944	 get_bound: 0.8761	 add_domain: 0.0075
Current lb:-0.017752736806869507
12026 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 106.34324789047241

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [4, 324] [5, 271] [4, 390] [5, 271] [5, 271] [4, 109] [4, 31] [4, 4] [5, 424] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.2163752168416977 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.9163788557052612, 23.176010131835938]
alpha/beta optimization time: 0.7913050651550293
This batch time : update_bounds func: 0.8802	 prepare: 0.0231	 bound: 0.7918	 transfer: 0.0486	 finalize: 0.0162
Accumulated time: update_bounds func: 86.3502	 prepare: 2.2392	 bound: 77.5995	 transfer: 0.0486	 finalize: 1.8633
batch bounding time:  0.8806064128875732
Current worst splitting domains [lb, ub] (depth):
[-0.01752,   inf] (27), [-0.01751,   inf] (21), [-0.01751,   inf] (25), [-0.01751,   inf] (27), [-0.01751,   inf] (31), [-0.01751,   inf] (31), [-0.01751,   inf] (25), [-0.01750,   inf] (33), [-0.01750,   inf] (25), [-0.01750,   inf] (17), [-0.01750,   inf] (25), [-0.01750,   inf] (27), [-0.01750,   inf] (25), [-0.01749,   inf] (29), [-0.01749,   inf] (29), [-0.01749,   inf] (35), [-0.01748,   inf] (31), [-0.01748,   inf] (29), [-0.01748,   inf] (21), [-0.01748,   inf] (33), 
length of domains: 3582
Total time: 1.0378	 pickout: 0.0537	 decision: 0.0963	 get_bound: 0.8808	 add_domain: 0.0070
Current lb:-0.01751963049173355
12154 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 107.38435244560242

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 390] [5, 218] [4, 324] [5, 320] [4, 390] [4, 31] [5, 320] [5, 419] [5, 218] [5, 219] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.25625503063201904 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.5166394710540771, 19.594348907470703]
alpha/beta optimization time: 0.8057584762573242
This batch time : update_bounds func: 0.9111	 prepare: 0.0355	 bound: 0.8063	 transfer: 0.0522	 finalize: 0.0166
Accumulated time: update_bounds func: 87.2614	 prepare: 2.2747	 bound: 78.4058	 transfer: 0.0522	 finalize: 1.8799
batch bounding time:  0.9115493297576904
Current worst splitting domains [lb, ub] (depth):
[-0.01728,   inf] (25), [-0.01728,   inf] (35), [-0.01728,   inf] (29), [-0.01728,   inf] (29), [-0.01727,   inf] (33), [-0.01727,   inf] (25), [-0.01727,   inf] (29), [-0.01727,   inf] (27), [-0.01726,   inf] (27), [-0.01726,   inf] (23), [-0.01726,   inf] (25), [-0.01725,   inf] (25), [-0.01725,   inf] (27), [-0.01725,   inf] (27), [-0.01724,   inf] (31), [-0.01724,   inf] (25), [-0.01724,   inf] (23), [-0.01724,   inf] (33), [-0.01724,   inf] (25), [-0.01724,   inf] (27), 
length of domains: 3603
Total time: 1.1210	 pickout: 0.0946	 decision: 0.1070	 get_bound: 0.9118	 add_domain: 0.0077
Current lb:-0.017284393310546875
12282 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 108.50842666625977

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 324] [5, 419] [4, 390] [4, 4] [5, 419] [5, 218] [5, 424] [5, 320] [5, 460] [5, 320] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.15827639400959015 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.9332513213157654, 21.039119720458984]
alpha/beta optimization time: 0.7939345836639404
This batch time : update_bounds func: 0.8823	 prepare: 0.0233	 bound: 0.7944	 transfer: 0.0473	 finalize: 0.0169
Accumulated time: update_bounds func: 88.1437	 prepare: 2.2979	 bound: 79.2002	 transfer: 0.0473	 finalize: 1.8967
batch bounding time:  0.8827271461486816
Current worst splitting domains [lb, ub] (depth):
[-0.01707,   inf] (27), [-0.01707,   inf] (21), [-0.01707,   inf] (21), [-0.01707,   inf] (23), [-0.01707,   inf] (29), [-0.01706,   inf] (25), [-0.01706,   inf] (27), [-0.01706,   inf] (25), [-0.01705,   inf] (29), [-0.01705,   inf] (27), [-0.01705,   inf] (25), [-0.01705,   inf] (25), [-0.01705,   inf] (29), [-0.01705,   inf] (31), [-0.01704,   inf] (29), [-0.01704,   inf] (29), [-0.01704,   inf] (21), [-0.01703,   inf] (19), [-0.01703,   inf] (27), [-0.01702,   inf] (31), 
length of domains: 3616
Total time: 1.0392	 pickout: 0.0546	 decision: 0.0946	 get_bound: 0.8830	 add_domain: 0.0070
Current lb:-0.017073044553399086
12410 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 109.55111956596375

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 109] [5, 218] [5, 218] [5, 460] [4, 311] [5, 460] [4, 109] [5, 271] [4, 31] [4, 109] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.023287925869226456 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.29347625374794006, 22.695552825927734]
alpha/beta optimization time: 0.7789306640625
This batch time : update_bounds func: 0.8672	 prepare: 0.0225	 bound: 0.7794	 transfer: 0.0489	 finalize: 0.0160
Accumulated time: update_bounds func: 89.0109	 prepare: 2.3204	 bound: 79.9796	 transfer: 0.0489	 finalize: 1.9127
batch bounding time:  0.8676457405090332
Current worst splitting domains [lb, ub] (depth):
[-0.01681,   inf] (25), [-0.01680,   inf] (27), [-0.01680,   inf] (31), [-0.01680,   inf] (33), [-0.01680,   inf] (31), [-0.01679,   inf] (35), [-0.01679,   inf] (27), [-0.01678,   inf] (19), [-0.01677,   inf] (25), [-0.01677,   inf] (29), [-0.01677,   inf] (29), [-0.01676,   inf] (25), [-0.01675,   inf] (35), [-0.01674,   inf] (33), [-0.01674,   inf] (29), [-0.01674,   inf] (25), [-0.01674,   inf] (25), [-0.01674,   inf] (33), [-0.01673,   inf] (27), [-0.01673,   inf] (25), 
length of domains: 3627
Total time: 1.0257	 pickout: 0.0543	 decision: 0.0956	 get_bound: 0.8679	 add_domain: 0.0079
Current lb:-0.016811519861221313
12538 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 110.58004546165466

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 460] [5, 320] [5, 419] [5, 419] [4, 31] [4, 31] [4, 54] [5, 218] [5, 271] [4, 53] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.04239151254296303 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.1754040718078613, 17.608739852905273]
alpha/beta optimization time: 0.8017704486846924
This batch time : update_bounds func: 0.8977	 prepare: 0.0225	 bound: 0.8023	 transfer: 0.0492	 finalize: 0.0232
Accumulated time: update_bounds func: 89.9086	 prepare: 2.3429	 bound: 80.7819	 transfer: 0.0492	 finalize: 1.9359
batch bounding time:  0.8981053829193115
Current worst splitting domains [lb, ub] (depth):
[-0.01659,   inf] (29), [-0.01658,   inf] (27), [-0.01658,   inf] (27), [-0.01658,   inf] (25), [-0.01657,   inf] (25), [-0.01656,   inf] (25), [-0.01655,   inf] (25), [-0.01654,   inf] (23), [-0.01654,   inf] (23), [-0.01654,   inf] (35), [-0.01652,   inf] (29), [-0.01652,   inf] (33), [-0.01652,   inf] (29), [-0.01651,   inf] (23), [-0.01651,   inf] (29), [-0.01650,   inf] (25), [-0.01650,   inf] (21), [-0.01650,   inf] (27), [-0.01649,   inf] (29), [-0.01649,   inf] (25), 
length of domains: 3639
Total time: 1.0645	 pickout: 0.0646	 decision: 0.0941	 get_bound: 0.8983	 add_domain: 0.0074
Current lb:-0.016587674617767334
12666 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 111.64766693115234

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 271] [5, 271] [5, 320] [5, 218] [5, 460] [5, 218] [5, 218] [5, 218] [5, 320] [5, 419] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.02958693355321884 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.3671375811100006, 23.18160629272461]
alpha/beta optimization time: 0.8273839950561523
This batch time : update_bounds func: 0.9320	 prepare: 0.0341	 bound: 0.8280	 transfer: 0.0519	 finalize: 0.0175
Accumulated time: update_bounds func: 90.8405	 prepare: 2.3770	 bound: 81.6099	 transfer: 0.0519	 finalize: 1.9535
batch bounding time:  0.9323968887329102
Current worst splitting domains [lb, ub] (depth):
[-0.01635,   inf] (27), [-0.01634,   inf] (25), [-0.01633,   inf] (33), [-0.01633,   inf] (19), [-0.01632,   inf] (25), [-0.01632,   inf] (33), [-0.01632,   inf] (27), [-0.01632,   inf] (23), [-0.01632,   inf] (27), [-0.01630,   inf] (29), [-0.01630,   inf] (33), [-0.01629,   inf] (29), [-0.01629,   inf] (25), [-0.01629,   inf] (23), [-0.01629,   inf] (35), [-0.01628,   inf] (35), [-0.01627,   inf] (19), [-0.01626,   inf] (31), [-0.01626,   inf] (29), [-0.01626,   inf] (25), 
length of domains: 3647
Total time: 1.1050	 pickout: 0.0619	 decision: 0.1039	 get_bound: 0.9326	 add_domain: 0.0066
Current lb:-0.01635163277387619
12794 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 112.75628089904785

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [4, 324] [5, 106] [5, 219] [5, 271] [4, 31] [4, 390] [5, 460] [4, 53] [5, 424] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.1448209285736084 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.4077887535095215, 22.328691482543945]
alpha/beta optimization time: 0.8197293281555176
This batch time : update_bounds func: 0.9130	 prepare: 0.0229	 bound: 0.8202	 transfer: 0.0530	 finalize: 0.0164
Accumulated time: update_bounds func: 91.7536	 prepare: 2.4000	 bound: 82.4301	 transfer: 0.0530	 finalize: 1.9698
batch bounding time:  0.9135284423828125
Current worst splitting domains [lb, ub] (depth):
[-0.01608,   inf] (33), [-0.01608,   inf] (33), [-0.01608,   inf] (23), [-0.01606,   inf] (27), [-0.01606,   inf] (33), [-0.01605,   inf] (31), [-0.01605,   inf] (23), [-0.01605,   inf] (33), [-0.01605,   inf] (29), [-0.01605,   inf] (25), [-0.01604,   inf] (29), [-0.01603,   inf] (29), [-0.01603,   inf] (29), [-0.01603,   inf] (25), [-0.01603,   inf] (33), [-0.01603,   inf] (31), [-0.01602,   inf] (31), [-0.01602,   inf] (29), [-0.01602,   inf] (19), [-0.01602,   inf] (19), 
length of domains: 3653
Total time: 1.0726	 pickout: 0.0532	 decision: 0.0971	 get_bound: 0.9138	 add_domain: 0.0085
Current lb:-0.016078544780611992
12922 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 113.83316802978516

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 106] [4, 31] [5, 218] [5, 271] [4, 31] [5, 419] [5, 320] [5, 106] [5, 271] [5, 320] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 0.06506557762622833 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.1219525337219238, 18.36398696899414]
alpha/beta optimization time: 0.7840166091918945
This batch time : update_bounds func: 0.8733	 prepare: 0.0230	 bound: 0.7845	 transfer: 0.0483	 finalize: 0.0170
Accumulated time: update_bounds func: 92.6269	 prepare: 2.4230	 bound: 83.2146	 transfer: 0.0483	 finalize: 1.9868
batch bounding time:  0.8737256526947021
Current worst splitting domains [lb, ub] (depth):
[-0.01586,   inf] (25), [-0.01586,   inf] (19), [-0.01586,   inf] (21), [-0.01585,   inf] (27), [-0.01585,   inf] (25), [-0.01585,   inf] (25), [-0.01584,   inf] (31), [-0.01584,   inf] (27), [-0.01583,   inf] (25), [-0.01583,   inf] (25), [-0.01583,   inf] (27), [-0.01582,   inf] (37), [-0.01582,   inf] (33), [-0.01582,   inf] (37), [-0.01582,   inf] (29), [-0.01581,   inf] (29), [-0.01581,   inf] (31), [-0.01581,   inf] (25), [-0.01581,   inf] (23), [-0.01581,   inf] (25), 
length of domains: 3664
Total time: 1.0309	 pickout: 0.0543	 decision: 0.0957	 get_bound: 0.8740	 add_domain: 0.0069
Current lb:-0.015857838094234467
13050 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 114.8671669960022

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [5, 218] [5, 218] [4, 31] [5, 320] [5, 320] [4, 444] [5, 271] [5, 218] [5, 320] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.024333909153938293 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.6389455199241638, 20.427019119262695]
alpha/beta optimization time: 0.7831902503967285
This batch time : update_bounds func: 0.8725	 prepare: 0.0225	 bound: 0.7837	 transfer: 0.0485	 finalize: 0.0174
Accumulated time: update_bounds func: 93.4994	 prepare: 2.4455	 bound: 83.9982	 transfer: 0.0485	 finalize: 2.0042
batch bounding time:  0.8729524612426758
Current worst splitting domains [lb, ub] (depth):
[-0.01566,   inf] (37), [-0.01566,   inf] (23), [-0.01566,   inf] (37), [-0.01565,   inf] (19), [-0.01564,   inf] (23), [-0.01564,   inf] (29), [-0.01562,   inf] (27), [-0.01562,   inf] (29), [-0.01561,   inf] (33), [-0.01561,   inf] (37), [-0.01561,   inf] (35), [-0.01561,   inf] (21), [-0.01561,   inf] (27), [-0.01559,   inf] (33), [-0.01558,   inf] (31), [-0.01558,   inf] (23), [-0.01558,   inf] (33), [-0.01558,   inf] (35), [-0.01557,   inf] (27), [-0.01557,   inf] (25), 
length of domains: 3675
Total time: 1.0284	 pickout: 0.0530	 decision: 0.0952	 get_bound: 0.8732	 add_domain: 0.0069
Current lb:-0.01566489227116108
13178 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 115.8989486694336

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 106] [5, 320] [4, 390] [5, 219] [4, 53] [5, 424] [5, 320] [5, 424] [4, 31] [5, 106] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.29566270112991333 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.2396163940429688, 17.17043113708496]
alpha/beta optimization time: 0.7830920219421387
This batch time : update_bounds func: 0.8714	 prepare: 0.0227	 bound: 0.7836	 transfer: 0.0485	 finalize: 0.0163
Accumulated time: update_bounds func: 94.3708	 prepare: 2.4681	 bound: 84.7818	 transfer: 0.0485	 finalize: 2.0205
batch bounding time:  0.8718087673187256
Current worst splitting domains [lb, ub] (depth):
[-0.01542,   inf] (31), [-0.01542,   inf] (29), [-0.01541,   inf] (31), [-0.01541,   inf] (27), [-0.01541,   inf] (27), [-0.01540,   inf] (33), [-0.01540,   inf] (25), [-0.01540,   inf] (27), [-0.01539,   inf] (33), [-0.01539,   inf] (23), [-0.01539,   inf] (23), [-0.01539,   inf] (29), [-0.01539,   inf] (31), [-0.01538,   inf] (33), [-0.01538,   inf] (29), [-0.01537,   inf] (29), [-0.01536,   inf] (33), [-0.01535,   inf] (19), [-0.01535,   inf] (29), [-0.01535,   inf] (35), 
length of domains: 3679
Total time: 1.0390	 pickout: 0.0627	 decision: 0.0966	 get_bound: 0.8721	 add_domain: 0.0076
Current lb:-0.015419037081301212
13306 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 116.94115114212036

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 31] [5, 424] [5, 106] [4, 324] [4, 53] [4, 31] [5, 320] [4, 53] [4, 31] [5, 218] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.23106394708156586 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.2567983865737915, 23.073347091674805]
alpha/beta optimization time: 0.779656171798706
This batch time : update_bounds func: 0.8736	 prepare: 0.0223	 bound: 0.7801	 transfer: 0.0483	 finalize: 0.0225
Accumulated time: update_bounds func: 95.2443	 prepare: 2.4904	 bound: 85.5620	 transfer: 0.0483	 finalize: 2.0429
batch bounding time:  0.8740038871765137
Current worst splitting domains [lb, ub] (depth):
[-0.01516,   inf] (27), [-0.01515,   inf] (31), [-0.01515,   inf] (27), [-0.01515,   inf] (23), [-0.01515,   inf] (33), [-0.01515,   inf] (33), [-0.01515,   inf] (21), [-0.01514,   inf] (25), [-0.01514,   inf] (25), [-0.01514,   inf] (19), [-0.01513,   inf] (29), [-0.01513,   inf] (31), [-0.01513,   inf] (27), [-0.01513,   inf] (31), [-0.01512,   inf] (33), [-0.01512,   inf] (31), [-0.01511,   inf] (29), [-0.01511,   inf] (33), [-0.01511,   inf] (35), [-0.01509,   inf] (25), 
length of domains: 3683
Total time: 1.1773	 pickout: 0.0493	 decision: 0.2474	 get_bound: 0.8742	 add_domain: 0.0064
Current lb:-0.015160858631134033
13434 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 118.12228846549988

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 390] [5, 106] [4, 109] [5, 460] [5, 106] [4, 31] [5, 218] [4, 274] [5, 320] [5, 218] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.14990979433059692 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.22162331640720367, 18.969890594482422]
alpha/beta optimization time: 0.7979955673217773
This batch time : update_bounds func: 0.8703	 prepare: 0.0238	 bound: 0.7985	 transfer: 0.0298	 finalize: 0.0176
Accumulated time: update_bounds func: 96.1147	 prepare: 2.5142	 bound: 86.3605	 transfer: 0.0298	 finalize: 2.0605
batch bounding time:  0.8707759380340576
Current worst splitting domains [lb, ub] (depth):
[-0.01491,   inf] (31), [-0.01490,   inf] (27), [-0.01490,   inf] (25), [-0.01490,   inf] (33), [-0.01490,   inf] (31), [-0.01489,   inf] (33), [-0.01489,   inf] (23), [-0.01489,   inf] (31), [-0.01488,   inf] (27), [-0.01488,   inf] (35), [-0.01487,   inf] (25), [-0.01487,   inf] (31), [-0.01486,   inf] (27), [-0.01486,   inf] (29), [-0.01485,   inf] (17), [-0.01485,   inf] (33), [-0.01485,   inf] (37), [-0.01485,   inf] (21), [-0.01484,   inf] (33), [-0.01484,   inf] (29), 
length of domains: 3690
Total time: 1.0366	 pickout: 0.0607	 decision: 0.0982	 get_bound: 0.8710	 add_domain: 0.0067
Current lb:-0.014906145632266998
13562 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 119.16251349449158

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 424] [5, 424] [5, 320] [5, 106] [5, 424] [4, 288] [4, 53] [4, 53] [4, 109] [5, 106] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.025780169293284416 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.5841618776321411, 20.023639678955078]
alpha/beta optimization time: 0.7789366245269775
This batch time : update_bounds func: 0.8698	 prepare: 0.0223	 bound: 0.7794	 transfer: 0.0514	 finalize: 0.0163
Accumulated time: update_bounds func: 96.9845	 prepare: 2.5365	 bound: 87.1398	 transfer: 0.0514	 finalize: 2.0768
batch bounding time:  0.8703267574310303
Current worst splitting domains [lb, ub] (depth):
[-0.01468,   inf] (23), [-0.01468,   inf] (23), [-0.01468,   inf] (35), [-0.01467,   inf] (25), [-0.01466,   inf] (25), [-0.01466,   inf] (21), [-0.01466,   inf] (33), [-0.01466,   inf] (29), [-0.01465,   inf] (23), [-0.01465,   inf] (25), [-0.01464,   inf] (17), [-0.01464,   inf] (33), [-0.01464,   inf] (29), [-0.01464,   inf] (25), [-0.01464,   inf] (29), [-0.01463,   inf] (27), [-0.01463,   inf] (23), [-0.01463,   inf] (23), [-0.01463,   inf] (21), [-0.01463,   inf] (27), 
length of domains: 3701
Total time: 1.0245	 pickout: 0.0517	 decision: 0.0951	 get_bound: 0.8706	 add_domain: 0.0071
Current lb:-0.014680057764053345
13690 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 120.19017434120178

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 218] [5, 460] [5, 419] [5, 320] [4, 31] [5, 218] [5, 419] [5, 424] [5, 460] [5, 218] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.16481804847717285 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.2995913028717041, 19.970293045043945]
alpha/beta optimization time: 0.7859306335449219
This batch time : update_bounds func: 0.8785	 prepare: 0.0230	 bound: 0.7864	 transfer: 0.0514	 finalize: 0.0173
Accumulated time: update_bounds func: 97.8630	 prepare: 2.5595	 bound: 87.9263	 transfer: 0.0514	 finalize: 2.0941
batch bounding time:  0.8789124488830566
Current worst splitting domains [lb, ub] (depth):
[-0.01446,   inf] (29), [-0.01445,   inf] (25), [-0.01444,   inf] (33), [-0.01444,   inf] (31), [-0.01444,   inf] (31), [-0.01444,   inf] (25), [-0.01443,   inf] (27), [-0.01443,   inf] (33), [-0.01442,   inf] (25), [-0.01442,   inf] (37), [-0.01441,   inf] (35), [-0.01441,   inf] (21), [-0.01441,   inf] (19), [-0.01441,   inf] (33), [-0.01440,   inf] (31), [-0.01439,   inf] (29), [-0.01439,   inf] (27), [-0.01438,   inf] (23), [-0.01437,   inf] (23), [-0.01437,   inf] (29), 
length of domains: 3713
Total time: 1.0356	 pickout: 0.0536	 decision: 0.0958	 get_bound: 0.8791	 add_domain: 0.0070
Current lb:-0.01445759180933237
13818 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 121.22923731803894

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 424] [5, 460] [4, 31] [4, 390] [4, 274] [5, 218] [5, 320] [5, 419] [5, 218] [5, 371] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.25028321146965027 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.637802004814148, 19.799854278564453]
alpha/beta optimization time: 0.790215253829956
This batch time : update_bounds func: 0.8890	 prepare: 0.0231	 bound: 0.7907	 transfer: 0.0505	 finalize: 0.0241
Accumulated time: update_bounds func: 98.7520	 prepare: 2.5826	 bound: 88.7170	 transfer: 0.0505	 finalize: 2.1183
batch bounding time:  0.8894808292388916
Current worst splitting domains [lb, ub] (depth):
[-0.01419,   inf] (29), [-0.01419,   inf] (33), [-0.01418,   inf] (19), [-0.01418,   inf] (33), [-0.01418,   inf] (23), [-0.01418,   inf] (31), [-0.01418,   inf] (35), [-0.01417,   inf] (27), [-0.01417,   inf] (37), [-0.01417,   inf] (25), [-0.01416,   inf] (27), [-0.01415,   inf] (37), [-0.01415,   inf] (29), [-0.01414,   inf] (29), [-0.01413,   inf] (35), [-0.01413,   inf] (37), [-0.01413,   inf] (29), [-0.01413,   inf] (35), [-0.01412,   inf] (33), [-0.01412,   inf] (31), 
length of domains: 3717
Total time: 1.0704	 pickout: 0.0644	 decision: 0.1099	 get_bound: 0.8897	 add_domain: 0.0064
Current lb:-0.014188265427947044
13946 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 122.30317664146423

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 424] [4, 390] [4, 53] [5, 419] [5, 218] [4, 31] [5, 419] [5, 271] [5, 371] [4, 255] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.1183934360742569 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.5988509058952332, 19.15428352355957]
alpha/beta optimization time: 0.7978560924530029
This batch time : update_bounds func: 0.8642	 prepare: 0.0228	 bound: 0.7984	 transfer: 0.0261	 finalize: 0.0164
Accumulated time: update_bounds func: 99.6162	 prepare: 2.6054	 bound: 89.5154	 transfer: 0.0261	 finalize: 2.1347
batch bounding time:  0.8645849227905273
Current worst splitting domains [lb, ub] (depth):
[-0.01395,   inf] (35), [-0.01394,   inf] (27), [-0.01393,   inf] (27), [-0.01393,   inf] (27), [-0.01393,   inf] (31), [-0.01393,   inf] (29), [-0.01392,   inf] (29), [-0.01391,   inf] (17), [-0.01391,   inf] (29), [-0.01390,   inf] (29), [-0.01390,   inf] (25), [-0.01390,   inf] (25), [-0.01390,   inf] (29), [-0.01390,   inf] (27), [-0.01389,   inf] (27), [-0.01389,   inf] (35), [-0.01389,   inf] (23), [-0.01389,   inf] (31), [-0.01388,   inf] (27), [-0.01388,   inf] (23), 
length of domains: 3728
Total time: 1.0223	 pickout: 0.0536	 decision: 0.0966	 get_bound: 0.8648	 add_domain: 0.0073
Current lb:-0.013948929496109486
14074 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 123.32927465438843

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 31] [5, 271] [4, 390] [4, 390] [4, 31] [5, 424] [5, 460] [5, 219] [4, 109] [4, 53] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.20461022853851318 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.4801012873649597, 20.628931045532227]
alpha/beta optimization time: 0.7836616039276123
This batch time : update_bounds func: 0.8756	 prepare: 0.0228	 bound: 0.7841	 transfer: 0.0515	 finalize: 0.0168
Accumulated time: update_bounds func: 100.4918	 prepare: 2.6282	 bound: 90.2995	 transfer: 0.0515	 finalize: 2.1514
batch bounding time:  0.8760466575622559
Current worst splitting domains [lb, ub] (depth):
[-0.01370,   inf] (27), [-0.01370,   inf] (29), [-0.01370,   inf] (31), [-0.01368,   inf] (29), [-0.01368,   inf] (17), [-0.01368,   inf] (35), [-0.01367,   inf] (27), [-0.01366,   inf] (25), [-0.01366,   inf] (27), [-0.01365,   inf] (31), [-0.01365,   inf] (35), [-0.01365,   inf] (33), [-0.01365,   inf] (25), [-0.01365,   inf] (31), [-0.01364,   inf] (35), [-0.01364,   inf] (31), [-0.01364,   inf] (25), [-0.01364,   inf] (19), [-0.01363,   inf] (29), [-0.01363,   inf] (27), 
length of domains: 3730
Total time: 1.0361	 pickout: 0.0572	 decision: 0.0963	 get_bound: 0.8763	 add_domain: 0.0063
Current lb:-0.01369873434305191
14202 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 124.36901473999023

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [4, 109] [4, 31] [5, 460] [5, 219] [4, 31] [5, 271] [5, 460] [5, 320] [5, 424] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.2027784287929535 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.9783689975738525, 15.340462684631348]
alpha/beta optimization time: 0.786221981048584
This batch time : update_bounds func: 0.8799	 prepare: 0.0236	 bound: 0.7867	 transfer: 0.0518	 finalize: 0.0172
Accumulated time: update_bounds func: 101.3717	 prepare: 2.6518	 bound: 91.0862	 transfer: 0.0518	 finalize: 2.1686
batch bounding time:  0.8803133964538574
Current worst splitting domains [lb, ub] (depth):
[-0.01350,   inf] (27), [-0.01349,   inf] (31), [-0.01349,   inf] (33), [-0.01349,   inf] (31), [-0.01348,   inf] (23), [-0.01348,   inf] (27), [-0.01348,   inf] (27), [-0.01348,   inf] (31), [-0.01348,   inf] (31), [-0.01348,   inf] (27), [-0.01347,   inf] (25), [-0.01347,   inf] (23), [-0.01347,   inf] (35), [-0.01347,   inf] (27), [-0.01347,   inf] (31), [-0.01347,   inf] (29), [-0.01346,   inf] (27), [-0.01346,   inf] (33), [-0.01346,   inf] (33), [-0.01346,   inf] (31), 
length of domains: 3736
Total time: 1.0372	 pickout: 0.0548	 decision: 0.0951	 get_bound: 0.8806	 add_domain: 0.0068
Current lb:-0.013497278094291687
14330 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 125.4094705581665

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 460] [4, 444] [4, 390] [5, 106] [5, 218] [5, 320] [5, 320] [5, 271] [4, 53] [4, 311] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.4147912263870239 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.33383291959762573, 20.443397521972656]
alpha/beta optimization time: 0.7832736968994141
This batch time : update_bounds func: 0.8758	 prepare: 0.0234	 bound: 0.7837	 transfer: 0.0519	 finalize: 0.0161
Accumulated time: update_bounds func: 102.2475	 prepare: 2.6752	 bound: 91.8699	 transfer: 0.0519	 finalize: 2.1848
batch bounding time:  0.8762204647064209
Current worst splitting domains [lb, ub] (depth):
[-0.01328,   inf] (23), [-0.01328,   inf] (33), [-0.01328,   inf] (33), [-0.01326,   inf] (31), [-0.01326,   inf] (23), [-0.01326,   inf] (27), [-0.01325,   inf] (27), [-0.01325,   inf] (37), [-0.01325,   inf] (23), [-0.01324,   inf] (31), [-0.01324,   inf] (19), [-0.01324,   inf] (25), [-0.01323,   inf] (29), [-0.01323,   inf] (29), [-0.01323,   inf] (35), [-0.01322,   inf] (29), [-0.01322,   inf] (25), [-0.01322,   inf] (33), [-0.01321,   inf] (37), [-0.01321,   inf] (35), 
length of domains: 3737
Total time: 1.0321	 pickout: 0.0534	 decision: 0.0959	 get_bound: 0.8765	 add_domain: 0.0063
Current lb:-0.01328471302986145
14458 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 126.445556640625

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 218] [5, 106] [5, 106] [5, 424] [5, 218] [5, 271] [4, 109] [5, 106] [4, 288] [4, 324] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.3876174986362457 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.6541643738746643, 18.175552368164062]
alpha/beta optimization time: 0.781940221786499
This batch time : update_bounds func: 0.8743	 prepare: 0.0226	 bound: 0.7824	 transfer: 0.0517	 finalize: 0.0172
Accumulated time: update_bounds func: 103.1218	 prepare: 2.6978	 bound: 92.6524	 transfer: 0.0517	 finalize: 2.2019
batch bounding time:  0.8747439384460449
Current worst splitting domains [lb, ub] (depth):
[-0.01308,   inf] (31), [-0.01307,   inf] (25), [-0.01307,   inf] (29), [-0.01307,   inf] (31), [-0.01306,   inf] (27), [-0.01306,   inf] (19), [-0.01306,   inf] (31), [-0.01306,   inf] (27), [-0.01306,   inf] (33), [-0.01306,   inf] (29), [-0.01306,   inf] (25), [-0.01305,   inf] (33), [-0.01304,   inf] (29), [-0.01304,   inf] (33), [-0.01303,   inf] (31), [-0.01303,   inf] (33), [-0.01303,   inf] (27), [-0.01302,   inf] (27), [-0.01302,   inf] (25), [-0.01302,   inf] (25), 
length of domains: 3743
Total time: 1.0292	 pickout: 0.0526	 decision: 0.0949	 get_bound: 0.8750	 add_domain: 0.0066
Current lb:-0.013080079108476639
14586 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 127.47805094718933

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 31] [5, 320] [5, 271] [4, 53] [5, 460] [5, 219] [4, 53] [5, 271] [4, 31] [5, 424] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.388844758272171 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.417319893836975, 20.155555725097656]
alpha/beta optimization time: 0.8075425624847412
This batch time : update_bounds func: 0.9008	 prepare: 0.0228	 bound: 0.8080	 transfer: 0.0520	 finalize: 0.0175
Accumulated time: update_bounds func: 104.0226	 prepare: 2.7207	 bound: 93.4604	 transfer: 0.0520	 finalize: 2.2194
batch bounding time:  0.9012341499328613
Current worst splitting domains [lb, ub] (depth):
[-0.01285,   inf] (25), [-0.01284,   inf] (29), [-0.01284,   inf] (31), [-0.01284,   inf] (23), [-0.01283,   inf] (29), [-0.01283,   inf] (19), [-0.01283,   inf] (37), [-0.01282,   inf] (33), [-0.01282,   inf] (35), [-0.01282,   inf] (23), [-0.01281,   inf] (25), [-0.01281,   inf] (31), [-0.01281,   inf] (21), [-0.01281,   inf] (31), [-0.01281,   inf] (33), [-0.01280,   inf] (29), [-0.01280,   inf] (25), [-0.01280,   inf] (23), [-0.01279,   inf] (29), [-0.01278,   inf] (29), 
length of domains: 3746
Total time: 1.0544	 pickout: 0.0521	 decision: 0.0944	 get_bound: 0.9015	 add_domain: 0.0064
Current lb:-0.0128459632396698
14714 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 128.53571248054504

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 460] [5, 424] [5, 419] [5, 320] [5, 424] [5, 218] [5, 419] [5, 424] [4, 288] [4, 109] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.30065006017684937 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.1793310642242432, 20.42522430419922]
alpha/beta optimization time: 0.8149502277374268
This batch time : update_bounds func: 0.9068	 prepare: 0.0230	 bound: 0.8154	 transfer: 0.0517	 finalize: 0.0162
Accumulated time: update_bounds func: 104.9295	 prepare: 2.7437	 bound: 94.2758	 transfer: 0.0517	 finalize: 2.2356
batch bounding time:  0.9072127342224121
Current worst splitting domains [lb, ub] (depth):
[-0.01262,   inf] (31), [-0.01262,   inf] (29), [-0.01262,   inf] (27), [-0.01262,   inf] (23), [-0.01262,   inf] (25), [-0.01262,   inf] (35), [-0.01262,   inf] (29), [-0.01262,   inf] (33), [-0.01261,   inf] (27), [-0.01261,   inf] (29), [-0.01261,   inf] (33), [-0.01261,   inf] (23), [-0.01261,   inf] (29), [-0.01261,   inf] (27), [-0.01260,   inf] (29), [-0.01260,   inf] (37), [-0.01259,   inf] (33), [-0.01259,   inf] (35), [-0.01259,   inf] (23), [-0.01258,   inf] (31), 
length of domains: 3750
Total time: 1.0625	 pickout: 0.0525	 decision: 0.0958	 get_bound: 0.9075	 add_domain: 0.0068
Current lb:-0.012621045112609863
14842 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 129.60193634033203

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 390] [4, 444] [5, 424] [5, 460] [4, 302] [5, 106] [5, 424] [4, 31] [5, 320] [4, 288] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.4458617866039276 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.6689470410346985, 21.142675399780273]
alpha/beta optimization time: 0.8002378940582275
This batch time : update_bounds func: 1.0625	 prepare: 0.0245	 bound: 0.8008	 transfer: 0.0519	 finalize: 0.1846
Accumulated time: update_bounds func: 105.9920	 prepare: 2.7683	 bound: 95.0766	 transfer: 0.0519	 finalize: 2.4203
batch bounding time:  1.0630402565002441
Current worst splitting domains [lb, ub] (depth):
[-0.01241,   inf] (31), [-0.01241,   inf] (31), [-0.01238,   inf] (27), [-0.01238,   inf] (29), [-0.01238,   inf] (25), [-0.01238,   inf] (25), [-0.01238,   inf] (31), [-0.01237,   inf] (25), [-0.01237,   inf] (27), [-0.01237,   inf] (31), [-0.01237,   inf] (27), [-0.01236,   inf] (19), [-0.01236,   inf] (27), [-0.01236,   inf] (27), [-0.01236,   inf] (23), [-0.01236,   inf] (27), [-0.01235,   inf] (27), [-0.01235,   inf] (29), [-0.01235,   inf] (33), [-0.01234,   inf] (33), 
length of domains: 3753
Total time: 1.2186	 pickout: 0.0512	 decision: 0.0977	 get_bound: 1.0633	 add_domain: 0.0064
Current lb:-0.012412820011377335
14970 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 130.8243157863617

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 106] [4, 31] [4, 109] [4, 390] [5, 460] [4, 53] [4, 324] [4, 274] [5, 271] [4, 53] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.7432170510292053 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.3555352985858917, 20.624841690063477]
alpha/beta optimization time: 0.802731990814209
This batch time : update_bounds func: 0.8957	 prepare: 0.0230	 bound: 0.8032	 transfer: 0.0517	 finalize: 0.0173
Accumulated time: update_bounds func: 106.8877	 prepare: 2.7912	 bound: 95.8798	 transfer: 0.0517	 finalize: 2.4376
batch bounding time:  0.8961117267608643
Current worst splitting domains [lb, ub] (depth):
[-0.01219,   inf] (23), [-0.01219,   inf] (27), [-0.01218,   inf] (29), [-0.01218,   inf] (27), [-0.01218,   inf] (33), [-0.01217,   inf] (33), [-0.01217,   inf] (29), [-0.01216,   inf] (35), [-0.01216,   inf] (31), [-0.01215,   inf] (37), [-0.01215,   inf] (27), [-0.01215,   inf] (29), [-0.01215,   inf] (29), [-0.01215,   inf] (23), [-0.01214,   inf] (25), [-0.01213,   inf] (27), [-0.01213,   inf] (37), [-0.01213,   inf] (31), [-0.01213,   inf] (27), [-0.01213,   inf] (35), 
length of domains: 3750
Total time: 1.0595	 pickout: 0.0618	 decision: 0.0955	 get_bound: 0.8963	 add_domain: 0.0058
Current lb:-0.01219351589679718
15098 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 131.88725471496582

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 218] [4, 243] [5, 424] [4, 390] [5, 106] [4, 31] [4, 53] [4, 31] [5, 106] [4, 53] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.36146366596221924 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.8465113639831543, 19.85118293762207]
alpha/beta optimization time: 0.8193874359130859
This batch time : update_bounds func: 0.9186	 prepare: 0.0233	 bound: 0.8199	 transfer: 0.0521	 finalize: 0.0228
Accumulated time: update_bounds func: 107.8063	 prepare: 2.8145	 bound: 96.6997	 transfer: 0.0521	 finalize: 2.4604
batch bounding time:  0.919058084487915
Current worst splitting domains [lb, ub] (depth):
[-0.01197,   inf] (29), [-0.01196,   inf] (35), [-0.01196,   inf] (19), [-0.01196,   inf] (29), [-0.01196,   inf] (27), [-0.01195,   inf] (27), [-0.01194,   inf] (37), [-0.01194,   inf] (31), [-0.01193,   inf] (27), [-0.01193,   inf] (25), [-0.01193,   inf] (35), [-0.01192,   inf] (31), [-0.01191,   inf] (25), [-0.01191,   inf] (29), [-0.01191,   inf] (27), [-0.01190,   inf] (29), [-0.01190,   inf] (31), [-0.01190,   inf] (25), [-0.01189,   inf] (31), [-0.01189,   inf] (29), 
length of domains: 3752
Total time: 1.0718	 pickout: 0.0480	 decision: 0.0976	 get_bound: 0.9193	 add_domain: 0.0068
Current lb:-0.011965267360210419
15226 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 132.9627275466919

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 424] [4, 31] [5, 218] [5, 424] [4, 54] [5, 460] [4, 53] [4, 31] [4, 274] [5, 218] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.3699231743812561 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.106238842010498, 19.292320251464844]
alpha/beta optimization time: 0.7958431243896484
This batch time : update_bounds func: 0.9016	 prepare: 0.0359	 bound: 0.7965	 transfer: 0.0517	 finalize: 0.0171
Accumulated time: update_bounds func: 108.7079	 prepare: 2.8504	 bound: 97.4961	 transfer: 0.0517	 finalize: 2.4776
batch bounding time:  0.9020359516143799
Current worst splitting domains [lb, ub] (depth):
[-0.01179,   inf] (23), [-0.01179,   inf] (35), [-0.01179,   inf] (29), [-0.01179,   inf] (29), [-0.01178,   inf] (31), [-0.01178,   inf] (31), [-0.01178,   inf] (27), [-0.01178,   inf] (35), [-0.01177,   inf] (27), [-0.01176,   inf] (27), [-0.01176,   inf] (27), [-0.01175,   inf] (33), [-0.01175,   inf] (25), [-0.01175,   inf] (29), [-0.01175,   inf] (31), [-0.01174,   inf] (27), [-0.01173,   inf] (35), [-0.01173,   inf] (37), [-0.01173,   inf] (37), [-0.01173,   inf] (27), 
length of domains: 3752
Total time: 1.0755	 pickout: 0.0614	 decision: 0.1056	 get_bound: 0.9023	 add_domain: 0.0062
Current lb:-0.011791794560849667
15354 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 134.04186058044434

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 31] [4, 444] [5, 424] [4, 53] [5, 419] [5, 106] [4, 109] [5, 106] [5, 271] [4, 324] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.731212854385376 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.5084301829338074, 22.262313842773438]
alpha/beta optimization time: 0.788170337677002
This batch time : update_bounds func: 0.8816	 prepare: 0.0228	 bound: 0.7887	 transfer: 0.0521	 finalize: 0.0175
Accumulated time: update_bounds func: 109.5895	 prepare: 2.8732	 bound: 98.2848	 transfer: 0.0521	 finalize: 2.4951
batch bounding time:  0.8820383548736572
Current worst splitting domains [lb, ub] (depth):
[-0.01159,   inf] (27), [-0.01158,   inf] (25), [-0.01158,   inf] (27), [-0.01158,   inf] (27), [-0.01157,   inf] (33), [-0.01157,   inf] (15), [-0.01157,   inf] (19), [-0.01157,   inf] (35), [-0.01157,   inf] (25), [-0.01157,   inf] (31), [-0.01156,   inf] (23), [-0.01156,   inf] (23), [-0.01156,   inf] (23), [-0.01155,   inf] (17), [-0.01155,   inf] (29), [-0.01154,   inf] (23), [-0.01154,   inf] (27), [-0.01154,   inf] (29), [-0.01152,   inf] (19), [-0.01151,   inf] (33), 
length of domains: 3744
Total time: 1.0349	 pickout: 0.0520	 decision: 0.0950	 get_bound: 0.8823	 add_domain: 0.0056
Current lb:-0.011586287058889866
15482 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 135.08069968223572

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 109] [5, 320] [5, 460] [4, 324] [4, 31] [5, 17] [5, 218] [4, 53] [5, 460] [4, 390] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.7400254011154175 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.4498952031135559, 22.457969665527344]
alpha/beta optimization time: 0.8026318550109863
This batch time : update_bounds func: 0.8955	 prepare: 0.0231	 bound: 0.8031	 transfer: 0.0522	 finalize: 0.0167
Accumulated time: update_bounds func: 110.4850	 prepare: 2.8963	 bound: 99.0879	 transfer: 0.0522	 finalize: 2.5118
batch bounding time:  0.8959462642669678
Current worst splitting domains [lb, ub] (depth):
[-0.01139,   inf] (27), [-0.01139,   inf] (23), [-0.01139,   inf] (27), [-0.01138,   inf] (37), [-0.01138,   inf] (25), [-0.01137,   inf] (23), [-0.01137,   inf] (27), [-0.01137,   inf] (31), [-0.01136,   inf] (37), [-0.01136,   inf] (27), [-0.01135,   inf] (33), [-0.01135,   inf] (31), [-0.01135,   inf] (19), [-0.01134,   inf] (33), [-0.01134,   inf] (33), [-0.01134,   inf] (29), [-0.01134,   inf] (35), [-0.01133,   inf] (25), [-0.01132,   inf] (17), [-0.01132,   inf] (25), 
length of domains: 3731
Total time: 1.0624	 pickout: 0.0650	 decision: 0.0961	 get_bound: 0.8962	 add_domain: 0.0051
Current lb:-0.011392217129468918
15610 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 136.14705681800842

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 424] [4, 274] [5, 460] [5, 106] [4, 390] [5, 320] [5, 271] [4, 31] [5, 371] [4, 53] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.47566285729408264 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.3815670311450958, 21.66378402709961]
alpha/beta optimization time: 0.7995638847351074
This batch time : update_bounds func: 0.8934	 prepare: 0.0230	 bound: 0.8001	 transfer: 0.0518	 finalize: 0.0181
Accumulated time: update_bounds func: 111.3784	 prepare: 2.9193	 bound: 99.8880	 transfer: 0.0518	 finalize: 2.5300
batch bounding time:  0.8938727378845215
Current worst splitting domains [lb, ub] (depth):
[-0.01116,   inf] (31), [-0.01116,   inf] (31), [-0.01116,   inf] (29), [-0.01116,   inf] (25), [-0.01116,   inf] (27), [-0.01116,   inf] (19), [-0.01116,   inf] (35), [-0.01116,   inf] (21), [-0.01116,   inf] (27), [-0.01115,   inf] (27), [-0.01115,   inf] (31), [-0.01115,   inf] (25), [-0.01115,   inf] (19), [-0.01115,   inf] (35), [-0.01114,   inf] (27), [-0.01114,   inf] (29), [-0.01113,   inf] (27), [-0.01113,   inf] (19), [-0.01111,   inf] (29), [-0.01111,   inf] (19), 
length of domains: 3722
Total time: 1.0475	 pickout: 0.0522	 decision: 0.0956	 get_bound: 0.8941	 add_domain: 0.0056
Current lb:-0.011162921786308289
15738 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 137.1985204219818

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 424] [4, 53] [5, 424] [5, 320] [5, 320] [5, 219] [4, 31] [5, 218] [4, 109] [5, 218] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.6197024583816528 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.6445255279541016, 19.48354721069336]
alpha/beta optimization time: 0.7984728813171387
This batch time : update_bounds func: 0.8933	 prepare: 0.0242	 bound: 0.7990	 transfer: 0.0520	 finalize: 0.0176
Accumulated time: update_bounds func: 112.2717	 prepare: 2.9435	 bound: 100.6869	 transfer: 0.0520	 finalize: 2.5476
batch bounding time:  0.8936741352081299
Current worst splitting domains [lb, ub] (depth):
[-0.01099,   inf] (21), [-0.01099,   inf] (27), [-0.01098,   inf] (33), [-0.01098,   inf] (33), [-0.01097,   inf] (21), [-0.01097,   inf] (33), [-0.01096,   inf] (31), [-0.01096,   inf] (37), [-0.01095,   inf] (29), [-0.01094,   inf] (27), [-0.01094,   inf] (31), [-0.01094,   inf] (31), [-0.01093,   inf] (29), [-0.01093,   inf] (35), [-0.01093,   inf] (31), [-0.01093,   inf] (33), [-0.01092,   inf] (33), [-0.01091,   inf] (33), [-0.01091,   inf] (27), [-0.01091,   inf] (27), 
length of domains: 3709
Total time: 1.0544	 pickout: 0.0587	 decision: 0.0968	 get_bound: 0.8939	 add_domain: 0.0051
Current lb:-0.010990828275680542
15866 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 138.25645971298218

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 460] [5, 218] [4, 31] [4, 31] [5, 218] [5, 424] [4, 112] [5, 419] [5, 424] [4, 390] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.6464086771011353 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.1100354194641113, 19.14143180847168]
alpha/beta optimization time: 0.7933714389801025
This batch time : update_bounds func: 0.8854	 prepare: 0.0227	 bound: 0.7938	 transfer: 0.0518	 finalize: 0.0167
Accumulated time: update_bounds func: 113.1571	 prepare: 2.9662	 bound: 101.4808	 transfer: 0.0518	 finalize: 2.5643
batch bounding time:  0.885828971862793
Current worst splitting domains [lb, ub] (depth):
[-0.01078,   inf] (21), [-0.01078,   inf] (33), [-0.01078,   inf] (35), [-0.01078,   inf] (27), [-0.01078,   inf] (27), [-0.01078,   inf] (29), [-0.01077,   inf] (27), [-0.01077,   inf] (27), [-0.01076,   inf] (31), [-0.01075,   inf] (31), [-0.01075,   inf] (25), [-0.01075,   inf] (31), [-0.01075,   inf] (29), [-0.01075,   inf] (23), [-0.01075,   inf] (35), [-0.01074,   inf] (31), [-0.01074,   inf] (25), [-0.01073,   inf] (27), [-0.01073,   inf] (29), [-0.01073,   inf] (21), 
length of domains: 3699
Total time: 1.0373	 pickout: 0.0505	 decision: 0.0953	 get_bound: 0.8861	 add_domain: 0.0055
Current lb:-0.010784514248371124
15994 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 139.298570394516

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 302] [5, 424] [5, 106] [5, 424] [4, 390] [4, 390] [4, 53] [4, 109] [4, 390] [4, 31] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.537401020526886 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.5287202596664429, 21.207233428955078]
alpha/beta optimization time: 0.7879197597503662
This batch time : update_bounds func: 0.8821	 prepare: 0.0238	 bound: 0.7884	 transfer: 0.0518	 finalize: 0.0177
Accumulated time: update_bounds func: 114.0393	 prepare: 2.9900	 bound: 102.2692	 transfer: 0.0518	 finalize: 2.5820
batch bounding time:  0.882570743560791
Current worst splitting domains [lb, ub] (depth):
[-0.01060,   inf] (23), [-0.01060,   inf] (35), [-0.01060,   inf] (27), [-0.01060,   inf] (25), [-0.01060,   inf] (25), [-0.01059,   inf] (35), [-0.01058,   inf] (29), [-0.01058,   inf] (23), [-0.01058,   inf] (25), [-0.01058,   inf] (33), [-0.01058,   inf] (37), [-0.01057,   inf] (35), [-0.01057,   inf] (21), [-0.01057,   inf] (33), [-0.01056,   inf] (35), [-0.01055,   inf] (31), [-0.01055,   inf] (25), [-0.01055,   inf] (35), [-0.01054,   inf] (27), [-0.01054,   inf] (25), 
length of domains: 3691
Total time: 1.0375	 pickout: 0.0525	 decision: 0.0967	 get_bound: 0.8828	 add_domain: 0.0055
Current lb:-0.010601520538330078
16122 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 140.33977723121643

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [5, 106] [4, 109] [5, 271] [4, 31] [4, 31] [5, 419] [5, 320] [4, 255] [4, 53] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.6863164901733398 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.1421407461166382, 17.193889617919922]
alpha/beta optimization time: 0.7901320457458496
This batch time : update_bounds func: 0.8843	 prepare: 0.0231	 bound: 0.7906	 transfer: 0.0523	 finalize: 0.0178
Accumulated time: update_bounds func: 114.9236	 prepare: 3.0131	 bound: 103.0598	 transfer: 0.0523	 finalize: 2.5998
batch bounding time:  0.8847405910491943
Current worst splitting domains [lb, ub] (depth):
[-0.01041,   inf] (35), [-0.01040,   inf] (33), [-0.01040,   inf] (29), [-0.01040,   inf] (35), [-0.01039,   inf] (35), [-0.01039,   inf] (25), [-0.01038,   inf] (29), [-0.01038,   inf] (27), [-0.01038,   inf] (37), [-0.01038,   inf] (27), [-0.01037,   inf] (23), [-0.01037,   inf] (19), [-0.01037,   inf] (29), [-0.01037,   inf] (27), [-0.01036,   inf] (35), [-0.01036,   inf] (19), [-0.01036,   inf] (29), [-0.01036,   inf] (37), [-0.01035,   inf] (29), [-0.01035,   inf] (27), 
length of domains: 3686
Total time: 1.0497	 pickout: 0.0580	 decision: 0.1009	 get_bound: 0.8850	 add_domain: 0.0058
Current lb:-0.010406307876110077
16250 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 141.39296174049377

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 106] [4, 31] [5, 424] [4, 31] [5, 419] [5, 271] [4, 324] [5, 320] [4, 288] [5, 271] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.6123491525650024 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.6707957983016968, 20.410144805908203]
alpha/beta optimization time: 0.8011190891265869
This batch time : update_bounds func: 0.8951	 prepare: 0.0235	 bound: 0.8016	 transfer: 0.0522	 finalize: 0.0173
Accumulated time: update_bounds func: 115.8186	 prepare: 3.0366	 bound: 103.8614	 transfer: 0.0522	 finalize: 2.6170
batch bounding time:  0.8955013751983643
Current worst splitting domains [lb, ub] (depth):
[-0.01018,   inf] (29), [-0.01018,   inf] (33), [-0.01017,   inf] (25), [-0.01017,   inf] (37), [-0.01017,   inf] (27), [-0.01017,   inf] (31), [-0.01016,   inf] (25), [-0.01016,   inf] (27), [-0.01016,   inf] (29), [-0.01016,   inf] (31), [-0.01015,   inf] (29), [-0.01015,   inf] (27), [-0.01015,   inf] (35), [-0.01015,   inf] (29), [-0.01015,   inf] (27), [-0.01014,   inf] (23), [-0.01013,   inf] (25), [-0.01013,   inf] (33), [-0.01013,   inf] (29), [-0.01012,   inf] (35), 
length of domains: 3677
Total time: 1.0511	 pickout: 0.0521	 decision: 0.0970	 get_bound: 0.8957	 add_domain: 0.0063
Current lb:-0.010177865624427795
16378 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 142.4478042125702

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 271] [4, 31] [5, 218] [4, 288] [4, 53] [5, 424] [5, 460] [4, 274] [5, 424] [5, 106] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.931195855140686 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.9003480672836304, 21.378664016723633]
alpha/beta optimization time: 0.7787811756134033
This batch time : update_bounds func: 0.8737	 prepare: 0.0237	 bound: 0.7793	 transfer: 0.0523	 finalize: 0.0179
Accumulated time: update_bounds func: 116.6923	 prepare: 3.0603	 bound: 104.6407	 transfer: 0.0523	 finalize: 2.6349
batch bounding time:  0.8741066455841064
Current worst splitting domains [lb, ub] (depth):
[-0.01004,   inf] (27), [-0.01004,   inf] (19), [-0.01003,   inf] (27), [-0.01003,   inf] (31), [-0.01003,   inf] (33), [-0.01002,   inf] (23), [-0.01002,   inf] (27), [-0.01002,   inf] (25), [-0.01001,   inf] (37), [-0.01001,   inf] (33), [-0.01001,   inf] (33), [-0.01001,   inf] (25), [-0.01001,   inf] (31), [-0.01001,   inf] (29), [-0.00999,   inf] (29), [-0.00999,   inf] (25), [-0.00999,   inf] (27), [-0.00999,   inf] (27), [-0.00998,   inf] (27), [-0.00998,   inf] (33), 
length of domains: 3665
Total time: 1.0685	 pickout: 0.0925	 decision: 0.0963	 get_bound: 0.8743	 add_domain: 0.0054
Current lb:-0.010039523243904114
16506 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 143.52023148536682

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [5, 219] [5, 460] [4, 31] [5, 419] [5, 320] [4, 53] [5, 460] [5, 424] [5, 106] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.7673931121826172 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.0219953060150146, 23.363977432250977]
alpha/beta optimization time: 0.8156082630157471
This batch time : update_bounds func: 0.9257	 prepare: 0.0388	 bound: 0.8161	 transfer: 0.0524	 finalize: 0.0177
Accumulated time: update_bounds func: 117.6180	 prepare: 3.0990	 bound: 105.4568	 transfer: 0.0524	 finalize: 2.6527
batch bounding time:  0.9261062145233154
Current worst splitting domains [lb, ub] (depth):
[-0.00983,   inf] (27), [-0.00982,   inf] (31), [-0.00982,   inf] (35), [-0.00981,   inf] (33), [-0.00980,   inf] (29), [-0.00980,   inf] (27), [-0.00980,   inf] (33), [-0.00980,   inf] (27), [-0.00980,   inf] (37), [-0.00980,   inf] (29), [-0.00980,   inf] (29), [-0.00979,   inf] (35), [-0.00979,   inf] (29), [-0.00979,   inf] (37), [-0.00978,   inf] (25), [-0.00978,   inf] (27), [-0.00978,   inf] (19), [-0.00978,   inf] (37), [-0.00978,   inf] (27), [-0.00977,   inf] (27), 
length of domains: 3652
Total time: 1.1043	 pickout: 0.0644	 decision: 0.1083	 get_bound: 0.9263	 add_domain: 0.0053
Current lb:-0.009829431772232056
16634 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 144.6282503604889

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [4, 288] [5, 419] [4, 288] [4, 53] [4, 311] [5, 419] [5, 271] [5, 106] [5, 424] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.5928730964660645 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.9872929453849792, 21.85665512084961]
alpha/beta optimization time: 0.8009500503540039
This batch time : update_bounds func: 1.0565	 prepare: 0.0246	 bound: 0.8014	 transfer: 0.0474	 finalize: 0.0168
Accumulated time: update_bounds func: 118.6745	 prepare: 3.1237	 bound: 106.2583	 transfer: 0.0474	 finalize: 2.6694
batch bounding time:  1.0569086074829102
Current worst splitting domains [lb, ub] (depth):
[-0.00966,   inf] (23), [-0.00965,   inf] (23), [-0.00965,   inf] (29), [-0.00965,   inf] (31), [-0.00965,   inf] (33), [-0.00965,   inf] (35), [-0.00965,   inf] (27), [-0.00964,   inf] (27), [-0.00964,   inf] (35), [-0.00964,   inf] (27), [-0.00964,   inf] (31), [-0.00963,   inf] (29), [-0.00963,   inf] (35), [-0.00963,   inf] (31), [-0.00963,   inf] (25), [-0.00961,   inf] (35), [-0.00961,   inf] (33), [-0.00960,   inf] (29), [-0.00960,   inf] (29), [-0.00960,   inf] (25), 
length of domains: 3628
Total time: 1.2489	 pickout: 0.0887	 decision: 0.0988	 get_bound: 1.0572	 add_domain: 0.0042
Current lb:-0.009656563401222229
16762 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 145.88181734085083

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 288] [5, 460] [4, 109] [5, 419] [5, 106] [4, 390] [5, 320] [4, 109] [5, 419] [5, 271] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.5736156105995178 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.9623682498931885, 21.713672637939453]
alpha/beta optimization time: 0.7943134307861328
This batch time : update_bounds func: 0.8898	 prepare: 0.0235	 bound: 0.7948	 transfer: 0.0478	 finalize: 0.0233
Accumulated time: update_bounds func: 119.5643	 prepare: 3.1471	 bound: 107.0531	 transfer: 0.0478	 finalize: 2.6927
batch bounding time:  0.8902323246002197
Current worst splitting domains [lb, ub] (depth):
[-0.00946,   inf] (37), [-0.00945,   inf] (29), [-0.00945,   inf] (25), [-0.00945,   inf] (25), [-0.00945,   inf] (35), [-0.00944,   inf] (37), [-0.00944,   inf] (29), [-0.00944,   inf] (35), [-0.00944,   inf] (17), [-0.00944,   inf] (39), [-0.00943,   inf] (25), [-0.00943,   inf] (25), [-0.00942,   inf] (35), [-0.00942,   inf] (31), [-0.00942,   inf] (27), [-0.00942,   inf] (25), [-0.00941,   inf] (35), [-0.00941,   inf] (27), [-0.00941,   inf] (29), [-0.00941,   inf] (25), 
length of domains: 3605
Total time: 1.0474	 pickout: 0.0562	 decision: 0.0953	 get_bound: 0.8905	 add_domain: 0.0054
Current lb:-0.009458929300308228
16890 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 146.933096408844

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 30] [5, 424] [5, 320] [5, 320] [5, 106] [5, 371] [5, 424] [5, 106] [4, 53] [5, 30] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.858210027217865 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.8037298917770386, 18.430673599243164]
alpha/beta optimization time: 0.8088781833648682
This batch time : update_bounds func: 0.9105	 prepare: 0.0352	 bound: 0.8095	 transfer: 0.0473	 finalize: 0.0181
Accumulated time: update_bounds func: 120.4747	 prepare: 3.1823	 bound: 107.8626	 transfer: 0.0473	 finalize: 2.7108
batch bounding time:  0.9108920097351074
Current worst splitting domains [lb, ub] (depth):
[-0.00928,   inf] (29), [-0.00928,   inf] (31), [-0.00928,   inf] (37), [-0.00928,   inf] (27), [-0.00927,   inf] (35), [-0.00927,   inf] (23), [-0.00927,   inf] (35), [-0.00927,   inf] (25), [-0.00926,   inf] (27), [-0.00926,   inf] (25), [-0.00926,   inf] (33), [-0.00925,   inf] (31), [-0.00925,   inf] (23), [-0.00924,   inf] (29), [-0.00924,   inf] (25), [-0.00924,   inf] (25), [-0.00924,   inf] (31), [-0.00924,   inf] (37), [-0.00924,   inf] (33), [-0.00923,   inf] (33), 
length of domains: 3581
Total time: 1.0977	 pickout: 0.0757	 decision: 0.1067	 get_bound: 0.9112	 add_domain: 0.0041
Current lb:-0.009281545877456665
17018 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 148.03456783294678

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 53] [4, 53] [4, 390] [4, 53] [5, 419] [5, 320] [5, 419] [5, 320] [5, 320] [4, 302] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.7492297291755676 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.2938169240951538, 18.441192626953125]
alpha/beta optimization time: 0.8168649673461914
This batch time : update_bounds func: 0.9070	 prepare: 0.0236	 bound: 0.8177	 transfer: 0.0473	 finalize: 0.0179
Accumulated time: update_bounds func: 121.3817	 prepare: 3.2059	 bound: 108.6803	 transfer: 0.0473	 finalize: 2.7286
batch bounding time:  0.9074468612670898
Current worst splitting domains [lb, ub] (depth):
[-0.00912,   inf] (15), [-0.00912,   inf] (25), [-0.00911,   inf] (35), [-0.00911,   inf] (29), [-0.00911,   inf] (39), [-0.00911,   inf] (31), [-0.00910,   inf] (35), [-0.00910,   inf] (33), [-0.00910,   inf] (25), [-0.00909,   inf] (31), [-0.00908,   inf] (25), [-0.00908,   inf] (27), [-0.00908,   inf] (29), [-0.00908,   inf] (25), [-0.00907,   inf] (25), [-0.00907,   inf] (23), [-0.00906,   inf] (35), [-0.00905,   inf] (27), [-0.00905,   inf] (25), [-0.00905,   inf] (27), 
length of domains: 3555
Total time: 1.0870	 pickout: 0.0750	 decision: 0.1004	 get_bound: 0.9077	 add_domain: 0.0040
Current lb:-0.009121363051235676
17146 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 149.12559413909912

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 431] [5, 320] [4, 444] [5, 271] [5, 30] [4, 53] [4, 31] [4, 274] [5, 218] [5, 424] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.9411651492118835 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.3064611554145813, 23.112627029418945]
alpha/beta optimization time: 0.7911713123321533
This batch time : update_bounds func: 0.8800	 prepare: 0.0235	 bound: 0.7917	 transfer: 0.0474	 finalize: 0.0171
Accumulated time: update_bounds func: 122.2617	 prepare: 3.2294	 bound: 109.4719	 transfer: 0.0474	 finalize: 2.7457
batch bounding time:  0.880387544631958
Current worst splitting domains [lb, ub] (depth):
[-0.00893,   inf] (23), [-0.00893,   inf] (29), [-0.00893,   inf] (25), [-0.00893,   inf] (27), [-0.00892,   inf] (25), [-0.00892,   inf] (29), [-0.00892,   inf] (25), [-0.00892,   inf] (31), [-0.00892,   inf] (27), [-0.00892,   inf] (31), [-0.00891,   inf] (37), [-0.00891,   inf] (33), [-0.00891,   inf] (31), [-0.00891,   inf] (33), [-0.00891,   inf] (37), [-0.00890,   inf] (29), [-0.00890,   inf] (27), [-0.00890,   inf] (33), [-0.00890,   inf] (37), [-0.00890,   inf] (27), 
length of domains: 3522
Total time: 1.0323	 pickout: 0.0514	 decision: 0.0969	 get_bound: 0.8806	 add_domain: 0.0033
Current lb:-0.008933649398386478
17274 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 150.16241836547852

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 320] [5, 271] [5, 218] [4, 324] [5, 218] [5, 424] [5, 460] [5, 424] [5, 320] [5, 424] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.9291003942489624 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.4076409637928009, 17.532501220703125]
alpha/beta optimization time: 0.7810366153717041
This batch time : update_bounds func: 0.8703	 prepare: 0.0239	 bound: 0.7815	 transfer: 0.0472	 finalize: 0.0172
Accumulated time: update_bounds func: 123.1320	 prepare: 3.2533	 bound: 110.2535	 transfer: 0.0472	 finalize: 2.7629
batch bounding time:  0.8706958293914795
Current worst splitting domains [lb, ub] (depth):
[-0.00879,   inf] (31), [-0.00879,   inf] (29), [-0.00878,   inf] (31), [-0.00876,   inf] (25), [-0.00876,   inf] (27), [-0.00875,   inf] (35), [-0.00874,   inf] (27), [-0.00874,   inf] (33), [-0.00874,   inf] (35), [-0.00873,   inf] (25), [-0.00873,   inf] (25), [-0.00872,   inf] (37), [-0.00872,   inf] (25), [-0.00872,   inf] (33), [-0.00871,   inf] (37), [-0.00871,   inf] (27), [-0.00870,   inf] (33), [-0.00870,   inf] (25), [-0.00870,   inf] (23), [-0.00869,   inf] (27), 
length of domains: 3496
Total time: 1.0241	 pickout: 0.0511	 decision: 0.0971	 get_bound: 0.8709	 add_domain: 0.0050
Current lb:-0.008787932805716991
17402 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 151.1904730796814

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 424] [4, 109] [5, 106] [4, 324] [5, 271] [5, 419] [5, 320] [4, 324] [4, 31] [4, 109] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -1.1932146549224854 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.6666741967201233, 20.985801696777344]
alpha/beta optimization time: 0.7831573486328125
This batch time : update_bounds func: 0.8732	 prepare: 0.0238	 bound: 0.7836	 transfer: 0.0474	 finalize: 0.0180
Accumulated time: update_bounds func: 124.0052	 prepare: 3.2771	 bound: 111.0371	 transfer: 0.0474	 finalize: 2.7809
batch bounding time:  0.8736622333526611
Current worst splitting domains [lb, ub] (depth):
[-0.00857,   inf] (21), [-0.00857,   inf] (27), [-0.00857,   inf] (31), [-0.00856,   inf] (31), [-0.00856,   inf] (23), [-0.00855,   inf] (25), [-0.00855,   inf] (29), [-0.00855,   inf] (33), [-0.00854,   inf] (37), [-0.00854,   inf] (31), [-0.00854,   inf] (29), [-0.00854,   inf] (25), [-0.00854,   inf] (37), [-0.00854,   inf] (27), [-0.00853,   inf] (29), [-0.00853,   inf] (27), [-0.00853,   inf] (29), [-0.00853,   inf] (25), [-0.00853,   inf] (35), [-0.00852,   inf] (35), 
length of domains: 3463
Total time: 1.0226	 pickout: 0.0506	 decision: 0.0947	 get_bound: 0.8739	 add_domain: 0.0034
Current lb:-0.008568823337554932
17530 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 152.21691513061523

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 218] [4, 53] [5, 419] [5, 419] [5, 320] [5, 460] [5, 424] [5, 419] [4, 53] [5, 419] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.7379178404808044 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.6525195837020874, 16.508655548095703]
alpha/beta optimization time: 0.7834970951080322
This batch time : update_bounds func: 0.8754	 prepare: 0.0250	 bound: 0.7840	 transfer: 0.0473	 finalize: 0.0186
Accumulated time: update_bounds func: 124.8806	 prepare: 3.3021	 bound: 111.8211	 transfer: 0.0473	 finalize: 2.7995
batch bounding time:  0.8758702278137207
Current worst splitting domains [lb, ub] (depth):
[-0.00842,   inf] (29), [-0.00841,   inf] (27), [-0.00841,   inf] (25), [-0.00841,   inf] (27), [-0.00840,   inf] (35), [-0.00840,   inf] (25), [-0.00840,   inf] (25), [-0.00839,   inf] (35), [-0.00839,   inf] (39), [-0.00839,   inf] (31)/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:530: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(eps_temp / std).reshape(1, -1, 1, 1)
, [-0.00839,   inf] (21), [-0.00838,   inf] (31), [-0.00838,   inf] (27), [-0.00837,   inf] (31), [-0.00837,   inf] (27), [-0.00837,   inf] (29), [-0.00837,   inf] (31), [-0.00836,   inf] (29), [-0.00836,   inf] (25), [-0.00836,   inf] (35), 
length of domains: 3435
Total time: 1.0267	 pickout: 0.0511	 decision: 0.0955	 get_bound: 0.8761	 add_domain: 0.0040
Current lb:-0.008416138589382172
17658 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Time out!!!!!!!!
Image 799 label 4 verification end, final lower bound -0.008416138589382172, upper bound inf, time: 153.48297262191772
799 -0.008416138589382172
Result: image 799 verification failure (with branch and bound).
Wall time: 186.12985467910767

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 0): []
verification failure idx (total 1): [799]
final verified acc: 0.0%[1]
verifier is called on 1 examples.
total verified: 0
mean time [cnt:1] (excluding attack success): 180.40500617027283
