Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_conv_big_pgd.pth
  name: cifar_conv_big
data:
  start: 187
  end: 188
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR_ERAN
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.00784313725
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 64
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 180
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 100
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:21:06 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (5): ReLU()
  (6): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (7): ReLU()
  (8): Flatten()
  (9): Linear(in_features=4096, out_features=512, bias=True)
  (10): ReLU()
  (11): Linear(in_features=512, out_features=512, bias=True)
  (12): ReLU()
  (13): Linear(in_features=512, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([1000, 3, 32, 32]) torch.Size([1000]) torch.Size([1000])
X range: tensor(2.7537) tensor(-2.4291) tensor(0.0238)
Note runnerup label is empty here!
############################
epsilon after preprocessing: tensor([[[[0.0388]],

         [[0.0393]],

         [[0.0390]]]]), data_max = tensor([[[[2.5141]],

         [[2.5968]],

         [[2.7537]]]]), data_min = tensor([[[[-2.4291]],

         [[-2.4183]],

         [[-2.2214]]]])
Task length: 1
saving results to Verified_ret_[cifar_conv_big]_start=187_end=188_iter=20_b=64_timeout=180_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 187 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 3, correct label 3, image norm 2511.0380859375, logits tensor([-1.8255, -1.6280,  0.2301,  0.6210, -0.3289,  0.3286,  0.2442, -0.3064,
        -2.4209,  0.3332], device='cuda:0', grad_fn=<SelectBackward>)
##### PGD attack: True label: 3, Tested against: ['all'] ######
pgd prediction: tensor([-1.9115, -1.4229,  0.1733,  0.5691, -0.3876,  0.2625,  0.3189, -0.4645,
        -2.3395,  0.5347], device='cuda:0', grad_fn=<SqueezeBackward1>)
attack margin tensor([2.4806, 1.9920, 0.3958,    inf, 0.9567, 0.3066, 0.2502, 1.0336, 2.9086,
        0.0344], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[-1.8255, -1.6280,  0.2301,  0.6210, -0.3289,  0.3286,  0.2442, -0.3064,
         -2.4209,  0.3332]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 1.4108e+00,  7.8619e-01, -6.7701e-02,  5.2049e-01,  3.6517e-04,
         -1.9385e-01,  2.8551e-01,  2.0182e+00, -4.7828e-01]], device='cuda:0') None
best_l after optimization: -5.279768943786621 with beta sum per layer: []
alpha/beta optimization time: 22.867778778076172
initial alpha-CROWN bounds: tensor([[ 1.4976,  1.1440, -0.0306,  0.5522,  0.0304, -0.0850,  0.3334,  2.1845,
         -0.3468]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.3468, device='cuda:0', grad_fn=<MinBackward1>)
Sorted order for labels to verify: [9, 6, 5, 2, 4, 7, 1, 0, 8, 3]
##### [0:187] Tested against 9 ######
Model prediction is: tensor([[-1.8255, -1.6280,  0.2301,  0.6210, -0.3289,  0.3286,  0.2442, -0.3064,
         -2.4209,  0.3332]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /16 start_node /17
setting alpha for layer /16 start_node /19
setting alpha for layer /16 start_node /21
setting alpha for layer /16 start_node /31
setting alpha for layer /16 start_node /33
not setting layer /16 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 32, 32, 32]) != torch.Size([2, 9, 1, 32, 32, 32]))
setting alpha for layer /18 start_node /19
setting alpha for layer /18 start_node /21
setting alpha for layer /18 start_node /31
setting alpha for layer /18 start_node /33
not setting layer /18 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /20 start_node /21
setting alpha for layer /20 start_node /31
setting alpha for layer /20 start_node /33
not setting layer /20 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 64, 16, 16]) != torch.Size([2, 9, 1, 64, 16, 16]))
setting alpha for layer /22 start_node /31
setting alpha for layer /22 start_node /33
not setting layer /22 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 64, 8, 8]) != torch.Size([2, 9, 1, 64, 8, 8]))
setting alpha for layer /32 start_node /33
not setting layer /32 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 512]) != torch.Size([2, 9, 1, 512]))
not setting layer /34 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 512]) != torch.Size([2, 9, 1, 512]))
0 /15 torch.Size([1, 32, 32, 32])
1 /17 torch.Size([1, 32, 16, 16])
2 /19 torch.Size([1, 64, 16, 16])
3 /21 torch.Size([1, 64, 8, 8])
4 /31 torch.Size([1, 512])
5 /33 torch.Size([1, 512])
best_l after optimization: 0.3467763066291809 with beta sum per layer: []
alpha/beta optimization time: 3.7139945030212402
alpha-CROWN with fixed intermediate bounds: tensor([[-0.3468]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.3467763066291809
layer 0 size torch.Size([32768]) unstable 1851
layer 1 size torch.Size([8192]) unstable 80
layer 2 size torch.Size([16384]) unstable 1213
layer 3 size torch.Size([4096]) unstable 78
layer 4 size torch.Size([512]) unstable 39
layer 5 size torch.Size([512]) unstable 63
-----------------
# of unstable neurons: 3324
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 32, 32]) pre split depth:  2
batch:  torch.Size([1, 32, 32, 32]) post split depth:  2
splitting decisions: 
split level 0: [5, 246] 
split level 1: [5, 332] 
regular batch size: 2*2, diving batch size 1*0
best_l after optimization: 1.0973738431930542 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.2607666552066803]
alpha/beta optimization time: 0.5435771942138672
This batch time : update_bounds func: 0.5504	 prepare: 0.0035	 bound: 0.5441	 transfer: 0.0018	 finalize: 0.0009
Accumulated time: update_bounds func: 0.5504	 prepare: 0.0035	 bound: 0.5441	 transfer: 0.0018	 finalize: 0.0009
batch bounding time:  0.5505964756011963
Current worst splitting domains [lb, ub] (depth):
[-0.30127,   inf] (3), [-0.28822,   inf] (3), [-0.25428,   inf] (3), [-0.25360,   inf] (3), 
length of domains: 4
Total time: 0.5968	 pickout: 0.0045	 decision: 0.0401	 get_bound: 0.5519	 add_domain: 0.0003
Current lb:-0.3012720048427582
4 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.238129615783691

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([4, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 227] [5, 227] [5, 227] [5, 227] 
regular batch size: 2*4, diving batch size 1*0
best_l after optimization: 1.8758643865585327 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 1.6766014099121094]
alpha/beta optimization time: 0.5441668033599854
This batch time : update_bounds func: 0.5529	 prepare: 0.0045	 bound: 0.5447	 transfer: 0.0024	 finalize: 0.0012
Accumulated time: update_bounds func: 1.1033	 prepare: 0.0080	 bound: 1.0888	 transfer: 0.0024	 finalize: 0.0021
batch bounding time:  0.553164005279541
Current worst splitting domains [lb, ub] (depth):
[-0.28087,   inf] (5), [-0.26836,   inf] (5), [-0.25164,   inf] (5), [-0.24195,   inf] (5), [-0.23439,   inf] (5), [-0.23422,   inf] (5), [-0.18316,   inf] (5), [-0.18128,   inf] (5), 
length of domains: 8
Total time: 0.6127	 pickout: 0.0186	 decision: 0.0404	 get_bound: 0.5532	 add_domain: 0.0005
Current lb:-0.2808731198310852
12 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.8510987758636475

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 419] [5, 419] [5, 419] [5, 419] [5, 419] [5, 419] [5, 419] [5, 262] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 3.3031044006347656 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 5.299229621887207]
alpha/beta optimization time: 0.44768476486206055
This batch time : update_bounds func: 0.4587	 prepare: 0.0042	 bound: 0.4481	 transfer: 0.0040	 finalize: 0.0022
Accumulated time: update_bounds func: 1.5620	 prepare: 0.0123	 bound: 1.5369	 transfer: 0.0040	 finalize: 0.0044
batch bounding time:  0.45891332626342773
Current worst splitting domains [lb, ub] (depth):
[-0.26244,   inf] (7), [-0.25507,   inf] (7), [-0.24923,   inf] (7), [-0.24416,   inf] (7), [-0.23488,   inf] (7), [-0.22467,   inf] (7), [-0.21435,   inf] (7), [-0.21355,   inf] (7), [-0.20969,   inf] (7), [-0.20865,   inf] (7), [-0.19463,   inf] (7), [-0.19075,   inf] (7), [-0.16558,   inf] (7), [-0.15558,   inf] (7), [-0.14710,   inf] (7), [-0.13278,   inf] (7), 
length of domains: 16
Total time: 0.5229	 pickout: 0.0245	 decision: 0.0385	 get_bound: 0.4590	 add_domain: 0.0009
Current lb:-0.26243773102760315
28 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.374298334121704

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([16, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([16, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 473] [5, 473] [5, 473] [5, 473] [5, 473] [5, 473] [5, 473] [5, 262] [5, 262] [5, 473] 
regular batch size: 2*16, diving batch size 1*0
best_l after optimization: 5.6728620529174805 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 13.6152925491333]
alpha/beta optimization time: 0.4661235809326172
This batch time : update_bounds func: 0.4924	 prepare: 0.0063	 bound: 0.4665	 transfer: 0.0153	 finalize: 0.0041
Accumulated time: update_bounds func: 2.0543	 prepare: 0.0186	 bound: 2.0034	 transfer: 0.0153	 finalize: 0.0084
batch bounding time:  0.49259257316589355
Current worst splitting domains [lb, ub] (depth):
[-0.24760,   inf] (9), [-0.23960,   inf] (9), [-0.23550,   inf] (9), [-0.22908,   inf] (9), [-0.22896,   inf] (9), [-0.22413,   inf] (9), [-0.21984,   inf] (9), [-0.20998,   inf] (9), [-0.20632,   inf] (9), [-0.20572,   inf] (9), [-0.19836,   inf] (9), [-0.19424,   inf] (9), [-0.19173,   inf] (9), [-0.18916,   inf] (9), [-0.18808,   inf] (9), [-0.18179,   inf] (9), [-0.17888,   inf] (9), [-0.17796,   inf] (9), [-0.17718,   inf] (9), [-0.17392,   inf] (9), 
length of domains: 32
Total time: 0.5516	 pickout: 0.0132	 decision: 0.0439	 get_bound: 0.4927	 add_domain: 0.0018
Current lb:-0.2476026713848114
60 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.926339149475098

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([32, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([32, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 262] [5, 262] [5, 262] [5, 262] [5, 262] [5, 262] [5, 262] [5, 262] [5, 262] [5, 262] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: 9.360206604003906 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.23732654750347137, 34.95802307128906]
alpha/beta optimization time: 0.5716195106506348
This batch time : update_bounds func: 0.6196	 prepare: 0.0108	 bound: 0.5721	 transfer: 0.0291	 finalize: 0.0074
Accumulated time: update_bounds func: 2.6739	 prepare: 0.0294	 bound: 2.5755	 transfer: 0.0291	 finalize: 0.0159
batch bounding time:  0.6198382377624512
Current worst splitting domains [lb, ub] (depth):
[-0.23430,   inf] (11), [-0.22487,   inf] (11), [-0.22076,   inf] (11), [-0.21603,   inf] (11), [-0.21315,   inf] (11), [-0.21007,   inf] (11), [-0.20149,   inf] (11), [-0.20136,   inf] (11), [-0.19747,   inf] (11), [-0.19332,   inf] (11), [-0.19157,   inf] (11), [-0.19026,   inf] (11), [-0.18842,   inf] (11), [-0.18759,   inf] (11), [-0.18119,   inf] (11), [-0.17998,   inf] (11), [-0.17977,   inf] (11), [-0.17865,   inf] (11), [-0.17321,   inf] (11), [-0.17197,   inf] (11), 
length of domains: 63
Total time: 0.7427	 pickout: 0.0582	 decision: 0.0611	 get_bound: 0.6199	 add_domain: 0.0034
Current lb:-0.23429828882217407
124 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.670020818710327

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([63, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([63, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 109] [4, 415] [4, 415] [4, 415] [4, 415] [4, 415] [5, 205] [4, 109] [4, 415] [5, 205] 
regular batch size: 2*63, diving batch size 1*0
best_l after optimization: 11.966642379760742 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 10.426602363586426, 73.29852294921875]
alpha/beta optimization time: 0.7952852249145508
This batch time : update_bounds func: 0.8770	 prepare: 0.0191	 bound: 0.7957	 transfer: 0.0475	 finalize: 0.0143
Accumulated time: update_bounds func: 3.5509	 prepare: 0.0485	 bound: 3.3712	 transfer: 0.0475	 finalize: 0.0302
batch bounding time:  0.8773348331451416
Current worst splitting domains [lb, ub] (depth):
[-0.21395,   inf] (13), [-0.21314,   inf] (13), [-0.21166,   inf] (13), [-0.21019,   inf] (13), [-0.20298,   inf] (13), [-0.20270,   inf] (13), [-0.19710,   inf] (13), [-0.18780,   inf] (13), [-0.18700,   inf] (13), [-0.18109,   inf] (13), [-0.18008,   inf] (13), [-0.17835,   inf] (13), [-0.17739,   inf] (13), [-0.17681,   inf] (13), [-0.17566,   inf] (13), [-0.17440,   inf] (13), [-0.16930,   inf] (13), [-0.16863,   inf] (13), [-0.16782,   inf] (13), [-0.16702,   inf] (13), 
length of domains: 105
Total time: 1.0260	 pickout: 0.0373	 decision: 0.1044	 get_bound: 0.8775	 add_domain: 0.0067
Current lb:-0.21394780278205872
250 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.697975873947144

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 415] [4, 109] [4, 415] [5, 205] [5, 205] [5, 205] [5, 205] [4, 415] [5, 205] [5, 205] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.378442764282227 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 22.647361755371094, 39.44431686401367]
alpha/beta optimization time: 0.8021810054779053
This batch time : update_bounds func: 0.8816	 prepare: 0.0200	 bound: 0.8026	 transfer: 0.0442	 finalize: 0.0144
Accumulated time: update_bounds func: 4.4324	 prepare: 0.0685	 bound: 4.1739	 transfer: 0.0442	 finalize: 0.0446
batch bounding time:  0.8819410800933838
Current worst splitting domains [lb, ub] (depth):
[-0.20269,   inf] (15), [-0.20010,   inf] (15), [-0.19898,   inf] (15), [-0.19656,   inf] (15), [-0.19395,   inf] (15), [-0.19316,   inf] (15), [-0.19146,   inf] (15), [-0.18801,   inf] (15), [-0.17755,   inf] (15), [-0.17450,   inf] (15), [-0.17034,   inf] (15), [-0.16771,   inf] (15), [-0.16640,   inf] (15), [-0.16635,   inf] (15), [-0.16548,   inf] (15), [-0.16350,   inf] (15), [-0.15962,   inf] (15), [-0.15859,   inf] (15), [-0.15798,   inf] (15), [-0.15791,   inf] (15), 
length of domains: 130
Total time: 1.0324	 pickout: 0.0505	 decision: 0.0944	 get_bound: 0.8821	 add_domain: 0.0053
Current lb:-0.20269188284873962
378 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.73225450515747

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 205] [5, 205] [5, 309] [5, 205] [5, 205] [5, 309] [5, 309] [5, 309] [5, 309] [5, 309] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.518289566040039 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 2.393892288208008, 64.31301879882812]
alpha/beta optimization time: 0.8097114562988281
This batch time : update_bounds func: 0.9011	 prepare: 0.0208	 bound: 0.8102	 transfer: 0.0517	 finalize: 0.0175
Accumulated time: update_bounds func: 5.3336	 prepare: 0.0893	 bound: 4.9840	 transfer: 0.0517	 finalize: 0.0622
batch bounding time:  0.901545524597168
Current worst splitting domains [lb, ub] (depth):
[-0.19156,   inf] (17), [-0.19094,   inf] (17), [-0.18891,   inf] (17), [-0.18538,   inf] (17), [-0.18314,   inf] (17), [-0.18300,   inf] (17), [-0.18284,   inf] (17), [-0.17821,   inf] (17), [-0.16722,   inf] (17), [-0.16443,   inf] (17), [-0.16030,   inf] (17), [-0.15772,   inf] (17), [-0.15624,   inf] (17), [-0.15570,   inf] (17), [-0.15346,   inf] (17), [-0.15179,   inf] (17), [-0.15047,   inf] (17), [-0.14952,   inf] (17), [-0.14795,   inf] (17), [-0.14721,   inf] (17), 
length of domains: 163
Total time: 1.0488	 pickout: 0.0484	 decision: 0.0924	 get_bound: 0.9018	 add_domain: 0.0063
Current lb:-0.19155646860599518
506 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.783273220062256

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 177] [5, 240] [5, 177] [5, 177] [4, 109] [5, 240] [5, 177] [4, 262] [5, 240] [5, 177] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 11.91845703125 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 4.396262168884277, 57.796722412109375]
alpha/beta optimization time: 0.8069591522216797
This batch time : update_bounds func: 0.8974	 prepare: 0.0212	 bound: 0.8074	 transfer: 0.0536	 finalize: 0.0148
Accumulated time: update_bounds func: 6.2310	 prepare: 0.1105	 bound: 5.7914	 transfer: 0.0536	 finalize: 0.0770
batch bounding time:  0.8978269100189209
Current worst splitting domains [lb, ub] (depth):
[-0.18348,   inf] (19), [-0.18333,   inf] (19), [-0.18072,   inf] (19), [-0.17704,   inf] (19), [-0.17599,   inf] (19), [-0.17439,   inf] (19), [-0.17030,   inf] (19), [-0.16964,   inf] (19), [-0.16759,   inf] (19), [-0.16022,   inf] (19), [-0.15632,   inf] (19), [-0.15283,   inf] (19), [-0.15060,   inf] (19), [-0.14984,   inf] (19), [-0.14912,   inf] (19), [-0.14676,   inf] (19), [-0.14400,   inf] (19), [-0.14186,   inf] (19), [-0.14180,   inf] (19), [-0.14133,   inf] (19), 
length of domains: 210
Total time: 1.0420	 pickout: 0.0441	 decision: 0.0927	 get_bound: 0.8980	 add_domain: 0.0073
Current lb:-0.18347901105880737
634 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.827215909957886

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 177] [5, 309] [5, 309] [5, 309] [5, 177] [5, 309] [5, 240] [5, 177] [5, 177] [5, 106] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.410016059875488 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 6.1381731033325195, 52.63873291015625]
alpha/beta optimization time: 0.7880547046661377
This batch time : update_bounds func: 0.8743	 prepare: 0.0213	 bound: 0.7885	 transfer: 0.0490	 finalize: 0.0151
Accumulated time: update_bounds func: 7.1053	 prepare: 0.1318	 bound: 6.5799	 transfer: 0.0490	 finalize: 0.0921
batch bounding time:  0.8746852874755859
Current worst splitting domains [lb, ub] (depth):
[-0.17567,   inf] (21), [-0.17540,   inf] (21), [-0.17306,   inf] (21), [-0.16910,   inf] (21), [-0.16894,   inf] (21), [-0.16656,   inf] (21), [-0.16282,   inf] (21), [-0.16023,   inf] (21), [-0.15828,   inf] (21), [-0.15253,   inf] (21), [-0.14897,   inf] (21), [-0.14585,   inf] (21), [-0.14446,   inf] (21), [-0.14355,   inf] (21), [-0.14272,   inf] (21), [-0.13990,   inf] (21), [-0.13706,   inf] (21), [-0.13667,   inf] (21), [-0.13604,   inf] (21), [-0.13588,   inf] (21), 
length of domains: 241
Total time: 1.0527	 pickout: 0.0784	 decision: 0.0929	 get_bound: 0.8749	 add_domain: 0.0065
Current lb:-0.17566943168640137
762 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.881964445114136

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 240] [4, 109] [5, 240] [4, 262] [5, 106] [4, 262] [5, 177] [5, 240] [4, 262] [5, 177] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.195191383361816 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 11.853899002075195, 46.596290588378906]
alpha/beta optimization time: 0.8235318660736084
This batch time : update_bounds func: 0.9154	 prepare: 0.0211	 bound: 0.8240	 transfer: 0.0545	 finalize: 0.0154
Accumulated time: update_bounds func: 8.0207	 prepare: 0.1529	 bound: 7.4039	 transfer: 0.0545	 finalize: 0.1075
batch bounding time:  0.9158246517181396
Current worst splitting domains [lb, ub] (depth):
[-0.16908,   inf] (23), [-0.16636,   inf] (23), [-0.16599,   inf] (23), [-0.16350,   inf] (23), [-0.16189,   inf] (23), [-0.16096,   inf] (23), [-0.15825,   inf] (23), [-0.15544,   inf] (23), [-0.15363,   inf] (23), [-0.15244,   inf] (23), [-0.15227,   inf] (23), [-0.14398,   inf] (23), [-0.14203,   inf] (23), [-0.13720,   inf] (23), [-0.13596,   inf] (23), [-0.13585,   inf] (23), [-0.13300,   inf] (23), [-0.13182,   inf] (23), [-0.12924,   inf] (23), [-0.12854,   inf] (23), 
length of domains: 284
Total time: 1.0654	 pickout: 0.0484	 decision: 0.0920	 get_bound: 0.9160	 add_domain: 0.0089
Current lb:-0.16907548904418945
890 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.949655532836914

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 262] [4, 262] [5, 106] [5, 106] [4, 262] [5, 240] [5, 240] [4, 109] [4, 262] [4, 109] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.429657936096191 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 14.169286727905273, 46.47739028930664]
alpha/beta optimization time: 0.8013076782226562
This batch time : update_bounds func: 0.9522	 prepare: 0.0212	 bound: 0.8018	 transfer: 0.0520	 finalize: 0.0768
Accumulated time: update_bounds func: 8.9729	 prepare: 0.1741	 bound: 8.2057	 transfer: 0.0520	 finalize: 0.1844
batch bounding time:  0.9526536464691162
Current worst splitting domains [lb, ub] (depth):
[-0.16260,   inf] (25), [-0.15983,   inf] (25), [-0.15868,   inf] (25), [-0.15622,   inf] (25), [-0.15495,   inf] (25), [-0.15475,   inf] (25), [-0.15201,   inf] (25), [-0.14743,   inf] (25), [-0.14544,   inf] (25), [-0.14534,   inf] (25), [-0.14398,   inf] (25), [-0.14267,   inf] (25), [-0.14197,   inf] (25), [-0.13898,   inf] (25), [-0.13631,   inf] (25), [-0.13542,   inf] (25), [-0.13413,   inf] (25), [-0.13231,   inf] (25), [-0.13000,   inf] (25), [-0.12824,   inf] (25), 
length of domains: 331
Total time: 1.1070	 pickout: 0.0523	 decision: 0.0936	 get_bound: 0.9529	 add_domain: 0.0082
Current lb:-0.1626017987728119
1018 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.058488845825195

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 106] [5, 106] [4, 262] [4, 262] [4, 402] [5, 106] [5, 106] [5, 106] [5, 106] [4, 262] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 11.488929748535156 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 18.618560791015625, 41.503746032714844]
alpha/beta optimization time: 0.7954614162445068
This batch time : update_bounds func: 0.8818	 prepare: 0.0210	 bound: 0.7959	 transfer: 0.0500	 finalize: 0.0145
Accumulated time: update_bounds func: 9.8547	 prepare: 0.1951	 bound: 9.0016	 transfer: 0.0500	 finalize: 0.1988
batch bounding time:  0.8821513652801514
Current worst splitting domains [lb, ub] (depth):
[-0.15561,   inf] (27), [-0.15298,   inf] (27), [-0.15291,   inf] (27), [-0.15030,   inf] (27), [-0.14841,   inf] (27), [-0.14705,   inf] (27), [-0.14574,   inf] (27), [-0.14052,   inf] (27), [-0.13855,   inf] (27), [-0.13726,   inf] (27), [-0.13508,   inf] (27), [-0.13479,   inf] (27), [-0.13469,   inf] (27), [-0.13386,   inf] (27), [-0.13313,   inf] (27), [-0.13210,   inf] (27), [-0.13034,   inf] (27), [-0.12876,   inf] (27), [-0.12579,   inf] (27), [-0.12479,   inf] (27), 
length of domains: 387
Total time: 1.0358	 pickout: 0.0497	 decision: 0.0938	 get_bound: 0.8824	 add_domain: 0.0099
Current lb:-0.15561246871948242
1146 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.096097707748413

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 42] [4, 42] [4, 42] [4, 42] [4, 42] [5, 270] [4, 42] [4, 42] [4, 42] [5, 106] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 10.022282600402832 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 34.439022064208984, 40.04056930541992]
alpha/beta optimization time: 0.812990665435791
This batch time : update_bounds func: 0.9004	 prepare: 0.0227	 bound: 0.8134	 transfer: 0.0484	 finalize: 0.0155
Accumulated time: update_bounds func: 10.7551	 prepare: 0.2178	 bound: 9.8150	 transfer: 0.0484	 finalize: 0.2143
batch bounding time:  0.9007668495178223
Current worst splitting domains [lb, ub] (depth):
[-0.15004,   inf] (29), [-0.14749,   inf] (29), [-0.14744,   inf] (29), [-0.14488,   inf] (29), [-0.14221,   inf] (29), [-0.14150,   inf] (29), [-0.13967,   inf] (29), [-0.13465,   inf] (29), [-0.13278,   inf] (29), [-0.13061,   inf] (29), [-0.12869,   inf] (29), [-0.12869,   inf] (29), [-0.12831,   inf] (29), [-0.12800,   inf] (29), [-0.12779,   inf] (29), [-0.12680,   inf] (29), [-0.12669,   inf] (29), [-0.12622,   inf] (29), [-0.12349,   inf] (29), [-0.11923,   inf] (29), 
length of domains: 443
Total time: 1.0876	 pickout: 0.0847	 decision: 0.0922	 get_bound: 0.9010	 add_domain: 0.0096
Current lb:-0.15003812313079834
1274 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.1857008934021

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 182] [5, 270] [5, 270] [5, 270] [4, 182] [4, 42] [5, 270] [5, 270] [4, 402] [4, 402] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.55000114440918 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 21.606115341186523, 44.371177673339844]
alpha/beta optimization time: 0.7941820621490479
This batch time : update_bounds func: 0.8819	 prepare: 0.0210	 bound: 0.7946	 transfer: 0.0504	 finalize: 0.0155
Accumulated time: update_bounds func: 11.6370	 prepare: 0.2388	 bound: 10.6097	 transfer: 0.0504	 finalize: 0.2298
batch bounding time:  0.8822681903839111
Current worst splitting domains [lb, ub] (depth):
[-0.14562,   inf] (31), [-0.14270,   inf] (31), [-0.14248,   inf] (31), [-0.14000,   inf] (31), [-0.13723,   inf] (31), [-0.13563,   inf] (31), [-0.13439,   inf] (31), [-0.12934,   inf] (31), [-0.12801,   inf] (31), [-0.12512,   inf] (31), [-0.12444,   inf] (31), [-0.12385,   inf] (31), [-0.12217,   inf] (31), [-0.12203,   inf] (31), [-0.12047,   inf] (31), [-0.12036,   inf] (31), [-0.11950,   inf] (31), [-0.11929,   inf] (31), [-0.11828,   inf] (31), [-0.11793,   inf] (31), 
length of domains: 489
Total time: 1.0665	 pickout: 0.0815	 decision: 0.0932	 get_bound: 0.8825	 add_domain: 0.0093
Current lb:-0.14561831951141357
1402 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.254714012145996

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 270] [4, 182] [4, 402] [4, 402] [5, 270] [4, 182] [4, 182] [4, 182] [5, 270] [5, 453] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 9.342596054077148 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 17.378986358642578, 42.5067138671875]
alpha/beta optimization time: 0.7929041385650635
This batch time : update_bounds func: 0.8783	 prepare: 0.0210	 bound: 0.7933	 transfer: 0.0484	 finalize: 0.0152
Accumulated time: update_bounds func: 12.5153	 prepare: 0.2598	 bound: 11.4030	 transfer: 0.0484	 finalize: 0.2450
batch bounding time:  0.8786947727203369
Current worst splitting domains [lb, ub] (depth):
[-0.14067,   inf] (33), [-0.13841,   inf] (33), [-0.13726,   inf] (33), [-0.13479,   inf] (33), [-0.13193,   inf] (33), [-0.13191,   inf] (33), [-0.12951,   inf] (33), [-0.12452,   inf] (33), [-0.12267,   inf] (33), [-0.11965,   inf] (33), [-0.11921,   inf] (33), [-0.11747,   inf] (33), [-0.11661,   inf] (33), [-0.11644,   inf] (33), [-0.11509,   inf] (33), [-0.11468,   inf] (33), [-0.11428,   inf] (33), [-0.11408,   inf] (33), [-0.11288,   inf] (33), [-0.11209,   inf] (33), 
length of domains: 532
Total time: 1.1009	 pickout: 0.1197	 decision: 0.0932	 get_bound: 0.8789	 add_domain: 0.0090
Current lb:-0.1406688690185547
1530 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 19.357678651809692

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 453] [5, 218] [5, 218] [5, 218] [4, 402] [5, 453] [4, 402] [4, 402] [4, 182] [4, 359] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 8.225048065185547 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 15.787017822265625, 48.049163818359375]
alpha/beta optimization time: 0.8063995838165283
This batch time : update_bounds func: 0.9001	 prepare: 0.0223	 bound: 0.8069	 transfer: 0.0548	 finalize: 0.0157
Accumulated time: update_bounds func: 13.4154	 prepare: 0.2821	 bound: 12.2099	 transfer: 0.0548	 finalize: 0.2607
batch bounding time:  0.9004685878753662
Current worst splitting domains [lb, ub] (depth):
[-0.13556,   inf] (35), [-0.13417,   inf] (35), [-0.13352,   inf] (35), [-0.13083,   inf] (35), [-0.12641,   inf] (35), [-0.12627,   inf] (35), [-0.12383,   inf] (35), [-0.12114,   inf] (35), [-0.11967,   inf] (35), [-0.11799,   inf] (35), [-0.11549,   inf] (35), [-0.11534,   inf] (35), [-0.11359,   inf] (35), [-0.11242,   inf] (35), [-0.11147,   inf] (35), [-0.11125,   inf] (35), [-0.11013,   inf] (35), [-0.11005,   inf] (35), [-0.10830,   inf] (35), [-0.10806,   inf] (35), 
length of domains: 570
Total time: 1.0568	 pickout: 0.0557	 decision: 0.0916	 get_bound: 0.9007	 add_domain: 0.0088
Current lb:-0.13556194305419922
1658 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 20.416632175445557

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 218] [5, 453] [5, 453] [4, 274] [5, 218] [5, 453] [5, 453] [5, 218] [5, 218] [5, 218] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.710620880126953 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 15.698933601379395, 46.73931884765625]
alpha/beta optimization time: 0.8466107845306396
This batch time : update_bounds func: 0.9330	 prepare: 0.0223	 bound: 0.8471	 transfer: 0.0483	 finalize: 0.0148
Accumulated time: update_bounds func: 14.3484	 prepare: 0.3045	 bound: 13.0569	 transfer: 0.0483	 finalize: 0.2755
batch bounding time:  0.9333231449127197
Current worst splitting domains [lb, ub] (depth):
[-0.13145,   inf] (37), [-0.12918,   inf] (37), [-0.12846,   inf] (37), [-0.12633,   inf] (37), [-0.12296,   inf] (37), [-0.12110,   inf] (37), [-0.11875,   inf] (37), [-0.11591,   inf] (37), [-0.11524,   inf] (37), [-0.11352,   inf] (37), [-0.11311,   inf] (37), [-0.11120,   inf] (37), [-0.11090,   inf] (37), [-0.10891,   inf] (37), [-0.10851,   inf] (37), [-0.10756,   inf] (37), [-0.10684,   inf] (37), [-0.10675,   inf] (37), [-0.10634,   inf] (37), [-0.10564,   inf] (37), 
length of domains: 600
Total time: 1.0879	 pickout: 0.0494	 decision: 0.0961	 get_bound: 0.9335	 add_domain: 0.0088
Current lb:-0.13144969940185547
1786 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 21.50673246383667

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 496] [5, 496] [4, 182] [4, 182] [5, 496] [5, 218] [5, 218] [4, 302] [5, 453] [5, 453] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.896516799926758 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 19.996585845947266, 45.51833724975586]
alpha/beta optimization time: 0.7963025569915771
This batch time : update_bounds func: 0.8821	 prepare: 0.0209	 bound: 0.7967	 transfer: 0.0484	 finalize: 0.0157
Accumulated time: update_bounds func: 15.2304	 prepare: 0.3253	 bound: 13.8537	 transfer: 0.0484	 finalize: 0.2912
batch bounding time:  0.8824737071990967
Current worst splitting domains [lb, ub] (depth):
[-0.12757,   inf] (39), [-0.12529,   inf] (39), [-0.12475,   inf] (39), [-0.12308,   inf] (39), [-0.11919,   inf] (39), [-0.11694,   inf] (39), [-0.11436,   inf] (39), [-0.11084,   inf] (39), [-0.11028,   inf] (39), [-0.10864,   inf] (39), [-0.10741,   inf] (39), [-0.10720,   inf] (39), [-0.10507,   inf] (39), [-0.10454,   inf] (39), [-0.10373,   inf] (39), [-0.10341,   inf] (39), [-0.10253,   inf] (39), [-0.10183,   inf] (39), [-0.10171,   inf] (39), [-0.10171,   inf] (39), 
length of domains: 642
Total time: 1.0345	 pickout: 0.0498	 decision: 0.0925	 get_bound: 0.8827	 add_domain: 0.0094
Current lb:-0.1275678128004074
1914 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 22.543638706207275

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 402] [4, 302] [5, 496] [5, 453] [4, 109] [5, 496] [5, 496] [4, 402] [5, 496] [4, 376] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 8.68316650390625 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 19.029850006103516, 49.380516052246094]
alpha/beta optimization time: 0.7912611961364746
This batch time : update_bounds func: 0.8830	 prepare: 0.0210	 bound: 0.7917	 transfer: 0.0544	 finalize: 0.0155
Accumulated time: update_bounds func: 16.1134	 prepare: 0.3463	 bound: 14.6454	 transfer: 0.0544	 finalize: 0.3067
batch bounding time:  0.8833637237548828
Current worst splitting domains [lb, ub] (depth):
[-0.12404,   inf] (41), [-0.12121,   inf] (41), [-0.12086,   inf] (41), [-0.11826,   inf] (41), [-0.11323,   inf] (41), [-0.11131,   inf] (41), [-0.11064,   inf] (41), [-0.10873,   inf] (41), [-0.10637,   inf] (41), [-0.10525,   inf] (41), [-0.10456,   inf] (41), [-0.10427,   inf] (41), [-0.10125,   inf] (41), [-0.10073,   inf] (41), [-0.10029,   inf] (41), [-0.09998,   inf] (41), [-0.09838,   inf] (41), [-0.09836,   inf] (41), [-0.09818,   inf] (41), [-0.09795,   inf] (41), 
length of domains: 692
Total time: 1.1086	 pickout: 0.0568	 decision: 0.1570	 get_bound: 0.8836	 add_domain: 0.0112
Current lb:-0.12404095381498337
2042 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 23.654545307159424

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 302] [4, 402] [4, 274] [5, 496] [4, 302] [5, 509] [4, 302] [5, 509] [4, 376] [5, 496] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.665431976318359 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 19.99656867980957, 44.24610137939453]
alpha/beta optimization time: 0.8127248287200928
This batch time : update_bounds func: 0.9030	 prepare: 0.0211	 bound: 0.8132	 transfer: 0.0515	 finalize: 0.0169
Accumulated time: update_bounds func: 17.0164	 prepare: 0.3675	 bound: 15.4585	 transfer: 0.0515	 finalize: 0.3236
batch bounding time:  0.903419017791748
Current worst splitting domains [lb, ub] (depth):
[-0.11975,   inf] (43), [-0.11736,   inf] (43), [-0.11688,   inf] (43), [-0.11442,   inf] (43), [-0.10982,   inf] (43), [-0.10729,   inf] (43), [-0.10726,   inf] (43), [-0.10461,   inf] (43), [-0.10297,   inf] (43), [-0.10129,   inf] (43), [-0.10069,   inf] (43), [-0.09952,   inf] (43), [-0.09909,   inf] (43), [-0.09770,   inf] (43), [-0.09634,   inf] (43), [-0.09592,   inf] (43), [-0.09501,   inf] (43), [-0.09471,   inf] (43), [-0.09408,   inf] (35), [-0.09403,   inf] (19), 
length of domains: 738
Total time: 1.0930	 pickout: 0.0862	 decision: 0.0928	 get_bound: 0.9036	 add_domain: 0.0104
Current lb:-0.11974643170833588
2170 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 24.749998807907104

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 359] [4, 359] [4, 135] [5, 509] [5, 509] [5, 6] [5, 509] [5, 6] [4, 359] [4, 359] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.114184379577637 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 18.80223274230957, 44.55793380737305]
alpha/beta optimization time: 0.7915198802947998
This batch time : update_bounds func: 0.8785	 prepare: 0.0210	 bound: 0.7920	 transfer: 0.0492	 finalize: 0.0151
Accumulated time: update_bounds func: 17.8949	 prepare: 0.3885	 bound: 16.2505	 transfer: 0.0492	 finalize: 0.3387
batch bounding time:  0.878868818283081
Current worst splitting domains [lb, ub] (depth):
[-0.11567,   inf] (45), [-0.11354,   inf] (45), [-0.11289,   inf] (45), [-0.11080,   inf] (45), [-0.10612,   inf] (45), [-0.10443,   inf] (45), [-0.10355,   inf] (45), [-0.10163,   inf] (45), [-0.09896,   inf] (45), [-0.09727,   inf] (45), [-0.09721,   inf] (45), [-0.09634,   inf] (45), [-0.09496,   inf] (45), [-0.09459,   inf] (45), [-0.09364,   inf] (45), [-0.09293,   inf] (45), [-0.09278,   inf] (29), [-0.09275,   inf] (31), [-0.09272,   inf] (21), [-0.09269,   inf] (37), 
length of domains: 779
Total time: 1.0263	 pickout: 0.0452	 decision: 0.0921	 get_bound: 0.8791	 add_domain: 0.0099
Current lb:-0.11567080020904541
2298 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 25.778607606887817

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 509] [5, 509] [5, 509] [4, 135] [4, 359] [4, 135] [5, 6] [4, 135] [4, 302] [4, 302] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.405320167541504 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 18.077938079833984, 49.578102111816406]
alpha/beta optimization time: 0.7945826053619385
This batch time : update_bounds func: 0.8804	 prepare: 0.0210	 bound: 0.7950	 transfer: 0.0484	 finalize: 0.0156
Accumulated time: update_bounds func: 18.7753	 prepare: 0.4095	 bound: 17.0455	 transfer: 0.0484	 finalize: 0.3543
batch bounding time:  0.8807878494262695
Current worst splitting domains [lb, ub] (depth):
[-0.11219,   inf] (47), [-0.10996,   inf] (47), [-0.10917,   inf] (47), [-0.10660,   inf] (47), [-0.10289,   inf] (47), [-0.10146,   inf] (47), [-0.10070,   inf] (47), [-0.09872,   inf] (47), [-0.09526,   inf] (47), [-0.09408,   inf] (47), [-0.09389,   inf] (47), [-0.09351,   inf] (47), [-0.09181,   inf] (47), [-0.09170,   inf] (47), [-0.09155,   inf] (35), [-0.09154,   inf] (27), [-0.09154,   inf] (43), [-0.09151,   inf] (31), [-0.09151,   inf] (27), [-0.09146,   inf] (27), 
length of domains: 817
Total time: 1.0572	 pickout: 0.0737	 decision: 0.0931	 get_bound: 0.8810	 add_domain: 0.0093
Current lb:-0.11219305545091629
2426 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 26.838048934936523

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 6] [5, 6] [5, 6] [5, 6] [5, 6] [4, 376] [4, 359] [4, 376] [5, 509] [4, 466] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.945952892303467 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 21.366941452026367, 43.60751724243164]
alpha/beta optimization time: 0.8315849304199219
This batch time : update_bounds func: 0.9195	 prepare: 0.0211	 bound: 0.8321	 transfer: 0.0497	 finalize: 0.0163
Accumulated time: update_bounds func: 19.6948	 prepare: 0.4306	 bound: 17.8776	 transfer: 0.0497	 finalize: 0.3706
batch bounding time:  0.9198973178863525
Current worst splitting domains [lb, ub] (depth):
[-0.10904,   inf] (49), [-0.10678,   inf] (49), [-0.10607,   inf] (49), [-0.10353,   inf] (49), [-0.10001,   inf] (49), [-0.09921,   inf] (49), [-0.09740,   inf] (49), [-0.09638,   inf] (49), [-0.09168,   inf] (49), [-0.09037,   inf] (27), [-0.09035,   inf] (25), [-0.09028,   inf] (15), [-0.09026,   inf] (33), [-0.09023,   inf] (33), [-0.09021,   inf] (37), [-0.09020,   inf] (45), [-0.09020,   inf] (19), [-0.09018,   inf] (25), [-0.09015,   inf] (19), [-0.09011,   inf] (25), 
length of domains: 855
Total time: 1.1113	 pickout: 0.0893	 decision: 0.0922	 get_bound: 0.9201	 add_domain: 0.0097
Current lb:-0.10903775691986084
2554 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 27.951868057250977

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 376] [4, 376] [5, 245] [5, 245] [5, 245] [5, 245] [5, 245] [5, 245] [5, 6] [4, 109] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.239484786987305 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 21.018272399902344, 48.82695770263672]
alpha/beta optimization time: 0.8176734447479248
This batch time : update_bounds func: 0.9149	 prepare: 0.0212	 bound: 0.8181	 transfer: 0.0511	 finalize: 0.0242
Accumulated time: update_bounds func: 20.6098	 prepare: 0.4517	 bound: 18.6957	 transfer: 0.0511	 finalize: 0.3947
batch bounding time:  0.9153432846069336
Current worst splitting domains [lb, ub] (depth):
[-0.10603,   inf] (51), [-0.10374,   inf] (51), [-0.10309,   inf] (51), [-0.10056,   inf] (51), [-0.09790,   inf] (51), [-0.09671,   inf] (51), [-0.09602,   inf] (51), [-0.09548,   inf] (51), [-0.09480,   inf] (51), [-0.09415,   inf] (51), [-0.09322,   inf] (51), [-0.09272,   inf] (51), [-0.09247,   inf] (51), [-0.09020,   inf] (51), [-0.08923,   inf] (27), [-0.08922,   inf] (49), [-0.08922,   inf] (25), [-0.08918,   inf] (29), [-0.08917,   inf] (31), [-0.08913,   inf] (27), 
length of domains: 892
Total time: 1.0703	 pickout: 0.0505	 decision: 0.0937	 get_bound: 0.9156	 add_domain: 0.0105
Current lb:-0.10603334754705429
2682 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 29.02460265159607

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 245] [5, 245] [4, 376] [4, 376] [4, 302] [4, 376] [4, 482] [4, 302] [4, 376] [4, 376] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.62770938873291 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 21.62939453125, 48.29084396362305]
alpha/beta optimization time: 0.7950923442840576
This batch time : update_bounds func: 0.8816	 prepare: 0.0214	 bound: 0.7956	 transfer: 0.0484	 finalize: 0.0159
Accumulated time: update_bounds func: 21.4914	 prepare: 0.4732	 bound: 19.4913	 transfer: 0.0484	 finalize: 0.4106
batch bounding time:  0.8819718360900879
Current worst splitting domains [lb, ub] (depth):
[-0.10298,   inf] (53), [-0.10085,   inf] (53), [-0.10069,   inf] (53), [-0.09888,   inf] (53), [-0.09840,   inf] (53), [-0.09669,   inf] (53), [-0.09464,   inf] (53), [-0.09394,   inf] (53), [-0.09384,   inf] (53), [-0.09222,   inf] (53), [-0.09212,   inf] (53), [-0.09133,   inf] (53), [-0.09098,   inf] (53), [-0.09041,   inf] (53), [-0.08980,   inf] (53), [-0.08848,   inf] (41), [-0.08848,   inf] (39), [-0.08846,   inf] (21), [-0.08844,   inf] (35), [-0.08843,   inf] (29), 
length of domains: 921
Total time: 1.0449	 pickout: 0.0553	 decision: 0.0985	 get_bound: 0.8822	 add_domain: 0.0089
Current lb:-0.10298354923725128
2810 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 30.071840286254883

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 274] [4, 302] [4, 274] [4, 135] [4, 302] [4, 135] [4, 466] [5, 51] [5, 51] [5, 51] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.300960063934326 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 21.211151123046875, 48.496192932128906]
alpha/beta optimization time: 0.7919485569000244
This batch time : update_bounds func: 0.8786	 prepare: 0.0226	 bound: 0.7924	 transfer: 0.0481	 finalize: 0.0151
Accumulated time: update_bounds func: 22.3700	 prepare: 0.4957	 bound: 20.2837	 transfer: 0.0481	 finalize: 0.4257
batch bounding time:  0.8789725303649902
Current worst splitting domains [lb, ub] (depth):
[-0.10011,   inf] (55), [-0.09847,   inf] (55), [-0.09778,   inf] (55), [-0.09621,   inf] (55), [-0.09594,   inf] (55), [-0.09377,   inf] (55), [-0.09188,   inf] (55), [-0.09166,   inf] (55), [-0.09000,   inf] (55), [-0.08991,   inf] (55), [-0.08925,   inf] (55), [-0.08872,   inf] (55), [-0.08862,   inf] (55), [-0.08812,   inf] (55), [-0.08766,   inf] (55), [-0.08736,   inf] (33), [-0.08736,   inf] (37), [-0.08736,   inf] (45), [-0.08736,   inf] (33), [-0.08733,   inf] (23), 
length of domains: 960
Total time: 1.0520	 pickout: 0.0691	 decision: 0.0935	 get_bound: 0.8792	 add_domain: 0.0102
Current lb:-0.10011494159698486
2938 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 31.126174688339233

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 135] [4, 359] [4, 135] [4, 359] [5, 51] [5, 51] [5, 294] [4, 274] [5, 294] [4, 466] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.283074378967285 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 18.045215606689453, 45.914127349853516]
alpha/beta optimization time: 0.8046607971191406
This batch time : update_bounds func: 0.8907	 prepare: 0.0213	 bound: 0.8051	 transfer: 0.0482	 finalize: 0.0157
Accumulated time: update_bounds func: 23.2606	 prepare: 0.5170	 bound: 21.0887	 transfer: 0.0482	 finalize: 0.4414
batch bounding time:  0.8910436630249023
Current worst splitting domains [lb, ub] (depth):
[-0.09740,   inf] (57), [-0.09581,   inf] (57), [-0.09509,   inf] (57), [-0.09376,   inf] (57), [-0.09372,   inf] (57), [-0.09161,   inf] (57), [-0.08981,   inf] (57), [-0.08976,   inf] (57), [-0.08780,   inf] (57), [-0.08716,   inf] (57), [-0.08682,   inf] (57), [-0.08673,   inf] (57), [-0.08649,   inf] (49), [-0.08644,   inf] (45), [-0.08643,   inf] (37), [-0.08642,   inf] (49), [-0.08640,   inf] (33), [-0.08639,   inf] (17), [-0.08637,   inf] (23), [-0.08636,   inf] (41), 
length of domains: 996
Total time: 1.1409	 pickout: 0.0713	 decision: 0.1683	 get_bound: 0.8913	 add_domain: 0.0101
Current lb:-0.09740491956472397
3066 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 32.26958990097046

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 51] [5, 51] [5, 51] [4, 274] [5, 51] [5, 294] [4, 302] [4, 135] [4, 482] [4, 482] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.435654640197754 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 22.18767547607422, 43.88047790527344]
alpha/beta optimization time: 0.7978663444519043
This batch time : update_bounds func: 0.8854	 prepare: 0.0211	 bound: 0.7983	 transfer: 0.0495	 finalize: 0.0160
Accumulated time: update_bounds func: 24.1460	 prepare: 0.5381	 bound: 21.8870	 transfer: 0.0495	 finalize: 0.4574
batch bounding time:  0.8857390880584717
Current worst splitting domains [lb, ub] (depth):
[-0.09513,   inf] (59), [-0.09349,   inf] (59), [-0.09285,   inf] (59), [-0.09198,   inf] (59), [-0.09140,   inf] (59), [-0.08946,   inf] (59), [-0.08800,   inf] (59), [-0.08771,   inf] (59), [-0.08598,   inf] (59), [-0.08566,   inf] (27), [-0.08563,   inf] (27), [-0.08563,   inf] (35), [-0.08560,   inf] (27), [-0.08559,   inf] (37), [-0.08557,   inf] (33), [-0.08557,   inf] (41), [-0.08555,   inf] (29), [-0.08555,   inf] (25), [-0.08555,   inf] (57), [-0.08554,   inf] (25), 
length of domains: 1036
Total time: 1.0320	 pickout: 0.0438	 decision: 0.0920	 get_bound: 0.8859	 add_domain: 0.0102
Current lb:-0.09512528777122498
3194 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 33.30413365364075

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 294] [4, 466] [5, 294] [5, 294] [5, 294] [4, 466] [5, 294] [4, 482] [4, 135] [4, 402] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.6602888107299805 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 17.941265106201172, 47.22881317138672]
alpha/beta optimization time: 0.7972283363342285
This batch time : update_bounds func: 0.8832	 prepare: 0.0215	 bound: 0.7977	 transfer: 0.0482	 finalize: 0.0153
Accumulated time: update_bounds func: 25.0292	 prepare: 0.5596	 bound: 22.6847	 transfer: 0.0482	 finalize: 0.4728
batch bounding time:  0.8835899829864502
Current worst splitting domains [lb, ub] (depth):
[-0.09321,   inf] (61), [-0.09106,   inf] (61), [-0.09093,   inf] (61), [-0.09090,   inf] (61), [-0.08988,   inf] (61), [-0.08951,   inf] (61), [-0.08602,   inf] (61), [-0.08594,   inf] (61), [-0.08491,   inf] (61), [-0.08484,   inf] (23), [-0.08484,   inf] (43), [-0.08483,   inf] (35), [-0.08483,   inf] (25), [-0.08480,   inf] (35), [-0.08479,   inf] (15), [-0.08477,   inf] (53), [-0.08473,   inf] (49), [-0.08472,   inf] (15), [-0.08469,   inf] (39), [-0.08467,   inf] (37), 
length of domains: 1080
Total time: 1.0814	 pickout: 0.0912	 decision: 0.0945	 get_bound: 0.8838	 add_domain: 0.0120
Current lb:-0.09320569038391113
3322 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 34.38818383216858

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 491] [5, 294] [5, 491] [5, 294] [4, 466] [4, 466] [4, 359] [3, 3837] [5, 491] [5, 270] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.890909671783447 with beta sum per layer: [0.0, 0.0, 0.0, 1.1973217725753784, 20.055618286132812, 49.808555603027344]
alpha/beta optimization time: 0.7992289066314697
This batch time : update_bounds func: 0.8863	 prepare: 0.0217	 bound: 0.7997	 transfer: 0.0484	 finalize: 0.0161
Accumulated time: update_bounds func: 25.9155	 prepare: 0.5813	 bound: 23.4844	 transfer: 0.0484	 finalize: 0.4888
batch bounding time:  0.8867604732513428
Current worst splitting domains [lb, ub] (depth):
[-0.09171,   inf] (63), [-0.08945,   inf] (63), [-0.08912,   inf] (63), [-0.08895,   inf] (63), [-0.08707,   inf] (63), [-0.08668,   inf] (63), [-0.08573,   inf] (63), [-0.08462,   inf] (63), [-0.08432,   inf] (63), [-0.08391,   inf] (59), [-0.08390,   inf] (35), [-0.08387,   inf] (63), [-0.08384,   inf] (33), [-0.08383,   inf] (21), [-0.08379,   inf] (41), [-0.08378,   inf] (39), [-0.08377,   inf] (41), [-0.08375,   inf] (39), [-0.08374,   inf] (35), [-0.08373,   inf] (49), 
length of domains: 1115
Total time: 1.0378	 pickout: 0.0482	 decision: 0.0927	 get_bound: 0.8870	 add_domain: 0.0100
Current lb:-0.0917125940322876
3450 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 35.42887997627258

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 482] [4, 482] [4, 482] [4, 482] [4, 482] [4, 482] [5, 491] [5, 491] [5, 491] [5, 491] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.084454536437988 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 22.80896759033203, 47.34270477294922]
alpha/beta optimization time: 0.7991759777069092
This batch time : update_bounds func: 0.8870	 prepare: 0.0221	 bound: 0.7997	 transfer: 0.0492	 finalize: 0.0156
Accumulated time: update_bounds func: 26.8025	 prepare: 0.6034	 bound: 24.2841	 transfer: 0.0492	 finalize: 0.5044
batch bounding time:  0.8874223232269287
Current worst splitting domains [lb, ub] (depth):
[-0.09047,   inf] (65), [-0.08821,   inf] (65), [-0.08745,   inf] (65), [-0.08725,   inf] (65), [-0.08535,   inf] (65), [-0.08498,   inf] (65), [-0.08422,   inf] (65), [-0.08324,   inf] (63), [-0.08323,   inf] (65), [-0.08323,   inf] (27), [-0.08322,   inf] (21), [-0.08317,   inf] (47), [-0.08316,   inf] (29), [-0.08314,   inf] (33), [-0.08313,   inf] (39), [-0.08309,   inf] (21), [-0.08307,   inf] (45), [-0.08304,   inf] (23), [-0.08303,   inf] (47), [-0.08302,   inf] (61), 
length of domains: 1146
Total time: 1.0875	 pickout: 0.0948	 decision: 0.0950	 get_bound: 0.8876	 add_domain: 0.0099
Current lb:-0.09047387540340424
3578 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 36.51922059059143

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 7879] [2, 7879] [5, 491] [5, 491] [5, 491] [5, 491] [4, 482] [3, 3837] [3, 3305] [5, 218] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.38360595703125 with beta sum per layer: [0.0, 0.0, 1.5110933780670166, 2.345656633377075, 17.974607467651367, 46.33232116699219]
alpha/beta optimization time: 0.8083033561706543
This batch time : update_bounds func: 0.9036	 prepare: 0.0223	 bound: 0.8088	 transfer: 0.0494	 finalize: 0.0227
Accumulated time: update_bounds func: 27.7061	 prepare: 0.6257	 bound: 25.0929	 transfer: 0.0494	 finalize: 0.5271
batch bounding time:  0.9040019512176514
Current worst splitting domains [lb, ub] (depth):
[-0.08926,   inf] (67), [-0.08702,   inf] (67), [-0.08604,   inf] (67), [-0.08584,   inf] (67), [-0.08396,   inf] (67), [-0.08356,   inf] (67), [-0.08271,   inf] (67), [-0.08248,   inf] (67), [-0.08240,   inf] (67), [-0.08226,   inf] (29), [-0.08226,   inf] (35), [-0.08225,   inf] (29), [-0.08225,   inf] (39), [-0.08221,   inf] (35), [-0.08219,   inf] (45), [-0.08219,   inf] (35), [-0.08214,   inf] (29), [-0.08214,   inf] (49), [-0.08209,   inf] (51), [-0.08208,   inf] (55), 
length of domains: 1177
Total time: 1.0786	 pickout: 0.0689	 decision: 0.0947	 get_bound: 0.9042	 add_domain: 0.0108
Current lb:-0.08926498889923096
3706 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 37.60085582733154

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 9157] [3, 3837] [2, 7879] [2, 7879] [2, 7879] [2, 7879] [2, 7879] [3, 1230] [2, 9157] [4, 135] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.1792378425598145 with beta sum per layer: [0.0, 0.0, 8.134844779968262, 2.853874921798706, 17.117202758789062, 46.783241271972656]
alpha/beta optimization time: 0.8285422325134277
This batch time : update_bounds func: 0.9299	 prepare: 0.0351	 bound: 0.8291	 transfer: 0.0486	 finalize: 0.0165
Accumulated time: update_bounds func: 28.6360	 prepare: 0.6608	 bound: 25.9221	 transfer: 0.0486	 finalize: 0.5437
batch bounding time:  0.9302716255187988
Current worst splitting domains [lb, ub] (depth):
[-0.08782,   inf] (69), [-0.08649,   inf] (69), [-0.08598,   inf] (69), [-0.08495,   inf] (69), [-0.08474,   inf] (69), [-0.08291,   inf] (69), [-0.08241,   inf] (69), [-0.08202,   inf] (69), [-0.08160,   inf] (63), [-0.08160,   inf] (39), [-0.08159,   inf] (33), [-0.08159,   inf] (29), [-0.08159,   inf] (39), [-0.08157,   inf] (27), [-0.08154,   inf] (39), [-0.08154,   inf] (33), [-0.08153,   inf] (47), [-0.08153,   inf] (31), [-0.08152,   inf] (29), [-0.08149,   inf] (39), 
length of domains: 1214
Total time: 1.1061	 pickout: 0.0605	 decision: 0.1042	 get_bound: 0.9305	 add_domain: 0.0109
Current lb:-0.08782047778367996
3834 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 38.709818601608276

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3837] [3, 3837] [2, 9157] [3, 3837] [3, 3837] [5, 221] [5, 221] [2, 9157] [4, 274] [5, 453] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.59698486328125 with beta sum per layer: [0.0, 0.0, 3.50435471534729, 5.699267387390137, 19.579526901245117, 41.22223663330078]
alpha/beta optimization time: 0.7959182262420654
This batch time : update_bounds func: 0.8835	 prepare: 0.0226	 bound: 0.7964	 transfer: 0.0484	 finalize: 0.0157
Accumulated time: update_bounds func: 29.5194	 prepare: 0.6834	 bound: 26.7185	 transfer: 0.0484	 finalize: 0.5593
batch bounding time:  0.8838496208190918
Current worst splitting domains [lb, ub] (depth):
[-0.08665,   inf] (71), [-0.08530,   inf] (71), [-0.08461,   inf] (71), [-0.08392,   inf] (71), [-0.08367,   inf] (71), [-0.08330,   inf] (71), [-0.08268,   inf] (71), [-0.08136,   inf] (71), [-0.08132,   inf] (71), [-0.08107,   inf] (71), [-0.08103,   inf] (47), [-0.08103,   inf] (17), [-0.08102,   inf] (49), [-0.08102,   inf] (51), [-0.08101,   inf] (69), [-0.08099,   inf] (67), [-0.08096,   inf] (29), [-0.08095,   inf] (63), [-0.08091,   inf] (39), [-0.08091,   inf] (45), 
length of domains: 1255
Total time: 1.1643	 pickout: 0.1082	 decision: 0.0947	 get_bound: 0.8841	 add_domain: 0.0773
Current lb:-0.08665220439434052
3962 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 39.876784801483154

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 221] [5, 221] [5, 221] [5, 221] [5, 221] [5, 221] [5, 221] [3, 3837] [5, 221] [5, 485] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.918137073516846 with beta sum per layer: [0.0, 0.0, 7.930754661560059, 6.965395450592041, 12.753806114196777, 38.809749603271484]
alpha/beta optimization time: 0.8038365840911865
This batch time : update_bounds func: 0.8968	 prepare: 0.0231	 bound: 0.8043	 transfer: 0.0522	 finalize: 0.0168
Accumulated time: update_bounds func: 30.4162	 prepare: 0.7065	 bound: 27.5228	 transfer: 0.0522	 finalize: 0.5761
batch bounding time:  0.897202730178833
Current worst splitting domains [lb, ub] (depth):
[-0.08516,   inf] (73), [-0.08409,   inf] (73), [-0.08380,   inf] (73), [-0.08312,   inf] (73), [-0.08269,   inf] (73), [-0.08237,   inf] (73), [-0.08219,   inf] (73), [-0.08211,   inf] (73), [-0.08205,   inf] (73), [-0.08191,   inf] (73), [-0.08177,   inf] (73), [-0.08100,   inf] (73), [-0.08060,   inf] (73), [-0.08053,   inf] (73), [-0.08048,   inf] (71), [-0.08048,   inf] (13), [-0.08048,   inf] (29), [-0.08046,   inf] (25), [-0.08045,   inf] (63), [-0.08045,   inf] (71), 
length of domains: 1299
Total time: 1.0513	 pickout: 0.0479	 decision: 0.0935	 get_bound: 0.8974	 add_domain: 0.0124
Current lb:-0.08515739440917969
4090 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 40.93081593513489

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 485] [4, 29] [5, 485] [5, 485] [4, 29] [2, 9157] [2, 9157] [5, 485] [4, 29] [2, 9157] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.162446022033691 with beta sum per layer: [0.0, 0.0, 11.267162322998047, 6.319634437561035, 16.22081756591797, 39.1834602355957]
alpha/beta optimization time: 0.799468994140625
This batch time : update_bounds func: 0.8875	 prepare: 0.0231	 bound: 0.7999	 transfer: 0.0484	 finalize: 0.0156
Accumulated time: update_bounds func: 31.3037	 prepare: 0.7296	 bound: 28.3228	 transfer: 0.0484	 finalize: 0.5917
batch bounding time:  0.887925386428833
Current worst splitting domains [lb, ub] (depth):
[-0.08426,   inf] (75), [-0.08297,   inf] (75), [-0.08291,   inf] (75), [-0.08221,   inf] (75), [-0.08156,   inf] (75), [-0.08117,   inf] (75), [-0.08108,   inf] (75), [-0.08096,   inf] (75), [-0.08087,   inf] (75), [-0.08083,   inf] (75), [-0.08063,   inf] (75), [-0.07997,   inf] (75), [-0.07991,   inf] (43), [-0.07991,   inf] (71), [-0.07987,   inf] (53), [-0.07987,   inf] (27), [-0.07986,   inf] (47), [-0.07986,   inf] (35), [-0.07986,   inf] (23), [-0.07986,   inf] (59), 
length of domains: 1335
Total time: 1.0485	 pickout: 0.0536	 decision: 0.0939	 get_bound: 0.8881	 add_domain: 0.0129
Current lb:-0.08426356315612793
4218 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 41.982155323028564

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 29] [3, 1230] [4, 29] [4, 29] [3, 1230] [2, 9157] [5, 485] [5, 485] [4, 29] [5, 485] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.2946953773498535 with beta sum per layer: [0.0, 0.0, 14.596829414367676, 5.18311071395874, 17.213970184326172, 39.73909378051758]
alpha/beta optimization time: 0.801708459854126
This batch time : update_bounds func: 0.9012	 prepare: 0.0231	 bound: 0.8022	 transfer: 0.0505	 finalize: 0.0250
Accumulated time: update_bounds func: 32.2049	 prepare: 0.7527	 bound: 29.1250	 transfer: 0.0505	 finalize: 0.6167
batch bounding time:  0.901724100112915
Current worst splitting domains [lb, ub] (depth):
[-0.08338,   inf] (77), [-0.08202,   inf] (77), [-0.08161,   inf] (77), [-0.08137,   inf] (77), [-0.08133,   inf] (77), [-0.08022,   inf] (77), [-0.08015,   inf] (77), [-0.08005,   inf] (77), [-0.07998,   inf] (77), [-0.07998,   inf] (77), [-0.07992,   inf] (77), [-0.07989,   inf] (77), [-0.07970,   inf] (77), [-0.07945,   inf] (75), [-0.07945,   inf] (31), [-0.07944,   inf] (29), [-0.07944,   inf] (41), [-0.07943,   inf] (71), [-0.07943,   inf] (27), [-0.07942,   inf] (57), 
length of domains: 1371
Total time: 1.0627	 pickout: 0.0537	 decision: 0.0938	 get_bound: 0.9020	 add_domain: 0.0132
Current lb:-0.08337542414665222
4346 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 43.04775953292847

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 313] [5, 313] [5, 485] [5, 485] [5, 313] [5, 485] [5, 313] [3, 1230] [5, 485] [5, 313] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.572644233703613 with beta sum per layer: [0.0, 0.0, 19.378751754760742, 4.836662769317627, 11.858039855957031, 41.64820861816406]
alpha/beta optimization time: 0.8009188175201416
This batch time : update_bounds func: 0.9057	 prepare: 0.0357	 bound: 0.8015	 transfer: 0.0515	 finalize: 0.0156
Accumulated time: update_bounds func: 33.1106	 prepare: 0.7884	 bound: 29.9265	 transfer: 0.0515	 finalize: 0.6323
batch bounding time:  0.9061403274536133
Current worst splitting domains [lb, ub] (depth):
[-0.08199,   inf] (79), [-0.08072,   inf] (79), [-0.08064,   inf] (79), [-0.08047,   inf] (79), [-0.08029,   inf] (79), [-0.07993,   inf] (79), [-0.07934,   inf] (79), [-0.07910,   inf] (79), [-0.07890,   inf] (79), [-0.07888,   inf] (79), [-0.07886,   inf] (45), [-0.07884,   inf] (19), [-0.07884,   inf] (73), [-0.07882,   inf] (33), [-0.07881,   inf] (37), [-0.07879,   inf] (37), [-0.07879,   inf] (61), [-0.07879,   inf] (75), [-0.07878,   inf] (27), [-0.07878,   inf] (77), 
length of domains: 1411
Total time: 1.1100	 pickout: 0.0872	 decision: 0.1039	 get_bound: 0.9064	 add_domain: 0.0125
Current lb:-0.08199203014373779
4474 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 44.16046357154846

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 1230] [5, 313] [3, 1230] [5, 313] [3, 1230] [3, 1230] [5, 313] [5, 313] [3, 1230] [5, 313] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.093289375305176 with beta sum per layer: [0.0, 0.0, 17.990692138671875, 7.761784076690674, 14.794267654418945, 34.68267059326172]
alpha/beta optimization time: 0.8049249649047852
This batch time : update_bounds func: 0.8923	 prepare: 0.0234	 bound: 0.8054	 transfer: 0.0469	 finalize: 0.0162
Accumulated time: update_bounds func: 34.0029	 prepare: 0.8118	 bound: 30.7319	 transfer: 0.0469	 finalize: 0.6485
batch bounding time:  0.8927037715911865
Current worst splitting domains [lb, ub] (depth):
[-0.08074,   inf] (81), [-0.08067,   inf] (81), [-0.07938,   inf] (81), [-0.07938,   inf] (81), [-0.07931,   inf] (81), [-0.07916,   inf] (81), [-0.07896,   inf] (81), [-0.07893,   inf] (81), [-0.07886,   inf] (81), [-0.07855,   inf] (73), [-0.07855,   inf] (41), [-0.07854,   inf] (33), [-0.07854,   inf] (79), [-0.07853,   inf] (27), [-0.07852,   inf] (81), [-0.07851,   inf] (79), [-0.07851,   inf] (69), [-0.07850,   inf] (77), [-0.07850,   inf] (79), [-0.07849,   inf] (19), 
length of domains: 1457
Total time: 1.0541	 pickout: 0.0526	 decision: 0.0947	 get_bound: 0.8929	 add_domain: 0.0139
Current lb:-0.08073534071445465
4602 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 45.21746587753296

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5612] [2, 5612] [2, 5612] [2, 5612] [2, 5612] [2, 5612] [2, 5612] [2, 5612] [2, 6101] [4, 29] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.914665222167969 with beta sum per layer: [0.0, 0.0, 17.645076751708984, 7.725517272949219, 11.174636840820312, 34.071258544921875]
alpha/beta optimization time: 0.7911586761474609
This batch time : update_bounds func: 0.8802	 prepare: 0.0234	 bound: 0.7916	 transfer: 0.0484	 finalize: 0.0164
Accumulated time: update_bounds func: 34.8832	 prepare: 0.8352	 bound: 31.5235	 transfer: 0.0484	 finalize: 0.6648
batch bounding time:  0.880643367767334
Current worst splitting domains [lb, ub] (depth):
[-0.07993,   inf] (83), [-0.07987,   inf] (83), [-0.07861,   inf] (83), [-0.07858,   inf] (83), [-0.07851,   inf] (83), [-0.07836,   inf] (83), [-0.07819,   inf] (83), [-0.07817,   inf] (27), [-0.07816,   inf] (35), [-0.07815,   inf] (73), [-0.07815,   inf] (49), [-0.07815,   inf] (83), [-0.07814,   inf] (49), [-0.07814,   inf] (47), [-0.07813,   inf] (77), [-0.07812,   inf] (37), [-0.07812,   inf] (61), [-0.07810,   inf] (25), [-0.07810,   inf] (31), [-0.07809,   inf] (73), 
length of domains: 1501
Total time: 1.0435	 pickout: 0.0545	 decision: 0.0943	 get_bound: 0.8809	 add_domain: 0.0139
Current lb:-0.07993345707654953
4730 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 46.26392889022827

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 466] [4, 466] [3, 3305] [4, 466] [4, 466] [3, 3305] [3, 3305] [4, 42] [5, 453] [5, 485] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.281510353088379 with beta sum per layer: [0.0, 0.0, 20.646167755126953, 6.300823211669922, 16.639686584472656, 28.140119552612305]
alpha/beta optimization time: 0.7993574142456055
This batch time : update_bounds func: 0.8878	 prepare: 0.0236	 bound: 0.7999	 transfer: 0.0484	 finalize: 0.0156
Accumulated time: update_bounds func: 35.7710	 prepare: 0.8587	 bound: 32.3234	 transfer: 0.0484	 finalize: 0.6804
batch bounding time:  0.8882191181182861
Current worst splitting domains [lb, ub] (depth):
[-0.07889,   inf] (85), [-0.07883,   inf] (85), [-0.07840,   inf] (85), [-0.07837,   inf] (85), [-0.07786,   inf] (85), [-0.07778,   inf] (73), [-0.07777,   inf] (41), [-0.07776,   inf] (25), [-0.07775,   inf] (63), [-0.07773,   inf] (27), [-0.07770,   inf] (53), [-0.07770,   inf] (51), [-0.07770,   inf] (25), [-0.07768,   inf] (31), [-0.07768,   inf] (27), [-0.07768,   inf] (21), [-0.07766,   inf] (81), [-0.07765,   inf] (83), [-0.07765,   inf] (53), [-0.07763,   inf] (85), 
length of domains: 1551
Total time: 1.0503	 pickout: 0.0508	 decision: 0.0956	 get_bound: 0.8884	 add_domain: 0.0154
Current lb:-0.07889316231012344
4858 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 47.31692719459534

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3305] [3, 3305] [3, 3305] [3, 3305] [2, 6101] [4, 29] [4, 466] [5, 270] [5, 491] [5, 270] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.0367302894592285 with beta sum per layer: [0.0, 0.0, 18.783527374267578, 16.80181312561035, 15.88965892791748, 31.540061950683594]
alpha/beta optimization time: 0.8279404640197754
This batch time : update_bounds func: 1.0161	 prepare: 0.0243	 bound: 0.8285	 transfer: 0.0515	 finalize: 0.1114
Accumulated time: update_bounds func: 36.7871	 prepare: 0.8831	 bound: 33.1519	 transfer: 0.0515	 finalize: 0.7918
batch bounding time:  1.016571044921875
Current worst splitting domains [lb, ub] (depth):
[-0.07817,   inf] (87), [-0.07810,   inf] (87), [-0.07768,   inf] (87), [-0.07764,   inf] (87), [-0.07740,   inf] (85), [-0.07739,   inf] (79), [-0.07739,   inf] (53), [-0.07739,   inf] (81), [-0.07739,   inf] (25), [-0.07738,   inf] (57), [-0.07738,   inf] (25), [-0.07738,   inf] (49), [-0.07737,   inf] (31), [-0.07737,   inf] (79), [-0.07736,   inf] (85), [-0.07735,   inf] (75), [-0.07735,   inf] (75), [-0.07734,   inf] (77), [-0.07734,   inf] (75), [-0.07734,   inf] (71), 
length of domains: 1601
Total time: 1.1780	 pickout: 0.0520	 decision: 0.0939	 get_bound: 1.0169	 add_domain: 0.0152
Current lb:-0.07816704362630844
4986 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 48.49791097640991

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 6101] [2, 6101] [2, 6101] [2, 6101] [2, 6101] [3, 1230] [5, 51] [3, 3305] [4, 262] [4, 135] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.046209335327148 with beta sum per layer: [0.0, 0.0, 18.28413963317871, 14.261890411376953, 10.560473442077637, 30.459396362304688]
alpha/beta optimization time: 0.7974538803100586
This batch time : update_bounds func: 0.8832	 prepare: 0.0247	 bound: 0.7979	 transfer: 0.0444	 finalize: 0.0157
Accumulated time: update_bounds func: 37.6703	 prepare: 0.9078	 bound: 33.9498	 transfer: 0.0444	 finalize: 0.8075
batch bounding time:  0.8836297988891602
Current worst splitting domains [lb, ub] (depth):
[-0.07716,   inf] (89), [-0.07713,   inf] (77), [-0.07713,   inf] (71), [-0.07713,   inf] (69), [-0.07712,   inf] (45), [-0.07711,   inf] (59), [-0.07710,   inf] (89), [-0.07709,   inf] (73), [-0.07709,   inf] (79), [-0.07708,   inf] (71), [-0.07707,   inf] (75), [-0.07707,   inf] (83), [-0.07706,   inf] (71), [-0.07706,   inf] (41), [-0.07705,   inf] (79), [-0.07705,   inf] (23), [-0.07704,   inf] (77), [-0.07704,   inf] (81), [-0.07703,   inf] (37), [-0.07703,   inf] (39), 
length of domains: 1646
Total time: 1.0920	 pickout: 0.0971	 decision: 0.0950	 get_bound: 0.8838	 add_domain: 0.0161
Current lb:-0.07716494798660278
5114 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 49.59281373023987

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 266] [4, 29] [5, 221] [5, 221] [4, 42] [4, 182] [5, 266] [5, 221] [3, 1230] [5, 485] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.421893119812012 with beta sum per layer: [0.0, 0.0, 25.237045288085938, 12.061853408813477, 9.763815879821777, 32.66331481933594]
alpha/beta optimization time: 0.7945137023925781
This batch time : update_bounds func: 0.8841	 prepare: 0.0239	 bound: 0.7950	 transfer: 0.0485	 finalize: 0.0162
Accumulated time: update_bounds func: 38.5544	 prepare: 0.9316	 bound: 34.7448	 transfer: 0.0485	 finalize: 0.8237
batch bounding time:  0.8844544887542725
Current worst splitting domains [lb, ub] (depth):
[-0.07683,   inf] (89), [-0.07682,   inf] (85), [-0.07682,   inf] (85), [-0.07682,   inf] (83), [-0.07682,   inf] (45), [-0.07682,   inf] (39), [-0.07681,   inf] (59), [-0.07680,   inf] (43), [-0.07680,   inf] (87), [-0.07678,   inf] (39), [-0.07678,   inf] (49), [-0.07678,   inf] (65), [-0.07677,   inf] (73), [-0.07677,   inf] (41), [-0.07676,   inf] (83), [-0.07676,   inf] (85), [-0.07676,   inf] (23), [-0.07676,   inf] (43), [-0.07675,   inf] (31), [-0.07674,   inf] (77), 
length of domains: 1687
Total time: 1.0458	 pickout: 0.0535	 decision: 0.0936	 get_bound: 0.8847	 add_domain: 0.0140
Current lb:-0.07682707905769348
5242 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 50.64129018783569

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 266] [3, 3305] [2, 5612] [2, 5612] [4, 302] [5, 453] [5, 491] [5, 509] [2, 6101] [4, 376] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.961099624633789 with beta sum per layer: [0.0, 0.0, 20.56005859375, 7.479981422424316, 10.114974021911621, 32.459632873535156]
alpha/beta optimization time: 0.8012371063232422
This batch time : update_bounds func: 0.8905	 prepare: 0.0241	 bound: 0.8018	 transfer: 0.0487	 finalize: 0.0155
Accumulated time: update_bounds func: 39.4449	 prepare: 0.9557	 bound: 35.5466	 transfer: 0.0487	 finalize: 0.8392
batch bounding time:  0.8909010887145996
Current worst splitting domains [lb, ub] (depth):
[-0.07648,   inf] (33), [-0.07648,   inf] (85), [-0.07648,   inf] (49), [-0.07648,   inf] (77), [-0.07647,   inf] (85), [-0.07647,   inf] (27), [-0.07647,   inf] (75), [-0.07646,   inf] (65), [-0.07645,   inf] (83), [-0.07644,   inf] (49), [-0.07643,   inf] (81), [-0.07643,   inf] (73), [-0.07643,   inf] (25), [-0.07643,   inf] (35), [-0.07642,   inf] (75), [-0.07642,   inf] (25), [-0.07642,   inf] (83), [-0.07641,   inf] (51), [-0.07641,   inf] (83), [-0.07640,   inf] (45), 
length of domains: 1733
Total time: 1.0962	 pickout: 0.0957	 decision: 0.0944	 get_bound: 0.8911	 add_domain: 0.0149
Current lb:-0.07647906243801117
5370 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 51.74009656906128

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 109] [2, 6101] [5, 294] [2, 9157] [2, 5612] [4, 466] [5, 313] [5, 221] [5, 266] [5, 6] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.787713050842285 with beta sum per layer: [0.0, 0.0, 24.969707489013672, 15.507007598876953, 6.239655494689941, 24.125276565551758]
alpha/beta optimization time: 0.8161478042602539
This batch time : update_bounds func: 0.9158	 prepare: 0.0240	 bound: 0.8166	 transfer: 0.0485	 finalize: 0.0263
Accumulated time: update_bounds func: 40.3606	 prepare: 0.9797	 bound: 36.3632	 transfer: 0.0485	 finalize: 0.8655
batch bounding time:  0.9162344932556152
Current worst splitting domains [lb, ub] (depth):
[-0.07622,   inf] (75), [-0.07622,   inf] (85), [-0.07621,   inf] (83), [-0.07621,   inf] (85), [-0.07621,   inf] (67), [-0.07620,   inf] (83), [-0.07620,   inf] (87), [-0.07620,   inf] (83), [-0.07620,   inf] (81), [-0.07620,   inf] (33), [-0.07619,   inf] (33), [-0.07618,   inf] (59), [-0.07618,   inf] (81), [-0.07618,   inf] (75), [-0.07618,   inf] (81), [-0.07617,   inf] (87), [-0.07617,   inf] (83), [-0.07617,   inf] (81), [-0.07616,   inf] (81), [-0.07616,   inf] (73), 
length of domains: 1784
Total time: 1.1271	 pickout: 0.0991	 decision: 0.0949	 get_bound: 0.9165	 add_domain: 0.0167
Current lb:-0.07621639966964722
5498 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 52.87010478973389

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 485] [2, 5612] [3, 3305] [3, 3305] [5, 221] [3, 3305] [2, 6101] [3, 3305] [3, 3305] [5, 270] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.570059776306152 with beta sum per layer: [0.0, 0.0, 32.133182525634766, 22.26518440246582, 5.512198448181152, 24.413307189941406]
alpha/beta optimization time: 0.8565256595611572
This batch time : update_bounds func: 0.9515	 prepare: 0.0242	 bound: 0.8570	 transfer: 0.0535	 finalize: 0.0156
Accumulated time: update_bounds func: 41.3122	 prepare: 1.0039	 bound: 37.2202	 transfer: 0.0535	 finalize: 0.8810
batch bounding time:  0.9519810676574707
Current worst splitting domains [lb, ub] (depth):
[-0.07598,   inf] (85), [-0.07598,   inf] (47), [-0.07598,   inf] (81), [-0.07598,   inf] (81), [-0.07598,   inf] (49), [-0.07596,   inf] (83), [-0.07595,   inf] (83), [-0.07595,   inf] (89), [-0.07594,   inf] (75), [-0.07594,   inf] (81), [-0.07594,   inf] (91), [-0.07594,   inf] (81), [-0.07594,   inf] (85), [-0.07594,   inf] (61), [-0.07593,   inf] (51), [-0.07592,   inf] (79), [-0.07592,   inf] (31), [-0.07591,   inf] (81), [-0.07591,   inf] (85), [-0.07590,   inf] (75), 
length of domains: 1836
Total time: 1.1180	 pickout: 0.0514	 decision: 0.0943	 get_bound: 0.9522	 add_domain: 0.0202
Current lb:-0.07597994804382324
5626 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 53.992103576660156

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 6101] [5, 51] [3, 3305] [3, 3305] [5, 51] [3, 3305] [3, 3305] [2, 5298] [5, 485] [3, 3305] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.501259803771973 with beta sum per layer: [0.0, 0.0, 31.282737731933594, 18.429309844970703, 8.486530303955078, 27.986141204833984]
alpha/beta optimization time: 0.8081281185150146
This batch time : update_bounds func: 0.8984	 prepare: 0.0242	 bound: 0.8087	 transfer: 0.0487	 finalize: 0.0165
Accumulated time: update_bounds func: 42.2106	 prepare: 1.0280	 bound: 38.0289	 transfer: 0.0487	 finalize: 0.8975
batch bounding time:  0.89888596534729
Current worst splitting domains [lb, ub] (depth):
[-0.07573,   inf] (75), [-0.07573,   inf] (37), [-0.07572,   inf] (89), [-0.07570,   inf] (79), [-0.07570,   inf] (31), [-0.07569,   inf] (69), [-0.07569,   inf] (93), [-0.07569,   inf] (89), [-0.07569,   inf] (55), [-0.07569,   inf] (39), [-0.07568,   inf] (89), [-0.07568,   inf] (73), [-0.07566,   inf] (71), [-0.07566,   inf] (79), [-0.07566,   inf] (49), [-0.07566,   inf] (75), [-0.07565,   inf] (89), [-0.07565,   inf] (75), [-0.07564,   inf] (81), [-0.07564,   inf] (85), 
length of domains: 1880
Total time: 1.0773	 pickout: 0.0578	 decision: 0.1048	 get_bound: 0.8991	 add_domain: 0.0156
Current lb:-0.07573080062866211
5754 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 55.072545528411865

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 313] [5, 496] [2, 5298] [3, 1230] [4, 109] [3, 3837] [2, 5298] [2, 5298] [5, 491] [5, 496] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.207865238189697 with beta sum per layer: [0.0, 0.0, 28.632036209106445, 12.825054168701172, 7.8507184982299805, 30.600074768066406]
alpha/beta optimization time: 0.8122971057891846
This batch time : update_bounds func: 0.9077	 prepare: 0.0256	 bound: 0.8128	 transfer: 0.0516	 finalize: 0.0172
Accumulated time: update_bounds func: 43.1183	 prepare: 1.0536	 bound: 38.8417	 transfer: 0.0516	 finalize: 0.9147
batch bounding time:  0.9081075191497803
Current worst splitting domains [lb, ub] (depth):
[-0.07549,   inf] (87), [-0.07549,   inf] (35), [-0.07548,   inf] (49), [-0.07548,   inf] (87), [-0.07548,   inf] (91), [-0.07548,   inf] (81), [-0.07548,   inf] (51), [-0.07547,   inf] (51), [-0.07546,   inf] (85), [-0.07546,   inf] (37), [-0.07546,   inf] (73), [-0.07546,   inf] (85), [-0.07546,   inf] (89), [-0.07545,   inf] (87), [-0.07545,   inf] (45), [-0.07545,   inf] (81), [-0.07545,   inf] (73), [-0.07545,   inf] (87), [-0.07544,   inf] (89), [-0.07544,   inf] (41), 
length of domains: 1929
Total time: 1.0964	 pickout: 0.0637	 decision: 0.1083	 get_bound: 0.9083	 add_domain: 0.0161
Current lb:-0.07548606395721436
5882 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 56.171836853027344

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 10955] [5, 453] [4, 376] [2, 6101] [5, 406] [3, 3305] [4, 376] [5, 51] [3, 3305] [5, 453] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.743376731872559 with beta sum per layer: [0.0, 0.0, 40.05382537841797, 7.122027397155762, 10.399953842163086, 30.97900390625]
alpha/beta optimization time: 0.7972633838653564
This batch time : update_bounds func: 0.8841	 prepare: 0.0240	 bound: 0.7977	 transfer: 0.0456	 finalize: 0.0163
Accumulated time: update_bounds func: 44.0024	 prepare: 1.0776	 bound: 39.6394	 transfer: 0.0456	 finalize: 0.9310
batch bounding time:  0.884486198425293
Current worst splitting domains [lb, ub] (depth):
[-0.07532,   inf] (83), [-0.07532,   inf] (71), [-0.07532,   inf] (93), [-0.07532,   inf] (75), [-0.07532,   inf] (21), [-0.07532,   inf] (29), [-0.07531,   inf] (83), [-0.07531,   inf] (75), [-0.07531,   inf] (39), [-0.07530,   inf] (55), [-0.07530,   inf] (51), [-0.07529,   inf] (87), [-0.07529,   inf] (85), [-0.07529,   inf] (87), [-0.07528,   inf] (55), [-0.07528,   inf] (85), [-0.07528,   inf] (85), [-0.07527,   inf] (69), [-0.07527,   inf] (85), [-0.07525,   inf] (85), 
length of domains: 1973
Total time: 1.1348	 pickout: 0.0557	 decision: 0.1792	 get_bound: 0.8847	 add_domain: 0.0152
Current lb:-0.07532393932342529
6010 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 57.30933690071106

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 266] [5, 221] [2, 5298] [5, 313] [4, 42] [5, 218] [3, 3305] [5, 313] [4, 466] [5, 294] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.450482368469238 with beta sum per layer: [0.0, 0.0, 34.683265686035156, 7.731977462768555, 9.308241844177246, 23.839603424072266]
alpha/beta optimization time: 0.7943599224090576
This batch time : update_bounds func: 0.8845	 prepare: 0.0243	 bound: 0.7948	 transfer: 0.0484	 finalize: 0.0165
Accumulated time: update_bounds func: 44.8868	 prepare: 1.1019	 bound: 40.4342	 transfer: 0.0484	 finalize: 0.9475
batch bounding time:  0.8848721981048584
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (77), [-0.07510,   inf] (75), [-0.07508,   inf] (85), [-0.07508,   inf] (73), [-0.07508,   inf] (49), [-0.07508,   inf] (61), [-0.07508,   inf] (21), [-0.07508,   inf] (73), [-0.07507,   inf] (89), [-0.07507,   inf] (85), [-0.07507,   inf] (83), [-0.07507,   inf] (43), [-0.07507,   inf] (89), [-0.07506,   inf] (75), [-0.07506,   inf] (67), [-0.07506,   inf] (79), [-0.07506,   inf] (85), [-0.07505,   inf] (83), [-0.07505,   inf] (79), [-0.07505,   inf] (89), 
length of domains: 2023
Total time: 1.0480	 pickout: 0.0519	 decision: 0.0943	 get_bound: 0.8851	 add_domain: 0.0167
Current lb:-0.07510435581207275
6138 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 58.36028003692627

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 313] [3, 1900] [2, 5612] [5, 221] [5, 245] [3, 1230] [4, 402] [2, 9157] [5, 266] [2, 5612] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.105839729309082 with beta sum per layer: [0.0, 0.0, 35.617462158203125, 14.00318717956543, 10.575366020202637, 25.79779815673828]
alpha/beta optimization time: 0.8033597469329834
This batch time : update_bounds func: 0.8923	 prepare: 0.0240	 bound: 0.8039	 transfer: 0.0483	 finalize: 0.0156
Accumulated time: update_bounds func: 45.7791	 prepare: 1.1259	 bound: 41.2381	 transfer: 0.0483	 finalize: 0.9631
batch bounding time:  0.8927085399627686
Current worst splitting domains [lb, ub] (depth):
[-0.07490,   inf] (81), [-0.07490,   inf] (85), [-0.07489,   inf] (31), [-0.07489,   inf] (77), [-0.07489,   inf] (47), [-0.07489,   inf] (47), [-0.07489,   inf] (65), [-0.07488,   inf] (83), [-0.07488,   inf] (89), [-0.07488,   inf] (77), [-0.07487,   inf] (27), [-0.07487,   inf] (87), [-0.07487,   inf] (91), [-0.07486,   inf] (93), [-0.07486,   inf] (75), [-0.07486,   inf] (71), [-0.07485,   inf] (87), [-0.07485,   inf] (41), [-0.07485,   inf] (33), [-0.07485,   inf] (89), 
length of domains: 2075
Total time: 1.0578	 pickout: 0.0515	 decision: 0.0963	 get_bound: 0.8929	 add_domain: 0.0171
Current lb:-0.07490265369415283
6266 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 59.421085834503174

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 266] [2, 5612] [4, 402] [3, 1230] [5, 6] [4, 376] [5, 406] [3, 653] [2, 4279] [5, 313] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.504067420959473 with beta sum per layer: [0.0, 0.0, 55.52671813964844, 27.474462509155273, 6.585031509399414, 19.082870483398438]
alpha/beta optimization time: 0.8067891597747803
This batch time : update_bounds func: 0.8969	 prepare: 0.0245	 bound: 0.8073	 transfer: 0.0484	 finalize: 0.0163
Accumulated time: update_bounds func: 46.6760	 prepare: 1.1504	 bound: 42.0454	 transfer: 0.0484	 finalize: 0.9794
batch bounding time:  0.8972914218902588
Current worst splitting domains [lb, ub] (depth):
[-0.07474,   inf] (89), [-0.07474,   inf] (87), [-0.07474,   inf] (83), [-0.07474,   inf] (83), [-0.07473,   inf] (77), [-0.07473,   inf] (85), [-0.07473,   inf] (73), [-0.07473,   inf] (73), [-0.07472,   inf] (89), [-0.07472,   inf] (79), [-0.07472,   inf] (81), [-0.07472,   inf] (79), [-0.07472,   inf] (27), [-0.07472,   inf] (95), [-0.07471,   inf] (85), [-0.07471,   inf] (91), [-0.07471,   inf] (59), [-0.07471,   inf] (69), [-0.07470,   inf] (91), [-0.07470,   inf] (85), 
length of domains: 2128
Total time: 1.0636	 pickout: 0.0536	 decision: 0.0948	 get_bound: 0.8975	 add_domain: 0.0177
Current lb:-0.07474136352539062
6394 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 60.48730206489563

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 653] [2, 6101] [3, 653] [3, 3305] [5, 313] [2, 5612] [2, 9157] [5, 485] [5, 266] [3, 1230] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.898276329040527 with beta sum per layer: [0.0, 0.0, 45.470550537109375, 18.37592315673828, 8.24846076965332, 19.20391082763672]
alpha/beta optimization time: 0.8177528381347656
This batch time : update_bounds func: 0.9221	 prepare: 0.0242	 bound: 0.8182	 transfer: 0.0494	 finalize: 0.0297
Accumulated time: update_bounds func: 47.5981	 prepare: 1.1746	 bound: 42.8636	 transfer: 0.0494	 finalize: 1.0091
batch bounding time:  0.9227128028869629
Current worst splitting domains [lb, ub] (depth):
[-0.07457,   inf] (39), [-0.07457,   inf] (87), [-0.07457,   inf] (75), [-0.07456,   inf] (91), [-0.07456,   inf] (89), [-0.07456,   inf] (79), [-0.07456,   inf] (85), [-0.07456,   inf] (87), [-0.07454,   inf] (91), [-0.07454,   inf] (49), [-0.07454,   inf] (53), [-0.07454,   inf] (85), [-0.07454,   inf] (45), [-0.07453,   inf] (85), [-0.07453,   inf] (87), [-0.07453,   inf] (85), [-0.07453,   inf] (37), [-0.07453,   inf] (29), [-0.07453,   inf] (83), [-0.07452,   inf] (91), 
length of domains: 2175
Total time: 1.0905	 pickout: 0.0524	 decision: 0.0946	 get_bound: 0.9231	 add_domain: 0.0203
Current lb:-0.0745740532875061
6522 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 61.58075833320618

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 496] [5, 266] [5, 313] [5, 406] [2, 5298] [4, 29] [5, 266] [2, 4279] [5, 406] [4, 376] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.201513290405273 with beta sum per layer: [0.0, 0.0, 38.74445724487305, 5.150275230407715, 7.6154069900512695, 28.14556312561035]
alpha/beta optimization time: 0.8097145557403564
This batch time : update_bounds func: 0.9107	 prepare: 0.0355	 bound: 0.8102	 transfer: 0.0483	 finalize: 0.0163
Accumulated time: update_bounds func: 48.5088	 prepare: 1.2101	 bound: 43.6738	 transfer: 0.0483	 finalize: 1.0255
batch bounding time:  0.9111316204071045
Current worst splitting domains [lb, ub] (depth):
[-0.07438,   inf] (51), [-0.07437,   inf] (21), [-0.07437,   inf] (79), [-0.07436,   inf] (57), [-0.07436,   inf] (57), [-0.07436,   inf] (49), [-0.07435,   inf] (87), [-0.07435,   inf] (35), [-0.07435,   inf] (87), [-0.07435,   inf] (81), [-0.07434,   inf] (75), [-0.07434,   inf] (83), [-0.07434,   inf] (87), [-0.07433,   inf] (53), [-0.07433,   inf] (95), [-0.07433,   inf] (87), [-0.07433,   inf] (43), [-0.07432,   inf] (29), [-0.07432,   inf] (73), [-0.07432,   inf] (83), 
length of domains: 2221
Total time: 1.0745	 pickout: 0.0440	 decision: 0.1027	 get_bound: 0.9113	 add_domain: 0.0164
Current lb:-0.07437610626220703
6650 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 62.65791463851929

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 51] [5, 240] [3, 1900] [4, 357] [3, 3837] [4, 376] [5, 266] [5, 453] [2, 4279] [3, 3305] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.529974937438965 with beta sum per layer: [0.0, 0.0, 46.855621337890625, 9.418302536010742, 8.409280776977539, 23.873306274414062]
alpha/beta optimization time: 0.7979781627655029
This batch time : update_bounds func: 0.8874	 prepare: 0.0245	 bound: 0.7985	 transfer: 0.0483	 finalize: 0.0157
Accumulated time: update_bounds func: 49.3962	 prepare: 1.2347	 bound: 44.4723	 transfer: 0.0483	 finalize: 1.0412
batch bounding time:  0.8878588676452637
Current worst splitting domains [lb, ub] (depth):
[-0.07423,   inf] (91), [-0.07423,   inf] (51), [-0.07423,   inf] (41), [-0.07422,   inf] (89), [-0.07422,   inf] (29), [-0.07422,   inf] (83), [-0.07422,   inf] (91), [-0.07421,   inf] (81), [-0.07421,   inf] (49), [-0.07421,   inf] (79), [-0.07420,   inf] (85), [-0.07420,   inf] (87), [-0.07420,   inf] (23), [-0.07420,   inf] (85), [-0.07420,   inf] (83), [-0.07420,   inf] (93), [-0.07420,   inf] (71), [-0.07419,   inf] (89), [-0.07419,   inf] (49), [-0.07419,   inf] (95), 
length of domains: 2265
Total time: 1.0437	 pickout: 0.0434	 decision: 0.0949	 get_bound: 0.8881	 add_domain: 0.0173
Current lb:-0.074229396879673
6778 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 63.70456790924072

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5302] [5, 51] [5, 496] [4, 445] [5, 453] [3, 3305] [5, 406] [2, 6101] [5, 294] [3, 1900] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.019359111785889 with beta sum per layer: [0.0, 0.0, 48.92620086669922, 12.907394409179688, 8.30668830871582, 19.42963409423828]
alpha/beta optimization time: 0.7905750274658203
This batch time : update_bounds func: 0.9800	 prepare: 0.0245	 bound: 0.7911	 transfer: 0.0482	 finalize: 0.1158
Accumulated time: update_bounds func: 50.3762	 prepare: 1.2592	 bound: 45.2633	 transfer: 0.0482	 finalize: 1.1570
batch bounding time:  0.9805114269256592
Current worst splitting domains [lb, ub] (depth):
[-0.07408,   inf] (19), [-0.07408,   inf] (91), [-0.07407,   inf] (37), [-0.07407,   inf] (47), [-0.07407,   inf] (89), [-0.07407,   inf] (77), [-0.07407,   inf] (73), [-0.07406,   inf] (87), [-0.07406,   inf] (33), [-0.07406,   inf] (49), [-0.07406,   inf] (35), [-0.07405,   inf] (85), [-0.07405,   inf] (45), [-0.07404,   inf] (85), [-0.07404,   inf] (29), [-0.07404,   inf] (85), [-0.07404,   inf] (83), [-0.07403,   inf] (89), [-0.07403,   inf] (29), [-0.07403,   inf] (73), 
length of domains: 2313
Total time: 1.1484	 pickout: 0.0563	 decision: 0.0938	 get_bound: 0.9808	 add_domain: 0.0176
Current lb:-0.07407665252685547
6906 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 64.8557357788086

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 240] [2, 4279] [5, 496] [4, 113] [4, 466] [3, 1900] [5, 485] [3, 653] [4, 42] [5, 245] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.726925373077393 with beta sum per layer: [0.0, 0.0, 36.91670227050781, 9.36285400390625, 16.871047973632812, 23.792043685913086]
alpha/beta optimization time: 0.7875525951385498
This batch time : update_bounds func: 0.8773	 prepare: 0.0242	 bound: 0.7880	 transfer: 0.0481	 finalize: 0.0156
Accumulated time: update_bounds func: 51.2535	 prepare: 1.2834	 bound: 46.0513	 transfer: 0.0481	 finalize: 1.1726
batch bounding time:  0.8777384757995605
Current worst splitting domains [lb, ub] (depth):
[-0.07393,   inf] (81), [-0.07393,   inf] (89), [-0.07393,   inf] (35), [-0.07393,   inf] (77), [-0.07393,   inf] (77), [-0.07392,   inf] (91), [-0.07392,   inf] (77), [-0.07392,   inf] (83), [-0.07391,   inf] (81), [-0.07391,   inf] (83), [-0.07391,   inf] (63), [-0.07391,   inf] (83), [-0.07391,   inf] (87), [-0.07391,   inf] (43), [-0.07391,   inf] (35), [-0.07391,   inf] (81), [-0.07391,   inf] (93), [-0.07391,   inf] (85), [-0.07390,   inf] (69), [-0.07390,   inf] (83), 
length of domains: 2355
Total time: 1.0407	 pickout: 0.0535	 decision: 0.0934	 get_bound: 0.8780	 add_domain: 0.0157
Current lb:-0.07393240928649902
7034 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 65.89932775497437

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5612] [2, 5298] [5, 453] [4, 29] [2, 9157] [5, 406] [2, 9157] [4, 445] [3, 3305] [5, 266] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.246753692626953 with beta sum per layer: [0.0, 0.0, 57.866477966308594, 18.407817840576172, 8.209178924560547, 22.147655487060547]
alpha/beta optimization time: 0.8156099319458008
This batch time : update_bounds func: 0.9070	 prepare: 0.0245	 bound: 0.8161	 transfer: 0.0494	 finalize: 0.0166
Accumulated time: update_bounds func: 52.1606	 prepare: 1.3079	 bound: 46.8675	 transfer: 0.0494	 finalize: 1.1892
batch bounding time:  0.9074399471282959
Current worst splitting domains [lb, ub] (depth):
[-0.07382,   inf] (91), [-0.07382,   inf] (33), [-0.07381,   inf] (81), [-0.07381,   inf] (49), [-0.07380,   inf] (35), [-0.07380,   inf] (73), [-0.07380,   inf] (93), [-0.07380,   inf] (81), [-0.07380,   inf] (87), [-0.07380,   inf] (89), [-0.07379,   inf] (69), [-0.07379,   inf] (63), [-0.07379,   inf] (87), [-0.07379,   inf] (19), [-0.07379,   inf] (81), [-0.07378,   inf] (35), [-0.07378,   inf] (83), [-0.07378,   inf] (29), [-0.07378,   inf] (33), [-0.07378,   inf] (91), 
length of domains: 2405
Total time: 1.0662	 pickout: 0.0461	 decision: 0.0951	 get_bound: 0.9077	 add_domain: 0.0173
Current lb:-0.07382082939147949
7162 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 66.96823263168335

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3036] [5, 6] [3, 3305] [4, 441] [4, 309] [5, 221] [2, 4279] [5, 266] [2, 10955] [4, 466] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.145283222198486 with beta sum per layer: [0.0, 0.0, 37.06584167480469, 16.763011932373047, 7.728473663330078, 25.43597412109375]
alpha/beta optimization time: 0.7886888980865479
This batch time : update_bounds func: 0.8818	 prepare: 0.0242	 bound: 0.7892	 transfer: 0.0495	 finalize: 0.0185
Accumulated time: update_bounds func: 53.0423	 prepare: 1.3321	 bound: 47.6566	 transfer: 0.0495	 finalize: 1.2077
batch bounding time:  0.8822052478790283
Current worst splitting domains [lb, ub] (depth):
[-0.07368,   inf] (25), [-0.07368,   inf] (55), [-0.07367,   inf] (87), [-0.07367,   inf] (73), [-0.07367,   inf] (83), [-0.07367,   inf] (25), [-0.07366,   inf] (15), [-0.07366,   inf] (89), [-0.07366,   inf] (93), [-0.07366,   inf] (85), [-0.07366,   inf] (87), [-0.07366,   inf] (93), [-0.07366,   inf] (89), [-0.07366,   inf] (87), [-0.07365,   inf] (83), [-0.07365,   inf] (89), [-0.07365,   inf] (87), [-0.07365,   inf] (33), [-0.07365,   inf] (23), [-0.07365,   inf] (89), 
length of domains: 2453
Total time: 1.0774	 pickout: 0.0849	 decision: 0.0932	 get_bound: 0.8824	 add_domain: 0.0169
Current lb:-0.07367897033691406
7290 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 68.0487711429596

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 135] [5, 51] [3, 653] [5, 485] [3, 3305] [5, 106] [5, 177] [2, 5298] [2, 5302] [2, 5612] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.948720932006836 with beta sum per layer: [0.0, 0.0, 47.06963348388672, 15.328302383422852, 9.599332809448242, 22.096221923828125]
alpha/beta optimization time: 0.796044111251831
This batch time : update_bounds func: 0.9000	 prepare: 0.0252	 bound: 0.7965	 transfer: 0.0514	 finalize: 0.0265
Accumulated time: update_bounds func: 53.9423	 prepare: 1.3573	 bound: 48.4531	 transfer: 0.0514	 finalize: 1.2342
batch bounding time:  0.9005513191223145
Current worst splitting domains [lb, ub] (depth):
[-0.07358,   inf] (75), [-0.07358,   inf] (77), [-0.07357,   inf] (93), [-0.07357,   inf] (81), [-0.07356,   inf] (97), [-0.07356,   inf] (91), [-0.07356,   inf] (83), [-0.07356,   inf] (79), [-0.07356,   inf] (79), [-0.07356,   inf] (89), [-0.07355,   inf] (93), [-0.07355,   inf] (81), [-0.07355,   inf] (95), [-0.07355,   inf] (39), [-0.07355,   inf] (79), [-0.07355,   inf] (99), [-0.07355,   inf] (93), [-0.07355,   inf] (91), [-0.07354,   inf] (33), [-0.07354,   inf] (93), 
length of domains: 2500
Total time: 1.0737	 pickout: 0.0556	 decision: 0.0951	 get_bound: 0.9009	 add_domain: 0.0221
Current lb:-0.07357645034790039
7418 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 69.12527918815613

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 485] [3, 1230] [2, 5298] [3, 3305] [2, 5302] [3, 3036] [3, 653] [2, 7879] [3, 1230] [5, 266] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.012441158294678 with beta sum per layer: [0.0, 0.0, 46.29808044433594, 18.489337921142578, 8.263460159301758, 24.565982818603516]
alpha/beta optimization time: 0.7926900386810303
This batch time : update_bounds func: 0.8830	 prepare: 0.0246	 bound: 0.7932	 transfer: 0.0483	 finalize: 0.0166
Accumulated time: update_bounds func: 54.8254	 prepare: 1.3818	 bound: 49.2463	 transfer: 0.0483	 finalize: 1.2508
batch bounding time:  0.8834381103515625
Current worst splitting domains [lb, ub] (depth):
[-0.07346,   inf] (79), [-0.07346,   inf] (63), [-0.07345,   inf] (31), [-0.07345,   inf] (81), [-0.07345,   inf] (89), [-0.07345,   inf] (89), [-0.07345,   inf] (29), [-0.07345,   inf] (23), [-0.07345,   inf] (53), [-0.07345,   inf] (89), [-0.07345,   inf] (83), [-0.07344,   inf] (93), [-0.07344,   inf] (51), [-0.07344,   inf] (53), [-0.07344,   inf] (95), [-0.07344,   inf] (17), [-0.07344,   inf] (91), [-0.07344,   inf] (49), [-0.07344,   inf] (83), [-0.07344,   inf] (89), 
length of domains: 2543
Total time: 1.0595	 pickout: 0.0640	 decision: 0.0950	 get_bound: 0.8837	 add_domain: 0.0168
Current lb:-0.07345807552337646
7546 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 70.18817377090454

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 6101] [5, 221] [5, 106] [3, 3305] [4, 466] [2, 5298] [4, 109] [5, 240] [5, 294] [2, 4279] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.2149457931518555 with beta sum per layer: [0.0, 0.0, 42.239749908447266, 20.484195709228516, 10.670055389404297, 26.04399871826172]
alpha/beta optimization time: 0.8047587871551514
This batch time : update_bounds func: 0.8905	 prepare: 0.0242	 bound: 0.8052	 transfer: 0.0450	 finalize: 0.0156
Accumulated time: update_bounds func: 55.7159	 prepare: 1.4060	 bound: 50.0515	 transfer: 0.0450	 finalize: 1.2664
batch bounding time:  0.8909637928009033
Current worst splitting domains [lb, ub] (depth):
[-0.07336,   inf] (85), [-0.07335,   inf] (89), [-0.07335,   inf] (79), [-0.07335,   inf] (47), [-0.07334,   inf] (93), [-0.07334,   inf] (51), [-0.07334,   inf] (31), [-0.07334,   inf] (37), [-0.07334,   inf] (97), [-0.07334,   inf] (79), [-0.07334,   inf] (81), [-0.07334,   inf] (99), [-0.07333,   inf] (95), [-0.07333,   inf] (79), [-0.07333,   inf] (81), [-0.07333,   inf] (39), [-0.07333,   inf] (47), [-0.07333,   inf] (89), [-0.07333,   inf] (81), [-0.07333,   inf] (93), 
length of domains: 2595
Total time: 1.0611	 pickout: 0.0556	 decision: 0.0953	 get_bound: 0.8912	 add_domain: 0.0190
Current lb:-0.0733557939529419
7674 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 71.25215101242065

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 6101] [2, 5298] [5, 313] [4, 402] [2, 5302] [5, 51] [5, 218] [5, 453] [2, 10955] [2, 6101] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.391159534454346 with beta sum per layer: [0.0, 0.0, 56.731658935546875, 15.649341583251953, 2.8916640281677246, 21.46344566345215]
alpha/beta optimization time: 0.8070697784423828
This batch time : update_bounds func: 0.8989	 prepare: 0.0254	 bound: 0.8076	 transfer: 0.0490	 finalize: 0.0164
Accumulated time: update_bounds func: 56.6148	 prepare: 1.4315	 bound: 50.8591	 transfer: 0.0490	 finalize: 1.2828
batch bounding time:  0.8993039131164551
Current worst splitting domains [lb, ub] (depth):
[-0.07326,   inf] (39), [-0.07326,   inf] (75), [-0.07325,   inf] (87), [-0.07325,   inf] (77), [-0.07325,   inf] (17), [-0.07324,   inf] (85), [-0.07324,   inf] (87), [-0.07324,   inf] (85), [-0.07324,   inf] (85), [-0.07324,   inf] (81), [-0.07324,   inf] (91), [-0.07324,   inf] (63), [-0.07323,   inf] (71), [-0.07323,   inf] (87), [-0.07323,   inf] (87), [-0.07323,   inf] (87), [-0.07323,   inf] (55), [-0.07323,   inf] (63), [-0.07323,   inf] (93), [-0.07323,   inf] (79), 
length of domains: 2649
Total time: 1.0682	 pickout: 0.0558	 decision: 0.0943	 get_bound: 0.8995	 add_domain: 0.0186
Current lb:-0.07325565814971924
7802 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 72.32312893867493

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 496] [5, 313] [3, 653] [5, 485] [5, 309] [2, 5612] [5, 266] [2, 5612] [3, 653] [3, 3305] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.75714111328125 with beta sum per layer: [0.0, 0.0, 55.28687286376953, 16.811405181884766, 3.4372684955596924, 18.288421630859375]
alpha/beta optimization time: 0.7939536571502686
This batch time : update_bounds func: 0.8819	 prepare: 0.0253	 bound: 0.7945	 transfer: 0.0461	 finalize: 0.0157
Accumulated time: update_bounds func: 57.4967	 prepare: 1.4567	 bound: 51.6536	 transfer: 0.0461	 finalize: 1.2984
batch bounding time:  0.8822922706604004
Current worst splitting domains [lb, ub] (depth):
[-0.07316,   inf] (95), [-0.07316,   inf] (97), [-0.07316,   inf] (93), [-0.07316,   inf] (73), [-0.07316,   inf] (73), [-0.07315,   inf] (95), [-0.07315,   inf] (73), [-0.07315,   inf] (73), [-0.07315,   inf] (25), [-0.07315,   inf] (43), [-0.07314,   inf] (81), [-0.07314,   inf] (95), [-0.07314,   inf] (87), [-0.07314,   inf] (75), [-0.07314,   inf] (37), [-0.07313,   inf] (53), [-0.07313,   inf] (89), [-0.07313,   inf] (41), [-0.07313,   inf] (49), [-0.07312,   inf] (47), 
length of domains: 2707
Total time: 1.1795	 pickout: 0.0510	 decision: 0.2260	 get_bound: 0.8825	 add_domain: 0.0200
Current lb:-0.07315874099731445
7930 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 73.50524806976318

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5298] [3, 3036] [2, 5298] [5, 313] [5, 485] [3, 3836] [3, 3837] [5, 485] [5, 270] [4, 359] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.183744430541992 with beta sum per layer: [0.0, 0.0, 39.535728454589844, 14.97462272644043, 8.67680549621582, 22.86129379272461]
alpha/beta optimization time: 0.7853307723999023
This batch time : update_bounds func: 0.8759	 prepare: 0.0240	 bound: 0.7858	 transfer: 0.0493	 finalize: 0.0164
Accumulated time: update_bounds func: 58.3726	 prepare: 1.4807	 bound: 52.4394	 transfer: 0.0493	 finalize: 1.3148
batch bounding time:  0.8763008117675781
Current worst splitting domains [lb, ub] (depth):
[-0.07304,   inf] (89), [-0.07304,   inf] (91), [-0.07304,   inf] (77), [-0.07304,   inf] (95), [-0.07304,   inf] (79), [-0.07303,   inf] (91), [-0.07303,   inf] (91), [-0.07303,   inf] (71), [-0.07303,   inf] (95), [-0.07303,   inf] (81), [-0.07302,   inf] (77), [-0.07302,   inf] (57), [-0.07302,   inf] (95), [-0.07302,   inf] (91), [-0.07301,   inf] (79), [-0.07301,   inf] (95), [-0.07301,   inf] (101), [-0.07301,   inf] (89), [-0.07301,   inf] (43), [-0.07301,   inf] (85), 
length of domains: 2754
Total time: 1.0395	 pickout: 0.0529	 decision: 0.0930	 get_bound: 0.8765	 add_domain: 0.0171
Current lb:-0.07304167002439499
8058 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 74.54767966270447

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5298] [5, 406] [3, 1230] [3, 3836] [3, 1230] [3, 3036] [2, 5298] [3, 3837] [2, 5302] [3, 3305] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.878577709197998 with beta sum per layer: [0.0, 0.0, 68.13878631591797, 22.96356964111328, 5.733084678649902, 14.415651321411133]
alpha/beta optimization time: 0.7914259433746338
This batch time : update_bounds func: 0.8820	 prepare: 0.0246	 bound: 0.7919	 transfer: 0.0488	 finalize: 0.0154
Accumulated time: update_bounds func: 59.2546	 prepare: 1.5053	 bound: 53.2313	 transfer: 0.0488	 finalize: 1.3302
batch bounding time:  0.8824417591094971
Current worst splitting domains [lb, ub] (depth):
[-0.07293,   inf] (89), [-0.07293,   inf] (77), [-0.07293,   inf] (87), [-0.07293,   inf] (21), [-0.07293,   inf] (83), [-0.07293,   inf] (53), [-0.07293,   inf] (85), [-0.07293,   inf] (85), [-0.07292,   inf] (79), [-0.07292,   inf] (93), [-0.07292,   inf] (97), [-0.07292,   inf] (91), [-0.07292,   inf] (75), [-0.07291,   inf] (47), [-0.07291,   inf] (77), [-0.07291,   inf] (87), [-0.07291,   inf] (87), [-0.07291,   inf] (85), [-0.07291,   inf] (99), [-0.07291,   inf] (55), 
length of domains: 2810
Total time: 1.0495	 pickout: 0.0531	 decision: 0.0943	 get_bound: 0.8827	 add_domain: 0.0195
Current lb:-0.07293368130922318
8186 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 75.59987330436707

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 445] [2, 9157] [5, 266] [4, 42] [2, 6101] [5, 51] [2, 5612] [5, 266] [2, 7879] [2, 5302] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.4842023849487305 with beta sum per layer: [0.0, 0.0, 47.068138122558594, 17.166522979736328, 5.610718727111816, 16.432697296142578]
alpha/beta optimization time: 0.8288059234619141
This batch time : update_bounds func: 0.9174	 prepare: 0.0246	 bound: 0.8293	 transfer: 0.0468	 finalize: 0.0162
Accumulated time: update_bounds func: 60.1720	 prepare: 1.5299	 bound: 54.0606	 transfer: 0.0468	 finalize: 1.3464
batch bounding time:  0.9178421497344971
Current worst splitting domains [lb, ub] (depth):
[-0.07282,   inf] (83), [-0.07282,   inf] (83), [-0.07282,   inf] (29), [-0.07281,   inf] (91), [-0.07281,   inf] (71), [-0.07281,   inf] (99), [-0.07281,   inf] (95), [-0.07281,   inf] (85), [-0.07281,   inf] (77), [-0.07280,   inf] (81), [-0.07280,   inf] (101), [-0.07280,   inf] (69), [-0.07280,   inf] (85), [-0.07280,   inf] (89), [-0.07280,   inf] (45), [-0.07279,   inf] (27), [-0.07279,   inf] (63), [-0.07279,   inf] (79), [-0.07279,   inf] (45), [-0.07279,   inf] (91), 
length of domains: 2864
Total time: 1.0959	 pickout: 0.0554	 decision: 0.1031	 get_bound: 0.9181	 add_domain: 0.0193
Current lb:-0.07282444089651108
8314 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 76.69926428794861

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 466] [2, 6101] [5, 218] [5, 406] [5, 221] [2, 4279] [2, 5298] [2, 5612] [2, 9157] [2, 6101] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.248316764831543 with beta sum per layer: [0.0, 0.0, 65.47196960449219, 14.140939712524414, 9.613040924072266, 21.279335021972656]
alpha/beta optimization time: 0.8082015514373779
This batch time : update_bounds func: 0.8982	 prepare: 0.0245	 bound: 0.8087	 transfer: 0.0482	 finalize: 0.0155
Accumulated time: update_bounds func: 61.0702	 prepare: 1.5544	 bound: 54.8693	 transfer: 0.0482	 finalize: 1.3619
batch bounding time:  0.8986673355102539
Current worst splitting domains [lb, ub] (depth):
[-0.07274,   inf] (87), [-0.07274,   inf] (93), [-0.07273,   inf] (85), [-0.07273,   inf] (75), [-0.07273,   inf] (95), [-0.07273,   inf] (89), [-0.07273,   inf] (85), [-0.07273,   inf] (85), [-0.07273,   inf] (91), [-0.07273,   inf] (87), [-0.07272,   inf] (85), [-0.07272,   inf] (101), [-0.07272,   inf] (27), [-0.07272,   inf] (87), [-0.07272,   inf] (57), [-0.07272,   inf] (71), [-0.07272,   inf] (83), [-0.07272,   inf] (87), [-0.07271,   inf] (79), [-0.07271,   inf] (87), 
length of domains: 2915
Total time: 1.0636	 pickout: 0.0514	 decision: 0.0952	 get_bound: 0.8989	 add_domain: 0.0181
Current lb:-0.0727352723479271
8442 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 77.76563119888306

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5612] [2, 5302] [5, 266] [4, 29] [3, 3836] [2, 5298] [5, 266] [4, 466] [2, 5302] [5, 266] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.271395683288574 with beta sum per layer: [0.0, 0.0, 65.19636535644531, 21.38787841796875, 5.402204513549805, 20.16289520263672]
alpha/beta optimization time: 0.7867200374603271
This batch time : update_bounds func: 0.8768	 prepare: 0.0246	 bound: 0.7872	 transfer: 0.0482	 finalize: 0.0165
Accumulated time: update_bounds func: 61.9471	 prepare: 1.5790	 bound: 55.6565	 transfer: 0.0482	 finalize: 1.3784
batch bounding time:  0.8772168159484863
Current worst splitting domains [lb, ub] (depth):
[-0.07265,   inf] (85), [-0.07264,   inf] (15), [-0.07264,   inf] (89), [-0.07264,   inf] (45), [-0.07264,   inf] (27), [-0.07264,   inf] (91), [-0.07263,   inf] (23), [-0.07263,   inf] (101), [-0.07263,   inf] (35), [-0.07263,   inf] (85), [-0.07263,   inf] (89), [-0.07262,   inf] (89), [-0.07262,   inf] (87), [-0.07262,   inf] (97), [-0.07262,   inf] (93), [-0.07262,   inf] (99), [-0.07262,   inf] (97), [-0.07262,   inf] (89), [-0.07261,   inf] (99), [-0.07261,   inf] (91), 
length of domains: 2966
Total time: 1.0423	 pickout: 0.0514	 decision: 0.0948	 get_bound: 0.8774	 add_domain: 0.0186
Current lb:-0.07264523953199387
8570 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 78.81065344810486

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 466] [5, 309] [4, 445] [4, 135] [4, 42] [5, 406] [4, 262] [3, 3036] [5, 453] [4, 445] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.824631690979004 with beta sum per layer: [0.0, 0.0, 46.38887405395508, 20.001102447509766, 10.465221405029297, 23.26615333557129]
alpha/beta optimization time: 0.812551736831665
This batch time : update_bounds func: 0.9026	 prepare: 0.0246	 bound: 0.8130	 transfer: 0.0482	 finalize: 0.0155
Accumulated time: update_bounds func: 62.8496	 prepare: 1.6036	 bound: 56.4695	 transfer: 0.0482	 finalize: 1.3939
batch bounding time:  0.9029912948608398
Current worst splitting domains [lb, ub] (depth):
[-0.07255,   inf] (87), [-0.07254,   inf] (91), [-0.07254,   inf] (95), [-0.07254,   inf] (91), [-0.07254,   inf] (89), [-0.07254,   inf] (83), [-0.07254,   inf] (99), [-0.07253,   inf] (89), [-0.07253,   inf] (95), [-0.07253,   inf] (33), [-0.07252,   inf] (103), [-0.07252,   inf] (91), [-0.07252,   inf] (89), [-0.07251,   inf] (95), [-0.07251,   inf] (97), [-0.07251,   inf] (79), [-0.07251,   inf] (91), [-0.07251,   inf] (47), [-0.07251,   inf] (93), [-0.07251,   inf] (101), 
length of domains: 3008
Total time: 1.0646	 pickout: 0.0505	 decision: 0.0938	 get_bound: 0.9032	 add_domain: 0.0170
Current lb:-0.07254505157470703
8698 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 79.8785092830658

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5302] [5, 266] [2, 5298] [2, 5298] [3, 653] [4, 445] [3, 653] [4, 445] [5, 406] [4, 402] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.945161819458008 with beta sum per layer: [0.0, 0.0, 57.57108688354492, 15.109407424926758, 11.389223098754883, 21.9550724029541]
alpha/beta optimization time: 0.786210298538208
This batch time : update_bounds func: 0.8764	 prepare: 0.0246	 bound: 0.7867	 transfer: 0.0483	 finalize: 0.0163
Accumulated time: update_bounds func: 63.7260	 prepare: 1.6282	 bound: 57.2562	 transfer: 0.0483	 finalize: 1.4102
batch bounding time:  0.8767731189727783
Current worst splitting domains [lb, ub] (depth):
[-0.07243,   inf] (21), [-0.07243,   inf] (75), [-0.07243,   inf] (87), [-0.07243,   inf] (27), [-0.07243,   inf] (95), [-0.07243,   inf] (91), [-0.07242,   inf] (83), [-0.07242,   inf] (43), [-0.07242,   inf] (93), [-0.07242,   inf] (91), [-0.07242,   inf] (59), [-0.07242,   inf] (29), [-0.07241,   inf] (97), [-0.07241,   inf] (89), [-0.07241,   inf] (53), [-0.07241,   inf] (91), [-0.07241,   inf] (81), [-0.07240,   inf] (49), [-0.07240,   inf] (31), [-0.07240,   inf] (91), 
length of domains: 3057
Total time: 1.0421	 pickout: 0.0508	 decision: 0.0962	 get_bound: 0.8770	 add_domain: 0.0181
Current lb:-0.0724339485168457
8826 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 80.92354393005371

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 240] [5, 313] [2, 4279] [5, 218] [3, 3836] [5, 406] [4, 445] [4, 182] [2, 5302] [3, 3036] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.111182689666748 with beta sum per layer: [0.0, 0.0, 56.656951904296875, 18.2785587310791, 7.6471147537231445, 24.243234634399414]
alpha/beta optimization time: 0.7903954982757568
This batch time : update_bounds func: 1.0025	 prepare: 0.0247	 bound: 0.7909	 transfer: 0.0482	 finalize: 0.1383
Accumulated time: update_bounds func: 64.7285	 prepare: 1.6528	 bound: 58.0471	 transfer: 0.0482	 finalize: 1.5485
batch bounding time:  1.0029218196868896
Current worst splitting domains [lb, ub] (depth):
[-0.07236,   inf] (91), [-0.07236,   inf] (81), [-0.07236,   inf] (87), [-0.07236,   inf] (87), [-0.07236,   inf] (81), [-0.07236,   inf] (51), [-0.07236,   inf] (91), [-0.07236,   inf] (73), [-0.07236,   inf] (91), [-0.07235,   inf] (87), [-0.07235,   inf] (79), [-0.07235,   inf] (79), [-0.07235,   inf] (81), [-0.07235,   inf] (73), [-0.07235,   inf] (85), [-0.07235,   inf] (97), [-0.07235,   inf] (85), [-0.07235,   inf] (89), [-0.07235,   inf] (97), [-0.07235,   inf] (93), 
length of domains: 3101
Total time: 1.1722	 pickout: 0.0520	 decision: 0.0942	 get_bound: 1.0032	 add_domain: 0.0229
Current lb:-0.07236337661743164
8954 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 82.10018539428711

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 6101] [5, 266] [5, 266] [2, 4279] [2, 5612] [5, 51] [2, 5302] [5, 313] [3, 3036] [2, 10955] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.682716369628906 with beta sum per layer: [0.0, 0.0, 59.21552658081055, 20.805315017700195, 4.057295799255371, 20.09264373779297]
alpha/beta optimization time: 0.8145501613616943
This batch time : update_bounds func: 0.9041	 prepare: 0.0246	 bound: 0.8150	 transfer: 0.0482	 finalize: 0.0158
Accumulated time: update_bounds func: 65.6326	 prepare: 1.6774	 bound: 58.8621	 transfer: 0.0482	 finalize: 1.5643
batch bounding time:  0.9045219421386719
Current worst splitting domains [lb, ub] (depth):
[-0.07230,   inf] (77), [-0.07230,   inf] (73), [-0.07230,   inf] (77), [-0.07230,   inf] (87), [-0.07229,   inf] (91), [-0.07229,   inf] (23), [-0.07229,   inf] (91), [-0.07229,   inf] (69), [-0.07229,   inf] (93), [-0.07228,   inf] (99), [-0.07228,   inf] (87), [-0.07228,   inf] (101), [-0.07228,   inf] (81), [-0.07228,   inf] (89), [-0.07228,   inf] (95), [-0.07228,   inf] (87), [-0.07228,   inf] (73), [-0.07228,   inf] (101), [-0.07228,   inf] (89), [-0.07228,   inf] (95), 
length of domains: 3150
Total time: 1.1303	 pickout: 0.1110	 decision: 0.0957	 get_bound: 0.9047	 add_domain: 0.0189
Current lb:-0.07229757308959961
9082 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 83.23344898223877

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 313] [5, 485] [5, 485] [3, 653] [2, 5302] [4, 42] [5, 406] [2, 7879] [2, 5298] [2, 5316] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.879204750061035 with beta sum per layer: [0.0, 0.0, 60.27042770385742, 26.31382942199707, 7.184389114379883, 15.02148723602295]
alpha/beta optimization time: 0.8137776851654053
This batch time : update_bounds func: 0.9040	 prepare: 0.0248	 bound: 0.8143	 transfer: 0.0482	 finalize: 0.0163
Accumulated time: update_bounds func: 66.5366	 prepare: 1.7022	 bound: 59.6764	 transfer: 0.0482	 finalize: 1.5806
batch bounding time:  0.9044880867004395
Current worst splitting domains [lb, ub] (depth):
[-0.07222,   inf] (89), [-0.07222,   inf] (95), [-0.07221,   inf] (97), [-0.07221,   inf] (93), [-0.07221,   inf] (83), [-0.07221,   inf] (75), [-0.07221,   inf] (91), [-0.07221,   inf] (85), [-0.07221,   inf] (43), [-0.07220,   inf] (89), [-0.07220,   inf] (91), [-0.07220,   inf] (81), [-0.07220,   inf] (93), [-0.07219,   inf] (55), [-0.07219,   inf] (75), [-0.07219,   inf] (55), [-0.07219,   inf] (37), [-0.07219,   inf] (21), [-0.07219,   inf] (49), [-0.07219,   inf] (89), 
length of domains: 3199
Total time: 1.1143	 pickout: 0.0968	 decision: 0.0943	 get_bound: 0.9047	 add_domain: 0.0185
Current lb:-0.07221651077270508
9210 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 84.35059523582458

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 445] [5, 406] [2, 4279] [2, 5298] [5, 266] [2, 9157] [5, 266] [5, 266] [4, 309] [2, 5298] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.761513710021973 with beta sum per layer: [0.0, 0.0, 60.356346130371094, 18.697391510009766, 6.5108256340026855, 22.77642250061035]
alpha/beta optimization time: 0.8382425308227539
This batch time : update_bounds func: 0.9309	 prepare: 0.0246	 bound: 0.8387	 transfer: 0.0516	 finalize: 0.0156
Accumulated time: update_bounds func: 67.4675	 prepare: 1.7268	 bound: 60.5151	 transfer: 0.0516	 finalize: 1.5962
batch bounding time:  0.9313297271728516
Current worst splitting domains [lb, ub] (depth):
[-0.07213,   inf] (91), [-0.07213,   inf] (81), [-0.07212,   inf] (81), [-0.07212,   inf] (91), [-0.07212,   inf] (87), [-0.07212,   inf] (55), [-0.07212,   inf] (91), [-0.07212,   inf] (85), [-0.07212,   inf] (75), [-0.07212,   inf] (81), [-0.07211,   inf] (91), [-0.07211,   inf] (97), [-0.07211,   inf] (93), [-0.07211,   inf] (93), [-0.07211,   inf] (79), [-0.07211,   inf] (95), [-0.07211,   inf] (41), [-0.07211,   inf] (89), [-0.07211,   inf] (81), [-0.07211,   inf] (59), 
length of domains: 3248
Total time: 1.2158	 pickout: 0.1698	 decision: 0.0953	 get_bound: 0.9316	 add_domain: 0.0191
Current lb:-0.07212667167186737
9338 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 85.56962776184082

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 266] [2, 7879] [3, 1900] [2, 5302] [2, 5612] [5, 294] [3, 3036] [4, 445] [5, 485] [2, 7879] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.165707588195801 with beta sum per layer: [0.0, 0.0, 66.93619537353516, 21.271209716796875, 5.258539199829102, 14.487458229064941]
alpha/beta optimization time: 0.8013908863067627
This batch time : update_bounds func: 0.8954	 prepare: 0.0249	 bound: 0.8019	 transfer: 0.0516	 finalize: 0.0164
Accumulated time: update_bounds func: 68.3629	 prepare: 1.7517	 bound: 61.3170	 transfer: 0.0516	 finalize: 1.6126
batch bounding time:  0.8958024978637695
Current worst splitting domains [lb, ub] (depth):
[-0.07206,   inf] (93), [-0.07206,   inf] (95), [-0.07206,   inf] (87), [-0.07206,   inf] (95), [-0.07205,   inf] (81), [-0.07205,   inf] (69), [-0.07205,   inf] (93), [-0.07205,   inf] (95), [-0.07205,   inf] (97), [-0.07205,   inf] (97), [-0.07205,   inf] (93), [-0.07205,   inf] (47), [-0.07204,   inf] (103), [-0.07204,   inf] (85), [-0.07204,   inf] (99), [-0.07204,   inf] (93), [-0.07204,   inf] (91), [-0.07204,   inf] (89), [-0.07204,   inf] (77), [-0.07204,   inf] (95), 
length of domains: 3299
Total time: 1.1008	 pickout: 0.0920	 decision: 0.0936	 get_bound: 0.8960	 add_domain: 0.0192
Current lb:-0.07205653190612793
9466 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 86.67365217208862

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 406] [2, 5298] [2, 5302] [2, 10955] [5, 266] [3, 3837] [3, 1900] [5, 406] [3, 3836] [2, 5302] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.328794002532959 with beta sum per layer: [0.0, 0.0, 65.30335998535156, 13.141407012939453, 5.214047908782959, 20.605043411254883]
alpha/beta optimization time: 0.7923882007598877
This batch time : update_bounds func: 0.8822	 prepare: 0.0245	 bound: 0.7929	 transfer: 0.0488	 finalize: 0.0156
Accumulated time: update_bounds func: 69.2451	 prepare: 1.7761	 bound: 62.1099	 transfer: 0.0488	 finalize: 1.6282
batch bounding time:  0.8826603889465332
Current worst splitting domains [lb, ub] (depth):
[-0.07198,   inf] (89), [-0.07198,   inf] (35), [-0.07198,   inf] (77), [-0.07198,   inf] (75), [-0.07198,   inf] (85), [-0.07198,   inf] (97), [-0.07198,   inf] (105), [-0.07198,   inf] (73), [-0.07198,   inf] (41), [-0.07198,   inf] (73), [-0.07198,   inf] (73), [-0.07198,   inf] (87), [-0.07198,   inf] (81), [-0.07198,   inf] (75), [-0.07198,   inf] (87), [-0.07198,   inf] (65), [-0.07198,   inf] (91), [-0.07198,   inf] (47), [-0.07198,   inf] (91), [-0.07198,   inf] (81), 
length of domains: 3347
Total time: 1.0546	 pickout: 0.0575	 decision: 0.0953	 get_bound: 0.8829	 add_domain: 0.0189
Current lb:-0.0719849094748497
9594 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 87.73124098777771

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 445] [4, 135] [2, 7879] [5, 313] [2, 5298] [5, 266] [2, 5316] [3, 1230] [4, 274] [3, 1230] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.962275505065918 with beta sum per layer: [0.0, 0.0, 56.086238861083984, 16.121000289916992, 10.091653823852539, 19.860763549804688]
alpha/beta optimization time: 0.796738862991333
This batch time : update_bounds func: 0.8873	 prepare: 0.0246	 bound: 0.7972	 transfer: 0.0484	 finalize: 0.0166
Accumulated time: update_bounds func: 70.1324	 prepare: 1.8007	 bound: 62.9071	 transfer: 0.0484	 finalize: 1.6448
batch bounding time:  0.8876850605010986
Current worst splitting domains [lb, ub] (depth):
[-0.07192,   inf] (91), [-0.07192,   inf] (89), [-0.07192,   inf] (95), [-0.07191,   inf] (47), [-0.07191,   inf] (97), [-0.07191,   inf] (33), [-0.07191,   inf] (105), [-0.07191,   inf] (75), [-0.07191,   inf] (47), [-0.07191,   inf] (83), [-0.07191,   inf] (77), [-0.07190,   inf] (91), [-0.07190,   inf] (95), [-0.07190,   inf] (97), [-0.07190,   inf] (77), [-0.07190,   inf] (79), [-0.07190,   inf] (77), [-0.07189,   inf] (89), [-0.07189,   inf] (103), [-0.07189,   inf] (33), 
length of domains: 3394
Total time: 1.0513	 pickout: 0.0509	 decision: 0.0944	 get_bound: 0.8879	 add_domain: 0.0181
Current lb:-0.07191681861877441
9722 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 88.78544449806213

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 6101] [4, 466] [5, 406] [5, 51] [2, 5302] [5, 496] [2, 5316] [5, 485] [5, 6] [2, 5612] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.278181552886963 with beta sum per layer: [0.0, 0.0, 60.335113525390625, 13.363344192504883, 10.782939910888672, 17.611291885375977]
alpha/beta optimization time: 0.7856152057647705
This batch time : update_bounds func: 0.8783	 prepare: 0.0245	 bound: 0.7861	 transfer: 0.0516	 finalize: 0.0158
Accumulated time: update_bounds func: 71.0107	 prepare: 1.8252	 bound: 63.6933	 transfer: 0.0516	 finalize: 1.6606
batch bounding time:  0.8787462711334229
Current worst splitting domains [lb, ub] (depth):
[-0.07184,   inf] (37), [-0.07184,   inf] (93), [-0.07184,   inf] (93), [-0.07184,   inf] (85), [-0.07183,   inf] (93), [-0.07183,   inf] (93), [-0.07183,   inf] (73), [-0.07183,   inf] (93), [-0.07183,   inf] (101), [-0.07183,   inf] (35), [-0.07183,   inf] (77), [-0.07183,   inf] (95), [-0.07183,   inf] (35), [-0.07183,   inf] (95), [-0.07183,   inf] (53), [-0.07182,   inf] (93), [-0.07182,   inf] (89), [-0.07182,   inf] (93), [-0.07182,   inf] (89), [-0.07182,   inf] (101), 
length of domains: 3446
Total time: 1.0436	 pickout: 0.0500	 decision: 0.0950	 get_bound: 0.8790	 add_domain: 0.0197
Current lb:-0.07183842360973358
9850 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 89.83194875717163

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 466] [2, 4279] [2, 5302] [2, 10955] [3, 3036] [5, 266] [5, 485] [2, 5302] [3, 653] [5, 453] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.073000907897949 with beta sum per layer: [0.0, 0.0, 69.63513946533203, 18.51652717590332, 6.583855152130127, 20.539024353027344]
alpha/beta optimization time: 0.7904512882232666
This batch time : update_bounds func: 0.8809	 prepare: 0.0248	 bound: 0.7909	 transfer: 0.0481	 finalize: 0.0165
Accumulated time: update_bounds func: 71.8916	 prepare: 1.8500	 bound: 64.4842	 transfer: 0.0481	 finalize: 1.6771
batch bounding time:  0.8812723159790039
Current worst splitting domains [lb, ub] (depth):
[-0.07178,   inf] (95), [-0.07178,   inf] (87), [-0.07178,   inf] (85), [-0.07177,   inf] (91), [-0.07177,   inf] (95), [-0.07177,   inf] (93), [-0.07177,   inf] (75), [-0.07177,   inf] (93), [-0.07177,   inf] (75), [-0.07177,   inf] (91), [-0.07177,   inf] (93), [-0.07177,   inf] (93), [-0.07177,   inf] (105), [-0.07177,   inf] (103), [-0.07177,   inf] (59), [-0.07177,   inf] (93), [-0.07177,   inf] (97), [-0.07177,   inf] (95), [-0.07176,   inf] (85), [-0.07176,   inf] (73), 
length of domains: 3497
Total time: 1.0440	 pickout: 0.0498	 decision: 0.0938	 get_bound: 0.8815	 add_domain: 0.0190
Current lb:-0.0717768669128418
9978 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 90.8787727355957

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3036] [5, 266] [2, 6101] [3, 3036] [3, 3836] [2, 5302] [5, 313] [3, 3036] [5, 313] [5, 406] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.867292404174805 with beta sum per layer: [0.0, 0.0, 61.034149169921875, 24.392301559448242, 5.346339702606201, 16.469970703125]
alpha/beta optimization time: 0.7959024906158447
This batch time : update_bounds func: 1.0279	 prepare: 0.0256	 bound: 0.7966	 transfer: 0.0542	 finalize: 0.0156
Accumulated time: update_bounds func: 72.9194	 prepare: 1.8756	 bound: 65.2808	 transfer: 0.0542	 finalize: 1.6927
batch bounding time:  1.0282964706420898
Current worst splitting domains [lb, ub] (depth):
[-0.07171,   inf] (93), [-0.07171,   inf] (51), [-0.07171,   inf] (77), [-0.07171,   inf] (101), [-0.07171,   inf] (87), [-0.07170,   inf] (91), [-0.07170,   inf] (81), [-0.07170,   inf] (49), [-0.07170,   inf] (81), [-0.07170,   inf] (93), [-0.07170,   inf] (25), [-0.07170,   inf] (105), [-0.07170,   inf] (97), [-0.07170,   inf] (91), [-0.07170,   inf] (93), [-0.07170,   inf] (81), [-0.07170,   inf] (103), [-0.07170,   inf] (87), [-0.07169,   inf] (85), [-0.07169,   inf] (71), 
length of domains: 3547
Total time: 1.2325	 pickout: 0.0894	 decision: 0.0954	 get_bound: 1.0285	 add_domain: 0.0192
Current lb:-0.07171285152435303
10106 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 92.11430549621582

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5298] [5, 491] [3, 1230] [2, 10955] [5, 266] [2, 5298] [2, 6101] [5, 294] [3, 3305] [3, 3036] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.417291641235352 with beta sum per layer: [0.0, 0.0, 62.66826629638672, 23.211484909057617, 4.94191837310791, 16.015634536743164]
alpha/beta optimization time: 0.7889535427093506
This batch time : update_bounds func: 0.8791	 prepare: 0.0247	 bound: 0.7895	 transfer: 0.0480	 finalize: 0.0165
Accumulated time: update_bounds func: 73.7985	 prepare: 1.9002	 bound: 66.0703	 transfer: 0.0480	 finalize: 1.7092
batch bounding time:  0.8795580863952637
Current worst splitting domains [lb, ub] (depth):
[-0.07164,   inf] (85), [-0.07163,   inf] (71), [-0.07163,   inf] (63), [-0.07163,   inf] (93), [-0.07163,   inf] (97), [-0.07163,   inf] (97), [-0.07163,   inf] (79), [-0.07163,   inf] (85), [-0.07162,   inf] (83), [-0.07162,   inf] (91), [-0.07162,   inf] (83), [-0.07162,   inf] (91), [-0.07162,   inf] (99), [-0.07162,   inf] (57), [-0.07162,   inf] (29), [-0.07161,   inf] (81), [-0.07161,   inf] (85), [-0.07161,   inf] (81), [-0.07161,   inf] (39), [-0.07161,   inf] (91), 
length of domains: 3601
Total time: 1.0459	 pickout: 0.0501	 decision: 0.0966	 get_bound: 0.8798	 add_domain: 0.0194
Current lb:-0.07163643091917038
10234 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 93.16309928894043

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 266] [3, 1900] [3, 3305] [5, 406] [5, 266] [3, 3836] [3, 1230] [3, 3836] [5, 266] [5, 266] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.193432807922363 with beta sum per layer: [0.0, 0.0, 54.96757507324219, 19.07709503173828, 7.217552661895752, 20.50802993774414]
alpha/beta optimization time: 0.7892124652862549
This batch time : update_bounds func: 0.8795	 prepare: 0.0245	 bound: 0.7897	 transfer: 0.0483	 finalize: 0.0157
Accumulated time: update_bounds func: 74.6781	 prepare: 1.9247	 bound: 66.8600	 transfer: 0.0483	 finalize: 1.7248
batch bounding time:  0.8799536228179932
Current worst splitting domains [lb, ub] (depth):
[-0.07156,   inf] (93), [-0.07156,   inf] (93), [-0.07156,   inf] (89), [-0.07156,   inf] (35), [-0.07156,   inf] (79), [-0.07156,   inf] (95), [-0.07155,   inf] (21), [-0.07155,   inf] (105), [-0.07155,   inf] (93), [-0.07155,   inf] (97), [-0.07155,   inf] (25), [-0.07155,   inf] (93), [-0.07155,   inf] (85), [-0.07155,   inf] (39), [-0.07155,   inf] (79), [-0.07155,   inf] (83), [-0.07155,   inf] (27), [-0.07155,   inf] (91), [-0.07155,   inf] (75), [-0.07155,   inf] (95), 
length of domains: 3655
Total time: 1.0530	 pickout: 0.0597	 decision: 0.0938	 get_bound: 0.8802	 add_domain: 0.0192
Current lb:-0.07156097888946533
10362 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 94.21917271614075

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 4279] [2, 10955] [2, 5298] [4, 274] [3, 653] [3, 3836] [4, 42] [2, 5316] [5, 406] [2, 4279] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.720501899719238 with beta sum per layer: [0.0, 0.0, 61.645111083984375, 19.897438049316406, 6.773333549499512, 17.596757888793945]
alpha/beta optimization time: 0.7869663238525391
This batch time : update_bounds func: 0.8803	 prepare: 0.0247	 bound: 0.7875	 transfer: 0.0513	 finalize: 0.0163
Accumulated time: update_bounds func: 75.5583	 prepare: 1.9494	 bound: 67.6475	 transfer: 0.0513	 finalize: 1.7411
batch bounding time:  0.8807148933410645
Current worst splitting domains [lb, ub] (depth):
[-0.07150,   inf] (91), [-0.07150,   inf] (97), [-0.07150,   inf] (93), [-0.07150,   inf] (99), [-0.07150,   inf] (93), [-0.07150,   inf] (93), [-0.07150,   inf] (83), [-0.07150,   inf] (97), [-0.07150,   inf] (89), [-0.07150,   inf] (91), [-0.07150,   inf] (69), [-0.07150,   inf] (95), [-0.07149,   inf] (93), [-0.07149,   inf] (89), [-0.07149,   inf] (93), [-0.07149,   inf] (89), [-0.07149,   inf] (95), [-0.07149,   inf] (83), [-0.07149,   inf] (77), [-0.07149,   inf] (87), 
length of domains: 3710
Total time: 1.0522	 pickout: 0.0560	 decision: 0.0955	 get_bound: 0.8809	 add_domain: 0.0197
Current lb:-0.07150495052337646
10490 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 95.27434992790222

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 406] [3, 3036] [5, 266] [3, 3836] [2, 5298] [3, 3036] [3, 3305] [3, 3836] [3, 653] [3, 1900] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.921638488769531 with beta sum per layer: [0.0, 0.0, 72.52093505859375, 26.478288650512695, 3.483199119567871, 15.680699348449707]
alpha/beta optimization time: 0.7915399074554443
This batch time : update_bounds func: 0.8859	 prepare: 0.0252	 bound: 0.7921	 transfer: 0.0516	 finalize: 0.0157
Accumulated time: update_bounds func: 76.4443	 prepare: 1.9746	 bound: 68.4396	 transfer: 0.0516	 finalize: 1.7568
batch bounding time:  0.8863658905029297
Current worst splitting domains [lb, ub] (depth):
[-0.07146,   inf] (83), [-0.07146,   inf] (91), [-0.07146,   inf] (81), [-0.07145,   inf] (85), [-0.07145,   inf] (83), [-0.07145,   inf] (73), [-0.07145,   inf] (75), [-0.07145,   inf] (85), [-0.07145,   inf] (83), [-0.07145,   inf] (95), [-0.07145,   inf] (101), [-0.07145,   inf] (91), [-0.07145,   inf] (95), [-0.07144,   inf] (89), [-0.07144,   inf] (87), [-0.07144,   inf] (89), [-0.07144,   inf] (95), [-0.07144,   inf] (89), [-0.07144,   inf] (103), [-0.07143,   inf] (89), 
length of domains: 3760
Total time: 1.0497	 pickout: 0.0495	 decision: 0.0939	 get_bound: 0.8866	 add_domain: 0.0197
Current lb:-0.0714573860168457
10618 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 96.32708358764648

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3305] [5, 266] [2, 6101] [5, 266] [3, 3305] [5, 485] [3, 3837] [5, 266] [4, 29] [2, 10955] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.409815788269043 with beta sum per layer: [0.0, 0.0, 63.73472595214844, 16.47701072692871, 6.886412143707275, 24.92353057861328]
alpha/beta optimization time: 0.7943050861358643
This batch time : update_bounds func: 0.8944	 prepare: 0.0246	 bound: 0.7948	 transfer: 0.0518	 finalize: 0.0228
Accumulated time: update_bounds func: 77.3387	 prepare: 1.9992	 bound: 69.2344	 transfer: 0.0518	 finalize: 1.7797
batch bounding time:  0.8948726654052734
Current worst splitting domains [lb, ub] (depth):
[-0.07139,   inf] (91), [-0.07139,   inf] (89), [-0.07139,   inf] (97), [-0.07139,   inf] (93), [-0.07139,   inf] (81), [-0.07139,   inf] (79), [-0.07139,   inf] (87), [-0.07139,   inf] (91), [-0.07139,   inf] (93), [-0.07139,   inf] (101), [-0.07139,   inf] (87), [-0.07139,   inf] (59), [-0.07139,   inf] (103), [-0.07139,   inf] (97), [-0.07138,   inf] (81), [-0.07138,   inf] (97), [-0.07138,   inf] (83), [-0.07138,   inf] (83), [-0.07138,   inf] (87), [-0.07138,   inf] (35), 
length of domains: 3807
Total time: 1.0629	 pickout: 0.0520	 decision: 0.0961	 get_bound: 0.8951	 add_domain: 0.0197
Current lb:-0.07139468193054199
10746 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 97.39300966262817

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5298] [4, 445] [2, 5298] [5, 406] [4, 466] [3, 1900] [2, 6101] [5, 406] [2, 5298] [2, 10725] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.886000633239746 with beta sum per layer: [0.0, 0.0, 71.68338012695312, 16.42530059814453, 4.960163593292236, 18.343669891357422]
alpha/beta optimization time: 0.795447587966919
This batch time : update_bounds func: 0.9031	 prepare: 0.0381	 bound: 0.7960	 transfer: 0.0515	 finalize: 0.0170
Accumulated time: update_bounds func: 78.2418	 prepare: 2.0373	 bound: 70.0304	 transfer: 0.0515	 finalize: 1.7967
batch bounding time:  0.9036505222320557
Current worst splitting domains [lb, ub] (depth):
[-0.07133,   inf] (83), [-0.07133,   inf] (93), [-0.07133,   inf] (93), [-0.07132,   inf] (91), [-0.07132,   inf] (75), [-0.07132,   inf] (89), [-0.07132,   inf] (93), [-0.07132,   inf] (75), [-0.07132,   inf] (101), [-0.07132,   inf] (85), [-0.07132,   inf] (73), [-0.07132,   inf] (53), [-0.07131,   inf] (81), [-0.07131,   inf] (71), [-0.07131,   inf] (79), [-0.07131,   inf] (55), [-0.07131,   inf] (89), [-0.07131,   inf] (89), [-0.07131,   inf] (91), [-0.07131,   inf] (93), 
length of domains: 3857
Total time: 1.0867	 pickout: 0.0587	 decision: 0.1051	 get_bound: 0.9039	 add_domain: 0.0190
Current lb:-0.0713280439376831
10874 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 98.48275303840637

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 466] [2, 5302] [3, 3036] [2, 5298] [5, 313] [2, 5298] [5, 406] [2, 9157] [2, 4279] [2, 5298] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.013031005859375 with beta sum per layer: [0.0, 0.0, 71.8349380493164, 23.253015518188477, 2.9527745246887207, 13.915901184082031]
alpha/beta optimization time: 0.8054091930389404
This batch time : update_bounds func: 0.8941	 prepare: 0.0252	 bound: 0.8059	 transfer: 0.0462	 finalize: 0.0164
Accumulated time: update_bounds func: 79.1359	 prepare: 2.0625	 bound: 70.8363	 transfer: 0.0462	 finalize: 1.8131
batch bounding time:  0.8945713043212891
Current worst splitting domains [lb, ub] (depth):
[-0.07126,   inf] (99), [-0.07126,   inf] (87), [-0.07126,   inf] (95), [-0.07126,   inf] (101), [-0.07126,   inf] (87), [-0.07126,   inf] (31), [-0.07126,   inf] (79), [-0.07126,   inf] (83), [-0.07126,   inf] (89), [-0.07126,   inf] (73), [-0.07126,   inf] (77), [-0.07125,   inf] (77), [-0.07125,   inf] (93), [-0.07125,   inf] (81), [-0.07125,   inf] (85), [-0.07125,   inf] (95), [-0.07125,   inf] (67), [-0.07125,   inf] (101), [-0.07125,   inf] (83), [-0.07125,   inf] (99), 
length of domains: 3909
Total time: 1.0647	 pickout: 0.0534	 decision: 0.0965	 get_bound: 0.8948	 add_domain: 0.0201
Current lb:-0.07126346230506897
11002 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 99.55101561546326

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 4279] [2, 4279] [3, 3836] [2, 4279] [5, 266] [5, 6] [3, 1230] [5, 406] [2, 5298] [5, 485] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.105495929718018 with beta sum per layer: [0.0, 0.0, 84.04939270019531, 29.854907989501953, 1.8901309967041016, 16.2728328704834]
alpha/beta optimization time: 0.797544002532959
This batch time : update_bounds func: 0.8895	 prepare: 0.0260	 bound: 0.7980	 transfer: 0.0486	 finalize: 0.0162
Accumulated time: update_bounds func: 80.0254	 prepare: 2.0884	 bound: 71.6344	 transfer: 0.0486	 finalize: 1.8293
batch bounding time:  0.8899030685424805
Current worst splitting domains [lb, ub] (depth):
[-0.07122,   inf] (85), [-0.07122,   inf] (95), [-0.07122,   inf] (65), [-0.07122,   inf] (89), [-0.07122,   inf] (91), [-0.07122,   inf] (93), [-0.07122,   inf] (93), [-0.07121,   inf] (75), [-0.07121,   inf] (95), [-0.07121,   inf] (79), [-0.07121,   inf] (79), [-0.07121,   inf] (79), [-0.07121,   inf] (105), [-0.07121,   inf] (55), [-0.07121,   inf] (93), [-0.07121,   inf] (83), [-0.07121,   inf] (83), [-0.07121,   inf] (97), [-0.07120,   inf] (83), [-0.07120,   inf] (93), 
length of domains: 3962
Total time: 1.0610	 pickout: 0.0555	 decision: 0.0955	 get_bound: 0.8901	 add_domain: 0.0199
Current lb:-0.0712209939956665
11130 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 100.61532592773438

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 266] [3, 3836] [4, 135] [2, 5302] [5, 266] [2, 5302] [2, 5302] [4, 274] [5, 406] [2, 7879] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.8235015869140625 with beta sum per layer: [0.0, 0.0, 65.45573425292969, 22.85547637939453, 9.728306770324707, 14.750917434692383]
alpha/beta optimization time: 0.7936568260192871
This batch time : update_bounds func: 0.8843	 prepare: 0.0248	 bound: 0.7941	 transfer: 0.0487	 finalize: 0.0163
Accumulated time: update_bounds func: 80.9097	 prepare: 2.1132	 bound: 72.4285	 transfer: 0.0487	 finalize: 1.8456
batch bounding time:  0.8846995830535889
Current worst splitting domains [lb, ub] (depth):
[-0.07117,   inf] (65), [-0.07117,   inf] (95), [-0.07117,   inf] (99), [-0.07117,   inf] (101), [-0.07117,   inf] (97), [-0.07117,   inf] (105), [-0.07117,   inf] (93), [-0.07117,   inf] (81), [-0.07117,   inf] (87), [-0.07117,   inf] (77), [-0.07117,   inf] (83), [-0.07117,   inf] (87), [-0.07117,   inf] (83), [-0.07116,   inf] (87), [-0.07116,   inf] (93), [-0.07116,   inf] (89), [-0.07116,   inf] (81), [-0.07116,   inf] (91), [-0.07116,   inf] (83), [-0.07116,   inf] (97), 
length of domains: 4011
Total time: 1.2117	 pickout: 0.0506	 decision: 0.0954	 get_bound: 0.8849	 add_domain: 0.1808
Current lb:-0.07117056846618652
11258 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 101.83007216453552

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 221] [3, 3036] [3, 653] [3, 3836] [3, 3036] [2, 10955] [5, 266] [2, 6101] [2, 4279] [2, 6101] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.3535661697387695 with beta sum per layer: [0.0, 0.0, 68.9327392578125, 19.939029693603516, 6.328733444213867, 16.34815216064453]
alpha/beta optimization time: 0.8252804279327393
This batch time : update_bounds func: 0.9203	 prepare: 0.0255	 bound: 0.8258	 transfer: 0.0518	 finalize: 0.0168
Accumulated time: update_bounds func: 81.8300	 prepare: 2.1387	 bound: 73.2543	 transfer: 0.0518	 finalize: 1.8624
batch bounding time:  0.9207615852355957
Current worst splitting domains [lb, ub] (depth):
[-0.07112,   inf] (95), [-0.07112,   inf] (83), [-0.07111,   inf] (39), [-0.07111,   inf] (97), [-0.07111,   inf] (83), [-0.07111,   inf] (99), [-0.07111,   inf] (93), [-0.07111,   inf] (31), [-0.07111,   inf] (33), [-0.07111,   inf] (83), [-0.07111,   inf] (75), [-0.07111,   inf] (97), [-0.07111,   inf] (81), [-0.07111,   inf] (93), [-0.07110,   inf] (95), [-0.07110,   inf] (79), [-0.07110,   inf] (89), [-0.07110,   inf] (85), [-0.07110,   inf] (89), [-0.07110,   inf] (93), 
length of domains: 4064
Total time: 1.1378	 pickout: 0.1004	 decision: 0.0966	 get_bound: 0.9210	 add_domain: 0.0198
Current lb:-0.07111647725105286
11386 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 102.97125196456909

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 266] [5, 266] [4, 376] [2, 5302] [3, 3305] [5, 406] [5, 266] [5, 218] [4, 274] [3, 3305] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.519820690155029 with beta sum per layer: [0.0, 0.0, 62.25937271118164, 20.83634376525879, 8.359359741210938, 19.144433975219727]
alpha/beta optimization time: 0.8145303726196289
This batch time : update_bounds func: 0.9075	 prepare: 0.0247	 bound: 0.8150	 transfer: 0.0514	 finalize: 0.0158
Accumulated time: update_bounds func: 82.7375	 prepare: 2.1634	 bound: 74.0693	 transfer: 0.0514	 finalize: 1.8782
batch bounding time:  0.9079041481018066
Current worst splitting domains [lb, ub] (depth):
[-0.07106,   inf] (99), [-0.07106,   inf] (81), [-0.07106,   inf] (77), [-0.07106,   inf] (93), [-0.07106,   inf] (103), [-0.07106,   inf] (99), [-0.07106,   inf] (79), [-0.07106,   inf] (99), [-0.07106,   inf] (85), [-0.07106,   inf] (87), [-0.07105,   inf] (97), [-0.07105,   inf] (77), [-0.07105,   inf] (93), [-0.07105,   inf] (91), [-0.07105,   inf] (87), [-0.07105,   inf] (95), [-0.07105,   inf] (89), [-0.07105,   inf] (91), [-0.07105,   inf] (93), [-0.07105,   inf] (79), 
length of domains: 4113
Total time: 1.0895	 pickout: 0.0664	 decision: 0.0959	 get_bound: 0.9081	 add_domain: 0.0191
Current lb:-0.07106423377990723
11514 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 104.063711643219

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 10955] [2, 7879] [3, 1900] [3, 3036] [2, 5316] [2, 4279] [3, 1230] [3, 653] [5, 266] [3, 3305] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.462784767150879 with beta sum per layer: [0.0, 0.0, 62.47818374633789, 30.151241302490234, 5.429098129272461, 15.272122383117676]
alpha/beta optimization time: 0.7904903888702393
This batch time : update_bounds func: 0.8817	 prepare: 0.0251	 bound: 0.7910	 transfer: 0.0484	 finalize: 0.0167
Accumulated time: update_bounds func: 83.6191	 prepare: 2.1885	 bound: 74.8603	 transfer: 0.0484	 finalize: 1.8949
batch bounding time:  0.8821256160736084
Current worst splitting domains [lb, ub] (depth):
[-0.07101,   inf] (87), [-0.07101,   inf] (107), [-0.07100,   inf] (79), [-0.07100,   inf] (45), [-0.07100,   inf] (97), [-0.07100,   inf] (85), [-0.07100,   inf] (37), [-0.07100,   inf] (95), [-0.07100,   inf] (103), [-0.07100,   inf] (19), [-0.07100,   inf] (31), [-0.07100,   inf] (75), [-0.07100,   inf] (91), [-0.07100,   inf] (77), [-0.07100,   inf] (81), [-0.07100,   inf] (19), [-0.07100,   inf] (83), [-0.07100,   inf] (85), [-0.07100,   inf] (101), [-0.07100,   inf] (37), 
length of domains: 4167
Total time: 1.0480	 pickout: 0.0510	 decision: 0.0948	 get_bound: 0.8824	 add_domain: 0.0198
Current lb:-0.07100570201873779
11642 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 105.11483669281006

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5302] [5, 31] [2, 6101] [5, 509] [3, 1900] [2, 6101] [5, 218] [2, 10955] [2, 5316] [5, 106] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.9333367347717285 with beta sum per layer: [0.0, 0.0, 71.78022766113281, 22.99183464050293, 5.680801868438721, 19.652042388916016]
alpha/beta optimization time: 0.7968277931213379
This batch time : update_bounds func: 0.8882	 prepare: 0.0251	 bound: 0.7973	 transfer: 0.0487	 finalize: 0.0166
Accumulated time: update_bounds func: 84.5073	 prepare: 2.2136	 bound: 75.6576	 transfer: 0.0487	 finalize: 1.9115
batch bounding time:  0.8886582851409912
Current worst splitting domains [lb, ub] (depth):
[-0.07095,   inf] (33), [-0.07095,   inf] (95), [-0.07095,   inf] (103), [-0.07095,   inf] (77), [-0.07095,   inf] (91), [-0.07095,   inf] (97), [-0.07095,   inf] (23), [-0.07095,   inf] (103), [-0.07095,   inf] (93), [-0.07095,   inf] (87), [-0.07094,   inf] (99), [-0.07094,   inf] (95), [-0.07094,   inf] (101), [-0.07094,   inf] (63), [-0.07094,   inf] (81), [-0.07094,   inf] (95), [-0.07094,   inf] (87), [-0.07094,   inf] (97), [-0.07094,   inf] (103), [-0.07094,   inf] (97), 
length of domains: 4220
Total time: 1.0579	 pickout: 0.0512	 decision: 0.0969	 get_bound: 0.8889	 add_domain: 0.0210
Current lb:-0.07095145434141159
11770 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 106.17600107192993

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 218] [2, 5298] [2, 5316] [2, 6101] [2, 5298] [2, 4279] [4, 42] [2, 5316] [3, 1900] [4, 445] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.939000129699707 with beta sum per layer: [0.0, 0.0, 79.65585327148438, 20.767637252807617, 6.199294090270996, 15.455770492553711]
alpha/beta optimization time: 0.8081023693084717
This batch time : update_bounds func: 0.8967	 prepare: 0.0258	 bound: 0.8086	 transfer: 0.0455	 finalize: 0.0162
Accumulated time: update_bounds func: 85.4040	 prepare: 2.2395	 bound: 76.4663	 transfer: 0.0455	 finalize: 1.9277
batch bounding time:  0.8971114158630371
Current worst splitting domains [lb, ub] (depth):
[-0.07091,   inf] (105), [-0.07091,   inf] (87), [-0.07091,   inf] (27), [-0.07091,   inf] (99), [-0.07091,   inf] (25), [-0.07091,   inf] (91), [-0.07091,   inf] (95), [-0.07091,   inf] (89), [-0.07091,   inf] (13), [-0.07091,   inf] (89), [-0.07091,   inf] (91), [-0.07091,   inf] (83), [-0.07090,   inf] (93), [-0.07090,   inf] (87), [-0.07090,   inf] (101), [-0.07090,   inf] (83), [-0.07090,   inf] (97), [-0.07090,   inf] (69), [-0.07090,   inf] (97), [-0.07090,   inf] (51), 
length of domains: 4270
Total time: 1.0587	 pickout: 0.0457	 decision: 0.0963	 get_bound: 0.8973	 add_domain: 0.0195
Current lb:-0.07091130316257477
11898 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 107.23763346672058

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5316] [2, 5298] [5, 270] [2, 4279] [5, 270] [2, 5298] [3, 3836] [2, 4279] [4, 415] [2, 5298] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.08751106262207 with beta sum per layer: [0.0, 0.0, 70.6760482788086, 21.6405029296875, 4.842226505279541, 17.404991149902344]
alpha/beta optimization time: 0.807631254196167
This batch time : update_bounds func: 0.8983	 prepare: 0.0254	 bound: 0.8081	 transfer: 0.0484	 finalize: 0.0158
Accumulated time: update_bounds func: 86.3023	 prepare: 2.2649	 bound: 77.2744	 transfer: 0.0484	 finalize: 1.9435
batch bounding time:  0.8987386226654053
Current worst splitting domains [lb, ub] (depth):
[-0.07088,   inf] (95), [-0.07088,   inf] (89), [-0.07087,   inf] (93), [-0.07087,   inf] (85), [-0.07087,   inf] (81), [-0.07087,   inf] (95), [-0.07087,   inf] (71), [-0.07087,   inf] (95), [-0.07087,   inf] (81), [-0.07087,   inf] (105), [-0.07087,   inf] (83), [-0.07087,   inf] (81), [-0.07087,   inf] (91), [-0.07087,   inf] (101), [-0.07087,   inf] (99), [-0.07087,   inf] (81), [-0.07086,   inf] (29), [-0.07086,   inf] (91), [-0.07086,   inf] (79), [-0.07086,   inf] (89), 
length of domains: 4322
Total time: 1.0703	 pickout: 0.0523	 decision: 0.0983	 get_bound: 0.8990	 add_domain: 0.0208
Current lb:-0.07087554782629013
12026 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 108.31109237670898

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 266] [2, 5302] [3, 3036] [5, 406] [3, 3305] [5, 406] [3, 3837] [2, 4279] [2, 6101] [2, 5316] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.002816200256348 with beta sum per layer: [0.0, 0.0, 75.30376434326172, 23.30470085144043, 5.816464424133301, 20.66410255432129]
alpha/beta optimization time: 0.8096132278442383
This batch time : update_bounds func: 0.8998	 prepare: 0.0249	 bound: 0.8101	 transfer: 0.0481	 finalize: 0.0163
Accumulated time: update_bounds func: 87.2021	 prepare: 2.2898	 bound: 78.0845	 transfer: 0.0481	 finalize: 1.9598
batch bounding time:  0.9002506732940674
Current worst splitting domains [lb, ub] (depth):
[-0.07082,   inf] (99), [-0.07082,   inf] (89), [-0.07082,   inf] (91), [-0.07082,   inf] (79), [-0.07082,   inf] (109), [-0.07082,   inf] (89), [-0.07082,   inf] (89), [-0.07082,   inf] (95), [-0.07081,   inf] (93), [-0.07081,   inf] (95), [-0.07081,   inf] (83), [-0.07081,   inf] (65), [-0.07081,   inf] (25), [-0.07081,   inf] (83), [-0.07081,   inf] (101), [-0.07081,   inf] (83), [-0.07081,   inf] (89), [-0.07081,   inf] (95), [-0.07081,   inf] (83), [-0.07080,   inf] (97), 
length of domains: 4369
Total time: 1.0657	 pickout: 0.0529	 decision: 0.0939	 get_bound: 0.9005	 add_domain: 0.0185
Current lb:-0.07082056999206543
12154 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 109.37975907325745

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 653] [2, 5298] [4, 445] [3, 1900] [5, 31] [2, 5302] [4, 445] [2, 4279] [3, 1900] [2, 5302] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.333085060119629 with beta sum per layer: [0.0, 0.0, 77.31025695800781, 31.52212142944336, 8.995137214660645, 13.726266860961914]
alpha/beta optimization time: 0.7986202239990234
This batch time : update_bounds func: 0.8884	 prepare: 0.0250	 bound: 0.7991	 transfer: 0.0482	 finalize: 0.0157
Accumulated time: update_bounds func: 88.0905	 prepare: 2.3147	 bound: 78.8836	 transfer: 0.0482	 finalize: 1.9755
batch bounding time:  0.88883376121521
Current worst splitting domains [lb, ub] (depth):
[-0.07077,   inf] (107), [-0.07077,   inf] (45), [-0.07077,   inf] (83), [-0.07077,   inf] (95), [-0.07077,   inf] (53), [-0.07077,   inf] (95), [-0.07077,   inf] (87), [-0.07077,   inf] (89), [-0.07077,   inf] (99), [-0.07077,   inf] (91), [-0.07077,   inf] (79), [-0.07077,   inf] (101), [-0.07077,   inf] (101), [-0.07077,   inf] (81), [-0.07076,   inf] (103), [-0.07076,   inf] (75), [-0.07076,   inf] (91), [-0.07076,   inf] (85), [-0.07076,   inf] (83), [-0.07076,   inf] (103), 
length of domains: 4420
Total time: 1.0856	 pickout: 0.0783	 decision: 0.0974	 get_bound: 0.8891	 add_domain: 0.0209
Current lb:-0.07077062129974365
12282 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 110.4685730934143

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 10955] [5, 245] [3, 1900] [2, 5298] [5, 294] [5, 266] [3, 3305] [5, 406] [3, 1900] [2, 6101] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.343740940093994 with beta sum per layer: [0.0, 0.0, 52.09104919433594, 22.687450408935547, 5.863338470458984, 18.300079345703125]
alpha/beta optimization time: 0.8351209163665771
This batch time : update_bounds func: 0.9293	 prepare: 0.0251	 bound: 0.8356	 transfer: 0.0515	 finalize: 0.0166
Accumulated time: update_bounds func: 89.0198	 prepare: 2.3399	 bound: 79.7193	 transfer: 0.0515	 finalize: 1.9921
batch bounding time:  0.9297330379486084
Current worst splitting domains [lb, ub] (depth):
[-0.07073,   inf] (75), [-0.07073,   inf] (83), [-0.07073,   inf] (77), [-0.07073,   inf] (103), [-0.07073,   inf] (95), [-0.07073,   inf] (89), [-0.07073,   inf] (97), [-0.07073,   inf] (71), [-0.07073,   inf] (91), [-0.07073,   inf] (101), [-0.07073,   inf] (105), [-0.07073,   inf] (93), [-0.07073,   inf] (69), [-0.07072,   inf] (99), [-0.07072,   inf] (99), [-0.07072,   inf] (77), [-0.07072,   inf] (93), [-0.07072,   inf] (97), [-0.07072,   inf] (89), [-0.07072,   inf] (87), 
length of domains: 4475
Total time: 1.1624	 pickout: 0.1186	 decision: 0.0943	 get_bound: 0.9300	 add_domain: 0.0196
Current lb:-0.07073080539703369
12410 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 111.63398003578186

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 1230] [2, 5612] [3, 1230] [2, 10955] [2, 5298] [4, 445] [3, 3036] [2, 9157] [2, 10955] [2, 4279] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.902408123016357 with beta sum per layer: [0.0, 0.0, 77.16471099853516, 26.661943435668945, 8.55392837524414, 12.87171745300293]
alpha/beta optimization time: 0.8106203079223633
This batch time : update_bounds func: 0.9114	 prepare: 0.0249	 bound: 0.8111	 transfer: 0.0526	 finalize: 0.0223
Accumulated time: update_bounds func: 89.9312	 prepare: 2.3648	 bound: 80.5304	 transfer: 0.0526	 finalize: 2.0144
batch bounding time:  0.9118304252624512
Current worst splitting domains [lb, ub] (depth):
[-0.07069,   inf] (73), [-0.07069,   inf] (87), [-0.07069,   inf] (97), [-0.07069,   inf] (107), [-0.07069,   inf] (95), [-0.07069,   inf] (93), [-0.07069,   inf] (93), [-0.07069,   inf] (91), [-0.07068,   inf] (91), [-0.07068,   inf] (105), [-0.07068,   inf] (97), [-0.07068,   inf] (99), [-0.07068,   inf] (39), [-0.07068,   inf] (95), [-0.07068,   inf] (105), [-0.07068,   inf] (97), [-0.07068,   inf] (103), [-0.07068,   inf] (103), [-0.07068,   inf] (101), [-0.07068,   inf] (91), 
length of domains: 4524
Total time: 1.3094	 pickout: 0.0936	 decision: 0.0951	 get_bound: 0.9121	 add_domain: 0.2087
Current lb:-0.070688895881176
12538 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 112.94660139083862

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 485] [3, 3305] [2, 5302] [5, 31] [2, 5298] [2, 5302] [3, 1900] [2, 5298] [5, 266] [4, 445] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.916872978210449 with beta sum per layer: [0.0, 0.0, 72.76761627197266, 21.941524505615234, 6.502264976501465, 13.634666442871094]
alpha/beta optimization time: 0.7971422672271729
This batch time : update_bounds func: 0.9261	 prepare: 0.0627	 bound: 0.7977	 transfer: 0.0483	 finalize: 0.0166
Accumulated time: update_bounds func: 90.8572	 prepare: 2.4274	 bound: 81.3281	 transfer: 0.0483	 finalize: 2.0310
batch bounding time:  0.9265177249908447
Current worst splitting domains [lb, ub] (depth):
[-0.07064,   inf] (101), [-0.07064,   inf] (73), [-0.07064,   inf] (93), [-0.07064,   inf] (31), [-0.07064,   inf] (103), [-0.07064,   inf] (95), [-0.07064,   inf] (81), [-0.07064,   inf] (99), [-0.07063,   inf] (79), [-0.07063,   inf] (67), [-0.07063,   inf] (93), [-0.07063,   inf] (101), [-0.07063,   inf] (101), [-0.07063,   inf] (95), [-0.07063,   inf] (91), [-0.07063,   inf] (91), [-0.07063,   inf] (91), [-0.07063,   inf] (91), [-0.07063,   inf] (97), [-0.07063,   inf] (93), 
length of domains: 4574
Total time: 1.1545	 pickout: 0.0993	 decision: 0.1088	 get_bound: 0.9267	 add_domain: 0.0198
Current lb:-0.07064461708068848
12666 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 114.10412311553955

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 4279] [2, 9157] [2, 5302] [5, 270] [2, 10725] [5, 406] [3, 3305] [2, 5316] [3, 1900] [2, 9157] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.626953125 with beta sum per layer: [0.0, 0.0, 83.3188247680664, 17.65972137451172, 5.3203043937683105, 14.140707015991211]
alpha/beta optimization time: 0.8078866004943848
This batch time : update_bounds func: 0.9013	 prepare: 0.0251	 bound: 0.8084	 transfer: 0.0515	 finalize: 0.0158
Accumulated time: update_bounds func: 91.7586	 prepare: 2.4526	 bound: 82.1365	 transfer: 0.0515	 finalize: 2.0468
batch bounding time:  0.9017724990844727
Current worst splitting domains [lb, ub] (depth):
[-0.07060,   inf] (81), [-0.07060,   inf] (99), [-0.07060,   inf] (95), [-0.07060,   inf] (91), [-0.07059,   inf] (89), [-0.07059,   inf] (101), [-0.07059,   inf] (99), [-0.07059,   inf] (79), [-0.07059,   inf] (77), [-0.07059,   inf] (99), [-0.07059,   inf] (91), [-0.07059,   inf] (79), [-0.07059,   inf] (99), [-0.07059,   inf] (101), [-0.07059,   inf] (95), [-0.07059,   inf] (93), [-0.07059,   inf] (41), [-0.07059,   inf] (93), [-0.07059,   inf] (93), [-0.07059,   inf] (95), 
length of domains: 4625
Total time: 1.1124	 pickout: 0.0931	 decision: 0.0962	 get_bound: 0.9020	 add_domain: 0.0212
Current lb:-0.07059693336486816
12794 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 115.21966981887817

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3305] [2, 4279] [2, 4279] [4, 445] [4, 445] [4, 444] [2, 10955] [3, 1900] [5, 313] [3, 653] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.746148109436035 with beta sum per layer: [0.0, 0.0, 89.67401885986328, 23.43144989013672, 6.775218963623047, 12.20751953125]
alpha/beta optimization time: 0.7968196868896484
This batch time : update_bounds func: 0.8851	 prepare: 0.0250	 bound: 0.7973	 transfer: 0.0457	 finalize: 0.0165
Accumulated time: update_bounds func: 92.6436	 prepare: 2.4776	 bound: 82.9338	 transfer: 0.0457	 finalize: 2.0633
batch bounding time:  0.8854842185974121
Current worst splitting domains [lb, ub] (depth):
[-0.07055,   inf] (101), [-0.07055,   inf] (105), [-0.07055,   inf] (73), [-0.07055,   inf] (85), [-0.07055,   inf] (97), [-0.07055,   inf] (85), [-0.07055,   inf] (81), [-0.07055,   inf] (97), [-0.07055,   inf] (91), [-0.07055,   inf] (87), [-0.07055,   inf] (95), [-0.07055,   inf] (81), [-0.07055,   inf] (95), [-0.07054,   inf] (85), [-0.07054,   inf] (91), [-0.07054,   inf] (67), [-0.07054,   inf] (77), [-0.07054,   inf] (87), [-0.07054,   inf] (55), [-0.07054,   inf] (57), 
length of domains: 4680
Total time: 1.0623	 pickout: 0.0618	 decision: 0.0943	 get_bound: 0.8857	 add_domain: 0.0205
Current lb:-0.07055413722991943
12922 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 116.28483366966248

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 444] [2, 5316] [5, 485] [2, 10955] [2, 4279] [3, 653] [2, 7879] [2, 8413] [2, 4279] [2, 5298] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.01348876953125 with beta sum per layer: [0.0, 0.0, 56.143348693847656, 29.222366333007812, 5.8298492431640625, 14.769006729125977]
alpha/beta optimization time: 0.7875208854675293
This batch time : update_bounds func: 0.8779	 prepare: 0.0252	 bound: 0.7880	 transfer: 0.0485	 finalize: 0.0158
Accumulated time: update_bounds func: 93.5216	 prepare: 2.5028	 bound: 83.7218	 transfer: 0.0485	 finalize: 2.0791
batch bounding time:  0.8783495426177979
Current worst splitting domains [lb, ub] (depth):
[-0.07051,   inf] (91), [-0.07051,   inf] (95), [-0.07051,   inf] (95), [-0.07050,   inf] (99), [-0.07050,   inf] (91), [-0.07050,   inf] (79), [-0.07050,   inf] (83), [-0.07050,   inf] (81), [-0.07050,   inf] (79), [-0.07050,   inf] (85), [-0.07050,   inf] (97), [-0.07049,   inf] (105), [-0.07049,   inf] (89), [-0.07049,   inf] (85), [-0.07049,   inf] (101), [-0.07049,   inf] (99), [-0.07049,   inf] (99), [-0.07049,   inf] (109), [-0.07049,   inf] (81), [-0.07049,   inf] (91), 
length of domains: 4730
Total time: 1.0426	 pickout: 0.0481	 decision: 0.0952	 get_bound: 0.8786	 add_domain: 0.0207
Current lb:-0.07050645351409912
13050 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 117.33041882514954

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5302] [2, 4279] [5, 266] [2, 4279] [5, 266] [3, 1900] [2, 7879] [3, 3305] [3, 1230] [4, 445] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.493072509765625 with beta sum per layer: [0.0, 0.0, 61.92323303222656, 31.907760620117188, 7.031916618347168, 11.362471580505371]
alpha/beta optimization time: 0.7984917163848877
This batch time : update_bounds func: 0.8942	 prepare: 0.0253	 bound: 0.7991	 transfer: 0.0525	 finalize: 0.0169
Accumulated time: update_bounds func: 94.4158	 prepare: 2.5280	 bound: 84.5209	 transfer: 0.0525	 finalize: 2.0961
batch bounding time:  0.8947751522064209
Current worst splitting domains [lb, ub] (depth):
[-0.07045,   inf] (81), [-0.07045,   inf] (101), [-0.07045,   inf] (91), [-0.07045,   inf] (95), [-0.07045,   inf] (77), [-0.07045,   inf] (93), [-0.07045,   inf] (91), [-0.07045,   inf] (89), [-0.07045,   inf] (99), [-0.07045,   inf] (85), [-0.07045,   inf] (87), [-0.07045,   inf] (105), [-0.07045,   inf] (101), [-0.07045,   inf] (85), [-0.07045,   inf] (95), [-0.07044,   inf] (83), [-0.07044,   inf] (93), [-0.07044,   inf] (105), [-0.07044,   inf] (89), [-0.07044,   inf] (25), 
length of domains: 4780
Total time: 1.0628	 pickout: 0.0511	 decision: 0.0962	 get_bound: 0.8950	 add_domain: 0.0204
Current lb:-0.07045245170593262
13178 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 118.39676403999329

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 653] [2, 10725] [2, 5302] [5, 406] [3, 1230] [5, 406] [2, 5298] [3, 3305] [2, 10955] [3, 653] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.563626766204834 with beta sum per layer: [0.0, 0.0, 66.74542236328125, 22.02447509765625, 5.97598934173584, 19.66683006286621]
alpha/beta optimization time: 0.7944416999816895
This batch time : update_bounds func: 0.8848	 prepare: 0.0249	 bound: 0.7949	 transfer: 0.0486	 finalize: 0.0159
Accumulated time: update_bounds func: 95.3006	 prepare: 2.5530	 bound: 85.3158	 transfer: 0.0486	 finalize: 2.1120
batch bounding time:  0.8853089809417725
Current worst splitting domains [lb, ub] (depth):
[-0.07041,   inf] (77), [-0.07041,   inf] (103), [-0.07041,   inf] (93), [-0.07041,   inf] (93), [-0.07041,   inf] (95), [-0.07041,   inf] (97), [-0.07041,   inf] (89), [-0.07041,   inf] (97), [-0.07041,   inf] (93), [-0.07041,   inf] (71), [-0.07041,   inf] (83), [-0.07041,   inf] (93), [-0.07041,   inf] (95), [-0.07041,   inf] (95), [-0.07040,   inf] (103), [-0.07040,   inf] (95), [-0.07040,   inf] (91), [-0.07040,   inf] (97), [-0.07040,   inf] (95), [-0.07040,   inf] (103), 
length of domains: 4830
Total time: 1.1783	 pickout: 0.1755	 decision: 0.0967	 get_bound: 0.8855	 add_domain: 0.0207
Current lb:-0.07041490077972412
13306 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 119.57814264297485

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 1230] [2, 10955] [2, 10955] [3, 1900] [2, 5302] [2, 10955] [4, 466] [5, 406] [2, 5302] [5, 221] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.122936248779297 with beta sum per layer: [0.0, 0.0, 80.58619689941406, 24.143924713134766, 6.419410228729248, 14.840093612670898]
alpha/beta optimization time: 0.8351955413818359
This batch time : update_bounds func: 0.9368	 prepare: 0.0253	 bound: 0.8358	 transfer: 0.0521	 finalize: 0.0231
Accumulated time: update_bounds func: 96.2374	 prepare: 2.5783	 bound: 86.1517	 transfer: 0.0521	 finalize: 2.1351
batch bounding time:  0.9372565746307373
Current worst splitting domains [lb, ub] (depth):
[-0.07037,   inf] (45), [-0.07037,   inf] (99), [-0.07037,   inf] (101), [-0.07037,   inf] (71), [-0.07037,   inf] (105), [-0.07037,   inf] (61), [-0.07037,   inf] (97), [-0.07037,   inf] (77), [-0.07037,   inf] (81), [-0.07037,   inf] (77), [-0.07037,   inf] (35), [-0.07037,   inf] (79), [-0.07037,   inf] (97), [-0.07036,   inf] (85), [-0.07036,   inf] (85), [-0.07036,   inf] (99), [-0.07036,   inf] (79), [-0.07036,   inf] (93), [-0.07036,   inf] (97), [-0.07036,   inf] (105), 
length of domains: 4882
Total time: 1.1099	 pickout: 0.0566	 decision: 0.0938	 get_bound: 0.9375	 add_domain: 0.0219
Current lb:-0.07037441432476044
13434 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 120.69104957580566

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 509] [2, 5316] [2, 4279] [5, 221] [4, 445] [5, 406] [3, 3836] [2, 6101] [3, 3305] [4, 466] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.005211353302002 with beta sum per layer: [0.0, 0.0, 83.20205688476562, 21.48581314086914, 5.660755157470703, 15.958660125732422]
alpha/beta optimization time: 0.8061656951904297
This batch time : update_bounds func: 0.8993	 prepare: 0.0248	 bound: 0.8067	 transfer: 0.0516	 finalize: 0.0157
Accumulated time: update_bounds func: 97.1367	 prepare: 2.6031	 bound: 86.9583	 transfer: 0.0516	 finalize: 2.1508
batch bounding time:  0.8996908664703369
Current worst splitting domains [lb, ub] (depth):
[-0.07033,   inf] (105), [-0.07033,   inf] (91), [-0.07033,   inf] (103), [-0.07033,   inf] (91), [-0.07033,   inf] (95), [-0.07033,   inf] (77), [-0.07033,   inf] (101), [-0.07033,   inf] (99), [-0.07033,   inf] (57), [-0.07032,   inf] (81), [-0.07032,   inf] (89), [-0.07032,   inf] (57), [-0.07032,   inf] (97), [-0.07032,   inf] (89), [-0.07032,   inf] (85), [-0.07032,   inf] (87), [-0.07032,   inf] (85), [-0.07032,   inf] (99), [-0.07032,   inf] (31), [-0.07032,   inf] (97), 
length of domains: 4935
Total time: 1.1087	 pickout: 0.0918	 decision: 0.0956	 get_bound: 0.8999	 add_domain: 0.0214
Current lb:-0.07033038139343262
13562 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 121.80278897285461

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5316] [4, 466] [2, 10725] [2, 5302] [5, 406] [4, 441] [3, 1900] [2, 8413] [3, 3305] [3, 1900] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.618069648742676 with beta sum per layer: [0.0, 0.0, 65.4156723022461, 12.287084579467773, 5.129798889160156, 14.315376281738281]
alpha/beta optimization time: 0.8104496002197266
This batch time : update_bounds func: 0.9013	 prepare: 0.0251	 bound: 0.8109	 transfer: 0.0484	 finalize: 0.0164
Accumulated time: update_bounds func: 98.0380	 prepare: 2.6282	 bound: 87.7692	 transfer: 0.0484	 finalize: 2.1672
batch bounding time:  0.9017384052276611
Current worst splitting domains [lb, ub] (depth):
[-0.07029,   inf] (99), [-0.07029,   inf] (81), [-0.07029,   inf] (101), [-0.07029,   inf] (87), [-0.07029,   inf] (85), [-0.07029,   inf] (95), [-0.07029,   inf] (95), [-0.07028,   inf] (77), [-0.07028,   inf] (97), [-0.07028,   inf] (77), [-0.07028,   inf] (85), [-0.07028,   inf] (95), [-0.07028,   inf] (51), [-0.07028,   inf] (99), [-0.07028,   inf] (97), [-0.07028,   inf] (95), [-0.07028,   inf] (99), [-0.07028,   inf] (47), [-0.07028,   inf] (81), [-0.07028,   inf] (93), 
length of domains: 4985
Total time: 1.1501	 pickout: 0.1339	 decision: 0.0942	 get_bound: 0.9020	 add_domain: 0.0200
Current lb:-0.0702885165810585
13690 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 122.95580410957336

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 8413] [3, 3305] [3, 3036] [5, 266] [5, 266] [2, 4279] [2, 5302] [5, 313] [5, 266] [3, 1230] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 8.098400115966797 with beta sum per layer: [0.0, 0.0, 85.01703643798828, 29.754348754882812, 2.9733774662017822, 10.604832649230957]
alpha/beta optimization time: 0.8060512542724609
This batch time : update_bounds func: 0.8926	 prepare: 0.0249	 bound: 0.8066	 transfer: 0.0451	 finalize: 0.0156
Accumulated time: update_bounds func: 98.9306	 prepare: 2.6530	 bound: 88.5758	 transfer: 0.0451	 finalize: 2.1828
batch bounding time:  0.8930685520172119
Current worst splitting domains [lb, ub] (depth):
[-0.07025,   inf] (73), [-0.07025,   inf] (95), [-0.07025,   inf] (91), [-0.07025,   inf] (93), [-0.07025,   inf] (89), [-0.07025,   inf] (97), [-0.07025,   inf] (77), [-0.07025,   inf] (81), [-0.07025,   inf] (33), [-0.07025,   inf] (27), [-0.07025,   inf] (99), [-0.07025,   inf] (73), [-0.07025,   inf] (89), [-0.07025,   inf] (91), [-0.07025,   inf] (97), [-0.07025,   inf] (79), [-0.07024,   inf] (85), [-0.07024,   inf] (97), [-0.07024,   inf] (95), [-0.07024,   inf] (81), 
length of domains: 5044
Total time: 1.1152	 pickout: 0.1034	 decision: 0.0957	 get_bound: 0.8933	 add_domain: 0.0227
Current lb:-0.07025063037872314
13818 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 124.07382416725159

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 313] [5, 406] [2, 5302] [2, 5298] [3, 3305] [3, 3836] [5, 313] [3, 653] [5, 270] [4, 71] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.583246231079102 with beta sum per layer: [0.0, 0.0, 68.77993774414062, 33.995994567871094, 2.880549192428589, 18.03942108154297]
alpha/beta optimization time: 0.7916879653930664
This batch time : update_bounds func: 0.8844	 prepare: 0.0260	 bound: 0.7922	 transfer: 0.0484	 finalize: 0.0174
Accumulated time: update_bounds func: 99.8150	 prepare: 2.6790	 bound: 89.3680	 transfer: 0.0484	 finalize: 2.2002
batch bounding time:  0.8848285675048828
Current worst splitting domains [lb, ub] (depth):
[-0.07022,   inf] (99), [-0.07022,   inf] (95), [-0.07022,   inf] (85), [-0.07022,   inf] (83), [-0.07022,   inf] (101), [-0.07021,   inf] (109), [-0.07021,   inf] (83), [-0.07021,   inf] (35), [-0.07021,   inf] (101), [-0.07021,   inf] (75), [-0.07021,   inf] (99), [-0.07021,   inf] (99), [-0.07021,   inf] (91), [-0.07021,   inf] (111), [-0.07021,   inf] (97), [-0.07021,   inf] (93), [-0.07021,   inf] (71), [-0.07021,   inf] (31), [-0.07021,   inf] (89), [-0.07021,   inf] (87), 
length of domains: 5095
Total time: 1.0721	 pickout: 0.0706	 decision: 0.0956	 get_bound: 0.8850	 add_domain: 0.0208
Current lb:-0.07021975517272949
13946 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 125.14932680130005

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 10955] [5, 266] [2, 4279] [3, 659] [3, 3036] [3, 1900] [5, 406] [5, 453] [2, 4279] [5, 313] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.4699225425720215 with beta sum per layer: [0.0, 0.0, 73.28927612304688, 24.880321502685547, 5.067919731140137, 16.04908561706543]
alpha/beta optimization time: 0.7926962375640869
This batch time : update_bounds func: 0.8831	 prepare: 0.0250	 bound: 0.7932	 transfer: 0.0485	 finalize: 0.0159
Accumulated time: update_bounds func: 100.6981	 prepare: 2.7040	 bound: 90.1612	 transfer: 0.0485	 finalize: 2.2161
batch bounding time:  0.8835556507110596
Current worst splitting domains [lb, ub] (depth):
[-0.07018,   inf] (109), [-0.07018,   inf] (95), [-0.07018,   inf] (83), [-0.07018,   inf] (93), [-0.07018,   inf] (23), [-0.07018,   inf] (91), [-0.07018,   inf] (91), [-0.07017,   inf] (95), [-0.07017,   inf] (97), [-0.07017,   inf] (75), [-0.07017,   inf] (95), [-0.07017,   inf] (73), [-0.07017,   inf] (79), [-0.07017,   inf] (101), [-0.07017,   inf] (81), [-0.07017,   inf] (93), [-0.07017,   inf] (91), [-0.07017,   inf] (85), [-0.07017,   inf] (103), [-0.07017,   inf] (93), 
length of domains: 5152
Total time: 1.3107	 pickout: 0.0872	 decision: 0.3180	 get_bound: 0.8838	 add_domain: 0.0218
Current lb:-0.07017705589532852
14074 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 126.46305346488953

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 31] [2, 4279] [3, 3305] [2, 8413] [4, 42] [5, 406] [2, 5298] [2, 4279] [3, 1900] [3, 3837] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.461780071258545 with beta sum per layer: [0.0, 0.0, 85.2043685913086, 26.013532638549805, 6.103155136108398, 15.213969230651855]
alpha/beta optimization time: 0.8015601634979248
This batch time : update_bounds func: 0.8957	 prepare: 0.0249	 bound: 0.8020	 transfer: 0.0516	 finalize: 0.0167
Accumulated time: update_bounds func: 101.5938	 prepare: 2.7289	 bound: 90.9632	 transfer: 0.0516	 finalize: 2.2329
batch bounding time:  0.8961005210876465
Current worst splitting domains [lb, ub] (depth):
[-0.07015,   inf] (79), [-0.07015,   inf] (103), [-0.07015,   inf] (93), [-0.07015,   inf] (77), [-0.07015,   inf] (85), [-0.07014,   inf] (93), [-0.07014,   inf] (87), [-0.07014,   inf] (99), [-0.07014,   inf] (89), [-0.07014,   inf] (91), [-0.07014,   inf] (91), [-0.07014,   inf] (89), [-0.07014,   inf] (111), [-0.07014,   inf] (91), [-0.07014,   inf] (97), [-0.07014,   inf] (81), [-0.07014,   inf] (91), [-0.07014,   inf] (101), [-0.07014,   inf] (33), [-0.07014,   inf] (91), 
length of domains: 5201
Total time: 1.0642	 pickout: 0.0546	 decision: 0.0936	 get_bound: 0.8963	 add_domain: 0.0197
Current lb:-0.07014691829681396
14202 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 127.53012418746948

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 406] [2, 4279] [5, 406] [3, 1900] [4, 445] [5, 406] [2, 5302] [2, 5316] [2, 10955] [5, 266] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.814177989959717 with beta sum per layer: [0.0, 0.0, 79.85311126708984, 17.11895751953125, 6.636563301086426, 12.194761276245117]
alpha/beta optimization time: 0.8345699310302734
This batch time : update_bounds func: 0.9250	 prepare: 0.0251	 bound: 0.8350	 transfer: 0.0485	 finalize: 0.0159
Accumulated time: update_bounds func: 102.5188	 prepare: 2.7540	 bound: 91.7982	 transfer: 0.0485	 finalize: 2.2488
batch bounding time:  0.9254615306854248
Current worst splitting domains [lb, ub] (depth):
[-0.07011,   inf] (103), [-0.07011,   inf] (87), [-0.07011,   inf] (91), [-0.07010,   inf] (95), [-0.07010,   inf] (91), [-0.07010,   inf] (97), [-0.07010,   inf] (99), [-0.07010,   inf] (91), [-0.07010,   inf] (97), [-0.07010,   inf] (73), [-0.07010,   inf] (107), [-0.07010,   inf] (103), [-0.07010,   inf] (85), [-0.07010,   inf] (83), [-0.07010,   inf] (89), [-0.07010,   inf] (51), [-0.07010,   inf] (53), [-0.07010,   inf] (97), [-0.07010,   inf] (103), [-0.07010,   inf] (87), 
length of domains: 5252
Total time: 1.1316	 pickout: 0.0888	 decision: 0.0956	 get_bound: 0.9257	 add_domain: 0.0215
Current lb:-0.07010698318481445
14330 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 128.6647481918335

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 10955] [4, 445] [4, 466] [2, 5302] [2, 4279] [2, 10955] [2, 10955] [2, 5302] [2, 5302] [5, 485] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.105058670043945 with beta sum per layer: [0.0, 0.0, 87.40274047851562, 21.846920013427734, 7.879589557647705, 14.286018371582031]
alpha/beta optimization time: 0.8078820705413818
This batch time : update_bounds func: 0.9091	 prepare: 0.0250	 bound: 0.8084	 transfer: 0.0519	 finalize: 0.0233
Accumulated time: update_bounds func: 103.4279	 prepare: 2.7790	 bound: 92.6066	 transfer: 0.0519	 finalize: 2.2721
batch bounding time:  0.9095363616943359
Current worst splitting domains [lb, ub] (depth):
[-0.07007,   inf] (93), [-0.07007,   inf] (85), [-0.07007,   inf] (103), [-0.07007,   inf] (45), [-0.07007,   inf] (93), [-0.07007,   inf] (87), [-0.07006,   inf] (87), [-0.07006,   inf] (81), [-0.07006,   inf] (81), [-0.07006,   inf] (79), [-0.07006,   inf] (85), [-0.07006,   inf] (97), [-0.07006,   inf] (107), [-0.07006,   inf] (101), [-0.07006,   inf] (93), [-0.07006,   inf] (81), [-0.07006,   inf] (93), [-0.07006,   inf] (99), [-0.07006,   inf] (93), [-0.07005,   inf] (99), 
length of domains: 5306
Total time: 1.0937	 pickout: 0.0680	 decision: 0.0938	 get_bound: 0.9098	 add_domain: 0.0221
Current lb:-0.07006800174713135
14458 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 129.76128220558167

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 4279] [5, 266] [2, 5316] [4, 466] [2, 5302] [2, 5298] [4, 357] [4, 466] [3, 3305] [3, 1900] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.430192947387695 with beta sum per layer: [0.0, 0.0, 74.20242309570312, 42.64888000488281, 4.498654365539551, 15.920524597167969]
alpha/beta optimization time: 0.8458454608917236
This batch time : update_bounds func: 0.9595	 prepare: 0.0382	 bound: 0.8465	 transfer: 0.0520	 finalize: 0.0223
Accumulated time: update_bounds func: 104.3874	 prepare: 2.8173	 bound: 93.4531	 transfer: 0.0520	 finalize: 2.2944
batch bounding time:  0.959942102432251
Current worst splitting domains [lb, ub] (depth):
[-0.07003,   inf] (79), [-0.07003,   inf] (89), [-0.07003,   inf] (97), [-0.07003,   inf] (55), [-0.07003,   inf] (41), [-0.07003,   inf] (97), [-0.07003,   inf] (83), [-0.07003,   inf] (103), [-0.07003,   inf] (41), [-0.07002,   inf] (103), [-0.07002,   inf] (95), [-0.07002,   inf] (95), [-0.07002,   inf] (101), [-0.07002,   inf] (81), [-0.07002,   inf] (85), [-0.07002,   inf] (91), [-0.07002,   inf] (97), [-0.07002,   inf] (79), [-0.07002,   inf] (93), [-0.07002,   inf] (107), 
length of domains: 5363
Total time: 1.1879	 pickout: 0.0975	 decision: 0.1066	 get_bound: 0.9602	 add_domain: 0.0236
Current lb:-0.07002907246351242
14586 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 130.95211553573608

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 1230] [4, 466] [2, 5298] [5, 294] [4, 402] [2, 10955] [5, 266] [3, 1900] [5, 6] [2, 10725] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.060466289520264 with beta sum per layer: [0.0, 0.0, 73.5657958984375, 18.102155685424805, 6.742164611816406, 16.66909408569336]
alpha/beta optimization time: 0.8070390224456787
This batch time : update_bounds func: 0.9117	 prepare: 0.0383	 bound: 0.8077	 transfer: 0.0486	 finalize: 0.0166
Accumulated time: update_bounds func: 105.2991	 prepare: 2.8556	 bound: 94.2608	 transfer: 0.0486	 finalize: 2.3110
batch bounding time:  0.9121370315551758
Current worst splitting domains [lb, ub] (depth):
[-0.06999,   inf] (83), [-0.06999,   inf] (91), [-0.06999,   inf] (97), [-0.06999,   inf] (97), [-0.06999,   inf] (107), [-0.06999,   inf] (101), [-0.06999,   inf] (97), [-0.06999,   inf] (85), [-0.06999,   inf] (91), [-0.06999,   inf] (103), [-0.06999,   inf] (83), [-0.06999,   inf] (27), [-0.06999,   inf] (93), [-0.06999,   inf] (93), [-0.06999,   inf] (91), [-0.06999,   inf] (81), [-0.06999,   inf] (39), [-0.06999,   inf] (95), [-0.06999,   inf] (35), [-0.06999,   inf] (83), 
length of domains: 5414
Total time: 1.1038	 pickout: 0.0664	 decision: 0.1052	 get_bound: 0.9124	 add_domain: 0.0198
Current lb:-0.0699927806854248
14714 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 132.05902481079102

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3305] [2, 5298] [2, 4279] [2, 4279] [4, 445] [3, 1900] [2, 5302] [5, 266] [2, 5302] [3, 1900] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.194964408874512 with beta sum per layer: [0.0, 0.0, 83.42739868164062, 23.437402725219727, 6.845867156982422, 15.242311477661133]
alpha/beta optimization time: 0.807276725769043
This batch time : update_bounds func: 0.8974	 prepare: 0.0251	 bound: 0.8078	 transfer: 0.0484	 finalize: 0.0157
Accumulated time: update_bounds func: 106.1965	 prepare: 2.8807	 bound: 95.0686	 transfer: 0.0484	 finalize: 2.3267
batch bounding time:  0.8978512287139893
Current worst splitting domains [lb, ub] (depth):
[-0.06996,   inf] (79), [-0.06996,   inf] (97), [-0.06996,   inf] (105), [-0.06996,   inf] (91), [-0.06996,   inf] (83), [-0.06996,   inf] (87), [-0.06996,   inf] (103), [-0.06996,   inf] (93), [-0.06996,   inf] (49), [-0.06996,   inf] (75), [-0.06996,   inf] (91), [-0.06995,   inf] (97), [-0.06995,   inf] (83), [-0.06995,   inf] (103), [-0.06995,   inf] (93), [-0.06995,   inf] (97), [-0.06995,   inf] (15), [-0.06995,   inf] (75), [-0.06995,   inf] (51), [-0.06995,   inf] (89), 
length of domains: 5466
Total time: 1.1211	 pickout: 0.1060	 decision: 0.0955	 get_bound: 0.8981	 add_domain: 0.0215
Current lb:-0.06995892524719238
14842 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 133.18380069732666

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 6101] [2, 5298] [2, 5285] [5, 406] [3, 3305] [5, 266] [2, 10725] [2, 4279] [5, 6] [5, 313] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.928356170654297 with beta sum per layer: [0.0, 0.0, 86.74783325195312, 26.309104919433594, 3.0042600631713867, 14.364341735839844]
alpha/beta optimization time: 0.8009459972381592
This batch time : update_bounds func: 0.8880	 prepare: 0.0250	 bound: 0.8014	 transfer: 0.0444	 finalize: 0.0167
Accumulated time: update_bounds func: 107.0845	 prepare: 2.9057	 bound: 95.8700	 transfer: 0.0444	 finalize: 2.3434
batch bounding time:  0.8884344100952148
Current worst splitting domains [lb, ub] (depth):
[-0.06993,   inf] (91), [-0.06993,   inf] (97), [-0.06993,   inf] (87), [-0.06993,   inf] (111), [-0.06993,   inf] (95), [-0.06993,   inf] (93), [-0.06993,   inf] (57), [-0.06993,   inf] (95), [-0.06993,   inf] (83), [-0.06993,   inf] (91), [-0.06993,   inf] (101), [-0.06993,   inf] (91), [-0.06993,   inf] (73), [-0.06993,   inf] (89), [-0.06993,   inf] (105), [-0.06993,   inf] (83), [-0.06993,   inf] (109), [-0.06993,   inf] (73), [-0.06993,   inf] (95), [-0.06992,   inf] (101), 
length of domains: 5519
Total time: 1.0606	 pickout: 0.0563	 decision: 0.0944	 get_bound: 0.8887	 add_domain: 0.0212
Current lb:-0.0699319839477539
14970 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 134.2473156452179

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 266] [3, 3036] [3, 3305] [2, 5285] [2, 16056] [2, 5302] [4, 482] [5, 406] [2, 5302] [2, 5302] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.182300567626953 with beta sum per layer: [0.0, 0.0, 82.68016052246094, 25.48038101196289, 4.595163822174072, 15.614625930786133]
alpha/beta optimization time: 0.8137640953063965
This batch time : update_bounds func: 0.9166	 prepare: 0.0255	 bound: 0.8143	 transfer: 0.0517	 finalize: 0.0245
Accumulated time: update_bounds func: 108.0011	 prepare: 2.9312	 bound: 96.6843	 transfer: 0.0517	 finalize: 2.3679
batch bounding time:  0.9172513484954834
Current worst splitting domains [lb, ub] (depth):
[-0.06990,   inf] (23), [-0.06990,   inf] (93), [-0.06990,   inf] (83), [-0.06990,   inf] (97), [-0.06990,   inf] (99), [-0.06990,   inf] (103), [-0.06990,   inf] (83), [-0.06990,   inf] (93), [-0.06990,   inf] (55), [-0.06990,   inf] (89), [-0.06990,   inf] (89), [-0.06990,   inf] (85), [-0.06990,   inf] (93), [-0.06989,   inf] (81), [-0.06989,   inf] (79), [-0.06989,   inf] (87), [-0.06989,   inf] (103), [-0.06989,   inf] (95), [-0.06989,   inf] (25), [-0.06989,   inf] (93), 
length of domains: 5575
Total time: 1.1245	 pickout: 0.0672	 decision: 0.0960	 get_bound: 0.9177	 add_domain: 0.0437
Current lb:-0.06989959627389908
15098 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 135.37608551979065

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 106] [5, 406] [3, 3305] [3, 3036] [2, 4279] [2, 10955] [5, 266] [3, 653] [4, 441] [5, 266] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.704336643218994 with beta sum per layer: [0.0, 0.0, 81.51832580566406, 23.50372314453125, 4.7407917976379395, 14.733284950256348]
alpha/beta optimization time: 0.8010191917419434
This batch time : update_bounds func: 0.8949	 prepare: 0.0249	 bound: 0.8015	 transfer: 0.0517	 finalize: 0.0163
Accumulated time: update_bounds func: 108.8960	 prepare: 2.9561	 bound: 97.4858	 transfer: 0.0517	 finalize: 2.3843
batch bounding time:  0.8953487873077393
Current worst splitting domains [lb, ub] (depth):
[-0.06987,   inf] (91), [-0.06987,   inf] (93), [-0.06987,   inf] (91), [-0.06987,   inf] (103), [-0.06987,   inf] (85), [-0.06987,   inf] (81), [-0.06987,   inf] (99), [-0.06987,   inf] (83), [-0.06987,   inf] (73), [-0.06987,   inf] (79), [-0.06987,   inf] (91), [-0.06987,   inf] (101), [-0.06986,   inf] (95), [-0.06986,   inf] (99), [-0.06986,   inf] (89), [-0.06986,   inf] (93), [-0.06986,   inf] (99), [-0.06986,   inf] (97), [-0.06986,   inf] (79), [-0.06986,   inf] (35), 
length of domains: 5633
Total time: 1.0598	 pickout: 0.0491	 decision: 0.0943	 get_bound: 0.8956	 add_domain: 0.0208
Current lb:-0.06987076997756958
15226 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 136.43892669677734

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 4279] [2, 5298] [3, 3036] [2, 10955] [4, 357] [3, 3305] [2, 10955] [5, 266] [5, 485] [4, 466] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.1335954666137695 with beta sum per layer: [0.0, 0.0, 81.62428283691406, 35.27251434326172, 5.288029670715332, 13.222421646118164]
alpha/beta optimization time: 0.8000624179840088
This batch time : update_bounds func: 0.8936	 prepare: 0.0252	 bound: 0.8006	 transfer: 0.0517	 finalize: 0.0157
Accumulated time: update_bounds func: 109.7896	 prepare: 2.9813	 bound: 98.2864	 transfer: 0.0517	 finalize: 2.4000
batch bounding time:  0.8940432071685791
Current worst splitting domains [lb, ub] (depth):
[-0.06983,   inf] (77), [-0.06983,   inf] (91), [-0.06983,   inf] (101), [-0.06983,   inf] (103), [-0.06983,   inf] (95), [-0.06983,   inf] (99), [-0.06983,   inf] (37), [-0.06983,   inf] (99), [-0.06983,   inf] (89), [-0.06983,   inf] (97), [-0.06983,   inf] (83), [-0.06983,   inf] (99), [-0.06983,   inf] (77), [-0.06982,   inf] (105), [-0.06982,   inf] (89), [-0.06982,   inf] (79), [-0.06982,   inf] (95), [-0.06982,   inf] (81), [-0.06982,   inf] (97), [-0.06982,   inf] (97), 
length of domains: 5687
Total time: 1.0640	 pickout: 0.0524	 decision: 0.0955	 get_bound: 0.8943	 add_domain: 0.0218
Current lb:-0.06983327865600586
15354 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 137.5059311389923

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 1230] [2, 5302] [2, 10725] [2, 10955] [2, 4279] [2, 10725] [5, 496] [2, 4279] [5, 266] [5, 266] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.110213279724121 with beta sum per layer: [0.0, 0.0, 99.12391662597656, 31.370634078979492, 3.9665842056274414, 11.978493690490723]
alpha/beta optimization time: 0.7962512969970703
This batch time : update_bounds func: 0.8878	 prepare: 0.0253	 bound: 0.7968	 transfer: 0.0486	 finalize: 0.0167
Accumulated time: update_bounds func: 110.6774	 prepare: 3.0066	 bound: 99.0832	 transfer: 0.0486	 finalize: 2.4167
batch bounding time:  0.8882455825805664
Current worst splitting domains [lb, ub] (depth):
[-0.06980,   inf] (27), [-0.06980,   inf] (79), [-0.06980,   inf] (101), [-0.06980,   inf] (91), [-0.06980,   inf] (111), [-0.06979,   inf] (93), [-0.06979,   inf] (81), [-0.06979,   inf] (63), [-0.06979,   inf] (73), [-0.06979,   inf] (97), [-0.06979,   inf] (95), [-0.06979,   inf] (101), [-0.06979,   inf] (95), [-0.06979,   inf] (111), [-0.06979,   inf] (95), [-0.06979,   inf] (85), [-0.06979,   inf] (107), [-0.06978,   inf] (99), [-0.06978,   inf] (97), [-0.06978,   inf] (89), 
length of domains: 5741
Total time: 1.0666	 pickout: 0.0604	 decision: 0.0967	 get_bound: 0.8885	 add_domain: 0.0210
Current lb:-0.06979716569185257
15482 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 138.57545948028564

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 359] [3, 1230] [3, 653] [2, 5298] [2, 10725] [3, 3036] [2, 7879] [5, 221] [2, 7879] [2, 5302] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.738727569580078 with beta sum per layer: [0.0, 0.36043086647987366, 84.92671203613281, 21.72002601623535, 4.031639099121094, 13.70869255065918]
alpha/beta optimization time: 0.7888247966766357
This batch time : update_bounds func: 1.1113	 prepare: 0.0262	 bound: 0.7893	 transfer: 0.0485	 finalize: 0.0158
Accumulated time: update_bounds func: 111.7887	 prepare: 3.0328	 bound: 99.8725	 transfer: 0.0485	 finalize: 2.4326
batch bounding time:  1.1117725372314453
Current worst splitting domains [lb, ub] (depth):
[-0.06976,   inf] (97), [-0.06976,   inf] (79), [-0.06976,   inf] (77), [-0.06976,   inf] (73), [-0.06976,   inf] (81), [-0.06976,   inf] (103), [-0.06976,   inf] (69), [-0.06976,   inf] (105), [-0.06976,   inf] (93), [-0.06976,   inf] (47), [-0.06975,   inf] (95), [-0.06975,   inf] (97), [-0.06975,   inf] (93), [-0.06975,   inf] (91), [-0.06975,   inf] (101), [-0.06975,   inf] (83), [-0.06975,   inf] (107), [-0.06975,   inf] (107), [-0.06975,   inf] (81), [-0.06975,   inf] (95), 
length of domains: 5799
Total time: 1.2827	 pickout: 0.0540	 decision: 0.0957	 get_bound: 1.1120	 add_domain: 0.0210
Current lb:-0.06976274400949478
15610 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 139.86121034622192

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3836] [3, 1900] [5, 313] [5, 485] [2, 6101] [2, 5316] [4, 482] [3, 1900] [2, 8413] [5, 245] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.733417987823486 with beta sum per layer: [0.0, 0.0, 83.26353454589844, 32.68452072143555, 3.49699330329895, 13.53742504119873]
alpha/beta optimization time: 0.7924652099609375
This batch time : update_bounds func: 0.8840	 prepare: 0.0257	 bound: 0.7930	 transfer: 0.0485	 finalize: 0.0163
Accumulated time: update_bounds func: 112.6727	 prepare: 3.0585	 bound: 100.6655	 transfer: 0.0485	 finalize: 2.4489
batch bounding time:  0.8844337463378906
Current worst splitting domains [lb, ub] (depth):
[-0.06973,   inf] (101), [-0.06973,   inf] (91), [-0.06973,   inf] (99), [-0.06973,   inf] (85), [-0.06973,   inf] (97), [-0.06973,   inf] (89), [-0.06973,   inf] (93), [-0.06973,   inf] (81), [-0.06973,   inf] (61), [-0.06973,   inf] (105), [-0.06973,   inf] (93), [-0.06973,   inf] (103), [-0.06973,   inf] (93), [-0.06973,   inf] (81), [-0.06972,   inf] (91), [-0.06972,   inf] (93), [-0.06972,   inf] (91), [-0.06972,   inf] (107), [-0.06972,   inf] (97), [-0.06972,   inf] (103), 
length of domains: 5856
Total time: 1.0580	 pickout: 0.0555	 decision: 0.0966	 get_bound: 0.8847	 add_domain: 0.0211
Current lb:-0.06973028182983398
15738 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 140.92220520973206

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 10955] [2, 5302] [4, 29] [3, 3305] [2, 4279] [2, 6101] [5, 266] [2, 7879] [4, 482] [3, 1900] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.8599090576171875 with beta sum per layer: [0.0, 0.0, 73.87603759765625, 21.791824340820312, 5.355233192443848, 15.78640365600586]
alpha/beta optimization time: 0.7891814708709717
This batch time : update_bounds func: 0.8801	 prepare: 0.0247	 bound: 0.7896	 transfer: 0.0486	 finalize: 0.0158
Accumulated time: update_bounds func: 113.5528	 prepare: 3.0832	 bound: 101.4551	 transfer: 0.0486	 finalize: 2.4647
batch bounding time:  0.8805716037750244
Current worst splitting domains [lb, ub] (depth):
[-0.06970,   inf] (85), [-0.06970,   inf] (93), [-0.06970,   inf] (103), [-0.06970,   inf] (101), [-0.06970,   inf] (85), [-0.06970,   inf] (91), [-0.06970,   inf] (95), [-0.06970,   inf] (81), [-0.06970,   inf] (97), [-0.06970,   inf] (83), [-0.06970,   inf] (89), [-0.06970,   inf] (83), [-0.06970,   inf] (61), [-0.06970,   inf] (93), [-0.06969,   inf] (97), [-0.06969,   inf] (93), [-0.06969,   inf] (85), [-0.06969,   inf] (103), [-0.06969,   inf] (99), [-0.06969,   inf] (101), 
length of domains: 5909
Total time: 1.0488	 pickout: 0.0539	 decision: 0.0938	 get_bound: 0.8808	 add_domain: 0.0203
Current lb:-0.06970202922821045
15866 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 141.97415709495544

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 266] [3, 653] [2, 5316] [2, 4279] [2, 6101] [2, 4279] [2, 4279] [2, 7879] [3, 653] [3, 1900] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.939899444580078 with beta sum per layer: [0.0, 0.0, 76.92644500732422, 25.85409927368164, 5.080836772918701, 12.563138008117676]
alpha/beta optimization time: 0.8058948516845703
This batch time : update_bounds func: 0.8948	 prepare: 0.0254	 bound: 0.8064	 transfer: 0.0457	 finalize: 0.0167
Accumulated time: update_bounds func: 114.4476	 prepare: 3.1087	 bound: 102.2615	 transfer: 0.0457	 finalize: 2.4814
batch bounding time:  0.8952245712280273
Current worst splitting domains [lb, ub] (depth):
[-0.06967,   inf] (79), [-0.06967,   inf] (99), [-0.06967,   inf] (93), [-0.06967,   inf] (101), [-0.06967,   inf] (91), [-0.06967,   inf] (81), [-0.06967,   inf] (99), [-0.06967,   inf] (101), [-0.06967,   inf] (89), [-0.06967,   inf] (95), [-0.06967,   inf] (81), [-0.06967,   inf] (95), [-0.06967,   inf] (97), [-0.06966,   inf] (95), [-0.06966,   inf] (95), [-0.06966,   inf] (93), [-0.06966,   inf] (91), [-0.06966,   inf] (93), [-0.06966,   inf] (105), [-0.06966,   inf] (103), 
length of domains: 5967
Total time: 1.0751	 pickout: 0.0630	 decision: 0.0952	 get_bound: 0.8954	 add_domain: 0.0215
Current lb:-0.06967270374298096
15994 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 143.05229091644287

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 6101] [2, 4279] [5, 266] [2, 4279] [2, 5298] [3, 3305] [2, 4279] [3, 1900] [4, 274] [3, 3836] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.937250137329102 with beta sum per layer: [0.0, 0.0, 82.05412292480469, 44.60165786743164, 5.328900337219238, 15.161112785339355]
alpha/beta optimization time: 0.7961146831512451
This batch time : update_bounds func: 0.8872	 prepare: 0.0249	 bound: 0.7966	 transfer: 0.0486	 finalize: 0.0157
Accumulated time: update_bounds func: 115.3348	 prepare: 3.1335	 bound: 103.0582	 transfer: 0.0486	 finalize: 2.4971
batch bounding time:  0.8876557350158691
Current worst splitting domains [lb, ub] (depth):
[-0.06964,   inf] (93), [-0.06964,   inf] (95), [-0.06964,   inf] (83), [-0.06964,   inf] (97), [-0.06964,   inf] (97), [-0.06964,   inf] (95), [-0.06964,   inf] (101), [-0.06964,   inf] (99), [-0.06964,   inf] (95), [-0.06964,   inf] (91), [-0.06964,   inf] (101), [-0.06964,   inf] (53), [-0.06963,   inf] (83), [-0.06963,   inf] (97), [-0.06963,   inf] (89), [-0.06963,   inf] (83), [-0.06963,   inf] (91), [-0.06963,   inf] (97), [-0.06963,   inf] (99), [-0.06963,   inf] (101), 
length of domains: 6022
Total time: 1.0584	 pickout: 0.0559	 decision: 0.0941	 get_bound: 0.8879	 add_domain: 0.0205
Current lb:-0.06964170932769775
16122 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 144.11374497413635

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 406] [3, 3036] [3, 3305] [5, 406] [3, 3836] [2, 5302] [2, 4279] [2, 4279] [5, 406] [2, 4279] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.150885581970215 with beta sum per layer: [0.0, 0.0, 85.46158599853516, 32.29940414428711, 6.016719818115234, 14.2565279006958]
alpha/beta optimization time: 0.8190031051635742
This batch time : update_bounds func: 0.9131	 prepare: 0.0251	 bound: 0.8195	 transfer: 0.0518	 finalize: 0.0162
Accumulated time: update_bounds func: 116.2479	 prepare: 3.1586	 bound: 103.8776	 transfer: 0.0518	 finalize: 2.5133
batch bounding time:  0.9135303497314453
Current worst splitting domains [lb, ub] (depth):
[-0.06961,   inf] (87), [-0.06961,   inf] (83), [-0.06961,   inf] (81), [-0.06961,   inf] (93), [-0.06961,   inf] (93), [-0.06961,   inf] (97), [-0.06961,   inf] (93), [-0.06961,   inf] (93), [-0.06961,   inf] (87), [-0.06961,   inf] (107), [-0.06961,   inf] (97), [-0.06961,   inf] (41), [-0.06961,   inf] (97), [-0.06961,   inf] (99), [-0.06960,   inf] (97), [-0.06960,   inf] (89), [-0.06960,   inf] (93), [-0.06960,   inf] (93), [-0.06960,   inf] (105), [-0.06960,   inf] (97), 
length of domains: 6075
Total time: 1.1191	 pickout: 0.0893	 decision: 0.0954	 get_bound: 0.9138	 add_domain: 0.0206
Current lb:-0.06961143016815186
16250 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 145.23597741127014

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5298] [5, 406] [4, 444] [5, 266] [5, 266] [2, 4279] [2, 5298] [3, 3036] [5, 266] [2, 10955] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.2634053230285645 with beta sum per layer: [0.0, 0.0, 79.16523742675781, 31.330482482910156, 4.129993438720703, 17.224010467529297]
alpha/beta optimization time: 0.7926762104034424
This batch time : update_bounds func: 0.8885	 prepare: 0.0256	 bound: 0.7932	 transfer: 0.0522	 finalize: 0.0160
Accumulated time: update_bounds func: 117.1364	 prepare: 3.1842	 bound: 104.6709	 transfer: 0.0522	 finalize: 2.5293
batch bounding time:  0.8889515399932861
Current worst splitting domains [lb, ub] (depth):
[-0.06958,   inf] (83), [-0.06958,   inf] (105), [-0.06958,   inf] (91), [-0.06958,   inf] (99), [-0.06958,   inf] (91), [-0.06958,   inf] (91), [-0.06958,   inf] (55), [-0.06958,   inf] (101), [-0.06957,   inf] (49), [-0.06957,   inf] (101), [-0.06957,   inf] (81), [-0.06957,   inf] (93), [-0.06957,   inf] (73), [-0.06957,   inf] (97), [-0.06957,   inf] (77), [-0.06957,   inf] (95), [-0.06957,   inf] (31), [-0.06957,   inf] (79), [-0.06957,   inf] (89), [-0.06957,   inf] (105), 
length of domains: 6125
Total time: 1.0596	 pickout: 0.0563	 decision: 0.0943	 get_bound: 0.8892	 add_domain: 0.0199
Current lb:-0.06957852840423584
16378 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 146.29874515533447

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3305] [2, 4279] [2, 5298] [2, 10955] [2, 5298] [3, 1900] [5, 491] [2, 5316] [4, 359] [3, 3836] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.5067524909973145 with beta sum per layer: [0.0, 0.0, 68.410888671875, 38.56907272338867, 5.6715407371521, 20.733814239501953]
alpha/beta optimization time: 0.8066186904907227
This batch time : update_bounds func: 0.8973	 prepare: 0.0249	 bound: 0.8071	 transfer: 0.0484	 finalize: 0.0165
Accumulated time: update_bounds func: 118.0336	 prepare: 3.2091	 bound: 105.4780	 transfer: 0.0484	 finalize: 2.5458
batch bounding time:  0.8977265357971191
Current worst splitting domains [lb, ub] (depth):
[-0.06955,   inf] (91), [-0.06955,   inf] (95), [-0.06955,   inf] (81), [-0.06955,   inf] (89), [-0.06955,   inf] (83), [-0.06955,   inf] (85), [-0.06955,   inf] (97), [-0.06955,   inf] (99), [-0.06954,   inf] (83), [-0.06954,   inf] (89), [-0.06954,   inf] (79), [-0.06954,   inf] (83), [-0.06954,   inf] (81), [-0.06954,   inf] (101), [-0.06954,   inf] (107), [-0.06954,   inf] (77), [-0.06954,   inf] (89), [-0.06954,   inf] (99), [-0.06954,   inf] (99), [-0.06954,   inf] (101), 
length of domains: 6174
Total time: 1.0670	 pickout: 0.0540	 decision: 0.0956	 get_bound: 0.8979	 add_domain: 0.0195
Current lb:-0.06954896450042725
16506 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 147.36906790733337

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 5302] [2, 4279] [3, 1900] [4, 445] [3, 3305] [5, 406] [3, 3836] [2, 6101] [3, 3305] [5, 406] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.902116298675537 with beta sum per layer: [0.0, 0.0, 90.12091827392578, 35.67845153808594, 6.7585296630859375, 12.082042694091797]
alpha/beta optimization time: 0.7966222763061523
This batch time : update_bounds func: 0.8880	 prepare: 0.0251	 bound: 0.7971	 transfer: 0.0486	 finalize: 0.0158
Accumulated time: update_bounds func: 118.9216	 prepare: 3.2341	 bound: 106.2751	 transfer: 0.0486	 finalize: 2.5616
batch bounding time:  0.8884334564208984
Current worst splitting domains [lb, ub] (depth):
[-0.06952,   inf] (95), [-0.06952,   inf] (93), [-0.06952,   inf] (75), [-0.06952,   inf] (95), [-0.06952,   inf] (93), [-0.06952,   inf] (101), [-0.06952,   inf] (95), [-0.06952,   inf] (103), [-0.06952,   inf] (89), [-0.06952,   inf] (79), [-0.06952,   inf] (99), [-0.06952,   inf] (93), [-0.06952,   inf] (53), [-0.06952,   inf] (103), [-0.06952,   inf] (97), [-0.06952,   inf] (97), [-0.06952,   inf] (101), [-0.06951,   inf] (87), [-0.06951,   inf] (79), [-0.06951,   inf] (97), 
length of domains: 6227
Total time: 1.0579	 pickout: 0.0535	 decision: 0.0951	 get_bound: 0.8887	 add_domain: 0.0205
Current lb:-0.06952077150344849
16634 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 148.43025064468384

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 406] [5, 266] [5, 313] [5, 406] [2, 10955] [2, 5316] [2, 5302] [2, 10955] [5, 406] [3, 1900] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.878526210784912 with beta sum per layer: [0.0, 0.3000229299068451, 87.83050537109375, 21.962268829345703, 4.016919136047363, 14.886148452758789]
alpha/beta optimization time: 0.7926220893859863
This batch time : update_bounds func: 0.8847	 prepare: 0.0257	 bound: 0.7931	 transfer: 0.0485	 finalize: 0.0167
Accumulated time: update_bounds func: 119.8063	 prepare: 3.2599	 bound: 107.0682	 transfer: 0.0485	 finalize: 2.5783
batch bounding time:  0.8851397037506104
Current worst splitting domains [lb, ub] (depth):
[-0.06949,   inf] (87), [-0.06949,   inf] (91), [-0.06949,   inf] (93), [-0.06949,   inf] (81), [-0.06949,   inf] (107), [-0.06949,   inf] (97), [-0.06949,   inf] (87), [-0.06949,   inf] (101), [-0.06949,   inf] (97), [-0.06949,   inf] (109), [-0.06949,   inf] (93), [-0.06949,   inf] (75), [-0.06949,   inf] (81), [-0.06949,   inf] (97), [-0.06949,   inf] (95), [-0.06948,   inf] (89), [-0.06948,   inf] (93), [-0.06948,   inf] (83), [-0.06948,   inf] (99), [-0.06948,   inf] (83), 
length of domains: 6279
Total time: 1.0689	 pickout: 0.0652	 decision: 0.0976	 get_bound: 0.8854	 add_domain: 0.0208
Current lb:-0.06948983669281006
16762 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 149.50282955169678

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 6101] [2, 5298] [2, 5302] [2, 6101] [5, 31] [2, 5302] [2, 6101] [5, 406] [2, 5302] [2, 16052] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.845268726348877 with beta sum per layer: [0.0, 0.0, 82.4925537109375, 28.121978759765625, 5.682741165161133, 12.920906066894531]
alpha/beta optimization time: 0.796318531036377
This batch time : update_bounds func: 0.8875	 prepare: 0.0250	 bound: 0.7968	 transfer: 0.0485	 finalize: 0.0158
Accumulated time: update_bounds func: 120.6938	 prepare: 3.2849	 bound: 107.8650	 transfer: 0.0485	 finalize: 2.5941
batch bounding time:  0.8878905773162842
Current worst splitting domains [lb, ub] (depth):
[-0.06946,   inf] (95), [-0.06946,   inf] (93), [-0.06946,   inf] (87), [-0.06946,   inf] (43), [-0.06946,   inf] (73), [-0.06946,   inf] (51), [-0.06946,   inf] (93), [-0.06946,   inf] (81), [-0.06946,   inf] (81), [-0.06946,   inf] (109), [-0.06946,   inf] (97), [-0.06946,   inf] (95), [-0.06946,   inf] (103), [-0.06946,   inf] (105), [-0.06946,   inf] (77), [-0.06946,   inf] (85), [-0.06946,   inf] (55), [-0.06946,   inf] (97), [-0.06946,   inf] (43), [-0.06946,   inf] (87), 
length of domains: 6331
Total time: 1.0561	 pickout: 0.0533	 decision: 0.0936	 get_bound: 0.8881	 add_domain: 0.0210
Current lb:-0.06946396827697754
16890 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 150.5620470046997

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 406] [2, 5302] [4, 445] [5, 509] [5, 221] [5, 51] [3, 653] [2, 7879] [2, 6101] [5, 31] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.682320594787598 with beta sum per layer: [0.0, 0.0, 69.7918701171875, 29.646804809570312, 4.674931526184082, 17.91556167602539]
alpha/beta optimization time: 0.7940871715545654
This batch time : update_bounds func: 0.8886	 prepare: 0.0252	 bound: 0.7946	 transfer: 0.0518	 finalize: 0.0165
Accumulated time: update_bounds func: 121.5823	 prepare: 3.3101	 bound: 108.6596	 transfer: 0.0518	 finalize: 2.6106
batch bounding time:  0.8890295028686523
Current worst splitting domains [lb, ub] (depth):
[-0.06944,   inf] (51), [-0.06943,   inf] (103), [-0.06943,   inf] (101), [-0.06943,   inf] (85), [-0.06943,   inf] (99), [-0.06943,   inf] (97), [-0.06943,   inf] (103), [-0.06943,   inf] (83), [-0.06943,   inf] (95), [-0.06943,   inf] (99), [-0.06943,   inf] (95), [-0.06943,   inf] (109), [-0.06943,   inf] (105), [-0.06943,   inf] (93), [-0.06943,   inf] (103), [-0.06943,   inf] (93), [-0.06943,   inf] (95), [-0.06943,   inf] (71), [-0.06943,   inf] (83), [-0.06942,   inf] (79), 
length of domains: 6381
Total time: 1.0560	 pickout: 0.0506	 decision: 0.0961	 get_bound: 0.8893	 add_domain: 0.0200
Current lb:-0.06943762302398682
17018 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 151.62138414382935

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 113] [4, 445] [2, 5316] [2, 5298] [4, 444] [3, 1900] [2, 5316] [4, 357] [2, 4279] [3, 3836] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.291376113891602 with beta sum per layer: [0.0, 0.3195094168186188, 82.75086975097656, 24.186077117919922, 7.761663436889648, 15.449100494384766]
alpha/beta optimization time: 0.7910110950469971
This batch time : update_bounds func: 0.8830	 prepare: 0.0258	 bound: 0.7915	 transfer: 0.0484	 finalize: 0.0159
Accumulated time: update_bounds func: 122.4654	 prepare: 3.3359	 bound: 109.4511	 transfer: 0.0484	 finalize: 2.6265
batch bounding time:  0.8834803104400635
Current worst splitting domains [lb, ub] (depth):
[-0.06941,   inf] (99), [-0.06941,   inf] (91), [-0.06941,   inf] (99), [-0.06941,   inf] (77), [-0.06940,   inf] (81), [-0.06940,   inf] (31), [-0.06940,   inf] (61), [-0.06940,   inf] (105), [-0.06940,   inf] (83), [-0.06940,   inf] (103), [-0.06940,   inf] (101), [-0.06940,   inf] (39), [-0.06940,   inf] (93), [-0.06940,   inf] (107), [-0.06940,   inf] (99), [-0.06940,   inf] (95), [-0.06940,   inf] (91), [-0.06940,   inf] (93), [-0.06940,   inf] (95), [-0.06940,   inf] (99), 
length of domains: 6434
Total time: 1.0487	 pickout: 0.0504	 decision: 0.0941	 get_bound: 0.8837	 add_domain: 0.0205
Current lb:-0.06940555572509766
17146 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 152.6732473373413

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 406] [2, 5302] [2, 10955] [2, 16056] [3, 653] [4, 135] [5, 491] [2, 5316] [3, 3305] [4, 445] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.53429651260376 with beta sum per layer: [0.0, 0.0, 87.85052490234375, 39.263702392578125, 6.170350074768066, 16.844240188598633]
alpha/beta optimization time: 0.8074133396148682
This batch time : update_bounds func: 0.9056	 prepare: 0.0251	 bound: 0.8079	 transfer: 0.0490	 finalize: 0.0231
Accumulated time: update_bounds func: 123.3710	 prepare: 3.3610	 bound: 110.2591	 transfer: 0.0490	 finalize: 2.6496
batch bounding time:  0.9060502052307129
Current worst splitting domains [lb, ub] (depth):
[-0.06938,   inf] (99), [-0.06938,   inf] (81), [-0.06938,   inf] (87), [-0.06938,   inf] (101), [-0.06938,   inf] (95), [-0.06937,   inf] (91), [-0.06937,   inf] (101), [-0.06937,   inf] (115), [-0.06937,   inf] (87), [-0.06937,   inf] (27), [-0.06937,   inf] (87), [-0.06937,   inf] (97), [-0.06937,   inf] (91), [-0.06937,   inf] (45), [-0.06937,   inf] (105), [-0.06937,   inf] (93), [-0.06937,   inf] (95), [-0.06937,   inf] (91), [-0.06937,   inf] (101), [-0.06937,   inf] (95), 
length of domains: 6485
Total time: 1.3243	 pickout: 0.0511	 decision: 0.3452	 get_bound: 0.9063	 add_domain: 0.0217
Current lb:-0.06937733292579651
17274 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 154.0006799697876

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 653] [2, 7879] [5, 406] [3, 3836] [2, 5302] [2, 5298] [4, 445] [2, 5595] [3, 3305] [4, 262] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 6.650991916656494 with beta sum per layer: [0.0, 0.0, 82.16471862792969, 29.468746185302734, 7.444209575653076, 19.01473617553711]/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:530: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(eps_temp / std).reshape(1, -1, 1, 1)

alpha/beta optimization time: 0.8030643463134766
This batch time : update_bounds func: 0.9111	 prepare: 0.0382	 bound: 0.8037	 transfer: 0.0519	 finalize: 0.0169
Accumulated time: update_bounds func: 124.2821	 prepare: 3.3992	 bound: 111.0627	 transfer: 0.0519	 finalize: 2.6665
batch bounding time:  0.9115469455718994
Current worst splitting domains [lb, ub] (depth):
[-0.06935,   inf] (37), [-0.06935,   inf] (87), [-0.06935,   inf] (99), [-0.06935,   inf] (105), [-0.06935,   inf] (81), [-0.06935,   inf] (81), [-0.06935,   inf] (83), [-0.06935,   inf] (97), [-0.06935,   inf] (93), [-0.06935,   inf] (89), [-0.06935,   inf] (95), [-0.06935,   inf] (35), [-0.06934,   inf] (97), [-0.06934,   inf] (93), [-0.06934,   inf] (77), [-0.06934,   inf] (53), [-0.06934,   inf] (91), [-0.06934,   inf] (103), [-0.06934,   inf] (31), [-0.06934,   inf] (35), 
length of domains: 6535
Total time: 1.0979	 pickout: 0.0622	 decision: 0.1041	 get_bound: 0.9118	 add_domain: 0.0197
Current lb:-0.06934890896081924
17402 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 155.10207271575928

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 32, 32]) pre split depth:  1
batch:  torch.Size([64, 32, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [5, 496] [2, 5298] [2, 5316] [3, 1900] [3, 3305] [3, 3305] [3, 1900] [1, 3806] [5, 266] [2, 5302] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 7.6277241706848145 with beta sum per layer: [0.0, 0.2434777468442917, 79.45730590820312, 32.236289978027344, 3.4362306594848633, 15.008208274841309]
alpha/beta optimization time: 0.8547267913818359
This batch time : update_bounds func: 0.9548	 prepare: 0.0257	 bound: 0.8552	 transfer: 0.0519	 finalize: 0.0214
Accumulated time: update_bounds func: 125.2368	 prepare: 3.4250	 bound: 111.9180	 transfer: 0.0519	 finalize: 2.6879
batch bounding time:  0.9552309513092041
Current worst splitting domains [lb, ub] (depth):
[-0.06933,   inf] (75), [-0.06933,   inf] (103), [-0.06933,   inf] (91), [-0.06933,   inf] (101), [-0.06933,   inf] (85), [-0.06932,   inf] (103), [-0.06932,   inf] (105), [-0.06932,   inf] (97), [-0.06932,   inf] (93), [-0.06932,   inf] (99), [-0.06932,   inf] (97), [-0.06932,   inf] (77), [-0.06932,   inf] (87), [-0.06932,   inf] (101), [-0.06932,   inf] (87), [-0.06932,   inf] (93), [-0.06932,   inf] (99), [-0.06932,   inf] (81), [-0.06932,   inf] (103), [-0.06932,   inf] (93), 
length of domains: 6593
Total time: 1.1785	 pickout: 0.1042	 decision: 0.0974	 get_bound: 0.9555	 add_domain: 0.0215
Current lb:-0.06932580471038818
17530 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Time out!!!!!!!!
Image 187 label 9 verification end, final lower bound -0.06932580471038818, upper bound inf, time: 156.6400911808014
187 -0.06932580471038818
Result: image 187 verification failure (with branch and bound).
Wall time: 187.1355299949646

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 0): []
verification failure idx (total 1): [187]
final verified acc: 0.0%[1]
verifier is called on 1 examples.
total verified: 0
mean time [cnt:1] (excluding attack success): 181.48603510856628
