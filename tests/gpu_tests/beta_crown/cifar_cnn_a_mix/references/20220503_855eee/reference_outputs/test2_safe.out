Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_cnn_a_mix.model
  name: cnn_4layer
data:
  start: 18
  end: 19
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR_SDP
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.00784313725
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 4096
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 200
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 20:55:40 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Flatten()
  (5): Linear(in_features=2048, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([200, 3, 32, 32]) torch.Size([200]) torch.Size([200])
X range: tensor(2.1256) tensor(-1.9889) tensor(-0.0131)
############################
epsilon after preprocessing: tensor([[[[0.0317]],

         [[0.0322]],

         [[0.0300]]]]), data_max = tensor([[[[2.0587]],

         [[2.1256]],

         [[2.1154]]]]), data_min = tensor([[[[-1.9889]],

         [[-1.9807]],

         [[-1.7076]]]])
Task length: 1
saving results to Verified_ret_[cnn_4layer]_start=18_end=19_iter=20_b=4096_timeout=200_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 18 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 6, correct label 6, image norm 1670.1436767578125, logits tensor([-40.1214, -44.1967, -34.0821, -36.7135, -34.0780, -36.5420, -31.8205,
        -38.2620, -42.6228, -43.6226], device='cuda:0',
       grad_fn=<SelectBackward>)
##### PGD attack: True label: 6, Tested against: ['all'] ######
pgd prediction: tensor([-39.8343, -44.1642, -34.0625, -36.5912, -33.3508, -36.4007, -32.4571,
        -37.6843, -42.4887, -43.5140], device='cuda:0',
       grad_fn=<SqueezeBackward1>)
attack margin tensor([ 7.3772, 11.7071,  1.6054,  4.1341,  0.8938,  3.9436,     inf,  5.2272,
        10.0316, 11.0569], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[-40.1214, -44.1967, -34.0821, -36.7135, -34.0780, -36.5420, -31.8205,
         -38.2620, -42.6228, -43.6226]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 3.8850,  7.1090, -1.4665,  1.9201, -1.1905,  0.9826,  1.8073,  6.6354,
          6.8236]], device='cuda:0') None
best_l after optimization: -28.374866485595703 with beta sum per layer: []
alpha/beta optimization time: 7.646455764770508
initial alpha-CROWN bounds: tensor([[ 4.1328,  7.3403, -1.2369,  2.0843, -1.0182,  1.1788,  2.0627,  6.8257,
          7.0053]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-1.2369, device='cuda:0', grad_fn=<MinBackward1>)
Sorted order for labels to verify: [4, 2, 5, 3, 7, 0, 8, 9, 1, 6]
##### [0:18] Tested against 4 ######
Model prediction is: tensor([[-40.1214, -44.1967, -34.0821, -36.7135, -34.0780, -36.5420, -31.8205,
         -38.2620, -42.6228, -43.6226]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 16, 16]) != torch.Size([2, 9, 1, 16, 16, 16]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 8, 8]) != torch.Size([2, 9, 1, 32, 8, 8]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 16, 16])
1 /11 torch.Size([1, 32, 8, 8])
2 /21 torch.Size([1, 100])
best_l after optimization: 1.0179786682128906 with beta sum per layer: []
alpha/beta optimization time: 2.0693869590759277
alpha-CROWN with fixed intermediate bounds: tensor([[-1.0180]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-1.0179786682128906
layer 0 size torch.Size([4096]) unstable 580
layer 1 size torch.Size([2048]) unstable 359
layer 2 size torch.Size([100]) unstable 45
-----------------
# of unstable neurons: 984
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 16, 16]) pre split depth:  8
batch:  torch.Size([1, 16, 16, 16]) post split depth:  8
splitting decisions: 
split level 0: [2, 71] 
split level 1: [2, 61] 
split level 2: [2, 8] 
split level 3: [2, 95] 
split level 4: [2, 40] 
split level 5: [2, 78] 
split level 6: [2, 58] 
split level 7: [2, 67] 
regular batch size: 2*128, diving batch size 1*0
best_l after optimization: -189.962646484375 with beta sum per layer: [0.0, 0.0, 0.08689828962087631]
alpha/beta optimization time: 0.3307185173034668
This batch time : update_bounds func: 0.3810	 prepare: 0.0197	 bound: 0.3311	 transfer: 0.0132	 finalize: 0.0163
Accumulated time: update_bounds func: 0.3810	 prepare: 0.0197	 bound: 0.3311	 transfer: 0.0132	 finalize: 0.0163
batch bounding time:  0.3814387321472168
Current worst splitting domains [lb, ub] (depth):
[-0.07042,   inf] (9), [-0.04503,   inf] (9), 
length of domains: 2
Total time: 0.6874	 pickout: 0.0010	 decision: 0.2708	 get_bound: 0.4153	 add_domain: 0.0002
Current lb:-0.07041830569505692
256 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.6021862030029297

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2, 16, 16, 16]) pre split depth:  7
batch:  torch.Size([2, 16, 16, 16]) post split depth:  7
splitting decisions: 
split level 0: [2, 19] [2, 19] 
split level 1: [2, 16] [2, 16] 
split level 2: [2, 29] [2, 29] 
split level 3: [1, 1124] [1, 1124] 
split level 4: [2, 82] [2, 82] 
split level 5: [2, 46] [2, 46] 
split level 6: [2, 94] [2, 94] 
regular batch size: 2*128, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -69.34041595458984 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.010167121887207031
This batch time : update_bounds func: 0.0632	 prepare: 0.0234	 bound: 0.0105	 transfer: 0.0129	 finalize: 0.0156
Accumulated time: update_bounds func: 0.4442	 prepare: 0.0431	 bound: 0.3416	 transfer: 0.0129	 finalize: 0.0319
batch bounding time:  0.06345057487487793
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.1429	 pickout: 0.0010	 decision: 0.0438	 get_bound: 0.0979	 add_domain: 0.0001
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 3.746397018432617

Image 18 label 4 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 3.806973934173584
18 1.0000000116860974e-07
##### [0:18] Tested against 2 ######
Model prediction is: tensor([[-40.1214, -44.1967, -34.0821, -36.7135, -34.0780, -36.5420, -31.8205,
         -38.2620, -42.6228, -43.6226]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 16, 16]) != torch.Size([2, 9, 1, 16, 16, 16]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 8, 8]) != torch.Size([2, 9, 1, 32, 8, 8]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 16, 16])
1 /11 torch.Size([1, 32, 8, 8])
2 /21 torch.Size([1, 100])
best_l after optimization: 1.2365198135375977 with beta sum per layer: []
alpha/beta optimization time: 1.1164238452911377
alpha-CROWN with fixed intermediate bounds: tensor([[-1.2365]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-1.2365198135375977
layer 0 size torch.Size([4096]) unstable 580
layer 1 size torch.Size([2048]) unstable 359
layer 2 size torch.Size([100]) unstable 45
-----------------
# of unstable neurons: 984
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 16, 16]) pre split depth:  8
batch:  torch.Size([1, 16, 16, 16]) post split depth:  8
splitting decisions: 
split level 0: [2, 66] 
split level 1: [2, 28] 
split level 2: [2, 61] 
split level 3: [2, 71] 
split level 4: [2, 8] 
split level 5: [2, 7] 
split level 6: [2, 83] 
split level 7: [2, 46] 
regular batch size: 2*128, diving batch size 1*0
best_l after optimization: -44.420005798339844 with beta sum per layer: [0.0, 0.0, 9.732633590698242]
alpha/beta optimization time: 0.28790998458862305
This batch time : update_bounds func: 0.3366	 prepare: 0.0192	 bound: 0.2882	 transfer: 0.0132	 finalize: 0.0153
Accumulated time: update_bounds func: 0.7808	 prepare: 0.0623	 bound: 0.6298	 transfer: 0.0132	 finalize: 0.0472
batch bounding time:  0.3369772434234619
Current worst splitting domains [lb, ub] (depth):
[-0.22679,   inf] (9), [-0.20883,   inf] (9), [-0.19865,   inf] (9), [-0.17560,   inf] (9), [-0.17458,   inf] (9), [-0.17243,   inf] (9), [-0.16004,   inf] (9), [-0.14620,   inf] (9), [-0.13860,   inf] (9), [-0.13470,   inf] (9), [-0.13400,   inf] (9), [-0.11372,   inf] (9), [-0.10812,   inf] (9), [-0.10759,   inf] (9), [-0.09510,   inf] (9), [-0.09212,   inf] (9), [-0.06467,   inf] (9), [-0.06313,   inf] (9), [-0.06237,   inf] (9), [-0.05988,   inf] (9), 
length of domains: 32
Total time: 0.4225	 pickout: 0.0009	 decision: 0.0476	 get_bound: 0.3725	 add_domain: 0.0015
Current lb:-0.22678832709789276
256 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.560117483139038

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([32, 16, 16, 16]) pre split depth:  3
batch:  torch.Size([32, 16, 16, 16]) post split depth:  3
splitting decisions: 
split level 0: [2, 16] [2, 14] [2, 16] [2, 14] [2, 14] [2, 16] [2, 14] [2, 14] [2, 16] [2, 14] 
split level 1: [2, 14] [2, 16] [2, 14] [2, 16] [2, 16] [2, 14] [2, 16] [2, 16] [2, 14] [2, 16] 
split level 2: [2, 40] [2, 40] [2, 40] [2, 40] [2, 40] [2, 40] [2, 40] [2, 40] [2, 40] [2, 40] 
regular batch size: 2*128, diving batch size 1*0
best_l after optimization: -58.1827392578125 with beta sum per layer: [0.0, 0.0, 15.84933853149414]
alpha/beta optimization time: 0.2771732807159424
This batch time : update_bounds func: 0.3294	 prepare: 0.0229	 bound: 0.2775	 transfer: 0.0137	 finalize: 0.0148
Accumulated time: update_bounds func: 1.1102	 prepare: 0.0852	 bound: 0.9073	 transfer: 0.0137	 finalize: 0.0620
batch bounding time:  0.32970142364501953
Current worst splitting domains [lb, ub] (depth):
[-0.09066,   inf] (13), [-0.07689,   inf] (13), [-0.06000,   inf] (13), [-0.04326,   inf] (13), [-0.04145,   inf] (13), [-0.03533,   inf] (13), [-0.03037,   inf] (13), [-0.00704,   inf] (13), [-0.00172,   inf] (13), 
length of domains: 9
Total time: 0.4001	 pickout: 0.0055	 decision: 0.0381	 get_bound: 0.3559	 add_domain: 0.0006
Current lb:-0.09065891057252884
512 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.9616310596466064

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([9, 16, 16, 16]) pre split depth:  5
batch:  torch.Size([9, 16, 16, 16]) post split depth:  5
splitting decisions: 
split level 0: [2, 95] [2, 95] [2, 95] [2, 95] [2, 95] [2, 95] [2, 95] [2, 95] [2, 95] 
split level 1: [2, 19] [2, 19] [2, 19] [2, 19] [2, 19] [2, 19] [2, 19] [2, 19] [2, 19] 
split level 2: [2, 10] [2, 10] [2, 10] [2, 10] [2, 10] [2, 10] [2, 10] [2, 10] [2, 10] 
split level 3: [2, 30] [2, 30] [2, 30] [2, 30] [2, 30] [2, 30] [2, 30] [2, 30] [2, 30] 
split level 4: [2, 50] [2, 50] [2, 50] [2, 50] [2, 50] [2, 50] [2, 50] [2, 50] [2, 50] 
regular batch size: 2*144, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -147.3446502685547 with beta sum per layer: [0.0, 0.0, 4.050921440124512]
alpha/beta optimization time: 0.010641336441040039
This batch time : update_bounds func: 0.0638	 prepare: 0.0257	 bound: 0.0109	 transfer: 0.0085	 finalize: 0.0180
Accumulated time: update_bounds func: 1.1740	 prepare: 0.1109	 bound: 0.9182	 transfer: 0.0085	 finalize: 0.0800
batch bounding time:  0.0640859603881836
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.1412	 pickout: 0.0021	 decision: 0.0367	 get_bound: 0.1024	 add_domain: 0.0001
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 2.1063263416290283

Image 18 label 2 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 2.1724047660827637
18 1.0000000116860974e-07
##### [0:18] Tested against 5 ######
Initial alpha-CROWN verified for label 5 with bound 1.1788047552108765
Image 18 label 5 verification end, final lower bound 1.1788047552108765, upper bound inf, time: 0.0004169940948486328
18 1.1788047552108765
##### [0:18] Tested against 3 ######
Initial alpha-CROWN verified for label 3 with bound 2.084291458129883
Image 18 label 3 verification end, final lower bound 2.084291458129883, upper bound inf, time: 0.0004074573516845703
18 2.084291458129883
##### [0:18] Tested against 7 ######
Initial alpha-CROWN verified for label 7 with bound 2.0627388954162598
Image 18 label 7 verification end, final lower bound 2.0627388954162598, upper bound inf, time: 0.00039696693420410156
18 2.0627388954162598
##### [0:18] Tested against 0 ######
Initial alpha-CROWN verified for label 0 with bound 4.132816314697266
Image 18 label 0 verification end, final lower bound 4.132816314697266, upper bound inf, time: 0.0004191398620605469
18 4.132816314697266
##### [0:18] Tested against 8 ######
Initial alpha-CROWN verified for label 8 with bound 6.825668811798096
Image 18 label 8 verification end, final lower bound 6.825668811798096, upper bound inf, time: 0.00039505958557128906
18 6.825668811798096
##### [0:18] Tested against 9 ######
Initial alpha-CROWN verified for label 9 with bound 7.005331039428711
Image 18 label 9 verification end, final lower bound 7.005331039428711, upper bound inf, time: 0.000553131103515625
18 7.005331039428711
##### [0:18] Tested against 1 ######
Initial alpha-CROWN verified for label 1 with bound 7.340282440185547
Image 18 label 1 verification end, final lower bound 7.340282440185547, upper bound inf, time: 0.0004076957702636719/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:462: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(preprocess_cifar(eps_temp, perturbation=True)).reshape(1,-1,1,1)

18 7.340282440185547
##### [0:18] Tested against 6 ######
groundtruth label, skip!
Result: image 18 verification success (with branch and bound)!
Wall time: 16.872278451919556

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 1): [18]
verification failure idx (total 0): []
final verified acc: 100.0%[1]
verifier is called on 1 examples.
total verified: 1
mean time [cnt:1] (excluding attack success): 15.449232578277588
