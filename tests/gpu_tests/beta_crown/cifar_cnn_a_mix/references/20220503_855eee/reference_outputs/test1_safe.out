Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_cnn_a_mix.model
  name: cnn_4layer
data:
  start: 7
  end: 8
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR_SDP
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.00784313725
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 4096
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 200
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 20:55:17 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Flatten()
  (5): Linear(in_features=2048, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([200, 3, 32, 32]) torch.Size([200]) torch.Size([200])
X range: tensor(2.1256) tensor(-1.9889) tensor(-0.0131)
############################
epsilon after preprocessing: tensor([[[[0.0317]],

         [[0.0322]],

         [[0.0300]]]]), data_max = tensor([[[[2.0587]],

         [[2.1256]],

         [[2.1154]]]]), data_min = tensor([[[[-1.9889]],

         [[-1.9807]],

         [[-1.7076]]]])
Task length: 1
saving results to Verified_ret_[cnn_4layer]_start=7_end=8_iter=20_b=4096_timeout=200_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 7 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 6, correct label 6, image norm 3749.12353515625, logits tensor([-36.2892, -37.4126, -32.6881, -32.7412, -30.5074, -33.8176, -28.7117,
        -34.6503, -36.7331, -37.1748], device='cuda:0',
       grad_fn=<SelectBackward>)
##### PGD attack: True label: 6, Tested against: ['all'] ######
pgd prediction: tensor([-35.7872, -37.2930, -32.4619, -32.5311, -29.8534, -33.4740, -29.2119,
        -33.7839, -36.3810, -36.8851], device='cuda:0',
       grad_fn=<SqueezeBackward1>)
attack margin tensor([6.5753, 8.0811, 3.2501, 3.3193, 0.6415, 4.2621,    inf, 4.5721, 7.1691,
        7.6732], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[-36.2892, -37.4126, -32.6881, -32.7412, -30.5074, -33.8176, -28.7117,
         -34.6503, -36.7331, -37.1748]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 2.8586,  3.4029, -0.2334,  0.8893, -1.5643,  1.3017,  1.0215,  3.1824,
          2.5906]], device='cuda:0') None
best_l after optimization: -15.705998420715332 with beta sum per layer: []
alpha/beta optimization time: 7.59922194480896
initial alpha-CROWN bounds: tensor([[ 3.1088,  3.7074,  0.0183,  1.0742, -1.3610,  1.5561,  1.2989,  3.4470,
          2.8562]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-1.3610, device='cuda:0', grad_fn=<MinBackward1>)
Sorted order for labels to verify: [4, 2, 3, 5, 7, 0, 8, 9, 1, 6]
##### [0:7] Tested against 4 ######
Model prediction is: tensor([[-36.2892, -37.4126, -32.6881, -32.7412, -30.5074, -33.8176, -28.7117,
         -34.6503, -36.7331, -37.1748]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 16, 16]) != torch.Size([2, 9, 1, 16, 16, 16]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 8, 8]) != torch.Size([2, 9, 1, 32, 8, 8]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 16, 16])
1 /11 torch.Size([1, 32, 8, 8])
2 /21 torch.Size([1, 100])
best_l after optimization: 1.3606626987457275 with beta sum per layer: []
alpha/beta optimization time: 2.019484758377075
alpha-CROWN with fixed intermediate bounds: tensor([[-1.3607]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-1.3606626987457275
layer 0 size torch.Size([4096]) unstable 685
layer 1 size torch.Size([2048]) unstable 367
layer 2 size torch.Size([100]) unstable 49
-----------------
# of unstable neurons: 1101
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 16, 16]) pre split depth:  8
batch:  torch.Size([1, 16, 16, 16]) post split depth:  8
splitting decisions: 
split level 0: [2, 88] 
split level 1: [2, 38] 
split level 2: [2, 58] 
split level 3: [2, 8] 
split level 4: [2, 49] 
split level 5: [2, 40] 
split level 6: [2, 95] 
split level 7: [2, 62] 
regular batch size: 2*128, diving batch size 1*0
best_l after optimization: -79.963623046875 with beta sum per layer: [0.0, 0.0, 2.404017925262451]
alpha/beta optimization time: 0.28551721572875977
This batch time : update_bounds func: 0.3315	 prepare: 0.0182	 bound: 0.2858	 transfer: 0.0111	 finalize: 0.0157
Accumulated time: update_bounds func: 0.3315	 prepare: 0.0182	 bound: 0.2858	 transfer: 0.0111	 finalize: 0.0157
batch bounding time:  0.33194756507873535
Current worst splitting domains [lb, ub] (depth):
[-0.32228,   inf] (9), [-0.32226,   inf] (9), [-0.31334,   inf] (9), [-0.30903,   inf] (9), [-0.30653,   inf] (9), [-0.30418,   inf] (9), [-0.29966,   inf] (9), [-0.29130,   inf] (9), [-0.22343,   inf] (9), [-0.22145,   inf] (9), [-0.21266,   inf] (9), [-0.20923,   inf] (9), [-0.20834,   inf] (9), [-0.20709,   inf] (9), [-0.20047,   inf] (9), [-0.19969,   inf] (9), [-0.15114,   inf] (9), [-0.14373,   inf] (9), [-0.13555,   inf] (9), [-0.13302,   inf] (9), 
length of domains: 26
Total time: 0.6307	 pickout: 0.0009	 decision: 0.2647	 get_bound: 0.3638	 add_domain: 0.0013
Current lb:-0.3222765028476715
256 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.4867210388183594

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([26, 16, 16, 16]) pre split depth:  3
batch:  torch.Size([26, 16, 16, 16]) post split depth:  3
splitting decisions: 
split level 0: [2, 67] [2, 67] [2, 67] [2, 67] [2, 67] [2, 67] [2, 67] [2, 67] [2, 67] [2, 67] 
split level 1: [2, 29] [2, 29] [2, 29] [2, 29] [2, 29] [2, 29] [2, 29] [2, 29] [2, 29] [2, 29] 
split level 2: [2, 16] [2, 16] [2, 16] [2, 16] [2, 16] [2, 16] [2, 16] [2, 16] [2, 16] [2, 16] 
regular batch size: 2*104, diving batch size 1*0
best_l after optimization: -6.012368202209473 with beta sum per layer: [0.0, 0.0, 20.574724197387695]
alpha/beta optimization time: 0.26546692848205566
This batch time : update_bounds func: 0.3064	 prepare: 0.0180	 bound: 0.2658	 transfer: 0.0103	 finalize: 0.0118
Accumulated time: update_bounds func: 0.6379	 prepare: 0.0361	 bound: 0.5516	 transfer: 0.0103	 finalize: 0.0275
batch bounding time:  0.30670166015625
Current worst splitting domains [lb, ub] (depth):
[-0.21232,   inf] (13), [-0.20813,   inf] (13), [-0.20230,   inf] (13), [-0.19764,   inf] (13), [-0.19361,   inf] (13), [-0.19357,   inf] (13), [-0.18514,   inf] (13), [-0.17652,   inf] (13), [-0.16340,   inf] (13), [-0.15427,   inf] (13), [-0.15259,   inf] (13), [-0.15174,   inf] (13), [-0.14687,   inf] (13), [-0.14586,   inf] (13), [-0.14345,   inf] (13), [-0.14157,   inf] (13), [-0.12247,   inf] (13), [-0.10945,   inf] (13), [-0.10798,   inf] (13), [-0.10750,   inf] (13), 
length of domains: 64
Total time: 0.3715	 pickout: 0.0045	 decision: 0.0361	 get_bound: 0.3273	 add_domain: 0.0035
Current lb:-0.21232472360134125
464 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.8593454360961914

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 16, 16, 16]) pre split depth:  2
batch:  torch.Size([64, 16, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [2, 82] [2, 82] [2, 82] [2, 82] [2, 82] [2, 82] [2, 82] [2, 82] [2, 82] [2, 82] 
split level 1: [2, 19] [2, 19] [2, 19] [2, 19] [2, 19] [2, 19] [2, 19] [2, 19] [2, 19] [2, 19] 
regular batch size: 2*128, diving batch size 1*0
best_l after optimization: -9.268123626708984 with beta sum per layer: [0.0, 0.0, 22.150856018066406]
alpha/beta optimization time: 0.278475284576416
This batch time : update_bounds func: 0.3340	 prepare: 0.0240	 bound: 0.2788	 transfer: 0.0157	 finalize: 0.0149
Accumulated time: update_bounds func: 0.9720	 prepare: 0.0601	 bound: 0.8304	 transfer: 0.0157	 finalize: 0.0424
batch bounding time:  0.3343689441680908
Current worst splitting domains [lb, ub] (depth):
[-0.15061,   inf] (16), [-0.14501,   inf] (16), [-0.14399,   inf] (16), [-0.14289,   inf] (16), [-0.14004,   inf] (16), [-0.13721,   inf] (16), [-0.13483,   inf] (16), [-0.13263,   inf] (16), [-0.12999,   inf] (16), [-0.12895,   inf] (16), [-0.12812,   inf] (16), [-0.12465,   inf] (16), [-0.12272,   inf] (16), [-0.11857,   inf] (16), [-0.11339,   inf] (16), [-0.11109,   inf] (16), [-0.10103,   inf] (16), [-0.09326,   inf] (16), [-0.09248,   inf] (16), [-0.09116,   inf] (16), 
length of domains: 74
Total time: 0.4140	 pickout: 0.0098	 decision: 0.0474	 get_bound: 0.3524	 add_domain: 0.0044
Current lb:-0.15060722827911377
720 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.274988174438477

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([74, 16, 16, 16]) pre split depth:  2
batch:  torch.Size([74, 16, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [2, 94] [2, 94] [2, 94] [2, 94] [2, 94] [2, 94] [2, 94] [2, 94] [2, 94] [2, 94] 
split level 1: [1, 1491] [2, 60] [1, 1491] [2, 60] [1, 1491] [1, 1491] [1, 1491] [1, 1491] [2, 60] [2, 60] 
regular batch size: 2*148, diving batch size 1*0
best_l after optimization: -11.571910858154297 with beta sum per layer: [0.0, 0.0, 19.14663314819336]
alpha/beta optimization time: 0.2991452217102051
This batch time : update_bounds func: 0.3610	 prepare: 0.0262	 bound: 0.2995	 transfer: 0.0171	 finalize: 0.0175
Accumulated time: update_bounds func: 1.3330	 prepare: 0.0863	 bound: 1.1299	 transfer: 0.0171	 finalize: 0.0599
batch bounding time:  0.36142873764038086
Current worst splitting domains [lb, ub] (depth):
[-0.10454,   inf] (19), [-0.10443,   inf] (19), [-0.10365,   inf] (19), [-0.10182,   inf] (19), [-0.09878,   inf] (19), [-0.09697,   inf] (19), [-0.09419,   inf] (19), [-0.09288,   inf] (19), [-0.09074,   inf] (19), [-0.09050,   inf] (19), [-0.08803,   inf] (19), [-0.08796,   inf] (19), [-0.08752,   inf] (19), [-0.08696,   inf] (19), [-0.08572,   inf] (19), [-0.08507,   inf] (19), [-0.08233,   inf] (19), [-0.08199,   inf] (19), [-0.08102,   inf] (19), [-0.08022,   inf] (19), 
length of domains: 56
Total time: 0.4430	 pickout: 0.0114	 decision: 0.0454	 get_bound: 0.3825	 add_domain: 0.0037
Current lb:-0.10453764349222183
1016 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.720014810562134

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([56, 16, 16, 16]) pre split depth:  2
batch:  torch.Size([56, 16, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [2, 60] [2, 15] [2, 60] [2, 15] [2, 60] [2, 60] [2, 60] [2, 60] [2, 60] [2, 60] 
split level 1: [2, 22] [2, 22] [2, 22] [2, 22] [2, 15] [2, 15] [2, 15] [2, 15] [2, 15] [2, 22] 
regular batch size: 2*112, diving batch size 1*0
best_l after optimization: -10.57398796081543 with beta sum per layer: [0.0, 0.05874056741595268, 13.93781852722168]
alpha/beta optimization time: 0.27222657203674316
This batch time : update_bounds func: 0.3118	 prepare: 0.0212	 bound: 0.2725	 transfer: 0.0042	 finalize: 0.0132
Accumulated time: update_bounds func: 1.6447	 prepare: 0.1075	 bound: 1.4024	 transfer: 0.0042	 finalize: 0.0732
batch bounding time:  0.3121023178100586
Current worst splitting domains [lb, ub] (depth):
[-0.07340,   inf] (22), [-0.07288,   inf] (22), [-0.07234,   inf] (22), [-0.07022,   inf] (22), [-0.06188,   inf] (22), [-0.06032,   inf] (22), [-0.05927,   inf] (22), [-0.05876,   inf] (22), [-0.05700,   inf] (22), [-0.05530,   inf] (22), [-0.05529,   inf] (22), [-0.05355,   inf] (22), [-0.05244,   inf] (22), [-0.05176,   inf] (22), [-0.05143,   inf] (22), [-0.05134,   inf] (22), [-0.05045,   inf] (22), [-0.04873,   inf] (22), [-0.04740,   inf] (22), [-0.04675,   inf] (22), 
length of domains: 44
Total time: 0.3793	 pickout: 0.0091	 decision: 0.0388	 get_bound: 0.3283	 add_domain: 0.0031
Current lb:-0.07340114563703537
1240 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.101096153259277

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([44, 16, 16, 16]) pre split depth:  3
batch:  torch.Size([44, 16, 16, 16]) post split depth:  3
splitting decisions: 
split level 0: [1, 1491] [2, 15] [2, 15] [1, 1491] [2, 46] [2, 46] [2, 15] [2, 46] [2, 46] [2, 46] 
split level 1: [2, 46] [2, 46] [2, 46] [2, 46] [2, 22] [2, 22] [2, 46] [2, 22] [2, 22] [2, 22] 
split level 2: [1, 979] [1, 979] [1, 979] [1, 979] [1, 979] [1, 979] [1, 979] [1, 979] [1, 979] [1, 979] 
regular batch size: 2*176, diving batch size 1*0
best_l after optimization: -30.59966278076172 with beta sum per layer: [0.0, 0.0, 7.893601894378662]
alpha/beta optimization time: 0.31215858459472656
This batch time : update_bounds func: 0.3745	 prepare: 0.0325	 bound: 0.3125	 transfer: 0.0076	 finalize: 0.0207
Accumulated time: update_bounds func: 2.0192	 prepare: 0.1400	 bound: 1.7149	 transfer: 0.0076	 finalize: 0.0938
batch bounding time:  0.3748760223388672
Current worst splitting domains [lb, ub] (depth):
[-0.03149,   inf] (26), [-0.03142,   inf] (26), [-0.02992,   inf] (26), [-0.02969,   inf] (26), [-0.02660,   inf] (26), [-0.02621,   inf] (26), [-0.02503,   inf] (26), [-0.02389,   inf] (26), [-0.02249,   inf] (26), [-0.02079,   inf] (26), [-0.01928,   inf] (26), [-0.01888,   inf] (26), [-0.01611,   inf] (26), [-0.01488,   inf] (26), [-0.01394,   inf] (26), [-0.01244,   inf] (26), [-0.01124,   inf] (26), [-0.00964,   inf] (26), [-0.00921,   inf] (26), [-0.00848,   inf] (26), 
length of domains: 32
Total time: 0.4604	 pickout: 0.0073	 decision: 0.0381	 get_bound: 0.4124	 add_domain: 0.0027
Current lb:-0.03149045258760452
1592 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.5636279582977295

remaining dive domains: 0/-1, dive_rate:0.0/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:462: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(preprocess_cifar(eps_temp, perturbation=True)).reshape(1,-1,1,1)

batch:  torch.Size([32, 16, 16, 16]) pre split depth:  3
batch:  torch.Size([32, 16, 16, 16]) post split depth:  3
splitting decisions: 
split level 0: [2, 35] [2, 35] [1, 1701] [1, 1701] [1, 1701] [1, 1701] [2, 35] [2, 35] [1, 1130] [1, 1701] 
split level 1: [2, 31] [2, 31] [1, 1109] [1, 1109] [1, 1109] [1, 1109] [2, 31] [2, 31] [2, 35] [2, 35] 
split level 2: [1, 1492] [1, 1492] [2, 35] [2, 35] [2, 35] [2, 35] [1, 1492] [1, 1492] [1, 1123] [1, 1492] 
regular batch size: 2*128, diving batch size 1*0

all verified at 19th iter
best_l after optimization: -13.902111053466797 with beta sum per layer: [0.0, 0.0, 0.9444845914840698]
alpha/beta optimization time: 0.2775712013244629
This batch time : update_bounds func: 0.3243	 prepare: 0.0246	 bound: 0.2779	 transfer: 0.0063	 finalize: 0.0148
Accumulated time: update_bounds func: 2.3435	 prepare: 0.1647	 bound: 1.9927	 transfer: 0.0063	 finalize: 0.1087
batch bounding time:  0.32466650009155273
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.3914	 pickout: 0.0056	 decision: 0.0328	 get_bound: 0.3529	 add_domain: 0.0001
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 5.956729888916016

Image 7 label 4 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 6.052744150161743
7 1.0000000116860974e-07
##### [0:7] Tested against 2 ######
Initial alpha-CROWN verified for label 2 with bound 0.018308822065591812
Image 7 label 2 verification end, final lower bound 0.018308822065591812, upper bound inf, time: 0.0003960132598876953
7 0.018308822065591812
##### [0:7] Tested against 3 ######
Initial alpha-CROWN verified for label 3 with bound 1.074182391166687
Image 7 label 3 verification end, final lower bound 1.074182391166687, upper bound inf, time: 0.00039577484130859375
7 1.074182391166687
##### [0:7] Tested against 5 ######
Initial alpha-CROWN verified for label 5 with bound 1.5561282634735107
Image 7 label 5 verification end, final lower bound 1.5561282634735107, upper bound inf, time: 0.0003955364227294922
7 1.5561282634735107
##### [0:7] Tested against 7 ######
Initial alpha-CROWN verified for label 7 with bound 1.2988699674606323
Image 7 label 7 verification end, final lower bound 1.2988699674606323, upper bound inf, time: 0.00039196014404296875
7 1.2988699674606323
##### [0:7] Tested against 0 ######
Initial alpha-CROWN verified for label 0 with bound 3.1088480949401855
Image 7 label 0 verification end, final lower bound 3.1088480949401855, upper bound inf, time: 0.0003876686096191406
7 3.1088480949401855
##### [0:7] Tested against 8 ######
Initial alpha-CROWN verified for label 8 with bound 3.4470467567443848
Image 7 label 8 verification end, final lower bound 3.4470467567443848, upper bound inf, time: 0.00038695335388183594
7 3.4470467567443848
##### [0:7] Tested against 9 ######
Initial alpha-CROWN verified for label 9 with bound 2.8561930656433105
Image 7 label 9 verification end, final lower bound 2.8561930656433105, upper bound inf, time: 0.0003788471221923828
7 2.8561930656433105
##### [0:7] Tested against 1 ######
Initial alpha-CROWN verified for label 1 with bound 3.7074379920959473
Image 7 label 1 verification end, final lower bound 3.7074379920959473, upper bound inf, time: 0.0005090236663818359
7 3.7074379920959473
##### [0:7] Tested against 6 ######
groundtruth label, skip!
Result: image 7 verification success (with branch and bound)!
Wall time: 16.738691329956055

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 1): [7]
verification failure idx (total 0): []
final verified acc: 100.0%[1]
verifier is called on 1 examples.
total verified: 1
mean time [cnt:1] (excluding attack success): 15.48997688293457
