Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_cnn_a_mix.model
  name: cnn_4layer
data:
  start: 83
  end: 84
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR_SDP
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.00784313725
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 3072
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 600
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 20:56:03 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Flatten()
  (5): Linear(in_features=2048, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([200, 3, 32, 32]) torch.Size([200]) torch.Size([200])
X range: tensor(2.1256) tensor(-1.9889) tensor(-0.0131)
############################
epsilon after preprocessing: tensor([[[[0.0317]],

         [[0.0322]],

         [[0.0300]]]]), data_max = tensor([[[[2.0587]],

         [[2.1256]],

         [[2.1154]]]]), data_min = tensor([[[[-1.9889]],

         [[-1.9807]],

         [[-1.7076]]]])
Task length: 1
saving results to Verified_ret_[cnn_4layer]_start=83_end=84_iter=20_b=3072_timeout=600_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 83 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 9, correct label 9, image norm 2746.865234375, logits tensor([-38.4824, -38.8508, -42.3743, -40.6830, -40.7441, -41.2199, -42.7789,
        -41.9925, -38.1940, -35.9327], device='cuda:0',
       grad_fn=<SelectBackward>)
##### PGD attack: True label: 9, Tested against: ['all'] ######
pgd prediction: tensor([-38.7441, -39.3480, -42.8382, -40.9432, -41.0285, -41.6135, -42.9237,
        -42.7495, -37.6593, -37.0403], device='cuda:0',
       grad_fn=<SqueezeBackward1>)
attack margin tensor([1.7037, 2.3076, 5.7979, 3.9029, 3.9882, 4.5732, 5.8834, 5.7092, 0.6190,
           inf], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[-38.4824, -38.8508, -42.3743, -40.6830, -40.7441, -41.2199, -42.7789,
         -41.9925, -38.1940, -35.9327]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-1.4251, -0.5160,  0.8424, -0.0316, -0.4201,  0.2164,  1.8195,  0.3640,
         -2.5534]], device='cuda:0') None
best_l after optimization: -2.7711403369903564 with beta sum per layer: []
alpha/beta optimization time: 7.686420917510986
initial alpha-CROWN bounds: tensor([[-1.0460, -0.3401,  1.5542,  0.5261,  0.1958,  0.7987,  2.2699,  0.9294,
         -2.1167]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-2.1167, device='cuda:0', grad_fn=<MinBackward1>)
Sorted order for labels to verify: [8, 0, 1, 3, 4, 5, 7, 2, 6, 9]
##### [0:83] Tested against 8 ######
Model prediction is: tensor([[-38.4824, -38.8508, -42.3743, -40.6830, -40.7441, -41.2199, -42.7789,
         -41.9925, -38.1940, -35.9327]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 16, 16]) != torch.Size([2, 9, 1, 16, 16, 16]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 8, 8]) != torch.Size([2, 9, 1, 32, 8, 8]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 16, 16])
1 /11 torch.Size([1, 32, 8, 8])
2 /21 torch.Size([1, 100])
best_l after optimization: 2.1163673400878906 with beta sum per layer: []
alpha/beta optimization time: 2.0632309913635254
alpha-CROWN with fixed intermediate bounds: tensor([[-2.1164]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-2.1163673400878906
layer 0 size torch.Size([4096]) unstable 773
layer 1 size torch.Size([2048]) unstable 328
layer 2 size torch.Size([100]) unstable 49
-----------------
# of unstable neurons: 1150
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 16, 16]) pre split depth:  8
batch:  torch.Size([1, 16, 16, 16]) post split depth:  8
splitting decisions: 
split level 0: [2, 47] 
split level 1: [2, 0] 
split level 2: [2, 8] 
split level 3: [2, 7] 
split level 4: [2, 78] 
split level 5: [2, 75] 
split level 6: [2, 31] 
split level 7: [2, 16] 
regular batch size: 2*128, diving batch size 1*0
best_l after optimization: -30.397611618041992 with beta sum per layer: [0.0, 0.0, 35.015323638916016]
alpha/beta optimization time: 0.2957425117492676
This batch time : update_bounds func: 0.3445	 prepare: 0.0185	 bound: 0.2961	 transfer: 0.0136	 finalize: 0.0156
Accumulated time: update_bounds func: 0.3445	 prepare: 0.0185	 bound: 0.2961	 transfer: 0.0136	 finalize: 0.0156
batch bounding time:  0.34491634368896484
Current worst splitting domains [lb, ub] (depth):
[-0.70601,   inf] (9), [-0.69105,   inf] (9), [-0.68143,   inf] (9), [-0.67043,   inf] (9), [-0.66750,   inf] (9), [-0.64272,   inf] (9), [-0.62828,   inf] (9), [-0.62769,   inf] (9), [-0.61371,   inf] (9), [-0.60714,   inf] (9), [-0.59380,   inf] (9), [-0.59330,   inf] (9), [-0.57794,   inf] (9), [-0.56270,   inf] (9), [-0.55933,   inf] (9), [-0.52863,   inf] (9), [-0.41906,   inf] (9), [-0.40852,   inf] (9), [-0.37833,   inf] (9), [-0.37771,   inf] (9), 
length of domains: 56
Total time: 0.6495	 pickout: 0.0009	 decision: 0.2688	 get_bound: 0.3771	 add_domain: 0.0026
Current lb:-0.7060109972953796
256 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.584552049636841

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([56, 16, 16, 16]) pre split depth:  2
batch:  torch.Size([56, 16, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [2, 40] [2, 40] [2, 40] [2, 40] [2, 40] [2, 40] [2, 40] [2, 40] [2, 40] [2, 40] 
split level 1: [2, 24] [2, 24] [2, 24] [2, 24] [2, 24] [2, 24] [2, 24] [2, 24] [2, 24] [2, 24] 
regular batch size: 2*112, diving batch size 1*0
best_l after optimization: 23.863346099853516 with beta sum per layer: [0.0, 0.0, 39.450904846191406]
alpha/beta optimization time: 0.2693636417388916
This batch time : update_bounds func: 0.3196	 prepare: 0.0196	 bound: 0.2697	 transfer: 0.0124	 finalize: 0.0174
Accumulated time: update_bounds func: 0.6641	 prepare: 0.0382	 bound: 0.5658	 transfer: 0.0124	 finalize: 0.0330
batch bounding time:  0.32000088691711426
Current worst splitting domains [lb, ub] (depth):
[-0.55787,   inf] (12), [-0.54939,   inf] (12), [-0.53636,   inf] (12), [-0.53552,   inf] (12), [-0.53378,   inf] (12), [-0.52659,   inf] (12), [-0.51809,   inf] (12), [-0.51789,   inf] (12), [-0.51717,   inf] (12), [-0.51611,   inf] (12), [-0.49703,   inf] (12), [-0.49610,   inf] (12), [-0.47984,   inf] (12), [-0.47933,   inf] (12), [-0.47126,   inf] (12), [-0.46793,   inf] (12), [-0.46009,   inf] (12), [-0.45826,   inf] (12), [-0.45671,   inf] (12), [-0.45025,   inf] (12), 
length of domains: 131
Total time: 0.4003	 pickout: 0.0093	 decision: 0.0485	 get_bound: 0.3353	 add_domain: 0.0073
Current lb:-0.5578699707984924
480 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.9864652156829834

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([131, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([131, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 70] [2, 70] [2, 70] [2, 70] [2, 70] [2, 70] [2, 70] [2, 70] [2, 70] [2, 70] 
regular batch size: 2*131, diving batch size 1*0
best_l after optimization: 42.68474197387695 with beta sum per layer: [0.0, 0.0, 37.81233215332031]
alpha/beta optimization time: 0.2944462299346924
This batch time : update_bounds func: 0.3638	 prepare: 0.0372	 bound: 0.2948	 transfer: 0.0151	 finalize: 0.0160
Accumulated time: update_bounds func: 1.0279	 prepare: 0.0754	 bound: 0.8606	 transfer: 0.0151	 finalize: 0.0490
batch bounding time:  0.3641796112060547
Current worst splitting domains [lb, ub] (depth):
[-0.50372,   inf] (14), [-0.49551,   inf] (14), [-0.48350,   inf] (14), [-0.47956,   inf] (14), [-0.47750,   inf] (14), [-0.47414,   inf] (14), [-0.47359,   inf] (14), [-0.46621,   inf] (14), [-0.46314,   inf] (14), [-0.46229,   inf] (14), [-0.46162,   inf] (14), [-0.46000,   inf] (14), [-0.45372,   inf] (14), [-0.45169,   inf] (14), [-0.44849,   inf] (14), [-0.44261,   inf] (14), [-0.44096,   inf] (14), [-0.43872,   inf] (14), [-0.43667,   inf] (14), [-0.43457,   inf] (14), 
length of domains: 205
Total time: 0.4699	 pickout: 0.0274	 decision: 0.0671	 get_bound: 0.3646	 add_domain: 0.0109
Current lb:-0.5037153959274292
742 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.459080696105957

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([205, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([205, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 46] [2, 46] [2, 46] [2, 46] [2, 46] [2, 46] [2, 46] [2, 46] [2, 46] [2, 46] 
regular batch size: 2*205, diving batch size 1*0
best_l after optimization: 64.44769287109375 with beta sum per layer: [0.0, 0.0, 61.33557891845703]
alpha/beta optimization time: 0.341141939163208
This batch time : update_bounds func: 0.4199	 prepare: 0.0359	 bound: 0.3415	 transfer: 0.0173	 finalize: 0.0243
Accumulated time: update_bounds func: 1.4477	 prepare: 0.1113	 bound: 1.2021	 transfer: 0.0173	 finalize: 0.0732
batch bounding time:  0.4203817844390869
Current worst splitting domains [lb, ub] (depth):
[-0.46335,   inf] (16), [-0.45527,   inf] (16), [-0.44370,   inf] (16), [-0.43793,   inf] (16), [-0.43587,   inf] (16), [-0.43487,   inf] (16), [-0.43159,   inf] (16), [-0.42427,   inf] (16), [-0.42307,   inf] (16), [-0.42245,   inf] (16), [-0.42233,   inf] (16), [-0.42026,   inf] (16), [-0.41915,   inf] (16), [-0.41162,   inf] (16), [-0.41117,   inf] (16), [-0.40946,   inf] (16), [-0.40638,   inf] (16), [-0.40296,   inf] (16), [-0.40195,   inf] (16), [-0.39764,   inf] (16), 
length of domains: 333
Total time: 0.5574	 pickout: 0.0324	 decision: 0.0849	 get_bound: 0.4210	 add_domain: 0.0191
Current lb:-0.4633544981479645
1152 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.020593166351318

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([333, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([333, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 30] [2, 30] [2, 30] [2, 30] [2, 30] [2, 30] [2, 30] [2, 30] [2, 30] [2, 30] 
regular batch size: 2*333, diving batch size 1*0
best_l after optimization: 38.087257385253906 with beta sum per layer: [0.0, 0.0, 142.2512664794922]
alpha/beta optimization time: 0.44146132469177246
This batch time : update_bounds func: 0.5613	 prepare: 0.0566	 bound: 0.4418	 transfer: 0.0221	 finalize: 0.0393
Accumulated time: update_bounds func: 2.0091	 prepare: 0.1679	 bound: 1.6439	 transfer: 0.0221	 finalize: 0.1125
batch bounding time:  0.56203293800354
Current worst splitting domains [lb, ub] (depth):
[-0.42367,   inf] (18), [-0.41568,   inf] (18), [-0.40483,   inf] (18), [-0.39977,   inf] (18), [-0.39760,   inf] (18), [-0.39574,   inf] (18), [-0.39268,   inf] (18), [-0.38544,   inf] (18), [-0.38457,   inf] (18), [-0.38303,   inf] (18), [-0.38295,   inf] (18), [-0.38221,   inf] (18), [-0.38085,   inf] (18), [-0.37322,   inf] (18), [-0.37251,   inf] (18), [-0.37072,   inf] (18), [-0.36845,   inf] (18), [-0.36388,   inf] (18), [-0.36278,   inf] (18), [-0.35972,   inf] (18), 
length of domains: 367
Total time: 0.8133	 pickout: 0.0504	 decision: 0.1773	 get_bound: 0.5630	 add_domain: 0.0226
Current lb:-0.4236694872379303
1818 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.841257333755493

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([367, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([367, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 2] [2, 10] [2, 2] [2, 10] [2, 10] [2, 10] [2, 2] [2, 10] [2, 2] [2, 10] 
regular batch size: 2*367, diving batch size 1*0
best_l after optimization: -9.610733032226562 with beta sum per layer: [0.0, 0.0, 168.1759033203125]
alpha/beta optimization time: 0.46672654151916504
This batch time : update_bounds func: 0.5995	 prepare: 0.0632	 bound: 0.4671	 transfer: 0.0221	 finalize: 0.0451
Accumulated time: update_bounds func: 2.6085	 prepare: 0.2311	 bound: 2.1109	 transfer: 0.0221	 finalize: 0.1576
batch bounding time:  0.6002204418182373
Current worst splitting domains [lb, ub] (depth):
[-0.39694,   inf] (20), [-0.38890,   inf] (20), [-0.37860,   inf] (20), [-0.37274,   inf] (20), [-0.37003,   inf] (20), [-0.36922,   inf] (20), [-0.36722,   inf] (20), [-0.35970,   inf] (20), [-0.35933,   inf] (20), [-0.35689,   inf] (20), [-0.35583,   inf] (20), [-0.35535,   inf] (20), [-0.35313,   inf] (20), [-0.34691,   inf] (20), [-0.34623,   inf] (20), [-0.34452,   inf] (20), [-0.34397,   inf] (20), [-0.33790,   inf] (20), [-0.33643,   inf] (20), [-0.33450,   inf] (20), 
length of domains: 334
Total time: 0.8062	 pickout: 0.0566	 decision: 0.1276	 get_bound: 0.6013	 add_domain: 0.0207
Current lb:-0.396939754486084
2552 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.655624866485596

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([334, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([334, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 10] [2, 2] [2, 10] [2, 2] [2, 2] [2, 2] [2, 10] [2, 2] [2, 10] [2, 2] 
regular batch size: 2*334, diving batch size 1*0
best_l after optimization: -5.177926063537598 with beta sum per layer: [0.0, 0.0, 148.2197265625]
alpha/beta optimization time: 0.4333689212799072
This batch time : update_bounds func: 0.5429	 prepare: 0.0577	 bound: 0.4337	 transfer: 0.0108	 finalize: 0.0390
Accumulated time: update_bounds func: 3.1514	 prepare: 0.2888	 bound: 2.5446	 transfer: 0.0108	 finalize: 0.1966
batch bounding time:  0.5441601276397705
Current worst splitting domains [lb, ub] (depth):
[-0.37107,   inf] (22), [-0.36267,   inf] (22), [-0.35319,   inf] (22), [-0.34708,   inf] (22), [-0.34492,   inf] (22), [-0.34384,   inf] (22), [-0.34220,   inf] (22), [-0.33503,   inf] (22), [-0.33475,   inf] (22), [-0.33110,   inf] (22), [-0.33051,   inf] (22), [-0.33040,   inf] (22), [-0.32827,   inf] (22), [-0.32215,   inf] (22), [-0.32066,   inf] (22), [-0.31952,   inf] (22), [-0.31870,   inf] (22), [-0.31274,   inf] (22), [-0.31116,   inf] (22), [-0.31051,   inf] (22), 
length of domains: 284
Total time: 0.8037	 pickout: 0.0493	 decision: 0.1898	 get_bound: 0.5452	 add_domain: 0.0194
Current lb:-0.3710712492465973
3220 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.46740984916687

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([284, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([284, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 48] [2, 48] [2, 48] [2, 48] [2, 48] [2, 48] [2, 48] [2, 48] [2, 48] [2, 48] 
regular batch size: 2*284, diving batch size 1*0
best_l after optimization: -7.214930057525635 with beta sum per layer: [0.0, 0.0, 122.91700744628906]
alpha/beta optimization time: 0.4017918109893799
This batch time : update_bounds func: 0.4928	 prepare: 0.0501	 bound: 0.4021	 transfer: 0.0059	 finalize: 0.0335
Accumulated time: update_bounds func: 3.6442	 prepare: 0.3389	 bound: 2.9467	 transfer: 0.0059	 finalize: 0.2301
batch bounding time:  0.4934723377227783
Current worst splitting domains [lb, ub] (depth):
[-0.34719,   inf] (24), [-0.33890,   inf] (24), [-0.32903,   inf] (24), [-0.32288,   inf] (24), [-0.32031,   inf] (24), [-0.31983,   inf] (24), [-0.31805,   inf] (24), [-0.31115,   inf] (24), [-0.31047,   inf] (24), [-0.30648,   inf] (24), [-0.30590,   inf] (24), [-0.30553,   inf] (24), [-0.30409,   inf] (24), [-0.29843,   inf] (24), [-0.29618,   inf] (24), [-0.29487,   inf] (24), [-0.29438,   inf] (24), [-0.28788,   inf] (24), [-0.28650,   inf] (24), [-0.28602,   inf] (24), 
length of domains: 256
Total time: 0.6582	 pickout: 0.0448	 decision: 0.1023	 get_bound: 0.4944	 add_domain: 0.0166
Current lb:-0.34718939661979675
3788 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.134066820144653

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 56] [2, 56] [2, 56] [2, 56] [2, 56] [2, 56] [2, 56] [2, 56] [2, 56] [2, 56] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 44.90391540527344 with beta sum per layer: [0.0, 0.25780773162841797, 83.92717742919922]
alpha/beta optimization time: 0.3799254894256592
This batch time : update_bounds func: 0.5090	 prepare: 0.0455	 bound: 0.3803	 transfer: 0.0070	 finalize: 0.0307
Accumulated time: update_bounds func: 4.1533	 prepare: 0.3843	 bound: 3.3270	 transfer: 0.0070	 finalize: 0.2609
batch bounding time:  0.5095748901367188
Current worst splitting domains [lb, ub] (depth):
[-0.31975,   inf] (26), [-0.31135,   inf] (26), [-0.30057,   inf] (26), [-0.29536,   inf] (26), [-0.29289,   inf] (26), [-0.29133,   inf] (26), [-0.29012,   inf] (26), [-0.28435,   inf] (26), [-0.28245,   inf] (26), [-0.28027,   inf] (26), [-0.28025,   inf] (26), [-0.27923,   inf] (26), [-0.27823,   inf] (26), [-0.27599,   inf] (26), [-0.27492,   inf] (26), [-0.27161,   inf] (26), [-0.26924,   inf] (26), [-0.26869,   inf] (26), [-0.26696,   inf] (26), [-0.26660,   inf] (26), 
length of domains: 373
Total time: 0.6670	 pickout: 0.0400	 decision: 0.0903	 get_bound: 0.5104	 add_domain: 0.0263
Current lb:-0.3197464942932129
4300 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.80609917640686

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([373, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([373, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 57] [2, 57] [2, 57] [2, 57] [2, 57] [2, 57] [2, 57] [2, 57] [2, 57] [2, 57] 
regular batch size: 2*373, diving batch size 1*0
best_l after optimization: -32.3992919921875 with beta sum per layer: [0.0, 0.42480340600013733, 173.35177612304688]
alpha/beta optimization time: 0.473712682723999
This batch time : update_bounds func: 0.6008	 prepare: 0.0658	 bound: 0.4741	 transfer: 0.0150	 finalize: 0.0439
Accumulated time: update_bounds func: 4.7541	 prepare: 0.4501	 bound: 3.8011	 transfer: 0.0150	 finalize: 0.3048
batch bounding time:  0.601600170135498
Current worst splitting domains [lb, ub] (depth):
[-0.30032,   inf] (28), [-0.29169,   inf] (28), [-0.28154,   inf] (28), [-0.27576,   inf] (28), [-0.27312,   inf] (28), [-0.27195,   inf] (28), [-0.27034,   inf] (28), [-0.26553,   inf] (28), [-0.26284,   inf] (28), [-0.26126,   inf] (28), [-0.26016,   inf] (28), [-0.25994,   inf] (28), [-0.25896,   inf] (28), [-0.25630,   inf] (28), [-0.25507,   inf] (28), [-0.25281,   inf] (28), [-0.24929,   inf] (28), [-0.24842,   inf] (28), [-0.24749,   inf] (28), [-0.24697,   inf] (28), 
length of domains: 344
Total time: 0.8178	 pickout: 0.0570	 decision: 0.1335	 get_bound: 0.6027	 add_domain: 0.0247
Current lb:-0.30031800270080566
5046 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.63245153427124

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([344, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([344, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 61] [2, 61] [2, 61] [2, 61] [2, 61] [2, 61] [2, 61] [2, 61] [2, 61] [2, 61] 
regular batch size: 2*344, diving batch size 1*0
best_l after optimization: -27.732505798339844 with beta sum per layer: [0.0, 0.68937087059021, 132.31224060058594]
alpha/beta optimization time: 0.44595789909362793
This batch time : update_bounds func: 0.5734	 prepare: 0.0603	 bound: 0.4464	 transfer: 0.0240	 finalize: 0.0410
Accumulated time: update_bounds func: 5.3275	 prepare: 0.5104	 bound: 4.2475	 transfer: 0.0240	 finalize: 0.3457
batch bounding time:  0.5741453170776367
Current worst splitting domains [lb, ub] (depth):
[-0.28270,   inf] (30), [-0.27413,   inf] (30), [-0.26442,   inf] (30), [-0.25839,   inf] (30), [-0.25602,   inf] (30), [-0.25495,   inf] (30), [-0.25259,   inf] (30), [-0.24777,   inf] (30), [-0.24502,   inf] (30), [-0.24298,   inf] (30), [-0.24259,   inf] (30), [-0.24211,   inf] (30), [-0.24176,   inf] (30), [-0.23969,   inf] (30), [-0.23750,   inf] (30), [-0.23520,   inf] (30), [-0.23183,   inf] (30), [-0.23113,   inf] (30), [-0.23013,   inf] (30), [-0.22947,   inf] (30), 
length of domains: 344
Total time: 0.8117	 pickout: 0.0526	 decision: 0.1578	 get_bound: 0.5752	 add_domain: 0.0260
Current lb:-0.2826961278915405
5734 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.452376127243042

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([344, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([344, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 9] [2, 9] [2, 9] [2, 9] [2, 9] [2, 9] [2, 9] [2, 9] [2, 9] [2, 9] 
regular batch size: 2*344, diving batch size 1*0
best_l after optimization: -11.965198516845703 with beta sum per layer: [0.0, 2.376274585723877, 99.82510375976562]
alpha/beta optimization time: 0.45581817626953125
This batch time : update_bounds func: 0.5879	 prepare: 0.0623	 bound: 0.4562	 transfer: 0.0089	 finalize: 0.0589
Accumulated time: update_bounds func: 5.9155	 prepare: 0.5727	 bound: 4.7036	 transfer: 0.0089	 finalize: 0.4046
batch bounding time:  0.5887393951416016
Current worst splitting domains [lb, ub] (depth):
[-0.26650,   inf] (32), [-0.25828,   inf] (32), [-0.24824,   inf] (32), [-0.24143,   inf] (32), [-0.23925,   inf] (32), [-0.23925,   inf] (32), [-0.23614,   inf] (32), [-0.23173,   inf] (32), [-0.22874,   inf] (32), [-0.22716,   inf] (32), [-0.22630,   inf] (32), [-0.22609,   inf] (32), [-0.22561,   inf] (32), [-0.22311,   inf] (32), [-0.22131,   inf] (32), [-0.21971,   inf] (32), [-0.21549,   inf] (32), [-0.21485,   inf] (32), [-0.21357,   inf] (32), [-0.21268,   inf] (32), 
length of domains: 349
Total time: 0.7909	 pickout: 0.0546	 decision: 0.1158	 get_bound: 0.5900	 add_domain: 0.0306
Current lb:-0.26649680733680725
6422 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.251304388046265

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([349, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([349, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 66] [2, 66] [2, 66] [1, 557] [1, 557] [2, 36] [2, 66] [2, 66] [2, 66] [2, 66] 
regular batch size: 2*349, diving batch size 1*0
best_l after optimization: -3.477726936340332 with beta sum per layer: [0.0, 13.932483673095703, 98.52595520019531]
alpha/beta optimization time: 0.4472320079803467
This batch time : update_bounds func: 0.5879	 prepare: 0.0652	 bound: 0.4476	 transfer: 0.0296	 finalize: 0.0438
Accumulated time: update_bounds func: 6.5033	 prepare: 0.6379	 bound: 5.1512	 transfer: 0.0296	 finalize: 0.4484
batch bounding time:  0.5886373519897461
Current worst splitting domains [lb, ub] (depth):
[-0.25145,   inf] (34), [-0.24304,   inf] (34), [-0.23350,   inf] (34), [-0.22436,   inf] (34), [-0.22078,   inf] (34), [-0.21994,   inf] (34), [-0.21702,   inf] (34), [-0.21646,   inf] (34), [-0.21637,   inf] (34), [-0.21383,   inf] (34), [-0.21330,   inf] (34), [-0.21187,   inf] (34), [-0.21171,   inf] (34), [-0.21085,   inf] (34), [-0.20647,   inf] (34), [-0.20503,   inf] (34), [-0.20132,   inf] (34), [-0.20009,   inf] (34), [-0.19911,   inf] (34), [-0.19887,   inf] (34), 
length of domains: 397
Total time: 0.8992	 pickout: 0.0861	 decision: 0.1882	 get_bound: 0.5897	 add_domain: 0.0352
Current lb:-0.2514471709728241
7120 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.160841941833496

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([397, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([397, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 36] [2, 36] [2, 36] [2, 66] [2, 36] [2, 25] [2, 36] [2, 25] [2, 25] [2, 25] 
regular batch size: 2*397, diving batch size 1*0
best_l after optimization: -30.657806396484375 with beta sum per layer: [0.0, 38.062049865722656, 130.32806396484375]
alpha/beta optimization time: 0.48685479164123535
This batch time : update_bounds func: 0.6502	 prepare: 0.0808	 bound: 0.4873	 transfer: 0.0295	 finalize: 0.0489
Accumulated time: update_bounds func: 7.1535	 prepare: 0.7187	 bound: 5.6385	 transfer: 0.0295	 finalize: 0.4973
batch bounding time:  0.6510410308837891
Current worst splitting domains [lb, ub] (depth):
[-0.23663,   inf] (36), [-0.22826,   inf] (36), [-0.21886,   inf] (36), [-0.20968,   inf] (36), [-0.20572,   inf] (36), [-0.20489,   inf] (36), [-0.20248,   inf] (36), [-0.20145,   inf] (36), [-0.20144,   inf] (36), [-0.19879,   inf] (36), [-0.19818,   inf] (36), [-0.19693,   inf] (36), [-0.19605,   inf] (36), [-0.19584,   inf] (36), [-0.19064,   inf] (36), [-0.19011,   inf] (36), [-0.18612,   inf] (36), [-0.18605,   inf] (36), [-0.18382,   inf] (36), [-0.18374,   inf] (36), 
length of domains: 423
Total time: 1.0187	 pickout: 0.0670	 decision: 0.1626	 get_bound: 0.6523	 add_domain: 0.1368
Current lb:-0.23663312196731567
7914 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.189096689224243

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([423, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([423, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 557] [1, 557] [1, 557] [1, 557] [2, 25] [2, 66] [2, 25] [2, 66] [2, 66] [2, 66] 
regular batch size: 2*423, diving batch size 1*0
best_l after optimization: -18.316360473632812 with beta sum per layer: [0.0, 60.638675689697266, 131.53981018066406]
alpha/beta optimization time: 0.5072956085205078
This batch time : update_bounds func: 0.6628	 prepare: 0.0809	 bound: 0.5076	 transfer: 0.0211	 finalize: 0.0512
Accumulated time: update_bounds func: 7.8163	 prepare: 0.7995	 bound: 6.1461	 transfer: 0.0211	 finalize: 0.5485
batch bounding time:  0.6636381149291992
Current worst splitting domains [lb, ub] (depth):
[-0.22050,   inf] (38), [-0.21805,   inf] (38), [-0.21156,   inf] (38), [-0.20927,   inf] (38), [-0.20034,   inf] (38), [-0.19890,   inf] (38), [-0.19102,   inf] (38), [-0.19018,   inf] (38), [-0.18915,   inf] (38), [-0.18895,   inf] (38), [-0.18814,   inf] (38), [-0.18556,   inf] (38), [-0.18550,   inf] (38), [-0.18336,   inf] (38), [-0.18286,   inf] (38), [-0.18206,   inf] (38), [-0.17829,   inf] (38), [-0.17800,   inf] (38), [-0.17665,   inf] (38), [-0.17656,   inf] (38), 
length of domains: 455
Total time: 0.9150	 pickout: 0.0708	 decision: 0.1411	 get_bound: 0.6649	 add_domain: 0.0381
Current lb:-0.22049982845783234
8760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.113285779953003

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([455, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([455, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 25] [2, 25] [2, 25] [2, 25] [2, 25] [2, 25] [1, 685] [2, 25] [2, 25] [2, 36] 
regular batch size: 2*455, diving batch size 1*0
best_l after optimization: 1.796283483505249 with beta sum per layer: [0.0, 130.1530303955078, 98.30908203125]
alpha/beta optimization time: 0.5336370468139648
This batch time : update_bounds func: 0.6971	 prepare: 0.0875	 bound: 0.5340	 transfer: 0.0186	 finalize: 0.0546
Accumulated time: update_bounds func: 8.5134	 prepare: 0.8870	 bound: 6.6801	 transfer: 0.0186	 finalize: 0.6031
batch bounding time:  0.6979901790618896
Current worst splitting domains [lb, ub] (depth):
[-0.20618,   inf] (40), [-0.20375,   inf] (40), [-0.19723,   inf] (40), [-0.19501,   inf] (40), [-0.18583,   inf] (40), [-0.18439,   inf] (40), [-0.17799,   inf] (40), [-0.17557,   inf] (40), [-0.17538,   inf] (40), [-0.17457,   inf] (40), [-0.17299,   inf] (40), [-0.17184,   inf] (40), [-0.17179,   inf] (40), [-0.17022,   inf] (40), [-0.16973,   inf] (40), [-0.16896,   inf] (40), [-0.16487,   inf] (40), [-0.16366,   inf] (40), [-0.16243,   inf] (40), [-0.16226,   inf] (40), 
length of domains: 588
Total time: 1.0320	 pickout: 0.0723	 decision: 0.2089	 get_bound: 0.6994	 add_domain: 0.0514
Current lb:-0.2061784863471985
9670 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.156436920166016

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([588, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([588, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 685] [1, 685] [1, 114] [1, 685] [1, 685] [1, 685] [1, 1076] [1, 684] [1, 685] [1, 685] 
regular batch size: 2*588, diving batch size 1*0
best_l after optimization: 21.294296264648438 with beta sum per layer: [0.0, 384.6561584472656, 112.88736724853516]
alpha/beta optimization time: 0.641395092010498
This batch time : update_bounds func: 0.8994	 prepare: 0.1139	 bound: 0.6418	 transfer: 0.0258	 finalize: 0.0690
Accumulated time: update_bounds func: 9.4128	 prepare: 1.0009	 bound: 7.3219	 transfer: 0.0258	 finalize: 0.6721
batch bounding time:  0.9004693031311035
Current worst splitting domains [lb, ub] (depth):
[-0.19486,   inf] (42), [-0.19218,   inf] (42), [-0.18510,   inf] (42), [-0.18314,   inf] (42), [-0.17491,   inf] (42), [-0.17345,   inf] (42), [-0.17136,   inf] (42), [-0.16780,   inf] (42), [-0.16285,   inf] (42), [-0.16187,   inf] (42), [-0.16172,   inf] (42), [-0.16130,   inf] (42), [-0.15932,   inf] (42), [-0.15895,   inf] (42), [-0.15721,   inf] (42), [-0.15715,   inf] (42), [-0.15422,   inf] (42), [-0.15410,   inf] (42), [-0.15119,   inf] (42), [-0.14966,   inf] (42), 
length of domains: 831
Total time: 1.2657	 pickout: 0.0943	 decision: 0.1924	 get_bound: 0.9036	 add_domain: 0.0753
Current lb:-0.19486036896705627
10846 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.435449361801147

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([831, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([831, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 114] [1, 114] [1, 685] [1, 114] [1, 685] [1, 684] [1, 684] [1, 753] [1, 685] [1, 1321] 
regular batch size: 2*831, diving batch size 1*0
best_l after optimization: 39.07390594482422 with beta sum per layer: [0.0, 838.6236572265625, 127.1781005859375]
alpha/beta optimization time: 0.8720476627349854
This batch time : update_bounds func: 1.2116	 prepare: 0.1748	 bound: 0.8725	 transfer: 0.0532	 finalize: 0.1060
Accumulated time: update_bounds func: 10.6244	 prepare: 1.1757	 bound: 8.1944	 transfer: 0.0532	 finalize: 0.7782
batch bounding time:  1.2136623859405518
Current worst splitting domains [lb, ub] (depth):
[-0.18402,   inf] (44), [-0.18142,   inf] (44), [-0.17297,   inf] (44), [-0.17106,   inf] (44), [-0.17079,   inf] (44), [-0.16812,   inf] (44), [-0.16260,   inf] (44), [-0.16085,   inf] (44), [-0.16084,   inf] (44), [-0.15844,   inf] (44), [-0.15768,   inf] (44), [-0.15099,   inf] (44), [-0.15017,   inf] (44), [-0.14890,   inf] (44), [-0.14831,   inf] (44), [-0.14820,   inf] (44), [-0.14717,   inf] (44), [-0.14549,   inf] (44), [-0.14499,   inf] (44), [-0.14351,   inf] (44), 
length of domains: 1163
Total time: 1.8365	 pickout: 0.1364	 decision: 0.3709	 get_bound: 1.2171	 add_domain: 0.1122
Current lb:-0.1840185970067978
12508 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.29273295402527

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1163, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1163, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1076] [1, 1076] [1, 753] [1, 753] [1, 1076] [1, 1076] [1, 753] [1, 114] [1, 753] [1, 114] 
regular batch size: 2*1163, diving batch size 1*0
best_l after optimization: 37.50848388671875 with beta sum per layer: [0.0, 1470.145751953125, 163.95233154296875]
alpha/beta optimization time: 1.1498260498046875
This batch time : update_bounds func: 1.6953	 prepare: 0.2468	 bound: 1.1504	 transfer: 0.0786	 finalize: 0.1454
Accumulated time: update_bounds func: 12.3197	 prepare: 1.4225	 bound: 9.3448	 transfer: 0.0786	 finalize: 0.9236
batch bounding time:  1.6984210014343262
Current worst splitting domains [lb, ub] (depth):
[-0.17443,   inf] (46), [-0.17207,   inf] (46), [-0.16241,   inf] (46), [-0.16065,   inf] (46), [-0.16050,   inf] (46), [-0.15825,   inf] (46), [-0.15189,   inf] (46), [-0.15057,   inf] (46), [-0.14998,   inf] (46), [-0.14836,   inf] (46), [-0.14681,   inf] (46), [-0.14341,   inf] (46), [-0.14237,   inf] (46), [-0.14144,   inf] (46), [-0.13927,   inf] (46), [-0.13869,   inf] (46), [-0.13697,   inf] (46), [-0.13669,   inf] (46), [-0.13646,   inf] (46), [-0.13632,   inf] (46), 
length of domains: 1609
Total time: 2.5586	 pickout: 0.2383	 decision: 0.4611	 get_bound: 1.7021	 add_domain: 0.1570
Current lb:-0.17443357408046722
14834 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 20.887687921524048

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1609, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1609, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 684] [1, 684] [1, 1076] [1, 684] [1, 1076] [1, 684] [1, 1076] [1, 1321] [1, 1076] [1, 1321] 
regular batch size: 2*1609, diving batch size 1*0
best_l after optimization: 71.8694076538086 with beta sum per layer: [0.2654830813407898, 2482.36865234375, 215.44476318359375]
alpha/beta optimization time: 1.5254790782928467
This batch time : update_bounds func: 2.3016	 prepare: 0.3449	 bound: 1.5260	 transfer: 0.1237	 finalize: 0.2977
Accumulated time: update_bounds func: 14.6212	 prepare: 1.7674	 bound: 10.8708	 transfer: 0.1237	 finalize: 1.2213
batch bounding time:  2.305241823196411
Current worst splitting domains [lb, ub] (depth):
[-0.16261,   inf] (48), [-0.15970,   inf] (48), [-0.15331,   inf] (48), [-0.15168,   inf] (48), [-0.14848,   inf] (48), [-0.14550,   inf] (48), [-0.14478,   inf] (48), [-0.14341,   inf] (48), [-0.14270,   inf] (48), [-0.14091,   inf] (48), [-0.13704,   inf] (48), [-0.13522,   inf] (48), [-0.13483,   inf] (48), [-0.13411,   inf] (48), [-0.13378,   inf] (48), [-0.13213,   inf] (48), [-0.13197,   inf] (48), [-0.13174,   inf] (48), [-0.13028,   inf] (48), [-0.12860,   inf] (48), 
length of domains: 2250
Total time: 3.5069	 pickout: 0.3085	 decision: 0.6591	 get_bound: 2.3110	 add_domain: 0.2284
Current lb:-0.16261421144008636
18052 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 24.430580615997314

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2250, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([2250, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 753] [1, 753] [1, 1321] [1, 1321] [1, 753] [1, 753] [1, 753] [1, 753] [1, 1321] [1, 1321] 
regular batch size: 2*2250, diving batch size 1*0
best_l after optimization: 99.5247573852539 with beta sum per layer: [3.2842280864715576, 4059.830078125, 270.2554931640625]
alpha/beta optimization time: 2.1290879249572754
This batch time : update_bounds func: 3.1026	 prepare: 0.4447	 bound: 2.1295	 transfer: 0.1689	 finalize: 0.3478
Accumulated time: update_bounds func: 17.7238	 prepare: 2.2121	 bound: 13.0004	 transfer: 0.1689	 finalize: 1.5691
batch bounding time:  3.1068315505981445
Current worst splitting domains [lb, ub] (depth):
[-0.15311,   inf] (50), [-0.15024,   inf] (50), [-0.13899,   inf] (50), [-0.13894,   inf] (50), [-0.13764,   inf] (50), [-0.13739,   inf] (50), [-0.13606,   inf] (50), [-0.13596,   inf] (50), [-0.13474,   inf] (50), [-0.13397,   inf] (50), [-0.13191,   inf] (50), [-0.13180,   inf] (50), [-0.12878,   inf] (50), [-0.12742,   inf] (50), [-0.12702,   inf] (50), [-0.12575,   inf] (50), [-0.12518,   inf] (50), [-0.12325,   inf] (50), [-0.12299,   inf] (50), [-0.12246,   inf] (50), 
length of domains: 3092
Total time: 4.7876	 pickout: 0.4123	 decision: 0.8417	 get_bound: 3.1150	 add_domain: 0.4186
Current lb:-0.1531141698360443
22552 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 29.26862668991089

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3072, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([3072, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1321] [1, 1321] [1, 684] [1, 1321] [1, 684] [1, 684] [1, 684] [1, 1321] [1, 1321] [1, 1321] 
regular batch size: 2*3072, diving batch size 1*0
best_l after optimization: 105.12336730957031 with beta sum per layer: [15.029190063476562, 6086.57421875, 346.8783874511719]
alpha/beta optimization time: 2.8402538299560547
This batch time : update_bounds func: 4.3128	 prepare: 0.6298	 bound: 2.8407	 transfer: 0.2379	 finalize: 0.4856
Accumulated time: update_bounds func: 22.0367	 prepare: 2.8418	 bound: 15.8411	 transfer: 0.2379	 finalize: 2.0547
batch bounding time:  4.319407939910889
Current worst splitting domains [lb, ub] (depth):
[-0.13951,   inf] (52), [-0.13849,   inf] (52), [-0.13670,   inf] (52), [-0.13568,   inf] (52), [-0.12711,   inf] (52), [-0.12576,   inf] (52), [-0.12552,   inf] (52), [-0.12507,   inf] (52), [-0.12450,   inf] (52), [-0.12369,   inf] (52), [-0.12262,   inf] (52), [-0.12162,   inf] (52), [-0.12097,   inf] (52), [-0.12023,   inf] (52), [-0.11920,   inf] (52), [-0.11899,   inf] (52), [-0.11806,   inf] (52), [-0.11788,   inf] (52), [-0.11685,   inf] (52), [-0.11680,   inf] (52), 
length of domains: 4024
Total time: 6.6202	 pickout: 0.5433	 decision: 1.1121	 get_bound: 4.3303	 add_domain: 0.6345
Current lb:-0.13950824737548828
28696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 35.971235036849976

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3072, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([3072, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 33] [2, 33] [2, 33] [2, 33] [1, 553] [1, 553] [2, 33] [1, 553] [2, 33] [1, 553] 
regular batch size: 2*3072, diving batch size 1*0
best_l after optimization: 82.61831665039062 with beta sum per layer: [27.898786544799805, 6231.48046875, 366.0781555175781]
alpha/beta optimization time: 2.850149393081665
This batch time : update_bounds func: 4.4239	 prepare: 0.6577	 bound: 2.8507	 transfer: 0.2458	 finalize: 0.6514
Accumulated time: update_bounds func: 26.4605	 prepare: 3.4995	 bound: 18.6918	 transfer: 0.2458	 finalize: 2.7061
batch bounding time:  4.430140495300293
Current worst splitting domains [lb, ub] (depth):
[-0.12944,   inf] (54), [-0.12833,   inf] (54), [-0.12660,   inf] (54), [-0.12555,   inf] (54), [-0.11534,   inf] (54), [-0.11431,   inf] (54), [-0.11416,   inf] (54), [-0.11247,   inf] (54), [-0.11214,   inf] (54), [-0.11208,   inf] (54), [-0.11157,   inf] (54), [-0.11145,   inf] (54), [-0.11103,   inf] (54), [-0.11069,   inf] (54), [-0.11020,   inf] (54), [-0.11006,   inf] (54), [-0.10958,   inf] (54), [-0.10911,   inf] (54), [-0.10909,   inf] (54), [-0.10856,   inf] (54), 
length of domains: 5551
Total time: 6.7125	 pickout: 0.5516	 decision: 1.2010	 get_bound: 4.4416	 add_domain: 0.5183
Current lb:-0.12943649291992188
34840 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 42.75308680534363

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3072, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([3072, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 113] [1, 113] [1, 113] [1, 113] [1, 113] [1, 113] [2, 33] [1, 113] [2, 33] [2, 33] 
regular batch size: 2*3072, diving batch size 1*0
best_l after optimization: 68.67794036865234 with beta sum per layer: [52.50416564941406, 5922.46044921875, 329.29669189453125]
alpha/beta optimization time: 2.842705726623535
This batch time : update_bounds func: 4.3121	 prepare: 0.6609	 bound: 2.8432	 transfer: 0.2408	 finalize: 0.5491
Accumulated time: update_bounds func: 30.7727	 prepare: 4.1604	 bound: 21.5350	 transfer: 0.2408	 finalize: 3.2551
batch bounding time:  4.318329095840454
Current worst splitting domains [lb, ub] (depth):
[-0.11949,   inf] (56), [-0.11822,   inf] (56), [-0.11672,   inf] (56), [-0.11543,   inf] (56), [-0.11435,   inf] (56), [-0.11255,   inf] (56), [-0.11144,   inf] (56), [-0.10969,   inf] (56), [-0.10405,   inf] (56), [-0.10278,   inf] (56), [-0.10209,   inf] (56), [-0.10207,   inf] (56), [-0.10167,   inf] (56), [-0.10166,   inf] (56), [-0.10153,   inf] (56), [-0.10102,   inf] (56), [-0.10068,   inf] (56), [-0.10018,   inf] (56), [-0.10018,   inf] (56), [-0.10009,   inf] (56), 
length of domains: 7186
Total time: 6.9311	 pickout: 0.5448	 decision: 1.3434	 get_bound: 4.3289	 add_domain: 0.7140
Current lb:-0.11949000507593155
40984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 49.7674024105072

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3072, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([3072, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 1959] [0, 1959] [0, 1959] [0, 1959] [0, 1959] [0, 1959] [0, 1959] [0, 1959] [0, 1959] [0, 1959] 
regular batch size: 2*3072, diving batch size 1*0
best_l after optimization: 89.66644287109375 with beta sum per layer: [131.84596252441406, 5473.36328125, 284.5732727050781]
alpha/beta optimization time: 2.8394570350646973
This batch time : update_bounds func: 4.3537	 prepare: 0.6630	 bound: 2.8400	 transfer: 0.2416	 finalize: 0.5925
Accumulated time: update_bounds func: 35.1263	 prepare: 4.8234	 bound: 24.3750	 transfer: 0.2416	 finalize: 3.8476
batch bounding time:  4.359740734100342
Current worst splitting domains [lb, ub] (depth):
[-0.10876,   inf] (58), [-0.10758,   inf] (58), [-0.10597,   inf] (58), [-0.10481,   inf] (58), [-0.10405,   inf] (58), [-0.10371,   inf] (58), [-0.10289,   inf] (58), [-0.10189,   inf] (58), [-0.10121,   inf] (58), [-0.10080,   inf] (58), [-0.10009,   inf] (58), [-0.09901,   inf] (58), [-0.09899,   inf] (58), [-0.09714,   inf] (58), [-0.09606,   inf] (58), [-0.09428,   inf] (58), [-0.09388,   inf] (58), [-0.09209,   inf] (58), [-0.09192,   inf] (58), [-0.09189,   inf] (58), 
length of domains: 9166
Total time: 7.0696	 pickout: 0.5774	 decision: 1.2982	 get_bound: 4.3711	 add_domain: 0.8229
Current lb:-0.10875652730464935
47128 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 56.90709090232849

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3072, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([3072, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 2999] [0, 2999] [0, 2999] [0, 2999] [0, 2999] [0, 2999] [0, 2999] [0, 2999] [0, 2999] [0, 2999] 
regular batch size: 2*3072, diving batch size 1*0
best_l after optimization: 120.53424835205078 with beta sum per layer: [240.12281799316406, 5094.240234375, 198.67762756347656]
alpha/beta optimization time: 2.863574743270874
This batch time : update_bounds func: 4.3917	 prepare: 0.6483	 bound: 2.8641	 transfer: 0.2453	 finalize: 0.6174
Accumulated time: update_bounds func: 39.5180	 prepare: 5.4717	 bound: 27.2391	 transfer: 0.2453	 finalize: 4.4650
batch bounding time:  4.39766526222229
Current worst splitting domains [lb, ub] (depth):
[-0.09803,   inf] (60), [-0.09689,   inf] (60), [-0.09541,   inf] (60), [-0.09522,   inf] (60), [-0.09428,   inf] (60), [-0.09412,   inf] (60), [-0.09347,   inf] (60), [-0.09294,   inf] (60), [-0.09260,   inf] (60), [-0.09234,   inf] (60), [-0.09147,   inf] (60), [-0.09119,   inf] (60), [-0.09064,   inf] (60), [-0.09055,   inf] (60), [-0.09034,   inf] (60), [-0.09006,   inf] (60), [-0.08952,   inf] (60), [-0.08940,   inf] (60), [-0.08857,   inf] (60), [-0.08840,   inf] (60), 
length of domains: 11390
Total time: 7.0447	 pickout: 0.5501	 decision: 1.1754	 get_bound: 4.4074	 add_domain: 0.9118
Current lb:-0.0980294868350029
53272 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 64.02518725395203

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3072, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([3072, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 553] [1, 553] [1, 553] [1, 553] [1, 553] [1, 553] [1, 553] [1, 553] [1, 553] [1, 553] 
regular batch size: 2*3072, diving batch size 1*0
best_l after optimization: 123.091064453125 with beta sum per layer: [386.141845703125, 4818.82080078125, 159.16485595703125]
alpha/beta optimization time: 2.860121250152588
This batch time : update_bounds func: 4.4384	 prepare: 0.6642	 bound: 2.8607	 transfer: 0.2416	 finalize: 0.6538
Accumulated time: update_bounds func: 43.9565	 prepare: 6.1359	 bound: 30.0997	 transfer: 0.2416	 finalize: 5.1188
batch bounding time:  4.444700479507446
Current worst splitting domains [lb, ub] (depth):
[-0.08677,   inf] (62), [-0.08538,   inf] (62), [-0.08480,   inf] (62), [-0.08465,   inf] (62), [-0.08392,   inf] (62), [-0.08386,   inf] (62), [-0.08259,   inf] (62), [-0.08256,   inf] (62), [-0.08203,   inf] (62), [-0.08198,   inf] (62), [-0.08192,   inf] (62), [-0.08189,   inf] (62), [-0.08179,   inf] (62), [-0.08151,   inf] (62), [-0.08098,   inf] (62), [-0.08059,   inf] (62), [-0.08051,   inf] (62), [-0.08002,   inf] (62), [-0.07987,   inf] (62), [-0.07971,   inf] (62), 
length of domains: 13741
Total time: 7.3092	 pickout: 0.5669	 decision: 1.3084	 get_bound: 4.4556	 add_domain: 0.9782
Current lb:-0.0867709368467331
59416 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 71.40598678588867

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3072, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([3072, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 499] [1, 940] [1, 940] [1, 940] [0, 3243] [1, 499] [0, 3243] [1, 499] [0, 3243] [1, 499] 
regular batch size: 2*3072, diving batch size 1*0
best_l after optimization: 128.3182373046875 with beta sum per layer: [494.83990478515625, 4393.6455078125, 109.30172729492188]
alpha/beta optimization time: 2.8717129230499268
This batch time : update_bounds func: 4.5017	 prepare: 0.6529	 bound: 2.8722	 transfer: 0.2453	 finalize: 0.7129
Accumulated time: update_bounds func: 48.4582	 prepare: 6.7888	 bound: 32.9719	 transfer: 0.2453	 finalize: 5.8317
batch bounding time:  4.507859945297241
Current worst splitting domains [lb, ub] (depth):
[-0.07939,   inf] (64), [-0.07807,   inf] (64), [-0.07749,   inf] (64), [-0.07736,   inf] (64), [-0.07602,   inf] (64), [-0.07525,   inf] (64), [-0.07471,   inf] (64), [-0.07447,   inf] (64), [-0.07442,   inf] (64), [-0.07411,   inf] (64), [-0.07394,   inf] (64), [-0.07390,   inf] (64), [-0.07368,   inf] (64), [-0.07341,   inf] (64), [-0.07326,   inf] (64), [-0.07315,   inf] (64), [-0.07260,   inf] (64), [-0.07248,   inf] (64), [-0.07242,   inf] (64), [-0.07228,   inf] (64), 
length of domains: 16172
Total time: 7.0374	 pickout: 0.5649	 decision: 1.2464	 get_bound: 4.5189	 add_domain: 0.7071
Current lb:-0.0793924331665039
65560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 78.5287914276123

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3072, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([3072, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 940] [1, 499] [1, 499] [1, 499] [1, 940] [1, 499] [1, 940] [1, 940] [1, 940] [1, 940] 
regular batch size: 2*3072, diving batch size 1*0
best_l after optimization: 105.3742904663086 with beta sum per layer: [592.185302734375, 4268.1181640625, 91.37980651855469]
alpha/beta optimization time: 2.89030385017395
This batch time : update_bounds func: 4.5368	 prepare: 0.6529	 bound: 2.8908	 transfer: 0.2413	 finalize: 0.7337
Accumulated time: update_bounds func: 52.9950	 prepare: 7.4416	 bound: 35.8627	 transfer: 0.2413	 finalize: 6.5654
batch bounding time:  4.542876243591309
Current worst splitting domains [lb, ub] (depth):
[-0.07205,   inf] (66), [-0.07073,   inf] (66), [-0.07014,   inf] (66), [-0.06998,   inf] (66), [-0.06862,   inf] (66), [-0.06793,   inf] (66), [-0.06731,   inf] (66), [-0.06708,   inf] (66), [-0.06696,   inf] (66), [-0.06674,   inf] (66), [-0.06662,   inf] (66), [-0.06657,   inf] (66), [-0.06629,   inf] (66), [-0.06608,   inf] (66), [-0.06591,   inf] (66), [-0.06567,   inf] (66), [-0.06512,   inf] (66), [-0.06509,   inf] (66), [-0.06492,   inf] (66), [-0.06448,   inf] (66), 
length of domains: 18415
Total time: 7.1299	 pickout: 0.5671	 decision: 1.2970	 get_bound: 4.5552	 add_domain: 0.7106
Current lb:-0.07205098867416382
71704 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 85.73260068893433

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3072, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([3072, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1910] [1, 1910] [1, 1910] [1, 1910] [1, 1910] [1, 940] [1, 1910] [1, 1910] [1, 1910] [1, 1910] 
regular batch size: 2*3072, diving batch size 1*0
best_l after optimization: 75.3289794921875 with beta sum per layer: [635.8125, 4219.2333984375, 92.18917846679688]
alpha/beta optimization time: 2.869819402694702
This batch time : update_bounds func: 4.6453	 prepare: 0.6950	 bound: 2.8703	 transfer: 0.2445	 finalize: 0.3882
Accumulated time: update_bounds func: 57.6403	 prepare: 8.1366	 bound: 38.7329	 transfer: 0.2445	 finalize: 6.9536
batch bounding time:  4.652101993560791
Current worst splitting domains [lb, ub] (depth):
[-0.06315,   inf] (68), [-0.06183,   inf] (68), [-0.06128,   inf] (68), [-0.06112,   inf] (68), [-0.06056,   inf] (68), [-0.05971,   inf] (68), [-0.05926,   inf] (68), [-0.05874,   inf] (68), [-0.05857,   inf] (68), [-0.05843,   inf] (68), [-0.05807,   inf] (68), [-0.05801,   inf] (68), [-0.05791,   inf] (68), [-0.05772,   inf] (68), [-0.05724,   inf] (68), [-0.05710,   inf] (68), [-0.05674,   inf] (68), [-0.05620,   inf] (68), [-0.05612,   inf] (68), [-0.05601,   inf] (68), 
length of domains: 20176
Total time: 7.7393	 pickout: 0.5643	 decision: 1.3669	 get_bound: 4.6646	 add_domain: 1.1435
Current lb:-0.06314516067504883
77848 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 93.55524134635925

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3072, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([3072, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 1175] [0, 1175] [0, 1175] [0, 1175] [1, 1910] [0, 1175] [1, 1910] [1, 1910] [1, 1910] [0, 1175] 
regular batch size: 2*3072, diving batch size 1*0
best_l after optimization: 58.452880859375 with beta sum per layer: [613.930908203125, 3998.1689453125, 91.21478271484375]
alpha/beta optimization time: 2.871246337890625
This batch time : update_bounds func: 4.6992	 prepare: 0.6808	 bound: 2.8717	 transfer: 0.2425	 finalize: 0.3931
Accumulated time: update_bounds func: 62.3395	 prepare: 8.8174	 bound: 41.6046	 transfer: 0.2425	 finalize: 7.3467
batch bounding time:  4.705527305603027
Current worst splitting domains [lb, ub] (depth):
[-0.05498,   inf] (70), [-0.05368,   inf] (70), [-0.05312,   inf] (70), [-0.05296,   inf] (70), [-0.05186,   inf] (70), [-0.05157,   inf] (70), [-0.05149,   inf] (70), [-0.05103,   inf] (70), [-0.05075,   inf] (70), [-0.05059,   inf] (70), [-0.05029,   inf] (70), [-0.05018,   inf] (70), [-0.05008,   inf] (70), [-0.04991,   inf] (70), [-0.04976,   inf] (70), [-0.04969,   inf] (70), [-0.04962,   inf] (70), [-0.04957,   inf] (70), [-0.04947,   inf] (70), [-0.04917,   inf] (70), 
length of domains: 21809
Total time: 6.9337	 pickout: 0.5701	 decision: 1.0060	 get_bound: 4.7160	 add_domain: 0.6417
Current lb:-0.054982155561447144
83992 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 100.57479596138

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3072, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([3072, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1918] [1, 1918] [1, 1585] [1, 1585] [0, 1175] [1, 1918] [1, 1918] [1, 1918] [0, 1175] [0, 1175] 
regular batch size: 2*3072, diving batch size 1*0
best_l after optimization: 42.48432922363281 with beta sum per layer: [649.8743896484375, 4001.01708984375, 95.48408508300781]
alpha/beta optimization time: 2.8633925914764404
This batch time : update_bounds func: 4.7022	 prepare: 0.6928	 bound: 2.8638	 transfer: 0.2420	 finalize: 0.8840
Accumulated time: update_bounds func: 67.0418	 prepare: 9.5101	 bound: 44.4684	 transfer: 0.2420	 finalize: 8.2307
batch bounding time:  4.7091147899627686
Current worst splitting domains [lb, ub] (depth):
[-0.04773,   inf] (72), [-0.04645,   inf] (72), [-0.04600,   inf] (72), [-0.04586,   inf] (72), [-0.04424,   inf] (72), [-0.04423,   inf] (72), [-0.04369,   inf] (72), [-0.04368,   inf] (72), [-0.04298,   inf] (72), [-0.04297,   inf] (72), [-0.04254,   inf] (72), [-0.04247,   inf] (72), [-0.04242,   inf] (72), [-0.04241,   inf] (72), [-0.04241,   inf] (72), [-0.04236,   inf] (72), [-0.04228,   inf] (72), [-0.04192,   inf] (72), [-0.04190,   inf] (72), [-0.04175,   inf] (72), 
length of domains: 23231
Total time: 7.3685	 pickout: 0.5722	 decision: 1.4565	 get_bound: 4.7219	 add_domain: 0.6179
Current lb:-0.047727230936288834
90136 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 108.03627753257751

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3072, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([3072, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 501] [1, 501] [1, 1918] [1, 1918] [1, 501] [1, 501] [1, 501] [1, 501] [1, 501] [1, 501] 
regular batch size: 2*3072, diving batch size 1*0
best_l after optimization: 29.298355102539062 with beta sum per layer: [599.3831787109375, 4354.47607421875, 100.32077026367188]
alpha/beta optimization time: 2.8565285205841064
This batch time : update_bounds func: 4.8436	 prepare: 0.7010	 bound: 2.8570	 transfer: 0.2426	 finalize: 1.0239
Accumulated time: update_bounds func: 71.8854	 prepare: 10.2111	 bound: 47.3254	 transfer: 0.2426	 finalize: 9.2546
batch bounding time:  4.850581407546997
Current worst splitting domains [lb, ub] (depth):
[-0.03974,   inf] (74), [-0.03876,   inf] (74), [-0.03858,   inf] (74), [-0.03846,   inf] (74), [-0.03626,   inf] (74), [-0.03625,   inf] (74), [-0.03569,   inf] (74), [-0.03555,   inf] (74), [-0.03521,   inf] (74), [-0.03511,   inf] (74), [-0.03504,   inf] (74), [-0.03500,   inf] (74), [-0.03496,   inf] (74), [-0.03450,   inf] (74), [-0.03450,   inf] (74), [-0.03443,   inf] (74), [-0.03427,   inf] (74), [-0.03394,   inf] (74), [-0.03378,   inf] (74), [-0.03374,   inf] (74), 
length of domains: 24614
Total time: 7.6023	 pickout: 0.5765	 decision: 1.5425	 get_bound: 4.8637	 add_domain: 0.6196
Current lb:-0.03973579406738281
96280 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 115.73404335975647

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3072, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([3072, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1585] [1, 501] [1, 501] [1, 1585] [1, 1585] [1, 1585] [1, 1585] [1, 1918] [1, 501] [1, 501] 
regular batch size: 2*3072, diving batch size 1*0
best_l after optimization: 12.75830078125 with beta sum per layer: [560.3186645507812, 4370.3544921875, 113.76886749267578]
alpha/beta optimization time: 2.845106601715088
This batch time : update_bounds func: 4.2103	 prepare: 0.7015	 bound: 2.8455	 transfer: 0.2473	 finalize: 0.3952
Accumulated time: update_bounds func: 76.0956	 prepare: 10.9126	 bound: 50.1710	 transfer: 0.2473	 finalize: 9.6498
batch bounding time:  4.21690821647644
Current worst splitting domains [lb, ub] (depth):
[-0.03269,   inf] (76), [-0.03134,   inf] (76), [-0.03075,   inf] (76), [-0.03058,   inf] (76), [-0.02927,   inf] (76), [-0.02920,   inf] (76), [-0.02866,   inf] (76), [-0.02842,   inf] (76), [-0.02790,   inf] (76), [-0.02788,   inf] (76), [-0.02732,   inf] (76), [-0.02726,   inf] (76), [-0.02722,   inf] (76), [-0.02720,   inf] (76), [-0.02707,   inf] (76), [-0.02705,   inf] (76), [-0.02669,   inf] (76), [-0.02662,   inf] (76), [-0.02659,   inf] (76), [-0.02651,   inf] (76), 
length of domains: 25485
Total time: 7.6578	 pickout: 0.5830	 decision: 1.5954	 get_bound: 4.2284	 add_domain: 1.2510
Current lb:-0.03269355371594429
102424 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 123.50073289871216

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3072, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([3072, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1078] [1, 1078] [1, 1078] [1, 1078] [1, 1078] [1, 1078] [1, 1078] [1, 1078] [1, 1078] [1, 1078] 
regular batch size: 2*3072, diving batch size 1*0
best_l after optimization: 0.4081801176071167 with beta sum per layer: [505.6979064941406, 4487.025390625, 124.27989196777344]
alpha/beta optimization time: 2.824040651321411
This batch time : update_bounds func: 4.8224	 prepare: 0.6912	 bound: 2.8245	 transfer: 0.2415	 finalize: 1.0450
Accumulated time: update_bounds func: 80.9180	 prepare: 11.6038	 bound: 52.9954	 transfer: 0.2415	 finalize: 10.6948
batch bounding time:  4.829603433609009
Current worst splitting domains [lb, ub] (depth):
[-0.02481,   inf] (78), [-0.02349,   inf] (78), [-0.02285,   inf] (78), [-0.02266,   inf] (78), [-0.02136,   inf] (78), [-0.02136,   inf] (78), [-0.02094,   inf] (78), [-0.02077,   inf] (78), [-0.02022,   inf] (78), [-0.02006,   inf] (78), [-0.02003,   inf] (78), [-0.01971,   inf] (78), [-0.01965,   inf] (78), [-0.01960,   inf] (78), [-0.01947,   inf] (78), [-0.01945,   inf] (78), [-0.01939,   inf] (78), [-0.01938,   inf] (78), [-0.01926,   inf] (78), [-0.01918,   inf] (78), 
length of domains: 25948
Total time: 6.9254	 pickout: 0.5768	 decision: 1.0070	 get_bound: 4.8419	 add_domain: 0.4996
Current lb:-0.024809682741761208
108568 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 130.53457689285278

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3072, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([3072, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 3243] [0, 3243] [0, 3243] [0, 3243] [0, 3243] [0, 3243] [0, 3243] [0, 3243] [1, 1585] [0, 3243] 
regular batch size: 2*3072, diving batch size 1*0
best_l after optimization: -11.471979141235352 with beta sum per layer: [480.1483154296875, 4616.53955078125, 137.66368103027344]
alpha/beta optimization time: 2.813640594482422
This batch time : update_bounds func: 4.2539	 prepare: 0.6894	 bound: 2.8141	 transfer: 0.2468	 finalize: 0.4836
Accumulated time: update_bounds func: 85.1719	 prepare: 12.2932	 bound: 55.8095	 transfer: 0.2468	 finalize: 11.1784
batch bounding time:  4.26178503036499
Current worst splitting domains [lb, ub] (depth):
[-0.01792,   inf] (80), [-0.01663,   inf] (80), [-0.01602,   inf] (80), [-0.01583,   inf] (80), [-0.01445,   inf] (80), [-0.01445,   inf] (80), [-0.01389,   inf] (80), [-0.01384,   inf] (80), [-0.01319,   inf] (80), [-0.01315,   inf] (80), [-0.01313,   inf] (80), [-0.01262,   inf] (80), [-0.01260,   inf] (80), [-0.01259,   inf] (80), [-0.01257,   inf] (80), [-0.01239,   inf] (80), [-0.01234,   inf] (80), [-0.01228,   inf] (80), [-0.01215,   inf] (80), [-0.01210,   inf] (80), 
length of domains: 25830
Total time: 7.7044	 pickout: 0.5855	 decision: 1.6381	 get_bound: 4.2784	 add_domain: 1.2024
Current lb:-0.01791718229651451
114712 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 138.3510115146637

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3072, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([3072, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1614] [1, 1614] [1, 1614] [1, 1614] [0, 3000] [1, 1614] [1, 1614] [1, 1614] [0, 3000] [1, 1614] 
regular batch size: 2*3072, diving batch size 1*0
best_l after optimization: -20.826459884643555 with beta sum per layer: [469.6455993652344, 4737.41015625, 140.61624145507812]
alpha/beta optimization time: 2.8169705867767334
This batch time : update_bounds func: 4.8401	 prepare: 0.6742	 bound: 2.8174	 transfer: 0.2434	 finalize: 1.0845
Accumulated time: update_bounds func: 90.0120	 prepare: 12.9674	 bound: 58.6269	 transfer: 0.2434	 finalize: 12.2629
batch bounding time:  4.847102165222168
Current worst splitting domains [lb, ub] (depth):
[-0.01347,   inf] (82), [-0.01219,   inf] (82), [-0.01158,   inf] (82), [-0.01140,   inf] (82), [-0.00998,   inf] (82), [-0.00942,   inf] (82), [-0.00938,   inf] (82), [-0.00914,   inf] (82), [-0.00895,   inf] (54), [-0.00895,   inf] (66), [-0.00895,   inf] (64), [-0.00895,   inf] (58), [-0.00895,   inf] (56), [-0.00894,   inf] (52), [-0.00894,   inf] (60), [-0.00894,   inf] (78), [-0.00894,   inf] (74), [-0.00894,   inf] (62), [-0.00894,   inf] (70), [-0.00894,   inf] (68), 
length of domains: 25121
Total time: 6.8104	 pickout: 0.6123	 decision: 1.0011	 get_bound: 4.8599	 add_domain: 0.3370
Current lb:-0.01347148884087801
120856 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 145.28473258018494

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3072, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([3072, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1577] [1, 1577] [1, 1577] [1, 1577] [1, 1577] [1, 1577] [1, 1577] [1, 1577] [2, 33] [1, 1918] 
regular batch size: 2*3072, diving batch size 1*0
best_l after optimization: -27.45763397216797 with beta sum per layer: [468.31072998046875, 4714.28515625, 141.01243591308594]
alpha/beta optimization time: 2.8019886016845703
This batch time : update_bounds func: 4.1664	 prepare: 0.6783	 bound: 2.8024	 transfer: 0.2423	 finalize: 0.4243
Accumulated time: update_bounds func: 94.1784	 prepare: 13.6457	 bound: 61.4293	 transfer: 0.2423	 finalize: 12.6872
batch bounding time:  4.173498153686523
Current worst splitting domains [lb, ub] (depth):
[-0.00772,   inf] (72), [-0.00772,   inf] (72), [-0.00772,   inf] (68), [-0.00772,   inf] (66), [-0.00772,   inf] (76), [-0.00772,   inf] (66), [-0.00772,   inf] (52), [-0.00772,   inf] (68), [-0.00771,   inf] (68), [-0.00771,   inf] (70), [-0.00771,   inf] (74), [-0.00771,   inf] (70), [-0.00771,   inf] (56), [-0.00771,   inf] (68), [-0.00771,   inf] (66), [-0.00771,   inf] (60), [-0.00771,   inf] (68), [-0.00771,   inf] (60), [-0.00771,   inf] (58), [-0.00771,   inf] (72), 
length of domains: 23557
Total time: 6.6551	 pickout: 0.5931	 decision: 1.6528	 get_bound: 4.1870	 add_domain: 0.2222
Current lb:-0.007717106491327286
127000 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 152.07241082191467

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3072, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([3072, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 501] [1, 1918] [1, 1910] [1, 1910] [0, 3016] [1, 113] [1, 1076] [1, 1122] [1, 499] [0, 1175] 
regular batch size: 2*3072, diving batch size 1*0
best_l after optimization: -35.21502685546875 with beta sum per layer: [484.6243591308594, 4805.3310546875, 144.12911987304688]
alpha/beta optimization time: 2.7891786098480225
This batch time : update_bounds func: 4.8086	 prepare: 0.6847	 bound: 2.7896	 transfer: 0.2415	 finalize: 1.0739
Accumulated time: update_bounds func: 98.9870	 prepare: 14.3304	 bound: 64.2189	 transfer: 0.2415	 finalize: 13.7611
batch bounding time:  4.815861463546753
Current worst splitting domains [lb, ub] (depth):
[-0.00654,   inf] (72), [-0.00654,   inf] (52), [-0.00654,   inf] (56), [-0.00654,   inf] (66), [-0.00654,   inf] (54), [-0.00654,   inf] (70), [-0.00654,   inf] (72), [-0.00654,   inf] (68), [-0.00654,   inf] (70), [-0.00654,   inf] (72), [-0.00654,   inf] (56), [-0.00654,   inf] (68), [-0.00654,   inf] (72), [-0.00654,   inf] (64), [-0.00653,   inf] (60), [-0.00653,   inf] (78), [-0.00653,   inf] (62), [-0.00653,   inf] (66), [-0.00653,   inf] (78), [-0.00653,   inf] (60), 
length of domains: 20977
Total time: 7.1313	 pickout: 0.6000	 decision: 1.6243	 get_bound: 4.8285	 add_domain: 0.0785
Current lb:-0.006538964342325926
133144 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 159.34647798538208

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3072, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([3072, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 501] [0, 2999] [1, 753] [1, 1910] [2, 33] [0, 1175] [1, 1918] [0, 1959] [1, 1585] [1, 1585] 
regular batch size: 2*3072, diving batch size 1*0
best_l after optimization: -41.55265808105469 with beta sum per layer: [485.02703857421875, 4897.19677734375, 144.02145385742188]
alpha/beta optimization time: 2.784515380859375
This batch time : update_bounds func: 4.1330	 prepare: 0.6684	 bound: 2.7849	 transfer: 0.2424	 finalize: 0.4191
Accumulated time: update_bounds func: 103.1200	 prepare: 14.9988	 bound: 67.0039	 transfer: 0.2424	 finalize: 14.1803
batch bounding time:  4.139767169952393
Current worst splitting domains [lb, ub] (depth):
[-0.00544,   inf] (66), [-0.00544,   inf] (52), [-0.00543,   inf] (72), [-0.00543,   inf] (68), [-0.00543,   inf] (66), [-0.00543,   inf] (70), [-0.00543,   inf] (66), [-0.00543,   inf] (58), [-0.00543,   inf] (66), [-0.00543,   inf] (64), [-0.00543,   inf] (62), [-0.00543,   inf] (64), [-0.00543,   inf] (62), [-0.00543,   inf] (58), [-0.00543,   inf] (64), [-0.00543,   inf] (70), [-0.00543,   inf] (60), [-0.00543,   inf] (64), [-0.00543,   inf] (60), [-0.00543,   inf] (66), 
length of domains: 18009
Total time: 6.3158	 pickout: 0.5912	 decision: 1.5537	 get_bound: 4.1512	 add_domain: 0.0197
Current lb:-0.00543630076572299
139288 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 165.80993628501892

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3072, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([3072, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 564] [1, 114] [0, 2998] [1, 1910] [0, 1959] [0, 3243] [1, 1910] [1, 940] [1, 1122] [1, 1577] 
regular batch size: 2*3072, diving batch size 1*0
best_l after optimization: -48.03042984008789 with beta sum per layer: [511.8087463378906, 4861.94921875, 138.93841552734375]
alpha/beta optimization time: 2.7884654998779297
This batch time : update_bounds func: 4.6992	 prepare: 0.7027	 bound: 2.7889	 transfer: 0.2425	 finalize: 0.9448
Accumulated time: update_bounds func: 107.8191	 prepare: 15.7015	 bound: 69.7928	 transfer: 0.2425	 finalize: 15.1251
batch bounding time:  4.706023216247559
Current worst splitting domains [lb, ub] (depth):
[-0.00441,   inf] (64), [-0.00441,   inf] (70), [-0.00441,   inf] (74), [-0.00441,   inf] (74), [-0.00441,   inf] (64), [-0.00441,   inf] (68), [-0.00440,   inf] (64), [-0.00440,   inf] (64), [-0.00440,   inf] (62), [-0.00440,   inf] (66), [-0.00440,   inf] (60), [-0.00440,   inf] (56), [-0.00440,   inf] (66), [-0.00440,   inf] (68), [-0.00440,   inf] (66), [-0.00440,   inf] (56), [-0.00440,   inf] (56), [-0.00440,   inf] (78), [-0.00440,   inf] (74), [-0.00440,   inf] (66), 
length of domains: 14985
Total time: 6.8537	 pickout: 0.6048	 decision: 1.5205	 get_bound: 4.7178	 add_domain: 0.0106
Current lb:-0.004405498504638672
145432 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 172.8153829574585

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3072, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([3072, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1585] [0, 1959] [0, 1175] [1, 1078] [1, 553] [1, 940] [1, 1585] [1, 1585] [1, 1585] [1, 501] 
regular batch size: 2*3072, diving batch size 1*0
best_l after optimization: -53.925724029541016 with beta sum per layer: [510.8355712890625, 4891.884765625, 141.78660583496094]
alpha/beta optimization time: 2.786159038543701
This batch time : update_bounds func: 4.6146	 prepare: 0.6975	 bound: 2.7866	 transfer: 0.2421	 finalize: 0.8717
Accumulated time: update_bounds func: 112.4338	 prepare: 16.3990	 bound: 72.5794	 transfer: 0.2421	 finalize: 15.9969
batch bounding time:  4.621443748474121
Current worst splitting domains [lb, ub] (depth):
[-0.00341,   inf] (72), [-0.00341,   inf] (70), [-0.00341,   inf] (58), [-0.00341,   inf] (64), [-0.00341,   inf] (64), [-0.00341,   inf] (74), [-0.00341,   inf] (64), [-0.00341,   inf] (66), [-0.00341,   inf] (56), [-0.00341,   inf] (74), [-0.00341,   inf] (68), [-0.00341,   inf] (70), [-0.00341,   inf] (56), [-0.00341,   inf] (52), [-0.00341,   inf] (64), [-0.00341,   inf] (74), [-0.00341,   inf] (72), [-0.00341,   inf] (64), [-0.00341,   inf] (62), [-0.00341,   inf] (58), 
length of domains: 11924
Total time: 6.6189	 pickout: 0.5909	 decision: 1.3902	 get_bound: 4.6330	 add_domain: 0.0047
Current lb:-0.0034122467041015625
151576 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 179.58094573020935

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3072, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([3072, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1585] [1, 564] [1, 940] [1, 1910] [1, 1910] [0, 3243] [1, 1585] [1, 1910] [1, 114] [1, 940] 
regular batch size: 2*3072, diving batch size 1*0
best_l after optimization: -59.50815200805664 with beta sum per layer: [498.018798828125, 4917.40771484375, 148.06495666503906]
alpha/beta optimization time: 2.7893588542938232
This batch time : update_bounds func: 4.5278	 prepare: 0.6975	 bound: 2.7899	 transfer: 0.2436	 finalize: 0.7779
Accumulated time: update_bounds func: 116.9616	 prepare: 17.0966	 bound: 75.3693	 transfer: 0.2436	 finalize: 16.7748
batch bounding time:  4.534932851791382
Current worst splitting domains [lb, ub] (depth):
[-0.00249,   inf] (80), [-0.00249,   inf] (62), [-0.00249,   inf] (72), [-0.00249,   inf] (62), [-0.00249,   inf] (72), [-0.00249,   inf] (56), [-0.00249,   inf] (58), [-0.00249,   inf] (56), [-0.00249,   inf] (62), [-0.00249,   inf] (66), [-0.00249,   inf] (62), [-0.00249,   inf] (70), [-0.00249,   inf] (70), [-0.00249,   inf] (74), [-0.00249,   inf] (74), [-0.00249,   inf] (60), [-0.00249,   inf] (70), [-0.00249,   inf] (76), [-0.00249,   inf] (68), [-0.00249,   inf] (68), 
length of domains: 8853
Total time: 6.4768	 pickout: 0.6068	 decision: 1.3202	 get_bound: 4.5465	 add_domain: 0.0033
Current lb:-0.0024909786880016327
157720 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 186.20435667037964

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3072, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([3072, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 3000] [1, 1585] [1, 940] [1, 499] [0, 1175] [1, 1076] [1, 113] [1, 940] [1, 940] [1, 1910] 
regular batch size: 2*3072, diving batch size 1*0

all verified at 7th iter
best_l after optimization: -65.10514068603516 with beta sum per layer: [520.896484375, 4902.1162109375, 140.07345581054688]
alpha/beta optimization time: 0.9890189170837402
This batch time : update_bounds func: 2.5844	 prepare: 0.6640	 bound: 0.9894	 transfer: 0.2419	 finalize: 0.6724
Accumulated time: update_bounds func: 119.5460	 prepare: 17.7606	 bound: 76.3587	 transfer: 0.2419	 finalize: 17.4472
batch bounding time:  2.5911142826080322
Current worst splitting domains [lb, ub] (depth):
[-0.00158,   inf] (66), [-0.00158,   inf] (66), [-0.00158,   inf] (58), [-0.00158,   inf] (58), [-0.00158,   inf] (66), [-0.00158,   inf] (78), [-0.00158,   inf] (70), [-0.00158,   inf] (66), [-0.00158,   inf] (52), [-0.00158,   inf] (54), [-0.00158,   inf] (66), [-0.00158,   inf] (60), [-0.00158,   inf] (76), [-0.00158,   inf] (76), [-0.00158,   inf] (80), [-0.00158,   inf] (80), [-0.00158,   inf] (66), [-0.00158,   inf] (60), [-0.00158,   inf] (64), [-0.00158,   inf] (70), 
length of domains: 5781
Total time: 4.7103	 pickout: 0.6078	 decision: 1.4962	 get_bound: 2.6032	 add_domain: 0.0030
Current lb:-0.0015823503490537405
163864 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 191.05755424499512

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3072, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([3072, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1910] [1, 1974] [0, 1959] [1, 113] [1, 302] [0, 3016] [1, 499] [1, 1918] [1, 1577] [2, 33] 
regular batch size: 2*3072, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -70.35206604003906 with beta sum per layer: [551.5943603515625, 4921.6572265625, 142.69384765625]
alpha/beta optimization time: 0.08148050308227539
This batch time : update_bounds func: 1.7913	 prepare: 0.6592	 bound: 0.0819	 transfer: 0.2341	 finalize: 0.6126
Accumulated time: update_bounds func: 121.3373	 prepare: 18.4198	 bound: 76.4405	 transfer: 0.2341	 finalize: 18.0598
batch bounding time:  1.7978014945983887
Current worst splitting domains [lb, ub] (depth):
[-0.00072,   inf] (64), [-0.00072,   inf] (70), [-0.00072,   inf] (64), [-0.00072,   inf] (66), [-0.00072,   inf] (68), [-0.00072,   inf] (54), [-0.00072,   inf] (68), [-0.00072,   inf] (70), [-0.00072,   inf] (80), [-0.00072,   inf] (52), [-0.00072,   inf] (64), [-0.00072,   inf] (62), [-0.00072,   inf] (60), [-0.00072,   inf] (80), [-0.00072,   inf] (74), [-0.00072,   inf] (68), [-0.00072,   inf] (68), [-0.00072,   inf] (58), [-0.00072,   inf] (64), [-0.00072,   inf] (64), 
length of domains: 2709
Total time: 3.7858	 pickout: 0.6254	 decision: 1.3486	 get_bound: 1.8089	 add_domain: 0.0029
Current lb:-0.0007195472717285156
170008 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 194.98293733596802

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2709, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([2709, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 499] [1, 1585] [1, 113] [1, 940] [1, 940] [1, 114] [1, 1122] [1, 1918] [1, 499] [1, 1076] 
regular batch size: 2*2709, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -66.40800476074219 with beta sum per layer: [471.74658203125, 4368.568359375, 127.65486145019531]
alpha/beta optimization time: 0.07327675819396973
This batch time : update_bounds func: 1.3155	 prepare: 0.5761	 bound: 0.0737	 transfer: 0.2030	 finalize: 0.4483
Accumulated time: update_bounds func: 122.6527	 prepare: 18.9959	 bound: 76.5142	 transfer: 0.2030	 finalize: 18.5081
batch bounding time:  1.3208732604980469
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 3.1067	 pickout: 0.5980	 decision: 1.1761	 get_bound: 1.3300	 add_domain: 0.0025
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 198.28812313079834

Image 83 label 8 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 198.3901903629303
83 1.0000000116860974e-07
##### [0:83] Tested against 0 ######
Model prediction is: tensor([[-38.4824, -38.8508, -42.3743, -40.6830, -40.7441, -41.2199, -42.7789,
         -41.9925, -38.1940, -35.9327]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 16, 16]) != torch.Size([2, 9, 1, 16, 16, 16]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 8, 8]) != torch.Size([2, 9, 1, 32, 8, 8]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 16, 16])
1 /11 torch.Size([1, 32, 8, 8])
2 /21 torch.Size([1, 100])
best_l after optimization: 1.0456576347351074 with beta sum per layer: []
alpha/beta optimization time: 1.0150010585784912
alpha-CROWN with fixed intermediate bounds: tensor([[-1.0457]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-1.0456576347351074
layer 0 size torch.Size([4096]) unstable 773
layer 1 size torch.Size([2048]) unstable 328
layer 2 size torch.Size([100]) unstable 49
-----------------
# of unstable neurons: 1150
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 16, 16]) pre split depth:  8
batch:  torch.Size([1, 16, 16, 16]) post split depth:  8
splitting decisions: 
split level 0: [2, 40] 
split level 1: [2, 7] 
split level 2: [2, 30] 
split level 3: [2, 28] 
split level 4: [2, 48] 
split level 5: [2, 20] 
split level 6: [2, 61] 
split level 7: [2, 36] 
regular batch size: 2*128, diving batch size 1*0
best_l after optimization: -258.9119567871094 with beta sum per layer: [0.0, 0.0, 0.1563078761100769]
alpha/beta optimization time: 0.29320287704467773
This batch time : update_bounds func: 0.3330	 prepare: 0.0181	 bound: 0.2935	 transfer: 0.0057	 finalize: 0.0150
Accumulated time: update_bounds func: 122.9857	 prepare: 19.0141	 bound: 76.8077	 transfer: 0.0057	 finalize: 18.5230
batch bounding time:  0.3333137035369873
Current worst splitting domains [lb, ub] (depth):
[-0.17553,   inf] (9), [-0.06226,   inf] (9), [-0.05078,   inf] (9), [-0.01703,   inf] (9), 
length of domains: 4
Total time: 0.4131	 pickout: 0.0009	 decision: 0.0466	 get_bound: 0.3652	 add_domain: 0.0003
Current lb:-0.17553263902664185
256 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.4556739330291748

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 16, 16, 16]) pre split depth:  6
batch:  torch.Size([4, 16, 16, 16]) post split depth:  6
splitting decisions: 
split level 0: [2, 56] [2, 56] [2, 56] [2, 67] 
split level 1: [2, 67] [2, 67] [2, 67] [2, 56] 
split level 2: [2, 8] [2, 8] [2, 8] [2, 8] 
split level 3: [2, 65] [2, 65] [2, 65] [2, 29] 
split level 4: [2, 29] [2, 29] [2, 29] [2, 65] 
split level 5: [2, 10] [2, 10] [2, 10] [2, 10] 
regular batch size: 2*128, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -124.43814086914062 with beta sum per layer: [0.0, 0.0, 10.003704071044922]
alpha/beta optimization time: 0.009995460510253906
This batch time : update_bounds func: 0.0523	 prepare: 0.0217	 bound: 0.0103	 transfer: 0.0051	 finalize: 0.0145
Accumulated time: update_bounds func: 123.0380	 prepare: 19.0358	 bound: 76.8180	 transfer: 0.0051	 finalize: 18.5375
batch bounding time:  0.052533626556396484
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.1256	 pickout: 0.0012	 decision: 0.0387	 get_bound: 0.0856	 add_domain: 0.0001
No domains left, verification finished!/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:462: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(preprocess_cifar(eps_temp, perturbation=True)).reshape(1,-1,1,1)

Global ub: inf, batch ub: inf
Cumulative time: 1.5827503204345703

Image 83 label 0 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.6427984237670898
83 1.0000000116860974e-07
##### [0:83] Tested against 1 ######
Model prediction is: tensor([[-38.4824, -38.8508, -42.3743, -40.6830, -40.7441, -41.2199, -42.7789,
         -41.9925, -38.1940, -35.9327]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 16, 16]) != torch.Size([2, 9, 1, 16, 16, 16]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 8, 8]) != torch.Size([2, 9, 1, 32, 8, 8]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 16, 16])
1 /11 torch.Size([1, 32, 8, 8])
2 /21 torch.Size([1, 100])
best_l after optimization: 0.33977365493774414 with beta sum per layer: []
alpha/beta optimization time: 0.9979445934295654
alpha-CROWN with fixed intermediate bounds: tensor([[-0.3398]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.33977365493774414
layer 0 size torch.Size([4096]) unstable 773
layer 1 size torch.Size([2048]) unstable 328
layer 2 size torch.Size([100]) unstable 49
-----------------
# of unstable neurons: 1150
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 16, 16]) pre split depth:  8
batch:  torch.Size([1, 16, 16, 16]) post split depth:  8
splitting decisions: 
split level 0: [2, 2] 
split level 1: [2, 31] 
split level 2: [2, 25] 
split level 3: [2, 7] 
split level 4: [2, 16] 
split level 5: [2, 37] 
split level 6: [2, 6] 
split level 7: [2, 48] 
regular batch size: 2*128, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -448.4403381347656 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.022184371948242188
This batch time : update_bounds func: 0.0616	 prepare: 0.0185	 bound: 0.0225	 transfer: 0.0052	 finalize: 0.0147
Accumulated time: update_bounds func: 123.0996	 prepare: 19.0543	 bound: 76.8405	 transfer: 0.0052	 finalize: 18.5523
batch bounding time:  0.06187701225280762
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.1417	 pickout: 0.0009	 decision: 0.0472	 get_bound: 0.0936	 add_domain: 0.0001
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.164144515991211

Image 83 label 1 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.2251250743865967
83 1.0000000116860974e-07
##### [0:83] Tested against 3 ######
Initial alpha-CROWN verified for label 3 with bound 0.5261249542236328
Image 83 label 3 verification end, final lower bound 0.5261249542236328, upper bound inf, time: 0.00041604042053222656
83 0.5261249542236328
##### [0:83] Tested against 4 ######
Initial alpha-CROWN verified for label 4 with bound 0.1957596242427826
Image 83 label 4 verification end, final lower bound 0.1957596242427826, upper bound inf, time: 0.00040459632873535156
83 0.1957596242427826
##### [0:83] Tested against 5 ######
Initial alpha-CROWN verified for label 5 with bound 0.7986669540405273
Image 83 label 5 verification end, final lower bound 0.7986669540405273, upper bound inf, time: 0.00039696693420410156
83 0.7986669540405273
##### [0:83] Tested against 7 ######
Initial alpha-CROWN verified for label 7 with bound 0.9293989539146423
Image 83 label 7 verification end, final lower bound 0.9293989539146423, upper bound inf, time: 0.0004100799560546875
83 0.9293989539146423
##### [0:83] Tested against 2 ######
Initial alpha-CROWN verified for label 2 with bound 1.5541800260543823
Image 83 label 2 verification end, final lower bound 1.5541800260543823, upper bound inf, time: 0.0004184246063232422
83 1.5541800260543823
##### [0:83] Tested against 6 ######
Initial alpha-CROWN verified for label 6 with bound 2.269852876663208
Image 83 label 6 verification end, final lower bound 2.269852876663208, upper bound inf, time: 0.0004069805145263672
83 2.269852876663208
##### [0:83] Tested against 9 ######
groundtruth label, skip!
Result: image 83 verification success (with branch and bound)!
Wall time: 212.4228377342224

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 1): [83]
verification failure idx (total 0): []
final verified acc: 100.0%[1]
verifier is called on 1 examples.
total verified: 1
mean time [cnt:1] (excluding attack success): 210.7797932624817
