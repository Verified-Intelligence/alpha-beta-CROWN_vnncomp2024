Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_cnn_a_mix.model
  name: cnn_4layer
data:
  start: 164
  end: 165
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR_SDP
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.00784313725
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 4096
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 200
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:03:13 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Flatten()
  (5): Linear(in_features=2048, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([200, 3, 32, 32]) torch.Size([200]) torch.Size([200])
X range: tensor(2.1256) tensor(-1.9889) tensor(-0.0131)
############################
epsilon after preprocessing: tensor([[[[0.0317]],

         [[0.0322]],

         [[0.0300]]]]), data_max = tensor([[[[2.0587]],

         [[2.1256]],

         [[2.1154]]]]), data_min = tensor([[[[-1.9889]],

         [[-1.9807]],

         [[-1.7076]]]])
Task length: 1
saving results to Verified_ret_[cnn_4layer]_start=164_end=165_iter=20_b=4096_timeout=200_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 164 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 5, correct label 5, image norm 1927.1124267578125, logits tensor([-27.8771, -31.3601, -24.5739, -25.3679, -26.6531, -23.5427, -27.7355,
        -26.0212, -30.0260, -30.4284], device='cuda:0',
       grad_fn=<SelectBackward>)
Model prediction is: tensor([[-27.8771, -31.3601, -24.5739, -25.3679, -26.6531, -23.5427, -27.7355,
         -26.0212, -30.0260, -30.4284]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 1.1201,  3.2130, -1.6694,  0.5096,  0.1008,  0.6979, -0.4838,  2.8198,
          2.5321]], device='cuda:0') None
best_l after optimization: -10.722243309020996 with beta sum per layer: []
alpha/beta optimization time: 7.80588173866272
initial alpha-CROWN bounds: tensor([[ 1.3640,  3.4680, -1.4749,  0.5973,  0.3005,  0.8812, -0.2711,  3.0511,
          2.8061]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-1.4749, device='cuda:0', grad_fn=<MinBackward1>)
##### [0:164] Tested against 2 ######
Model prediction is: tensor([[-27.8771, -31.3601, -24.5739, -25.3679, -26.6531, -23.5427, -27.7355,
         -26.0212, -30.0260, -30.4284]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 16, 16]) != torch.Size([2, 9, 1, 16, 16, 16]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 8, 8]) != torch.Size([2, 9, 1, 32, 8, 8]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 16, 16])
1 /11 torch.Size([1, 32, 8, 8])
2 /21 torch.Size([1, 100])
best_l after optimization: 1.4746243953704834 with beta sum per layer: []
alpha/beta optimization time: 2.158594846725464
alpha-CROWN with fixed intermediate bounds: tensor([[-1.4746]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-1.4746243953704834
layer 0 size torch.Size([4096]) unstable 940
layer 1 size torch.Size([2048]) unstable 329
layer 2 size torch.Size([100]) unstable 44
-----------------
# of unstable neurons: 1313
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 16, 16]) pre split depth:  8
batch:  torch.Size([1, 16, 16, 16]) post split depth:  8
splitting decisions: 
split level 0: [2, 15] 
split level 1: [2, 8] 
split level 2: [2, 92] 
split level 3: [2, 22] 
split level 4: [2, 72] 
split level 5: [2, 31] 
split level 6: [2, 47] 
split level 7: [2, 7] 
regular batch size: 2*128, diving batch size 1*0
best_l after optimization: -38.87751388549805 with beta sum per layer: [0.0, 0.0, 85.07523345947266]
alpha/beta optimization time: 0.2969076633453369
This batch time : update_bounds func: 0.3396	 prepare: 0.0182	 bound: 0.2972	 transfer: 0.0084	 finalize: 0.0149
Accumulated time: update_bounds func: 0.3396	 prepare: 0.0182	 bound: 0.2972	 transfer: 0.0084	 finalize: 0.0149
batch bounding time:  0.3399045467376709
Current worst splitting domains [lb, ub] (depth):
[-0.79099,   inf] (9), [-0.78570,   inf] (9), [-0.77864,   inf] (9), [-0.77527,   inf] (9), [-0.77505,   inf] (9), [-0.76608,   inf] (9), [-0.76471,   inf] (9), [-0.75675,   inf] (9), [-0.65761,   inf] (9), [-0.65558,   inf] (9), [-0.64048,   inf] (9), [-0.63726,   inf] (9), [-0.63126,   inf] (9), [-0.62652,   inf] (9), [-0.60786,   inf] (9), [-0.60366,   inf] (9), [-0.40165,   inf] (9), [-0.40038,   inf] (9), [-0.39829,   inf] (9), [-0.37110,   inf] (9), 
length of domains: 72
Total time: 0.6447	 pickout: 0.0009	 decision: 0.2685	 get_bound: 0.3718	 add_domain: 0.0034
Current lb:-0.7909868955612183
256 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.7075159549713135

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([72, 16, 16, 16]) pre split depth:  2
batch:  torch.Size([72, 16, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [2, 87] [2, 87] [2, 87] [2, 87] [2, 87] [2, 87] [2, 87] [2, 87] [2, 87] [2, 87] 
split level 1: [2, 71] [2, 71] [2, 71] [2, 71] [2, 71] [2, 71] [2, 71] [2, 71] [2, 71] [2, 71] 
regular batch size: 2*144, diving batch size 1*0
best_l after optimization: 11.031465530395508 with beta sum per layer: [0.0, 2.724796772003174, 128.34121704101562]
alpha/beta optimization time: 0.2923929691314697
This batch time : update_bounds func: 0.3573	 prepare: 0.0253	 bound: 0.2927	 transfer: 0.0148	 finalize: 0.0234
Accumulated time: update_bounds func: 0.6969	 prepare: 0.0436	 bound: 0.5899	 transfer: 0.0148	 finalize: 0.0383
batch bounding time:  0.35780882835388184
Current worst splitting domains [lb, ub] (depth):
[-0.74419,   inf] (12), [-0.73950,   inf] (12), [-0.73217,   inf] (12), [-0.72871,   inf] (12), [-0.72831,   inf] (12), [-0.71958,   inf] (12), [-0.71832,   inf] (12), [-0.71024,   inf] (12), [-0.65666,   inf] (12), [-0.64230,   inf] (12), [-0.64128,   inf] (12), [-0.63783,   inf] (12), [-0.63112,   inf] (12), [-0.62235,   inf] (12), [-0.62010,   inf] (12), [-0.60520,   inf] (12), [-0.60439,   inf] (12), [-0.60241,   inf] (12), [-0.58548,   inf] (12), [-0.58113,   inf] (12), 
length of domains: 104
Total time: 0.4400	 pickout: 0.0106	 decision: 0.0456	 get_bound: 0.3771	 add_domain: 0.0067
Current lb:-0.7441927194595337
544 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.149296045303345

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([104, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([104, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 4] [2, 4] [2, 4] [2, 4] [2, 4] [2, 4] [2, 4] [2, 4] [2, 4] [2, 4] 
regular batch size: 2*104, diving batch size 1*0
best_l after optimization: 24.85971450805664 with beta sum per layer: [0.0, 7.393050193786621, 68.30333709716797]
alpha/beta optimization time: 0.3050267696380615
This batch time : update_bounds func: 0.3547	 prepare: 0.0287	 bound: 0.3054	 transfer: 0.0030	 finalize: 0.0171
Accumulated time: update_bounds func: 1.0516	 prepare: 0.0722	 bound: 0.8953	 transfer: 0.0030	 finalize: 0.0554
batch bounding time:  0.35504150390625
Current worst splitting domains [lb, ub] (depth):
[-0.73025,   inf] (14), [-0.72525,   inf] (14), [-0.71685,   inf] (14), [-0.71338,   inf] (14), [-0.71322,   inf] (14), [-0.70466,   inf] (14), [-0.70282,   inf] (14), [-0.69467,   inf] (14), [-0.63686,   inf] (14), [-0.62229,   inf] (14), [-0.61969,   inf] (14), [-0.61656,   inf] (14), [-0.60873,   inf] (14), [-0.59999,   inf] (14), [-0.59627,   inf] (14), [-0.58867,   inf] (14), [-0.58447,   inf] (14), [-0.58287,   inf] (14), [-0.56932,   inf] (14), [-0.56358,   inf] (14), 
length of domains: 141
Total time: 0.4426	 pickout: 0.0202	 decision: 0.0588	 get_bound: 0.3554	 add_domain: 0.0082
Current lb:-0.7302499413490295
752 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.593641042709351

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([141, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([141, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 538] [2, 50] [2, 90] [1, 1146] [2, 90] [1, 1505] [1, 1505] [1, 1505] [1, 538] [1, 1146] 
regular batch size: 2*141, diving batch size 1*0
best_l after optimization: 51.528167724609375 with beta sum per layer: [0.0, 32.18061065673828, 82.44314575195312]
alpha/beta optimization time: 0.3098447322845459
This batch time : update_bounds func: 0.3702	 prepare: 0.0395	 bound: 0.3102	 transfer: 0.0041	 finalize: 0.0157
Accumulated time: update_bounds func: 1.4218	 prepare: 0.1117	 bound: 1.2055	 transfer: 0.0041	 finalize: 0.0711
batch bounding time:  0.3705103397369385
Current worst splitting domains [lb, ub] (depth):
[-0.72178,   inf] (16), [-0.71725,   inf] (16), [-0.70982,   inf] (16), [-0.70828,   inf] (16), [-0.70454,   inf] (16), [-0.70289,   inf] (16), [-0.69602,   inf] (16), [-0.69321,   inf] (16), [-0.69101,   inf] (16), [-0.68530,   inf] (16), [-0.68452,   inf] (16), [-0.68220,   inf] (16), [-0.67511,   inf] (16), [-0.62097,   inf] (16), [-0.61548,   inf] (16), [-0.61036,   inf] (16), [-0.60728,   inf] (16), [-0.60387,   inf] (16), [-0.60191,   inf] (16), [-0.59614,   inf] (16), 
length of domains: 233
Total time: 0.4829	 pickout: 0.0277	 decision: 0.0701	 get_bound: 0.3709	 add_domain: 0.0143
Current lb:-0.721778392791748
1034 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.07877516746521

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([233, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([233, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 50] [2, 90] [2, 50] [1, 1146] [1, 1508] [1, 1505] [1, 1505] [2, 50] [1, 1146] [2, 50] 
regular batch size: 2*233, diving batch size 1*0
best_l after optimization: 102.08496856689453 with beta sum per layer: [0.0, 94.25025939941406, 124.60186004638672]
alpha/beta optimization time: 0.3638617992401123
This batch time : update_bounds func: 0.4552	 prepare: 0.0446	 bound: 0.3642	 transfer: 0.0185	 finalize: 0.0268
Accumulated time: update_bounds func: 1.8770	 prepare: 0.1563	 bound: 1.5697	 transfer: 0.0185	 finalize: 0.0979
batch bounding time:  0.45573902130126953
Current worst splitting domains [lb, ub] (depth):
[-0.71380,   inf] (18), [-0.70932,   inf] (18), [-0.70158,   inf] (18), [-0.69902,   inf] (18), [-0.69585,   inf] (18), [-0.69221,   inf] (18), [-0.69026,   inf] (18), [-0.68532,   inf] (18), [-0.68488,   inf] (18), [-0.68409,   inf] (18), [-0.68017,   inf] (18), [-0.67702,   inf] (18), [-0.67697,   inf] (18), [-0.67357,   inf] (18), [-0.67338,   inf] (18), [-0.67221,   inf] (18), [-0.66946,   inf] (18), [-0.66542,   inf] (18), [-0.66516,   inf] (18), [-0.65633,   inf] (18), 
length of domains: 407
Total time: 0.6477	 pickout: 0.0337	 decision: 0.0857	 get_bound: 0.4564	 add_domain: 0.0719
Current lb:-0.7138020396232605
1500 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.729969263076782

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([407, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([407, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1146] [1, 1508] [1, 1146] [1, 1508] [2, 50] [2, 50] [1, 1508] [2, 50] [1, 1146] [2, 50] 
regular batch size: 2*407, diving batch size 1*0
best_l after optimization: 161.78050231933594 with beta sum per layer: [0.0, 234.55970764160156, 222.5496368408203]
alpha/beta optimization time: 0.4999983310699463
This batch time : update_bounds func: 0.6490	 prepare: 0.0764	 bound: 0.5004	 transfer: 0.0236	 finalize: 0.0467
Accumulated time: update_bounds func: 2.5260	 prepare: 0.2327	 bound: 2.0701	 transfer: 0.0236	 finalize: 0.1447
batch bounding time:  0.6497561931610107
Current worst splitting domains [lb, ub] (depth):
[-0.70476,   inf] (20), [-0.70142,   inf] (20), [-0.69677,   inf] (20), [-0.69253,   inf] (20), [-0.69056,   inf] (20), [-0.68779,   inf] (20), [-0.68462,   inf] (20), [-0.68406,   inf] (20), [-0.68133,   inf] (20), [-0.67873,   inf] (20), [-0.67720,   inf] (20), [-0.67587,   inf] (20), [-0.67536,   inf] (20), [-0.67210,   inf] (20), [-0.66882,   inf] (20), [-0.66834,   inf] (20), [-0.66733,   inf] (20), [-0.66521,   inf] (20), [-0.66413,   inf] (20), [-0.66383,   inf] (20), 
length of domains: 693
Total time: 0.8902	 pickout: 0.0596	 decision: 0.1342	 get_bound: 0.6509	 add_domain: 0.0455
Current lb:-0.7047553658485413
2314 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.627005100250244

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([693, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([693, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 90] [1, 538] [2, 90] [2, 90] [2, 50] [1, 1146] [2, 90] [2, 90] [2, 50] [1, 538] 
regular batch size: 2*693, diving batch size 1*0
best_l after optimization: 246.87680053710938 with beta sum per layer: [0.18093793094158173, 550.4974975585938, 397.7186279296875]
alpha/beta optimization time: 0.7483022212982178
This batch time : update_bounds func: 1.0152	 prepare: 0.1348	 bound: 0.7487	 transfer: 0.0459	 finalize: 0.0825
Accumulated time: update_bounds func: 3.5412	 prepare: 0.3676	 bound: 2.8188	 transfer: 0.0459	 finalize: 0.2272
batch bounding time:  1.0164613723754883
Current worst splitting domains [lb, ub] (depth):
[-0.69701,   inf] (22), [-0.69380,   inf] (22), [-0.68899,   inf] (22), [-0.68489,   inf] (22), [-0.68266,   inf] (22), [-0.68079,   inf] (22), [-0.67913,   inf] (22), [-0.67694,   inf] (22), [-0.67636,   inf] (22), [-0.67311,   inf] (22), [-0.67046,   inf] (22), [-0.67002,   inf] (22), [-0.66952,   inf] (22), [-0.66816,   inf] (22), [-0.66762,   inf] (22), [-0.66408,   inf] (22), [-0.66113,   inf] (22), [-0.66057,   inf] (22), [-0.65955,   inf] (22), [-0.65738,   inf] (22), 
length of domains: 1162
Total time: 1.4782	 pickout: 0.1156	 decision: 0.2643	 get_bound: 1.0185	 add_domain: 0.0799
Current lb:-0.6970078349113464
3700 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.117948293685913

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1162, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1162, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1508] [1, 1146] [1, 614] [1, 614] [1, 538] [2, 97] [1, 1141] [1, 1508] [2, 37] [1, 538] 
regular batch size: 2*1162, diving batch size 1*0
best_l after optimization: 359.118408203125 with beta sum per layer: [0.5394107103347778, 1265.172607421875, 705.6702270507812]
alpha/beta optimization time: 1.142716884613037
This batch time : update_bounds func: 1.6299	 prepare: 0.2225	 bound: 1.1431	 transfer: 0.0735	 finalize: 0.1350
Accumulated time: update_bounds func: 5.1711	 prepare: 0.5901	 bound: 3.9619	 transfer: 0.0735	 finalize: 0.3622
batch bounding time:  1.6319890022277832
Current worst splitting domains [lb, ub] (depth):
[-0.68922,   inf] (24), [-0.68528,   inf] (24), [-0.68133,   inf] (24), [-0.67724,   inf] (24), [-0.67704,   inf] (24), [-0.67449,   inf] (24), [-0.67203,   inf] (24), [-0.67144,   inf] (24), [-0.66933,   inf] (24), [-0.66921,   inf] (24), [-0.66913,   inf] (24), [-0.66565,   inf] (24), [-0.66496,   inf] (24), [-0.66475,   inf] (24), [-0.66448,   inf] (24), [-0.66245,   inf] (24), [-0.66176,   inf] (24), [-0.66154,   inf] (24), [-0.66110,   inf] (24), [-0.66024,   inf] (24), 
length of domains: 1944
Total time: 2.4000	 pickout: 0.1920	 decision: 0.4296	 get_bound: 1.6355	 add_domain: 0.1430
Current lb:-0.6892185807228088
6024 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.53850245475769

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1944, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1944, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 614] [2, 97] [1, 1508] [1, 1508] [2, 97] [1, 614] [1, 1146] [1, 538] [1, 1899] [2, 25] 
regular batch size: 2*1944, diving batch size 1*0
best_l after optimization: 539.5301513671875 with beta sum per layer: [1.9236760139465332, 2629.96240234375, 1188.28173828125]
alpha/beta optimization time: 1.853750467300415
This batch time : update_bounds func: 2.7328	 prepare: 0.4500	 bound: 1.8542	 transfer: 0.1162	 finalize: 0.3028
Accumulated time: update_bounds func: 7.9039	 prepare: 1.0400	 bound: 5.8161	 transfer: 0.1162	 finalize: 0.6650
batch bounding time:  2.7366669178009033
Current worst splitting domains [lb, ub] (depth):
[-0.68152,   inf] (26), [-0.67644,   inf] (26), [-0.67340,   inf] (26), [-0.66940,   inf] (26), [-0.66940,   inf] (26), [-0.66812,   inf] (26), [-0.66669,   inf] (26), [-0.66385,   inf] (26), [-0.66361,   inf] (26), [-0.66167,   inf] (26), [-0.66148,   inf] (26), [-0.65891,   inf] (26), [-0.65732,   inf] (26), [-0.65699,   inf] (26), [-0.65694,   inf] (26), [-0.65684,   inf] (26), [-0.65659,   inf] (26), [-0.65532,   inf] (26), [-0.65392,   inf] (26), [-0.65351,   inf] (26), 
length of domains: 3115
Total time: 4.2025	 pickout: 0.3376	 decision: 0.8010	 get_bound: 2.7431	 add_domain: 0.3208
Current lb:-0.681523859500885
9912 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.778606176376343

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3115, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([3115, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 25] [1, 614] [2, 25] [2, 25] [2, 25] [1, 614] [1, 1141] [1, 614] [1, 614] [1, 1508] 
regular batch size: 2*3115, diving batch size 1*0
best_l after optimization: 822.5068359375 with beta sum per layer: [6.571990966796875, 4818.6923828125, 1861.173583984375]
alpha/beta optimization time: 2.8886401653289795
This batch time : update_bounds func: 4.5051	 prepare: 0.6264	 bound: 2.8895	 transfer: 0.2139	 finalize: 0.6694
Accumulated time: update_bounds func: 12.4090	 prepare: 1.6665	 bound: 8.7056	 transfer: 0.2139	 finalize: 1.3345
batch bounding time:  4.51129674911499
Current worst splitting domains [lb, ub] (depth):
[-0.67417,   inf] (28), [-0.66894,   inf] (28), [-0.66603,   inf] (28), [-0.66209,   inf] (28), [-0.66181,   inf] (28), [-0.66064,   inf] (28), [-0.65911,   inf] (28), [-0.65781,   inf] (28), [-0.65624,   inf] (28), [-0.65600,   inf] (28), [-0.65416,   inf] (28), [-0.65359,   inf] (28), [-0.65198,   inf] (28), [-0.65036,   inf] (28), [-0.64962,   inf] (28), [-0.64938,   inf] (28), [-0.64935,   inf] (28), [-0.64897,   inf] (28), [-0.64777,   inf] (28), [-0.64776,   inf] (28), 
length of domains: 4882
Total time: 6.7342	 pickout: 0.5551	 decision: 1.1302	 get_bound: 4.5220	 add_domain: 0.5269
Current lb:-0.6741706132888794
16142 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 21.5754075050354

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4096, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([4096, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 97] [2, 25] [2, 97] [2, 97] [2, 97] [2, 25] [2, 25] [2, 25] [2, 25] [2, 25] 
regular batch size: 2*4096, diving batch size 1*0
best_l after optimization: 1290.862548828125 with beta sum per layer: [13.915047645568848, 6590.005859375, 2272.157470703125]
alpha/beta optimization time: 3.7364673614501953
This batch time : update_bounds func: 5.7005	 prepare: 0.8176	 bound: 3.7371	 transfer: 0.3050	 finalize: 0.8194
Accumulated time: update_bounds func: 18.1095	 prepare: 2.4840	 bound: 12.4427	 transfer: 0.3050	 finalize: 2.1539
batch bounding time:  5.710286855697632
Current worst splitting domains [lb, ub] (depth):
[-0.66537,   inf] (30), [-0.66164,   inf] (30), [-0.65722,   inf] (30), [-0.65334,   inf] (30), [-0.65327,   inf] (30), [-0.65274,   inf] (30), [-0.65181,   inf] (30), [-0.65025,   inf] (30), [-0.64894,   inf] (30), [-0.64882,   inf] (30), [-0.64532,   inf] (30), [-0.64506,   inf] (30), [-0.64452,   inf] (30), [-0.64351,   inf] (30), [-0.64201,   inf] (30), [-0.64201,   inf] (30), [-0.64171,   inf] (30), [-0.64063,   inf] (30), [-0.64041,   inf] (30), [-0.64038,   inf] (30), 
length of domains: 7917
Total time: 9.4883	 pickout: 0.9931	 decision: 1.9545	 get_bound: 5.7258	 add_domain: 0.8149
Current lb:-0.6653711199760437
24334 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 31.14701008796692

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4096, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([4096, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 37] [2, 37] [2, 37] [2, 37] [2, 37] [2, 37] [2, 97] [2, 37] [2, 97] [2, 37] 
regular batch size: 2*4096, diving batch size 1*0
best_l after optimization: 1701.693115234375 with beta sum per layer: [17.13776969909668, 6387.25439453125, 2115.3896484375]
alpha/beta optimization time: 3.729626178741455
This batch time : update_bounds func: 5.7445	 prepare: 0.8075	 bound: 3.7301	 transfer: 0.2799	 finalize: 0.9055
Accumulated time: update_bounds func: 23.8540	 prepare: 3.2916	 bound: 16.1727	 transfer: 0.2799	 finalize: 3.0594
batch bounding time:  5.753067970275879
Current worst splitting domains [lb, ub] (depth):
[-0.65840,   inf] (32), [-0.65459,   inf] (32), [-0.65027,   inf] (32), [-0.64636,   inf] (32), [-0.64624,   inf] (32), [-0.64547,   inf] (32), [-0.64339,   inf] (32), [-0.64297,   inf] (32), [-0.64187,   inf] (32), [-0.64048,   inf] (32), [-0.63834,   inf] (32), [-0.63740,   inf] (32), [-0.63724,   inf] (32), [-0.63629,   inf] (32), [-0.63478,   inf] (32), [-0.63368,   inf] (32), [-0.63356,   inf] (32), [-0.63333,   inf] (32), [-0.63329,   inf] (32), [-0.63314,   inf] (32), 
length of domains: 10834
Total time: 8.8853	 pickout: 0.7636	 decision: 1.7313	 get_bound: 5.7702	 add_domain: 0.6202
Current lb:-0.6584049463272095
32526 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 40.1261932849884

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4096, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([4096, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 29] [1, 1505] [1, 29] [1, 29] [1, 1505] [1, 29] [2, 37] [1, 29] [1, 1505] [2, 37] 
regular batch size: 2*4096, diving batch size 1*0
best_l after optimization: 2369.38623046875 with beta sum per layer: [0.12217828631401062, 7862.978515625, 1843.550048828125]
alpha/beta optimization time: 3.835918426513672
This batch time : update_bounds func: 6.3735	 prepare: 1.2155	 bound: 3.8365	 transfer: 0.2836	 finalize: 0.7696
Accumulated time: update_bounds func: 30.2275	 prepare: 4.5070	 bound: 20.0092	 transfer: 0.2836	 finalize: 3.8289
batch bounding time:  6.382327556610107
Current worst splitting domains [lb, ub] (depth):
[-0.65264,   inf] (34), [-0.64591,   inf] (34), [-0.64454,   inf] (34), [-0.64371,   inf] (34), [-0.64095,   inf] (34), [-0.64049,   inf] (34), [-0.63934,   inf] (34), [-0.63751,   inf] (34), [-0.63716,   inf] (34), [-0.63637,   inf] (34), [-0.63531,   inf] (34), [-0.63417,   inf] (34), [-0.63352,   inf] (34), [-0.63271,   inf] (34), [-0.63249,   inf] (34), [-0.63117,   inf] (34), [-0.63009,   inf] (34), [-0.62899,   inf] (34), [-0.62895,   inf] (34), [-0.62889,   inf] (34), 
length of domains: 13865
Total time: 10.0581	 pickout: 0.9321	 decision: 2.0869	 get_bound: 6.3984	 add_domain: 0.6407
Current lb:-0.6526376605033875
40718 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 50.27180218696594

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4096, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([4096, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1571] [1, 1571] [1, 1571] [1, 1571] [1, 1571] [1, 1571] [1, 1571] [1, 1571] [1, 1571] [1, 29] 
regular batch size: 2*4096, diving batch size 1*0
best_l after optimization: 2927.619140625 with beta sum per layer: [0.7359277009963989, 7433.2919921875, 1368.983154296875]
alpha/beta optimization time: 3.7207515239715576
This batch time : update_bounds func: 5.6670	 prepare: 0.8159	 bound: 3.7212	 transfer: 0.2830	 finalize: 0.8227
Accumulated time: update_bounds func: 35.8946	 prepare: 5.3230	 bound: 23.7304	 transfer: 0.2830	 finalize: 4.6516
batch bounding time:  5.6755287647247314
Current worst splitting domains [lb, ub] (depth):
[-0.64783,   inf] (36), [-0.64065,   inf] (36), [-0.63966,   inf] (36), [-0.63853,   inf] (36), [-0.63584,   inf] (36), [-0.63549,   inf] (36), [-0.63443,   inf] (36), [-0.63227,   inf] (36), [-0.63200,   inf] (36), [-0.63011,   inf] (36), [-0.62951,   inf] (36), [-0.62862,   inf] (36), [-0.62756,   inf] (36), [-0.62745,   inf] (36), [-0.62633,   inf] (36), [-0.62480,   inf] (36), [-0.62371,   inf] (36), [-0.62354,   inf] (36), [-0.62324,   inf] (36), [-0.62271,   inf] (36), 
length of domains: 17343
Total time: 9.3765	 pickout: 0.7072	 decision: 1.9362	 get_bound: 5.6924	 add_domain: 1.0406
Current lb:-0.6478292942047119
48910 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 59.729408740997314

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4096, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([4096, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1899] [1, 29] [1, 1899] [1, 29] [1, 1899] [1, 1899] [1, 1899] [1, 29] [1, 1505] [1, 29] 
regular batch size: 2*4096, diving batch size 1*0
best_l after optimization: 3213.18212890625 with beta sum per layer: [0.39580005407333374, 7325.5244140625, 1104.8267822265625]
alpha/beta optimization time: 4.0867226123809814
This batch time : update_bounds func: 6.4765	 prepare: 1.2179	 bound: 4.0872	 transfer: 0.2850	 finalize: 0.8621
Accumulated time: update_bounds func: 42.3711	 prepare: 6.5408	 bound: 27.8176	 transfer: 0.2850	 finalize: 5.5137
batch bounding time:  6.48520302772522
Current worst splitting domains [lb, ub] (depth):
[-0.63919,   inf] (38), [-0.63781,   inf] (38), [-0.63526,   inf] (38), [-0.63312,   inf] (38), [-0.63068,   inf] (38), [-0.62967,   inf] (38), [-0.62691,   inf] (38), [-0.62686,   inf] (38), [-0.62686,   inf] (38), [-0.62584,   inf] (38), [-0.62580,   inf] (38), [-0.62558,   inf] (38), [-0.62471,   inf] (38), [-0.62428,   inf] (38), [-0.62363,   inf] (38), [-0.62323,   inf] (38), [-0.62312,   inf] (38), [-0.62277,   inf] (38), [-0.62148,   inf] (38), [-0.62103,   inf] (38), 
length of domains: 21180
Total time: 10.3529	 pickout: 0.7174	 decision: 1.9725	 get_bound: 6.5022	 add_domain: 1.1608
Current lb:-0.6391893029212952
57102 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 70.16481328010559

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4096, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([4096, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1891] [1, 1891] [1, 1899] [1, 1899] [1, 1891] [1, 1891] [1, 1891] [1, 1907] [1, 1899] [1, 1978] 
regular batch size: 2*4096, diving batch size 1*0
best_l after optimization: 3511.42333984375 with beta sum per layer: [1.6791355609893799, 7132.7607421875, 852.416748046875]
alpha/beta optimization time: 4.0689966678619385
This batch time : update_bounds func: 6.1326	 prepare: 0.8126	 bound: 4.0695	 transfer: 0.2818	 finalize: 0.9462
Accumulated time: update_bounds func: 48.5036	 prepare: 7.3535	 bound: 31.8871	 transfer: 0.2818	 finalize: 6.4599
batch bounding time:  6.141098976135254
Current worst splitting domains [lb, ub] (depth):
[-0.63244,   inf] (40), [-0.62988,   inf] (40), [-0.62771,   inf] (40), [-0.62759,   inf] (40), [-0.62672,   inf] (40), [-0.62534,   inf] (40), [-0.62457,   inf] (40), [-0.62406,   inf] (40), [-0.62323,   inf] (40), [-0.62179,   inf] (40), [-0.62009,   inf] (40), [-0.61998,   inf] (40), [-0.61971,   inf] (40), [-0.61961,   inf] (40), [-0.61932,   inf] (40), [-0.61916,   inf] (40), [-0.61818,   inf] (40), [-0.61802,   inf] (40), [-0.61775,   inf] (40), [-0.61773,   inf] (40), 
length of domains: 25235
Total time: 9.4900	 pickout: 0.7149	 decision: 1.8058	 get_bound: 6.1572	 add_domain: 0.8120
Current lb:-0.632440447807312
65294 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 79.73364591598511

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4096, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([4096, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1505] [1, 1907] [1, 1505] [1, 1978] [1, 1914] [1, 1914] [1, 474] [1, 1505] [1, 474] [1, 1505] 
regular batch size: 2*4096, diving batch size 1*0
best_l after optimization: 3893.434814453125 with beta sum per layer: [14.17808723449707, 8211.970703125, 466.3624267578125]
alpha/beta optimization time: 4.110748529434204
This batch time : update_bounds func: 6.2726	 prepare: 0.8124	 bound: 4.1112	 transfer: 0.2838	 finalize: 1.0419
Accumulated time: update_bounds func: 54.7762	 prepare: 8.1659	 bound: 35.9983	 transfer: 0.2838	 finalize: 7.5018
batch bounding time:  6.281270980834961
Current worst splitting domains [lb, ub] (depth):
[-0.62416,   inf] (42), [-0.62350,   inf] (42), [-0.62267,   inf] (42), [-0.62194,   inf] (42), [-0.62132,   inf] (42), [-0.62007,   inf] (42), [-0.61972,   inf] (42), [-0.61948,   inf] (42), [-0.61887,   inf] (42), [-0.61720,   inf] (42), [-0.61575,   inf] (42), [-0.61459,   inf] (42), [-0.61355,   inf] (42), [-0.61349,   inf] (42), [-0.61343,   inf] (42), [-0.61241,   inf] (42), [-0.61234,   inf] (42), [-0.61194,   inf] (42), [-0.61174,   inf] (42), [-0.61150,   inf] (42), 
length of domains: 29298
Total time: 9.6805	 pickout: 0.7051	 decision: 1.8412	 get_bound: 6.2970	 add_domain: 0.8373
Current lb:-0.6241573691368103
73486 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 89.49545669555664

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4096, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([4096, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1907] [1, 1505] [1, 1907] [1, 1907] [1, 1907] [1, 1907] [1, 1907] [1, 1907] [1, 1907] [1, 1907] 
regular batch size: 2*4096, diving batch size 1*0
best_l after optimization: 4193.2275390625 with beta sum per layer: [43.5561637878418, 9973.4091796875, 124.0867919921875]
alpha/beta optimization time: 4.157368183135986
This batch time : update_bounds func: 6.3465	 prepare: 0.8102	 bound: 4.1578	 transfer: 0.2825	 finalize: 1.0718
Accumulated time: update_bounds func: 61.1227	 prepare: 8.9761	 bound: 40.1561	 transfer: 0.2825	 finalize: 8.5736
batch bounding time:  6.355356216430664
Current worst splitting domains [lb, ub] (depth):
[-0.61716,   inf] (44), [-0.61561,   inf] (44), [-0.61513,   inf] (44), [-0.61489,   inf] (44), [-0.61475,   inf] (44), [-0.61321,   inf] (44), [-0.61321,   inf] (44), [-0.61300,   inf] (44), [-0.61236,   inf] (44), [-0.61231,   inf] (44), [-0.61011,   inf] (44), [-0.60833,   inf] (44), [-0.60781,   inf] (44), [-0.60637,   inf] (44), [-0.60611,   inf] (44), [-0.60611,   inf] (44), [-0.60542,   inf] (44), [-0.60526,   inf] (44), [-0.60485,   inf] (44), [-0.60445,   inf] (44), 
length of domains: 33349
Total time: 9.8657	 pickout: 0.7224	 decision: 1.9137	 get_bound: 6.3714	 add_domain: 0.8583
Current lb:-0.617162823677063
81678 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 99.44443345069885

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4096, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([4096, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1978] [1, 1891] [1, 1978] [1, 1978] [1, 1891] [1, 1978] [1, 1505] [1, 1891] [1, 1978] [1, 1891] 
regular batch size: 2*4096, diving batch size 1*0
best_l after optimization: 4313.935546875 with beta sum per layer: [52.579986572265625, 8776.8544921875, 52.60585403442383]
alpha/beta optimization time: 4.166814804077148
This batch time : update_bounds func: 6.5137	 prepare: 0.8183	 bound: 4.1672	 transfer: 0.2809	 finalize: 1.2240
Accumulated time: update_bounds func: 67.6364	 prepare: 9.7944	 bound: 44.3233	 transfer: 0.2809	 finalize: 9.7976
batch bounding time:  6.525680065155029
Current worst splitting domains [lb, ub] (depth):
[-0.60959,   inf] (46), [-0.60919,   inf] (46), [-0.60742,   inf] (46), [-0.60724,   inf] (46), [-0.60714,   inf] (46), [-0.60659,   inf] (46), [-0.60541,   inf] (46), [-0.60508,   inf] (46), [-0.60477,   inf] (46), [-0.60472,   inf] (46), [-0.60460,   inf] (46), [-0.60440,   inf] (46), [-0.60433,   inf] (46), [-0.60307,   inf] (46), [-0.60238,   inf] (46), [-0.60212,   inf] (46), [-0.60212,   inf] (46), [-0.60203,   inf] (46), [-0.60177,   inf] (46), [-0.60117,   inf] (46), 
length of domains: 37378
Total time: 10.1765	 pickout: 0.7137	 decision: 1.9757	 get_bound: 6.5463	 add_domain: 0.9408
Current lb:-0.6095894575119019
89870 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 109.7043845653534

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4096, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([4096, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 474] [1, 1541] [1, 474] [1, 474] [1, 1541] [1, 1541] [1, 474] [1, 474] [1, 1541] [1, 1541] 
regular batch size: 2*4096, diving batch size 1*0
best_l after optimization: 4380.88525390625 with beta sum per layer: [53.83042526245117, 8084.9638671875, 19.015810012817383]
alpha/beta optimization time: 4.171670913696289
This batch time : update_bounds func: 5.8184	 prepare: 0.8348	 bound: 4.1721	 transfer: 0.2866	 finalize: 0.5006
Accumulated time: update_bounds func: 73.4548	 prepare: 10.6292	 bound: 48.4955	 transfer: 0.2866	 finalize: 10.2982
batch bounding time:  5.826935291290283
Current worst splitting domains [lb, ub] (depth):
[-0.60552,   inf] (48), [-0.60392,   inf] (48), [-0.60322,   inf] (48), [-0.60276,   inf] (48), [-0.60188,   inf] (48), [-0.60131,   inf] (48), [-0.60087,   inf] (48), [-0.60079,   inf] (48), [-0.60051,   inf] (48), [-0.60017,   inf] (48), [-0.59946,   inf] (48), [-0.59934,   inf] (48), [-0.59912,   inf] (48), [-0.59844,   inf] (48), [-0.59821,   inf] (48), [-0.59786,   inf] (48), [-0.59777,   inf] (48), [-0.59746,   inf] (48), [-0.59675,   inf] (48), [-0.59635,   inf] (48), 
length of domains: 41459
Total time: 10.3211	 pickout: 0.7195	 decision: 2.0817	 get_bound: 5.8426	 add_domain: 1.6773
Current lb:-0.6055161356925964
98062 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 120.12230110168457

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4096, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([4096, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1541] [1, 1978] [1, 219] [1, 1541] [1, 1978] [1, 1978] [1, 219] [1, 219] [1, 219] [1, 1541] 
regular batch size: 2*4096, diving batch size 1*0
best_l after optimization: 4038.1142578125 with beta sum per layer: [61.48427963256836, 7046.65625, 338.6811218261719]
alpha/beta optimization time: 4.166862487792969
This batch time : update_bounds func: 6.8806	 prepare: 0.8424	 bound: 4.1674	 transfer: 0.2886	 finalize: 1.5590
Accumulated time: update_bounds func: 80.3354	 prepare: 11.4716	 bound: 52.6628	 transfer: 0.2886	 finalize: 11.8572
batch bounding time:  6.889723062515259
Current worst splitting domains [lb, ub] (depth):
[-0.60023,   inf] (50), [-0.59746,   inf] (50), [-0.59717,   inf] (50), [-0.59668,   inf] (50), [-0.59488,   inf] (50), [-0.59487,   inf] (50), [-0.59486,   inf] (50), [-0.59463,   inf] (50), [-0.59455,   inf] (50), [-0.59448,   inf] (50), [-0.59397,   inf] (50), [-0.59238,   inf] (50), [-0.59217,   inf] (50), [-0.59213,   inf] (50), [-0.59210,   inf] (50), [-0.59191,   inf] (50), [-0.59184,   inf] (50), [-0.59176,   inf] (50), [-0.59170,   inf] (50), [-0.59133,   inf] (50), 
length of domains: 44950
Total time: 9.9585	 pickout: 0.7315	 decision: 1.3837	 get_bound: 6.9065	 add_domain: 0.9367
Current lb:-0.6002334356307983
106254 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 130.17315292358398

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4096, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([4096, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 219] [1, 660] [1, 1541] [1, 660] [1, 219] [1, 660] [1, 219] [1, 660] [1, 660] [1, 660] 
regular batch size: 2*4096, diving batch size 1*0
best_l after optimization: 4268.0986328125 with beta sum per layer: [53.07280349731445, 7006.14501953125, 140.09503173828125]
alpha/beta optimization time: 4.152320623397827
This batch time : update_bounds func: 6.2491	 prepare: 1.2567	 bound: 4.1528	 transfer: 0.3112	 finalize: 0.5037
Accumulated time: update_bounds func: 86.5844	 prepare: 12.7282	 bound: 56.8157	 transfer: 0.3112	 finalize: 12.3609
batch bounding time:  6.257979154586792
Current worst splitting domains [lb, ub] (depth):
[-0.59394,   inf] (52), [-0.59191,   inf] (52), [-0.58981,   inf] (52), [-0.58927,   inf] (52), [-0.58867,   inf] (52), [-0.58856,   inf] (52), [-0.58757,   inf] (52), [-0.58730,   inf] (52), [-0.58723,   inf] (52), [-0.58721,   inf] (52), [-0.58672,   inf] (52), [-0.58670,   inf] (52), [-0.58662,   inf] (52), [-0.58587,   inf] (52), [-0.58575,   inf] (52), [-0.58500,   inf] (52), [-0.58480,   inf] (52), [-0.58464,   inf] (52), [-0.58463,   inf] (52), [-0.58455,   inf] (52), 
length of domains: 48793
Total time: 11.6343	 pickout: 0.9554	 decision: 2.4916	 get_bound: 6.2756	 add_domain: 1.9117
Current lb:-0.593943178653717
114446 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 141.89856815338135

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4096, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([4096, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 660] [1, 660] [1, 1141] [1, 219] [1, 660] [1, 660] [1, 1541] [1, 1541] [1, 1541] [1, 219] 
regular batch size: 2*4096, diving batch size 1*0
best_l after optimization: 4190.359375 with beta sum per layer: [35.85270690917969, 6747.1220703125, 207.29600524902344]/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:462: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(preprocess_cifar(eps_temp, perturbation=True)).reshape(1,-1,1,1)

alpha/beta optimization time: 4.145688533782959
This batch time : update_bounds func: 6.9042	 prepare: 0.8799	 bound: 4.1462	 transfer: 0.2836	 finalize: 1.5718
Accumulated time: update_bounds func: 93.4887	 prepare: 13.6081	 bound: 60.9619	 transfer: 0.2836	 finalize: 13.9326
batch bounding time:  6.912931442260742
Current worst splitting domains [lb, ub] (depth):
[-0.58649,   inf] (54), [-0.58439,   inf] (54), [-0.58387,   inf] (54), [-0.58320,   inf] (54), [-0.58240,   inf] (54), [-0.58203,   inf] (54), [-0.58202,   inf] (54), [-0.58146,   inf] (54), [-0.58133,   inf] (54), [-0.58117,   inf] (54), [-0.58103,   inf] (54), [-0.58059,   inf] (54), [-0.57982,   inf] (54), [-0.57932,   inf] (54), [-0.57930,   inf] (54), [-0.57924,   inf] (54), [-0.57908,   inf] (54), [-0.57873,   inf] (54), [-0.57872,   inf] (54), [-0.57867,   inf] (54), 
length of domains: 52528
Total time: 10.0406	 pickout: 0.7565	 decision: 1.3972	 get_bound: 6.9305	 add_domain: 0.9564
Current lb:-0.5864920616149902
122638 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 152.0330307483673

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4096, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([4096, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1141] [1, 1141] [1, 219] [2, 77] [1, 1939] [1, 1141] [1, 1141] [1, 1141] [1, 1141] [1, 1141] 
regular batch size: 2*4096, diving batch size 1*0
best_l after optimization: 3597.213623046875 with beta sum per layer: [22.651918411254883, 6210.873046875, 729.2525634765625]
alpha/beta optimization time: 4.1429762840271
This batch time : update_bounds func: 7.0234	 prepare: 0.8802	 bound: 4.1435	 transfer: 0.2861	 finalize: 1.6893
Accumulated time: update_bounds func: 100.5121	 prepare: 14.4884	 bound: 65.1054	 transfer: 0.2861	 finalize: 15.6220
batch bounding time:  7.032172441482544
Current worst splitting domains [lb, ub] (depth):
[-0.58061,   inf] (56), [-0.57848,   inf] (56), [-0.57843,   inf] (56), [-0.57768,   inf] (56), [-0.57638,   inf] (56), [-0.57606,   inf] (56), [-0.57602,   inf] (56), [-0.57592,   inf] (56), [-0.57588,   inf] (56), [-0.57553,   inf] (56), [-0.57545,   inf] (56), [-0.57527,   inf] (56), [-0.57400,   inf] (56), [-0.57398,   inf] (56), [-0.57388,   inf] (56), [-0.57376,   inf] (56), [-0.57340,   inf] (56), [-0.57338,   inf] (56), [-0.57335,   inf] (56), [-0.57319,   inf] (56), 
length of domains: 55357
Total time: 10.0540	 pickout: 0.7370	 decision: 1.3971	 get_bound: 7.0480	 add_domain: 0.8719
Current lb:-0.580605149269104
130830 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 162.19329524040222

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4096, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([4096, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 77] [1, 1141] [1, 1939] [2, 77] [1, 474] [1, 1141] [1, 1939] [1, 1939] [1, 1141] [2, 77] 
regular batch size: 2*4096, diving batch size 1*0
best_l after optimization: 3774.9208984375 with beta sum per layer: [20.21131134033203, 6481.0859375, 498.4169616699219]
alpha/beta optimization time: 4.15239953994751
This batch time : update_bounds func: 6.9527	 prepare: 0.8869	 bound: 4.1528	 transfer: 0.2831	 finalize: 1.6065
Accumulated time: update_bounds func: 107.4648	 prepare: 15.3753	 bound: 69.2582	 transfer: 0.2831	 finalize: 17.2284
batch bounding time:  6.961311340332031
Current worst splitting domains [lb, ub] (depth):
[-0.57580,   inf] (58), [-0.57298,   inf] (58), [-0.57285,   inf] (58), [-0.57252,   inf] (58), [-0.57250,   inf] (58), [-0.57069,   inf] (58), [-0.57066,   inf] (58), [-0.57044,   inf] (58), [-0.57035,   inf] (58), [-0.57030,   inf] (58), [-0.57005,   inf] (58), [-0.56995,   inf] (58), [-0.56994,   inf] (58), [-0.56861,   inf] (58), [-0.56854,   inf] (58), [-0.56847,   inf] (58), [-0.56814,   inf] (58), [-0.56806,   inf] (58), [-0.56784,   inf] (58), [-0.56783,   inf] (58), 
length of domains: 58511
Total time: 10.0530	 pickout: 0.7441	 decision: 1.4016	 get_bound: 6.9764	 add_domain: 0.9307
Current lb:-0.575801432132721
139022 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 172.35591006278992

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4096, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([4096, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1939] [1, 474] [1, 1939] [1, 1141] [2, 77] [1, 1939] [1, 1876] [1, 1939] [1, 1914] [2, 77] 
regular batch size: 2*4096, diving batch size 1*0
best_l after optimization: 3779.85302734375 with beta sum per layer: [22.74633026123047, 6616.0673828125, 459.7428283691406]
alpha/beta optimization time: 4.147337198257446
This batch time : update_bounds func: 5.9258	 prepare: 0.9157	 bound: 4.1478	 transfer: 0.2847	 finalize: 0.5516
Accumulated time: update_bounds func: 113.3906	 prepare: 16.2909	 bound: 73.4060	 transfer: 0.2847	 finalize: 17.7800
batch bounding time:  5.935114145278931
Current worst splitting domains [lb, ub] (depth):
[-0.56999,   inf] (60), [-0.56914,   inf] (60), [-0.56773,   inf] (60), [-0.56704,   inf] (60), [-0.56699,   inf] (60), [-0.56688,   inf] (60), [-0.56640,   inf] (60), [-0.56555,   inf] (60), [-0.56520,   inf] (60), [-0.56514,   inf] (60), [-0.56513,   inf] (60), [-0.56462,   inf] (60), [-0.56446,   inf] (60), [-0.56436,   inf] (60), [-0.56423,   inf] (60), [-0.56394,   inf] (60), [-0.56381,   inf] (60), [-0.56301,   inf] (60), [-0.56300,   inf] (60), [-0.56292,   inf] (60), 
length of domains: 61724
Total time: 10.3789	 pickout: 0.8257	 decision: 2.6138	 get_bound: 5.9522	 add_domain: 0.9872
Current lb:-0.5699939131736755
147214 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 182.85624837875366

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4096, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([4096, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1914] [1, 1939] [1, 1914] [1, 1914] [1, 1939] [1, 1939] [1, 1939] [1, 1914] [1, 1914] [1, 1914] 
regular batch size: 2*4096, diving batch size 1*0
best_l after optimization: 4002.157958984375 with beta sum per layer: [32.769920349121094, 7000.86376953125, 254.83676147460938]
alpha/beta optimization time: 4.147857427597046
This batch time : update_bounds func: 5.9662	 prepare: 0.8964	 bound: 4.1484	 transfer: 0.2888	 finalize: 0.6050
Accumulated time: update_bounds func: 119.3568	 prepare: 17.1874	 bound: 77.5544	 transfer: 0.2888	 finalize: 18.3850
batch bounding time:  5.976526737213135
Current worst splitting domains [lb, ub] (depth):
[-0.56604,   inf] (62), [-0.56378,   inf] (62), [-0.56341,   inf] (62), [-0.56309,   inf] (62), [-0.56159,   inf] (62), [-0.56123,   inf] (62), [-0.56122,   inf] (62), [-0.56119,   inf] (62), [-0.56118,   inf] (62), [-0.56118,   inf] (62), [-0.56065,   inf] (62), [-0.56034,   inf] (62), [-0.55902,   inf] (62), [-0.55897,   inf] (62), [-0.55895,   inf] (62), [-0.55891,   inf] (62), [-0.55881,   inf] (62), [-0.55870,   inf] (62), [-0.55837,   inf] (62), [-0.55836,   inf] (62), 
length of domains: 65349
Total time: 10.7305	 pickout: 0.8415	 decision: 2.8301	 get_bound: 5.9966	 add_domain: 1.0624
Current lb:-0.5660444498062134
155406 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Time out!!!!!!!!
Image 164 label 2 verification end, final lower bound -0.5660444498062134, upper bound inf, time: 195.22443747520447
164 -0.5660444498062134
Result: image 164 verification failure (with branch and bound).
Wall time: 205.04825830459595

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 0): []
verification failure idx (total 1): [164]
final verified acc: 0.0%[1]
verifier is called on 1 examples.
total verified: 0
mean time [cnt:1] (excluding attack success): 204.99100971221924
