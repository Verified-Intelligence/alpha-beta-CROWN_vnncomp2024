Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_cnn_a_mix4.model
  name: cnn_4layer_mix4
data:
  start: 92
  end: 93
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR_SDP
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.00784313725
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 4096
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 30
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:08:05 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Flatten()
  (5): Linear(in_features=2048, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([200, 3, 32, 32]) torch.Size([200]) torch.Size([200])
X range: tensor(2.1256) tensor(-1.9889) tensor(-0.0131)
############################
epsilon after preprocessing: tensor([[[[0.0317]],

         [[0.0322]],

         [[0.0300]]]]), data_max = tensor([[[[2.0587]],

         [[2.1256]],

         [[2.1154]]]]), data_min = tensor([[[[-1.9889]],

         [[-1.9807]],

         [[-1.7076]]]])
Task length: 1
saving results to Verified_ret_[cnn_4layer_mix4]_start=92_end=93_iter=20_b=4096_timeout=30_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 92 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 5, correct label 5, image norm 3129.664306640625, logits tensor([-22.8693, -22.7425, -18.8375, -17.0775, -18.2238, -16.8974, -19.1091,
        -18.7904, -26.2104, -21.3066], device='cuda:0',
       grad_fn=<SelectBackward>)
Model prediction is: tensor([[-22.8693, -22.7425, -18.8375, -17.0775, -18.2238, -16.8974, -19.1091,
         -18.7904, -26.2104, -21.3066]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 4.6633,  4.0336,  0.9363, -0.1225,  0.2394,  1.0592,  0.7927,  7.6372,
          2.9054]], device='cuda:0') None
best_l after optimization: -22.54421615600586 with beta sum per layer: []
alpha/beta optimization time: 7.85021185874939
initial alpha-CROWN bounds: tensor([[ 4.7053,  4.0963,  0.9752, -0.0995,  0.2727,  1.0842,  0.8489,  7.6958,
          2.9653]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.0995, device='cuda:0', grad_fn=<MinBackward1>)
##### [0:92] Tested against 3 ######
Model prediction is: tensor([[-22.8693, -22.7425, -18.8375, -17.0775, -18.2238, -16.8974, -19.1091,
         -18.7904, -26.2104, -21.3066]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 16, 16]) != torch.Size([2, 9, 1, 16, 16, 16]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 8, 8]) != torch.Size([2, 9, 1, 32, 8, 8]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 16, 16])
1 /11 torch.Size([1, 32, 8, 8])
2 /21 torch.Size([1, 100])
best_l after optimization: 0.09953153133392334 with beta sum per layer: []
alpha/beta optimization time: 2.196485757827759
alpha-CROWN with fixed intermediate bounds: tensor([[-0.0995]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.09953153133392334
layer 0 size torch.Size([4096]) unstable 669
layer 1 size torch.Size([2048]) unstable 235
layer 2 size torch.Size([100]) unstable 16
-----------------
# of unstable neurons: 920
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 16, 16]) pre split depth:  8
batch:  torch.Size([1, 16, 16, 16]) post split depth:  8
splitting decisions: 
split level 0: [2, 67] 
split level 1: [2, 7] 
split level 2: [2, 83] 
split level 3: [2, 57] 
split level 4: [2, 0] 
split level 5: [2, 4] 
split level 6: [2, 31] 
split level 7: [1, 1699] 
regular batch size: 2*128, diving batch size 1*0
best_l after optimization: -4.272608280181885 with beta sum per layer: [0.0, 6.071959495544434, 38.10068893432617]
alpha/beta optimization time: 0.29561352729797363
This batch time : update_bounds func: 0.3420	 prepare: 0.0180	 bound: 0.2959	 transfer: 0.0097	 finalize: 0.0177
Accumulated time: update_bounds func: 0.3420	 prepare: 0.0180	 bound: 0.2959	 transfer: 0.0097	 finalize: 0.0177
batch bounding time:  0.3423643112182617
Current worst splitting domains [lb, ub] (depth):
[-0.05128,   inf] (9), [-0.05023,   inf] (9), [-0.05020,   inf] (9), [-0.05000,   inf] (9), [-0.04948,   inf] (9), [-0.04935,   inf] (9), [-0.04912,   inf] (9), [-0.04901,   inf] (9), [-0.04866,   inf] (9), [-0.04846,   inf] (9), [-0.04824,   inf] (9), [-0.04814,   inf] (9), [-0.04773,   inf] (9), [-0.04757,   inf] (9), [-0.04731,   inf] (9), [-0.04661,   inf] (9), [-0.03710,   inf] (9), [-0.03635,   inf] (9), [-0.03584,   inf] (9), [-0.03566,   inf] (9), 
length of domains: 58
Total time: 0.6441	 pickout: 0.0009	 decision: 0.2655	 get_bound: 0.3746	 add_domain: 0.0031
Current lb:-0.05128425732254982
256 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.700775623321533

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([58, 16, 16, 16]) pre split depth:  2
batch:  torch.Size([58, 16, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [1, 606] [1, 606] [1, 606] [1, 606] [1, 723] [1, 606] [1, 606] [1, 606] [1, 723] [1, 606] 
split level 1: [2, 53] [2, 53] [2, 53] [2, 53] [1, 606] [2, 53] [2, 53] [2, 53] [1, 606] [2, 53] 
regular batch size: 2*116, diving batch size 1*0
best_l after optimization: -0.3218343257904053 with beta sum per layer: [0.0, 15.837408065795898, 24.35224151611328]
alpha/beta optimization time: 0.30294036865234375
This batch time : update_bounds func: 0.3537	 prepare: 0.0234	 bound: 0.3033	 transfer: 0.0133	 finalize: 0.0129
Accumulated time: update_bounds func: 0.6958	 prepare: 0.0414	 bound: 0.5993	 transfer: 0.0133	 finalize: 0.0306
batch bounding time:  0.35416746139526367
Current worst splitting domains [lb, ub] (depth):
[-0.04927,   inf] (12), [-0.04848,   inf] (12), [-0.04822,   inf] (12), [-0.04819,   inf] (12), [-0.04802,   inf] (12), [-0.04743,   inf] (12), [-0.04734,   inf] (12), [-0.04733,   inf] (12), [-0.04724,   inf] (12), [-0.04719,   inf] (12), [-0.04712,   inf] (12), [-0.04699,   inf] (12), [-0.04680,   inf] (12), [-0.04653,   inf] (12), [-0.04647,   inf] (12), [-0.04640,   inf] (12), [-0.04628,   inf] (12), [-0.04624,   inf] (12), [-0.04615,   inf] (12), [-0.04612,   inf] (12), 
length of domains: 130
Total time: 0.4506	 pickout: 0.0102	 decision: 0.0621	 get_bound: 0.3717	 add_domain: 0.0066
Current lb:-0.049273934215307236
488 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.152792930603027

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([130, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([130, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 723] [1, 723] [1, 133] [1, 723] [1, 723] [1, 133] [1, 723] [1, 133] [1, 723] [1, 133] 
regular batch size: 2*130, diving batch size 1*0
best_l after optimization: 5.312089443206787 with beta sum per layer: [0.0, 17.240924835205078, 12.41843318939209]
alpha/beta optimization time: 0.30001187324523926
This batch time : update_bounds func: 0.3623	 prepare: 0.0387	 bound: 0.3003	 transfer: 0.0071	 finalize: 0.0154
Accumulated time: update_bounds func: 1.0581	 prepare: 0.0801	 bound: 0.8996	 transfer: 0.0071	 finalize: 0.0460
batch bounding time:  0.362743616104126
Current worst splitting domains [lb, ub] (depth):
[-0.04811,   inf] (14), [-0.04772,   inf] (14), [-0.04731,   inf] (14), [-0.04713,   inf] (14), [-0.04707,   inf] (14), [-0.04694,   inf] (14), [-0.04687,   inf] (14), [-0.04668,   inf] (14), [-0.04667,   inf] (14), [-0.04654,   inf] (14), [-0.04633,   inf] (14), [-0.04631,   inf] (14), [-0.04623,   inf] (14), [-0.04614,   inf] (14), [-0.04609,   inf] (14), [-0.04607,   inf] (14), [-0.04590,   inf] (14), [-0.04588,   inf] (14), [-0.04585,   inf] (14), [-0.04582,   inf] (14), 
length of domains: 224
Total time: 0.4522	 pickout: 0.0199	 decision: 0.0564	 get_bound: 0.3631	 add_domain: 0.0127
Current lb:-0.04810912162065506
748 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.607043266296387

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([224, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([224, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 133] [1, 133] [1, 133] [1, 133] [1, 723] [1, 133] [1, 133] [1, 723] [1, 133] [1, 133] 
regular batch size: 2*224, diving batch size 1*0
best_l after optimization: 9.485457420349121 with beta sum per layer: [0.0, 48.070068359375, 17.47967529296875]
alpha/beta optimization time: 0.35511207580566406
This batch time : update_bounds func: 0.4423	 prepare: 0.0421	 bound: 0.3555	 transfer: 0.0171	 finalize: 0.0266
Accumulated time: update_bounds func: 1.5004	 prepare: 0.1222	 bound: 1.2551	 transfer: 0.0171	 finalize: 0.0726
batch bounding time:  0.4427952766418457
Current worst splitting domains [lb, ub] (depth):
[-0.04709,   inf] (16), [-0.04670,   inf] (16), [-0.04648,   inf] (16), [-0.04630,   inf] (16), [-0.04613,   inf] (16), [-0.04611,   inf] (16), [-0.04607,   inf] (16), [-0.04591,   inf] (16), [-0.04588,   inf] (16), [-0.04584,   inf] (16), [-0.04569,   inf] (16), [-0.04569,   inf] (16), [-0.04559,   inf] (16), [-0.04552,   inf] (16), [-0.04552,   inf] (16), [-0.04540,   inf] (16), [-0.04534,   inf] (16), [-0.04532,   inf] (16), [-0.04531,   inf] (16), [-0.04530,   inf] (16), 
length of domains: 392
Total time: 0.5838	 pickout: 0.0335	 decision: 0.0841	 get_bound: 0.4435	 add_domain: 0.0227
Current lb:-0.04708784446120262
1196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.194557428359985

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([392, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([392, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 219] [1, 219] [1, 219] [1, 219] [1, 219] [1, 219] [1, 219] [1, 219] [1, 219] [1, 219] 
regular batch size: 2*392, diving batch size 1*0
best_l after optimization: 18.188371658325195 with beta sum per layer: [0.0, 125.22003936767578, 25.078718185424805]
alpha/beta optimization time: 0.4958994388580322
This batch time : update_bounds func: 0.6458	 prepare: 0.0735	 bound: 0.4963	 transfer: 0.0279	 finalize: 0.0463
Accumulated time: update_bounds func: 2.1462	 prepare: 0.1957	 bound: 1.7513	 transfer: 0.0279	 finalize: 0.1188
batch bounding time:  0.6465730667114258
Current worst splitting domains [lb, ub] (depth):
[-0.04620,   inf] (18), [-0.04582,   inf] (18), [-0.04552,   inf] (18), [-0.04542,   inf] (18), [-0.04526,   inf] (18), [-0.04524,   inf] (18), [-0.04517,   inf] (18), [-0.04505,   inf] (18), [-0.04503,   inf] (18), [-0.04499,   inf] (18), [-0.04482,   inf] (18), [-0.04474,   inf] (18), [-0.04472,   inf] (18), [-0.04467,   inf] (18), [-0.04459,   inf] (18), [-0.04451,   inf] (18), [-0.04450,   inf] (18), [-0.04447,   inf] (18), [-0.04440,   inf] (18), [-0.04439,   inf] (18), 
length of domains: 733
Total time: 0.9430	 pickout: 0.0589	 decision: 0.1924	 get_bound: 0.6477	 add_domain: 0.0440
Current lb:-0.04620005190372467
1980 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.14370059967041

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([733, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([733, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1592] [1, 1592] [1, 1592] [1, 1592] [1, 1592] [1, 905] [1, 1592] [1, 905] [1, 1592] [1, 1592] 
regular batch size: 2*733, diving batch size 1*0
best_l after optimization: 33.792232513427734 with beta sum per layer: [0.0, 262.2763977050781, 45.35607147216797]
alpha/beta optimization time: 0.7766189575195312
This batch time : update_bounds func: 1.0612	 prepare: 0.1408	 bound: 0.7771	 transfer: 0.0503	 finalize: 0.0895
Accumulated time: update_bounds func: 3.2074	 prepare: 0.3365	 bound: 2.5284	 transfer: 0.0503	 finalize: 0.2083
batch bounding time:  1.062631368637085
Current worst splitting domains [lb, ub] (depth):
[-0.04543,   inf] (20), [-0.04506,   inf] (20), [-0.04496,   inf] (20), [-0.04470,   inf] (20), [-0.04465,   inf] (20), [-0.04459,   inf] (20), [-0.04447,   inf] (20), [-0.04437,   inf] (20), [-0.04434,   inf] (20), [-0.04428,   inf] (20), [-0.04423,   inf] (20), [-0.04422,   inf] (20), [-0.04419,   inf] (20), [-0.04418,   inf] (20), [-0.04403,   inf] (20), [-0.04399,   inf] (20), [-0.04392,   inf] (20), [-0.04391,   inf] (20), [-0.04389,   inf] (20), [-0.04388,   inf] (20), 
length of domains: 1393
Total time: 1.5687	 pickout: 0.1196	 decision: 0.2956	 get_bound: 1.0649	 add_domain: 0.0887
Current lb:-0.045432545244693756
3446 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.724859952926636

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1393, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1393, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 905] [1, 905] [1, 905] [1, 905] [1, 905] [1, 905] [1, 421] [1, 1592] [1, 905] [1, 905] 
regular batch size: 2*1393, diving batch size 1*0
best_l after optimization: 60.97868347167969 with beta sum per layer: [0.0, 679.3759765625, 85.46051025390625]
alpha/beta optimization time: 1.337092399597168
This batch time : update_bounds func: 2.0009	 prepare: 0.3980	 bound: 1.3376	 transfer: 0.0926	 finalize: 0.1659
Accumulated time: update_bounds func: 5.2083	 prepare: 0.7344	 bound: 3.8661	 transfer: 0.0926	 finalize: 0.3742
batch bounding time:  2.003730297088623
Current worst splitting domains [lb, ub] (depth):
[-0.04468,   inf] (22), [-0.04437,   inf] (22), [-0.04432,   inf] (22), [-0.04421,   inf] (22), [-0.04403,   inf] (22), [-0.04392,   inf] (22), [-0.04391,   inf] (22), [-0.04390,   inf] (22)/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:462: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(preprocess_cifar(eps_temp, perturbation=True)).reshape(1,-1,1,1)
, [-0.04385,   inf] (22), [-0.04366,   inf] (22), [-0.04361,   inf] (22), [-0.04360,   inf] (22), [-0.04358,   inf] (22), [-0.04357,   inf] (22), [-0.04355,   inf] (22), [-0.04353,   inf] (22), [-0.04345,   inf] (22), [-0.04343,   inf] (22), [-0.04342,   inf] (22), [-0.04338,   inf] (22), 
length of domains: 2572
Total time: 3.2073	 pickout: 0.2532	 decision: 0.6711	 get_bound: 2.0084	 add_domain: 0.2746
Current lb:-0.04467770829796791
6232 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.956059455871582

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2572, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([2572, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 421] [1, 421] [1, 421] [1, 421] [1, 421] [1, 421] [1, 421] [1, 421] [1, 421] [1, 905] 
regular batch size: 2*2572, diving batch size 1*0
best_l after optimization: 108.98838806152344 with beta sum per layer: [0.0, 1593.9910888671875, 156.43255615234375]
alpha/beta optimization time: 2.4052438735961914
This batch time : update_bounds func: 3.5622	 prepare: 0.4868	 bound: 2.4057	 transfer: 0.1756	 finalize: 0.4823
Accumulated time: update_bounds func: 8.7705	 prepare: 1.2212	 bound: 6.2718	 transfer: 0.1756	 finalize: 0.8565
batch bounding time:  3.567370891571045
Current worst splitting domains [lb, ub] (depth):
[-0.04397,   inf] (24), [-0.04365,   inf] (24), [-0.04361,   inf] (24), [-0.04350,   inf] (24), [-0.04332,   inf] (24), [-0.04321,   inf] (24), [-0.04319,   inf] (24), [-0.04318,   inf] (24), [-0.04314,   inf] (24), [-0.04292,   inf] (24), [-0.04290,   inf] (24), [-0.04286,   inf] (24), [-0.04285,   inf] (24), [-0.04285,   inf] (24), [-0.04284,   inf] (24), [-0.04280,   inf] (24), [-0.04274,   inf] (24), [-0.04272,   inf] (24), [-0.04270,   inf] (24), [-0.04263,   inf] (24), 
length of domains: 4890
Total time: 5.3674	 pickout: 0.4553	 decision: 0.9514	 get_bound: 3.5764	 add_domain: 0.3842
Current lb:-0.043967753648757935
11376 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.379541635513306

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4096, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([4096, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 581] [1, 581] [1, 581] [1, 581] [1, 581] [1, 581] [1, 581] [1, 581] [1, 581] [1, 1683] 
regular batch size: 2*4096, diving batch size 1*0
best_l after optimization: 187.25360107421875 with beta sum per layer: [6.245903015136719, 3092.193359375, 221.4275665283203]
alpha/beta optimization time: 3.7692837715148926
This batch time : update_bounds func: 5.8413	 prepare: 0.8106	 bound: 3.7698	 transfer: 0.2767	 finalize: 0.9647
Accumulated time: update_bounds func: 14.6118	 prepare: 2.0319	 bound: 10.0416	 transfer: 0.2767	 finalize: 1.8212
batch bounding time:  5.850233554840088
Current worst splitting domains [lb, ub] (depth):
[-0.04353,   inf] (26), [-0.04321,   inf] (26), [-0.04317,   inf] (26), [-0.04306,   inf] (26), [-0.04289,   inf] (26), [-0.04277,   inf] (26), [-0.04274,   inf] (26), [-0.04274,   inf] (26), [-0.04271,   inf] (26), [-0.04246,   inf] (26), [-0.04243,   inf] (26), [-0.04242,   inf] (26), [-0.04242,   inf] (26), [-0.04231,   inf] (26), [-0.04230,   inf] (26), [-0.04227,   inf] (26), [-0.04227,   inf] (26), [-0.04224,   inf] (26), [-0.04217,   inf] (26), [-0.04213,   inf] (26), 
length of domains: 8935
Total time: 9.2813	 pickout: 0.7371	 decision: 1.8689	 get_bound: 5.8660	 add_domain: 0.8093
Current lb:-0.043528828769922256
19568 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Time out!!!!!!!!
Image 92 label 3 verification end, final lower bound -0.043528828769922256, upper bound inf, time: 25.9092276096344
92 -0.043528828769922256
Result: image 92 verification failure (with branch and bound).
Wall time: 35.73460650444031

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 0): []
verification failure idx (total 1): [92]
final verified acc: 0.0%[1]
verifier is called on 1 examples.
total verified: 0
mean time [cnt:1] (excluding attack success): 35.65558171272278
