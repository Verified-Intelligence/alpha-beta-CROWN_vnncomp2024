Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: mnist_conv_small_nat.pth
  name: mnist_conv_small
data:
  start: 225
  end: 226
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: MNIST_ERAN
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.12
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 2048
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 180
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 100
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Tue May  3 01:22:59 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(1, 16, kernel_size=(4, 4), stride=(2, 2))
  (1): ReLU()
  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))
  (3): ReLU()
  (4): Flatten()
  (5): Linear(in_features=800, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([1000, 1, 28, 28]) torch.Size([1000]) torch.Size([1000])
X range: tensor(2.8215) tensor(-0.4242) tensor(-0.0274)
Note runnerup label is empty here!
############################
epsilon after preprocessing: tensor([[[[0.3895]]]]), data_max = tensor([[[[2.8215]]]]), data_min = tensor([[[[-0.4242]]]])
Task length: 1
saving results to Verified_ret_[mnist_conv_small]_start=225_end=226_iter=20_b=2048_timeout=180_branching=kfsb-max-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 225 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 2, correct label 2, image norm 541.1094970703125, logits tensor([ 1.5918,  2.0589,  9.9670,  6.1006, -7.5965, -5.6112, -9.0007,  2.4802,
         1.7141, -1.6150], device='cuda:0', grad_fn=<SelectBackward>)
Model prediction is: tensor([[ 1.5918,  2.0589,  9.9670,  6.1006, -7.5965, -5.6112, -9.0007,  2.4802,
          1.7141, -1.6150]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 1.1769,  0.1894, -4.8167,  8.2674,  4.1129,  8.7605, -0.6091, -0.9468,
          0.3608]], device='cuda:0') None
best_l after optimization: -24.53098487854004 with beta sum per layer: []
alpha/beta optimization time: 7.160936117172241
initial alpha-CROWN bounds: tensor([[ 1.8306,  1.4990, -3.9769,  9.1497,  5.0694,  9.3069,  0.5403, -0.4629,
          1.5750]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-3.9769, device='cuda:0', grad_fn=<MinBackward1>)
##### [0:225] Tested against 3 ######
Model prediction is: tensor([[ 1.5918,  2.0589,  9.9670,  6.1006, -7.5965, -5.6112, -9.0007,  2.4802,
          1.7141, -1.6150]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 13, 13]) != torch.Size([2, 9, 1, 16, 13, 13]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 5, 5]) != torch.Size([2, 9, 1, 32, 5, 5]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 13, 13])
1 /11 torch.Size([1, 32, 5, 5])
2 /21 torch.Size([1, 100])
best_l after optimization: 3.9768834114074707 with beta sum per layer: []
alpha/beta optimization time: 1.7589335441589355
alpha-CROWN with fixed intermediate bounds: tensor([[-3.9769]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-3.9768834114074707
layer 0 size torch.Size([2704]) unstable 919
layer 1 size torch.Size([800]) unstable 167
layer 2 size torch.Size([100]) unstable 29
-----------------
# of unstable neurons: 1115
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 13, 13]) pre split depth:  7
batch:  torch.Size([1, 16, 13, 13]) post split depth:  7
splitting decisions: 
split level 0: [2, 9] 
split level 1: [2, 80] 
split level 2: [1, 123] 
split level 3: [2, 48] 
split level 4: [2, 5] 
split level 5: [2, 59] 
split level 6: [2, 60] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 31.0437068939209 with beta sum per layer: [0.0, 7.367264747619629, 96.7428970336914]
alpha/beta optimization time: 0.2521178722381592
This batch time : update_bounds func: 0.2717	 prepare: 0.0100	 bound: 0.2524	 transfer: 0.0016	 finalize: 0.0073
Accumulated time: update_bounds func: 0.2717	 prepare: 0.0100	 bound: 0.2524	 transfer: 0.0016	 finalize: 0.0073
batch bounding time:  0.27190208435058594
Current worst splitting domains [lb, ub] (depth):
[-2.28450,   inf] (8), [-2.27200,   inf] (8), [-1.98634,   inf] (8), [-1.95577,   inf] (8), [-1.75774,   inf] (8), [-1.71213,   inf] (8), [-1.66544,   inf] (8), [-1.62053,   inf] (8), [-1.61889,   inf] (8), [-1.58137,   inf] (8), [-1.57746,   inf] (8), [-1.53488,   inf] (8), [-1.52009,   inf] (8), [-1.47442,   inf] (8), [-1.44085,   inf] (8), [-1.39411,   inf] (8), [-1.38634,   inf] (8), [-1.36696,   inf] (8), [-1.30076,   inf] (8), [-1.27979,   inf] (8), 
length of domains: 60
Total time: 0.3345	 pickout: 0.0009	 decision: 0.0425	 get_bound: 0.2884	 add_domain: 0.0027
Current lb:-2.2844972610473633
128 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.9228785037994385

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([60, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([60, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 47] [2, 47] [2, 47] [2, 47] [2, 47] [2, 47] [2, 47] [2, 47] [2, 47] [2, 47] 
regular batch size: 2*60, diving batch size 1*0
best_l after optimization: 39.935829162597656 with beta sum per layer: [0.0, 6.938793659210205, 98.40383911132812]
alpha/beta optimization time: 0.24655485153198242
This batch time : update_bounds func: 0.2678	 prepare: 0.0124	 bound: 0.2468	 transfer: 0.0015	 finalize: 0.0067
Accumulated time: update_bounds func: 0.5395	 prepare: 0.0225	 bound: 0.4993	 transfer: 0.0015	 finalize: 0.0140
batch bounding time:  0.2679765224456787
Current worst splitting domains [lb, ub] (depth):
[-2.14273,   inf] (10), [-2.13145,   inf] (10), [-1.82654,   inf] (10), [-1.79148,   inf] (10), [-1.56225,   inf] (10), [-1.53610,   inf] (10), [-1.43844,   inf] (10), [-1.42942,   inf] (10), [-1.41323,   inf] (10), [-1.38597,   inf] (10), [-1.36030,   inf] (10), [-1.35105,   inf] (10), [-1.30280,   inf] (10), [-1.29194,   inf] (10), [-1.23492,   inf] (10), [-1.13531,   inf] (10), [-1.08983,   inf] (10), [-1.08192,   inf] (10), [-1.07240,   inf] (10), [-1.05074,   inf] (10), 
length of domains: 68
Total time: 0.3144	 pickout: 0.0089	 decision: 0.0342	 get_bound: 0.2682	 add_domain: 0.0032
Current lb:-2.1427271366119385
248 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.238060712814331

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([68, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([68, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 0] [2, 0] [2, 0] [1, 423] [2, 0] [1, 122] [1, 423] [1, 423] [2, 0] [2, 0] 
regular batch size: 2*68, diving batch size 1*0
best_l after optimization: 50.16583251953125 with beta sum per layer: [0.0, 10.428606033325195, 116.88142395019531]
alpha/beta optimization time: 0.25040507316589355
This batch time : update_bounds func: 0.2759	 prepare: 0.0138	 bound: 0.2507	 transfer: 0.0035	 finalize: 0.0076
Accumulated time: update_bounds func: 0.8154	 prepare: 0.0363	 bound: 0.7499	 transfer: 0.0035	 finalize: 0.0216
batch bounding time:  0.276141881942749
Current worst splitting domains [lb, ub] (depth):
[-1.99948,   inf] (12), [-1.99444,   inf] (12), [-1.68904,   inf] (12), [-1.64438,   inf] (12), [-1.62564,   inf] (12), [-1.54563,   inf] (12), [-1.41108,   inf] (12), [-1.40305,   inf] (12), [-1.39725,   inf] (12), [-1.36799,   inf] (12), [-1.32686,   inf] (12), [-1.28504,   inf] (12), [-1.25250,   inf] (12), [-1.23905,   inf] (12), [-1.22618,   inf] (12), [-1.19697,   inf] (12), [-1.14944,   inf] (12), [-1.13901,   inf] (12), [-1.10808,   inf] (12), [-1.08977,   inf] (12), 
length of domains: 80
Total time: 0.3257	 pickout: 0.0097	 decision: 0.0357	 get_bound: 0.2764	 add_domain: 0.0039
Current lb:-1.9994803667068481
384 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.564788579940796

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([80, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([80, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 122] [1, 122] [2, 0] [1, 423] [1, 122] [1, 122] [1, 423] [2, 0] [1, 122] [2, 0] 
regular batch size: 2*80, diving batch size 1*0
best_l after optimization: 55.57111358642578 with beta sum per layer: [0.0, 16.10879898071289, 127.04396057128906]
alpha/beta optimization time: 0.25320982933044434
This batch time : update_bounds func: 0.2807	 prepare: 0.0158	 bound: 0.2535	 transfer: 0.0019	 finalize: 0.0091
Accumulated time: update_bounds func: 1.0961	 prepare: 0.0521	 bound: 1.0035	 transfer: 0.0019	 finalize: 0.0306
batch bounding time:  0.28098535537719727
Current worst splitting domains [lb, ub] (depth):
[-1.85382,   inf] (14), [-1.85102,   inf] (14), [-1.66417,   inf] (14), [-1.59809,   inf] (14), [-1.51174,   inf] (14), [-1.49983,   inf] (14), [-1.48605,   inf] (14), [-1.36894,   inf] (14), [-1.30227,   inf] (14), [-1.29962,   inf] (14), [-1.28442,   inf] (14), [-1.27918,   inf] (14), [-1.26606,   inf] (14), [-1.16844,   inf] (14), [-1.15601,   inf] (14), [-1.13815,   inf] (14), [-1.13433,   inf] (14), [-1.12866,   inf] (14), [-1.12043,   inf] (14), [-1.09963,   inf] (14), 
length of domains: 102
Total time: 0.3385	 pickout: 0.0114	 decision: 0.0401	 get_bound: 0.2812	 add_domain: 0.0058
Current lb:-1.8538167476654053
544 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.9045844078063965

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([102, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([102, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 423] [1, 423] [1, 423] [1, 423] [1, 122] [1, 318] [1, 122] [1, 122] [1, 423] [1, 423] 
regular batch size: 2*102, diving batch size 1*0
best_l after optimization: 87.53740692138672 with beta sum per layer: [0.0, 15.408087730407715, 151.12564086914062]
alpha/beta optimization time: 0.2692708969116211
This batch time : update_bounds func: 0.3058	 prepare: 0.0200	 bound: 0.2696	 transfer: 0.0038	 finalize: 0.0119
Accumulated time: update_bounds func: 1.4019	 prepare: 0.0721	 bound: 1.2730	 transfer: 0.0038	 finalize: 0.0425
batch bounding time:  0.30606961250305176
Current worst splitting domains [lb, ub] (depth):
[-1.73747,   inf] (16), [-1.73707,   inf] (16), [-1.58375,   inf] (16), [-1.57313,   inf] (16), [-1.54789,   inf] (16), [-1.51924,   inf] (16), [-1.44777,   inf] (16), [-1.35473,   inf] (16), [-1.30772,   inf] (16), [-1.23128,   inf] (16), [-1.21487,   inf] (16), [-1.21297,   inf] (16), [-1.19920,   inf] (16), [-1.18680,   inf] (16), [-1.17693,   inf] (16), [-1.16088,   inf] (16), [-1.16080,   inf] (16), [-1.14283,   inf] (16), [-1.08602,   inf] (16), [-1.07553,   inf] (16), 
length of domains: 152
Total time: 0.3734	 pickout: 0.0146	 decision: 0.0442	 get_bound: 0.3064	 add_domain: 0.0081
Current lb:-1.737470269203186
748 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.279419183731079

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([152, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([152, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 318] [1, 318] [1, 318] [1, 318] [1, 267] [1, 318] [1, 423] [1, 318] [1, 713] [1, 318] 
regular batch size: 2*152, diving batch size 1*0
best_l after optimization: 118.115478515625 with beta sum per layer: [0.0, 34.00438690185547, 197.15748596191406]
alpha/beta optimization time: 0.27097439765930176
This batch time : update_bounds func: 0.3266	 prepare: 0.0290	 bound: 0.2713	 transfer: 0.0086	 finalize: 0.0170
Accumulated time: update_bounds func: 1.7285	 prepare: 0.1012	 bound: 1.5443	 transfer: 0.0086	 finalize: 0.0595
batch bounding time:  0.3269834518432617
Current worst splitting domains [lb, ub] (depth):
[-1.68781,   inf] (18), [-1.67647,   inf] (18), [-1.52161,   inf] (18), [-1.51088,   inf] (18), [-1.45422,   inf] (18), [-1.44210,   inf] (18), [-1.32921,   inf] (18), [-1.32894,   inf] (18), [-1.30691,   inf] (18), [-1.28117,   inf] (18), [-1.25760,   inf] (18), [-1.24765,   inf] (18), [-1.17321,   inf] (18), [-1.14691,   inf] (18), [-1.14564,   inf] (18), [-1.12061,   inf] (18), [-1.11859,   inf] (18), [-1.10933,   inf] (18), [-1.08606,   inf] (18), [-1.06918,   inf] (18), 
length of domains: 228
Total time: 0.4176	 pickout: 0.0211	 decision: 0.0557	 get_bound: 0.3275	 add_domain: 0.0134
Current lb:-1.68781316280365
1052 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.6990065574646

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([228, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([228, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 267] [1, 267] [1, 584] [1, 267] [1, 267] [1, 318] [1, 267] [1, 318] [1, 267] [1, 267] 
regular batch size: 2*228, diving batch size 1*0
best_l after optimization: 167.86959838867188 with beta sum per layer: [0.0, 59.66286849975586, 225.88088989257812]
alpha/beta optimization time: 0.2751903533935547
This batch time : update_bounds func: 0.4087	 prepare: 0.0447	 bound: 0.2755	 transfer: 0.0087	 finalize: 0.0787
Accumulated time: update_bounds func: 2.1372	 prepare: 0.1459	 bound: 1.8198	 transfer: 0.0087	 finalize: 0.1382
batch bounding time:  0.4091963768005371
Current worst splitting domains [lb, ub] (depth):
[-1.60193,   inf] (20), [-1.58020,   inf] (20), [-1.48612,   inf] (20), [-1.45072,   inf] (20), [-1.44336,   inf] (20), [-1.39736,   inf] (20), [-1.39666,   inf] (20), [-1.35380,   inf] (20), [-1.29148,   inf] (20), [-1.27179,   inf] (20), [-1.25268,   inf] (20), [-1.23756,   inf] (20), [-1.20494,   inf] (20), [-1.18870,   inf] (20), [-1.10572,   inf] (20), [-1.10461,   inf] (20), [-1.10273,   inf] (20), [-1.10100,   inf] (20), [-1.10024,   inf] (20), [-1.08164,   inf] (20), 
length of domains: 392
Total time: 0.5404	 pickout: 0.0315	 decision: 0.0751	 get_bound: 0.4099	 add_domain: 0.0239
Current lb:-1.601929783821106
1508 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.242635488510132

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([392, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([392, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 248] [1, 424] [1, 248] [1, 248] [1, 189] [0, 2322] [0, 2322] [1, 424] [0, 2322] [1, 189] 
regular batch size: 2*392, diving batch size 1*0
best_l after optimization: 185.7841033935547 with beta sum per layer: [0.5907366871833801, 121.56175231933594, 359.3841247558594]
alpha/beta optimization time: 0.32770395278930664
This batch time : update_bounds func: 0.4669	 prepare: 0.0739	 bound: 0.3280	 transfer: 0.0166	 finalize: 0.0468
Accumulated time: update_bounds func: 2.6041	 prepare: 0.2198	 bound: 2.1479	 transfer: 0.0166	 finalize: 0.1849
batch bounding time:  0.46762990951538086
Current worst splitting domains [lb, ub] (depth):
[-1.56118,   inf] (22), [-1.49144,   inf] (22), [-1.45754,   inf] (22), [-1.45095,   inf] (22), [-1.40957,   inf] (22), [-1.39199,   inf] (22), [-1.39133,   inf] (22), [-1.34926,   inf] (22), [-1.31716,   inf] (22), [-1.28153,   inf] (22), [-1.27009,   inf] (22), [-1.22617,   inf] (22), [-1.17780,   inf] (22), [-1.16094,   inf] (22), [-1.14429,   inf] (22), [-1.14100,   inf] (22), [-1.13883,   inf] (22), [-1.12231,   inf] (22), [-1.12108,   inf] (22), [-1.09716,   inf] (22), 
length of domains: 533
Total time: 0.6727	 pickout: 0.0538	 decision: 0.1155	 get_bound: 0.4689	 add_domain: 0.0344
Current lb:-1.561178207397461
2292 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.921702861785889

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([533, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([533, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 584] [2, 6] [2, 6] [1, 267] [2, 6] [1, 424] [1, 248] [2, 6] [2, 6] [1, 424] 
regular batch size: 2*533, diving batch size 1*0
best_l after optimization: 165.90481567382812 with beta sum per layer: [0.9926356077194214, 188.83908081054688, 470.5088195800781]
alpha/beta optimization time: 0.37921619415283203
This batch time : update_bounds func: 0.5646	 prepare: 0.1011	 bound: 0.3795	 transfer: 0.0197	 finalize: 0.0617
Accumulated time: update_bounds func: 3.1687	 prepare: 0.3210	 bound: 2.5274	 transfer: 0.0197	 finalize: 0.2467
batch bounding time:  0.5656330585479736
Current worst splitting domains [lb, ub] (depth):
[-1.52778,   inf] (24), [-1.42351,   inf] (24), [-1.38886,   inf] (24), [-1.36024,   inf] (24), [-1.34906,   inf] (24), [-1.34628,   inf] (24), [-1.33670,   inf] (24), [-1.28201,   inf] (24), [-1.24916,   inf] (24), [-1.23263,   inf] (24), [-1.19855,   inf] (24), [-1.18338,   inf] (24), [-1.15225,   inf] (24), [-1.11924,   inf] (24), [-1.10794,   inf] (24), [-1.10535,   inf] (24), [-1.10092,   inf] (24), [-1.08499,   inf] (24), [-1.08483,   inf] (24), [-1.07343,   inf] (24), 
length of domains: 629
Total time: 0.8777	 pickout: 0.0736	 decision: 0.1934	 get_bound: 0.5673	 add_domain: 0.0434
Current lb:-1.527779459953308
3358 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.809375524520874

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([629, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([629, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 713] [1, 248] [1, 248] [1, 713] [2, 6] [1, 713] [1, 584] [1, 709] [1, 248] [2, 6] 
regular batch size: 2*629, diving batch size 1*0
best_l after optimization: 147.74636840820312 with beta sum per layer: [1.6301231384277344, 251.02017211914062, 504.49639892578125]
alpha/beta optimization time: 0.4156074523925781
This batch time : update_bounds func: 0.6249	 prepare: 0.1194	 bound: 0.4159	 transfer: 0.0144	 finalize: 0.0723
Accumulated time: update_bounds func: 3.7935	 prepare: 0.4403	 bound: 2.9433	 transfer: 0.0144	 finalize: 0.3189
batch bounding time:  0.6260316371917725
Current worst splitting domains [lb, ub] (depth):
[-1.47366,   inf] (26), [-1.38588,   inf] (26), [-1.34699,   inf] (26), [-1.30240,   inf] (26), [-1.30234,   inf] (26), [-1.30191,   inf] (26), [-1.28540,   inf] (26), [-1.20827,   inf] (26), [-1.20355,   inf] (26), [-1.19729,   inf] (26), [-1.16982,   inf] (26), [-1.16838,   inf] (26), [-1.14538,   inf] (26), [-1.13116,   inf] (26), [-1.09365,   inf] (26), [-1.04236,   inf] (26), [-1.03977,   inf] (26), [-1.03120,   inf] (26), [-1.02233,   inf] (26), [-1.02220,   inf] (26), 
length of domains: 732
Total time: 0.9874	 pickout: 0.0887	 decision: 0.2184	 get_bound: 0.6280	 add_domain: 0.0523
Current lb:-1.4736560583114624
4616 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.808889865875244

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([732, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([732, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 189] [1, 709] [1, 713] [2, 6] [1, 189] [1, 189] [1, 248] [1, 424] [1, 189] [1, 248] 
regular batch size: 2*732, diving batch size 1*0
best_l after optimization: 177.34970092773438 with beta sum per layer: [1.8516700267791748, 302.754150390625, 542.9698486328125]
alpha/beta optimization time: 0.4521036148071289
This batch time : update_bounds func: 0.6982	 prepare: 0.1396	 bound: 0.4524	 transfer: 0.0162	 finalize: 0.0865
Accumulated time: update_bounds func: 4.4917	 prepare: 0.5800	 bound: 3.3958	 transfer: 0.0162	 finalize: 0.4054
batch bounding time:  0.6995375156402588
Current worst splitting domains [lb, ub] (depth):
[-1.35543,   inf] (28), [-1.32684,   inf] (28), [-1.32011,   inf] (28), [-1.29129,   inf] (28), [-1.25803,   inf] (28), [-1.24011,   inf] (28), [-1.23355,   inf] (28), [-1.19330,   inf] (28), [-1.18427,   inf] (28), [-1.17082,   inf] (28), [-1.16179,   inf] (28), [-1.15045,   inf] (28), [-1.12714,   inf] (28), [-1.12320,   inf] (28), [-1.11824,   inf] (28), [-1.10995,   inf] (28), [-1.10839,   inf] (28), [-1.09006,   inf] (28), [-1.06195,   inf] (28), [-1.06017,   inf] (28), 
length of domains: 854
Total time: 1.1145	 pickout: 0.1027	 decision: 0.2484	 get_bound: 0.7018	 add_domain: 0.0615
Current lb:-1.3554335832595825
6080 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.938059091567993

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([854, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([854, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 6] [2, 6] [1, 42] [1, 709] [1, 713] [1, 424] [1, 709] [1, 584] [2, 6] [1, 584] 
regular batch size: 2*854, diving batch size 1*0
best_l after optimization: 204.48939514160156 with beta sum per layer: [2.4374396800994873, 347.87872314453125, 588.781494140625]
alpha/beta optimization time: 0.503084659576416
This batch time : update_bounds func: 0.8562	 prepare: 0.1627	 bound: 0.5034	 transfer: 0.0253	 finalize: 0.1609
Accumulated time: update_bounds func: 5.3479	 prepare: 0.7427	 bound: 3.8992	 transfer: 0.0253	 finalize: 0.5663
batch bounding time:  0.8577916622161865
Current worst splitting domains [lb, ub] (depth):
[-1.28829,   inf] (30), [-1.26110,   inf] (30), [-1.24403,   inf] (30), [-1.23374,   inf] (30), [-1.20200,   inf] (30), [-1.20043,   inf] (30), [-1.16637,   inf] (30), [-1.16438,   inf] (30), [-1.15910,   inf] (30), [-1.14171,   inf] (30), [-1.13027,   inf] (30), [-1.12113,   inf] (30), [-1.11548,   inf] (30), [-1.10758,   inf] (30), [-1.08240,   inf] (30), [-1.06175,   inf] (30), [-1.06103,   inf] (30), [-1.05337,   inf] (30), [-1.02972,   inf] (30), [-1.02481,   inf] (30), 
length of domains: 1042
Total time: 1.3385	 pickout: 0.1214	 decision: 0.2786	 get_bound: 0.8606	 add_domain: 0.0779
Current lb:-1.2882918119430542
7788 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.293858289718628

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1042, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([1042, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 134] [1, 583] [1, 713] [1, 42] [1, 713] [1, 189] [1, 713] [1, 42] [1, 134] [1, 134] 
regular batch size: 2*1042, diving batch size 1*0
best_l after optimization: 219.89794921875 with beta sum per layer: [3.89208722114563, 451.89215087890625, 670.9974365234375]
alpha/beta optimization time: 0.5742363929748535
This batch time : update_bounds func: 0.9292	 prepare: 0.1994	 bound: 0.5746	 transfer: 0.0267	 finalize: 0.1235
Accumulated time: update_bounds func: 6.2771	 prepare: 0.9421	 bound: 4.4738	 transfer: 0.0267	 finalize: 0.6898
batch bounding time:  0.9310448169708252
Current worst splitting domains [lb, ub] (depth):
[-1.22281,   inf] (32), [-1.18952,   inf] (32), [-1.18847,   inf] (32), [-1.15488,   inf] (32), [-1.14889,   inf] (32), [-1.12724,   inf] (32), [-1.11589,   inf] (32), [-1.09991,   inf] (32), [-1.09408,   inf] (32), [-1.08818,   inf] (32), [-1.08538,   inf] (32), [-1.07919,   inf] (32), [-1.07240,   inf] (32), [-1.07124,   inf] (32), [-1.05914,   inf] (32), [-1.05003,   inf] (32), [-1.03476,   inf] (32), [-1.02920,   inf] (32), [-1.02371,   inf] (32), [-1.01654,   inf] (32), 
length of domains: 1200
Total time: 1.5292	 pickout: 0.1523	 decision: 0.3496	 get_bound: 0.9344	 add_domain: 0.0930
Current lb:-1.2228094339370728
9872 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.8460111618042

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1200, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([1200, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 424] [1, 709] [1, 584] [1, 584] [1, 189] [1, 583] [1, 584] [1, 584] [1, 584] [1, 584] 
regular batch size: 2*1200, diving batch size 1*0
best_l after optimization: 295.7136535644531 with beta sum per layer: [5.590188026428223, 561.1446533203125, 684.0494995117188]
alpha/beta optimization time: 0.63588547706604
This batch time : update_bounds func: 1.0558	 prepare: 0.2314	 bound: 0.6362	 transfer: 0.0438	 finalize: 0.1386
Accumulated time: update_bounds func: 7.3329	 prepare: 1.1735	 bound: 5.1100	 transfer: 0.0438	 finalize: 0.8285
batch bounding time:  1.057863473892212
Current worst splitting domains [lb, ub] (depth):
[-1.15735,   inf] (34), [-1.13834,   inf] (34), [-1.13709,   inf] (34), [-1.12431,   inf] (34), [-1.10556,   inf] (34), [-1.07565,   inf] (34), [-1.05971,   inf] (34), [-1.05928,   inf] (34), [-1.04823,   inf] (34), [-1.04751,   inf] (34), [-1.04037,   inf] (34), [-1.02915,   inf] (34), [-1.02647,   inf] (34), [-1.02593,   inf] (34), [-1.02308,   inf] (34), [-1.01317,   inf] (34), [-1.00688,   inf] (34), [-0.98716,   inf] (34), [-0.98412,   inf] (34), [-0.97828,   inf] (34), 
length of domains: 1460
Total time: 1.7856	 pickout: 0.1763	 decision: 0.4299	 get_bound: 1.0617	 add_domain: 0.1178
Current lb:-1.1573543548583984
12272 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.656743049621582

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1460, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([1460, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 263] [1, 134] [1, 42] [1, 189] [1, 42] [1, 189] [1, 709] [1, 263] [1, 189] [1, 263] 
regular batch size: 2*1460, diving batch size 1*0
best_l after optimization: 383.5037841796875 with beta sum per layer: [8.12778091430664, 703.1825561523438, 741.811279296875]
alpha/beta optimization time: 0.742328405380249
This batch time : update_bounds func: 1.3148	 prepare: 0.2818	 bound: 0.7427	 transfer: 0.0472	 finalize: 0.2363
Accumulated time: update_bounds func: 8.6476	 prepare: 1.4553	 bound: 5.8527	 transfer: 0.0472	 finalize: 1.0647
batch bounding time:  1.3173458576202393
Current worst splitting domains [lb, ub] (depth):
[-1.08672,   inf] (36), [-1.07401,   inf] (36), [-1.06028,   inf] (36), [-1.04205,   inf] (36), [-1.01993,   inf] (36), [-1.01189,   inf] (36), [-1.00836,   inf] (36), [-0.99509,   inf] (36), [-0.99331,   inf] (36), [-0.99248,   inf] (36), [-0.98873,   inf] (36), [-0.98624,   inf] (36), [-0.98176,   inf] (36), [-0.97649,   inf] (36), [-0.95850,   inf] (36), [-0.95843,   inf] (36), [-0.95817,   inf] (36), [-0.95198,   inf] (36), [-0.95142,   inf] (36), [-0.93731,   inf] (36), 
length of domains: 1860
Total time: 2.2021	 pickout: 0.2150	 decision: 0.5095	 get_bound: 1.3221	 add_domain: 0.1555
Current lb:-1.0867220163345337
15192 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.889898777008057

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1860, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([1860, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 189] [1, 583] [1, 424] [1, 583] [1, 424] [1, 424] [1, 134] [1, 42] [1, 263] [1, 189] 
regular batch size: 2*1860, diving batch size 1*0
best_l after optimization: 467.4964599609375 with beta sum per layer: [10.375652313232422, 948.4793090820312, 858.4473876953125]
alpha/beta optimization time: 0.9345583915710449
This batch time : update_bounds func: 1.6533	 prepare: 0.3603	 bound: 0.9349	 transfer: 0.0592	 finalize: 0.2893
Accumulated time: update_bounds func: 10.3009	 prepare: 1.8155	 bound: 6.7876	 transfer: 0.0592	 finalize: 1.3541
batch bounding time:  1.6564195156097412
Current worst splitting domains [lb, ub] (depth):
[-1.00732,   inf] (38), [-0.97488,   inf] (38), [-0.97105,   inf] (38), [-0.97096,   inf] (38), [-0.96028,   inf] (38), [-0.94132,   inf] (38), [-0.93873,   inf] (38), [-0.93841,   inf] (38), [-0.93498,   inf] (38), [-0.92420,   inf] (38), [-0.92273,   inf] (38), [-0.92127,   inf] (38), [-0.91782,   inf] (38), [-0.91774,   inf] (38), [-0.91247,   inf] (38), [-0.90061,   inf] (38), [-0.90053,   inf] (38), [-0.89800,   inf] (38), [-0.89385,   inf] (38), [-0.89141,   inf] (38), 
length of domains: 2344
Total time: 2.7710	 pickout: 0.2767	 decision: 0.6305	 get_bound: 1.6622	 add_domain: 0.2015
Current lb:-1.0073214769363403
18912 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.700763940811157

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 263] [1, 42] [1, 134] [1, 263] [1, 134] [1, 263] [1, 709] [1, 42] [1, 263] [1, 42] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 602.87451171875 with beta sum per layer: [9.812294006347656, 1099.167724609375, 849.4739379882812]
alpha/beta optimization time: 1.0121939182281494
This batch time : update_bounds func: 1.8026	 prepare: 0.3987	 bound: 1.0125	 transfer: 0.0661	 finalize: 0.3147
Accumulated time: update_bounds func: 12.1036	 prepare: 2.2142	 bound: 7.8001	 transfer: 0.0661	 finalize: 1.6688
batch bounding time:  1.806304931640625
Current worst splitting domains [lb, ub] (depth):
[-0.94208,   inf] (40), [-0.90783,   inf] (40), [-0.90569,   inf] (40), [-0.90067,   inf] (40), [-0.87625,   inf] (40), [-0.87114,   inf] (40), [-0.86980,   inf] (40), [-0.86947,   inf] (40), [-0.85826,   inf] (40), [-0.85713,   inf] (40), [-0.85258,   inf] (40), [-0.84987,   inf] (40), [-0.84837,   inf] (40), [-0.84414,   inf] (40), [-0.84140,   inf] (40), [-0.84043,   inf] (40), [-0.83897,   inf] (40), [-0.83494,   inf] (40), [-0.83354,   inf] (40), [-0.83178,   inf] (40), 
length of domains: 3233
Total time: 3.1663	 pickout: 0.3047	 decision: 0.6856	 get_bound: 1.8130	 add_domain: 0.3630
Current lb:-0.9420772790908813
23008 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 21.90854287147522

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 709] [1, 263] [1, 709] [0, 2322] [0, 2322] [1, 263] [2, 19] [1, 42] [1, 263] [1, 263] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 805.8167724609375 with beta sum per layer: [12.5296630859375, 1144.318359375, 687.593505859375]
alpha/beta optimization time: 1.0121808052062988
This batch time : update_bounds func: 1.9287	 prepare: 0.4012	 bound: 1.0125	 transfer: 0.0782	 finalize: 0.3454
Accumulated time: update_bounds func: 14.0322	 prepare: 2.6154	 bound: 8.8127	 transfer: 0.0782	 finalize: 2.0143
batch bounding time:  1.9328298568725586
Current worst splitting domains [lb, ub] (depth):
[-0.88209,   inf] (42), [-0.86973,   inf] (42), [-0.84565,   inf] (42), [-0.84494,   inf] (42), [-0.84031,   inf] (42), [-0.81360,   inf] (42), [-0.80697,   inf] (42), [-0.80341,   inf] (42), [-0.79949,   inf] (42), [-0.79633,   inf] (42), [-0.79391,   inf] (42), [-0.78921,   inf] (42), [-0.78907,   inf] (42), [-0.78662,   inf] (42), [-0.78638,   inf] (42), [-0.78205,   inf] (42), [-0.78113,   inf] (42), [-0.77890,   inf] (42), [-0.77784,   inf] (42), [-0.77650,   inf] (42), 
length of domains: 4634
Total time: 3.2192	 pickout: 0.3198	 decision: 0.6351	 get_bound: 1.9400	 add_domain: 0.3243
Current lb:-0.8820918798446655
27104 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 25.172467470169067

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 192] [2, 19] [2, 19] [1, 192] [1, 192] [1, 188] [1, 192] [1, 192] [1, 188] [2, 19] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 718.8819580078125 with beta sum per layer: [16.410675048828125, 1318.473876953125, 531.3426513671875]
alpha/beta optimization time: 1.0168359279632568
This batch time : update_bounds func: 1.8913	 prepare: 0.4047	 bound: 1.0172	 transfer: 0.0768	 finalize: 0.3817
Accumulated time: update_bounds func: 15.9236	 prepare: 3.0201	 bound: 9.8299	 transfer: 0.0768	 finalize: 2.3959
batch bounding time:  1.8950178623199463
Current worst splitting domains [lb, ub] (depth):
[-0.86879,   inf] (44), [-0.83174,   inf] (44), [-0.82717,   inf] (44), [-0.80824,   inf] (44), [-0.79433,   inf] (44), [-0.79026,   inf] (44), [-0.78450,   inf] (44), [-0.78264,   inf] (44), [-0.76581,   inf] (44), [-0.76525,   inf] (44), [-0.76002,   inf] (44), [-0.75538,   inf] (44), [-0.75465,   inf] (44), [-0.75093,   inf] (44), [-0.74223,   inf] (44), [-0.73622,   inf] (44), [-0.73184,   inf] (44), [-0.72978,   inf] (44), [-0.72856,   inf] (44), [-0.72755,   inf] (44), 
length of domains: 5844
Total time: 3.2981	 pickout: 0.3115	 decision: 0.7730	 get_bound: 1.9018	 add_domain: 0.3118
Current lb:-0.8687855005264282
31200 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 28.51316213607788

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 188] [1, 188] [2, 19] [1, 192] [1, 188] [2, 19] [1, 192] [1, 188] [1, 188] [1, 188] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 612.315185546875 with beta sum per layer: [13.69034194946289, 1367.680419921875, 485.6085205078125]
alpha/beta optimization time: 1.0188570022583008
This batch time : update_bounds func: 1.9282	 prepare: 0.4120	 bound: 1.0192	 transfer: 0.0776	 finalize: 0.4087
Accumulated time: update_bounds func: 17.8518	 prepare: 3.4321	 bound: 10.8491	 transfer: 0.0776	 finalize: 2.8046
batch bounding time:  1.9322941303253174
Current worst splitting domains [lb, ub] (depth):
[-0.79537,   inf] (46), [-0.78293,   inf] (46), [-0.77189,   inf] (46), [-0.76761,   inf] (46), [-0.76261,   inf] (46), [-0.74742,   inf] (46), [-0.74528,   inf] (46), [-0.73072,   inf] (46), [-0.72722,   inf] (46), [-0.71885,   inf] (46), [-0.71751,   inf] (46), [-0.71525,   inf] (46), [-0.71497,   inf] (46), [-0.70902,   inf] (46), [-0.69713,   inf] (46), [-0.69533,   inf] (46), [-0.69467,   inf] (46), [-0.69143,   inf] (46), [-0.69100,   inf] (46), [-0.69048,   inf] (46), 
length of domains: 6849
Total time: 3.3747	 pickout: 0.3123	 decision: 0.8196	 get_bound: 1.9393	 add_domain: 0.3034
Current lb:-0.7953677177429199
35296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 31.93474268913269

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 188] [2, 19] [1, 583] [1, 188] [2, 19] [1, 188] [2, 19] [1, 188] [2, 19] [1, 188] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 663.5340576171875 with beta sum per layer: [13.425511360168457, 1278.6204833984375, 419.96197509765625]
alpha/beta optimization time: 1.0156433582305908
This batch time : update_bounds func: 1.9238	 prepare: 0.4109	 bound: 1.0160	 transfer: 0.0770	 finalize: 0.4091
Accumulated time: update_bounds func: 19.7756	 prepare: 3.8430	 bound: 11.8651	 transfer: 0.0770	 finalize: 3.2137
batch bounding time:  1.9278266429901123
Current worst splitting domains [lb, ub] (depth):
[-0.72352,   inf] (48), [-0.72284,   inf] (48), [-0.71795,   inf] (48), [-0.70953,   inf] (48), [-0.70324,   inf] (48), [-0.68591,   inf] (48), [-0.68108,   inf] (48), [-0.67701,   inf] (48), [-0.67526,   inf] (48), [-0.67513,   inf] (48), [-0.67030,   inf] (48), [-0.66890,   inf] (48), [-0.66689,   inf] (48), [-0.66209,   inf] (48), [-0.65682,   inf] (48), [-0.65326,   inf] (48), [-0.65040,   inf] (48), [-0.64349,   inf] (48), [-0.64000,   inf] (48), [-0.63976,   inf] (48), 
length of domains: 8038
Total time: 3.4787	 pickout: 0.3116	 decision: 0.7110	 get_bound: 1.9350	 add_domain: 0.5211
Current lb:-0.7235232591629028
39392 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 35.46051907539368

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 717] [1, 717] [1, 717] [1, 717] [1, 717] [1, 717] [1, 717] [1, 717] [1, 722] [1, 722] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 533.7989501953125 with beta sum per layer: [14.525196075439453, 1324.8560791015625, 282.4146728515625]
alpha/beta optimization time: 1.0180420875549316
This batch time : update_bounds func: 1.9769	 prepare: 0.4144	 bound: 1.0184	 transfer: 0.0782	 finalize: 0.4547
Accumulated time: update_bounds func: 21.7525	 prepare: 4.2573	 bound: 12.8835	 transfer: 0.0782	 finalize: 3.6684
batch bounding time:  1.9808878898620605
Current worst splitting domains [lb, ub] (depth):
[-0.69471,   inf] (50), [-0.69308,   inf] (50), [-0.68900,   inf] (50), [-0.68084,   inf] (50), [-0.67356,   inf] (50), [-0.65703,   inf] (50), [-0.65138,   inf] (50), [-0.64785,   inf] (50), [-0.64123,   inf] (50), [-0.63879,   inf] (50), [-0.63726,   inf] (50), [-0.63004,   inf] (50), [-0.63002,   inf] (50), [-0.62785,   inf] (50), [-0.62756,   inf] (50), [-0.62478,   inf] (50), [-0.61394,   inf] (50), [-0.61056,   inf] (50), [-0.61032,   inf] (50), [-0.60793,   inf] (50), 
length of domains: 9116
Total time: 3.3749	 pickout: 0.3154	 decision: 0.7410	 get_bound: 1.9879	 add_domain: 0.3306
Current lb:-0.6947066783905029
43488 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 38.88455557823181

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 271] [1, 271] [1, 583] [1, 583] [2, 84] [1, 271] [1, 271] [1, 583] [0, 2349] [2, 84] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 656.486572265625 with beta sum per layer: [13.826009750366211, 1273.749267578125, 263.08123779296875]
alpha/beta optimization time: 1.0148952007293701
This batch time : update_bounds func: 1.9937	 prepare: 0.4136	 bound: 1.0152	 transfer: 0.0769	 finalize: 0.4765
Accumulated time: update_bounds func: 23.7462	 prepare: 4.6710	 bound: 13.8987	 transfer: 0.0769	 finalize: 4.1449
batch bounding time:  1.997467041015625
Current worst splitting domains [lb, ub] (depth):
[-0.64662,   inf] (52), [-0.64380,   inf] (52), [-0.64078,   inf] (52), [-0.63943,   inf] (52), [-0.62455,   inf] (52), [-0.60613,   inf] (52), [-0.60394,   inf] (52), [-0.59979,   inf] (52), [-0.59750,   inf] (52), [-0.58665,   inf] (52), [-0.58638,   inf] (52), [-0.57685,   inf] (52), [-0.57660,   inf] (52), [-0.57659,   inf] (52), [-0.57353,   inf] (52), [-0.57043,   inf] (52), [-0.56499,   inf] (52), [-0.56284,   inf] (52), [-0.56113,   inf] (52), [-0.56083,   inf] (52), 
length of domains: 10461
Total time: 3.4527	 pickout: 0.3187	 decision: 0.7652	 get_bound: 2.0042	 add_domain: 0.3645
Current lb:-0.6466183662414551
47584 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 42.3859601020813

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 271] [2, 84] [1, 188] [1, 271] [2, 84] [2, 84] [1, 271] [2, 84] [1, 271] [1, 271] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 743.17822265625 with beta sum per layer: [12.427701950073242, 1247.6761474609375, 241.48492431640625]
alpha/beta optimization time: 1.0149550437927246
This batch time : update_bounds func: 2.0204	 prepare: 0.4187	 bound: 1.0154	 transfer: 0.0788	 finalize: 0.4966
Accumulated time: update_bounds func: 25.7666	 prepare: 5.0896	 bound: 14.9141	 transfer: 0.0788	 finalize: 4.6415
batch bounding time:  2.0242552757263184
Current worst splitting domains [lb, ub] (depth):
[-0.59490,   inf] (54), [-0.58840,   inf] (54), [-0.57285,   inf] (54), [-0.56527,   inf] (54), [-0.55705,   inf] (54), [-0.55229,   inf] (54), [-0.54954,   inf] (54), [-0.54838,   inf] (54), [-0.54489,   inf] (54), [-0.54347,   inf] (54), [-0.54026,   inf] (54), [-0.53656,   inf] (54), [-0.53520,   inf] (54), [-0.53481,   inf] (54), [-0.53366,   inf] (54), [-0.52907,   inf] (54), [-0.51989,   inf] (54), [-0.51871,   inf] (54), [-0.51589,   inf] (54), [-0.51264,   inf] (54), 
length of domains: 12148
Total time: 3.5593	 pickout: 0.3201	 decision: 0.7923	 get_bound: 2.0314	 add_domain: 0.4155
Current lb:-0.5948985815048218
51680 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 45.9905903339386

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 84] [2, 84] [0, 2322] [2, 84] [2, 84] [0, 2322] [1, 271] [1, 271] [2, 84] [1, 188] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 746.0538330078125 with beta sum per layer: [23.550113677978516, 999.3494873046875, 252.09169006347656]
alpha/beta optimization time: 1.0114541053771973
This batch time : update_bounds func: 2.0501	 prepare: 0.4174	 bound: 1.0118	 transfer: 0.0779	 finalize: 0.5312
Accumulated time: update_bounds func: 27.8167	 prepare: 5.5070	 bound: 15.9259	 transfer: 0.0779	 finalize: 5.1727
batch bounding time:  2.0538952350616455
Current worst splitting domains [lb, ub] (depth):
[-0.54575,   inf] (56), [-0.52519,   inf] (56), [-0.52158,   inf] (56), [-0.52038,   inf] (56), [-0.51850,   inf] (56), [-0.51349,   inf] (56), [-0.50887,   inf] (56), [-0.50190,   inf] (56), [-0.50053,   inf] (56), [-0.49713,   inf] (56), [-0.49607,   inf] (56), [-0.49393,   inf] (56), [-0.49158,   inf] (56), [-0.49092,   inf] (56), [-0.48932,   inf] (56), [-0.48589,   inf] (56), [-0.48545,   inf] (56), [-0.48139,   inf] (56), [-0.47959,   inf] (56), [-0.47934,   inf] (56), 
length of domains: 13853
Total time: 3.6387	 pickout: 0.3220	 decision: 0.8278	 get_bound: 2.0607	 add_domain: 0.4282
Current lb:-0.5457460880279541
55776 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 49.67567205429077

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 107] [1, 107] [1, 107] [1, 107] [1, 193] [1, 193] [0, 2309] [1, 107] [1, 107] [0, 2322] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 827.0048217773438 with beta sum per layer: [27.04037094116211, 781.81103515625, 244.72586059570312]
alpha/beta optimization time: 1.0120909214019775
This batch time : update_bounds func: 2.0843	 prepare: 0.4304	 bound: 1.0124	 transfer: 0.0786	 finalize: 0.5513
Accumulated time: update_bounds func: 29.9010	 prepare: 5.9374	 bound: 16.9384	 transfer: 0.0786	 finalize: 5.7240
batch bounding time:  2.088148355484009
Current worst splitting domains [lb, ub] (depth):
[-0.52438,   inf] (58), [-0.49922,   inf] (58), [-0.49922,   inf] (58), [-0.49581,   inf] (58), [-0.48412,   inf] (58), [-0.48172,   inf] (58), [-0.47941,   inf] (58), [-0.47844,   inf] (58), [-0.47521,   inf] (58), [-0.47152,   inf] (58), [-0.46824,   inf] (58), [-0.46658,   inf] (58), [-0.46309,   inf] (58), [-0.46299,   inf] (58), [-0.45970,   inf] (58), [-0.45532,   inf] (58), [-0.45497,   inf] (58), [-0.45471,   inf] (58), [-0.45420,   inf] (58), [-0.45259,   inf] (58), 
length of domains: 15738
Total time: 3.7290	 pickout: 0.3290	 decision: 0.8462	 get_bound: 2.0951	 add_domain: 0.4586
Current lb:-0.524383544921875
59872 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 53.450143814086914

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 128] [1, 128] [1, 128] [0, 2309] [0, 2349] [0, 2349] [1, 128] [0, 2349] [1, 128] [1, 722] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 812.8953857421875 with beta sum per layer: [26.75714874267578, 679.8221435546875, 225.6939697265625]
alpha/beta optimization time: 1.0132949352264404
This batch time : update_bounds func: 2.1294	 prepare: 0.4341	 bound: 1.0137	 transfer: 0.0764	 finalize: 0.5938
Accumulated time: update_bounds func: 32.0304	 prepare: 6.3715	 bound: 17.9520	 transfer: 0.0764	 finalize: 6.3178
batch bounding time:  2.133744239807129
Current worst splitting domains [lb, ub] (depth):
[-0.47344,   inf] (60), [-0.46662,   inf] (60), [-0.45783,   inf] (60), [-0.45537,   inf] (60), [-0.45246,   inf] (60), [-0.44964,   inf] (60), [-0.44826,   inf] (60), [-0.44340,   inf] (60), [-0.43625,   inf] (60), [-0.43338,   inf] (60), [-0.43328,   inf] (60), [-0.43321,   inf] (60), [-0.43172,   inf] (60), [-0.43077,   inf] (60), [-0.43036,   inf] (60), [-0.42974,   inf] (60), [-0.42919,   inf] (60), [-0.42905,   inf] (60), [-0.42707,   inf] (60), [-0.42491,   inf] (60), 
length of domains: 17667
Total time: 3.8285	 pickout: 0.3262	 decision: 0.8838	 get_bound: 2.1410	 add_domain: 0.4775
Current lb:-0.47343695163726807
63968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 57.32476043701172

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 319] [1, 128] [1, 319] [1, 319] [1, 128] [1, 176] [1, 176] [1, 128] [1, 319] [1, 107] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 812.3283081054688 with beta sum per layer: [32.42385482788086, 622.19287109375, 206.13931274414062]
alpha/beta optimization time: 1.0140161514282227
This batch time : update_bounds func: 2.1465	 prepare: 0.4315	 bound: 1.0144	 transfer: 0.0784	 finalize: 0.2546
Accumulated time: update_bounds func: 34.1769	 prepare: 6.8030	 bound: 18.9664	 transfer: 0.0784	 finalize: 6.5724
batch bounding time:  2.1501333713531494
Current worst splitting domains [lb, ub] (depth):
[-0.43734,   inf] (62), [-0.43190,   inf] (62), [-0.43027,   inf] (62), [-0.42579,   inf] (62), [-0.42337,   inf] (62), [-0.41975,   inf] (62), [-0.41153,   inf] (62), [-0.41121,   inf] (62), [-0.40860,   inf] (62), [-0.40754,   inf] (62), [-0.40419,   inf] (62), [-0.40302,   inf] (62), [-0.40120,   inf] (62), [-0.40017,   inf] (62), [-0.39971,   inf] (62), [-0.39897,   inf] (62), [-0.39747,   inf] (62), [-0.39695,   inf] (62), [-0.39605,   inf] (62), [-0.39385,   inf] (62), 
length of domains: 19656
Total time: 3.5513	 pickout: 0.3267	 decision: 0.5723	 get_bound: 2.1568	 add_domain: 0.4954
Current lb:-0.43734419345855713
68064 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 60.92205047607422

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 176] [1, 722] [1, 722] [1, 722] [0, 2309] [0, 2309] [1, 319] [1, 319] [1, 128] [1, 722] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 746.323486328125 with beta sum per layer: [40.24860382080078, 616.4683837890625, 183.7703399658203]
alpha/beta optimization time: 1.0128085613250732
This batch time : update_bounds func: 1.7983	 prepare: 0.4387	 bound: 1.0132	 transfer: 0.0780	 finalize: 0.2570
Accumulated time: update_bounds func: 35.9752	 prepare: 7.2417	 bound: 19.9795	 transfer: 0.0780	 finalize: 6.8293
batch bounding time:  1.8021190166473389
Current worst splitting domains [lb, ub] (depth):
[-0.42157,   inf] (64), [-0.39645,   inf] (64), [-0.39491,   inf] (64), [-0.39264,   inf] (64), [-0.39175,   inf] (64), [-0.38879,   inf] (64), [-0.37764,   inf] (64), [-0.37584,   inf] (64), [-0.37452,   inf] (64), [-0.37377,   inf] (64), [-0.37217,   inf] (64), [-0.37165,   inf] (64), [-0.36874,   inf] (64), [-0.36716,   inf] (64), [-0.36650,   inf] (64), [-0.36630,   inf] (64), [-0.36437,   inf] (64), [-0.36408,   inf] (64), [-0.36254,   inf] (64), [-0.36244,   inf] (64), 
length of domains: 21608
Total time: 4.0776	 pickout: 0.3301	 decision: 0.9718	 get_bound: 1.8090	 add_domain: 0.9667
Current lb:-0.4215749502182007
72160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 65.04962515830994

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 722] [1, 319] [0, 2322] [1, 128] [1, 319] [1, 128] [1, 722] [1, 176] [1, 319] [1, 107] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 631.0773315429688 with beta sum per layer: [45.488380432128906, 623.423095703125, 165.52430725097656]
alpha/beta optimization time: 1.015904426574707
This batch time : update_bounds func: 2.2900	 prepare: 0.4374	 bound: 1.0163	 transfer: 0.0783	 finalize: 0.7457
Accumulated time: update_bounds func: 38.2651	 prepare: 7.6791	 bound: 20.9958	 transfer: 0.0783	 finalize: 7.5750
batch bounding time:  2.2937936782836914
Current worst splitting domains [lb, ub] (depth):
[-0.38568,   inf] (66), [-0.36863,   inf] (66), [-0.35908,   inf] (66), [-0.35730,   inf] (66), [-0.35182,   inf] (66), [-0.34806,   inf] (66), [-0.34784,   inf] (66), [-0.34615,   inf] (66), [-0.34566,   inf] (66), [-0.34244,   inf] (66), [-0.34103,   inf] (66), [-0.34029,   inf] (66), [-0.33988,   inf] (66), [-0.33954,   inf] (66), [-0.33618,   inf] (66), [-0.33600,   inf] (66), [-0.33402,   inf] (66), [-0.33269,   inf] (66), [-0.33260,   inf] (66), [-0.33258,   inf] (66), 
length of domains: 23411
Total time: 3.6971	 pickout: 0.3306	 decision: 0.5729	 get_bound: 2.3007	 add_domain: 0.4929
Current lb:-0.3856751024723053
76256 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 68.79897499084473

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [0, 2309] [1, 196] [0, 2309] [0, 2349] [1, 722] [1, 722] [1, 107] [1, 193] [0, 2309] [1, 128] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 396.9951477050781 with beta sum per layer: [45.15082550048828, 679.8834228515625, 188.44544982910156]
alpha/beta optimization time: 1.0147733688354492
This batch time : update_bounds func: 2.2965	 prepare: 0.4377	 bound: 1.0151	 transfer: 0.0763	 finalize: 0.7559
Accumulated time: update_bounds func: 40.5616	 prepare: 8.1168	 bound: 22.0109	 transfer: 0.0763	 finalize: 8.3309
batch bounding time:  2.30039644241333
Current worst splitting domains [lb, ub] (depth):
[-0.35841,   inf] (68), [-0.35307,   inf] (68), [-0.33164,   inf] (68), [-0.32915,   inf] (68), [-0.32685,   inf] (68), [-0.32556,   inf] (68), [-0.32325,   inf] (68), [-0.32210,   inf] (68), [-0.32125,   inf] (68), [-0.31865,   inf] (68), [-0.31782,   inf] (68), [-0.31675,   inf] (68), [-0.31638,   inf] (68), [-0.31439,   inf] (68), [-0.31341,   inf] (68), [-0.31237,   inf] (68), [-0.31189,   inf] (68), [-0.31052,   inf] (68), [-0.30857,   inf] (68), [-0.30855,   inf] (68), 
length of domains: 24859
Total time: 3.6707	 pickout: 0.3313	 decision: 0.5751	 get_bound: 2.3074	 add_domain: 0.4570
Current lb:-0.35840508341789246
80352 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 72.52497625350952

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 317] [1, 196] [1, 193] [1, 196] [1, 196] [1, 317] [1, 722] [1, 317] [1, 317] [1, 107] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 307.0833740234375 with beta sum per layer: [42.73463439941406, 676.353271484375, 174.50677490234375]
alpha/beta optimization time: 1.0129399299621582
This batch time : update_bounds func: 1.8004	 prepare: 0.4366	 bound: 1.0133	 transfer: 0.0783	 finalize: 0.2594
Accumulated time: update_bounds func: 42.3620	 prepare: 8.5534	 bound: 23.0242	 transfer: 0.0783	 finalize: 8.5903
batch bounding time:  1.8043882846832275
Current worst splitting domains [lb, ub] (depth):
[-0.34268,   inf] (70), [-0.34255,   inf] (70), [-0.31917,   inf] (70), [-0.31720,   inf] (70), [-0.30765,   inf] (70), [-0.30638,   inf] (70), [-0.30626,   inf] (70), [-0.30538,   inf] (70), [-0.30061,   inf] (70), [-0.29894,   inf] (70), [-0.29760,   inf] (70), [-0.29687,   inf] (70), [-0.29626,   inf] (70), [-0.29456,   inf] (70), [-0.29411,   inf] (70), [-0.29400,   inf] (70), [-0.29244,   inf] (70), [-0.29182,   inf] (70), [-0.29010,   inf] (70), [-0.28800,   inf] (70), 
length of domains: 26107
Total time: 3.6988	 pickout: 0.3346	 decision: 1.1194	 get_bound: 1.8116	 add_domain: 0.4332
Current lb:-0.3426778316497803
84448 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 76.28435635566711

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [0, 2309] [1, 317] [1, 317] [1, 317] [0, 2349] [1, 317] [0, 2309] [1, 129] [1, 196] [1, 317] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 321.4481506347656 with beta sum per layer: [40.01683807373047, 691.1632080078125, 172.3651123046875]
alpha/beta optimization time: 1.012373447418213
This batch time : update_bounds func: 1.8022	 prepare: 0.4376	 bound: 1.0127	 transfer: 0.0768	 finalize: 0.2619
Accumulated time: update_bounds func: 44.1642	 prepare: 8.9910	 bound: 24.0370	 transfer: 0.0768	 finalize: 8.8522
batch bounding time:  1.806304693222046
Current worst splitting domains [lb, ub] (depth):
[-0.32601,   inf] (72), [-0.31535,   inf] (72), [-0.30336,   inf] (72), [-0.29884,   inf] (72), [-0.29475,   inf] (72), [-0.28839,   inf] (72), [-0.28760,   inf] (72), [-0.28246,   inf] (72), [-0.28238,   inf] (72), [-0.28110,   inf] (72), [-0.28086,   inf] (72), [-0.28004,   inf] (72), [-0.27967,   inf] (72), [-0.27384,   inf] (72), [-0.27348,   inf] (72), [-0.27309,   inf] (72), [-0.27163,   inf] (72), [-0.27141,   inf] (72), [-0.27135,   inf] (72), [-0.27107,   inf] (72), 
length of domains: 27439
Total time: 3.7482	 pickout: 0.3352	 decision: 1.1510	 get_bound: 1.8136	 add_domain: 0.4483
Current lb:-0.32601115107536316
88544 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 80.09335589408875

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [0, 2349] [1, 129] [0, 2349] [1, 129] [1, 317] [1, 129] [1, 129] [0, 2349] [0, 2243] [1, 102] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 333.71112060546875 with beta sum per layer: [41.488426208496094, 750.1177978515625, 205.9375]
alpha/beta optimization time: 1.0112190246582031
This batch time : update_bounds func: 1.8105	 prepare: 0.4435	 bound: 1.0116	 transfer: 0.0776	 finalize: 0.2648
Accumulated time: update_bounds func: 45.9746	 prepare: 9.4344	 bound: 25.0485	 transfer: 0.0776	 finalize: 9.1171
batch bounding time:  1.8145220279693604
Current worst splitting domains [lb, ub] (depth):
[-0.30011,   inf] (74), [-0.28529,   inf] (74), [-0.28238,   inf] (74), [-0.27923,   inf] (74), [-0.27792,   inf] (74), [-0.27400,   inf] (74), [-0.27392,   inf] (74), [-0.27223,   inf] (74), [-0.26875,   inf] (74), [-0.26516,   inf] (74), [-0.25942,   inf] (74), [-0.25940,   inf] (74), [-0.25868,   inf] (74), [-0.25819,   inf] (74), [-0.25643,   inf] (74), [-0.25617,   inf] (74), [-0.25567,   inf] (74), [-0.25232,   inf] (74), [-0.25139,   inf] (74), [-0.25131,   inf] (74), 
length of domains: 28896
Total time: 3.8120	 pickout: 0.3334	 decision: 1.1920	 get_bound: 1.8218	 add_domain: 0.4649
Current lb:-0.3001115918159485
92640 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 83.965815782547

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [0, 2243] [0, 2243] [0, 2309] [1, 129] [0, 2243] [0, 2243] [1, 129] [1, 722] [0, 2243] [1, 319] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 319.02691650390625 with beta sum per layer: [45.772361755371094, 782.4952392578125, 206.67640686035156]
alpha/beta optimization time: 1.0153985023498535
This batch time : update_bounds func: 1.8153	 prepare: 0.4421	 bound: 1.0158	 transfer: 0.0763	 finalize: 0.2678
Accumulated time: update_bounds func: 47.7899	 prepare: 9.8765	 bound: 26.0643	 transfer: 0.0763	 finalize: 9.3849
batch bounding time:  1.8195290565490723
Current worst splitting domains [lb, ub] (depth):
[-0.29944,   inf] (76), [-0.28500,   inf] (76), [-0.27792,   inf] (76), [-0.27338,   inf] (76), [-0.26860,   inf] (76), [-0.26182,   inf] (76), [-0.25868,   inf] (76), [-0.25807,   inf] (76), [-0.25540,   inf] (76), [-0.25131,   inf] (76), [-0.24923,   inf] (76), [-0.24830,   inf] (76), [-0.24338,   inf] (76), [-0.24263,   inf] (76), [-0.24226,   inf] (76), [-0.24046,   inf] (76), [-0.23995,   inf] (76), [-0.23823,   inf] (76), [-0.23750,   inf] (76), [-0.23697,   inf] (76), 
length of domains: 30403
Total time: 3.8761	 pickout: 0.3353	 decision: 1.2426	 get_bound: 1.8270	 add_domain: 0.4712
Current lb:-0.2994420528411865
96736 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 87.90655207633972

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 129] [1, 319] [1, 129] [1, 129] [0, 2349] [1, 129] [1, 643] [1, 319] [1, 129] [1, 129] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 265.0401611328125 with beta sum per layer: [46.92521286010742, 851.8235473632812, 252.66868591308594]
alpha/beta optimization time: 1.0114161968231201
This batch time : update_bounds func: 1.8132	 prepare: 0.4395	 bound: 1.0118	 transfer: 0.0783	 finalize: 0.2708
Accumulated time: update_bounds func: 49.6031	 prepare: 10.3161	 bound: 27.0761	 transfer: 0.0783	 finalize: 9.6557
batch bounding time:  1.817415714263916
Current worst splitting domains [lb, ub] (depth):
[-0.26939,   inf] (78), [-0.24841,   inf] (78), [-0.24812,   inf] (78), [-0.24348,   inf] (78), [-0.24330,   inf] (78), [-0.24263,   inf] (78), [-0.24175,   inf] (78), [-0.24168,   inf] (78), [-0.24131,   inf] (78), [-0.23750,   inf] (78), [-0.23697,   inf] (78), [-0.23488,   inf] (78), [-0.23422,   inf] (78), [-0.23243,   inf] (78), [-0.22512,   inf] (78), [-0.22484,   inf] (78), [-0.22164,   inf] (78), [-0.22154,   inf] (78), [-0.22153,   inf] (78), [-0.21918,   inf] (78), 
length of domains: 31803
Total time: 3.9210	 pickout: 0.3412	 decision: 1.2972	 get_bound: 1.8249	 add_domain: 0.4577
Current lb:-0.26939183473587036
100832 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 91.89558863639832

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 102] [1, 102] [1, 643] [1, 643] [1, 102] [1, 643] [1, 634] [1, 102] [1, 319] [1, 643] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 227.60487365722656 with beta sum per layer: [46.66694641113281, 876.891357421875, 245.1241455078125]
alpha/beta optimization time: 1.0124852657318115
This batch time : update_bounds func: 1.8342	 prepare: 0.4527	 bound: 1.0128	 transfer: 0.0783	 finalize: 0.2771
Accumulated time: update_bounds func: 51.4373	 prepare: 10.7687	 bound: 28.0889	 transfer: 0.0783	 finalize: 9.9328
batch bounding time:  1.8383879661560059
Current worst splitting domains [lb, ub] (depth):
[-0.26133,   inf] (80), [-0.24048,   inf] (80), [-0.23517,   inf] (80), [-0.23339,   inf] (80), [-0.22995,   inf] (80), [-0.22678,   inf] (80), [-0.22624,   inf] (80), [-0.22593,   inf] (80), [-0.22402,   inf] (80), [-0.22300,   inf] (80), [-0.21738,   inf] (80), [-0.21644,   inf] (80), [-0.21611,   inf] (80), [-0.21369,   inf] (80), [-0.21273,   inf] (80), [-0.20932,   inf] (80), [-0.20704,   inf] (80), [-0.20648,   inf] (80), [-0.20550,   inf] (80), [-0.20403,   inf] (80), 
length of domains: 33136
Total time: 3.9531	 pickout: 0.3422	 decision: 1.3176	 get_bound: 1.8459	 add_domain: 0.4473
Current lb:-0.2613273561000824
104928 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 95.91392731666565

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 643] [1, 643] [1, 643] [1, 643] [1, 176] [1, 643] [1, 643] [1, 102] [1, 643] [1, 634] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 199.88697814941406 with beta sum per layer: [47.23283386230469, 867.9981079101562, 250.09530639648438]
alpha/beta optimization time: 1.0123262405395508
This batch time : update_bounds func: 2.5892	 prepare: 0.4444	 bound: 1.0127	 transfer: 0.0770	 finalize: 0.2730
Accumulated time: update_bounds func: 54.0265	 prepare: 11.2131	 bound: 29.1016	 transfer: 0.0770	 finalize: 10.2058
batch bounding time:  2.5933680534362793
Current worst splitting domains [lb, ub] (depth):
[-0.24574,   inf] (82), [-0.22615,   inf] (82), [-0.21963,   inf] (82), [-0.21779,   inf] (82), [-0.21764,   inf] (82), [-0.21095,   inf] (82), [-0.21069,   inf] (82), [-0.20791,   inf] (82), [-0.20043,   inf] (82), [-0.19989,   inf] (82), [-0.19929,   inf] (82), [-0.19732,   inf] (82), [-0.19311,   inf] (82), [-0.19200,   inf] (82), [-0.19045,   inf] (82), [-0.18885,   inf] (82), [-0.18833,   inf] (82), [-0.18570,   inf] (82), [-0.18564,   inf] (82), [-0.18555,   inf] (82), 
length of domains: 34438
Total time: 4.0065	 pickout: 0.3648	 decision: 0.5934	 get_bound: 2.6009	 add_domain: 0.4473
Current lb:-0.2457401156425476
109024 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 99.98646974563599

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 74] [2, 74] [2, 74] [2, 74] [2, 74] [2, 74] [2, 74] [2, 74] [2, 74] [2, 74] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 192.79527282714844 with beta sum per layer: [46.851959228515625, 875.38330078125, 290.0281677246094]
alpha/beta optimization time: 1.0123767852783203
This batch time : update_bounds func: 2.6505	 prepare: 0.4448	 bound: 1.0127	 transfer: 0.0791	 finalize: 1.1000
Accumulated time: update_bounds func: 56.6770	 prepare: 11.6579	 bound: 30.1143	 transfer: 0.0791	 finalize: 11.3058
batch bounding time:  2.654688835144043
Current worst splitting domains [lb, ub] (depth):
[-0.22942,   inf] (84), [-0.20955,   inf] (84), [-0.20327,   inf] (84), [-0.20166,   inf] (84), [-0.20142,   inf] (84), [-0.19498,   inf] (84), [-0.19451,   inf] (84), [-0.19177,   inf] (84), [-0.18564,   inf] (84), [-0.18405,   inf] (84), [-0.18266,   inf] (84), [-0.18264,   inf] (84), [-0.18077,   inf] (84), [-0.17649,   inf] (84), [-0.17588,   inf] (84), [-0.17461,   inf] (84), [-0.17234,   inf] (84), [-0.17214,   inf] (84), [-0.16952,   inf] (84), [-0.16931,   inf] (84), 
length of domains: 35743
Total time: 4.0613	 pickout: 0.3480	 decision: 0.6034	 get_bound: 2.6623	 add_domain: 0.4475
Current lb:-0.22941748797893524
113120 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 104.11442303657532

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 634] [1, 634] [1, 634] [1, 634] [1, 634] [1, 634] [1, 634] [1, 634] [1, 634] [1, 228] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 186.83868408203125 with beta sum per layer: [44.200199127197266, 906.0660400390625, 279.9334411621094]
alpha/beta optimization time: 1.0138165950775146
This batch time : update_bounds func: 1.8301	 prepare: 0.4492	 bound: 1.0142	 transfer: 0.0791	 finalize: 0.2746
Accumulated time: update_bounds func: 58.5071	 prepare: 12.1072	 bound: 31.1285	 transfer: 0.0791	 finalize: 11.5804
batch bounding time:  1.8344626426696777
Current worst splitting domains [lb, ub] (depth):
[-0.18282,   inf] (86), [-0.18081,   inf] (86), [-0.16952,   inf] (86), [-0.16319,   inf] (86), [-0.16318,   inf] (86), [-0.16167,   inf] (86), [-0.16121,   inf] (86), [-0.15843,   inf] (76), [-0.15823,   inf] (78), [-0.15803,   inf] (72), [-0.15780,   inf] (74), [-0.15770,   inf] (76), [-0.15767,   inf] (80), [-0.15755,   inf] (80), [-0.15750,   inf] (78), [-0.15744,   inf] (76), [-0.15739,   inf] (78), [-0.15728,   inf] (72), [-0.15726,   inf] (78), [-0.15711,   inf] (78), 
length of domains: 37097
Total time: 4.1818	 pickout: 0.3482	 decision: 0.6062	 get_bound: 1.8423	 add_domain: 1.3850
Current lb:-0.1828157603740692
117216 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 108.36098623275757

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 228] [1, 228] [1, 634] [1, 228] [1, 228] [2, 1] [1, 634] [1, 634] [1, 643] [1, 129] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 163.54444885253906 with beta sum per layer: [45.874534606933594, 918.4307861328125, 271.909912109375]
alpha/beta optimization time: 1.0129306316375732
This batch time : update_bounds func: 1.8209	 prepare: 0.4428	 bound: 1.0133	 transfer: 0.0776	 finalize: 0.2736
Accumulated time: update_bounds func: 60.3281	 prepare: 12.5500	 bound: 32.1418	 transfer: 0.0776	 finalize: 11.8540
batch bounding time:  1.8251426219940186
Current worst splitting domains [lb, ub] (depth):
[-0.16769,   inf] (88), [-0.16564,   inf] (88), [-0.15495,   inf] (78), [-0.15456,   inf] (80), [-0.15451,   inf] (82), [-0.15444,   inf] (78), [-0.15415,   inf] (72), [-0.15404,   inf] (76), [-0.15394,   inf] (78), [-0.15389,   inf] (76), [-0.15384,   inf] (80), [-0.15361,   inf] (74), [-0.15350,   inf] (82), [-0.15350,   inf] (78), [-0.15343,   inf] (82), [-0.15342,   inf] (72), [-0.15330,   inf] (74), [-0.15330,   inf] (76), [-0.15326,   inf] (76), [-0.15294,   inf] (76), 
length of domains: 38404
Total time: 3.2327	 pickout: 0.3491	 decision: 0.6033	 get_bound: 1.8329	 add_domain: 0.4475
Current lb:-0.16769498586654663
121312 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 111.65973663330078

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 1] [2, 1] [1, 643] [1, 634] [1, 306] [1, 643] [1, 129] [1, 643] [1, 129] [1, 643] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 145.15380859375 with beta sum per layer: [49.297096252441406, 943.2579956054688, 284.4666442871094]
alpha/beta optimization time: 1.013639211654663
This batch time : update_bounds func: 1.8344	 prepare: 0.4531	 bound: 1.0140	 transfer: 0.0782	 finalize: 0.2755
Accumulated time: update_bounds func: 62.1624	 prepare: 13.0030	 bound: 33.1558	 transfer: 0.0782	 finalize: 12.1295
batch bounding time:  1.8386144638061523
Current worst splitting domains [lb, ub] (depth):
[-0.15822,   inf] (90), [-0.15597,   inf] (90), [-0.15101,   inf] (78), [-0.15097,   inf] (76), [-0.15080,   inf] (78), [-0.15074,   inf] (80), [-0.15061,   inf] (78), [-0.15056,   inf] (76), [-0.15054,   inf] (76), [-0.15054,   inf] (76), [-0.15044,   inf] (72), [-0.15039,   inf] (78), [-0.15039,   inf] (82), [-0.15000,   inf] (76), [-0.14980,   inf] (78), [-0.14973,   inf] (68), [-0.14965,   inf] (76), [-0.14943,   inf] (78), [-0.14919,   inf] (74), [-0.14876,   inf] (76), 
length of domains: 39672
Total time: 4.1793	 pickout: 0.3473	 decision: 1.5413	 get_bound: 1.8464	 add_domain: 0.4443
Current lb:-0.1582188457250595
125408 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 115.90629839897156

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 193] [1, 306] [2, 74] [1, 643] [1, 643] [1, 634] [0, 2309] [1, 634] [1, 643] [1, 129] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 143.45840454101562 with beta sum per layer: [46.574520111083984, 897.7537841796875, 285.765625]
alpha/beta optimization time: 1.0132548809051514
This batch time : update_bounds func: 2.7843	 prepare: 0.4542	 bound: 1.0136	 transfer: 0.0783	 finalize: 0.2751
Accumulated time: update_bounds func: 64.9467	 prepare: 13.4573	 bound: 34.1694	 transfer: 0.0783	 finalize: 12.4046
batch bounding time:  2.788652181625366
Current worst splitting domains [lb, ub] (depth):
[-0.15318,   inf] (92), [-0.14758,   inf] (78), [-0.14757,   inf] (76), [-0.14756,   inf] (72), [-0.14747,   inf] (78), [-0.14731,   inf] (76), [-0.14722,   inf] (80), [-0.14708,   inf] (70), [-0.14693,   inf] (70), [-0.14674,   inf] (76), [-0.14663,   inf] (74), [-0.14654,   inf] (80), [-0.14652,   inf] (80), [-0.14646,   inf] (74), [-0.14623,   inf] (78), [-0.14607,   inf] (76), [-0.14603,   inf] (72), [-0.14583,   inf] (76), [-0.14561,   inf] (78), [-0.14554,   inf] (74), 
length of domains: 40963
Total time: 4.2047	 pickout: 0.3509	 decision: 0.6080	 get_bound: 2.7963	 add_domain: 0.4494
Current lb:-0.1531781107187271
129504 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 120.17717790603638

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 193] [1, 643] [1, 319] [1, 129] [1, 643] [1, 102] [1, 634] [0, 2309] [1, 129] [1, 643] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 122.77210998535156 with beta sum per layer: [48.721282958984375, 930.967041015625, 305.8013916015625]
alpha/beta optimization time: 1.014371395111084
This batch time : update_bounds func: 1.8339	 prepare: 0.4507	 bound: 1.0147	 transfer: 0.0785	 finalize: 0.2758
Accumulated time: update_bounds func: 66.7806	 prepare: 13.9080	 bound: 35.1842	 transfer: 0.0785	 finalize: 12.6804
batch bounding time:  1.8380630016326904
Current worst splitting domains [lb, ub] (depth):
[-0.14425,   inf] (82), [-0.14414,   inf] (70), [-0.14410,   inf] (76), [-0.14394,   inf] (76), [-0.14377,   inf] (80), [-0.14374,   inf] (78), [-0.14365,   inf] (68), [-0.14354,   inf] (76), [-0.14349,   inf] (82), [-0.14348,   inf] (78), [-0.14345,   inf] (70), [-0.14335,   inf] (76), [-0.14328,   inf] (80), [-0.14326,   inf] (80), [-0.14308,   inf] (78), [-0.14303,   inf] (84), [-0.14302,   inf] (82), [-0.14299,   inf] (74), [-0.14282,   inf] (80), [-0.14275,   inf] (80), 
length of domains: 42196
Total time: 4.2790	 pickout: 0.3494	 decision: 0.6097	 get_bound: 1.8457	 add_domain: 1.4742
Current lb:-0.14425286650657654
133600 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 124.52347755432129

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 176] [1, 196] [1, 634] [1, 643] [1, 634] [1, 634] [1, 317] [1, 102] [1, 176] [1, 102] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 139.64471435546875 with beta sum per layer: [45.130126953125, 907.8323974609375, 274.628173828125]
alpha/beta optimization time: 1.0139126777648926
This batch time : update_bounds func: 1.8384	 prepare: 0.4528	 bound: 1.0143	 transfer: 0.0784	 finalize: 0.2790
Accumulated time: update_bounds func: 68.6190	 prepare: 14.3608	 bound: 36.1985	 transfer: 0.0784	 finalize: 12.9594
batch bounding time:  1.842592716217041
Current worst splitting domains [lb, ub] (depth):
[-0.14110,   inf] (78), [-0.14091,   inf] (78), [-0.14091,   inf] (78), [-0.14088,   inf] (78), [-0.14074,   inf] (82), [-0.14069,   inf] (74), [-0.14068,   inf] (78), [-0.14058,   inf] (78), [-0.14052,   inf] (72), [-0.14033,   inf] (78), [-0.14005,   inf] (80), [-0.13998,   inf] (78), [-0.13997,   inf] (80), [-0.13973,   inf] (76), [-0.13962,   inf] (74), [-0.13952,   inf] (82), [-0.13940,   inf] (76), [-0.13919,   inf] (76), [-0.13909,   inf] (76), [-0.13906,   inf] (76), 
length of domains: 43479
Total time: 3.2601	 pickout: 0.3499	 decision: 0.6111	 get_bound: 1.8504	 add_domain: 0.4487
Current lb:-0.1411048173904419
137696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 127.85189700126648

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 643] [1, 102] [1, 643] [1, 129] [1, 176] [1, 317] [1, 634] [1, 643] [1, 129] [1, 643] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 119.165283203125 with beta sum per layer: [45.791778564453125, 891.3008422851562, 283.5217590332031]
alpha/beta optimization time: 1.0134007930755615
This batch time : update_bounds func: 1.8374	 prepare: 0.4523	 bound: 1.0138	 transfer: 0.0785	 finalize: 0.2781
Accumulated time: update_bounds func: 70.4564	 prepare: 14.8131	 bound: 37.2123	 transfer: 0.0785	 finalize: 13.2375
batch bounding time:  1.8416950702667236
Current worst splitting domains [lb, ub] (depth):
[-0.13818,   inf] (76), [-0.13788,   inf] (80), [-0.13770,   inf] (76), [-0.13769,   inf] (76), [-0.13769,   inf] (74), [-0.13768,   inf] (74), [-0.13766,   inf] (70), [-0.13761,   inf] (82), [-0.13743,   inf] (74), [-0.13729,   inf] (74), [-0.13697,   inf] (78), [-0.13688,   inf] (78), [-0.13686,   inf] (82), [-0.13682,   inf] (76), [-0.13682,   inf] (74), [-0.13658,   inf] (78), [-0.13654,   inf] (76), [-0.13654,   inf] (78), [-0.13633,   inf] (80), [-0.13632,   inf] (76), 
length of domains: 44685
Total time: 4.2985	 pickout: 0.3535	 decision: 1.6529	 get_bound: 1.8495	 add_domain: 0.4426
Current lb:-0.13817855715751648
141792 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 132.21923685073853

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 102] [1, 634] [1, 634] [1, 643] [1, 643] [1, 317] [0, 2309] [1, 176] [1, 102] [1, 196] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 116.89102172851562 with beta sum per layer: [49.62193298339844, 911.0310668945312, 259.1634521484375]
alpha/beta optimization time: 1.0138041973114014
This batch time : update_bounds func: 2.9876	 prepare: 0.4523	 bound: 1.0142	 transfer: 0.0760	 finalize: 1.4311
Accumulated time: update_bounds func: 73.4440	 prepare: 15.2654	 bound: 38.2264	 transfer: 0.0760	 finalize: 14.6686
batch bounding time:  2.9929213523864746
Current worst splitting domains [lb, ub] (depth):
[-0.13496,   inf] (76), [-0.13490,   inf] (68), [-0.13456,   inf] (82), [-0.13452,   inf] (78), [-0.13450,   inf] (80), [-0.13432,   inf] (80), [-0.13428,   inf] (72), [-0.13424,   inf] (68), [-0.13420,   inf] (78), [-0.13394,   inf] (82), [-0.13388,   inf] (76), [-0.13381,   inf] (78), [-0.13360,   inf] (80), [-0.13354,   inf] (72), [-0.13324,   inf] (74), [-0.13319,   inf] (76), [-0.13316,   inf] (76), [-0.13307,   inf] (76), [-0.13298,   inf] (84), [-0.13286,   inf] (80), 
length of domains: 45859
Total time: 4.4021	 pickout: 0.3493	 decision: 0.6131	 get_bound: 3.0017	 add_domain: 0.4380
Current lb:-0.1349606215953827
145888 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 136.69022727012634

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 129] [1, 317] [2, 74] [1, 643] [1, 634] [0, 2309] [1, 129] [1, 196] [1, 176] [1, 634] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 103.35228729248047 with beta sum per layer: [46.303367614746094, 925.2455444335938, 281.76556396484375]
alpha/beta optimization time: 1.0132193565368652
This batch time : update_bounds func: 1.8622	 prepare: 0.4657	 bound: 1.0136	 transfer: 0.0777	 finalize: 0.2910
Accumulated time: update_bounds func: 75.3062	 prepare: 15.7312	 bound: 39.2400	 transfer: 0.0777	 finalize: 14.9596
batch bounding time:  1.8667120933532715
Current worst splitting domains [lb, ub] (depth):
[-0.13217,   inf] (82), [-0.13217,   inf] (76), [-0.13197,   inf] (82), [-0.13173,   inf] (76), [-0.13166,   inf] (76), [-0.13160,   inf] (78), [-0.13155,   inf] (78), [-0.13144,   inf] (76), [-0.13141,   inf] (80), [-0.13114,   inf] (76), [-0.13107,   inf] (76), [-0.13096,   inf] (78), [-0.13091,   inf] (76), [-0.13086,   inf] (68), [-0.13085,   inf] (82), [-0.13079,   inf] (78), [-0.13074,   inf] (82), [-0.13061,   inf] (72), [-0.13056,   inf] (82), [-0.13049,   inf] (76), 
length of domains: 47028
Total time: 3.3211	 pickout: 0.3769	 decision: 0.6168	 get_bound: 1.8750	 add_domain: 0.4523
Current lb:-0.13217100501060486
149984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 140.08532905578613

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 176] [1, 102] [1, 634] [1, 643] [1, 196] [1, 643] [1, 643] [1, 196] [1, 722] [1, 102] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 104.54603576660156 with beta sum per layer: [46.057273864746094, 888.3341064453125, 276.6859436035156]
alpha/beta optimization time: 1.0191364288330078
This batch time : update_bounds func: 1.8636	 prepare: 0.4640	 bound: 1.0195	 transfer: 0.0794	 finalize: 0.2862
Accumulated time: update_bounds func: 77.1698	 prepare: 16.1952	 bound: 40.2596	 transfer: 0.0794	 finalize: 15.2458
batch bounding time:  1.8680164813995361
Current worst splitting domains [lb, ub] (depth):
[-0.12945,   inf] (78), [-0.12928,   inf] (76), [-0.12925,   inf] (76), [-0.12923,   inf] (82), [-0.12918,   inf] (76), [-0.12917,   inf] (78), [-0.12913,   inf] (74), [-0.12898,   inf] (82), [-0.12895,   inf] (80), [-0.12880,   inf] (80), [-0.12879,   inf] (78), [-0.12871,   inf] (78), [-0.12859,   inf] (76), [-0.12840,   inf] (70), [-0.12822,   inf] (78), [-0.12802,   inf] (74), [-0.12801,   inf] (76), [-0.12770,   inf] (76), [-0.12755,   inf] (76), [-0.12702,   inf] (74), 
length of domains: 48164
Total time: 4.4728	 pickout: 0.3546	 decision: 1.8022	 get_bound: 1.8758	 add_domain: 0.4402
Current lb:-0.12944680452346802
154080 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 144.62840819358826

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 643] [1, 643] [1, 643] [2, 74] [1, 129] [1, 643] [1, 176] [1, 176] [1, 634] [1, 634] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 113.71244812011719 with beta sum per layer: [49.568878173828125, 925.6226806640625, 283.00201416015625]
alpha/beta optimization time: 1.016923189163208
This batch time : update_bounds func: 1.9051	 prepare: 0.4872	 bound: 1.0173	 transfer: 0.0794	 finalize: 0.3062
Accumulated time: update_bounds func: 79.0749	 prepare: 16.6824	 bound: 41.2769	 transfer: 0.0794	 finalize: 15.5520
batch bounding time:  1.9096038341522217
Current worst splitting domains [lb, ub] (depth):
[-0.12684,   inf] (76), [-0.12679,   inf] (76), [-0.12679,   inf] (82), [-0.12675,   inf] (72), [-0.12656,   inf] (78), [-0.12640,   inf] (78), [-0.12640,   inf] (78), [-0.12637,   inf] (76), [-0.12619,   inf] (82), [-0.12616,   inf] (76), [-0.12606,   inf] (82), [-0.12604,   inf] (76), [-0.12595,   inf] (76), [-0.12592,   inf] (76), [-0.12576,   inf] (72), [-0.12570,   inf] (74), [-0.12569,   inf] (78), [-0.12560,   inf] (76), [-0.12556,   inf] (78), [-0.12529,   inf] (76), 
length of domains: 49320
Total time: 3.3682	 pickout: 0.3591	 decision: 0.6357	 get_bound: 1.9176	 add_domain: 0.4558
Current lb:-0.12683847546577454
158176 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 148.0845980644226

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 102] [1, 643] [2, 74] [1, 317] [1, 643] [1, 129] [1, 643] [1, 102] [1, 306] [1, 102] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 100.96089172363281 with beta sum per layer: [44.983673095703125, 899.7061767578125, 298.5126953125]
alpha/beta optimization time: 1.0165412425994873
This batch time : update_bounds func: 1.8942	 prepare: 0.4858	 bound: 1.0170	 transfer: 0.0768	 finalize: 0.2998
Accumulated time: update_bounds func: 80.9691	 prepare: 17.1682	 bound: 42.2939	 transfer: 0.0768	 finalize: 15.8518
batch bounding time:  1.898745059967041
Current worst splitting domains [lb, ub] (depth):
[-0.12404,   inf] (78), [-0.12385,   inf] (74), [-0.12380,   inf] (80), [-0.12367,   inf] (76), [-0.12358,   inf] (80), [-0.12357,   inf] (78), [-0.12352,   inf] (76), [-0.12351,   inf] (80), [-0.12343,   inf] (76), [-0.12326,   inf] (80), [-0.12321,   inf] (78), [-0.12319,   inf] (76), [-0.12319,   inf] (76), [-0.12305,   inf] (70), [-0.12286,   inf] (80), [-0.12282,   inf] (70), [-0.12273,   inf] (78), [-0.12244,   inf] (76), [-0.12243,   inf] (80), [-0.12229,   inf] (76), 
length of domains: 50441
Total time: 4.6403	 pickout: 0.3839	 decision: 1.9056	 get_bound: 1.9071	 add_domain: 0.4438
Current lb:-0.12403547763824463
162272 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 152.80027437210083

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 643] [1, 129] [1, 634] [1, 102] [0, 2349] [1, 643] [1, 643] [1, 634] [1, 643] [1, 634] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 92.17620849609375 with beta sum per layer: [46.923458099365234, 913.0713500976562, 280.9795227050781]
alpha/beta optimization time: 1.0224032402038574
This batch time : update_bounds func: 3.2657	 prepare: 0.4749	 bound: 1.0228	 transfer: 0.0788	 finalize: 1.6742
Accumulated time: update_bounds func: 84.2348	 prepare: 17.6431	 bound: 43.3168	 transfer: 0.0788	 finalize: 17.5260
batch bounding time:  3.2700412273406982
Current worst splitting domains [lb, ub] (depth):
[-0.12173,   inf] (74), [-0.12170,   inf] (76), [-0.12145,   inf] (78), [-0.12144,   inf] (84), [-0.12139,   inf] (78), [-0.12136,   inf] (80), [-0.12133,   inf] (78), [-0.12119,   inf] (72), [-0.12112,   inf] (80), [-0.12103,   inf] (80), [-0.12093,   inf] (76), [-0.12084,   inf] (82), [-0.12083,   inf] (76), [-0.12054,   inf] (82), [-0.12046,   inf] (76), [-0.12043,   inf] (68), [-0.12036,   inf] (80), [-0.12035,   inf] (76), [-0.12029,   inf] (80), [-0.12022,   inf] (78), 
length of domains: 51523
Total time: 4.7075	 pickout: 0.3685	 decision: 0.6237	 get_bound: 3.2778	 add_domain: 0.4375
Current lb:-0.1217256486415863
166368 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 157.58106660842896

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 129] [1, 319] [1, 643] [1, 634] [0, 2322] [1, 634] [1, 643] [0, 2322] [1, 634] [1, 634] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 104.36923217773438 with beta sum per layer: [47.56797790527344, 887.3004760742188, 290.78759765625]
alpha/beta optimization time: 1.0123887062072754
This batch time : update_bounds func: 1.8663	 prepare: 0.4676	 bound: 1.0128	 transfer: 0.0783	 finalize: 0.2928
Accumulated time: update_bounds func: 86.1011	 prepare: 18.1107	 bound: 44.3295	 transfer: 0.0783	 finalize: 17.8187
batch bounding time:  1.8707540035247803
Current worst splitting domains [lb, ub] (depth):
[-0.11941,   inf] (74), [-0.11939,   inf] (82), [-0.11936,   inf] (80), [-0.11925,   inf] (80), [-0.11913,   inf] (78), [-0.11910,   inf] (78), [-0.11908,   inf] (74), [-0.11893,   inf] (74), [-0.11865,   inf] (80), [-0.11858,   inf] (82), [-0.11856,   inf] (74), [-0.11852,   inf] (74), [-0.11847,   inf] (76), [-0.11844,   inf] (78), [-0.11837,   inf] (80), [-0.11827,   inf] (80), [-0.11810,   inf] (76), [-0.11804,   inf] (80), [-0.11801,   inf] (78), [-0.11798,   inf] (76), 
length of domains: 52670
Total time: 3.3268	 pickout: 0.3720	 decision: 0.6201	 get_bound: 1.8790	 add_domain: 0.4558
Current lb:-0.1194060742855072
170464 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 160.9823980331421

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 317] [2, 74] [1, 634] [1, 643] [0, 2349] [1, 634] [1, 129] [1, 317] [1, 634] [2, 74] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 84.56043243408203 with beta sum per layer: [43.83103942871094, 893.176025390625, 282.152099609375]
alpha/beta optimization time: 1.0173165798187256
This batch time : update_bounds func: 3.2493	 prepare: 0.4791	 bound: 1.0177	 transfer: 0.0776	 finalize: 0.3069
Accumulated time: update_bounds func: 89.3504	 prepare: 18.5898	 bound: 45.3473	 transfer: 0.0776	 finalize: 18.1257
batch bounding time:  3.2540464401245117
Current worst splitting domains [lb, ub] (depth):
[-0.11697,   inf] (80), [-0.11690,   inf] (80), [-0.11689,   inf] (80)/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:556: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(eps_temp / std).reshape(1, -1, 1, 1)
, [-0.11688,   inf] (76), [-0.11681,   inf] (76), [-0.11671,   inf] (74), [-0.11655,   inf] (78), [-0.11642,   inf] (78), [-0.11620,   inf] (72), [-0.11619,   inf] (76), [-0.11607,   inf] (82), [-0.11597,   inf] (80), [-0.11596,   inf] (78), [-0.11595,   inf] (78), [-0.11586,   inf] (80), [-0.11584,   inf] (76), [-0.11574,   inf] (82), [-0.11571,   inf] (76), [-0.11562,   inf] (76), [-0.11561,   inf] (78), 
length of domains: 53742
Total time: 4.7040	 pickout: 0.3710	 decision: 0.6212	 get_bound: 3.2626	 add_domain: 0.4492
Current lb:-0.11696964502334595
174560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 165.76423168182373

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 634] [1, 643] [1, 634] [1, 643] [1, 102] [1, 643] [1, 643] [1, 634] [1, 129] [1, 196] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 91.24761962890625 with beta sum per layer: [47.49850845336914, 871.6176147460938, 290.04522705078125]
alpha/beta optimization time: 1.0129544734954834
This batch time : update_bounds func: 1.8600	 prepare: 0.4672	 bound: 1.0134	 transfer: 0.0793	 finalize: 0.2853
Accumulated time: update_bounds func: 91.2103	 prepare: 19.0569	 bound: 46.3607	 transfer: 0.0793	 finalize: 18.4110
batch bounding time:  1.8645999431610107
Current worst splitting domains [lb, ub] (depth):
[-0.11475,   inf] (80), [-0.11473,   inf] (78), [-0.11472,   inf] (76), [-0.11460,   inf] (74), [-0.11450,   inf] (74), [-0.11448,   inf] (80), [-0.11448,   inf] (82), [-0.11436,   inf] (72), [-0.11435,   inf] (82), [-0.11433,   inf] (78), [-0.11431,   inf] (80), [-0.11422,   inf] (80), [-0.11418,   inf] (76), [-0.11411,   inf] (72), [-0.11396,   inf] (80), [-0.11391,   inf] (86), [-0.11381,   inf] (68), [-0.11381,   inf] (80), [-0.11377,   inf] (78), [-0.11372,   inf] (80), 
length of domains: 54820
Total time: 3.3033	 pickout: 0.3712	 decision: 0.6227	 get_bound: 1.8727	 add_domain: 0.4367
Current lb:-0.11474689841270447
178656 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 169.15437602996826

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 634] [1, 102] [1, 643] [1, 129] [1, 129] [1, 634] [1, 176] [1, 722] [1, 176] [1, 643] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 89.27813720703125 with beta sum per layer: [46.01718521118164, 893.2237548828125, 267.36602783203125]
alpha/beta optimization time: 1.0151021480560303
This batch time : update_bounds func: 1.8751	 prepare: 0.4724	 bound: 1.0155	 transfer: 0.0799	 finalize: 0.2929
Accumulated time: update_bounds func: 93.0854	 prepare: 19.5293	 bound: 47.3762	 transfer: 0.0799	 finalize: 18.7039
batch bounding time:  1.8795676231384277
Current worst splitting domains [lb, ub] (depth):
[-0.11247,   inf] (82), [-0.11238,   inf] (78), [-0.11231,   inf] (80), [-0.11228,   inf] (82), [-0.11223,   inf] (76), [-0.11217,   inf] (76), [-0.11212,   inf] (82), [-0.11206,   inf] (82), [-0.11199,   inf] (72), [-0.11197,   inf] (78), [-0.11196,   inf] (80), [-0.11195,   inf] (78), [-0.11195,   inf] (78), [-0.11192,   inf] (78), [-0.11191,   inf] (78), [-0.11190,   inf] (76), [-0.11186,   inf] (74), [-0.11173,   inf] (76), [-0.11169,   inf] (76), [-0.11165,   inf] (78), 
length of domains: 55891
Total time: 4.7582	 pickout: 0.3658	 decision: 2.0695	 get_bound: 1.8875	 add_domain: 0.4355
Current lb:-0.11247247457504272
182752 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Time out!!!!!!!!
Image 225 label 3 verification end, final lower bound -0.11247247457504272, upper bound inf, time: 175.36028409004211
225 -0.11247247457504272
Result: image 225 verification failure (with branch and bound).
Wall time: 184.1942834854126

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 0): []
verification failure idx (total 1): [225]
final verified acc: 0.0%[1]
verifier is called on 1 examples.
total verified: 0
mean time [cnt:1] (excluding attack success): 184.1362965106964
