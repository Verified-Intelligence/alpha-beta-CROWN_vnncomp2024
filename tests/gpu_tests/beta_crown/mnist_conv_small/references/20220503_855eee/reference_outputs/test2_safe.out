Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: mnist_conv_small_nat.pth
  name: mnist_conv_small
data:
  start: 4
  end: 5
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: MNIST_ERAN
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.12
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 2048
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 180
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 100
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Tue May  3 01:17:08 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(1, 16, kernel_size=(4, 4), stride=(2, 2))
  (1): ReLU()
  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))
  (3): ReLU()
  (4): Flatten()
  (5): Linear(in_features=800, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([1000, 1, 28, 28]) torch.Size([1000]) torch.Size([1000])
X range: tensor(2.8215) tensor(-0.4242) tensor(-0.0274)
Note runnerup label is empty here!
############################
epsilon after preprocessing: tensor([[[[0.3895]]]]), data_max = tensor([[[[2.8215]]]]), data_min = tensor([[[[-0.4242]]]])
Task length: 1
saving results to Verified_ret_[mnist_conv_small]_start=4_end=5_iter=20_b=2048_timeout=180_branching=kfsb-max-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 4 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 4, correct label 4, image norm 482.3518981933594, logits tensor([-1.3253, -1.1976, -1.6536, -2.8595,  8.7830, -3.1041, -0.2604,  0.6880,
        -2.5880,  3.2975], device='cuda:0', grad_fn=<SelectBackward>)
##### PGD attack: True label: 4, Tested against: ['all'] ######
pgd prediction: tensor([-0.6009, -1.6079, -2.5873, -1.7929,  5.8731, -3.8654, -1.5943,  2.0506,
        -1.6856,  5.6351], device='cuda:0', grad_fn=<SqueezeBackward1>)
attack margin tensor([6.4740, 7.4810, 8.4604, 7.6660,    inf, 9.7386, 7.4674, 3.8225, 7.5587,
        0.2380], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[-1.3253, -1.1976, -1.6536, -2.8595,  8.7830, -3.1041, -0.2604,  0.6880,
         -2.5880,  3.2975]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-1.3431, -1.4266, -3.5550, -2.7377, -1.5790, -2.2653, -6.0664, -4.0777,
         -6.8970]], device='cuda:0') None
best_l after optimization: 16.461315155029297 with beta sum per layer: []
alpha/beta optimization time: 7.671950817108154
initial alpha-CROWN bounds: tensor([[-0.1220, -0.2383, -1.8188, -1.0789, -0.0389, -0.8357, -4.8375, -2.4071,
         -5.0839]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-5.0839, device='cuda:0', grad_fn=<MinBackward1>)
Sorted order for labels to verify: [9, 7, 0, 6, 1, 8, 3, 2, 5, 4]
##### [0:4] Tested against 9 ######
Model prediction is: tensor([[-1.3253, -1.1976, -1.6536, -2.8595,  8.7830, -3.1041, -0.2604,  0.6880,
         -2.5880,  3.2975]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 13, 13]) != torch.Size([2, 9, 1, 16, 13, 13]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 5, 5]) != torch.Size([2, 9, 1, 32, 5, 5]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 13, 13])
1 /11 torch.Size([1, 32, 5, 5])
2 /21 torch.Size([1, 100])
best_l after optimization: 5.083219051361084 with beta sum per layer: []
alpha/beta optimization time: 1.9846761226654053
alpha-CROWN with fixed intermediate bounds: tensor([[-5.0832]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-5.083219051361084
layer 0 size torch.Size([2704]) unstable 992
layer 1 size torch.Size([800]) unstable 151
layer 2 size torch.Size([100]) unstable 40
-----------------
# of unstable neurons: 1183
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 13, 13]) pre split depth:  7
batch:  torch.Size([1, 16, 13, 13]) post split depth:  7
splitting decisions: 
split level 0: [2, 51] 
split level 1: [2, 12] 
split level 2: [2, 95] 
split level 3: [2, 6] 
split level 4: [2, 99] 
split level 5: [2, 25] 
split level 6: [2, 11] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -22.44263458251953 with beta sum per layer: [0.0, 0.0, 124.61376953125]
alpha/beta optimization time: 0.28399109840393066
This batch time : update_bounds func: 0.3090	 prepare: 0.0149	 bound: 0.2843	 transfer: 0.0016	 finalize: 0.0078
Accumulated time: update_bounds func: 0.3090	 prepare: 0.0149	 bound: 0.2843	 transfer: 0.0016	 finalize: 0.0078
batch bounding time:  0.3092689514160156
Current worst splitting domains [lb, ub] (depth):
[-3.18724,   inf] (8), [-2.88399,   inf] (8), [-2.65270,   inf] (8), [-2.41272,   inf] (8), [-1.96960,   inf] (8), [-1.93312,   inf] (8), [-1.91169,   inf] (8), [-1.67977,   inf] (8), [-1.57337,   inf] (8), [-1.50905,   inf] (8), [-1.50613,   inf] (8), [-1.29291,   inf] (8), [-1.29011,   inf] (8), [-1.23966,   inf] (8), [-1.17317,   inf] (8), [-1.07958,   inf] (8), [-1.02031,   inf] (8), [-0.98586,   inf] (8), [-0.81331,   inf] (8), [-0.80724,   inf] (8), 
length of domains: 34
Total time: 0.3869	 pickout: 0.0012	 decision: 0.0519	 get_bound: 0.3321	 add_domain: 0.0017
Current lb:-3.187241315841675
128 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.2174527645111084

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([34, 16, 13, 13]) pre split depth:  2
batch:  torch.Size([34, 16, 13, 13]) post split depth:  2
splitting decisions: 
split level 0: [2, 97] [1, 632] [1, 632] [1, 632] [2, 97] [2, 97] [2, 97] [2, 97] [1, 706] [2, 97] 
split level 1: [1, 632] [2, 97] [2, 97] [2, 97] [2, 5] [1, 632] [2, 5] [0, 2244] [2, 97] [1, 632] 
regular batch size: 2*68, diving batch size 1*0
best_l after optimization: 43.582366943359375 with beta sum per layer: [0.22081007063388824, 4.090297222137451, 183.7793731689453]
alpha/beta optimization time: 0.2491145133972168
This batch time : update_bounds func: 0.2728	 prepare: 0.0132	 bound: 0.2494	 transfer: 0.0016	 finalize: 0.0081
Accumulated time: update_bounds func: 0.5818	 prepare: 0.0281	 bound: 0.5337	 transfer: 0.0016	 finalize: 0.0159
batch bounding time:  0.2729918956756592
Current worst splitting domains [lb, ub] (depth):
[-2.84597,   inf] (11), [-2.52671,   inf] (11), [-2.49672,   inf] (11), [-2.41213,   inf] (11), [-2.36342,   inf] (11), [-2.27457,   inf] (11), [-2.14116,   inf] (11), [-2.05321,   inf] (11), [-2.00894,   inf] (11), [-1.92562,   inf] (11), [-1.82798,   inf] (11), [-1.76385,   inf] (11), [-1.58960,   inf] (11), [-1.47397,   inf] (11), [-1.40402,   inf] (11), [-1.39129,   inf] (11), [-1.27918,   inf] (11), [-1.27722,   inf] (11), [-1.27718,   inf] (11), [-1.22745,   inf] (11), 
length of domains: 66
Total time: 0.3205	 pickout: 0.0049	 decision: 0.0303	 get_bound: 0.2821	 add_domain: 0.0032
Current lb:-2.84596586227417
264 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.538698673248291

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([66, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([66, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 48] [2, 48] [1, 706] [2, 48] [1, 706] [1, 706] [2, 48] [1, 706] [1, 706] [1, 706] 
regular batch size: 2*66, diving batch size 1*0
best_l after optimization: 62.5894660949707 with beta sum per layer: [0.40032362937927246, 7.722679615020752, 176.5903778076172]
alpha/beta optimization time: 0.2468271255493164
This batch time : update_bounds func: 0.2711	 prepare: 0.0135	 bound: 0.2471	 transfer: 0.0023	 finalize: 0.0079
Accumulated time: update_bounds func: 0.8529	 prepare: 0.0416	 bound: 0.7809	 transfer: 0.0023	 finalize: 0.0238
batch bounding time:  0.27132511138916016
Current worst splitting domains [lb, ub] (depth):
[-2.71069,   inf] (13), [-2.39164,   inf] (13), [-2.29987,   inf] (13), [-2.28526,   inf] (13), [-2.19422,   inf] (13), [-2.04771,   inf] (13), [-2.01583,   inf] (13), [-2.00899,   inf] (13), [-1.93100,   inf] (13), [-1.91521,   inf] (13), [-1.87515,   inf] (13), [-1.86781,   inf] (13), [-1.84858,   inf] (13), [-1.72573,   inf] (13), [-1.65653,   inf] (13), [-1.55719,   inf] (13), [-1.51568,   inf] (13), [-1.44821,   inf] (13), [-1.35623,   inf] (13), [-1.34823,   inf] (13), 
length of domains: 87
Total time: 0.3200	 pickout: 0.0090	 decision: 0.0350	 get_bound: 0.2715	 add_domain: 0.0045
Current lb:-2.7106852531433105
396 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.85969614982605

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([87, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([87, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 706] [1, 706] [2, 5] [1, 706] [2, 5] [2, 48] [1, 706] [1, 702] [2, 5] [2, 5] 
regular batch size: 2*87, diving batch size 1*0
best_l after optimization: 73.05888366699219 with beta sum per layer: [0.2993304431438446, 18.69705581665039, 223.71353149414062]
alpha/beta optimization time: 0.2511601448059082
This batch time : update_bounds func: 0.2839	 prepare: 0.0177	 bound: 0.2515	 transfer: 0.0036	 finalize: 0.0107
Accumulated time: update_bounds func: 1.1368	 prepare: 0.0593	 bound: 1.0323	 transfer: 0.0036	 finalize: 0.0345
batch bounding time:  0.28412747383117676
Current worst splitting domains [lb, ub] (depth):
[-2.53435,   inf] (15), [-2.26872,   inf] (15), [-2.23917,   inf] (15), [-2.22261,   inf] (15), [-1.99141,   inf] (15), [-1.98532,   inf] (15), [-1.96514,   inf] (15), [-1.90215,   inf] (15), [-1.89814,   inf] (15), [-1.89619,   inf] (15), [-1.89322,   inf] (15), [-1.73576,   inf] (15), [-1.73466,   inf] (15), [-1.72322,   inf] (15), [-1.64779,   inf] (15), [-1.59735,   inf] (15), [-1.57902,   inf] (15), [-1.52449,   inf] (15), [-1.52218,   inf] (15), [-1.47606,   inf] (15), 
length of domains: 102
Total time: 0.3422	 pickout: 0.0118	 decision: 0.0405	 get_bound: 0.2844	 add_domain: 0.0055
Current lb:-2.5343523025512695
570 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.203327655792236

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([102, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([102, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [0, 2244] [1, 702] [2, 5] [2, 5] [0, 2244] [2, 5] [2, 5] [2, 73] [2, 48] [2, 48] 
regular batch size: 2*102, diving batch size 1*0
best_l after optimization: 92.94510650634766 with beta sum per layer: [0.6202714443206787, 24.26939582824707, 243.46090698242188]
alpha/beta optimization time: 0.258791446685791
This batch time : update_bounds func: 0.2984	 prepare: 0.0209	 bound: 0.2591	 transfer: 0.0057	 finalize: 0.0123
Accumulated time: update_bounds func: 1.4352	 prepare: 0.0802	 bound: 1.2914	 transfer: 0.0057	 finalize: 0.0467
batch bounding time:  0.2986762523651123
Current worst splitting domains [lb, ub] (depth):
[-2.51680,   inf] (17), [-2.19588,   inf] (17), [-2.17108,   inf] (17), [-1.94828,   inf] (17), [-1.91343,   inf] (17), [-1.88297,   inf] (17), [-1.87802,   inf] (17), [-1.85026,   inf] (17), [-1.78019,   inf] (17), [-1.77203,   inf] (17), [-1.75195,   inf] (17), [-1.72439,   inf] (17), [-1.68415,   inf] (17), [-1.67553,   inf] (17), [-1.66267,   inf] (17), [-1.60890,   inf] (17), [-1.60781,   inf] (17), [-1.59891,   inf] (17), [-1.58446,   inf] (17), [-1.57790,   inf] (17), 
length of domains: 127
Total time: 0.3635	 pickout: 0.0143	 decision: 0.0430	 get_bound: 0.2990	 add_domain: 0.0072
Current lb:-2.516796112060547
774 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.568397760391235

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([127, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([127, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 73] [2, 73] [2, 73] [0, 2244] [0, 2244] [2, 73] [0, 2244] [2, 48] [0, 2244] [0, 2244] 
regular batch size: 2*127, diving batch size 1*0
best_l after optimization: 110.27819061279297 with beta sum per layer: [0.5782087445259094, 32.71672058105469, 280.99578857421875]
alpha/beta optimization time: 0.2657320499420166
This batch time : update_bounds func: 0.3126	 prepare: 0.0258	 bound: 0.2660	 transfer: 0.0052	 finalize: 0.0151
Accumulated time: update_bounds func: 1.7478	 prepare: 0.1060	 bound: 1.5574	 transfer: 0.0052	 finalize: 0.0618
batch bounding time:  0.3129279613494873
Current worst splitting domains [lb, ub] (depth):
[-2.39654,   inf] (19), [-2.06593,   inf] (19), [-2.04819,   inf] (19), [-1.88759,   inf] (19), [-1.88432,   inf] (19), [-1.82815,   inf] (19), [-1.74833,   inf] (19), [-1.73159,   inf] (19), [-1.72231,   inf] (19), [-1.66475,   inf] (19), [-1.64716,   inf] (19), [-1.63128,   inf] (19), [-1.61537,   inf] (19), [-1.60817,   inf] (19), [-1.59857,   inf] (19), [-1.59198,   inf] (19), [-1.58416,   inf] (19), [-1.56834,   inf] (19), [-1.54459,   inf] (19), [-1.54366,   inf] (19), 
length of domains: 170
Total time: 0.3907	 pickout: 0.0172	 decision: 0.0502	 get_bound: 0.3133	 add_domain: 0.0100
Current lb:-2.396535873413086
1028 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.960786819458008

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([170, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([170, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 5] [2, 5] [0, 2244] [2, 73] [2, 73] [2, 73] [0, 2244] [2, 73] [2, 5] [1, 633] 
regular batch size: 2*170, diving batch size 1*0
best_l after optimization: 139.74539184570312 with beta sum per layer: [0.8046891689300537, 54.49170684814453, 345.745849609375]
alpha/beta optimization time: 0.28188490867614746
This batch time : update_bounds func: 0.3426	 prepare: 0.0342	 bound: 0.2822	 transfer: 0.0047	 finalize: 0.0208
Accumulated time: update_bounds func: 2.0905	 prepare: 0.1402	 bound: 1.8396	 transfer: 0.0047	 finalize: 0.0826
batch bounding time:  0.3430752754211426
Current worst splitting domains [lb, ub] (depth):
[-2.07775,   inf] (21), [-2.06977,   inf] (21), [-2.03154,   inf] (21), [-1.75559,   inf] (21), [-1.75342,   inf] (21), [-1.74453,   inf] (21), [-1.73161,   inf] (21), [-1.72077,   inf] (21), [-1.69817,   inf] (21), [-1.68303,   inf] (21), [-1.58176,   inf] (21), [-1.56107,   inf] (21), [-1.53313,   inf] (21), [-1.51769,   inf] (21), [-1.49972,   inf] (21), [-1.46937,   inf] (21), [-1.46117,   inf] (21), [-1.45410,   inf] (21), [-1.41687,   inf] (21), [-1.40688,   inf] (21), 
length of domains: 234
Total time: 0.4399	 pickout: 0.0229	 decision: 0.0590	 get_bound: 0.3436	 add_domain: 0.0145
Current lb:-2.0777525901794434
1368 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.40339732170105

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([234, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([234, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 19] [2, 19] [2, 5] [1, 633] [2, 19] [2, 19] [2, 19] [1, 633] [1, 633] [2, 19] 
regular batch size: 2*234, diving batch size 1*0
best_l after optimization: 178.44334411621094 with beta sum per layer: [1.4324926137924194, 79.02836608886719, 428.5428771972656]
alpha/beta optimization time: 0.28138303756713867
This batch time : update_bounds func: 0.3727	 prepare: 0.0475	 bound: 0.2817	 transfer: 0.0126	 finalize: 0.0298
Accumulated time: update_bounds func: 2.4632	 prepare: 0.1877	 bound: 2.1213	 transfer: 0.0126	 finalize: 0.1124
batch bounding time:  0.3732259273529053
Current worst splitting domains [lb, ub] (depth):
[-1.95959,   inf] (23), [-1.95559,   inf] (23), [-1.70963,   inf] (23), [-1.70151,   inf] (23), [-1.68184,   inf] (23), [-1.67234,   inf] (23), [-1.64263,   inf] (23), [-1.62525,   inf] (23), [-1.61808,   inf] (23), [-1.59852,   inf] (23), [-1.53209,   inf] (23), [-1.47249,   inf] (23), [-1.43677,   inf] (23), [-1.42524,   inf] (23), [-1.39627,   inf] (23), [-1.36830,   inf] (23), [-1.36425,   inf] (23), [-1.36091,   inf] (23), [-1.35231,   inf] (23), [-1.34403,   inf] (23), 
length of domains: 337
Total time: 0.5564	 pickout: 0.0317	 decision: 0.1291	 get_bound: 0.3740	 add_domain: 0.0217
Current lb:-1.9595937728881836
1836 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.963804483413696

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([337, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([337, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 702] [1, 702] [2, 19] [2, 19] [2, 19] [2, 19] [1, 633] [1, 633] [2, 19] [1, 702] 
regular batch size: 2*337, diving batch size 1*0
best_l after optimization: 200.2015380859375 with beta sum per layer: [2.4109699726104736, 112.63296508789062, 607.234375]
alpha/beta optimization time: 0.3110330104827881
This batch time : update_bounds func: 0.4395	 prepare: 0.0691	 bound: 0.3114	 transfer: 0.0158	 finalize: 0.0416
Accumulated time: update_bounds func: 2.9027	 prepare: 0.2569	 bound: 2.4327	 transfer: 0.0158	 finalize: 0.1540
batch bounding time:  0.44010376930236816
Current worst splitting domains [lb, ub] (depth):
[-1.83965,   inf] (25), [-1.83076,   inf] (25), [-1.70870,   inf] (25), [-1.69584,   inf] (25), [-1.58812,   inf] (25), [-1.58427,   inf] (25), [-1.58296,   inf] (25), [-1.56663,   inf] (25), [-1.52919,   inf] (25), [-1.50614,   inf] (25), [-1.49872,   inf] (25), [-1.49298,   inf] (25), [-1.41721,   inf] (25), [-1.38753,   inf] (25), [-1.37154,   inf] (25), [-1.34544,   inf] (25), [-1.31829,   inf] (25), [-1.28165,   inf] (25), [-1.26193,   inf] (25), [-1.26156,   inf] (25), 
length of domains: 437
Total time: 0.6182	 pickout: 0.0476	 decision: 0.0999	 get_bound: 0.4411	 add_domain: 0.0296
Current lb:-1.8396494388580322
2510 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.587574005126953

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([437, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([437, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 56] [2, 56] [2, 56] [2, 56] [2, 56] [2, 56] [2, 56] [2, 56] [2, 10] [2, 5] 
regular batch size: 2*437, diving batch size 1*0
best_l after optimization: 217.72726440429688 with beta sum per layer: [4.406132698059082, 141.20553588867188, 751.3590087890625]
alpha/beta optimization time: 0.3469126224517822
This batch time : update_bounds func: 0.5055	 prepare: 0.0898	 bound: 0.3472	 transfer: 0.0132	 finalize: 0.0532
Accumulated time: update_bounds func: 3.4081	 prepare: 0.3467	 bound: 2.7799	 transfer: 0.0132	 finalize: 0.2071
batch bounding time:  0.506281852722168
Current worst splitting domains [lb, ub] (depth):
[-1.74609,   inf] (27), [-1.74553,   inf] (27), [-1.60807,   inf] (27), [-1.59983,   inf] (27), [-1.49255,   inf] (27), [-1.48867,   inf] (27), [-1.48411,   inf] (27), [-1.46921,   inf] (27), [-1.40841,   inf] (27), [-1.38423,   inf] (27), [-1.37720,   inf] (27), [-1.34529,   inf] (27), [-1.29620,   inf] (27), [-1.29569,   inf] (27), [-1.23485,   inf] (27), [-1.22512,   inf] (27), [-1.21469,   inf] (27), [-1.20971,   inf] (27), [-1.18873,   inf] (27), [-1.17016,   inf] (27), 
length of domains: 559
Total time: 0.7890	 pickout: 0.0607	 decision: 0.1807	 get_bound: 0.5076	 add_domain: 0.0400
Current lb:-1.7460905313491821
3384 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.384138584136963

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([559, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([559, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 32] [2, 32] [2, 32] [2, 32] [2, 32] [2, 32] [2, 32] [2, 32] [2, 56] [2, 10] 
regular batch size: 2*559, diving batch size 1*0
best_l after optimization: 199.26434326171875 with beta sum per layer: [6.146203994750977, 176.73814392089844, 923.04345703125]
alpha/beta optimization time: 0.3922579288482666
This batch time : update_bounds func: 0.5949	 prepare: 0.1162	 bound: 0.3926	 transfer: 0.0151	 finalize: 0.0684
Accumulated time: update_bounds func: 4.0030	 prepare: 0.4629	 bound: 3.1725	 transfer: 0.0151	 finalize: 0.2755
batch bounding time:  0.5959146022796631
Current worst splitting domains [lb, ub] (depth):
[-1.69010,   inf] (29), [-1.68285,   inf] (29), [-1.54629,   inf] (29), [-1.53269,   inf] (29), [-1.42842,   inf] (29), [-1.42705,   inf] (29), [-1.42579,   inf] (29), [-1.40890,   inf] (29), [-1.32452,   inf] (29), [-1.28381,   inf] (29), [-1.25587,   inf] (29), [-1.24091,   inf] (29), [-1.23640,   inf] (29), [-1.21289,   inf] (29), [-1.14303,   inf] (29), [-1.11087,   inf] (29), [-1.10716,   inf] (29), [-1.08591,   inf] (29), [-1.08585,   inf] (29), [-1.08314,   inf] (29), 
length of domains: 663
Total time: 0.9255	 pickout: 0.0772	 decision: 0.2011	 get_bound: 0.5976	 add_domain: 0.0496
Current lb:-1.6900957822799683
4502 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.320534944534302

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([663, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([663, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 638] [1, 633] [1, 638] [1, 633] [1, 638] [1, 633] [1, 702] [1, 702] [2, 32] [2, 32] 
regular batch size: 2*663, diving batch size 1*0
best_l after optimization: 153.2291259765625 with beta sum per layer: [7.900841236114502, 224.63449096679688, 1029.8167724609375]
alpha/beta optimization time: 0.4304687976837158
This batch time : update_bounds func: 0.6682	 prepare: 0.1378	 bound: 0.4308	 transfer: 0.0160	 finalize: 0.0805
Accumulated time: update_bounds func: 4.6712	 prepare: 0.6008	 bound: 3.6033	 transfer: 0.0160	 finalize: 0.3559
batch bounding time:  0.6693568229675293
Current worst splitting domains [lb, ub] (depth):
[-1.60196,   inf] (31), [-1.58846,   inf] (31), [-1.45212,   inf] (31), [-1.43176,   inf] (31), [-1.40665,   inf] (31), [-1.36078,   inf] (31), [-1.33929,   inf] (31), [-1.33303,   inf] (31), [-1.30026,   inf] (31), [-1.28789,   inf] (31), [-1.26198,   inf] (31), [-1.25167,   inf] (31), [-1.22632,   inf] (31), [-1.21779,   inf] (31), [-1.16431,   inf] (31), [-1.16155,   inf] (31), [-1.15831,   inf] (31), [-1.15482,   inf] (31), [-1.12114,   inf] (31), [-1.10892,   inf] (31), 
length of domains: 741
Total time: 1.0487	 pickout: 0.0950	 decision: 0.2248	 get_bound: 0.6714	 add_domain: 0.0575
Current lb:-1.6019612550735474
5828 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.382591724395752

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([741, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([741, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 633] [2, 10] [1, 633] [2, 10] [0, 2231] [1, 633] [1, 633] [2, 10] [2, 10] [1, 638] 
regular batch size: 2*741, diving batch size 1*0
best_l after optimization: 100.76495361328125 with beta sum per layer: [9.428262710571289, 231.77647399902344, 1119.5809326171875]
alpha/beta optimization time: 0.45775914192199707
This batch time : update_bounds func: 0.7251	 prepare: 0.1544	 bound: 0.4581	 transfer: 0.0191	 finalize: 0.0899
Accumulated time: update_bounds func: 5.3962	 prepare: 0.7552	 bound: 4.0614	 transfer: 0.0191	 finalize: 0.4459
batch bounding time:  0.7264022827148438
Current worst splitting domains [lb, ub] (depth):
[-1.46679,   inf] (33), [-1.45183,   inf] (33), [-1.40660,   inf] (33), [-1.36572,   inf] (33), [-1.30619,   inf] (33), [-1.29667,   inf] (33), [-1.24468,   inf] (33), [-1.24427,   inf] (33), [-1.22257,   inf] (33), [-1.21419,   inf] (33), [-1.21019,   inf] (33), [-1.19688,   inf] (33), [-1.18935,   inf] (33), [-1.17424,   inf] (33), [-1.15073,   inf] (33), [-1.14149,   inf] (33), [-1.13285,   inf] (33), [-1.11880,   inf] (33), [-1.11137,   inf] (33), [-1.10431,   inf] (33), 
length of domains: 831
Total time: 1.1459	 pickout: 0.1052	 decision: 0.2455	 get_bound: 0.7287	 add_domain: 0.0665
Current lb:-1.4667925834655762
7310 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.543630838394165

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([831, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([831, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [0, 2231] [2, 10] [1, 638] [0, 2231] [0, 2231] [2, 10] [1, 638] [2, 10] [1, 638] [0, 2231] 
regular batch size: 2*831, diving batch size 1*0
best_l after optimization: 92.98041534423828 with beta sum per layer: [9.3173246383667, 252.74578857421875, 1220.339599609375]
alpha/beta optimization time: 0.491863489151001
This batch time : update_bounds func: 0.8400	 prepare: 0.1722	 bound: 0.4922	 transfer: 0.0161	 finalize: 0.1557
Accumulated time: update_bounds func: 6.2362	 prepare: 0.9274	 bound: 4.5536	 transfer: 0.0161	 finalize: 0.6016
batch bounding time:  0.8417670726776123
Current worst splitting domains [lb, ub] (depth):
[-1.46292,   inf] (35), [-1.36129,   inf] (35), [-1.32836,   inf] (35), [-1.32448,   inf] (35), [-1.29742,   inf] (35), [-1.29334,   inf] (35), [-1.21110,   inf] (35), [-1.20550,   inf] (35), [-1.17343,   inf] (35), [-1.15935,   inf] (35), [-1.12837,   inf] (35), [-1.11877,   inf] (35), [-1.10733,   inf] (35), [-1.10343,   inf] (35), [-1.09156,   inf] (35), [-1.08418,   inf] (35), [-1.07053,   inf] (35), [-1.06900,   inf] (35), [-1.06791,   inf] (35), [-1.05811,   inf] (35), 
length of domains: 847
Total time: 1.3031	 pickout: 0.1208	 decision: 0.2681	 get_bound: 0.8446	 add_domain: 0.0696
Current lb:-1.4629229307174683
8972 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.864380598068237

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([847, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([847, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 638] [2, 10] [0, 2231] [2, 10] [1, 638] [1, 638] [1, 638] [2, 10] [0, 2231] [2, 10] 
regular batch size: 2*847, diving batch size 1*0
best_l after optimization: 10.711017608642578 with beta sum per layer: [8.56143569946289, 262.3478698730469, 1084.06005859375]
alpha/beta optimization time: 0.4966127872467041
This batch time : update_bounds func: 0.8517	 prepare: 0.1770	 bound: 0.4970	 transfer: 0.0184	 finalize: 0.1049
Accumulated time: update_bounds func: 7.0879	 prepare: 1.1044	 bound: 5.0506	 transfer: 0.0184	 finalize: 0.7065
batch bounding time:  0.8533008098602295
Current worst splitting domains [lb, ub] (depth):
[-1.34157,   inf] (37), [-1.31681,   inf] (37), [-1.29471,   inf] (37), [-1.23155,   inf] (37), [-1.19274,   inf] (37), [-1.17587,   inf] (37), [-1.17416,   inf] (37), [-1.17107,   inf] (37), [-1.16148,   inf] (37), [-1.13069,   inf] (37), [-1.12692,   inf] (37), [-1.09708,   inf] (37), [-1.08911,   inf] (37), [-1.07554,   inf] (37), [-1.07249,   inf] (37), [-1.05868,   inf] (37), [-1.04755,   inf] (37), [-1.02617,   inf] (37), [-1.02079,   inf] (37), [-1.01991,   inf] (37), 
length of domains: 846
Total time: 1.2800	 pickout: 0.1217	 decision: 0.2264	 get_bound: 0.8559	 add_domain: 0.0760
Current lb:-1.3415734767913818
10666 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.166412353515625

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([846, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([846, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 0] [1, 188] [1, 188] [1, 313] [2, 0] [2, 0] [1, 313] [2, 0] [1, 188] [2, 0] 
regular batch size: 2*846, diving batch size 1*0
best_l after optimization: 59.0121955871582 with beta sum per layer: [10.024972915649414, 311.4110412597656, 950.75146484375]
alpha/beta optimization time: 0.4980137348175049
This batch time : update_bounds func: 0.8033	 prepare: 0.1768	 bound: 0.4984	 transfer: 0.0212	 finalize: 0.1030
Accumulated time: update_bounds func: 7.8913	 prepare: 1.2813	 bound: 5.5490	 transfer: 0.0212	 finalize: 0.8095
batch bounding time:  0.8048405647277832
Current worst splitting domains [lb, ub] (depth):
[-1.26214,   inf] (39), [-1.24822,   inf] (39), [-1.23875,   inf] (39), [-1.15097,   inf] (39), [-1.12780,   inf] (39), [-1.11420,   inf] (39), [-1.09637,   inf] (39), [-1.09470,   inf] (39), [-1.08301,   inf] (39), [-1.07875,   inf] (39), [-1.07540,   inf] (39), [-1.06338,   inf] (39), [-1.05714,   inf] (39), [-1.05067,   inf] (39), [-1.02176,   inf] (39), [-1.00867,   inf] (39), [-1.00424,   inf] (39), [-0.99648,   inf] (39), [-0.98207,   inf] (39), [-0.97639,   inf] (39), 
length of domains: 876
Total time: 1.2941	 pickout: 0.1240	 decision: 0.2853	 get_bound: 0.8074	 add_domain: 0.0773
Current lb:-1.2621419429779053
12358 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.479542016983032

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([876, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([876, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 188] [2, 0] [2, 0] [2, 0] [2, 0] [1, 188] [1, 188] [1, 188] [2, 0] [2, 0] 
regular batch size: 2*876, diving batch size 1*0
best_l after optimization: 19.918224334716797 with beta sum per layer: [11.06683349609375, 335.85809326171875, 837.6686401367188]
alpha/beta optimization time: 0.5086166858673096
This batch time : update_bounds func: 0.8713	 prepare: 0.1813	 bound: 0.5090	 transfer: 0.0156	 finalize: 0.1612
Accumulated time: update_bounds func: 8.7626	 prepare: 1.4626	 bound: 6.0579	 transfer: 0.0156	 finalize: 0.9707
batch bounding time:  0.8729414939880371
Current worst splitting domains [lb, ub] (depth):
[-1.21889,   inf] (41), [-1.16752,   inf] (41), [-1.15857,   inf] (41), [-1.07019,   inf] (41), [-1.05224,   inf] (41), [-1.05210,   inf] (41), [-1.04979,   inf] (41), [-1.04422,   inf] (41), [-1.02897,   inf] (41), [-1.01659,   inf] (41), [-1.00242,   inf] (41), [-0.99943,   inf] (41), [-0.99635,   inf] (41), [-0.98316,   inf] (41), [-0.96885,   inf] (41), [-0.96532,   inf] (41), [-0.96168,   inf] (41), [-0.94384,   inf] (41), [-0.92748,   inf] (41), [-0.92415,   inf] (41), 
length of domains: 865
Total time: 1.3609	 pickout: 0.1267	 decision: 0.2808	 get_bound: 0.8756	 add_domain: 0.0779
Current lb:-1.2188889980316162
14110 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.860007524490356

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([865, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([865, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 637] [1, 313] [1, 637] [1, 313] [1, 637] [1, 637] [1, 637] [1, 313] [1, 313] [1, 313] 
regular batch size: 2*865, diving batch size 1*0
best_l after optimization: 99.37309265136719 with beta sum per layer: [10.926109313964844, 356.9582214355469, 720.3368530273438]
alpha/beta optimization time: 0.5025348663330078
This batch time : update_bounds func: 0.8028	 prepare: 0.1796	 bound: 0.5029	 transfer: 0.0107	 finalize: 0.1052
Accumulated time: update_bounds func: 9.5654	 prepare: 1.6422	 bound: 6.5608	 transfer: 0.0107	 finalize: 1.0759
batch bounding time:  0.8042619228363037
Current worst splitting domains [lb, ub] (depth):
[-1.11198,   inf] (43), [-1.06257,   inf] (43), [-1.04869,   inf] (43), [-1.04353,   inf] (43), [-0.99253,   inf] (43), [-0.97066,   inf] (43), [-0.94806,   inf] (43), [-0.94770,   inf] (43), [-0.94723,   inf] (43), [-0.94526,   inf] (43), [-0.93956,   inf] (43), [-0.92620,   inf] (43), [-0.91473,   inf] (43), [-0.90007,   inf] (43), [-0.89556,   inf] (43), [-0.89368,   inf] (43), [-0.89275,   inf] (43), [-0.89193,   inf] (43), [-0.89044,   inf] (43), [-0.88950,   inf] (43), 
length of domains: 967
Total time: 1.3015	 pickout: 0.1259	 decision: 0.2795	 get_bound: 0.8069	 add_domain: 0.0892
Current lb:-1.1119797229766846
15840 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.18060541152954

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([967, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([967, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 707] [1, 707] [1, 707] [1, 707] [1, 707] [1, 707] [1, 707] [0, 2282] [1, 707] [1, 707] 
regular batch size: 2*967, diving batch size 1*0
best_l after optimization: 162.32220458984375 with beta sum per layer: [11.797143936157227, 454.77783203125, 671.84521484375]
alpha/beta optimization time: 0.5469434261322021
This batch time : update_bounds func: 0.9374	 prepare: 0.1990	 bound: 0.5473	 transfer: 0.0165	 finalize: 0.1698
Accumulated time: update_bounds func: 10.5028	 prepare: 1.8412	 bound: 7.1081	 transfer: 0.0165	 finalize: 1.2457
batch bounding time:  0.9390687942504883
Current worst splitting domains [lb, ub] (depth):
[-1.02905,   inf] (45), [-0.97987,   inf] (45), [-0.96576,   inf] (45), [-0.96138,   inf] (45), [-0.91839,   inf] (45), [-0.90953,   inf] (45), [-0.88107,   inf] (45), [-0.87619,   inf] (45), [-0.86469,   inf] (45), [-0.86360,   inf] (45), [-0.86245,   inf] (45), [-0.86163,   inf] (45), [-0.86124,   inf] (45), [-0.85754,   inf] (45), [-0.84397,   inf] (45), [-0.83367,   inf] (45), [-0.82734,   inf] (45), [-0.82647,   inf] (45), [-0.82259,   inf] (45), [-0.81447,   inf] (45), 
length of domains: 1156
Total time: 1.5007	 pickout: 0.1393	 decision: 0.3087	 get_bound: 0.9420	 add_domain: 0.1106
Current lb:-1.0290530920028687
17774 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.701700448989868

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1156, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([1156, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 313] [0, 2282] [1, 313] [1, 637] [1, 707] [0, 2282] [0, 2282] [1, 313] [1, 707] [1, 313] 
regular batch size: 2*1156, diving batch size 1*0
best_l after optimization: 216.89309692382812 with beta sum per layer: [18.5167179107666, 640.0152587890625, 635.1168212890625]
alpha/beta optimization time: 0.6175031661987305
This batch time : update_bounds func: 1.0883	 prepare: 0.2396	 bound: 0.6178	 transfer: 0.0260	 finalize: 0.1993
Accumulated time: update_bounds func: 11.5911	 prepare: 2.0808	 bound: 7.7259	 transfer: 0.0260	 finalize: 1.4450
batch bounding time:  1.0904171466827393
Current worst splitting domains [lb, ub] (depth):
[-0.95201,   inf] (47), [-0.89498,   inf] (47), [-0.89222,   inf] (47), [-0.88177,   inf] (47), [-0.86145,   inf] (47), [-0.85637,   inf] (47), [-0.85618,   inf] (47), [-0.84889,   inf] (47), [-0.83072,   inf] (47), [-0.81263,   inf] (47), [-0.80952,   inf] (47), [-0.79303,   inf] (47), [-0.78394,   inf] (47), [-0.78231,   inf] (47), [-0.78053,   inf] (47), [-0.78022,   inf] (47), [-0.76497,   inf] (47), [-0.76019,   inf] (47), [-0.75817,   inf] (47), [-0.75776,   inf] (47), 
length of domains: 1355
Total time: 1.7539	 pickout: 0.1679	 decision: 0.3598	 get_bound: 1.0941	 add_domain: 0.1322
Current lb:-0.9520097970962524
20086 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 20.480716228485107

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1355, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([1355, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 313] [1, 258] [1, 258] [1, 313] [1, 258] [1, 637] [1, 258] [1, 313] [1, 637] [1, 703] 
regular batch size: 2*1355, diving batch size 1*0
best_l after optimization: 292.676025390625 with beta sum per layer: [22.454570770263672, 774.8475341796875, 589.05322265625]
alpha/beta optimization time: 0.6988706588745117
This batch time : update_bounds func: 1.2402	 prepare: 0.2778	 bound: 0.6992	 transfer: 0.0317	 finalize: 0.2251
Accumulated time: update_bounds func: 12.8312	 prepare: 2.3586	 bound: 8.4251	 transfer: 0.0317	 finalize: 1.6700
batch bounding time:  1.2425117492675781
Current worst splitting domains [lb, ub] (depth):
[-0.82202,   inf] (49), [-0.80611,   inf] (49), [-0.80541,   inf] (49), [-0.79147,   inf] (49), [-0.77032,   inf] (49), [-0.76717,   inf] (49), [-0.76212,   inf] (49), [-0.75971,   inf] (49), [-0.75047,   inf] (49), [-0.74667,   inf] (49), [-0.73428,   inf] (49), [-0.73393,   inf] (49), [-0.73356,   inf] (49), [-0.71693,   inf] (49), [-0.71220,   inf] (49), [-0.70912,   inf] (49), [-0.70869,   inf] (49), [-0.70638,   inf] (49), [-0.70339,   inf] (49), [-0.69936,   inf] (49), 
length of domains: 1663
Total time: 2.0320	 pickout: 0.2005	 decision: 0.4155	 get_bound: 1.2467	 add_domain: 0.1693
Current lb:-0.8220166563987732
22796 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 22.542704105377197

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1663, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([1663, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 258] [1, 258] [0, 2254] [1, 703] [1, 313] [0, 2254] [1, 258] [1, 112] [1, 703] [1, 703] 
regular batch size: 2*1663, diving batch size 1*0
best_l after optimization: 364.0751953125 with beta sum per layer: [30.508729934692383, 994.438232421875, 530.921142578125]
alpha/beta optimization time: 0.8214492797851562
This batch time : update_bounds func: 1.5149	 prepare: 0.3444	 bound: 0.8218	 transfer: 0.0570	 finalize: 0.2828
Accumulated time: update_bounds func: 14.3461	 prepare: 2.7030	 bound: 9.2469	 transfer: 0.0570	 finalize: 1.9528
batch bounding time:  1.5180790424346924
Current worst splitting domains [lb, ub] (depth):
[-0.74012,   inf] (51), [-0.71714,   inf] (51), [-0.71643,   inf] (51), [-0.71308,   inf] (51), [-0.70285,   inf] (51), [-0.68966,   inf] (51), [-0.68461,   inf] (51), [-0.68289,   inf] (51), [-0.68064,   inf] (51), [-0.67515,   inf] (51), [-0.66839,   inf] (51), [-0.66545,   inf] (51), [-0.65973,   inf] (51), [-0.65700,   inf] (51), [-0.65254,   inf] (51), [-0.64355,   inf] (51), [-0.64352,   inf] (51), [-0.64068,   inf] (51), [-0.63415,   inf] (51), [-0.62695,   inf] (51), 
length of domains: 2102
Total time: 2.5484	 pickout: 0.2455	 decision: 0.5633	 get_bound: 1.5235	 add_domain: 0.2161
Current lb:-0.7401231527328491
26122 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 25.127671003341675

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [0, 2282] [1, 703] [0, 2254] [1, 703] [1, 708] [0, 2282] [1, 703] [0, 2254] [0, 2282] [0, 2254] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 449.0722351074219 with beta sum per layer: [38.809024810791016, 1301.70458984375, 397.95880126953125]
alpha/beta optimization time: 1.0259945392608643
This batch time : update_bounds func: 2.1789	 prepare: 0.6287	 bound: 1.0264	 transfer: 0.0604	 finalize: 0.4523
Accumulated time: update_bounds func: 16.5250	 prepare: 3.3317	 bound: 10.2734	 transfer: 0.0604	 finalize: 2.4052
batch bounding time:  2.1826765537261963
Current worst splitting domains [lb, ub] (depth):
[-0.71319,   inf] (53), [-0.66274,   inf] (53), [-0.65381,   inf] (53), [-0.65112,   inf] (53), [-0.64971,   inf] (53), [-0.64201,   inf] (53), [-0.63436,   inf] (53), [-0.61759,   inf] (53), [-0.61529,   inf] (53), [-0.60705,   inf] (53), [-0.60477,   inf] (53), [-0.60317,   inf] (53), [-0.60183,   inf] (53), [-0.60064,   inf] (53), [-0.59947,   inf] (53), [-0.59841,   inf] (53), [-0.59590,   inf] (53), [-0.57900,   inf] (53), [-0.57618,   inf] (53), [-0.57465,   inf] (53), 
length of domains: 2828
Total time: 3.7405	 pickout: 0.3270	 decision: 0.9079	 get_bound: 2.1897	 add_domain: 0.3158
Current lb:-0.7131938934326172
30218 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 28.926467418670654

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 703] [1, 703] [0, 2254] [1, 112] [0, 2272] [1, 112] [1, 112] [1, 112] [1, 112] [0, 2272] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 587.6832275390625 with beta sum per layer: [35.285789489746094, 1372.40185546875, 153.02761840820312]
alpha/beta optimization time: 1.031482219696045
This batch time : update_bounds func: 2.2355	 prepare: 0.6369	 bound: 1.0320	 transfer: 0.0773	 finalize: 0.4789
Accumulated time: update_bounds func: 18.7605	 prepare: 3.9686	 bound: 11.3054	 transfer: 0.0773	 finalize: 2.8841
batch bounding time:  2.239440679550171
Current worst splitting domains [lb, ub] (depth):
[-0.64884,   inf] (55), [-0.63446,   inf] (55), [-0.60628,   inf] (55), [-0.60388,   inf] (55), [-0.60103,   inf] (55), [-0.59849,   inf] (55), [-0.58848,   inf] (55), [-0.58407,   inf] (55), [-0.58050,   inf] (55), [-0.57810,   inf] (55), [-0.57221,   inf] (55), [-0.56182,   inf] (55), [-0.55228,   inf] (55), [-0.55097,   inf] (55), [-0.54856,   inf] (55), [-0.54554,   inf] (55), [-0.54534,   inf] (55), [-0.54427,   inf] (55), [-0.54184,   inf] (55), [-0.54104,   inf] (55), 
length of domains: 4215
Total time: 4.0403	 pickout: 0.4397	 decision: 0.8425	 get_bound: 2.2466	 add_domain: 0.5113
Current lb:-0.6488351821899414
34314 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 33.00758671760559

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 703] [1, 112] [1, 703] [1, 703] [1, 112] [1, 703] [1, 112] [1, 112] [1, 178] [1, 112] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 644.9415893554688 with beta sum per layer: [30.53548812866211, 1445.26220703125, 60.85456085205078]
alpha/beta optimization time: 1.0314593315124512
This batch time : update_bounds func: 2.2660	 prepare: 0.6356	 bound: 1.0319	 transfer: 0.0776	 finalize: 0.5096
Accumulated time: update_bounds func: 21.0264	 prepare: 4.6042	 bound: 12.3373	 transfer: 0.0776	 finalize: 3.3937
batch bounding time:  2.2700445652008057
Current worst splitting domains [lb, ub] (depth):
[-0.56859,   inf] (57), [-0.56341,   inf] (57), [-0.55474,   inf] (57), [-0.54856,   inf] (57), [-0.54588,   inf] (57), [-0.53707,   inf] (57), [-0.53237,   inf] (57), [-0.53053,   inf] (57), [-0.52744,   inf] (57), [-0.52523,   inf] (57), [-0.52240,   inf] (57), [-0.52229,   inf] (57), [-0.52044,   inf] (57), [-0.51825,   inf] (57), [-0.51721,   inf] (57), [-0.51024,   inf] (57), [-0.50914,   inf] (57), [-0.50848,   inf] (57), [-0.50749,   inf] (57), [-0.50487,   inf] (57), 
length of domains: 5766
Total time: 4.0132	 pickout: 0.4258	 decision: 0.8724	 get_bound: 2.2773	 add_domain: 0.4377
Current lb:-0.5685857534408569
38410 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 37.062634229660034

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 112] [1, 708] [1, 112] [1, 178] [0, 2272] [1, 28] [1, 36] [1, 708] [1, 28] [1, 178] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 623.5028076171875 with beta sum per layer: [23.19759750366211, 1568.72705078125, 49.34593200683594]
alpha/beta optimization time: 1.0337040424346924
This batch time : update_bounds func: 2.2778	 prepare: 0.6330	 bound: 1.0342	 transfer: 0.0781	 finalize: 0.5215
Accumulated time: update_bounds func: 23.3043	 prepare: 5.2372	 bound: 13.3715	 transfer: 0.0781	 finalize: 3.9151
batch bounding time:  2.2820022106170654
Current worst splitting domains [lb, ub] (depth):
[-0.54588,   inf] (59), [-0.52692,   inf] (59), [-0.51383,   inf] (59), [-0.50546,   inf] (59), [-0.50070,   inf] (59), [-0.49529,   inf] (59), [-0.49519,   inf] (59), [-0.49077,   inf] (59), [-0.48999,   inf] (59), [-0.48977,   inf] (59), [-0.48869,   inf] (59), [-0.48284,   inf] (59), [-0.48227,   inf] (59), [-0.47503,   inf] (59), [-0.47483,   inf] (59), [-0.47223,   inf] (59), [-0.46959,   inf] (59), [-0.46860,   inf] (59), [-0.46338,   inf] (59), [-0.46212,   inf] (59), 
length of domains: 7295
Total time: 4.1179	 pickout: 0.4276	 decision: 0.9513	 get_bound: 2.2897	 add_domain: 0.4493
Current lb:-0.5458762049674988
42506 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 41.22501564025879

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 28] [1, 28] [1, 259] [1, 178] [1, 259] [1, 28] [1, 33] [1, 28] [1, 33] [0, 2272] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 589.5997314453125 with beta sum per layer: [20.406801223754883, 1637.63818359375, 41.52239227294922]
alpha/beta optimization time: 1.0314698219299316
This batch time : update_bounds func: 2.3137	 prepare: 0.6396	 bound: 1.0319	 transfer: 0.0799	 finalize: 0.3793
Accumulated time: update_bounds func: 25.6179	 prepare: 5.8768	 bound: 14.4033	 transfer: 0.0799	 finalize: 4.2944
batch bounding time:  2.3177361488342285
Current worst splitting domains [lb, ub] (depth):
[-0.49842,   inf] (61), [-0.49468,   inf] (61), [-0.48977,   inf] (61), [-0.48869,   inf] (61), [-0.48836,   inf] (61), [-0.48056,   inf] (61), [-0.46618,   inf] (61), [-0.46299,   inf] (61), [-0.45976,   inf] (61), [-0.45889,   inf] (61), [-0.45830,   inf] (61), [-0.45075,   inf] (61), [-0.44974,   inf] (61), [-0.44488,   inf] (61), [-0.44407,   inf] (61), [-0.44313,   inf] (61), [-0.44033,   inf] (61), [-0.44029,   inf] (61), [-0.44021,   inf] (61), [-0.43775,   inf] (61), 
length of domains: 8781
Total time: 4.2739	 pickout: 0.4284	 decision: 0.8428	 get_bound: 2.3251	 add_domain: 0.6776
Current lb:-0.49841880798339844
46602 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 45.544240951538086

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 708] [1, 708] [1, 27] [1, 27] [1, 33] [1, 33] [0, 2272] [1, 708] [1, 256] [1, 27] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 487.7047119140625 with beta sum per layer: [15.69747543334961, 1778.00146484375, 35.80242156982422]
alpha/beta optimization time: 1.0336849689483643
This batch time : update_bounds func: 2.3655	 prepare: 0.6379	 bound: 1.0342	 transfer: 0.0782	 finalize: 0.6042
Accumulated time: update_bounds func: 27.9834	 prepare: 6.5147	 bound: 15.4375	 transfer: 0.0782	 finalize: 4.8986
batch bounding time:  2.369704008102417
Current worst splitting domains [lb, ub] (depth):
[-0.46309,   inf] (63), [-0.45407,   inf] (63), [-0.45023,   inf] (63), [-0.44883,   inf] (63), [-0.44765,   inf] (63), [-0.43695,   inf] (63), [-0.43636,   inf] (63), [-0.43396,   inf] (63), [-0.42277,   inf] (63), [-0.41773,   inf] (63), [-0.41630,   inf] (63), [-0.41054,   inf] (63), [-0.40897,   inf] (63), [-0.40878,   inf] (63), [-0.40593,   inf] (63), [-0.40568,   inf] (63), [-0.40502,   inf] (63), [-0.40392,   inf] (63), [-0.40229,   inf] (63), [-0.40183,   inf] (63), 
length of domains: 10078
Total time: 4.1480	 pickout: 0.4344	 decision: 0.8922	 get_bound: 2.3773	 add_domain: 0.4442
Current lb:-0.46309229731559753
50698 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 49.743212938308716

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 27] [1, 256] [1, 256] [1, 708] [1, 708] [1, 27] [1, 256] [1, 27] [1, 27] [1, 33] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 381.5797119140625 with beta sum per layer: [18.08585548400879, 1845.677001953125, 35.936302185058594]
alpha/beta optimization time: 1.0337321758270264
This batch time : update_bounds func: 2.3891	 prepare: 0.6463	 bound: 1.0342	 transfer: 0.0781	 finalize: 0.6202
Accumulated time: update_bounds func: 30.3725	 prepare: 7.1610	 bound: 16.4717	 transfer: 0.0781	 finalize: 5.5188
batch bounding time:  2.393303632736206
Current worst splitting domains [lb, ub] (depth):
[-0.42199,   inf] (65), [-0.39875,   inf] (65), [-0.39602,   inf] (65), [-0.39299,   inf] (65), [-0.39126,   inf] (65), [-0.38625,   inf] (65), [-0.38507,   inf] (65), [-0.38235,   inf] (65), [-0.38185,   inf] (65), [-0.37835,   inf] (65), [-0.37569,   inf] (65), [-0.37243,   inf] (65), [-0.36977,   inf] (65), [-0.36961,   inf] (65), [-0.36795,   inf] (65), [-0.36776,   inf] (65), [-0.36680,   inf] (65), [-0.36505,   inf] (65), [-0.36471,   inf] (65), [-0.36456,   inf] (65), 
length of domains: 11175
Total time: 4.1655	 pickout: 0.4345	 decision: 0.9013	 get_bound: 2.4010	 add_domain: 0.4288
Current lb:-0.42199334502220154
54794 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 53.96163582801819

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 33] [1, 27] [1, 259] [1, 259] [1, 259] [1, 27] [1, 259] [1, 27] [1, 259] [1, 259] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 240.05117797851562 with beta sum per layer: [18.61962127685547, 1758.6368408203125, 34.37535095214844]
alpha/beta optimization time: 1.0335798263549805
This batch time : update_bounds func: 2.4423	 prepare: 0.6571	 bound: 1.0340	 transfer: 0.0788	 finalize: 0.6607
Accumulated time: update_bounds func: 32.8148	 prepare: 7.8181	 bound: 17.5057	 transfer: 0.0788	 finalize: 6.1795
batch bounding time:  2.4466664791107178
Current worst splitting domains [lb, ub] (depth):
[-0.38398,   inf] (67), [-0.37123,   inf] (67), [-0.36989,   inf] (67), [-0.36639,   inf] (67), [-0.36194,   inf] (67), [-0.36174,   inf] (67), [-0.35841,   inf] (67), [-0.35783,   inf] (67), [-0.34882,   inf] (67), [-0.34678,   inf] (67), [-0.34341,   inf] (67), [-0.34171,   inf] (67), [-0.34049,   inf] (67), [-0.33472,   inf] (67), [-0.33364,   inf] (67), [-0.33196,   inf] (67), [-0.33000,   inf] (67), [-0.32705,   inf] (67), [-0.32672,   inf] (67), [-0.32602,   inf] (67), 
length of domains: 11919
Total time: 4.2136	 pickout: 0.4388	 decision: 0.9317	 get_bound: 2.4544	 add_domain: 0.3887
Current lb:-0.38398468494415283
58890 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 58.24125695228577

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 259] [1, 256] [1, 256] [1, 256] [1, 256] [1, 256] [1, 256] [1, 259] [1, 256] [1, 636] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 204.36968994140625 with beta sum per layer: [20.559518814086914, 1676.098388671875, 40.01397705078125]
alpha/beta optimization time: 1.029855728149414
This batch time : update_bounds func: 2.4417	 prepare: 0.6487	 bound: 1.0303	 transfer: 0.0772	 finalize: 0.6739
Accumulated time: update_bounds func: 35.2565	 prepare: 8.4667	 bound: 18.5360	 transfer: 0.0772	 finalize: 6.8535
batch bounding time:  2.4463701248168945
Current worst splitting domains [lb, ub] (depth):
[-0.36376,   inf] (69), [-0.33186,   inf] (69), [-0.32641,   inf] (69), [-0.31302,   inf] (69), [-0.31068,   inf] (69), [-0.30990,   inf] (69), [-0.30978,   inf] (69), [-0.30841,   inf] (69), [-0.30705,   inf] (69), [-0.30470,   inf] (69), [-0.30161,   inf] (69), [-0.30101,   inf] (69), [-0.30042,   inf] (69), [-0.30033,   inf] (69), [-0.29940,   inf] (69), [-0.29894,   inf] (69), [-0.29809,   inf] (69), [-0.29669,   inf] (69), [-0.28824,   inf] (69), [-0.28726,   inf] (69), 
length of domains: 12706
Total time: 4.2650	 pickout: 0.4519	 decision: 0.9589	 get_bound: 2.4545	 add_domain: 0.3996
Current lb:-0.3637615442276001
62986 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 62.56679320335388

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 256] [1, 256] [1, 36] [0, 2282] [1, 33] [1, 256] [1, 28] [1, 143] [1, 143] [1, 143] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 146.59275817871094 with beta sum per layer: [22.516006469726562, 1681.82861328125, 48.003997802734375]
alpha/beta optimization time: 1.0298171043395996
This batch time : update_bounds func: 2.1982	 prepare: 0.6767	 bound: 1.0303	 transfer: 0.0786	 finalize: 0.4012
Accumulated time: update_bounds func: 37.4548	 prepare: 9.1434	 bound: 19.5663	 transfer: 0.0786	 finalize: 7.2547
batch bounding time:  2.2030279636383057
Current worst splitting domains [lb, ub] (depth):
[-0.30095,   inf] (71), [-0.29043,   inf] (71), [-0.28387,   inf] (71), [-0.27903,   inf] (71), [-0.27769,   inf] (71), [-0.27670,   inf] (71), [-0.27635,   inf] (71), [-0.27223,   inf] (71), [-0.26924,   inf] (71), [-0.26916,   inf] (71), [-0.26906,   inf] (71), [-0.26728,   inf] (71), [-0.26282,   inf] (71), [-0.26041,   inf] (71), [-0.25969,   inf] (71), [-0.25919,   inf] (71), [-0.25900,   inf] (71), [-0.25693,   inf] (71), [-0.25526,   inf] (71), [-0.25432,   inf] (71), 
length of domains: 13381
Total time: 4.3887	 pickout: 0.4444	 decision: 0.9909	 get_bound: 2.2115	 add_domain: 0.7418
Current lb:-0.3009527325630188
67082 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 67.01749753952026

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 143] [1, 178] [1, 143] [1, 36] [1, 36] [1, 36] [1, 143] [1, 36] [1, 639] [1, 33] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 92.33407592773438 with beta sum per layer: [21.580963134765625, 1705.4803466796875, 58.289085388183594]
alpha/beta optimization time: 1.0319716930389404
This batch time : update_bounds func: 2.4744	 prepare: 0.6518	 bound: 1.0324	 transfer: 0.0769	 finalize: 0.3880
Accumulated time: update_bounds func: 39.9292	 prepare: 9.7952	 bound: 20.5987	 transfer: 0.0769	 finalize: 7.6427
batch bounding time:  2.4788753986358643
Current worst splitting domains [lb, ub] (depth):
[-0.27200,   inf] (73), [-0.25496,   inf] (73), [-0.25037,   inf] (73), [-0.24726,   inf] (73), [-0.24029,   inf] (73), [-0.23782,   inf] (73), [-0.23631,   inf] (73), [-0.23502,   inf] (73), [-0.23465,   inf] (73), [-0.23343,   inf] (73), [-0.23303,   inf] (73), [-0.23152,   inf] (73), [-0.23052,   inf] (73), [-0.22589,   inf] (73), [-0.22366,   inf] (73), [-0.22038,   inf] (73), [-0.21944,   inf] (73), [-0.21879,   inf] (73), [-0.21557,   inf] (73), [-0.21547,   inf] (73), 
length of domains: 13970
Total time: 4.0037	 pickout: 0.4469	 decision: 0.6927	 get_bound: 2.4870	 add_domain: 0.3771
Current lb:-0.27200204133987427
71178 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 71.08585834503174

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 639] [1, 639] [1, 28] [1, 639] [1, 36] [0, 2254] [1, 34] [1, 34] [1, 639] [1, 34] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 69.84175109863281 with beta sum per layer: [21.165607452392578, 1778.2711181640625, 50.64554214477539]
alpha/beta optimization time: 1.030027151107788
This batch time : update_bounds func: 2.5111	 prepare: 0.6518	 bound: 1.0305	 transfer: 0.0790	 finalize: 0.7388
Accumulated time: update_bounds func: 42.4403	 prepare: 10.4470	 bound: 21.6291	 transfer: 0.0790	 finalize: 8.3816
batch bounding time:  2.5160458087921143
Current worst splitting domains [lb, ub] (depth):
[-0.23369,   inf] (75), [-0.21753,   inf] (75), [-0.20910,   inf] (75), [-0.20423,   inf] (75), [-0.20238,   inf] (75), [-0.20065,   inf] (75), [-0.19920,   inf] (75), [-0.19759,   inf] (75), [-0.19483,   inf] (75), [-0.19390,   inf] (75), [-0.19236,   inf] (75), [-0.19231,   inf] (75), [-0.18557,   inf] (75), [-0.18212,   inf] (75), [-0.18110,   inf] (75), [-0.17974,   inf] (75), [-0.17954,   inf] (75), [-0.17847,   inf] (75), [-0.17712,   inf] (75), [-0.17698,   inf] (75), 
length of domains: 14477
Total time: 4.3728	 pickout: 0.4453	 decision: 1.0333	 get_bound: 2.5245	 add_domain: 0.3696
Current lb:-0.2336927354335785
75274 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 75.52526044845581

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 28] [1, 28] [1, 28] [0, 2282] [1, 36] [0, 2282] [0, 2254] [1, 34] [1, 639] [1, 34] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 53.894840240478516 with beta sum per layer: [19.244258880615234, 1740.510986328125, 57.32626724243164]
alpha/beta optimization time: 1.02669095993042
This batch time : update_bounds func: 2.1666	 prepare: 0.6568	 bound: 1.0271	 transfer: 0.0777	 finalize: 0.3933
Accumulated time: update_bounds func: 44.6069	 prepare: 11.1038	 bound: 22.6562	 transfer: 0.0777	 finalize: 8.7749
batch bounding time:  2.171592950820923
Current worst splitting domains [lb, ub] (depth):
[-0.18283,   inf] (77), [-0.18035,   inf] (77), [-0.17790,   inf] (77), [-0.17249,   inf] (77), [-0.16487,   inf] (77), [-0.16301,   inf] (77), [-0.16287,   inf] (77), [-0.16192,   inf] (77), [-0.15909,   inf] (77), [-0.15556,   inf] (77), [-0.15549,   inf] (77), [-0.15457,   inf] (77), [-0.15400,   inf] (77), [-0.15305,   inf] (77), [-0.14874,   inf] (77), [-0.14726,   inf] (77), [-0.14575,   inf] (77), [-0.13994,   inf] (77), [-0.13962,   inf] (77), [-0.13929,   inf] (77), 
length of domains: 14942
Total time: 4.4546	 pickout: 0.4460	 decision: 1.0585	 get_bound: 2.1803	 add_domain: 0.7699
Current lb:-0.18283145129680634
79370 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 80.0476586818695

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 636] [1, 33] [1, 36] [1, 178] [1, 639] [1, 143] [1, 143] [1, 639] [1, 636] [1, 639] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 35.19212341308594 with beta sum per layer: [19.28128433227539, 1700.9149169921875, 56.697357177734375]
alpha/beta optimization time: 1.0221552848815918
This batch time : update_bounds func: 2.4421	 prepare: 0.6681	 bound: 1.0226	 transfer: 0.0788	 finalize: 0.6600
Accumulated time: update_bounds func: 47.0491	 prepare: 11.7719	 bound: 23.6788	 transfer: 0.0788	 finalize: 9.4348
batch bounding time:  2.446291446685791
Current worst splitting domains [lb, ub] (depth):
[-0.15393,   inf] (79), [-0.13550,   inf] (79), [-0.13509,   inf] (79), [-0.13411,   inf] (79), [-0.12979,   inf] (79), [-0.12811,   inf] (79), [-0.12646,   inf] (79), [-0.12131,   inf] (79), [-0.12069,   inf] (79), [-0.12068,   inf] (79), [-0.12064,   inf] (79), [-0.12040,   inf] (79), [-0.11586,   inf] (79), [-0.11366,   inf] (79), [-0.11193,   inf] (79), [-0.11153,   inf] (79), [-0.11133,   inf] (79), [-0.11131,   inf] (79), [-0.11032,   inf] (79), [-0.11025,   inf] (79), 
length of domains: 15262
Total time: 3.9316	 pickout: 0.4516	 decision: 0.7044	 get_bound: 2.4538	 add_domain: 0.3219
Current lb:-0.15393143892288208
83466 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 84.04942154884338

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [0, 2259] [2, 9] [0, 2259] [1, 36] [0, 2259] [1, 636] [0, 2259] [1, 36] [2, 9] [2, 9] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 13.201904296875 with beta sum per layer: [22.41024398803711, 1669.13818359375, 71.82656860351562]
alpha/beta optimization time: 1.0032572746276855
This batch time : update_bounds func: 1.8327	 prepare: 0.4485	 bound: 1.0036	 transfer: 0.0776	 finalize: 0.2901
Accumulated time: update_bounds func: 48.8817	 prepare: 12.2205	 bound: 24.6824	 transfer: 0.0776	 finalize: 9.7249
batch bounding time:  1.8375022411346436
Current worst splitting domains [lb, ub] (depth):
[-0.14796,   inf] (81), [-0.12394,   inf] (81), [-0.11935,   inf] (81), [-0.11930,   inf] (81), [-0.11349,   inf] (81), [-0.11029,   inf] (81), [-0.11013,   inf] (81), [-0.10831,   inf] (81), [-0.10321,   inf] (81), [-0.10091,   inf] (81), [-0.09831,   inf] (81), [-0.09773,   inf] (81), [-0.09717,   inf] (81), [-0.09482,   inf] (81), [-0.09413,   inf] (81), [-0.09331,   inf] (81), [-0.09103,   inf] (81), [-0.09093,   inf] (81), [-0.08988,   inf] (81), [-0.08946,   inf] (81), 
length of domains: 15400
Total time: 3.8686	 pickout: 0.3322	 decision: 0.9635	 get_bound: 1.8456	 add_domain: 0.7273
Current lb:-0.14795871078968048
87562 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 87.99143362045288

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 9] [2, 9] [2, 9] [2, 9] [2, 9] [2, 9] [0, 2259] [2, 13] [2, 9] [2, 9] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: -4.607395648956299 with beta sum per layer: [22.165096282958984, 1559.500732421875, 90.39303588867188]
alpha/beta optimization time: 1.002150058746338
This batch time : update_bounds func: 2.2538	 prepare: 0.4524	 bound: 1.0025	 transfer: 0.0787	 finalize: 0.7079
Accumulated time: update_bounds func: 51.1355	 prepare: 12.6729	 bound: 25.6849	 transfer: 0.0787	 finalize: 10.4328
batch bounding time:  2.2580983638763428
Current worst splitting domains [lb, ub] (depth):
[-0.12377,   inf] (83), [-0.10016,   inf] (83), [-0.09909,   inf] (83), [-0.09573,   inf] (83), [-0.09170,   inf] (83), [-0.09031,   inf] (83), [-0.08984,   inf] (83), [-0.08749,   inf] (83), [-0.08074,   inf] (83), [-0.08057,   inf] (83), [-0.08038,   inf] (83), [-0.07922,   inf] (83), [-0.07652,   inf] (83), [-0.07586,   inf] (83), [-0.07505,   inf] (63), [-0.07421,   inf] (83), [-0.07349,   inf] (55), [-0.07331,   inf] (55), [-0.07280,   inf] (61), [-0.07279,   inf] (83), 
length of domains: 15341
Total time: 3.4481	 pickout: 0.3364	 decision: 0.5710	 get_bound: 2.2658	 add_domain: 0.2750
Current lb:-0.12376990914344788
91658 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 91.51817965507507

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 13] [2, 13] [2, 13] [2, 13] [2, 13] [2, 13] [2, 13] [2, 13] [2, 13] [1, 33] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: -13.2307767868042 with beta sum per layer: [21.61023712158203, 1611.591796875, 65.87631225585938]
alpha/beta optimization time: 1.0006003379821777
This batch time : update_bounds func: 1.8414	 prepare: 0.4686	 bound: 1.0010	 transfer: 0.0764	 finalize: 0.2829
Accumulated time: update_bounds func: 52.9769	 prepare: 13.1415	 bound: 26.6859	 transfer: 0.0764	 finalize: 10.7157
batch bounding time:  1.8457074165344238
Current worst splitting domains [lb, ub] (depth):
[-0.09647,   inf] (85), [-0.07272,   inf] (85), [-0.07202,   inf] (85), [-0.06828,   inf] (85), [-0.06637,   inf] (63), [-0.06582,   inf] (61), [-0.06566,   inf] (85), [-0.06537,   inf] (55), [-0.06491,   inf] (65), [-0.06420,   inf] (61), [-0.06410,   inf] (65), [-0.06359,   inf] (63), [-0.06342,   inf] (59), [-0.06325,   inf] (57), [-0.06299,   inf] (63), [-0.06288,   inf] (61), [-0.06287,   inf] (61), [-0.06272,   inf] (85), [-0.06250,   inf] (85), [-0.06240,   inf] (67), 
length of domains: 15162
Total time: 3.9028	 pickout: 0.3433	 decision: 0.9842	 get_bound: 1.8533	 add_domain: 0.7219
Current lb:-0.09646955132484436
95754 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 95.499995470047

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 639] [1, 639] [1, 636] [1, 639] [1, 27] [1, 27] [1, 178] [1, 28] [1, 259] [1, 256] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: -38.30603790283203 with beta sum per layer: [22.370067596435547, 1567.43701171875, 66.0260009765625]
alpha/beta optimization time: 0.9980869293212891
This batch time : update_bounds func: 2.2568	 prepare: 0.4563	 bound: 0.9984	 transfer: 0.0783	 finalize: 0.7109
Accumulated time: update_bounds func: 55.2336	 prepare: 13.5978	 bound: 27.6843	 transfer: 0.0783	 finalize: 11.4266
batch bounding time:  2.2609925270080566
Current worst splitting domains [lb, ub] (depth):
[-0.05978,   inf] (57), [-0.05881,   inf] (61), [-0.05873,   inf] (57), [-0.05854,   inf] (63), [-0.05846,   inf] (57), [-0.05837,   inf] (63), [-0.05823,   inf] (59), [-0.05802,   inf] (59), [-0.05796,   inf] (61), [-0.05782,   inf] (59), [-0.05751,   inf] (63), [-0.05751,   inf] (55), [-0.05714,   inf] (55), [-0.05676,   inf] (57), [-0.05672,   inf] (57), [-0.05652,   inf] (59), [-0.05649,   inf] (59), [-0.05641,   inf] (57), [-0.05597,   inf] (57), [-0.05573,   inf] (61), 
length of domains: 14795
Total time: 3.4108	 pickout: 0.3367	 decision: 0.5704	 get_bound: 2.2685	 add_domain: 0.2352
Current lb:-0.05977928638458252
99850 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 98.99058961868286

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 33] [1, 27] [1, 33] [1, 27] [1, 178] [1, 27] [1, 256] [1, 28] [1, 28] [1, 708] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: -64.5786361694336 with beta sum per layer: [20.710391998291016, 1635.44677734375, 68.94234466552734]
alpha/beta optimization time: 0.9984664916992188
This batch time : update_bounds func: 1.8293	 prepare: 0.4543	 bound: 0.9988	 transfer: 0.0780	 finalize: 0.2855
Accumulated time: update_bounds func: 57.0630	 prepare: 14.0521	 bound: 28.6832	 transfer: 0.0780	 finalize: 11.7121
batch bounding time:  1.833531141281128
Current worst splitting domains [lb, ub] (depth):
[-0.05291,   inf] (61), [-0.05230,   inf] (61), [-0.05191,   inf] (57), [-0.05135,   inf] (63), [-0.05078,   inf] (61), [-0.05076,   inf] (55), [-0.05033,   inf] (65), [-0.05007,   inf] (55), [-0.05005,   inf] (61), [-0.04988,   inf] (59), [-0.04950,   inf] (55), [-0.04908,   inf] (63), [-0.04885,   inf] (61), [-0.04837,   inf] (61), [-0.04829,   inf] (55), [-0.04824,   inf] (57), [-0.04823,   inf] (57), [-0.04821,   inf] (57), [-0.04805,   inf] (57), [-0.04784,   inf] (61), 
length of domains: 14203
Total time: 3.3618	 pickout: 0.3415	 decision: 0.9740	 get_bound: 1.8409	 add_domain: 0.2053
Current lb:-0.05291318893432617
103946 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 102.43731260299683

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 256] [1, 256] [1, 178] [1, 27] [1, 27] [1, 259] [1, 259] [1, 708] [1, 27] [1, 259] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: -88.0101089477539 with beta sum per layer: [22.251436233520508, 1646.8365478515625, 68.28868103027344]
alpha/beta optimization time: 0.9985508918762207
This batch time : update_bounds func: 2.2306	 prepare: 0.4528	 bound: 0.9989	 transfer: 0.0771	 finalize: 0.6896
Accumulated time: update_bounds func: 59.2936	 prepare: 14.5049	 bound: 29.6821	 transfer: 0.0771	 finalize: 12.4017
batch bounding time:  2.234837293624878
Current worst splitting domains [lb, ub] (depth):
[-0.04605,   inf] (63), [-0.04574,   inf] (57), [-0.04521,   inf] (63), [-0.04510,   inf] (61), [-0.04504,   inf] (61), [-0.04441,   inf] (63), [-0.04402,   inf] (57), [-0.04395,   inf] (59), [-0.04394,   inf] (61), [-0.04388,   inf] (65), [-0.04382,   inf] (67), [-0.04341,   inf] (63), [-0.04303,   inf] (67), [-0.04293,   inf] (61), [-0.04212,   inf] (63), [-0.04212,   inf] (55), [-0.04209,   inf] (61), [-0.04209,   inf] (55), [-0.04155,   inf] (61), [-0.04126,   inf] (61), 
length of domains: 13338
Total time: 3.7139	 pickout: 0.3412	 decision: 0.9640	 get_bound: 2.2424	 add_domain: 0.1664
Current lb:-0.04604750871658325
108042 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 106.23956561088562

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 27] [1, 708] [1, 27] [1, 27] [1, 27] [1, 27] [1, 256] [1, 256] [1, 256] [1, 259] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: -113.67753601074219 with beta sum per layer: [22.639545440673828, 1635.89501953125, 71.13905334472656]
alpha/beta optimization time: 0.9984743595123291
This batch time : update_bounds func: 1.8355	 prepare: 0.4585	 bound: 0.9988	 transfer: 0.0777	 finalize: 0.2883
Accumulated time: update_bounds func: 61.1290	 prepare: 14.9634	 bound: 30.6809	 transfer: 0.0777	 finalize: 12.6900
batch bounding time:  1.8396878242492676
Current worst splitting domains [lb, ub] (depth):
[-0.03882,   inf] (69), [-0.03844,   inf] (59), [-0.03840,   inf] (59), [-0.03819,   inf] (59), [-0.03819,   inf] (59), [-0.03781,   inf] (63), [-0.03777,   inf] (57), [-0.03712,   inf] (59), [-0.03702,   inf] (57), [-0.03660,   inf] (55), [-0.03647,   inf] (65), [-0.03620,   inf] (57), [-0.03601,   inf] (61), [-0.03593,   inf] (61), [-0.03573,   inf] (61), [-0.03544,   inf] (65), [-0.03543,   inf] (71), [-0.03500,   inf] (55), [-0.03489,   inf] (67), [-0.03459,   inf] (71), 
length of domains: 12178
Total time: 3.2503	 pickout: 0.3407	 decision: 0.9352	 get_bound: 1.8471	 add_domain: 0.1272
Current lb:-0.03881877660751343
112138 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 109.58153080940247

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 143] [1, 259] [1, 27] [1, 27] [1, 36] [1, 27] [1, 178] [1, 178] [1, 28] [1, 112] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: -136.86492919921875 with beta sum per layer: [24.45295524597168, 1632.5296630859375, 74.899169921875]
alpha/beta optimization time: 0.9982266426086426
This batch time : update_bounds func: 2.1628	 prepare: 0.4533	 bound: 0.9986	 transfer: 0.0785	 finalize: 0.6207
Accumulated time: update_bounds func: 63.2918	 prepare: 15.4167	 bound: 31.6795	 transfer: 0.0785	 finalize: 13.3107
batch bounding time:  2.166977643966675
Current worst splitting domains [lb, ub] (depth):
[-0.03296,   inf] (57), [-0.03263,   inf] (71), [-0.03154,   inf] (63), [-0.03154,   inf] (63), [-0.03108,   inf] (55), [-0.03104,   inf] (59), [-0.03101,   inf] (63), [-0.03095,   inf] (63), [-0.03053,   inf] (55), [-0.03034,   inf] (63), [-0.03028,   inf] (69), [-0.03025,   inf] (57), [-0.03022,   inf] (63), [-0.02958,   inf] (61), [-0.02952,   inf] (67), [-0.02924,   inf] (61), [-0.02910,   inf] (59), [-0.02903,   inf] (61), [-0.02880,   inf] (55), [-0.02869,   inf] (61), 
length of domains: 10721
Total time: 3.5001	 pickout: 0.3413	 decision: 0.8978	 get_bound: 2.1744	 add_domain: 0.0866
Current lb:-0.03296065330505371
116234 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 113.17467498779297

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 178] [1, 34] [1, 27] [1, 256] [1, 259] [1, 259] [1, 27] [1, 256] [1, 112] [1, 27] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: -159.757568359375 with beta sum per layer: [23.64516830444336, 1669.2249755859375, 75.82467651367188]
alpha/beta optimization time: 1.0017139911651611
This batch time : update_bounds func: 2.1754	 prepare: 0.4492	 bound: 1.0021	 transfer: 0.0763	 finalize: 0.6361
Accumulated time: update_bounds func: 65.4672	 prepare: 15.8659	 bound: 32.6816	 transfer: 0.0763	 finalize: 13.9467
batch bounding time:  2.1795544624328613
Current worst splitting domains [lb, ub] (depth):
[-0.02711,   inf] (57), [-0.02668,   inf] (59), [-0.02664,   inf] (57), [-0.02558,   inf] (55), [-0.02515,   inf] (67), [-0.02509,   inf] (55), [-0.02498,   inf] (57), [-0.02489,   inf] (59), [-0.02479,   inf] (55), [-0.02474,   inf] (59), [-0.02470,   inf] (55), [-0.02461,   inf] (57), [-0.02451,   inf] (61), [-0.02440,   inf] (59), [-0.02377,   inf] (55), [-0.02367,   inf] (61), [-0.02347,   inf] (69), [-0.02331,   inf] (57), [-0.02288,   inf] (55), [-0.02240,   inf] (57), 
length of domains: 9028
Total time: 3.4561	 pickout: 0.3429	 decision: 0.8727	 get_bound: 2.1869	 add_domain: 0.0536
Current lb:-0.02711498737335205
120330 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 116.72540879249573

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 256] [1, 256] [1, 33] [0, 2282] [1, 259] [1, 112] [1, 256] [1, 28] [1, 256] [1, 259] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: -180.96090698242188 with beta sum per layer: [22.7591552734375, 1664.6610107421875, 84.25285339355469]
alpha/beta optimization time: 0.9991095066070557
This batch time : update_bounds func: 2.1209	 prepare: 0.4510	 bound: 0.9995	 transfer: 0.0777	 finalize: 0.5814
Accumulated time: update_bounds func: 67.5881	 prepare: 16.3169	 bound: 33.6811	 transfer: 0.0777	 finalize: 14.5282
batch bounding time:  2.125312566757202
Current worst splitting domains [lb, ub] (depth):
[-0.02233,   inf] (59), [-0.02187,   inf] (63), [-0.02136,   inf] (61), [-0.02049,   inf] (61), [-0.02043,   inf] (55), [-0.02015,   inf] (61), [-0.01990,   inf] (57), [-0.01981,   inf] (63), [-0.01964,   inf] (67), [-0.01941,   inf] (55), [-0.01863,   inf] (63), [-0.01861,   inf] (55), [-0.01860,   inf] (59), [-0.01822,   inf] (69), [-0.01794,   inf] (63), [-0.01780,   inf] (59), [-0.01728,   inf] (59), [-0.01728,   inf] (61), [-0.01728,   inf] (79), [-0.01727,   inf] (69), 
length of domains: 7207
Total time: 3.3313	 pickout: 0.3438	 decision: 0.8214	 get_bound: 2.1328	 add_domain: 0.0333
Current lb:-0.02232825756072998
124426 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 120.15163922309875

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 703] [1, 27] [1, 27] [1, 28] [1, 112] [1, 27] [1, 178] [1, 27] [1, 636] [1, 28] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: -202.1114501953125 with beta sum per layer: [24.417078018188477, 1713.479736328125, 73.04154968261719]
alpha/beta optimization time: 0.9975879192352295
This batch time : update_bounds func: 2.0541	 prepare: 0.4486	 bound: 0.9979	 transfer: 0.0786	 finalize: 0.5176
Accumulated time: update_bounds func: 69.6423	 prepare: 16.7655	 bound: 34.6791	 transfer: 0.0786	 finalize: 15.0458
batch bounding time:  2.0588126182556152
Current worst splitting domains [lb, ub] (depth):
[-0.01598,   inf] (57), [-0.01598,   inf] (57), [-0.01568,   inf] (65), [-0.01516,   inf] (61), [-0.01472,   inf] (55), [-0.01456,   inf] (59), [-0.01451,   inf] (55), [-0.01440,   inf] (65), [-0.01435,   inf] (61), [-0.01393,   inf] (59), [-0.01373,   inf] (55), [-0.01344,   inf] (63), [-0.01313,   inf] (61), [-0.01275,   inf] (61), [-0.01252,   inf] (61), [-0.01232,   inf] (67), [-0.01232,   inf] (71), [-0.01232,   inf] (57), [-0.01232,   inf] (61), [-0.01232,   inf] (69), 
length of domains: 5301
Total time: 3.2038	 pickout: 0.3433	 decision: 0.7718	 get_bound: 2.0666	 add_domain: 0.0220
Current lb:-0.01598489284515381
128522 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 123.44842433929443

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 28] [1, 256] [1, 259] [1, 27] [1, 256] [1, 708] [1, 708] [1, 259] [1, 143] [1, 33] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: -221.96815490722656 with beta sum per layer: [25.28628921508789, 1725.940185546875, 70.71102905273438]
alpha/beta optimization time: 0.999375581741333
This batch time : update_bounds func: 1.9837	 prepare: 0.4462	 bound: 0.9997	 transfer: 0.0760	 finalize: 0.4511
Accumulated time: update_bounds func: 71.6260	 prepare: 17.2117	 bound: 35.6788	 transfer: 0.0760	 finalize: 15.4970
batch bounding time:  1.9877190589904785
Current worst splitting domains [lb, ub] (depth):
[-0.01213,   inf] (61), [-0.01191,   inf] (57), [-0.01177,   inf] (55), [-0.01068,   inf] (59), [-0.01057,   inf] (59), [-0.01053,   inf] (55), [-0.01050,   inf] (57), [-0.01039,   inf] (57), [-0.00998,   inf] (61), [-0.00948,   inf] (59), [-0.00934,   inf] (57), [-0.00934,   inf] (61), [-0.00917,   inf] (63), [-0.00891,   inf] (55), [-0.00885,   inf] (57), [-0.00872,   inf] (57), [-0.00864,   inf] (61), [-0.00860,   inf] (63), [-0.00812,   inf] (55), [-0.00806,   inf] (63), 
length of domains: 3351
Total time: 3.0841	 pickout: 0.3466	 decision: 0.7270	 get_bound: 1.9948	 add_domain: 0.0157
Current lb:-0.012130022048950195
132618 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 126.61974453926086

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 178] [1, 178] [1, 708] [1, 143] [1, 27] [1, 708] [1, 112] [1, 256] [1, 27] [0, 2282] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: -239.660400390625 with beta sum per layer: [21.157316207885742, 1670.6590576171875, 82.71926879882812]
alpha/beta optimization time: 0.9934234619140625
This batch time : update_bounds func: 1.9266	 prepare: 0.4464	 bound: 0.9938	 transfer: 0.0784	 finalize: 0.3977
Accumulated time: update_bounds func: 73.5526	 prepare: 17.6580	 bound: 36.6726	 transfer: 0.0784	 finalize: 15.8947
batch bounding time:  1.930546760559082
Current worst splitting domains [lb, ub] (depth):
[-0.00666,   inf] (57), [-0.00661,   inf] (57), [-0.00634,   inf] (59), [-0.00559,   inf] (59), [-0.00532,   inf] (65), [-0.00477,   inf] (61), [-0.00468,   inf] (57), [-0.00457,   inf] (61), [-0.00444,   inf] (57), [-0.00439,   inf] (61), [-0.00417,   inf] (57), [-0.00408,   inf] (63), [-0.00370,   inf] (63), [-0.00368,   inf] (67), [-0.00337,   inf] (71), [-0.00321,   inf] (65), [-0.00310,   inf] (67), [-0.00309,   inf] (61), [-0.00294,   inf] (71), [-0.00291,   inf] (61), 
length of domains: 1346
Total time: 3.0916	 pickout: 0.3551	 decision: 0.7910	 get_bound: 1.9374	 add_domain: 0.0081
Current lb:-0.006659269332885742
136714 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 129.79664587974548

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1346, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([1346, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 256] [1, 28] [1, 143] [1, 33] [1, 259] [1, 27] [1, 256] [1, 33] [1, 28] [1, 27] 
regular batch size: 2*1346, diving batch size 1*0
best_l after optimization: -168.36570739746094 with beta sum per layer: [15.588079452514648, 1159.11669921875, 64.68073272705078]
alpha/beta optimization time: 0.6916153430938721
This batch time : update_bounds func: 1.2644	 prepare: 0.2898	 bound: 0.6920	 transfer: 0.0395	 finalize: 0.2370
Accumulated time: update_bounds func: 74.8170	 prepare: 17.9478	 bound: 37.3646	 transfer: 0.0395	 finalize: 16.1317
batch bounding time:  1.266946792602539
Current worst splitting domains [lb, ub] (depth):
[-0.00243,   inf] (61), [-0.00190,   inf] (63), [-0.00178,   inf] (59), [-0.00089,   inf] (61), [-0.00089,   inf] (59), [-0.00071,   inf] (67), [-0.00057,   inf] (61), 
length of domains: 7
Total time: 1.9707	 pickout: 0.2636	 decision: 0.4335	 get_bound: 1.2714	 add_domain: 0.0022
Current lb:-0.0024307966232299805
139406 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 131.85178995132446

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([7, 16, 13, 13]) pre split depth:  4
batch:  torch.Size([7, 16, 13, 13]) post split depth:  4
splitting decisions: 
split level 0: [1, 259] [1, 259] [1, 33] [1, 27] [1, 33] [1, 259] [1, 33] 
split level 1: [1, 178] [1, 27] [1, 178] [1, 33] [1, 256] [1, 36] [1, 27] 
split level 2: [1, 256] [1, 256] [1, 28] [1, 28] [1, 28] [1, 33] [1, 28] 
split level 3: [1, 33] [1, 33] [1, 256] [1, 178] [1, 636] [0, 2264] [1, 256] 
regular batch size: 2*56, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -28.28398895263672 with beta sum per layer: [2.0511293411254883, 26.947965621948242, 1.7668030261993408]
alpha/beta optimization time: 0.009322643280029297
This batch time : update_bounds func: 0.0312	 prepare: 0.0130	 bound: 0.0096	 transfer: 0.0015	 finalize: 0.0067
Accumulated time: update_bounds func: 74.8482	 prepare: 17.9608	 bound: 37.3742	 transfer: 0.0015	 finalize: 16.1384
batch bounding time:  0.031362056732177734
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0806	 pickout: 0.0027	 decision: 0.0297	 get_bound: 0.0481	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 131.948988199234

Image 4 label 9 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 132.01427793502808
4 1.0000000116860974e-07
##### [0:4] Tested against 7 ######
Model prediction is: tensor([[-1.3253, -1.1976, -1.6536, -2.8595,  8.7830, -3.1041, -0.2604,  0.6880,
         -2.5880,  3.2975]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 13, 13]) != torch.Size([2, 9, 1, 16, 13, 13]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 5, 5]) != torch.Size([2, 9, 1, 32, 5, 5]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 13, 13])
1 /11 torch.Size([1, 32, 5, 5])
2 /21 torch.Size([1, 100])
best_l after optimization: 4.8366899490356445 with beta sum per layer: []
alpha/beta optimization time: 0.9773836135864258
alpha-CROWN with fixed intermediate bounds: tensor([[-4.8367]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-4.8366899490356445
layer 0 size torch.Size([2704]) unstable 992
layer 1 size torch.Size([800]) unstable 151
layer 2 size torch.Size([100]) unstable 40
-----------------
# of unstable neurons: 1183
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 13, 13]) pre split depth:  7
batch:  torch.Size([1, 16, 13, 13]) post split depth:  7
splitting decisions: 
split level 0: [2, 6] 
split level 1: [2, 86] 
split level 2: [2, 99] 
split level 3: [2, 1] 
split level 4: [2, 51] 
split level 5: [2, 25] 
split level 6: [2, 14] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -69.63232421875 with beta sum per layer: [0.0, 0.0, 40.22986602783203]
alpha/beta optimization time: 0.25493288040161133
This batch time : update_bounds func: 0.2757	 prepare: 0.0097	 bound: 0.2552	 transfer: 0.0028	 finalize: 0.0076
Accumulated time: update_bounds func: 75.1239	 prepare: 17.9705	 bound: 37.6294	 transfer: 0.0028	 finalize: 16.1460
batch bounding time:  0.2758955955505371
Current worst splitting domains [lb, ub] (depth):
[-2.13601,   inf] (8), [-2.00151,   inf] (8), [-1.97349,   inf] (8), [-1.93737,   inf] (8), [-1.32745,   inf] (8), [-1.31937,   inf] (8), [-1.29127,   inf] (8), [-1.24719,   inf] (8), [-0.98881,   inf] (8), [-0.91973,   inf] (8), [-0.72464,   inf] (8), [-0.71442,   inf] (8), [-0.66779,   inf] (8), [-0.65063,   inf] (8), [-0.61292,   inf] (8), [-0.58500,   inf] (8), [-0.45050,   inf] (8), [-0.43226,   inf] (8), [-0.29218,   inf] (8), [-0.22609,   inf] (8), 
length of domains: 27
Total time: 0.3346	 pickout: 0.0008	 decision: 0.0411	 get_bound: 0.2915	 add_domain: 0.0012
Current lb:-2.136009931564331
128 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.329045057296753

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([27, 16, 13, 13]) pre split depth:  2
batch:  torch.Size([27, 16, 13, 13]) post split depth:  2
splitting decisions: 
split level 0: [1, 706] [1, 706] [1, 706] [1, 706] [1, 706] [1, 706] [1, 706] [1, 706] [1, 706] [2, 56] 
split level 1: [2, 56] [2, 36] [2, 36] [2, 36] [2, 36] [2, 36] [2, 36] [2, 36] [1, 636] [2, 36] 
regular batch size: 2*54, diving batch size 1*0
best_l after optimization: -0.4422473907470703 with beta sum per layer: [0.0, 2.777646064758301, 88.23145294189453]
alpha/beta optimization time: 0.24533748626708984
This batch time : update_bounds func: 0.2657	 prepare: 0.0105	 bound: 0.2456	 transfer: 0.0026	 finalize: 0.0066
Accumulated time: update_bounds func: 75.3896	 prepare: 17.9811	 bound: 37.8750	 transfer: 0.0026	 finalize: 16.1527
batch bounding time:  0.26587390899658203
Current worst splitting domains [lb, ub] (depth):
[-1.95143,   inf] (11), [-1.66796,   inf] (11), [-1.64518,   inf] (11), [-1.62291,   inf] (11), [-1.57337,   inf] (11), [-1.54247,   inf] (11), [-1.40473,   inf] (11), [-1.24586,   inf] (11), [-0.97145,   inf] (11), [-0.93142,   inf] (11), [-0.91479,   inf] (11), [-0.87511,   inf] (11), [-0.84352,   inf] (11), [-0.82309,   inf] (11), [-0.81249,   inf] (11), [-0.81172,   inf] (11), [-0.77528,   inf] (11), [-0.76653,   inf] (11), [-0.75597,   inf] (11), [-0.74610,   inf] (11), 
length of domains: 41
Total time: 0.3074	 pickout: 0.0042	 decision: 0.0279	 get_bound: 0.2732	 add_domain: 0.0021
Current lb:-1.9514265060424805
236 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.637014627456665

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([41, 16, 13, 13]) pre split depth:  2
batch:  torch.Size([41, 16, 13, 13]) post split depth:  2
splitting decisions: 
split level 0: [2, 58] [2, 56] [2, 56] [1, 256] [2, 56] [2, 56] [2, 56] [2, 58] [2, 56] [2, 56] 
split level 1: [2, 36] [2, 58] [1, 636] [1, 636] [1, 636] [2, 58] [2, 58] [2, 36] [2, 58] [2, 58] 
regular batch size: 2*82, diving batch size 1*0
best_l after optimization: -5.540465831756592 with beta sum per layer: [0.0, 14.09461498260498, 99.91761016845703]
alpha/beta optimization time: 0.2508523464202881
This batch time : update_bounds func: 0.2837	 prepare: 0.0183	 bound: 0.2512	 transfer: 0.0032	 finalize: 0.0105
Accumulated time: update_bounds func: 75.6733	 prepare: 17.9994	 bound: 38.1262	 transfer: 0.0032	 finalize: 16.1632
batch bounding time:  0.2839350700378418
Current worst splitting domains [lb, ub] (depth):
[-1.46368,   inf] (14), [-1.45152,   inf] (14), [-1.43727,   inf] (14), [-1.40384,   inf] (14), [-1.35129,   inf] (14), [-1.27950,   inf] (14), [-1.23115,   inf] (14), [-1.05781,   inf] (14), [-0.94071,   inf] (14), [-0.82885,   inf] (14), [-0.76820,   inf] (14), [-0.71691,   inf] (14), [-0.69654,   inf] (14), [-0.69565,   inf] (14), [-0.65560,   inf] (14), [-0.65550,   inf] (14), [-0.60406,   inf] (14), [-0.59851,   inf] (14), [-0.46931,   inf] (14), [-0.45515,   inf] (14), 
length of domains: 57
Total time: 0.3360	 pickout: 0.0060	 decision: 0.0316	 get_bound: 0.2952	 add_domain: 0.0032
Current lb:-1.463683009147644
400 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.9739904403686523

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([57, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([57, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 636] [2, 56] [2, 12] [1, 636] [2, 58] [2, 58] [2, 12] [1, 256] [2, 56] [1, 256] 
regular batch size: 2*57, diving batch size 1*0
best_l after optimization: 9.3807954788208 with beta sum per layer: [0.0, 13.151121139526367, 59.19880676269531]
alpha/beta optimization time: 0.24556279182434082
This batch time : update_bounds func: 0.2668	 prepare: 0.0120	 bound: 0.2459	 transfer: 0.0015	 finalize: 0.0072
Accumulated time: update_bounds func: 75.9401	 prepare: 18.0114	 bound: 38.3721	 transfer: 0.0015	 finalize: 16.1703
batch bounding time:  0.26705169677734375
Current worst splitting domains [lb, ub] (depth):
[-1.35579,   inf] (16), [-1.32145,   inf] (16), [-1.30025,   inf] (16), [-1.27246,   inf] (16), [-1.20125,   inf] (16), [-1.12334,   inf] (16), [-1.07043,   inf] (16), [-1.04022,   inf] (16), [-0.78145,   inf] (16), [-0.77757,   inf] (16), [-0.74650,   inf] (16), [-0.72879,   inf] (16), [-0.59004,   inf] (16), [-0.56896,   inf] (16), [-0.56339,   inf] (16), [-0.53516,   inf] (16), [-0.53095,   inf] (16), [-0.49264,   inf] (16), [-0.45390,   inf] (16), [-0.44473,   inf] (16), 
length of domains: 49
Total time: 0.3117	 pickout: 0.0082	 decision: 0.0334	 get_bound: 0.2672	 add_domain: 0.0028
Current lb:-1.355789303779602
514 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.2867608070373535

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([49, 16, 13, 13]) pre split depth:  2
batch:  torch.Size([49, 16, 13, 13]) post split depth:  2
splitting decisions: 
split level 0: [2, 12] [2, 58] [1, 636] [1, 256] [1, 256] [1, 256] [1, 256] [1, 636] [2, 58] [2, 58] 
split level 1: [1, 256] [1, 632] [1, 256] [2, 12] [1, 631] [1, 632] [1, 636] [2, 12] [1, 632] [1, 632] 
regular batch size: 2*98, diving batch size 1*0
best_l after optimization: -24.241975784301758 with beta sum per layer: [0.0, 25.3561954498291, 96.05064392089844]
alpha/beta optimization time: 0.2610912322998047
This batch time : update_bounds func: 0.2984	 prepare: 0.0215	 bound: 0.2614	 transfer: 0.0028	 finalize: 0.0122
Accumulated time: update_bounds func: 76.2385	 prepare: 18.0329	 bound: 38.6335	 transfer: 0.0028	 finalize: 16.1826
batch bounding time:  0.2987074851989746
Current worst splitting domains [lb, ub] (depth):
[-1.16460,   inf] (19), [-1.16451,   inf] (19), [-1.09313,   inf] (19), [-1.01575,   inf] (19), [-0.94866,   inf] (19), [-0.92029,   inf] (19), [-0.87873,   inf] (19), [-0.75981,   inf] (19), [-0.75174,   inf] (19), [-0.73140,   inf] (19), [-0.70071,   inf] (19), [-0.68003,   inf] (19), [-0.67637,   inf] (19), [-0.64704,   inf] (19), [-0.61663,   inf] (19), [-0.60240,   inf] (19), [-0.56820,   inf] (19), [-0.51301,   inf] (19), [-0.48758,   inf] (19), [-0.48182,   inf] (19), 
length of domains: 50
Total time: 0.3575	 pickout: 0.0071	 decision: 0.0349	 get_bound: 0.3124	 add_domain: 0.0032
Current lb:-1.1646000146865845
710 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.645599365234375

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([50, 16, 13, 13]) pre split depth:  2
batch:  torch.Size([50, 16, 13, 13]) post split depth:  2
splitting decisions: 
split level 0: [2, 89] [2, 89] [1, 632] [1, 632] [2, 89] [1, 631] [1, 631] [2, 12] [1, 631] [1, 632] 
split level 1: [1, 632] [1, 632] [1, 141] [2, 12] [1, 632] [0, 2254] [0, 2254] [1, 631] [1, 632] [1, 141] 
regular batch size: 2*100, diving batch size 1*0
best_l after optimization: -22.997379302978516 with beta sum per layer: [0.3117307126522064, 31.540321350097656, 61.15608596801758]
alpha/beta optimization time: 0.26436281204223633
This batch time : update_bounds func: 0.3005	 prepare: 0.0203	 bound: 0.2647	 transfer: 0.0029	 finalize: 0.0122
Accumulated time: update_bounds func: 76.5391	 prepare: 18.0532	 bound: 38.8982	 transfer: 0.0029	 finalize: 16.1947
batch bounding time:  0.30080747604370117
Current worst splitting domains [lb, ub] (depth):
[-0.79572,   inf] (22), [-0.78779,   inf] (22), [-0.74163,   inf] (22), [-0.73193,   inf] (22), [-0.69596,   inf] (22), [-0.67814,   inf] (22), [-0.67000,   inf] (22), [-0.62283,   inf] (22), [-0.60116,   inf] (22), [-0.56335,   inf] (22), [-0.53291,   inf] (22), [-0.43213,   inf] (22), [-0.37804,   inf] (22), [-0.36315,   inf] (22), [-0.34799,   inf] (22), [-0.34714,   inf] (22), [-0.32461,   inf] (22), [-0.32126,   inf] (22), [-0.31396,   inf] (22), [-0.30144,   inf] (22), 
length of domains: 58
Total time: 0.3622	 pickout: 0.0073	 decision: 0.0359	 get_bound: 0.3151	 add_domain: 0.0039
Current lb:-0.7957150936126709
910 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.0090103149414062

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([58, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([58, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [0, 2254] [0, 2254] [2, 12] [1, 633] [2, 73] [0, 2254] [2, 73] [0, 2254] [2, 89] [0, 2254] 
regular batch size: 2*58, diving batch size 1*0
best_l after optimization: 4.454410552978516 with beta sum per layer: [0.43156325817108154, 13.92218017578125, 42.612144470214844]
alpha/beta optimization time: 0.24843859672546387
This batch time : update_bounds func: 0.2711	 prepare: 0.0128	 bound: 0.2487	 transfer: 0.0018	 finalize: 0.0075
Accumulated time: update_bounds func: 76.8102	 prepare: 18.0660	 bound: 39.1469	 transfer: 0.0018	 finalize: 16.2022
batch bounding time:  0.2713015079498291
Current worst splitting domains [lb, ub] (depth):
[-0.78470,   inf] (24), [-0.78012,   inf] (24), [-0.68374,   inf] (24), [-0.66591,   inf] (24), [-0.61147,   inf] (24), [-0.58848,   inf] (24), [-0.57049,   inf] (24), [-0.56195,   inf] (24), [-0.55969,   inf] (24), [-0.43925,   inf] (24), [-0.42153,   inf] (24), [-0.41364,   inf] (24), [-0.39543,   inf] (24), [-0.36173,   inf] (24), [-0.32973,   inf] (24), [-0.28198,   inf] (24), [-0.28111,   inf] (24), [-0.28011,   inf] (24), [-0.27198,   inf] (24), [-0.26984,   inf] (24), 
length of domains: 53
Total time: 0.3178	 pickout: 0.0082	 decision: 0.0344	 get_bound: 0.2715	 add_domain: 0.0037
Current lb:-0.7846951484680176
1026 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.3278515338897705

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([53, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([53, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 73] [2, 73] [2, 12] [2, 89] [1, 633] [1, 633] [1, 633] [1, 633] [2, 73] [1, 633] 
regular batch size: 2*53, diving batch size 1*0
best_l after optimization: 0.47411441802978516 with beta sum per layer: [0.6926980018615723, 8.450995445251465, 42.884056091308594]
alpha/beta optimization time: 0.24817609786987305
This batch time : update_bounds func: 0.2700	 prepare: 0.0120	 bound: 0.2485	 transfer: 0.0026	 finalize: 0.0066
Accumulated time: update_bounds func: 77.0801	 prepare: 18.0780	 bound: 39.3954	 transfer: 0.0026	 finalize: 16.2088
batch bounding time:  0.27016639709472656
Current worst splitting domains [lb, ub] (depth):
[-0.68066,   inf] (26), [-0.67744,   inf] (26), [-0.55145,   inf] (26), [-0.54709,   inf] (26), [-0.53529,   inf] (26), [-0.52514,   inf] (26), [-0.51146,   inf] (26), [-0.46856,   inf] (26), [-0.43799,   inf] (26), [-0.35021,   inf] (26), [-0.34099,   inf] (26), [-0.31766,   inf] (26), [-0.31727,   inf] (26), [-0.29945,   inf] (26), [-0.27028,   inf] (26), [-0.18911,   inf] (26), [-0.18120,   inf] (26), [-0.16595,   inf] (26), [-0.16581,   inf] (26), [-0.15885,   inf] (26), 
length of domains: 49
Total time: 0.3137	 pickout: 0.0079	 decision: 0.0318	 get_bound: 0.2703	 add_domain: 0.0037
Current lb:-0.6806612014770508
1132 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.642618179321289

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([49, 16, 13, 13]) pre split depth:  2
batch:  torch.Size([49, 16, 13, 13]) post split depth:  2
splitting decisions: 
split level 0: [1, 633] [1, 633] [2, 9] [2, 89] [2, 89] [1, 631] [1, 631] [2, 89] [1, 633] [2, 9] 
split level 1: [2, 9] [1, 141] [2, 63] [1, 112] [1, 112] [1, 141] [1, 633] [1, 112] [2, 9] [1, 141] 
regular batch size: 2*98, diving batch size 1*0
best_l after optimization: -48.71075439453125 with beta sum per layer: [1.3590788841247559, 15.325763702392578, 62.552005767822266]
alpha/beta optimization time: 0.26256465911865234
This batch time : update_bounds func: 0.3005	 prepare: 0.0209	 bound: 0.2629	 transfer: 0.0044	 finalize: 0.0116
Accumulated time: update_bounds func: 77.3806	 prepare: 18.0989	 bound: 39.6582	 transfer: 0.0044	 finalize: 16.2205
batch bounding time:  0.3007841110229492
Current worst splitting domains [lb, ub] (depth):
[-0.53866,   inf] (29), [-0.49441,   inf] (29), [-0.29521,   inf] (29), [-0.28302,   inf] (29), [-0.27304,   inf] (29), [-0.25304,   inf] (29), [-0.25235,   inf] (29), [-0.23794,   inf] (29), [-0.20880,   inf] (29), [-0.19223,   inf] (29), [-0.17007,   inf] (29), [-0.15228,   inf] (29), [-0.15071,   inf] (29), [-0.13584,   inf] (29), [-0.11933,   inf] (29), [-0.11643,   inf] (29), [-0.10924,   inf] (29), [-0.08487,   inf] (29), [-0.06191,   inf] (29), [-0.05089,   inf] (29), 
length of domains: 24
Total time: 0.3604	 pickout: 0.0074	 decision: 0.0353	 get_bound: 0.3158	 add_domain: 0.0019
Current lb:-0.5386569499969482
1328 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.004449844360352

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([24, 16, 13, 13]) pre split depth:  3
batch:  torch.Size([24, 16, 13, 13]) post split depth:  3
splitting decisions: 
split level 0: [1, 631] [1, 631] [2, 73] [2, 47] [1, 631] [1, 31] [2, 9] [1, 31] [2, 47] [1, 31] 
split level 1: [2, 63] [2, 9] [2, 9] [1, 631] [1, 141] [2, 73] [2, 63] [2, 73] [1, 631] [1, 141] 
split level 2: [1, 141] [2, 63] [2, 63] [1, 141] [2, 63] [2, 63] [1, 708] [2, 63] [0, 2254] [2, 63] 
regular batch size: 2*96, diving batch size 1*0
best_l after optimization: -65.68925476074219 with beta sum per layer: [0.7865617871284485, 8.749490737915039, 32.873779296875]
alpha/beta optimization time: 0.2579689025878906
This batch time : update_bounds func: 0.2950	 prepare: 0.0213	 bound: 0.2583	 transfer: 0.0027	 finalize: 0.0123
Accumulated time: update_bounds func: 77.6757	 prepare: 18.1202	 bound: 39.9165	 transfer: 0.0027	 finalize: 16.2328
batch bounding time:  0.29534029960632324
Current worst splitting domains [lb, ub] (depth):
[-0.16677,   inf] (33), [-0.13328,   inf] (33), [-0.11322,   inf] (33), [-0.04037,   inf] (33), [-0.02680,   inf] (33), 
length of domains: 5
Total time: 0.3499	 pickout: 0.0040	 decision: 0.0287	 get_bound: 0.3167	 add_domain: 0.0006
Current lb:-0.1667739748954773
1520 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.355665683746338

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([5, 16, 13, 13]) pre split depth:  5
batch:  torch.Size([5, 16, 13, 13]) post split depth:  5
splitting decisions: 
split level 0: [2, 47] [2, 47] [2, 47] [2, 47] [1, 112] 
split level 1: [1, 708] [1, 31] [1, 112] [1, 31] [1, 141] 
split level 2: [2, 65] [1, 702] [1, 637] [1, 112] [1, 708] 
split level 3: [1, 638] [1, 708] [2, 65] [1, 708] [2, 65] 
split level 4: [1, 258] [2, 65] [1, 638] [2, 65] [1, 638] 
regular batch size: 2*80, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -92.85115814208984 with beta sum per layer: [0.0, 1.880336046218872, 22.923686981201172]
alpha/beta optimization time: 0.009214162826538086
This batch time : update_bounds func: 0.0384	 prepare: 0.0173	 bound: 0.0095	 transfer: 0.0023	 finalize: 0.0089
Accumulated time: update_bounds func: 77.7140	 prepare: 18.1376	 bound: 39.9260	 transfer: 0.0023	 finalize: 16.2416
batch bounding time:  0.03852391242980957
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0961	 pickout: 0.0014	 decision: 0.0331	 get_bound: 0.0615	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 4.45263934135437

Image 4 label 7 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 4.516457557678223
4 1.0000000116860974e-07
##### [0:4] Tested against 0 ######
Model prediction is: tensor([[-1.3253, -1.1976, -1.6536, -2.8595,  8.7830, -3.1041, -0.2604,  0.6880,
         -2.5880,  3.2975]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 13, 13]) != torch.Size([2, 9, 1, 16, 13, 13]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 5, 5]) != torch.Size([2, 9, 1, 32, 5, 5]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 13, 13])
1 /11 torch.Size([1, 32, 5, 5])
2 /21 torch.Size([1, 100])
best_l after optimization: 0.12140560150146484 with beta sum per layer: []
alpha/beta optimization time: 0.9355144500732422
alpha-CROWN with fixed intermediate bounds: tensor([[-0.1214]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.12140560150146484
layer 0 size torch.Size([2704]) unstable 992
layer 1 size torch.Size([800]) unstable 151
layer 2 size torch.Size([100]) unstable 40
-----------------
# of unstable neurons: 1183
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 13, 13]) pre split depth:  7
batch:  torch.Size([1, 16, 13, 13]) post split depth:  7
splitting decisions: 
split level 0: [2, 99] 
split level 1: [2, 51] 
split level 2: [2, 12] 
split level 3: [2, 25] 
split level 4: [2, 86] 
split level 5: [2, 41] 
split level 6: [1, 598] 
regular batch size: 2*64, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -450.5370788574219 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.012311697006225586
This batch time : update_bounds func: 0.0319	 prepare: 0.0098	 bound: 0.0127	 transfer: 0.0018	 finalize: 0.0073
Accumulated time: update_bounds func: 77.7460	 prepare: 18.1474	 bound: 39.9387	 transfer: 0.0018	 finalize: 16.2489
batch bounding time:  0.03208732604980469
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0894	 pickout: 0.0008	 decision: 0.0409	 get_bound: 0.0477	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.0414454936981201

Image 4 label 0 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.1028728485107422
4 1.0000000116860974e-07
##### [0:4] Tested against 6 ######
Model prediction is: tensor([[-1.3253, -1.1976, -1.6536, -2.8595,  8.7830, -3.1041, -0.2604,  0.6880,
         -2.5880,  3.2975]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 13, 13]) != torch.Size([2, 9, 1, 16, 13, 13]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 5, 5]) != torch.Size([2, 9, 1, 32, 5, 5]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 13, 13])
1 /11 torch.Size([1, 32, 5, 5])
2 /21 torch.Size([1, 100])
best_l after optimization: 0.8351082801818848 with beta sum per layer: []
alpha/beta optimization time: 0.9403471946716309
alpha-CROWN with fixed intermediate bounds: tensor([[-0.8351]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.8351082801818848
layer 0 size torch.Size([2704]) unstable 992
layer 1 size torch.Size([800]) unstable 151
layer 2 size torch.Size([100]) unstable 40
-----------------
# of unstable neurons: 1183
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 13, 13]) pre split depth:  7
batch:  torch.Size([1, 16, 13, 13]) post split depth:  7
splitting decisions: 
split level 0: [2, 11] 
split level 1: [2, 25] 
split level 2: [2, 9] 
split level 3: [2, 51] 
split level 4: [2, 12] 
split level 5: [2, 86] 
split level 6: [2, 1] 
regular batch size: 2*64, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -301.11041259765625 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.010074853897094727
This batch time : update_bounds func: 0.0294	 prepare: 0.0097	 bound: 0.0103	 transfer: 0.0018	 finalize: 0.0073
Accumulated time: update_bounds func: 77.7754	 prepare: 18.1571	 bound: 39.9490	 transfer: 0.0018	 finalize: 16.2562
batch bounding time:  0.029577016830444336
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0867	 pickout: 0.0007	 decision: 0.0407	 get_bound: 0.0452	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.0433449745178223

Image 4 label 6 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.1054155826568604
4 1.0000000116860974e-07
##### [0:4] Tested against 1 ######
Model prediction is: tensor([[-1.3253, -1.1976, -1.6536, -2.8595,  8.7830, -3.1041, -0.2604,  0.6880,
         -2.5880,  3.2975]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 13, 13]) != torch.Size([2, 9, 1, 16, 13, 13]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 5, 5]) != torch.Size([2, 9, 1, 32, 5, 5]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 13, 13])
1 /11 torch.Size([1, 32, 5, 5])
2 /21 torch.Size([1, 100])
best_l after optimization: 0.2377314567565918 with beta sum per layer: []
alpha/beta optimization time: 0.9507648944854736
alpha-CROWN with fixed intermediate bounds: tensor([[-0.2377]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.2377314567565918
layer 0 size torch.Size([2704]) unstable 992
layer 1 size torch.Size([800]) unstable 151
layer 2 size torch.Size([100]) unstable 40
-----------------
# of unstable neurons: 1183
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 13, 13]) pre split depth:  7
batch:  torch.Size([1, 16, 13, 13]) post split depth:  7
splitting decisions: 
split level 0: [2, 10] 
split level 1: [2, 51] 
split level 2: [2, 99] 
split level 3: [2, 58] 
split level 4: [2, 36] 
split level 5: [2, 86] 
split level 6: [2, 1] 
regular batch size: 2*64, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -371.0569763183594 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.011012792587280273
This batch time : update_bounds func: 0.0317	 prepare: 0.0097	 bound: 0.0113	 transfer: 0.0029	 finalize: 0.0075
Accumulated time: update_bounds func: 77.8071	 prepare: 18.1668	 bound: 39.9603	 transfer: 0.0029	 finalize: 16.2638
batch bounding time:  0.031832218170166016
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0894	 pickout: 0.0007	 decision: 0.0413	 get_bound: 0.0473	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.056476354598999

Image 4 label 1 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.1155591011047363
4 1.0000000116860974e-07
##### [0:4] Tested against 8 ######
Model prediction is: tensor([[-1.3253, -1.1976, -1.6536, -2.8595,  8.7830, -3.1041, -0.2604,  0.6880,
         -2.5880,  3.2975]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 13, 13]) != torch.Size([2, 9, 1, 16, 13, 13]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 5, 5]) != torch.Size([2, 9, 1, 32, 5, 5]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 13, 13])
1 /11 torch.Size([1, 32, 5, 5])
2 /21 torch.Size([1, 100])
best_l after optimization: 2.406036376953125 with beta sum per layer: []
alpha/beta optimization time: 0.9611639976501465
alpha-CROWN with fixed intermediate bounds: tensor([[-2.4060]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-2.406036376953125
layer 0 size torch.Size([2704]) unstable 992
layer 1 size torch.Size([800]) unstable 151
layer 2 size torch.Size([100]) unstable 40
-----------------
# of unstable neurons: 1183
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 13, 13]) pre split depth:  7
batch:  torch.Size([1, 16, 13, 13]) post split depth:  7
splitting decisions: 
split level 0: [2, 58] 
split level 1: [2, 25] 
split level 2: [2, 51] 
split level 3: [2, 95] 
split level 4: [2, 5] 
split level 5: [2, 65] 
split level 6: [2, 11] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -163.97279357910156 with beta sum per layer: [0.0, 0.0, 0.6594390273094177]
alpha/beta optimization time: 0.2717421054840088
This batch time : update_bounds func: 0.2912	 prepare: 0.0097	 bound: 0.2720	 transfer: 0.0016	 finalize: 0.0075
Accumulated time: update_bounds func: 78.0983	 prepare: 18.1765	 bound: 40.2323	 transfer: 0.0016	 finalize: 16.2713
batch bounding time:  0.29140400886535645
Current worst splitting domains [lb, ub] (depth):
[-0.26278,   inf] (8), [-0.24757,   inf] (8), [-0.15939,   inf] (8), [-0.05992,   inf] (8), [-0.05735,   inf] (8), [-0.01654,   inf] (8), 
length of domains: 6
Total time: 0.3492	 pickout: 0.0008	 decision: 0.0409	 get_bound: 0.3071	 add_domain: 0.0004
Current lb:-0.26277539134025574
128 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.3268802165985107

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([6, 16, 13, 13]) pre split depth:  5
batch:  torch.Size([6, 16, 13, 13]) post split depth:  5
splitting decisions: 
split level 0: [2, 99] [2, 99] [2, 99] [2, 99] [2, 99] [2, 99] 
split level 1: [1, 193] [1, 193] [1, 193] [1, 193] [1, 193] [1, 193] 
split level 2: [2, 56] [2, 56] [2, 56] [2, 56] [2, 56] [2, 56] 
split level 3: [2, 50] [2, 97] [2, 50] [1, 636] [2, 50] [2, 50] 
split level 4: [2, 97] [2, 50] [1, 598] [2, 50] [1, 598] [1, 598] 
regular batch size: 2*96, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -317.2371826171875 with beta sum per layer: [0.0, 0.0, 21.102048873901367]
alpha/beta optimization time: 0.009383678436279297
This batch time : update_bounds func: 0.0450	 prepare: 0.0176	 bound: 0.0097	 transfer: 0.0044	 finalize: 0.0130
Accumulated time: update_bounds func: 78.1433	 prepare: 18.1940	 bound: 40.2419	 transfer: 0.0044	 finalize: 16.2842
batch bounding time:  0.045204877853393555
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.1041	 pickout: 0.0015	 decision: 0.0339	 get_bound: 0.0687	 add_domain: 0.0001
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.431901454925537

Image 4 label 8 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.4915876388549805
4 1.0000000116860974e-07
##### [0:4] Tested against 3 ######
Model prediction is: tensor([[-1.3253, -1.1976, -1.6536, -2.8595,  8.7830, -3.1041, -0.2604,  0.6880,
         -2.5880,  3.2975]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 13, 13]) != torch.Size([2, 9, 1, 16, 13, 13]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 5, 5]) != torch.Size([2, 9, 1, 32, 5, 5]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 13, 13])
1 /11 torch.Size([1, 32, 5, 5])
2 /21 torch.Size([1, 100])
best_l after optimization: 1.0779237747192383 with beta sum per layer: []
alpha/beta optimization time: 0.9570472240447998
alpha-CROWN with fixed intermediate bounds: tensor([[-1.0779]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-1.0779237747192383
layer 0 size torch.Size([2704]) unstable 992
layer 1 size torch.Size([800]) unstable 151
layer 2 size torch.Size([100]) unstable 40
-----------------
# of unstable neurons: 1183
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 13, 13]) pre split depth:  7
batch:  torch.Size([1, 16, 13, 13]) post split depth:  7
splitting decisions: 
split level 0: [2, 1] 
split level 1: [2, 51] 
split level 2: [2, 56] 
split level 3: [2, 10] 
split level 4: [2, 9] 
split level 5: [2, 97] 
split level 6: [2, 12] 
regular batch size: 2*64, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -383.607177734375 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.010072946548461914
This batch time : update_bounds func: 0.0292	 prepare: 0.0097	 bound: 0.0103	 transfer: 0.0015	 finalize: 0.0073
Accumulated time: update_bounds func: 78.1724	 prepare: 18.2037	 bound: 40.2523	 transfer: 0.0015	 finalize: 16.2915
batch bounding time:  0.029299259185791016
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0864	 pickout: 0.0007	 decision: 0.0407	 get_bound: 0.0450	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.0597894191741943

Image 4 label 3 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.1189234256744385
4 1.0000000116860974e-07
##### [0:4] Tested against 2 ######
Model prediction is: tensor([[-1.3253, -1.1976, -1.6536, -2.8595,  8.7830, -3.1041, -0.2604,  0.6880,
         -2.5880,  3.2975]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 13, 13]) != torch.Size([2, 9, 1, 16, 13, 13]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 5, 5]) != torch.Size([2, 9, 1, 32, 5, 5]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 13, 13])
1 /11 torch.Size([1, 32, 5, 5])
2 /21 torch.Size([1, 100])
best_l after optimization: 1.8181571960449219 with beta sum per layer: []
alpha/beta optimization time: 1.0486011505126953
alpha-CROWN with fixed intermediate bounds: tensor([[-1.8182]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-1.8181571960449219
layer 0 size torch.Size([2704]) unstable 992
layer 1 size torch.Size([800]) unstable 151
layer 2 size torch.Size([100]) unstable 40
-----------------
# of unstable neurons: 1183
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 13, 13]) pre split depth:  7
batch:  torch.Size([1, 16, 13, 13]) post split depth:  7
splitting decisions: 
split level 0: [2, 51] 
split level 1: [2, 25] 
split level 2: [2, 1] 
split level 3: [2, 58] 
split level 4: [2, 99] 
split level 5: [2, 41] 
split level 6: [2, 12] 
regular batch size: 2*64, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -283.532470703125 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.011228561401367188
This batch time : update_bounds func: 0.0304	 prepare: 0.0097	 bound: 0.0115	 transfer: 0.0015	 finalize: 0.0073
Accumulated time: update_bounds func: 78.2028	 prepare: 18.2134	 bound: 40.2637	 transfer: 0.0015	 finalize: 16.2988
batch bounding time:  0.030508041381835938
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0878	 pickout: 0.0007	 decision: 0.0408	 get_bound: 0.0462	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.1525537967681885

Image 4 label 2 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.210026502609253
4 1.0000000116860974e-07
##### [0:4] Tested against 5 ######
Model prediction is: tensor([[-1.3253, -1.1976, -1.6536, -2.8595,  8.7830, -3.1041, -0.2604,  0.6880,
         -2.5880,  3.2975]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 13, 13]) != torch.Size([2, 9, 1, 16, 13, 13]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 5, 5]) != torch.Size([2, 9, 1, 32, 5, 5]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 13, 13])
1 /11 torch.Size([1, 32, 5, 5])
2 /21 torch.Size([1, 100])
best_l after optimization: 0.03824806213378906 with beta sum per layer: []
alpha/beta optimization time: 0.9235525131225586
alpha-CROWN with fixed intermediate bounds: tensor([[-0.0382]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.03824806213378906
layer 0 size torch.Size([2704]) unstable 992
layer 1 size torch.Size([800]) unstable 151
layer 2 size torch.Size([100]) unstable 40
-----------------
# of unstable neurons: 1183
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 13, 13]) pre split depth:  7
batch:  torch.Size([1, 16, 13, 13]) post split depth:  7
splitting decisions: 
split level 0: [2, 99] 
split level 1: [2, 86] 
split level 2: [2, 97] 
split level 3: [2, 25] 
split level 4: [2, 9] 
split level 5/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:556: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(eps_temp / std).reshape(1, -1, 1, 1)
: [2, 10] 
split level 6: [2, 11] 
regular batch size: 2*64, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -524.70703125 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.01005101203918457
This batch time : update_bounds func: 0.0291	 prepare: 0.0097	 bound: 0.0103	 transfer: 0.0016	 finalize: 0.0072
Accumulated time: update_bounds func: 78.2319	 prepare: 18.2231	 bound: 40.2740	 transfer: 0.0016	 finalize: 16.3060
batch bounding time:  0.02924513816833496
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0868	 pickout: 0.0007	 decision: 0.0409	 get_bound: 0.0451	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.0270516872406006

Image 4 label 5 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.086582899093628
4 1.0000000116860974e-07
##### [0:4] Tested against 4 ######
groundtruth label, skip!
Result: image 4 verification success (with branch and bound)!
Wall time: 155.55601572990417

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 1): [4]
verification failure idx (total 0): []
final verified acc: 100.0%[1]
verifier is called on 1 examples.
total verified: 1
mean time [cnt:1] (excluding attack success): 154.03810906410217
