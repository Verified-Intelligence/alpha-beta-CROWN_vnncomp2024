Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: mnist_conv_small_nat.pth
  name: mnist_conv_small
data:
  start: 113
  end: 114
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: MNIST_ERAN
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.12
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 2048
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 180
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 100
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Tue May  3 01:16:44 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(1, 16, kernel_size=(4, 4), stride=(2, 2))
  (1): ReLU()
  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))
  (3): ReLU()
  (4): Flatten()
  (5): Linear(in_features=800, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([1000, 1, 28, 28]) torch.Size([1000]) torch.Size([1000])
X range: tensor(2.8215) tensor(-0.4242) tensor(-0.0274)
Note runnerup label is empty here!
############################
epsilon after preprocessing: tensor([[[[0.3895]]]]), data_max = tensor([[[[2.8215]]]]), data_min = tensor([[[[-0.4242]]]])
Task length: 1
saving results to Verified_ret_[mnist_conv_small]_start=113_end=114_iter=20_b=2048_timeout=180_branching=kfsb-max-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 113 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 9, correct label 9, image norm 520.2838745117188, logits tensor([-4.1227, -5.8338, -1.1651,  2.5555,  1.7880, -3.6164, -8.9669,  4.6731,
         1.4478, 13.2568], device='cuda:0', grad_fn=<SelectBackward>)
##### PGD attack: True label: 9, Tested against: ['all'] ######
pgd prediction: tensor([-3.1159, -4.0030, -0.6726,  2.6987, -0.2683, -2.8590, -8.9765,  6.7044,
         1.6377,  8.7923], device='cuda:0', grad_fn=<SqueezeBackward1>)
attack margin tensor([11.9082, 12.7953,  9.4649,  6.0936,  9.0606, 11.6512, 17.7687,  2.0879,
         7.1546,     inf], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[-4.1227, -5.8338, -1.1651,  2.5555,  1.7880, -3.6164, -8.9669,  4.6731,
          1.4478, 13.2568]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 3.5425,  0.6511, -2.1751, -2.4561, -3.0957,  2.7296,  5.7511, -6.5224,
         -2.1588]], device='cuda:0') None
best_l after optimization: -4.015039443969727 with beta sum per layer: []
alpha/beta optimization time: 7.17138671875
initial alpha-CROWN bounds: tensor([[ 4.1918,  1.6687, -1.2693, -1.7332, -2.2137,  3.5305,  6.5221, -5.3492,
         -1.3328]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-5.3492, device='cuda:0', grad_fn=<MinBackward1>)
Sorted order for labels to verify: [7, 3, 8, 4, 2, 5, 0, 1, 6, 9]
##### [0:113] Tested against 7 ######
Model prediction is: tensor([[-4.1227, -5.8338, -1.1651,  2.5555,  1.7880, -3.6164, -8.9669,  4.6731,
          1.4478, 13.2568]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 13, 13]) != torch.Size([2, 9, 1, 16, 13, 13]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 5, 5]) != torch.Size([2, 9, 1, 32, 5, 5]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 13, 13])
1 /11 torch.Size([1, 32, 5, 5])
2 /21 torch.Size([1, 100])
best_l after optimization: 5.348905086517334 with beta sum per layer: []
alpha/beta optimization time: 1.769303560256958
alpha-CROWN with fixed intermediate bounds: tensor([[-5.3489]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-5.348905086517334
layer 0 size torch.Size([2704]) unstable 942
layer 1 size torch.Size([800]) unstable 146
layer 2 size torch.Size([100]) unstable 33
-----------------
# of unstable neurons: 1121
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 13, 13]) pre split depth:  7
batch:  torch.Size([1, 16, 13, 13]) post split depth:  7
splitting decisions: 
split level 0: [2, 1] 
split level 1: [2, 86] 
split level 2: [2, 63] 
split level 3: [2, 89] 
split level 4: [2, 7] 
split level 5: [2, 36] 
split level 6: [2, 58] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -59.615936279296875 with beta sum per layer: [0.0, 0.0, 36.33659362792969]
alpha/beta optimization time: 0.2533843517303467
This batch time : update_bounds func: 0.2737	 prepare: 0.0101	 bound: 0.2537	 transfer: 0.0016	 finalize: 0.0079
Accumulated time: update_bounds func: 0.2737	 prepare: 0.0101	 bound: 0.2537	 transfer: 0.0016	 finalize: 0.0079
batch bounding time:  0.27397871017456055
Current worst splitting domains [lb, ub] (depth):
[-2.09582,   inf] (8), [-1.67929,   inf] (8), [-1.46730,   inf] (8), [-1.45177,   inf] (8), [-1.28383,   inf] (8), [-1.03263,   inf] (8), [-0.95781,   inf] (8), [-0.94888,   inf] (8), [-0.84302,   inf] (8), [-0.83626,   inf] (8), [-0.80557,   inf] (8), [-0.78832,   inf] (8), [-0.78078,   inf] (8), [-0.74284,   inf] (8), [-0.73553,   inf] (8), [-0.62604,   inf] (8), [-0.61840,   inf] (8), [-0.56884,   inf] (8), [-0.52702,   inf] (8), [-0.51014,   inf] (8), 
length of domains: 30
Total time: 0.3348	 pickout: 0.0010	 decision: 0.0420	 get_bound: 0.2904	 add_domain: 0.0014
Current lb:-2.0958187580108643
128 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.93629789352417

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([30, 16, 13, 13]) pre split depth:  2
batch:  torch.Size([30, 16, 13, 13]) post split depth:  2
splitting decisions: 
split level 0: [2, 96] [2, 96] [1, 586] [1, 233] [2, 17] [1, 233] [2, 96] [1, 233] [2, 17] [1, 233] 
split level 1: [1, 586] [2, 17] [2, 17] [2, 17] [2, 96] [1, 586] [2, 17] [1, 586] [1, 586] [2, 17] 
regular batch size: 2*60, diving batch size 1*0
best_l after optimization: -28.270000457763672 with beta sum per layer: [0.0, 0.1323876678943634, 53.82657241821289]
alpha/beta optimization time: 0.2647993564605713
This batch time : update_bounds func: 0.2869	 prepare: 0.0125	 bound: 0.2651	 transfer: 0.0015	 finalize: 0.0073
Accumulated time: update_bounds func: 0.5606	 prepare: 0.0226	 bound: 0.5188	 transfer: 0.0015	 finalize: 0.0152
batch bounding time:  0.2870807647705078
Current worst splitting domains [lb, ub] (depth):
[-1.47810,   inf] (11), [-1.25526,   inf] (11), [-0.95681,   inf] (11), [-0.88958,   inf] (11), [-0.83016,   inf] (11), [-0.82761,   inf] (11), [-0.71862,   inf] (11), [-0.65328,   inf] (11), [-0.60710,   inf] (11), [-0.60256,   inf] (11), [-0.54112,   inf] (11), [-0.52020,   inf] (11), [-0.46103,   inf] (11), [-0.45832,   inf] (11), [-0.44414,   inf] (11), [-0.40460,   inf] (11), [-0.37627,   inf] (11), [-0.30226,   inf] (11), [-0.29263,   inf] (11), [-0.24701,   inf] (11), 
length of domains: 30
Total time: 0.3304	 pickout: 0.0046	 decision: 0.0289	 get_bound: 0.2955	 add_domain: 0.0015
Current lb:-1.4781016111373901
248 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.267423391342163

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([30, 16, 13, 13]) pre split depth:  2
batch:  torch.Size([30, 16, 13, 13]) post split depth:  2
splitting decisions: 
split level 0: [2, 17] [2, 17] [2, 65] [2, 17] [2, 17] [1, 586] [1, 586] [2, 65] [1, 586] [2, 65] 
split level 1: [1, 141] [1, 141] [1, 586] [1, 141] [1, 141] [2, 96] [1, 593] [2, 96] [2, 96] [2, 96] 
regular batch size: 2*60, diving batch size 1*0
best_l after optimization: -45.93613815307617 with beta sum per layer: [0.0, 0.5581169128417969, 45.754005432128906]
alpha/beta optimization time: 0.25264859199523926
This batch time : update_bounds func: 0.2748	 prepare: 0.0125	 bound: 0.2529	 transfer: 0.0015	 finalize: 0.0076
Accumulated time: update_bounds func: 0.8354	 prepare: 0.0351	 bound: 0.7717	 transfer: 0.0015	 finalize: 0.0228
batch bounding time:  0.2750570774078369
Current worst splitting domains [lb, ub] (depth):
[-0.68587,   inf] (14), [-0.60900,   inf] (14), [-0.55308,   inf] (14), [-0.53203,   inf] (14), [-0.51156,   inf] (14), [-0.41047,   inf] (14), [-0.33730,   inf] (14), [-0.30986,   inf] (14), [-0.27213,   inf] (14), [-0.24121,   inf] (14), [-0.19125,   inf] (14), [-0.17051,   inf] (14), [-0.13770,   inf] (14), [-0.09902,   inf] (14), [-0.08998,   inf] (14), [-0.03885,   inf] (14), [-0.02565,   inf] (14), [-0.02340,   inf] (14), [-0.02165,   inf] (14), 
length of domains: 19
Total time: 0.3178	 pickout: 0.0047	 decision: 0.0284	 get_bound: 0.2836	 add_domain: 0.0011
Current lb:-0.6858663558959961
368 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.5860724449157715

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([19, 16, 13, 13]) pre split depth:  3
batch:  torch.Size([19, 16, 13, 13]) post split depth:  3
splitting decisions: 
split level 0: [2, 65] [2, 65] [2, 65] [2, 65] [2, 65] [2, 65] [2, 65] [1, 593] [2, 65] [1, 632] 
split level 1: [1, 593] [1, 593] [1, 632] [1, 593] [1, 632] [2, 50] [1, 593] [1, 233] [1, 632] [1, 593] 
split level 2: [1, 632] [1, 632] [2, 50] [1, 632] [2, 50] [1, 632] [1, 632] [1, 632] [2, 50] [1, 233] 
regular batch size: 2*76, diving batch size 1*0
best_l after optimization: -115.94010162353516 with beta sum per layer: [0.0, 2.60965895652771, 34.37078857421875]
alpha/beta optimization time: 0.2543516159057617
This batch time : update_bounds func: 0.2827	 prepare: 0.0160	 bound: 0.2547	 transfer: 0.0025	 finalize: 0.0092
Accumulated time: update_bounds func: 1.1181	 prepare: 0.0510	 bound: 1.0264	 transfer: 0.0025	 finalize: 0.0320
batch bounding time:  0.28295302391052246
Current worst splitting domains [lb, ub] (depth):
[-0.16568,   inf] (18), [-0.09333,   inf] (18), [-0.09316,   inf] (18), [-0.02085,   inf] (18), 
length of domains: 4
Total time: 0.3295	 pickout: 0.0033	 decision: 0.0269	 get_bound: 0.2989	 add_domain: 0.0004
Current lb:-0.1656762957572937
520 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.916499614715576

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 16, 13, 13]) pre split depth:  5
batch:  torch.Size([4, 16, 13, 13]) post split depth:  5
splitting decisions: 
split level 0: [1, 136] [1, 136] [1, 136] [1, 136] 
split level 1: [2, 47] [2, 47] [2, 47] [2, 47] 
split level 2: [1, 636] [1, 636] [1, 636] [1, 636] 
split level 3: [2, 50] [2, 50] [2, 50] [2, 50] 
split level 4: [1, 233] [1, 233] [1, 233] [1, 233] 
regular batch size: 2*64, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -201.74496459960938 with beta sum per layer: [0.0, 3.254398822784424, 0.0]
alpha/beta optimization time: 0.009034156799316406
This batch time : update_bounds func: 0.0326	 prepare: 0.0134	 bound: 0.0093	 transfer: 0.0022	 finalize: 0.0073
Accumulated time: update_bounds func: 1.1507	 prepare: 0.0644	 bound: 1.0357	 transfer: 0.0022	 finalize: 0.0393
batch bounding time:  0.03269767761230469
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0833	 pickout: 0.0012	 decision: 0.0321	 get_bound: 0.0499	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 4.00045371055603

Image 113 label 7 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 4.0596253871917725
113 1.0000000116860974e-07
##### [0:113] Tested against 3 ######
Model prediction is: tensor([[-4.1227, -5.8338, -1.1651,  2.5555,  1.7880, -3.6164, -8.9669,  4.6731,
          1.4478, 13.2568]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 13, 13]) != torch.Size([2, 9, 1, 16, 13, 13]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 5, 5]) != torch.Size([2, 9, 1, 32, 5, 5]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 13, 13])
1 /11 torch.Size([1, 32, 5, 5])
2 /21 torch.Size([1, 100])
best_l after optimization: 1.7321577072143555 with beta sum per layer: []
alpha/beta optimization time: 0.9014079570770264
alpha-CROWN with fixed intermediate bounds: tensor([[-1.7322]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-1.7321577072143555
layer 0 size torch.Size([2704]) unstable 942
layer 1 size torch.Size([800]) unstable 146
layer 2 size torch.Size([100]) unstable 33
-----------------
# of unstable neurons: 1121
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 13, 13]) pre split depth:  7
batch:  torch.Size([1, 16, 13, 13]) post split depth:  7
splitting decisions: 
split level 0: [2, 1] 
split level 1: [2, 7] 
split level 2: [2, 96] 
split level 3: [2, 10] 
split level 4: [2, 36] 
split level 5: [2, 89] 
split level 6: [1, 586] 
regular batch size: 2*64, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -427.2794494628906 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.01009678840637207
This batch time : update_bounds func: 0.0299	 prepare: 0.0101	 bound: 0.0104	 transfer: 0.0016	 finalize: 0.0075
Accumulated time: update_bounds func: 1.1805	 prepare: 0.0745	 bound: 1.0460	 transfer: 0.0016	 finalize: 0.0468
batch bounding time:  0.029999256134033203
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0876	 pickout: 0.0007	 decision: 0.0409	 get_bound: 0.0459	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.0053820610046387

Image 113 label 3 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.066497564315796
113 1.0000000116860974e-07
##### [0:113] Tested against 8 ######
Model prediction is: tensor([[-4.1227, -5.8338, -1.1651,  2.5555,  1.7880, -3.6164, -8.9669,  4.6731,
          1.4478, 13.2568]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 13, 13]) != torch.Size([2, 9, 1, 16, 13, 13]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 5, 5]) != torch.Size([2, 9, 1, 32, 5, 5]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 13, 13])
1 /11 torch.Size([1, 32, 5, 5])
2 /21 torch.Size([1, 100])
best_l after optimization: 1.3317193984985352 with beta sum per layer: []
alpha/beta optimization time: 0.9804849624633789
alpha-CROWN with fixed intermediate bounds: tensor([[-1.3317]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-1.3317193984985352
layer 0 size torch.Size([2704]) unstable 942
layer 1 size torch.Size([800]) unstable 146
layer 2 size torch.Size([100]) unstable 33
-----------------
# of unstable neurons: 1121
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 13, 13]) pre split depth:  7
batch:  torch.Size([1, 16, 13, 13]) post split depth:  7
splitting decisions: 
split level 0: [2, 58] 
split level 1: [2, 65] 
split level 2: [2, 17] 
split level 3: [2, 50] 
split level 4: [2, 7] 
split level 5: [2, 89] 
split level 6: [2, 96] 
regular batch size: 2*64, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -448.7498779296875 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.010030984878540039
This batch time : update_bounds func: 0.0295	 prepare: 0.0099	 bound: 0.0103	 transfer: 0.0015	 finalize: 0.0074
Accumulated time: update_bounds func: 1.2101	 prepare: 0.0844	 bound: 1.0563	 transfer: 0.0015	 finalize: 0.0542
batch bounding time:  0.02968597412109375
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0875	 pickout: 0.0007	 decision: 0.0408	 get_bound: 0.0458	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.0841901302337646

Image 113 label 8 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.1756367683410645
113 1.0000000116860974e-07
##### [0:113] Tested against 4 ######
Model prediction is: tensor([[-4.1227, -5.8338, -1.1651,  2.5555,  1.7880, -3.6164, -8.9669,  4.6731,
          1.4478, 13.2568]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 13, 13]) != torch.Size([2, 9, 1, 16, 13, 13]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 5, 5]) != torch.Size([2, 9, 1, 32, 5, 5]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 13, 13])
1 /11 torch.Size([1, 32, 5, 5])
2 /21 torch.Size([1, 100])
best_l after optimization: 2.212517738342285 with beta sum per layer: []
alpha/beta optimization time: 0.981661319732666
alpha-CROWN with fixed intermediate bounds: tensor([[-2.2125]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-2.212517738342285
layer 0 size torch.Size([2704]) unstable 942
layer 1 size torch.Size([800]) unstable 146
layer 2 size torch.Size([100]) unstable 33
-----------------
# of unstable neurons: 1121
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 13, 13]) pre split depth:  7
batch:  torch.Size([1, 16, 13, 13]) post split depth:  7
splitting decisions: 
split level 0: [2, 96] 
split level 1: [2, 7] 
split level 2: [1, 586] 
split level 3: [2, 33] 
split level 4: [2, 63] 
split level 5: [1, 233] 
split level 6: [2, 17] 
regular batch size: 2*64, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -350.13311767578125 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.011299610137939453
This batch time : update_bounds func: 0.0314	 prepare: 0.0104	 bound: 0.0116	 transfer: 0.0016	 finalize: 0.0075
Accumulated time: update_bounds func: 1.2414	 prepare: 0.0948	 bound: 1.0679	 transfer: 0.0016	 finalize: 0.0617
batch bounding time:  0.03150629997253418
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0893	 pickout: 0.0007	 decision: 0.0409	 get_bound: 0.0477	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.0872066020965576

Image 113 label 4 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.1460607051849365
113 1.0000000116860974e-07
##### [0:113] Tested against 2 ######
Model prediction is: tensor([[-4.1227, -5.8338, -1.1651,  2.5555,  1.7880, -3.6164, -8.9669,  4.6731,
          1.4478, 13.2568]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 13, 13]) != torch.Size([2, 9, 1, 16, 13, 13]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 5, 5]) != torch.Size([2, 9, 1, 32, 5, 5]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 13, 13])
1 /11 torch.Size([1, 32, 5, 5])
2 /21 torch.Size([1, 100])
best_l after optimization: 1.2675968408584595 with beta sum per layer: []
alpha/beta optimization time: 0.9501585960388184
alpha-CROWN with fixed intermediate bounds: tensor([[-1.2676]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-1.2675968408584595
layer 0 size torch.Size([2704]) unstable 942
layer 1 size torch.Size([800]) unstable 146
layer 2 size torch.Size([100]) unstable 33
-----------------
# of unstable neurons: 1121
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 13, 13]) pre split depth:  7
batch:  torch.Size([1, 16, 13, 13]) post split depth:  7
splitting decisions: 
split level 0: [2, 1] 
split level 1: [2, 17] 
split level 2: [2, 89] 
split level 3: [2, 96] 
split level 4: [2, 58] 
split level 5: [2, 33] 
split level 6: [2, 7] 
regular batch size: 2*64, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -595.8184814453125 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.012624263763427734
This batch time : update_bounds func: 0.0323	 prepare: 0.0100	 bound: 0.0129	 transfer: 0.0015	 finalize: 0.0075
Accumulated time: update_bounds func: 1.2738	 prepare: 0.1049	 bound: 1.0808	 transfer: 0.0015	 finalize: 0.0692
batch bounding time:  0.032448530197143555
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0904	 pickout: 0.0007	 decision: 0.0409	 get_bound: 0.0486	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.0568170547485352

Image 113 label 2 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.1141531467437744
113 1.0000000116860974e-07
##### [0:113] Tested against 5 ######
Initial alpha-CROWN verified for label 5 with bound 3.5305140018463135
Image 113 label 5 verification end, final lower bound 3.5305140018463135, upper bound inf, time: 0.00039267539978027344
113 3.5305140018463135
##### [0:113] Tested against 0 ######
Initial alpha-CROWN verified for label 0 with bound 4.19180154800415
Image 113 label 0 verification end, final lower bound 4.19180154800415, upper bound inf, time: 0.0004036426544189453
113 4.19180154800415
##### [0:113] Tested against 1 ######
Initial alpha-CROWN verified for label 1 with bound 1.668729305267334
Image 113 label 1 verification end, final lower bound 1.668729305267334, upper bound inf, time: 0.00040459632873535156
113 1.668729305267334
##### [0:113] Tested against 6 ######/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:556: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(eps_temp / std).reshape(1, -1, 1, 1)

Initial alpha-CROWN verified for label 6 with bound 6.522149562835693
Image 113 label 6 verification end, final lower bound 6.522149562835693, upper bound inf, time: 0.00040221214294433594
113 6.522149562835693
##### [0:113] Tested against 9 ######
groundtruth label, skip!
Result: image 113 verification success (with branch and bound)!
Wall time: 18.632426738739014

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 1): [113]
verification failure idx (total 0): []
final verified acc: 100.0%[1]
verifier is called on 1 examples.
total verified: 1
mean time [cnt:1] (excluding attack success): 17.37117624282837
