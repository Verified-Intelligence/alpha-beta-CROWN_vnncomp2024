Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: mnist_conv_small_nat.pth
  name: mnist_conv_small
data:
  start: 24
  end: 25
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: MNIST_ERAN
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.12
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 2048
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 180
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 100
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Tue May  3 01:19:49 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(1, 16, kernel_size=(4, 4), stride=(2, 2))
  (1): ReLU()
  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))
  (3): ReLU()
  (4): Flatten()
  (5): Linear(in_features=800, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([1000, 1, 28, 28]) torch.Size([1000]) torch.Size([1000])
X range: tensor(2.8215) tensor(-0.4242) tensor(-0.0274)
Note runnerup label is empty here!
############################
epsilon after preprocessing: tensor([[[[0.3895]]]]), data_max = tensor([[[[2.8215]]]]), data_min = tensor([[[[-0.4242]]]])
Task length: 1
saving results to Verified_ret_[mnist_conv_small]_start=24_end=25_iter=20_b=2048_timeout=180_branching=kfsb-max-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 24 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 4, correct label 4, image norm 421.6563720703125, logits tensor([-2.1875,  0.2578, -1.0516, -3.1591,  7.3650, -1.5875, -0.7107,  2.6733,
        -3.0372,  1.3310], device='cuda:0', grad_fn=<SelectBackward>)
Model prediction is: tensor([[-2.1875,  0.2578, -1.0516, -3.1591,  7.3650, -1.5875, -0.7107,  2.6733,
         -3.0372,  1.3310]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-3.2894, -5.0968, -6.7662, -5.2753, -5.5357, -4.3087, -8.7793, -5.5937,
         -7.8401]], device='cuda:0') None
best_l after optimization: 42.07672882080078 with beta sum per layer: []
alpha/beta optimization time: 7.135815382003784
initial alpha-CROWN bounds: tensor([[-2.4024, -3.6369, -5.5121, -4.1059, -4.4110, -3.2994, -7.5090, -4.4624,
         -6.7378]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-7.5090, device='cuda:0', grad_fn=<MinBackward1>)
##### [0:24] Tested against 7 ######
Model prediction is: tensor([[-2.1875,  0.2578, -1.0516, -3.1591,  7.3650, -1.5875, -0.7107,  2.6733,
         -3.0372,  1.3310]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 13, 13]) != torch.Size([2, 9, 1, 16, 13, 13]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 5, 5]) != torch.Size([2, 9, 1, 32, 5, 5]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 13, 13])
1 /11 torch.Size([1, 32, 5, 5])
2 /21 torch.Size([1, 100])
best_l after optimization: 7.508679389953613 with beta sum per layer: []
alpha/beta optimization time: 1.757434606552124
alpha-CROWN with fixed intermediate bounds: tensor([[-7.5087]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-7.508679389953613
layer 0 size torch.Size([2704]) unstable 1090
layer 1 size torch.Size([800]) unstable 210
layer 2 size torch.Size([100]) unstable 44
-----------------
# of unstable neurons: 1344
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 13, 13]) pre split depth:  7
batch:  torch.Size([1, 16, 13, 13]) post split depth:  7
splitting decisions: 
split level 0: [2, 6] 
split level 1: [2, 86] 
split level 2: [2, 1] 
split level 3: [2, 99] 
split level 4: [1, 632] 
split level 5: [2, 51] 
split level 6: [2, 89] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 248.97608947753906 with beta sum per layer: [0.0, 13.384486198425293, 147.3798065185547]
alpha/beta optimization time: 0.259768009185791
This batch time : update_bounds func: 0.2805	 prepare: 0.0103	 bound: 0.2601	 transfer: 0.0022	 finalize: 0.0076
Accumulated time: update_bounds func: 0.2805	 prepare: 0.0103	 bound: 0.2601	 transfer: 0.0022	 finalize: 0.0076
batch bounding time:  0.2807023525238037
Current worst splitting domains [lb, ub] (depth):
[-4.77832,   inf] (8), [-4.56525,   inf] (8), [-4.56359,   inf] (8), [-4.43579,   inf] (8), [-4.38213,   inf] (8), [-4.08697,   inf] (8), [-4.01970,   inf] (8), [-4.01097,   inf] (8), [-3.91201,   inf] (8), [-3.89844,   inf] (8), [-3.86507,   inf] (8), [-3.84194,   inf] (8), [-3.82416,   inf] (8), [-3.79319,   inf] (8), [-3.75752,   inf] (8), [-3.75280,   inf] (8), [-3.73380,   inf] (8), [-3.73288,   inf] (8), [-3.69211,   inf] (8), [-3.66222,   inf] (8), 
length of domains: 112
Total time: 0.3440	 pickout: 0.0009	 decision: 0.0418	 get_bound: 0.2963	 add_domain: 0.0050
Current lb:-4.778316497802734
128 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.934487819671631

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([112, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([112, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 631] [2, 36] [2, 36] [1, 631] [2, 36] [2, 56] [2, 56] [2, 36] [1, 631] [1, 631] 
regular batch size: 2*112, diving batch size 1*0
best_l after optimization: 338.001953125 with beta sum per layer: [0.0, 26.159290313720703, 375.97882080078125]
alpha/beta optimization time: 0.2692725658416748
This batch time : update_bounds func: 0.3127	 prepare: 0.0241	 bound: 0.2696	 transfer: 0.0050	 finalize: 0.0135
Accumulated time: update_bounds func: 0.5931	 prepare: 0.0343	 bound: 0.5296	 transfer: 0.0050	 finalize: 0.0211
batch bounding time:  0.31299304962158203
Current worst splitting domains [lb, ub] (depth):
[-4.74794,   inf] (10), [-4.41974,   inf] (10), [-4.37728,   inf] (10), [-4.36462,   inf] (10), [-4.19905,   inf] (10), [-3.91333,   inf] (10), [-3.86654,   inf] (10), [-3.83478,   inf] (10), [-3.83472,   inf] (10), [-3.73614,   inf] (10), [-3.68805,   inf] (10), [-3.67558,   inf] (10), [-3.65632,   inf] (10), [-3.64843,   inf] (10), [-3.64778,   inf] (10), [-3.61201,   inf] (10), [-3.57583,   inf] (10), [-3.53218,   inf] (10), [-3.53155,   inf] (10), [-3.52699,   inf] (10), 
length of domains: 183
Total time: 0.3828	 pickout: 0.0153	 decision: 0.0455	 get_bound: 0.3133	 add_domain: 0.0087
Current lb:-4.7479448318481445
352 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.3191404342651367

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([183, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([183, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 36] [1, 631] [2, 36] [2, 56] [1, 631] [2, 36] [2, 36] [1, 631] [2, 36] [2, 36] 
regular batch size: 2*183, diving batch size 1*0
best_l after optimization: 463.10882568359375 with beta sum per layer: [0.0, 43.603790283203125, 660.2445068359375]
alpha/beta optimization time: 0.29264330863952637
This batch time : update_bounds func: 0.3612	 prepare: 0.0358	 bound: 0.2930	 transfer: 0.0105	 finalize: 0.0211
Accumulated time: update_bounds func: 0.9543	 prepare: 0.0701	 bound: 0.8226	 transfer: 0.0105	 finalize: 0.0422
batch bounding time:  0.3615899085998535
Current worst splitting domains [lb, ub] (depth):
[-4.60033,   inf] (12), [-4.38088,   inf] (12), [-4.23385,   inf] (12), [-4.18880,   inf] (12), [-4.14472,   inf] (12), [-3.81310,   inf] (12), [-3.69498,   inf] (12), [-3.68810,   inf] (12), [-3.64577,   inf] (12), [-3.61218,   inf] (12), [-3.61069,   inf] (12), [-3.56074,   inf] (12), [-3.54284,   inf] (12), [-3.46473,   inf] (12), [-3.45834,   inf] (12), [-3.45586,   inf] (12), [-3.41925,   inf] (12), [-3.35988,   inf] (12), [-3.33980,   inf] (12), [-3.33876,   inf] (12), 
length of domains: 273
Total time: 0.4623	 pickout: 0.0238	 decision: 0.0621	 get_bound: 0.3621	 add_domain: 0.0143
Current lb:-4.600327014923096
718 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.78446102142334

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([273, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([273, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 706] [2, 56] [2, 25] [2, 25] [2, 56] [2, 56] [2, 56] [2, 25] [2, 56] [2, 25] 
regular batch size: 2*273, diving batch size 1*0
best_l after optimization: 663.786865234375 with beta sum per layer: [0.0, 68.48478698730469, 968.9935913085938]
alpha/beta optimization time: 0.32824110984802246
This batch time : update_bounds func: 0.4814	 prepare: 0.0810	 bound: 0.3286	 transfer: 0.0196	 finalize: 0.0508
Accumulated time: update_bounds func: 1.4357	 prepare: 0.1511	 bound: 1.1512	 transfer: 0.0196	 finalize: 0.0930
batch bounding time:  0.482088565826416
Current worst splitting domains [lb, ub] (depth):
[-4.30138,   inf] (14), [-4.26165,   inf] (14), [-4.15665,   inf] (14), [-3.98802,   inf] (14), [-3.94339,   inf] (14), [-3.91085,   inf] (14), [-3.88546,   inf] (14), [-3.69516,   inf] (14), [-3.57793,   inf] (14), [-3.56646,   inf] (14), [-3.49512,   inf] (14), [-3.43172,   inf] (14), [-3.42509,   inf] (14), [-3.42346,   inf] (14), [-3.39401,   inf] (14), [-3.37398,   inf] (14), [-3.33422,   inf] (14), [-3.29652,   inf] (14), [-3.27086,   inf] (14), [-3.26018,   inf] (14), 
length of domains: 445
Total time: 0.6396	 pickout: 0.0353	 decision: 0.0949	 get_bound: 0.4830	 add_domain: 0.0263
Current lb:-4.301376819610596
1264 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.429206609725952

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([445, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([445, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 56] [1, 706] [2, 56] [2, 25] [2, 56] [1, 706] [1, 706] [2, 25] [1, 706] [2, 56] 
regular batch size: 2*445, diving batch size 1*0
best_l after optimization: 949.8004760742188 with beta sum per layer: [0.0, 146.41786193847656, 1713.65673828125]
alpha/beta optimization time: 0.3752481937408447
This batch time : update_bounds func: 0.6094	 prepare: 0.1278	 bound: 0.3756	 transfer: 0.0249	 finalize: 0.0791
Accumulated time: update_bounds func: 2.0451	 prepare: 0.2789	 bound: 1.5268	 transfer: 0.0249	 finalize: 0.1721
batch bounding time:  0.6102950572967529
Current worst splitting domains [lb, ub] (depth):
[-4.17280,   inf] (16), [-4.02383,   inf] (16), [-3.99175,   inf] (16), [-3.86971,   inf] (16), [-3.77838,   inf] (16), [-3.74990,   inf] (16), [-3.66073,   inf] (16), [-3.64027,   inf] (16), [-3.63452,   inf] (16), [-3.58327,   inf] (16), [-3.44821,   inf] (16), [-3.39007,   inf] (16), [-3.38549,   inf] (16), [-3.31675,   inf] (16), [-3.29050,   inf] (16), [-3.25834,   inf] (16), [-3.23737,   inf] (16), [-3.23588,   inf] (16), [-3.22305,   inf] (16), [-3.18831,   inf] (16), 
length of domains: 731
Total time: 0.9522	 pickout: 0.0830	 decision: 0.2136	 get_bound: 0.6117	 add_domain: 0.0439
Current lb:-4.172800064086914
2154 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.388263463973999

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([731, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([731, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 25] [2, 25] [2, 25] [2, 25] [1, 706] [1, 706] [1, 631] [1, 631] [2, 73] [1, 257] 
regular batch size: 2*731, diving batch size 1*0
best_l after optimization: 1323.9609375 with beta sum per layer: [0.0, 299.03509521484375, 3017.95947265625]
alpha/beta optimization time: 0.4843156337738037
This batch time : update_bounds func: 0.8588	 prepare: 0.2112	 bound: 0.4847	 transfer: 0.0289	 finalize: 0.1305
Accumulated time: update_bounds func: 2.9039	 prepare: 0.4901	 bound: 2.0116	 transfer: 0.0289	 finalize: 0.3026
batch bounding time:  0.8601195812225342
Current worst splitting domains [lb, ub] (depth):
[-3.89537,   inf] (18), [-3.74236,   inf] (18), [-3.74023,   inf] (18), [-3.72726,   inf] (18), [-3.59873,   inf] (18), [-3.59461,   inf] (18), [-3.58364,   inf] (18), [-3.56511,   inf] (18), [-3.52606,   inf] (18), [-3.48574,   inf] (18), [-3.48251,   inf] (18), [-3.45466,   inf] (18), [-3.44058,   inf] (18), [-3.38387,   inf] (18), [-3.37538,   inf] (18), [-3.35998,   inf] (18), [-3.29901,   inf] (18), [-3.25062,   inf] (18), [-3.18366,   inf] (18), [-3.16777,   inf] (18), 
length of domains: 1160
Total time: 1.4376	 pickout: 0.1361	 decision: 0.3069	 get_bound: 0.8624	 add_domain: 0.1321
Current lb:-3.8953661918640137
3616 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.837470531463623

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1160, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([1160, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 257] [1, 636] [1, 257] [1, 257] [1, 256] [1, 257] [1, 256] [1, 256] [2, 73] [2, 12] 
regular batch size: 2*1160, diving batch size 1*0
best_l after optimization: 1745.56298828125 with beta sum per layer: [0.018571514636278152, 544.543212890625, 4854.2421875]
alpha/beta optimization time: 0.654315710067749
This batch time : update_bounds func: 1.2581	 prepare: 0.3476	 bound: 0.6548	 transfer: 0.0418	 finalize: 0.2083
Accumulated time: update_bounds func: 4.1620	 prepare: 0.8377	 bound: 2.6664	 transfer: 0.0418	 finalize: 0.5109
batch bounding time:  1.2600560188293457
Current worst splitting domains [lb, ub] (depth):
[-3.83078,   inf] (20), [-3.67442,   inf] (20), [-3.64756,   inf] (20), [-3.54460,   inf] (20), [-3.52866,   inf] (20), [-3.50107,   inf] (20), [-3.49351,   inf] (20), [-3.48257,   inf] (20), [-3.41036,   inf] (20), [-3.36755,   inf] (20), [-3.31870,   inf] (20), [-3.30190,   inf] (20), [-3.26318,   inf] (20), [-3.26070,   inf] (20), [-3.25088,   inf] (20), [-3.20927,   inf] (20), [-3.20653,   inf] (20), [-3.15151,   inf] (20), [-3.14662,   inf] (20), [-3.09744,   inf] (20), 
length of domains: 1720
Total time: 2.0349	 pickout: 0.2191	 decision: 0.4330	 get_bound: 1.2637	 add_domain: 0.1192
Current lb:-3.830780506134033
5936 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.894470691680908

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1720, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([1720, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 256] [1, 256] [1, 256] [1, 256] [1, 256] [1, 636] [1, 257] [1, 257] [1, 257] [1, 631] 
regular batch size: 2*1720, diving batch size 1*0
best_l after optimization: 2398.65625 with beta sum per layer: [0.21096429228782654, 928.0463256835938, 7047.97119140625]
alpha/beta optimization time: 0.8774363994598389
This batch time : update_bounds func: 1.8222	 prepare: 0.5080	 bound: 0.8779	 transfer: 0.0569	 finalize: 0.3711
Accumulated time: update_bounds func: 5.9842	 prepare: 1.3457	 bound: 3.5442	 transfer: 0.0569	 finalize: 0.8820
batch bounding time:  1.8254709243774414
Current worst splitting domains [lb, ub] (depth):
[-3.65890,   inf] (22), [-3.53670,   inf] (22), [-3.47376,   inf] (22), [-3.45995,   inf] (22), [-3.44599,   inf] (22), [-3.43637,   inf] (22), [-3.40490,   inf] (22), [-3.36889,   inf] (22), [-3.36034,   inf] (22), [-3.35676,   inf] (22), [-3.29557,   inf] (22), [-3.26329,   inf] (22), [-3.19634,   inf] (22), [-3.12562,   inf] (22), [-3.11856,   inf] (22), [-3.11400,   inf] (22), [-3.08935,   inf] (22), [-3.08920,   inf] (22), [-3.08913,   inf] (22), [-3.06701,   inf] (22), 
length of domains: 2594
Total time: 3.0371	 pickout: 0.3281	 decision: 0.6896	 get_bound: 1.8309	 add_domain: 0.1885
Current lb:-3.658902168273926
9376 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.969347715377808

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 707] [1, 136] [1, 636] [1, 707] [1, 707] [1, 707] [1, 707] [1, 257] [1, 707] [2, 12] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 3340.010009765625 with beta sum per layer: [0.3701932728290558, 1341.74072265625, 6949.8525390625]
alpha/beta optimization time: 1.0455787181854248
This batch time : update_bounds func: 2.1701	 prepare: 0.6039	 bound: 1.0460	 transfer: 0.0739	 finalize: 0.4355
Accumulated time: update_bounds func: 8.1543	 prepare: 1.9496	 bound: 4.5903	 transfer: 0.0739	 finalize: 1.3175
batch bounding time:  2.1738224029541016
Current worst splitting domains [lb, ub] (depth):
[-3.43768,   inf] (24), [-3.37815,   inf] (24), [-3.36456,   inf] (24), [-3.31830,   inf] (24), [-3.29434,   inf] (24), [-3.29012,   inf] (24), [-3.28204,   inf] (24), [-3.26382,   inf] (24), [-3.25736,   inf] (24), [-3.25273,   inf] (24), [-3.20206,   inf] (24), [-3.18563,   inf] (24), [-3.17410,   inf] (24), [-3.17114,   inf] (24), [-3.14042,   inf] (24), [-3.13284,   inf] (24), [-3.11980,   inf] (24), [-3.07109,   inf] (24), [-3.06856,   inf] (24), [-3.06220,   inf] (24), 
length of domains: 4182
Total time: 3.7684	 pickout: 0.4072	 decision: 0.8173	 get_bound: 2.1804	 add_domain: 0.3635
Current lb:-3.4376821517944336
13472 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.772104263305664

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 636] [1, 636] [1, 636] [2, 58] [1, 707] [1, 136] [1, 256] [1, 136] [2, 58] [2, 12] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 4158.09814453125 with beta sum per layer: [0.4190964698791504, 1420.380859375, 5036.326171875]
alpha/beta optimization time: 1.0421032905578613
This batch time : update_bounds func: 2.2417	 prepare: 0.6143	 bound: 1.0425	 transfer: 0.0802	 finalize: 0.4933
Accumulated time: update_bounds func: 10.3961	 prepare: 2.5639	 bound: 5.6328	 transfer: 0.0802	 finalize: 1.8108
batch bounding time:  2.245422601699829
Current worst splitting domains [lb, ub] (depth):
[-3.26353,   inf] (26), [-3.19620,   inf] (26), [-3.18401,   inf] (26), [-3.17455,   inf] (26), [-3.16481,   inf] (26), [-3.14443,   inf] (26), [-3.13254,   inf] (26), [-3.12705,   inf] (26), [-3.11715,   inf] (26), [-3.06392,   inf] (26), [-3.05573,   inf] (26), [-3.05008,   inf] (26), [-3.04510,   inf] (26), [-3.03498,   inf] (26), [-3.03362,   inf] (26), [-3.03096,   inf] (26), [-2.98683,   inf] (26), [-2.95583,   inf] (26), [-2.93904,   inf] (26), [-2.93011,   inf] (26), 
length of domains: 5974
Total time: 3.8110	 pickout: 0.3985	 decision: 0.8524	 get_bound: 2.2523	 add_domain: 0.3078
Current lb:-3.2635269165039062
17568 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 19.617666482925415

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 58] [2, 58] [1, 136] [2, 58] [2, 58] [1, 636] [2, 12] [2, 12] [1, 256] [2, 12] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 4144.41162109375 with beta sum per layer: [0.3731401264667511, 1475.757568359375, 4393.705078125]
alpha/beta optimization time: 1.0469655990600586
This batch time : update_bounds func: 2.2603	 prepare: 0.6079	 bound: 1.0474	 transfer: 0.0779	 finalize: 0.5162
Accumulated time: update_bounds func: 12.6563	 prepare: 3.1718	 bound: 6.6802	 transfer: 0.0779	 finalize: 2.3270
batch bounding time:  2.2642505168914795
Current worst splitting domains [lb, ub] (depth):
[-3.07937,   inf] (28), [-3.06449,   inf] (28), [-3.05173,   inf] (28), [-3.04632,   inf] (28), [-3.00494,   inf] (28), [-2.99549,   inf] (28), [-2.98261,   inf] (28), [-2.97683,   inf] (28), [-2.97475,   inf] (28), [-2.96653,   inf] (28), [-2.95664,   inf] (28), [-2.94071,   inf] (28), [-2.93973,   inf] (28), [-2.92355,   inf] (28), [-2.90632,   inf] (28), [-2.90481,   inf] (28), [-2.90295,   inf] (28), [-2.88105,   inf] (28), [-2.87544,   inf] (28), [-2.85556,   inf] (28), 
length of domains: 7559
Total time: 3.9081	 pickout: 0.3976	 decision: 0.9370	 get_bound: 2.2711	 add_domain: 0.3025
Current lb:-3.0793747901916504
21664 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 23.56281876564026

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 12] [2, 73] [2, 73] [1, 707] [2, 12] [2, 58] [2, 12] [1, 707] [2, 58] [2, 73] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 4517.0341796875 with beta sum per layer: [0.6604062914848328, 1388.107666015625, 3933.001708984375]
alpha/beta optimization time: 1.0399038791656494
This batch time : update_bounds func: 2.2752	 prepare: 0.6148	 bound: 1.0403	 transfer: 0.0784	 finalize: 0.5314
Accumulated time: update_bounds func: 14.9315	 prepare: 3.7866	 bound: 7.7205	 transfer: 0.0784	 finalize: 2.8584
batch bounding time:  2.278982639312744
Current worst splitting domains [lb, ub] (depth):
[-3.00424,   inf] (30), [-2.92971,   inf] (30), [-2.91859,   inf] (30), [-2.90906,   inf] (30), [-2.90013,   inf] (30), [-2.86190,   inf] (30), [-2.85925,   inf] (30), [-2.82879,   inf] (30), [-2.82660,   inf] (30), [-2.82014,   inf] (30), [-2.80246,   inf] (30), [-2.79779,   inf] (30), [-2.79245,   inf] (30), [-2.79228,   inf] (30), [-2.79096,   inf] (30), [-2.77992,   inf] (30), [-2.77647,   inf] (30), [-2.76677,   inf] (30), [-2.76263,   inf] (30), [-2.75707,   inf] (30), 
length of domains: 9256
Total time: 4.0290	 pickout: 0.3989	 decision: 0.8308	 get_bound: 2.2858	 add_domain: 0.5136
Current lb:-3.004241943359375
25760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 27.629714488983154

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 73] [1, 136] [2, 58] [2, 73] [2, 58] [2, 73] [2, 58] [1, 136] [2, 58] [1, 136] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 5118.4208984375 with beta sum per layer: [0.5863593816757202, 1436.304443359375, 3304.978759765625]
alpha/beta optimization time: 1.035679578781128
This batch time : update_bounds func: 2.3336	 prepare: 0.6170	 bound: 1.0361	 transfer: 0.0786	 finalize: 0.5910
Accumulated time: update_bounds func: 17.2651	 prepare: 4.4036	 bound: 8.7566	 transfer: 0.0786	 finalize: 3.4494
batch bounding time:  2.3376822471618652
Current worst splitting domains [lb, ub] (depth):
[-2.87518,   inf] (32), [-2.77382,   inf] (32), [-2.73970,   inf] (32), [-2.71462,   inf] (32), [-2.71250,   inf] (32), [-2.68779,   inf] (32), [-2.67799,   inf] (32), [-2.67707,   inf] (32), [-2.66848,   inf] (32), [-2.66487,   inf] (32), [-2.66100,   inf] (32), [-2.64869,   inf] (32), [-2.64712,   inf] (32), [-2.64529,   inf] (32), [-2.64225,   inf] (32), [-2.62955,   inf] (32), [-2.62695,   inf] (32), [-2.62359,   inf] (32), [-2.61946,   inf] (32), [-2.61776,   inf] (32), 
length of domains: 11146
Total time: 3.9881	 pickout: 0.4176	 decision: 0.8718	 get_bound: 2.3448	 add_domain: 0.3538
Current lb:-2.8751840591430664
29856 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 31.655240297317505

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 136] [1, 707] [2, 73] [1, 637] [2, 63] [1, 708] [2, 73] [2, 63] [1, 258] [1, 702] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 5424.5537109375 with beta sum per layer: [0.4978732466697693, 1425.478759765625, 2924.92626953125]
alpha/beta optimization time: 1.0371785163879395
This batch time : update_bounds func: 2.3751	 prepare: 0.6146	 bound: 1.0376	 transfer: 0.0783	 finalize: 0.6308
Accumulated time: update_bounds func: 19.6403	 prepare: 5.0182	 bound: 9.7943	 transfer: 0.0783	 finalize: 4.0801
batch bounding time:  2.3790690898895264
Current worst splitting domains [lb, ub] (depth):
[-2.68040,   inf] (34), [-2.61411,   inf] (34), [-2.60989,   inf] (34), [-2.60371,   inf] (34), [-2.57839,   inf] (34), [-2.56773,   inf] (34), [-2.56536,   inf] (34), [-2.55408,   inf] (34), [-2.55090,   inf] (34), [-2.53597,   inf] (34), [-2.53369,   inf] (34), [-2.53334,   inf] (34), [-2.52703,   inf] (34), [-2.52078,   inf] (34), [-2.51863,   inf] (34), [-2.51817,   inf] (34), [-2.50105,   inf] (34), [-2.49793,   inf] (34), [-2.49174,   inf] (34), [-2.48859,   inf] (34), 
length of domains: 13066
Total time: 4.0767	 pickout: 0.4072	 decision: 0.9164	 get_bound: 2.3861	 add_domain: 0.3669
Current lb:-2.680396318435669
33952 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 35.76984000205994

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 702] [1, 258] [1, 702] [1, 702] [2, 63] [1, 708] [2, 63] [2, 63] [1, 708] [2, 63] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 5835.8271484375 with beta sum per layer: [1.1576910018920898, 1161.7869873046875, 2520.27880859375]
alpha/beta optimization time: 1.0353367328643799
This batch time : update_bounds func: 2.3973	 prepare: 0.6165	 bound: 1.0358	 transfer: 0.0775	 finalize: 0.6560
Accumulated time: update_bounds func: 22.0376	 prepare: 5.6347	 bound: 10.8300	 transfer: 0.0775	 finalize: 4.7361
batch bounding time:  2.4018850326538086
Current worst splitting domains [lb, ub] (depth):
[-2.58964,   inf] (36), [-2.51742,   inf] (36), [-2.51422,   inf] (36), [-2.49967,   inf] (36), [-2.49352,   inf] (36), [-2.48268,   inf] (36), [-2.45560,   inf] (36), [-2.43978,   inf] (36), [-2.43218,   inf] (36), [-2.41863,   inf] (36), [-2.41780,   inf] (36), [-2.41362,   inf] (36), [-2.40467,   inf] (36), [-2.40123,   inf] (36), [-2.39346,   inf] (36), [-2.39049,   inf] (36), [-2.38946,   inf] (36), [-2.37796,   inf] (36), [-2.37509,   inf] (36), [-2.36346,   inf] (36), 
length of domains: 15042
Total time: 4.1411	 pickout: 0.4065	 decision: 0.9403	 get_bound: 2.4093	 add_domain: 0.3849
Current lb:-2.589637279510498
38048 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 39.94936776161194

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 63] [2, 63] [2, 63] [2, 63] [1, 702] [2, 63] [1, 258] [2, 63] [1, 258] [1, 708] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 5854.04736328125 with beta sum per layer: [0.5730749368667603, 1235.0098876953125, 2226.51611328125]
alpha/beta optimization time: 1.03891921043396
This batch time : update_bounds func: 2.1295	 prepare: 0.6210	 bound: 1.0393	 transfer: 0.0798	 finalize: 0.3778
Accumulated time: update_bounds func: 24.1671	 prepare: 6.2557	 bound: 11.8694	 transfer: 0.0798	 finalize: 5.1139
batch bounding time:  2.1333653926849365
Current worst splitting domains [lb, ub] (depth):
[-2.44455,   inf] (38), [-2.38214,   inf] (38), [-2.37000,   inf] (38), [-2.36832,   inf] (38), [-2.35289,   inf] (38), [-2.33985,   inf] (38), [-2.33903,   inf] (38), [-2.33730,   inf] (38), [-2.31965,   inf] (38), [-2.31232,   inf] (38), [-2.31034,   inf] (38), [-2.30378,   inf] (38), [-2.29527,   inf] (38), [-2.28031,   inf] (38), [-2.27900,   inf] (38), [-2.27077,   inf] (38), [-2.26974,   inf] (38), [-2.26881,   inf] (38), [-2.26524,   inf] (38), [-2.25843,   inf] (38), 
length of domains: 17020
Total time: 3.9493	 pickout: 0.4057	 decision: 1.0003	 get_bound: 2.1403	 add_domain: 0.4030
Current lb:-2.444549083709717
42144 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 43.93774080276489

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 31] [1, 258] [1, 31] [1, 136] [1, 636] [1, 636] [1, 31] [1, 636] [1, 31] [1, 258] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 5918.9296875 with beta sum per layer: [0.2895243763923645, 1254.0859375, 2034.42236328125]
alpha/beta optimization time: 1.021822452545166
This batch time : update_bounds func: 2.2620	 prepare: 0.4132	 bound: 1.0222	 transfer: 0.0891	 finalize: 0.7260
Accumulated time: update_bounds func: 26.4292	 prepare: 6.6689	 bound: 12.8916	 transfer: 0.0891	 finalize: 5.8399
batch bounding time:  2.265758752822876
Current worst splitting domains [lb, ub] (depth):
[-2.33681,   inf] (40), [-2.26594,   inf] (40), [-2.25625,   inf] (40), [-2.23964,   inf] (40), [-2.23783,   inf] (40), [-2.22429,   inf] (40), [-2.20992,   inf] (40), [-2.20302,   inf] (40), [-2.19689,   inf] (40), [-2.17575,   inf] (40), [-2.17334,   inf] (40), [-2.16987,   inf] (40), [-2.16947,   inf] (40), [-2.16935,   inf] (40), [-2.16622,   inf] (40), [-2.15631,   inf] (40), [-2.15478,   inf] (40), [-2.15214,   inf] (40), [-2.15162,   inf] (40), [-2.15108,   inf] (40), 
length of domains: 19035
Total time: 4.1525	 pickout: 0.3813	 decision: 1.1075	 get_bound: 2.2722	 add_domain: 0.3915
Current lb:-2.3368072509765625
46240 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 48.13386940956116

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 708] [1, 637] [1, 708] [1, 258] [1, 31] [1, 708] [1, 258] [1, 637] [1, 136] [1, 708] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 5648.6103515625 with beta sum per layer: [0.18099445104599, 1406.6298828125, 1854.373046875]
alpha/beta optimization time: 1.0265145301818848
This batch time : update_bounds func: 1.8260	 prepare: 0.4327	 bound: 1.0270	 transfer: 0.0800	 finalize: 0.2752
Accumulated time: update_bounds func: 28.2552	 prepare: 7.1016	 bound: 13.9186	 transfer: 0.0800	 finalize: 6.1150
batch bounding time:  1.830033302307129
Current worst splitting domains [lb, ub] (depth):
[-2.24336,   inf] (42), [-2.20435,   inf] (42), [-2.18964,   inf] (42), [-2.15177,   inf] (42), [-2.14028,   inf] (42), [-2.13988,   inf] (42), [-2.12261,   inf] (42), [-2.11575,   inf] (42), [-2.11186,   inf] (42), [-2.11018,   inf] (42), [-2.10855,   inf] (42), [-2.10673,   inf] (42), [-2.10071,   inf] (42), [-2.09394,   inf] (42), [-2.09340,   inf] (42), [-2.09143,   inf] (42), [-2.09116,   inf] (42), [-2.08229,   inf] (42), [-2.07468,   inf] (42), [-2.07420,   inf] (42), 
length of domains: 21025
Total time: 3.5157	 pickout: 0.2987	 decision: 0.9700	 get_bound: 1.8384	 add_domain: 0.4086
Current lb:-2.2433602809906006
50336 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 51.69832253456116

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 258] [1, 636] [1, 258] [1, 702] [1, 258] [1, 638] [1, 258] [1, 258] [1, 638] [1, 636] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 5723.65625 with beta sum per layer: [0.3409370481967926, 1169.821533203125, 1678.506591796875]
alpha/beta optimization time: 1.0191004276275635
This batch time : update_bounds func: 1.8245	 prepare: 0.4354	 bound: 1.0195	 transfer: 0.0784	 finalize: 0.2780
Accumulated time: update_bounds func: 30.0797	 prepare: 7.5369	 bound: 14.9380	 transfer: 0.0784	 finalize: 6.3931
batch bounding time:  1.8282270431518555
Current worst splitting domains [lb, ub] (depth):
[-2.12634,   inf] (44), [-2.07533,   inf] (44), [-2.06352,   inf] (44), [-2.05594,   inf] (44), [-2.03587,   inf] (44), [-2.03537,   inf] (44), [-2.03323,   inf] (44), [-2.03239,   inf] (44), [-2.02098,   inf] (44), [-2.01913,   inf] (44), [-2.01803,   inf] (44), [-2.00725,   inf] (44), [-2.00071,   inf] (44), [-1.99976,   inf] (44), [-1.99864,   inf] (44), [-1.99347,   inf] (44), [-1.99201,   inf] (44), [-1.99086,   inf] (44), [-1.98958,   inf] (44), [-1.98923,   inf] (44), 
length of domains: 23037
Total time: 4.0803	 pickout: 0.3008	 decision: 1.0153	 get_bound: 1.8350	 add_domain: 0.9293
Current lb:-2.1263415813446045
54432 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 55.82316303253174

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 637] [1, 637] [2, 9] [1, 638] [1, 637] [1, 637] [1, 636] [1, 638] [2, 9] [1, 708] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 5588.490234375 with beta sum per layer: [0.2904765009880066, 1175.2752685546875, 1529.382568359375]
alpha/beta optimization time: 1.0154790878295898
This batch time : update_bounds func: 2.2765	 prepare: 0.4213	 bound: 1.0158	 transfer: 0.0782	 finalize: 0.7490
Accumulated time: update_bounds func: 32.3562	 prepare: 7.9583	 bound: 15.9539	 transfer: 0.0782	 finalize: 7.1421
batch bounding time:  2.2804245948791504
Current worst splitting domains [lb, ub] (depth):
[-2.04881,   inf] (46), [-2.00279,   inf] (46), [-1.97880,   inf] (46), [-1.97655,   inf] (46), [-1.97466,   inf] (46), [-1.96153,   inf] (46), [-1.95921,   inf] (46), [-1.93801,   inf] (46), [-1.93359,   inf] (46), [-1.93233,   inf] (46), [-1.93225,   inf] (46), [-1.91961,   inf] (46), [-1.91619,   inf] (46), [-1.91413,   inf] (46), [-1.91320,   inf] (46), [-1.90891,   inf] (46), [-1.90806,   inf] (46), [-1.90207,   inf] (46), [-1.90153,   inf] (46), [-1.88989,   inf] (46), 
length of domains: 25039
Total time: 3.5682	 pickout: 0.3051	 decision: 0.5520	 get_bound: 2.2871	 add_domain: 0.4241
Current lb:-2.0488080978393555
58528 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 59.445329666137695

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 9] [2, 9] [2, 9] [1, 638] [1, 638] [1, 702] [1, 702] [2, 9] [1, 638] [1, 638] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 5452.38671875 with beta sum per layer: [0.32143470644950867, 1093.7615966796875, 1536.0452880859375]
alpha/beta optimization time: 1.0141472816467285
This batch time : update_bounds func: 2.3555	 prepare: 0.4281	 bound: 1.0145	 transfer: 0.0790	 finalize: 0.8218
Accumulated time: update_bounds func: 34.7116	 prepare: 8.3863	 bound: 16.9684	 transfer: 0.0790	 finalize: 7.9638
batch bounding time:  2.3590612411499023
Current worst splitting domains [lb, ub] (depth):
[-1.94595,   inf] (48), [-1.90521,   inf] (48), [-1.89947,   inf] (48), [-1.89386,   inf] (48), [-1.87742,   inf] (48), [-1.86921,   inf] (48), [-1.85654,   inf] (48), [-1.85456,   inf] (48), [-1.85175,   inf] (48), [-1.83337,   inf] (48), [-1.82858,   inf] (48), [-1.82489,   inf] (48), [-1.82029,   inf] (48), [-1.81758,   inf] (48), [-1.81534,   inf] (48), [-1.81320,   inf] (48), [-1.81304,   inf] (48), [-1.81101,   inf] (48), [-1.80788,   inf] (48), [-1.80648,   inf] (48), 
length of domains: 27036
Total time: 3.6664	 pickout: 0.3064	 decision: 0.5641	 get_bound: 2.3657	 add_domain: 0.4301
Current lb:-1.9459489583969116
62624 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 63.1561005115509

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 17] [2, 17] [2, 17] [2, 9] [2, 17] [2, 17] [2, 17] [2, 17] [2, 17] [1, 638] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 5189.40283203125 with beta sum per layer: [0.27838850021362305, 937.2591552734375, 1894.6925048828125]
alpha/beta optimization time: 1.0183310508728027
This batch time : update_bounds func: 2.3702	 prepare: 0.4199	 bound: 1.0187	 transfer: 0.0778	 finalize: 0.2679
Accumulated time: update_bounds func: 37.0819	 prepare: 8.8063	 bound: 17.9871	 transfer: 0.0778	 finalize: 8.2318
batch bounding time:  2.3740458488464355
Current worst splitting domains [lb, ub] (depth):
[-1.86958,   inf] (50), [-1.83094,   inf] (50), [-1.82489,   inf] (50), [-1.80975,   inf] (50), [-1.79004,   inf] (50), [-1.78826,   inf] (50), [-1.78744,   inf] (50), [-1.78691,   inf] (50), [-1.77852,   inf] (50), [-1.76596,   inf] (50), [-1.76453,   inf] (50), [-1.74657,   inf] (50), [-1.74506,   inf] (50), [-1.74352,   inf] (50), [-1.74316,   inf] (50), [-1.74311,   inf] (50), [-1.74307,   inf] (50), [-1.74239,   inf] (50), [-1.74063,   inf] (50), [-1.74049,   inf] (50), 
length of domains: 29045
Total time: 3.6995	 pickout: 0.3176	 decision: 0.5614	 get_bound: 2.3808	 add_domain: 0.4397
Current lb:-1.8695828914642334
66720 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 66.90120673179626

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 638] [1, 638] [2, 9] [1, 31] [2, 9] [2, 17] [2, 9] [1, 31] [2, 9] [2, 97] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 5082.90673828125 with beta sum per layer: [0.46885284781455994, 1009.859619140625, 1904.68017578125]
alpha/beta optimization time: 1.0158584117889404
This batch time : update_bounds func: 1.7982	 prepare: 0.4204	 bound: 1.0162	 transfer: 0.0779	 finalize: 0.2717
Accumulated time: update_bounds func: 38.8801	 prepare: 9.2266	 bound: 19.0033	 transfer: 0.0779	 finalize: 8.5034
batch bounding time:  1.8021020889282227
Current worst splitting domains [lb, ub] (depth):
[-1.78368,   inf] (52), [-1.75789,   inf] (52), [-1.72024,   inf] (52), [-1.71971,   inf] (52), [-1.71202,   inf] (52), [-1.70286,   inf] (52), [-1.68388,   inf] (52), [-1.68223,   inf] (52), [-1.67914,   inf] (52), [-1.67662,   inf] (52), [-1.67354,   inf] (52), [-1.67123,   inf] (52), [-1.66732,   inf] (52), [-1.65671,   inf] (52), [-1.65372,   inf] (52), [-1.65011,   inf] (52), [-1.64758,   inf] (52), [-1.64556,   inf] (52), [-1.64474,   inf] (52), [-1.64285,   inf] (52), 
length of domains: 31025
Total time: 3.7380	 pickout: 0.3099	 decision: 1.1795	 get_bound: 1.8091	 add_domain: 0.4396
Current lb:-1.7836796045303345
70816 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 70.68875002861023

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 97] [2, 97] [2, 97] [2, 97] [2, 97] [2, 70] [2, 70] [2, 70] [2, 97] [2, 97] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 4674.8759765625 with beta sum per layer: [0.646353542804718, 1052.7947998046875, 2126.7890625]
alpha/beta optimization time: 1.0191709995269775
This batch time : update_bounds func: 2.4849	 prepare: 0.4346	 bound: 1.0195	 transfer: 0.0777	 finalize: 0.2837
Accumulated time: update_bounds func: 41.3650	 prepare: 9.6612	 bound: 20.0228	 transfer: 0.0777	 finalize: 8.7871
batch bounding time:  2.4899544715881348
Current worst splitting domains [lb, ub] (depth):
[-1.69309,   inf] (54), [-1.66377,   inf] (54), [-1.63082,   inf] (54), [-1.63026,   inf] (54), [-1.62993,   inf] (54), [-1.62429,   inf] (54), [-1.61003,   inf] (54), [-1.60424,   inf] (54), [-1.59721,   inf] (54), [-1.59211,   inf] (54), [-1.58717,   inf] (54), [-1.58451,   inf] (54), [-1.58141,   inf] (54), [-1.57813,   inf] (54), [-1.57384,   inf] (54), [-1.57164,   inf] (54), [-1.56901,   inf] (54), [-1.56856,   inf] (54), [-1.56321,   inf] (54), [-1.56320,   inf] (54), 
length of domains: 32977
Total time: 3.8369	 pickout: 0.3202	 decision: 0.5681	 get_bound: 2.4988	 add_domain: 0.4498
Current lb:-1.6930853128433228
74912 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 74.5845103263855

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 70] [2, 70] [2, 70] [2, 32] [2, 70] [2, 70] [2, 32] [2, 97] [2, 32] [2, 32] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 4635.4912109375 with beta sum per layer: [0.3658143877983093, 1128.295654296875, 2210.490234375]
alpha/beta optimization time: 1.0154056549072266
This batch time : update_bounds func: 2.5404	 prepare: 0.4237	 bound: 1.0158	 transfer: 0.0781	 finalize: 1.0101
Accumulated time: update_bounds func: 43.9054	 prepare: 10.0849	 bound: 21.0386	 transfer: 0.0781	 finalize: 9.7972
batch bounding time:  2.5443150997161865
Current worst splitting domains [lb, ub] (depth):
[-1.61885,   inf] (56), [-1.58885,   inf] (56), [-1.57244,   inf] (56), [-1.56062,   inf] (56), [-1.55323,   inf] (56), [-1.55186,   inf] (56), [-1.54886,   inf] (56), [-1.54113,   inf] (56), [-1.52882,   inf] (56), [-1.51697,   inf] (56), [-1.51207,   inf] (56), [-1.50919,   inf] (56), [-1.50760,   inf] (56), [-1.50488,   inf] (56), [-1.50143,   inf] (56), [-1.48829,   inf] (56), [-1.48564,   inf] (56), [-1.48481,   inf] (56), [-1.48113,   inf] (56), [-1.47933,   inf] (56), 
length of domains: 34907
Total time: 3.8875	 pickout: 0.3274	 decision: 0.5720	 get_bound: 2.5513	 add_domain: 0.4367
Current lb:-1.6188459396362305
79008 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 78.5236406326294

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 32] [2, 32] [2, 47] [2, 32] [2, 32] [2, 47] [2, 32] [2, 47] [2, 47] [2, 32] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 4502.4462890625 with beta sum per layer: [0.6557812690734863, 1170.449462890625, 2235.330078125]
alpha/beta optimization time: 1.0148165225982666
This batch time : update_bounds func: 2.5685	 prepare: 0.4283	 bound: 1.0152	 transfer: 0.0776	 finalize: 1.0338
Accumulated time: update_bounds func: 46.4740	 prepare: 10.5132	 bound: 22.0538	 transfer: 0.0776	 finalize: 10.8310
batch bounding time:  2.572490930557251
Current worst splitting domains [lb, ub] (depth):
[-1.56228,   inf] (58), [-1.53363,   inf] (58), [-1.52212,   inf] (58), [-1.49900,   inf] (58), [-1.49701,   inf] (58), [-1.49451,   inf] (58), [-1.49121,   inf] (58), [-1.48957,   inf] (58), [-1.47292,   inf] (58), [-1.46126,   inf] (58), [-1.45641,   inf] (58), [-1.45303,   inf] (58), [-1.45028,   inf] (58), [-1.45019,   inf] (58), [-1.44865,   inf] (58), [-1.43298,   inf] (58), [-1.42593,   inf] (58), [-1.42532,   inf] (58), [-1.42509,   inf] (58), [-1.42351,   inf] (58), 
length of domains: 36795
Total time: 3.9127	 pickout: 0.3207	 decision: 0.5685	 get_bound: 2.5795	 add_domain: 0.4439
Current lb:-1.5622835159301758
83104 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 82.49386167526245

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 47] [2, 47] [1, 33] [2, 97] [2, 47] [2, 47] [2, 47] [1, 33] [1, 702] [2, 32] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 4436.6005859375 with beta sum per layer: [0.5858888030052185, 1281.6845703125, 2311.796875]
alpha/beta optimization time: 1.0163965225219727
This batch time : update_bounds func: 1.8075	 prepare: 0.4260	 bound: 1.0168	 transfer: 0.0776	 finalize: 0.2731
Accumulated time: update_bounds func: 48.2814	 prepare: 10.9392	 bound: 23.0705	 transfer: 0.0776	 finalize: 11.1041
batch bounding time:  1.811424970626831
Current worst splitting domains [lb, ub] (depth):
[-1.51724,   inf] (60), [-1.49436,   inf] (60), [-1.49046,   inf] (60), [-1.46202,   inf] (60), [-1.45205,   inf] (60), [-1.44662,   inf] (60), [-1.44622,   inf] (60), [-1.42683,   inf] (60), [-1.41927,   inf] (60), [-1.41234,   inf] (60), [-1.40595,   inf] (60), [-1.40573,   inf] (60), [-1.40309,   inf] (60), [-1.40308,   inf] (60), [-1.39636,   inf] (60), [-1.39145,   inf] (60), [-1.39020,   inf] (60), [-1.38862,   inf] (60), [-1.38410,   inf] (60), [-1.38297,   inf] (60), 
length of domains: 38691
Total time: 4.0112	 pickout: 0.3188	 decision: 0.5776	 get_bound: 1.8184	 add_domain: 1.2964
Current lb:-1.5172390937805176
87200 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 86.55788064002991

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 32] [2, 97] [1, 32] [2, 97] [1, 32] [1, 32] [1, 32] [2, 97] [2, 97] [1, 32] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 4396.27685546875 with beta sum per layer: [0.6252394318580627, 1200.2210693359375, 2378.649169921875]
alpha/beta optimization time: 1.0183069705963135
This batch time : update_bounds func: 1.8035	 prepare: 0.4220	 bound: 1.0187	 transfer: 0.0763	 finalize: 0.2732
Accumulated time: update_bounds func: 50.0849	 prepare: 11.3612	 bound: 24.0892	 transfer: 0.0763	 finalize: 11.3773
batch bounding time:  1.8076627254486084
Current worst splitting domains [lb, ub] (depth):
[-1.45684,   inf] (62), [-1.43482,   inf] (62), [-1.42175,   inf] (62), [-1.40178,   inf] (62), [-1.38944,   inf] (62), [-1.38078,   inf] (62), [-1.37972,   inf] (62), [-1.37867,   inf] (62), [-1.37078,   inf] (62), [-1.36901,   inf] (62), [-1.35889,   inf] (62), [-1.35672,   inf] (62), [-1.35141,   inf] (62), [-1.34379,   inf] (62), [-1.34319,   inf] (44), [-1.34169,   inf] (44), [-1.34112,   inf] (44), [-1.33991,   inf] (40), [-1.33982,   inf] (48), [-1.33940,   inf] (42), 
length of domains: 40599
Total time: 3.1446	 pickout: 0.3188	 decision: 0.5764	 get_bound: 1.8149	 add_domain: 0.4345
Current lb:-1.456839919090271
91296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 89.75509834289551

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 33] [1, 33] [1, 33] [1, 32] [1, 33] [1, 33] [1, 33] [1, 32] [1, 33] [2, 65] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 4307.3896484375 with beta sum per layer: [0.6441598534584045, 1173.8883056640625, 2400.6015625]
alpha/beta optimization time: 1.015899419784546
This batch time : update_bounds func: 1.7963	 prepare: 0.4184	 bound: 1.0163	 transfer: 0.0772	 finalize: 0.2708
Accumulated time: update_bounds func: 51.8812	 prepare: 11.7796	 bound: 25.1055	 transfer: 0.0772	 finalize: 11.6481
batch bounding time:  1.8001549243927002
Current worst splitting domains [lb, ub] (depth):
[-1.42132,   inf] (64), [-1.40364,   inf] (64), [-1.39375,   inf] (64), [-1.37353,   inf] (64), [-1.35407,   inf] (64), [-1.35216,   inf] (64), [-1.34866,   inf] (64), [-1.34350,   inf] (64), [-1.34267,   inf] (64), [-1.32657,   inf] (44), [-1.32524,   inf] (44), [-1.32352,   inf] (64), [-1.32325,   inf] (64), [-1.32282,   inf] (44), [-1.32270,   inf] (46), [-1.31976,   inf] (44), [-1.31975,   inf] (40), [-1.31973,   inf] (38), [-1.31973,   inf] (48), [-1.31972,   inf] (44), 
length of domains: 42486
Total time: 4.0107	 pickout: 0.3188	 decision: 1.4499	 get_bound: 1.8070	 add_domain: 0.4350
Current lb:-1.421316146850586
95392 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 93.8187358379364

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 711] [1, 711] [2, 65] [2, 65] [2, 65] [2, 65] [1, 711] [1, 142] [1, 711] [1, 258] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 4245.521484375 with beta sum per layer: [0.9583175778388977, 1296.4794921875, 2382.852294921875]
alpha/beta optimization time: 1.0162177085876465
This batch time : update_bounds func: 2.7694	 prepare: 0.4279	 bound: 1.0166	 transfer: 0.0772	 finalize: 1.2335
Accumulated time: update_bounds func: 54.6506	 prepare: 12.2075	 bound: 26.1221	 transfer: 0.0772	 finalize: 12.8816
batch bounding time:  2.7734458446502686
Current worst splitting domains [lb, ub] (depth):
[-1.32281,   inf] (66), [-1.31221,   inf] (46), [-1.30883,   inf] (36), [-1.30593,   inf] (40), [-1.30593,   inf] (58), [-1.30593,   inf] (46), [-1.30592,   inf] (50), [-1.30590,   inf] (46), [-1.30590,   inf] (44), [-1.30587,   inf] (48), [-1.30587,   inf] (36), [-1.30586,   inf] (50), [-1.30586,   inf] (42), [-1.30585,   inf] (44), [-1.30583,   inf] (38), [-1.30582,   inf] (48), [-1.30580,   inf] (38), [-1.30580,   inf] (54), [-1.30580,   inf] (54), [-1.30580,   inf] (50), 
length of domains: 44360
Total time: 4.1143	 pickout: 0.3172	 decision: 0.5820	 get_bound: 2.7805	 add_domain: 0.4345
Current lb:-1.3228135108947754
99488 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 97.99677920341492

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 142] [1, 638] [1, 257] [1, 637] [2, 32] [2, 17] [2, 17] [1, 31] [1, 258] [1, 638] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 4224.75732421875 with beta sum per layer: [0.8193012475967407, 1272.800048828125, 2407.7197265625]
alpha/beta optimization time: 1.0171318054199219
This batch time : update_bounds func: 1.8265	 prepare: 0.4311	 bound: 1.0175	 transfer: 0.0761	 finalize: 0.2858
Accumulated time: update_bounds func: 56.4771	 prepare: 12.6386	 bound: 27.1396	 transfer: 0.0761	 finalize: 13.1674
batch bounding time:  1.8303465843200684
Current worst splitting domains [lb, ub] (depth):
[-1.29679,   inf] (46), [-1.29669,   inf] (44), [-1.29604,   inf] (44), [-1.29241,   inf] (52), [-1.29241,   inf] (50), [-1.29241,   inf] (64), [-1.29241,   inf] (48), [-1.29241,   inf] (52), [-1.29239,   inf] (40), [-1.29239,   inf] (48), [-1.29238,   inf] (54), [-1.29238,   inf] (38), [-1.29238,   inf] (46), [-1.29236,   inf] (52), [-1.29235,   inf] (42), [-1.29232,   inf] (38), [-1.29232,   inf] (52), [-1.29232,   inf] (40), [-1.29231,   inf] (50), [-1.29231,   inf] (48), 
length of domains: 46229
Total time: 3.1762	 pickout: 0.3192	 decision: 0.5839	 get_bound: 1.8374	 add_domain: 0.4357
Current lb:-1.2967898845672607
103584 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 101.23262357711792

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 638] [2, 63] [1, 708] [2, 97] [2, 17] [0, 2254] [2, 17] [2, 70] [1, 708] [2, 17] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 4151.7177734375 with beta sum per layer: [0.8288119435310364, 1272.104248046875, 2440.99560546875]
alpha/beta optimization time: 1.01631760597229
This batch time : update_bounds func: 1.8078	 prepare: 0.4220	 bound: 1.0167	 transfer: 0.0763	 finalize: 0.2784
Accumulated time: update_bounds func: 58.2848	 prepare: 13.0605	 bound: 28.1562	 transfer: 0.0763	 finalize: 13.4457
batch bounding time:  1.8119144439697266
Current worst splitting domains [lb, ub] (depth):
[-1.27990,   inf] (48), [-1.27988,   inf] (50), [-1.27987,   inf] (50), [-1.27987,   inf] (34), [-1.27986,   inf] (46), [-1.27986,   inf] (46), [-1.27986,   inf] (52), [-1.27985,   inf] (46), [-1.27985,   inf] (34), [-1.27985,   inf] (54), [-1.27985,   inf] (42), [-1.27984,   inf] (46), [-1.27984,   inf] (46), [-1.27984,   inf] (46), [-1.27983,   inf] (40), [-1.27983,   inf] (46), [-1.27982,   inf] (42), [-1.27982,   inf] (44), [-1.27982,   inf] (48), [-1.27981,   inf] (46), 
length of domains: 48101
Total time: 4.2373	 pickout: 0.3287	 decision: 1.6459	 get_bound: 1.8202	 add_domain: 0.4426
Current lb:-1.2799030542373657
107680 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 105.52513599395752

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 97] [2, 17] [2, 9] [1, 258] [2, 17] [1, 258] [2, 97] [2, 9] [1, 142] [2, 97] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 4126.29248046875 with beta sum per layer: [0.9690330028533936, 1285.7467041015625, 2445.83349609375]
alpha/beta optimization time: 1.014983892440796
This batch time : update_bounds func: 2.9084	 prepare: 0.4236	 bound: 1.0153	 transfer: 0.0769	 finalize: 1.3784
Accumulated time: update_bounds func: 61.1933	 prepare: 13.4841	 bound: 29.1716	 transfer: 0.0769	 finalize: 14.8241
batch bounding time:  2.9124412536621094
Current worst splitting domains [lb, ub] (depth):
[-1.27093,   inf] (42), [-1.27072,   inf] (46), [-1.27008,   inf] (48), [-1.26881,   inf] (44), [-1.26810,   inf] (42), [-1.26806,   inf] (48), [-1.26806,   inf] (44), [-1.26806,   inf] (34), [-1.26805,   inf] (46), [-1.26805,   inf] (58), [-1.26804,   inf] (52), [-1.26804,   inf] (46), [-1.26803,   inf] (38), [-1.26802,   inf] (50), [-1.26800,   inf] (52), [-1.26799,   inf] (48), [-1.26798,   inf] (44), [-1.26796,   inf] (44), [-1.26796,   inf] (56), [-1.26795,   inf] (48), 
length of domains: 49985
Total time: 4.2720	 pickout: 0.3282	 decision: 0.5821	 get_bound: 2.9197	 add_domain: 0.4420
Current lb:-1.270927906036377
111776 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 109.85438394546509

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 708] [0, 2254] [0, 2254] [1, 258] [1, 258] [1, 638] [2, 9] [1, 258] [1, 708] [2, 70] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 4077.849853515625 with beta sum per layer: [0.8805005550384521, 1310.834716796875, 2458.13818359375]
alpha/beta optimization time: 1.015854835510254
This batch time : update_bounds func: 1.8126	 prepare: 0.4259	 bound: 1.0162	 transfer: 0.0781	 finalize: 0.2784
Accumulated time: update_bounds func: 63.0059	 prepare: 13.9100	 bound: 30.1878	 transfer: 0.0781	 finalize: 15.1025
batch bounding time:  1.8165736198425293
Current worst splitting domains [lb, ub] (depth):
[-1.26194,   inf] (46), [-1.25939,   inf] (42), [-1.25881,   inf] (46), [-1.25652,   inf] (44), [-1.25651,   inf] (52), [-1.25651,   inf] (40), [-1.25650,   inf] (50), [-1.25650,   inf] (48), [-1.25650,   inf] (48), [-1.25649,   inf] (54), [-1.25647,   inf] (42), [-1.25647,   inf] (56), [-1.25646,   inf] (50), [-1.25646,   inf] (50), [-1.25645,   inf] (52), [-1.25644,   inf] (52), [-1.25644,   inf] (38), [-1.25644,   inf] (44), [-1.25643,   inf] (58), [-1.25643,   inf] (40), 
length of domains: 51855
Total time: 3.1690	 pickout: 0.3235	 decision: 0.5801	 get_bound: 1.8238	 add_domain: 0.4416
Current lb:-1.261939287185669
115872 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 113.07955503463745

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [0, 2254] [1, 708] [1, 258] [2, 97] [2, 97] [1, 136] [1, 142] [2, 17] [2, 9] [2, 9] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 3993.72314453125 with beta sum per layer: [0.9304134845733643, 1264.9425048828125, 2525.532958984375]
alpha/beta optimization time: 1.0241565704345703
This batch time : update_bounds func: 1.8318	 prepare: 0.4248	 bound: 1.0246	 transfer: 0.0778	 finalize: 0.2906
Accumulated time: update_bounds func: 64.8376	 prepare: 14.3348	 bound: 31.2123	 transfer: 0.0778	 finalize: 15.3931
batch bounding time:  1.8359160423278809
Current worst splitting domains [lb, ub] (depth):
[-1.24648,   inf] (44), [-1.24571,   inf] (46), [-1.24571,   inf] (48), [-1.24571,   inf] (42), [-1.24571,   inf] (46), [-1.24570,   inf] (46), [-1.24570,   inf] (52), [-1.24569,   inf] (34), [-1.24569,   inf] (52), [-1.24569,   inf] (46), [-1.24569,   inf] (48), [-1.24568,   inf] (44), [-1.24568,   inf] (46), [-1.24568,   inf] (44), [-1.24567,   inf] (40), [-1.24566,   inf] (48), [-1.24566,   inf] (38), [-1.24566,   inf] (40), [-1.24565,   inf] (54), [-1.24565,   inf] (46), 
length of domains: 53698
Total time: 4.3987	 pickout: 0.3228	 decision: 1.7894	 get_bound: 1.8433	 add_domain: 0.4432
Current lb:-1.2464795112609863
119968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 117.53475093841553

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 63] [2, 9] [1, 708] [1, 708] [2, 9] [2, 9] [2, 70] [1, 142] [2, 70] [1, 638] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 3950.87939453125 with beta sum per layer: [0.954881489276886, 1287.306884765625, 2532.55322265625]
alpha/beta optimization time: 1.0153346061706543
This batch time : update_bounds func: 1.8158	 prepare: 0.4261	 bound: 1.0157	 transfer: 0.0782	 finalize: 0.2813
Accumulated time: update_bounds func: 66.6534	 prepare: 14.7610	 bound: 32.2280	 transfer: 0.0782	 finalize: 15.6743
batch bounding time:  1.8197362422943115
Current worst splitting domains [lb, ub] (depth):
[-1.23505,   inf] (46), [-1.23504,   inf] (40), [-1.23504,   inf] (52), [-1.23504,   inf] (46), [-1.23504,   inf] (38), [-1.23503,   inf] (54), [-1.23502,   inf] (40), [-1.23500,   inf] (52), [-1.23500,   inf] (46), [-1.23499,   inf] (44), [-1.23499,   inf] (50), [-1.23497,   inf] (50), [-1.23497,   inf] (54), [-1.23496,   inf] (48), [-1.23496,   inf] (42), [-1.23496,   inf] (48), [-1.23496,   inf] (40), [-1.23495,   inf] (40), [-1.23495,   inf] (46), [-1.23494,   inf] (42), 
length of domains: 55527
Total time: 4.4687	 pickout: 0.3234	 decision: 0.5839	 get_bound: 1.8271	 add_domain: 1.7344
Current lb:-1.2350517511367798
124064 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 122.05944561958313

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 97] [1, 708] [2, 97] [2, 9] [1, 708] [1, 33] [1, 638] [2, 70] [2, 9] [1, 708] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 3905.763427734375 with beta sum per layer: [0.708139181137085, 1327.956787109375, 2531.66748046875]
alpha/beta optimization time: 1.0164883136749268
This batch time : update_bounds func: 1.8103	 prepare: 0.4261	 bound: 1.0168	 transfer: 0.0762	 finalize: 0.2766
Accumulated time: update_bounds func: 68.4638	 prepare: 15.1870	 bound: 33.2449	 transfer: 0.0762	 finalize: 15.9509
batch bounding time:  1.814251184463501
Current worst splitting domains [lb, ub] (depth):
[-1.22607,   inf] (44), [-1.22600,   inf] (44), [-1.22579,   inf] (46), [-1.22522,   inf] (46), [-1.22457,   inf] (48), [-1.22456,   inf] (44), [-1.22456,   inf] (48), [-1.22455,   inf] (52), [-1.22455,   inf] (44), [-1.22454,   inf] (50), [-1.22454,   inf] (56), [-1.22453,   inf] (44), [-1.22453,   inf] (50), [-1.22453,   inf] (52), [-1.22452,   inf] (54), [-1.22451,   inf] (50), [-1.22451,   inf] (44), [-1.22451,   inf] (36), [-1.22450,   inf] (42), [-1.22450,   inf] (50), 
length of domains: 57364
Total time: 3.1753	 pickout: 0.3192	 decision: 0.5892	 get_bound: 1.8214	 add_domain: 0.4456
Current lb:-1.2260656356811523
128160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 125.29986667633057

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 708] [1, 638] [1, 638] [2, 65] [2, 9] [1, 636] [1, 702] [2, 70] [1, 136] [2, 97] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 3875.322509765625 with beta sum per layer: [1.0664738416671753, 1316.762451171875, 2587.13037109375]
alpha/beta optimization time: 1.0166864395141602
This batch time : update_bounds func: 3.2128	 prepare: 0.4293	 bound: 1.0171	 transfer: 0.0778	 finalize: 1.6735
Accumulated time: update_bounds func: 71.6766	 prepare: 15.6163	 bound: 34.2620	 transfer: 0.0778	 finalize: 17.6244
batch bounding time:  3.2169241905212402
Current worst splitting domains [lb, ub] (depth):
[-1.21646,   inf] (40), [-1.21471,   inf] (44), [-1.21471,   inf] (48), [-1.21471,   inf] (42), [-1.21470,   inf] (58), [-1.21470,   inf] (44), [-1.21470,   inf] (42), [-1.21469,   inf] (42), [-1.21467,   inf] (50), [-1.21467,   inf] (48), [-1.21466,   inf] (48), [-1.21466,   inf] (56), [-1.21466,   inf] (42), [-1.21466,   inf] (42), [-1.21466,   inf] (42), [-1.21465,   inf] (54), [-1.21463,   inf] (46), [-1.21463,   inf] (34), [-1.21462,   inf] (60), [-1.21462,   inf] (42), 
length of domains: 59215
Total time: 4.5863	 pickout: 0.3273	 decision: 0.5882	 get_bound: 3.2243	 add_domain: 0.4466
Current lb:-1.216459035873413
132256 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 129.94383883476257

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 9] [1, 142] [1, 708] [1, 702] [2, 32] [1, 638] [1, 708] [2, 9] [2, 17] [2, 97] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 3782.486328125 with beta sum per layer: [0.7681383490562439, 1318.548828125, 2645.380126953125]
alpha/beta optimization time: 1.0200047492980957
This batch time : update_bounds func: 1.8259	 prepare: 0.4347	 bound: 1.0204	 transfer: 0.0779	 finalize: 0.2776
Accumulated time: update_bounds func: 73.5025	 prepare: 16.0511	 bound: 35.2824	 transfer: 0.0779	 finalize: 17.9020
batch bounding time:  1.830148458480835
Current worst splitting domains [lb, ub] (depth):
[-1.20683,   inf] (48), [-1.20574,   inf] (58), [-1.20574,   inf] (48), [-1.20573,   inf] (38), [-1.20573,   inf] (46), [-1.20573,   inf] (52), [-1.20573,   inf] (44), [-1.20572,   inf] (36), [-1.20572,   inf] (42), [-1.20572,   inf] (42), [-1.20571,   inf] (48), [-1.20571,   inf] (48), [-1.20571,   inf] (48), [-1.20570,   inf] (50), [-1.20570,   inf] (46), [-1.20569,   inf] (44), [-1.20569,   inf] (42), [-1.20569,   inf] (44), [-1.20569,   inf] (50), [-1.20569,   inf] (46), 
length of domains: 61028
Total time: 3.2087	 pickout: 0.3238	 decision: 0.6019	 get_bound: 1.8377	 add_domain: 0.4453
Current lb:-1.2068250179290771
136352 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 133.20940947532654

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 638] [2, 65] [2, 9] [1, 708] [2, 65] [2, 97] [1, 638] [1, 708] [1, 136] [1, 637] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 3780.098876953125 with beta sum per layer: [0.9848463535308838, 1340.4324951171875, 2566.35107421875]
alpha/beta optimization time: 1.018205165863037
This batch time : update_bounds func: 3.2354	 prepare: 0.4244	 bound: 1.0186	 transfer: 0.0781	 finalize: 1.6996
Accumulated time: update_bounds func: 76.7379	 prepare: 16.4754	 bound: 36.3009	 transfer: 0.0781	 finalize: 19.6015
batch bounding time:  3.2393717765808105
Current worst splitting domains [lb, ub] (depth):
[-1.19685,   inf] (48), [-1.19685,   inf] (36), [-1.19685,   inf] (32), [-1.19685,   inf] (50), [-1.19685,   inf] (44), [-1.19684,   inf] (48), [-1.19684,   inf] (50), [-1.19684,   inf] (38), [-1.19684,   inf] (54), [-1.19683,   inf] (42), [-1.19683,   inf] (52), [-1.19683,   inf] (60), [-1.19683,   inf] (44), [-1.19682,   inf] (46), [-1.19682,   inf] (44), [-1.19682,   inf] (46), [-1.19682,   inf] (54), [-1.19682,   inf] (44), [-1.19681,   inf] (46), [-1.19680,   inf] (54), 
length of domains: 62868
Total time: 4.6107	 pickout: 0.3190	 decision: 0.5995	 get_bound: 3.2465	 add_domain: 0.4456
Current lb:-1.196853756904602
140448 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 137.87682437896729

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 17] [1, 258] [1, 637] [2, 17] [1, 638] [2, 17] [2, 17] [1, 702] [2, 32] [1, 31] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 3770.047119140625 with beta sum per layer: [1.0438131093978882, 1313.860595703125, 2645.373046875]
alpha/beta optimization time: 1.018848180770874
This batch time : update_bounds func: 1.8214	 prepare: 0.4320	 bound: 1.0192	 transfer: 0.0765	 finalize: 0.2791
Accumulated time: update_bounds func: 78.5594	 prepare: 16.9074	 bound: 37.3202	 transfer: 0.0765	 finalize: 19.8806
batch bounding time:  1.8254950046539307
Current worst splitting domains [lb, ub] (depth):
[-1.18981,   inf] (42), [-1.18836,   inf] (40), [-1.18836,   inf] (48), [-1.18836,   inf] (64), [-1.18836,   inf] (42), [-1.18836,   inf] (44), [-1.18835,   inf] (50), [-1.18834,   inf] (46), [-1.18834,   inf] (58), [-1.18834,   inf] (40), [-1.18833,   inf] (50), [-1.18833,   inf] (58), [-1.18833,   inf] (44), [-1.18833,   inf] (48), [-1.18832,   inf] (40), [-1.18831,   inf] (32), [-1.18831,   inf] (42), [-1.18831,   inf] (42), [-1.18831,   inf] (48), [-1.18830,   inf] (46), 
length of domains: 64715
Total time: 3.1941	 pickout: 0.3210	 decision: 0.5934	 get_bound: 1.8327	 add_domain: 0.4470
Current lb:-1.1898138523101807
144544 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 141.14021492004395

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 702] [1, 258] [2, 17] [2, 65] [1, 708] [1, 258] [1, 116] [1, 638] [2, 65] [1, 631] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 3681.57177734375 with beta sum per layer: [0.8154799938201904, 1380.46240234375, 2657.06005859375]
alpha/beta optimization time: 1.0199947357177734
This batch time : update_bounds func: 3.3952	 prepare: 0.4340	 bound: 1.0204	 transfer: 0.0780	 finalize: 1.8468
Accumulated time: update_bounds func: 81.9546	 prepare: 17.3414	 bound: 38.3405	 transfer: 0.0780	 finalize: 21.7274
batch bounding time:  3.399282932281494
Current worst splitting domains [lb, ub] (depth):
[-1.18294,   inf] (46), [-1.17999,   inf] (36), [-1.17999,   inf] (50), [-1.17998,   inf] (40), [-1.17998,   inf] (48), [-1.17998,   inf] (46), [-1.17998,   inf] (50), [-1.17997,   inf] (42), [-1.17996,   inf] (46), [-1.17996,   inf] (52), [-1.17996,   inf] (66), [-1.17996,   inf] (46), [-1.17995,   inf] (52), [-1.17995,   inf] (50), [-1.17993,   inf] (54), [-1.17993,   inf] (46), [-1.17992,   inf] (48), [-1.17992,   inf] (40), [-1.17992,   inf] (42), [-1.17992,   inf] (52), 
length of domains: 66524
Total time: 4.7701	 pickout: 0.3215	 decision: 0.5991	 get_bound: 3.4065	 add_domain: 0.4429
Current lb:-1.1829383373260498
148640 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 145.97621130943298

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [1, 637] [2, 63] [2, 17] [1, 258] [2, 17] [1, 631] [2, 17] [1, 136] [2, 9] [2, 97] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 3629.78466796875 with beta sum per layer: [1.043294072151184, 1363.317626953125, 2637.014404296875]
alpha/beta optimization time: 1.0198631286621094
This batch time : update_bounds func: 1.8292	 prepare: 0.4294	 bound: 1.0202	 transfer: 0.0770	 finalize: 0.2871
Accumulated time: update_bounds func: 83.7838	 prepare: 17.7709	 bound: 39.3608	 transfer: 0.0770	 finalize: 22.0145
batch bounding time:  1.8331356048583984
Current worst splitting domains [lb, ub] (depth):
[-1.17232,   inf] (52), [-1.17231,   inf] (42), [-1.17231,   inf] (34), [-1.17231,   inf] (48), [-1.17231,   inf] (52), [-1.17230,   inf] (48), [-1.17230,   inf] (58), [-1.17230,   inf] (52), [-1.17229,   inf] (38), [-1.17228,   inf] (48), [-1.17227,   inf] (54), [-1.17227,   inf] (52), [-1.17227,   inf] (54), [-1.17227,   inf] (42), [-1.17227,   inf] (40), [-1.17226,   inf] (46), [-1.17226,   inf] (56), [-1.17226,   inf] (46), [-1.17225,   inf] (46), [-1.17225,   inf] (44), 
length of domains: 68310
Total time: 3.2049	 pickout: 0.3266	 decision: 0.5949	 get_bound: 1.8405	 add_domain: 0.4429
Current lb:-1.172316074371338
152736 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 149.24232006072998

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 70] [2, 97] [1, 258] [2, 17] [2, 97] [2, 17] [1, 33] [2, 17] [1, 638] [2, 97] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 3659.8779296875 with beta sum per layer: [0.8819730281829834, 1331.2164306640625, 2680.39794921875]
alpha/beta optimization time: 1.020383358001709
This batch time : update_bounds func: 3.5628	 prepare: 0.4239	 bound: 1.0207	 transfer: 0.0775	 finalize: 2.0256
Accumulated time: update_bounds func: 87.3466	 prepare: 18.1948	 bound: 40.3815	 transfer: 0.0775	 finalize: 24.0402
batch bounding time:  3.5671043395996094
Current worst splitting domains [lb, ub] (depth):
[-1.16483,   inf] (48), [-1.16450,   inf] (48), [-1.16449,   inf] (44), [-1.16449,   inf] (50), [-1.16449,   inf] (42), [-1.16448,   inf] (52), [-1.16448,   inf] (62), [-1.16448,   inf] (40), [-1.16447,   inf] (48), [-1.16447,   inf] (62), [-1.16447,   inf] (44), [-1.16446,   inf] (48), [-1.16446,   inf] (44), [-1.16445,   inf] (46), [-1.16445,   inf] (46), [-1.16445,   inf] (42), [-1.16444,   inf] (50), [-1.16444,   inf] (54), [-1.16443,   inf] (52), [-1.16443,   inf] (44), 
length of domains: 70132
Total time: 4.9619	 pickout: 0.3374	 decision: 0.5992	 get_bound: 3.5746	 add_domain: 0.4507
Current lb:-1.1648280620574951
156832 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 154.26334619522095

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [0, 2254] [2, 97] [1, 637] [2, 9] [1, 637] [2, 97] [1, 32] [1, 708] [2, 17] [1, 32] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 3596.03662109375 with beta sum per layer: [1.0631396770477295, 1346.6982421875, 2753.28955078125]
alpha/beta optimization time: 1.0181710720062256
This batch time : update_bounds func: 1.8185	 prepare: 0.4263	 bound: 1.0185	 transfer: 0.0781	 finalize: 0.2808
Accumulated time: update_bounds func: 89.1651	 prepare: 18.6210	 bound: 41.4000	 transfer: 0.0781	 finalize: 24.3209
batch bounding time:  1.8227829933166504
Current worst splitting domains [lb, ub] (depth):
[-1.15714,   inf] (48), [-1.15714,   inf] (48), [-1.15714,   inf] (52), [-1.15714,   inf] (48), [-1.15713,   inf] (52), [-1.15713,   inf] (48), [-1.15713,   inf] (48), [-1.15713,   inf] (34), [-1.15712,   inf] (34), [-1.15712,   inf] (46), [-1.15712,   inf] (46), [-1.15711,   inf] (54), [-1.15711,   inf] (42), [-1.15710,   inf] (50), [-1.15710,   inf] (50), [-1.15710,   inf] (44), [-1.15710,   inf] (44), [-1.15709,   inf] (44), [-1.15709,   inf] (54), [-1.15708,   inf] (50), 
length of domains: 71928
Total time: 3.2065	 pickout: 0.3346	 decision: 0.5927	 get_bound: 1.8303	 add_domain: 0.4489
Current lb:-1.1571444272994995
160928 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 157.52904343605042

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [0, 2254] [2, 17] [2, 9] [2, 9] [2, 65] [2, 9] [2, 9] [1, 708] [2, 73] [1, 638] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 3545.552734375 with beta sum per layer: [0.998946487903595, 1416.4710693359375, 2658.544921875]
alpha/beta optimization time: 1.0190811157226562
This batch time : update_bounds func: 1.8227	 prepare: 0.4279	 bound: 1.0194	 transfer: 0.0790	 finalize: 0.2808
Accumulated time: update_bounds func: 90.9878	 prepare: 19.0489	 bound: 42.4195	 transfer: 0.0790	 finalize: 24.6018
batch bounding time:  1.826796054840088
Current worst splitting domains [lb, ub] (depth):
[-1.15002,   inf] (46), [-1.15002,   inf] (56), [-1.15002,   inf] (40), [-1.15001,   inf] (46), [-1.15001,   inf] (44), [-1.15001,   inf] (42), [-1.15000,   inf] (50), [-1.15000,   inf] (62), [-1.14999,   inf] (50), [-1.14999,   inf] (46), [-1.14999,   inf] (46), [-1.14998,   inf] (44), [-1.14998,   inf] (50), [-1.14998,   inf] (54), [-1.14998,   inf] (46), [-1.14997,   inf] (44), [-1.14997,   inf] (38), [-1.14996,   inf] (60), [-1.14996,   inf] (50), [-1.14996,   inf] (48), 
length of domains: 73704
Total time: 5.0157	 pickout: 0.3309	 decision: 0.5980	 get_bound: 1.8342	 add_domain: 2.2526
Current lb:-1.1500227451324463
165024 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 162.60257124900818

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 97] [1, 33] [1, 708] [1, 638] [1, 136] [2, 97] [2, 70] [2, 65] [2, 70] [1, 31] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 3538.56103515625 with beta sum per layer: [0.9694554805755615, 1347.65625, 2695.951171875]
alpha/beta optimization time: 1.0209295749664307
This batch time : update_bounds func: 1.8280	 prepare: 0.4289	 bound: 1.0213	 transfer: 0.0775	 finalize: 0.2857
Accumulated time: update_bounds func: 92.8158	 prepare: 19.4779	 bound: 43.4408	 transfer: 0.0775	 finalize: 24.8875
batch bounding time:  1.8320941925048828
Current worst splitting domains [lb, ub] (depth):
[-1.14321,   inf] (52), [-1.14320,   inf] (38), [-1.14320,   inf] (52), [-1.14320,   inf] (50), [-1.14320,   inf] (46), [-1.14319,   inf] (48), [-1.14319,   inf] (52), [-1.14319,   inf] (44), [-1.14319,   inf] (52), [-1.14319,   inf] (44), [-1.14319,   inf] (32), [-1.14319,   inf] (60), [-1.14318,   inf] (42), [-1.14318,   inf] (50), [-1.14318,   inf] (56), [-1.14317,   inf] (50), [-1.14317,   inf] (32), [-1.14317,   inf] (42), [-1.14317,   inf] (56), [-1.14317,   inf] (50), 
length of domains: 75493
Total time: 3.2123	 pickout: 0.3273	 decision: 0.5968	 get_bound: 1.8395	 add_domain: 0.4486
Current lb:-1.1432054042816162
169120 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 165.87441635131836

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 70] [2, 63] [2, 70] [2, 9] [2, 9] [2, 97] [2, 70] [2, 17] [2, 70] [1, 702] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 3504.1513671875 with beta sum per layer: [0.9691364169120789, 1339.6474609375, 2774.271484375]
alpha/beta optimization time: 1.016627550125122
This batch time : update_bounds func: 1.8222	 prepare: 0.4306	 bound: 1.0170	 transfer: 0.0768	 finalize: 0.2824
Accumulated time: update_bounds func: 94.6380	 prepare: 19.9085	 bound: 44.4578	 transfer: 0.0768	 finalize: 25.1699
batch bounding time:  1.826338291168213
Current worst splitting domains [lb, ub] (depth):
[-1.13701,   inf] (44), [-1.13647,   inf] (42), [-1.13647,   inf] (46), [-1.13647,   inf] (62), [-1.13646,   inf] (52), [-1.13646,   inf] (48), [-1.13645,   inf] (40), [-1.13645,   inf] (40), [-1.13644,   inf] (48), [-1.13644,   inf] (42), [-1.13643,   inf] (48), [-1.13643,   inf] (46), [-1.13643,   inf] (44), [-1.13643,   inf] (58), [-1.13642,   inf] (42), [-1.13642,   inf] (48), [-1.13642,   inf] (48), [-1.13642,   inf] (58), [-1.13642,   inf] (56), [-1.13641,   inf] (44), 
length of domains: 77274
Total time: 3.2014	 pickout: 0.3308	 decision: 0.5917	 get_bound: 1.8337	 add_domain: 0.4451
Current lb:-1.1370134353637695
173216 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 169.13690900802612

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 13, 13]) pre split depth:  1
batch:  torch.Size([2048, 16, 13, 13]) post split depth:  1
splitting decisions: 
split level 0: [2, 9] [1, 258] [1, 31] [2, 47] [1, 142] [2, 9] [1, 638] [1, 702] [2, 17] [1, 708] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 3465.51904296875 with beta sum per layer: [1.0037293434143066, 1422.470947265625, 2718.09912109375]
alpha/beta optimization time: 1.0177359580993652
This batch time : update_bounds func: 1.8271	 prepare: 0.4328	 bound: 1.0181	 transfer: 0.0786	 finalize: 0.2814
Accumulated time: update_bounds func: 96.4651	 prepare: 20.3413	 bound: 45.4759	 transfer: 0.0786	 finalize: 25.4513
batch bounding time:  1.8313679695129395
Current worst splitting domains [lb, ub] (depth):
[-1.12955,   inf] (48), [-1.12954,   inf] (54), [-1.12953,   inf] (50), [-1.12953,   inf] (40), [-1.12953,   inf] (46), [-1.12953,   inf] (44)/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:556: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(eps_temp / std).reshape(1, -1, 1, 1)
, [-1.12953,   inf] (62), [-1.12953,   inf] (32), [-1.12953,   inf] (52), [-1.12952,   inf] (46), [-1.12950,   inf] (52), [-1.12950,   inf] (44), [-1.12949,   inf] (52), [-1.12948,   inf] (40), [-1.12948,   inf] (58), [-1.12947,   inf] (60), [-1.12947,   inf] (48), [-1.12947,   inf] (44), [-1.12947,   inf] (50), [-1.12946,   inf] (42), 
length of domains: 79040
Total time: 5.0674	 pickout: 0.3364	 decision: 2.4449	 get_bound: 1.8391	 add_domain: 0.4470
Current lb:-1.129547119140625
177312 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Time out!!!!!!!!
Image 24 label 7 verification end, final lower bound -1.129547119140625, upper bound inf, time: 175.9591987133026
24 -1.129547119140625
Result: image 24 verification failure (with branch and bound).
Wall time: 184.78854823112488

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 0): []
verification failure idx (total 1): [24]
final verified acc: 0.0%[1]
verifier is called on 1 examples.
total verified: 0
mean time [cnt:1] (excluding attack success): 184.73514008522034
