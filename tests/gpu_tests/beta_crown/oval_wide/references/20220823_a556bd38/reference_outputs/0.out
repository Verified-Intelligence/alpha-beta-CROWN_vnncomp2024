Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  sparse_alpha: true
  save_adv_example: false
  precompile_jit: false
  mode: specify-target
  complete_verifier: bab
  enable_incomplete_verification: false
  get_crown_verified_acc: false
  csv_name: null
  results_file: null
  root_path: ''
model:
  path: cifar_wide.pth
  cache_onnx_conversion: false
  onnx_quirks: null
  name: cifar_model_wide
  onnx_path: null
  onnx_path_prefix: ''
  onnx_optimization_flags: none
data:
  start: 0
  end: 1
  select_instance: null
  num_outputs: 10
  mean: [0.485, 0.456, 0.406]
  std: [0.225, 0.225, 0.225]
  pkl_path: wide_100.pkl
  dataset: CIFAR
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: null
  vnnlib_path: null
  vnnlib_path_prefix: ''
solver:
  batch_size: 1024
  no_float64_last_iter: true
  no_amp: false
  early_stop_patience: 10
  start_save_best: 2
  bound_prop_method: alpha-crown
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
    full_conv_alpha: true
  beta-crown:
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  multi_class:
    multi_class_method: allclass_domain
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
bab:
  initial_max_domains: 1
  max_domains: 200000
  decision_thresh: 0
  timeout: 30
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_intermediate_layers: ''
  interm_transfer: true
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 100
    batch_size_primal: 100
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    max_num: 1000000000
    fixed_cuts: false
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
    lr: 0.01
  branching:
    method: fsb
    candidates: 1
    reduceop: min
    sb_coeff_thresh: 0.001
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      sort_domain_interval: -1
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  attack_mode: PGD
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 5000000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
  enable_mip_attack: false
  cex_path: ./test_cex.txt
debug:
  lp_test: null

Experiments at Tue Aug 23 16:23:56 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Flatten()
  (5): Linear(in_features=2048, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=10, bias=True)
)
No epsilon defined!
Files already downloaded and verified
Overwrite epsilon that saved in .pkl file, they should be after normalized!
saving results to Verified_ret_[cifar_model_wide]_start=0_end=1_iter=20_b=1024_timeout=30_branching=fsb-min-1_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip_cplex_cuts=False_multiclass=allclass_domain.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Total VNNLIB file length: 1, max property batch size: 1, total number of batches: 1

Properties batch 0, size 1
Remaining timeout: 27.929839849472046
##### [0] Spec matrix: [[[-1.  0.  0.  0.  0.  0.  1.  0.  0.  0.]]], thresh: [0] ######
Model prediction is: tensor([-0.26283619, -1.79466105,  0.92987883,  0.43162179,  1.08514738,
        -0.04146609,  2.40101671,  0.07541341, -2.04133391, -0.78272510],
       device='cuda:0')
layer /input.4 using sparse-features alpha with shape [1069]; unstable size 1069; total size 4096 (torch.Size([1, 16, 16, 16]))
layer /input.4 start_node /input.8 using sparse-spec alpha with unstable size 385 total_size 2048 output_shape (32, 8, 8)
layer /input.4 start_node /input.12 using sparse-spec alpha with unstable size 43 total_size 100 output_shape torch.Size([100])
layer /input.4 start_node /23 using full alpha with unstable size None total_size 1 output_shape 1
layer /12 using sparse-features alpha with shape [385]; unstable size 385; total size 2048 (torch.Size([1, 32, 8, 8]))
layer /12 start_node /input.12 using sparse-spec alpha with unstable size 43 total_size 100 output_shape torch.Size([100])
layer /12 start_node /23 using full alpha with unstable size None total_size 1 output_shape 1
layer /22 using sparse-features alpha with shape [43]; unstable size 43; total size 100 (torch.Size([1, 100]))
layer /22 start_node /23 using full alpha with unstable size None total_size 1 output_shape 1
Optimizable variables initialized.
initial CROWN bounds: tensor([[-1.05921614]], device='cuda:0') None
best_l after optimization: -0.7608984708786011 with beta sum per layer: []
alpha/beta optimization time: 5.415514707565308
initial alpha-CROWN bounds: tensor([[-0.76089847]], device='cuda:0')
Worst class: (+ rhs) -0.7608984708786011
Keeping slopes for these layers: ['/23']
layer 0 size torch.Size([4096]) unstable 1069
layer 1 size torch.Size([2048]) unstable 369
layer 2 size torch.Size([100]) unstable 42
-----------------
# of unstable neurons: 1480
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 16, 16]) pre split depth:  6
batch:  torch.Size([1, 16, 16, 16]) post split depth:  6
splitting decisions: 
split level 0: [2, 31] 
split level 1: [2, 6] 
split level 2: [2, 83] 
split level 3: [2, 58] 
split level 4: [2, 10] 
split level 5: [2, 45] 
regular batch size: 2*32, diving batch size 1*0
(64, 3, 32, 32) torch.Size([64, 1, 10]) torch.Size([64, 1])
best_l after optimization: 33.028602600097656 with beta sum per layer: [0.0, 0.0, 2.2293548583984375]
alpha/beta optimization time: 0.4450070858001709
pruning_in_iteration open status: True
ratio of positive domain = 59 / 64 = 0.921875
pruning-in-iteration extra time: 0.01090383529663086
Tensors transferred: pre=0.7622M lA=0.0298M alpha=0.1827M beta=0.0004M
This batch time : update_bounds func: 0.4551	 prepare: 0.0050	 bound: 0.4455	 transfer: 0.0031	 finalize: 0.0014
Accumulated time: update_bounds func: 0.4551	 prepare: 0.0050	 bound: 0.4455	 transfer: 0.0031	 finalize: 0.0014
batch bounding time:  0.4551994800567627
Current worst splitting domains lb-rhs (depth):
-0.30653 (6), -0.18730 (6), -0.13371 (6), -0.10901 (6), -0.08896 (6), 
length of domains: 5
Total time: 0.5394	 pickout: 0.0011	 decision: 0.0739	 get_bound: 0.4619	 add_domain: 0.0025
Accumulated time:	 pickout: 0.0011	 decision: 0.0739	 get_bound: 0.4619	 add_domain: 0.0025
Current (lb-rhs): -0.30652785301208496
59 domains visited
Cumulative time: 7.778308391571045

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([5, 16, 16, 16]) pre split depth:  4
batch:  torch.Size([5, 16, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 98] [2, 98] [2, 98] [2, 98] [2, 98] 
split level 1: [2, 89] [2, 89] [2, 89] [2, 89] [2, 89] 
split level 2: [2, 23] [2, 23] [2, 23] [2, 23] [2, 23] 
split level 3: [2, 22] [2, 22] [2, 22] [2, 22] [2, 22] 
regular batch size: 2*40, diving batch size 1*0
(80, 3, 32, 32) torch.Size([80, 1, 10]) torch.Size([80, 1])
best_l after optimization: 12.12468147277832 with beta sum per layer: [0.0, 0.0, 36.915260314941406]
alpha/beta optimization time: 0.23448634147644043
pruning_in_iteration open status: True
ratio of positive domain = 76 / 80 = 0.95
pruning-in-iteration extra time: 0.010757207870483398
Tensors transferred: pre=0.9528M lA=0.0238M alpha=0.2284M beta=0.0008M
This batch time : update_bounds func: 0.2455	 prepare: 0.0065	 bound: 0.2349	 transfer: 0.0023	 finalize: 0.0016
Accumulated time: update_bounds func: 0.7006	 prepare: 0.0114	 bound: 0.6804	 transfer: 0.0054	 finalize: 0.0030
batch bounding time:  0.24551749229431152
Current worst splitting domains lb-rhs (depth):
-0.07469 (10), -0.02490 (10), -0.01495 (10), -0.01432 (10), 
length of domains: 4
Total time: 0.3139	 pickout: 0.0012	 decision: 0.0574	 get_bound: 0.2531	 add_domain: 0.0022
Accumulated time:	 pickout: 0.0023	 decision: 0.1312	 get_bound: 0.7150	 add_domain: 0.0047
Current (lb-rhs): -0.07468879222869873
135 domains visited
Cumulative time: 8.092545509338379

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 16, 16, 16]) pre split depth:  4
batch:  torch.Size([4, 16, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 40] [2, 40] [2, 40] [2, 40] 
split level 1: [2, 42] [2, 42] [2, 42] [2, 42] 
split level 2: [2, 92] [2, 92] [2, 92] [2, 92] 
split level 3: [1, 1253] [2, 3] [1, 421] [2, 3] 
regular batch size: 2*32, diving batch size 1*0
(64, 3, 32, 32) torch.Size([64, 1, 10]) torch.Size([64, 1])

all verified at 0th iter
best_l after optimization: 13.52206039428711 with beta sum per layer: [0.0, 0.0, 19.929302215576172]
alpha/beta optimization time: 0.006688594818115234
pruning_in_iteration open status: False
ratio of positive domain = 64 / 64 = 1.0
pruning-in-iteration extra time: 0.0001087188720703125
Tensors transferred: pre=0.7622M lA=0.3811M alpha=0.1827M beta=0.0009M
This batch time : update_bounds func: 0.0164	 prepare: 0.0058	 bound: 0.0071	 transfer: 0.0020	 finalize: 0.0015
Accumulated time: update_bounds func: 0.7170	 prepare: 0.0172	 bound: 0.6875	 transfer: 0.0074	 finalize: 0.0044
batch bounding time:  0.016488075256347656
length of domains: 0
Total time: 0.0805	 pickout: 0.0009	 decision: 0.0557	 get_bound: 0.0227	 add_domain: 0.0011
Accumulated time:	 pickout: 0.0032	 decision: 0.1869	 get_bound: 0.7377	 add_domain: 0.0058
No domains left, verification finished!
199 domains visited
Cumulative time: 8.173215627670288

Result: safe in 10.7664 seconds
############# Summary #############
Final verified acc: 100.0% [total 1 examples]
Total verification count: 1 , total verified safe: 1 , verified unsafe: 0 , timeout: 0
mean time (bab) [total:1]: 8.696175813674927
mean time [1] 10.766379833221436 max time 10.766379833221436
safe (total 1): [0]
