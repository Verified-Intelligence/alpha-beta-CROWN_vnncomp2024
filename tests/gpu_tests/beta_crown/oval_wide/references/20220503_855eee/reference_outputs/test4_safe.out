Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: specify-target
  complete_verifier: bab
  enable_incomplete_verification: false
  get_crown_verified_acc: false
model:
  path: cifar_wide.pth
  name: cifar_model_wide
data:
  start: 94
  end: 95
  num_outputs: 10
  mean: [0.485, 0.456, 0.406]
  std: [0.225, 0.225, 0.225]
  pkl_path: wide_100.pkl
  dataset: CIFAR
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: null
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 1024
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 36
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: fsb
    candidates: 1
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Tue May  3 01:37:31 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Flatten()
  (5): Linear(in_features=2048, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=10, bias=True)
)
No epsilon defined!
Files already downloaded and verified
Overwrite epsilon that saved in .pkl file, they should be after normalized!
Task length: 1
saving results to Verified_ret_[cifar_model_wide]_start=94_end=95_iter=20_b=1024_timeout=36_branching=fsb-min-1_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 94 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 8, correct label 8, image norm 3726.52587890625, logits tensor([ 0.2584, -1.4698, -0.2088,  0.5678, -0.9017,  0.5434, -2.2244,  0.2381,
         2.1171,  1.0800], device='cuda:0', grad_fn=<SelectBackward>)
##### [0:94] Tested against 7 ######
Model prediction is: tensor([[ 0.2584, -1.4698, -0.2088,  0.5678, -0.9017,  0.5434, -2.2244,  0.2381,
          2.1171,  1.0800]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-0.3785]], device='cuda:0') None
best_l after optimization: 0.2607426345348358 with beta sum per layer: []
alpha/beta optimization time: 7.309548616409302
initial alpha-CROWN bounds: tensor([[-0.2607]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.2607, device='cuda:0', grad_fn=<MinBackward1>)
-0.2607426643371582
layer 0 size torch.Size([4096]) unstable 592
layer 1 size torch.Size([2048]) unstable 216
layer 2 size torch.Size([100]) unstable 24
-----------------
# of unstable neurons: 832
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 16, 16]) pre split depth:  6
batch:  torch.Size([1, 16, 16, 16]) post split depth:  6
splitting decisions: 
split level 0: [2, 61] 
split level 1: [2, 44] 
split level 2: [2, 88] 
split level 3: [2, 3] 
split level 4: [1, 1122] 
split level 5: [2, 86] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: -8.65796184539795 with beta sum per layer: [0.0, 1.8944746255874634, 10.032182693481445]
alpha/beta optimization time: 0.27973365783691406
This batch time : update_bounds func: 0.2919	 prepare: 0.0057	 bound: 0.2801	 transfer: 0.0019	 finalize: 0.0039
Accumulated time: update_bounds func: 0.2919	 prepare: 0.0057	 bound: 0.2801	 transfer: 0.0019	 finalize: 0.0039
batch bounding time:  0.2920796871185303
Current worst splitting domains [lb, ub] (depth):
[-0.14478,   inf] (7), [-0.12561,   inf] (7), [-0.05511,   inf] (7), [-0.02896,   inf] (7), 
length of domains: 4
Total time: 0.3720	 pickout: 0.0009	 decision: 0.0713	 get_bound: 0.2995	 add_domain: 0.0002
Current lb:-0.1447763442993164
64 neurons visited
0 diving domains visited
Global ub: tensor([[inf]], device='cuda:0'), batch ub: inf
Cumulative time: 9.492823123931885

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 16, 16, 16]) pre split depth:  4
batch:  torch.Size([4, 16, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [1, 987] [1, 987] [1, 987] [1, 987] 
split level 1: [2, 85] [2, 85] [2, 85] [2, 85] 
split level 2: [1, 1748] [1, 1748] [1, 1748] [1, 1748] 
split level 3: [1, 2026] [1, 2026] [1, 2026] [1, 2026] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: -1.5031529664993286 with beta sum per layer: [0.0, 11.441328048706055, 30.81866455078125]
alpha/beta optimization time: 0.2627072334289551
This batch time : update_bounds func: 0.2769	 prepare: 0.0071	 bound: 0.2630	 transfer: 0.0020	 finalize: 0.0046
Accumulated time: update_bounds func: 0.5688	 prepare: 0.0128	 bound: 0.5431	 transfer: 0.0020	 finalize: 0.0085
batch bounding time:  0.2770836353302002
Current worst splitting domains [lb, ub] (depth):
[-0.10516,   inf] (12), [-0.09643,   inf] (12), [-0.09468,   inf] (12), [-0.08724,   inf] (12), [-0.08607,   inf] (12), [-0.07560,   inf] (12), [-0.07513,   inf] (12), [-0.07344,   inf] (12), [-0.06597,   inf] (12), [-0.06549,   inf] (12), [-0.06297,   inf] (12), [-0.05741,   inf] (12), [-0.05637,   inf] (12), [-0.04721,   inf] (12), [-0.04707,   inf] (12), [-0.03803,   inf] (12), 
length of domains: 16
Total time: 0.3399	 pickout: 0.0012	 decision: 0.0543	 get_bound: 0.2838	 add_domain: 0.0006
Current lb:-0.10516498237848282
128 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.83311653137207

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([16, 16, 16, 16]) pre split depth:  2
batch:  torch.Size([16, 16, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [2, 6] [2, 6] [2, 6] [2, 6] [2, 6] [2, 6] [2, 6] [2, 6] [2, 6] [2, 6] 
split level 1: [1, 547] [1, 547] [1, 547] [1, 547] [1, 547] [1, 547] [1, 547] [1, 547] [1, 547] [1, 547] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: -0.4502732753753662 with beta sum per layer: [0.0, 22.94891357421875, 4.323437690734863]
alpha/beta optimization time: 0.2755587100982666
This batch time : update_bounds func: 0.2927	 prepare: 0.0090	 bound: 0.2759	 transfer: 0.0029	 finalize: 0.0046
Accumulated time: update_bounds func: 0.8615	 prepare: 0.0217	 bound: 0.8190	 transfer: 0.0029	 finalize: 0.0132
batch bounding time:  0.2929210662841797
Current worst splitting domains [lb, ub] (depth):
[-0.08485,   inf] (15), [-0.07639,   inf] (15), [-0.07439,   inf] (15), [-0.06723,   inf] (15), [-0.06423,   inf] (15), [-0.05382,   inf] (15), [-0.05344,   inf] (15), [-0.05315,   inf] (15), [-0.04518,   inf] (15), [-0.04407,   inf] (15), [-0.04269,   inf] (15), [-0.04238,   inf] (15), [-0.03908,   inf] (15), [-0.03601,   inf] (15), [-0.03540,   inf] (15), [-0.03256,   inf] (15), [-0.03076,   inf] (15), [-0.02881,   inf] (15), [-0.02666,   inf] (15), [-0.02557,   inf] (15), 
length of domains: 26
Total time: 0.3554	 pickout: 0.0029	 decision: 0.0524	 get_bound: 0.2990	 add_domain: 0.0012
Current lb:-0.0848546028137207
192 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.189021348953247

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([26, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([26, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1755] [1, 1755] [1, 1755] [1, 1755] [1, 1755] [1, 1755] [1, 1755] [1, 1755] [1, 1755] [1, 1755] 
regular batch size: 2*26, diving batch size 1*0
best_l after optimization: 0.9923804998397827 with beta sum per layer: [0.0, 19.671722412109375, 0.0]
alpha/beta optimization time: 0.26124024391174316
This batch time : update_bounds func: 0.2796	 prepare: 0.0083	 bound: 0.2616	 transfer: 0.0062	 finalize: 0.0033
Accumulated time: update_bounds func: 1.1411	 prepare: 0.0300	 bound: 1.0806	 transfer: 0.0062	 finalize: 0.0165
batch bounding time:  0.27988243103027344
Current worst splitting domains [lb, ub] (depth):
[-0.07367,   inf] (17), [-0.06400,   inf] (17), [-0.06251,   inf] (17), [-0.05432,   inf] (17), [-0.05304,   inf] (17), [-0.04863,   inf] (17), [-0.04706,   inf] (17), [-0.04246,   inf] (17), [-0.04199,   inf] (17), [-0.04180,   inf] (17), [-0.04099,   inf] (17), [-0.03985,   inf] (17), [-0.03268,   inf] (17), [-0.03166,   inf] (17), [-0.03095,   inf] (17), [-0.03067,   inf] (17), [-0.02839,   inf] (17), [-0.02790,   inf] (17), [-0.02531,   inf] (17), [-0.02357,   inf] (17), 
length of domains: 37
Total time: 0.3259	 pickout: 0.0055	 decision: 0.0388	 get_bound: 0.2800	 add_domain: 0.0016
Current lb:-0.07367289066314697
244 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.515591859817505

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([37, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([37, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1425] [1, 1425] [1, 1425] [1, 1425] [1, 1425] [1, 1425] [1, 1425] [1, 1425] [1, 1425] [1, 1425] 
regular batch size: 2*37, diving batch size 1*0
best_l after optimization: 1.3970363140106201 with beta sum per layer: [0.0, 22.959136962890625, 0.0]
alpha/beta optimization time: 0.2522122859954834
This batch time : update_bounds func: 0.2691	 prepare: 0.0080	 bound: 0.2525	 transfer: 0.0035	 finalize: 0.0049
Accumulated time: update_bounds func: 1.4102	 prepare: 0.0380	 bound: 1.3331	 transfer: 0.0035	 finalize: 0.0213
batch bounding time:  0.26930689811706543
Current worst splitting domains [lb, ub] (depth):
[-0.06580,   inf] (19), [-0.06191,   inf] (19), [-0.05618,   inf] (19), [-0.05451,   inf] (19), [-0.05211,   inf] (19), [-0.05064,   inf] (19), [-0.04634,   inf] (19), [-0.04510,   inf] (19), [-0.04227,   inf] (19), [-0.04146,   inf] (19), [-0.04066,   inf] (19), [-0.03897,   inf] (19), [-0.03680,   inf] (19), [-0.03501,   inf] (19), [-0.03424,   inf] (19), [-0.03386,   inf] (19), [-0.03381,   inf] (19), [-0.03298,   inf] (19), [-0.03190,   inf] (19), [-0.03028,   inf] (19), 
length of domains: 64
Total time: 0.3157	 pickout: 0.0067	 decision: 0.0369	 get_bound: 0.2694	 add_domain: 0.0027
Current lb:-0.06579707562923431
318 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.832087993621826

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([64, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1044] [1, 1044] [1, 1044] [1, 1044] [1, 1044] [1, 1044] [1, 1044] [1, 1044] [1, 1044] [1, 1044] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 1.5449072122573853 with beta sum per layer: [0.0, 37.89088821411133, 0.0]
alpha/beta optimization time: 0.25806307792663574
This batch time : update_bounds func: 0.2887	 prepare: 0.0129	 bound: 0.2584	 transfer: 0.0096	 finalize: 0.0075
Accumulated time: update_bounds func: 1.6989	 prepare: 0.0509	 bound: 1.5915	 transfer: 0.0096	 finalize: 0.0289
batch bounding time:  0.2889840602874756
Current worst splitting domains [lb, ub] (depth):
[-0.05767,   inf] (21), [-0.05379,   inf] (21), [-0.05369,   inf] (21), [-0.04996,   inf] (21), [-0.04808,   inf] (21), [-0.04642,   inf] (21), [-0.04393,   inf] (21), [-0.04301,   inf] (21), [-0.04246,   inf] (21), [-0.04042,   inf] (21), [-0.03898,   inf] (21), [-0.03861,   inf] (21), [-0.03698,   inf] (21), [-0.03649,   inf] (21), [-0.03441,   inf] (21), [-0.03318,   inf] (21), [-0.03308,   inf] (21), [-0.03254,   inf] (21), [-0.03115,   inf] (21), [-0.03108,   inf] (21), 
length of domains: 90
Total time: 0.3585	 pickout: 0.0097	 decision: 0.0559	 get_bound: 0.2892	 add_domain: 0.0038
Current lb:-0.05767321586608887
446 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.191825866699219

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([90, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([90, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 549] [1, 549] [1, 549] [1, 549] [1, 549] [1, 549] [1, 549] [1, 549] [1, 549] [1, 549] 
regular batch size: 2*90, diving batch size 1*0
best_l after optimization: 1.832667589187622 with beta sum per layer: [0.0, 47.571937561035156, 0.0]
alpha/beta optimization time: 0.26584482192993164
This batch time : update_bounds func: 0.3020	 prepare: 0.0172	 bound: 0.2661	 transfer: 0.0081	 finalize: 0.0101
Accumulated time: update_bounds func: 2.0009	 prepare: 0.0682	 bound: 1.8576	 transfer: 0.0081	 finalize: 0.0389
batch bounding time:  0.30226922035217285
Current worst splitting domains [lb, ub] (depth):
[-0.04977,   inf] (23), [-0.04700,   inf] (23), [-0.04582,   inf] (23), [-0.04567,   inf] (23), [-0.04309,   inf] (23), [-0.04303,   inf] (23), [-0.04192,   inf] (23), [-0.04026,   inf] (23), [-0.03927,   inf] (23), [-0.03852,   inf] (23), [-0.03740,   inf] (23), [-0.03603,   inf] (23), [-0.03561,   inf] (23), [-0.03493,   inf] (23), [-0.03462,   inf] (23), [-0.03323,   inf] (23), [-0.03249,   inf] (23), [-0.03215,   inf] (23), [-0.03171,   inf] (23), [-0.03084,   inf] (23), 
length of domains: 124
Total time: 0.3922	 pickout: 0.0132	 decision: 0.0710	 get_bound: 0.3025	 add_domain: 0.0054
Current lb:-0.04976784065365791
626 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.585880756378174

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([124, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([124, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2035] [1, 2035] [1, 2035] [1, 2035] [1, 2035] [1, 2035] [1, 2035] [1, 2035] [1, 2035] [1, 2035] 
regular batch size: 2*124, diving batch size 1*0
best_l after optimization: 1.8049108982086182 with beta sum per layer: [0.0, 62.91685104370117, 0.0]
alpha/beta optimization time: 0.2961289882659912
This batch time : update_bounds func: 0.3521	 prepare: 0.0259	 bound: 0.2965	 transfer: 0.0131	 finalize: 0.0159
Accumulated time: update_bounds func: 2.3529	 prepare: 0.0940	 bound: 2.1542	 transfer: 0.0131	 finalize: 0.0548
batch bounding time:  0.3524496555328369
Current worst splitting domains [lb, ub] (depth):
[-0.04268,   inf] (25), [-0.03997,   inf] (25), [-0.03868,   inf] (25), [-0.03845,   inf] (25), [-0.03719,   inf] (25), [-0.03601,   inf] (25), [-0.03594,   inf] (25), [-0.03477,   inf] (25), [-0.03451,   inf] (25), [-0.03317,   inf] (25), [-0.03315,   inf] (25), [-0.03302,   inf] (25), [-0.03212,   inf] (25), [-0.03136,   inf] (25), [-0.03049,   inf] (25), [-0.03048,   inf] (25), [-0.03033,   inf] (25), [-0.02928,   inf] (25), [-0.02894,   inf] (25), [-0.02847,   inf] (25), 
length of domains: 163
Total time: 0.4744	 pickout: 0.0201	 decision: 0.0940	 get_bound: 0.3528	 add_domain: 0.0075
Current lb:-0.04267513379454613
874 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.065282583236694

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([163, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([163, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1435] [1, 1435] [1, 1435] [1, 1435] [1, 1435] [1, 1435] [1, 1435] [1, 1435] [1, 1435] [1, 1435] 
regular batch size: 2*163, diving batch size 1*0
best_l after optimization: -2.028465747833252 with beta sum per layer: [0.0, 83.76122283935547, 0.0]
alpha/beta optimization time: 0.30516862869262695
This batch time : update_bounds func: 0.3734	 prepare: 0.0348	 bound: 0.3056	 transfer: 0.0136	 finalize: 0.0185
Accumulated time: update_bounds func: 2.7263	 prepare: 0.1288	 bound: 2.4597	 transfer: 0.0136	 finalize: 0.0733
batch bounding time:  0.3737926483154297
Current worst splitting domains [lb, ub] (depth):
[-0.03682,   inf] (27), [-0.03414,   inf] (27), [-0.03288,   inf] (27), [-0.03271,   inf] (27), [-0.03129,   inf] (27), [-0.03021,   inf] (27), [-0.03019,   inf] (27), [-0.02898,   inf] (27), [-0.02859,   inf] (27), [-0.02731,   inf] (27), [-0.02719,   inf] (27), [-0.02717,   inf] (27), [-0.02637,   inf] (27), [-0.02586,   inf] (27), [-0.02467,   inf] (27), [-0.02464,   inf] (27), [-0.02439,   inf] (27), [-0.02333,   inf] (27), [-0.02297,   inf] (27), [-0.02294,   inf] (27), 
length of domains: 123
Total time: 0.5232	 pickout: 0.0249	 decision: 0.1183	 get_bound: 0.3743	 add_domain: 0.0057
Current lb:-0.03682495653629303
1200 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.592390060424805

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([123, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([123, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1124] [1, 1124] [1, 1124] [1, 1124] [1, 1124] [1, 1124] [1, 1124] [1, 1124] [1, 1124] [1, 1124] 
regular batch size: 2*123, diving batch size 1*0
best_l after optimization: -0.24203431606292725 with beta sum per layer: [0.0, 51.309364318847656, 0.0]
alpha/beta optimization time: 0.2853846549987793
This batch time : update_bounds func: 0.3303	 prepare: 0.0234	 bound: 0.2857	 transfer: 0.0061	 finalize: 0.0145
Accumulated time: update_bounds func: 3.0566	 prepare: 0.1522	 bound: 2.7455	 transfer: 0.0061	 finalize: 0.0878
batch bounding time:  0.3306734561920166
Current worst splitting domains [lb, ub] (depth):
[-0.03135,   inf] (29), [-0.02894,   inf] (29), [-0.02742,   inf] (29), [-0.02730,   inf] (29), [-0.02577,   inf] (29), [-0.02504,   inf] (29), [-0.02501,   inf] (29), [-0.02358,   inf] (29), [-0.02336,   inf] (29), [-0.02181,   inf] (29), [-0.02173,   inf] (29), [-0.02135,   inf] (29), [-0.02128,   inf] (29), [-0.02037,   inf] (29), [-0.01945,   inf] (29), [-0.01945,   inf] (29), [-0.01889,   inf] (29), [-0.01797,   inf] (29), [-0.01776,   inf] (29), [-0.01713,   inf] (29), 
length of domains: 97
Total time: 0.4471	 pickout: 0.0203	 decision: 0.0910	 get_bound: 0.3311	 add_domain: 0.0046
Current lb:-0.03134666010737419
1446 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.042041540145874

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([97, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([97, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1050] [1, 1050] [1, 1050] [1, 1050] [1, 1050] [1, 1050] [1, 1050] [1, 1050] [1, 1050] [1, 1050] 
regular batch size: 2*97, diving batch size 1*0
best_l after optimization: 0.04487656056880951 with beta sum per layer: [0.0, 39.158599853515625, 0.0]
alpha/beta optimization time: 0.27291250228881836
This batch time : update_bounds func: 0.3208	 prepare: 0.0191	 bound: 0.2733	 transfer: 0.0155	 finalize: 0.0123
Accumulated time: update_bounds func: 3.3774	 prepare: 0.1713	 bound: 3.0187	 transfer: 0.0155	 finalize: 0.1001
batch bounding time:  0.3211357593536377
Current worst splitting domains [lb, ub] (depth):
[-0.02468,   inf] (31), [-0.02230,   inf] (31), [-0.02076,   inf] (31), [-0.02056,   inf] (31), [-0.01907,   inf] (31), [-0.01842,   inf] (31), [-0.01827,   inf] (31), [-0.01683,   inf] (31), [-0.01672,   inf] (31), [-0.01532,   inf] (31), [-0.01511,   inf] (31), [-0.01496,   inf] (31), [-0.01457,   inf] (31), [-0.01449,   inf] (31), [-0.01369,   inf] (31), [-0.01315,   inf] (31), [-0.01274,   inf] (31), [-0.01269,   inf] (31), [-0.01199,   inf] (31), [-0.01184,   inf] (31), 
length of domains: 75
Total time: 0.4159	 pickout: 0.0150	 decision: 0.0756	 get_bound: 0.3214	 add_domain: 0.0039
Current lb:-0.024684429168701172
1640 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.460045099258423

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([75, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([75, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 80] [2, 80] [2, 80] [2, 80] [2, 80] [2, 80] [2, 80] [2, 80] [2, 80] [2, 80] 
regular batch size: 2*75, diving batch size 1*0
best_l after optimization: -2.166947603225708 with beta sum per layer: [0.0, 26.442623138427734, 0.0]
alpha/beta optimization time: 0.2645845413208008
This batch time : update_bounds func: 0.3571	 prepare: 0.0149	 bound: 0.2649	 transfer: 0.0137	 finalize: 0.0627
Accumulated time: update_bounds func: 3.7345	 prepare: 0.1862	 bound: 3.2837	 transfer: 0.0137	 finalize: 0.1628
batch bounding time:  0.3574714660644531
Current worst splitting domains [lb, ub] (depth):
[-0.01972,   inf] (33), [-0.01735,   inf] (33), [-0.01582,   inf] (33), [-0.01555,   inf] (33), [-0.01410,   inf] (33), [-0.01352,   inf] (33), [-0.01321,   inf] (33), [-0.01186,   inf] (33), [-0.01179,   inf] (33), [-0.01037,   inf] (33), [-0.01014,   inf] (33), [-0.00994,   inf] (33), [-0.00954,   inf] (33), [-0.00947,   inf] (33), [-0.00877,   inf] (33), [-0.00804,   inf] (33), [-0.00785,   inf] (33), [-0.00768,   inf] (33), [-0.00700,   inf] (33), [-0.00667,   inf] (33), 
length of domains: 46
Total time: 0.4336	 pickout: 0.0119	 decision: 0.0616	 get_bound: 0.3577	 add_domain: 0.0024
Current lb:-0.01972063258290291
1790 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.895240545272827

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([46, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([46, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1749] [1, 1749] [1, 1749] [1, 1749] [1, 1749] [1, 1749] [1, 1749] [1, 1749] [1, 1749] [1, 1749] 
regular batch size: 2*46, diving batch size 1*0
best_l after optimization: -0.7587053775787354 with beta sum per layer: [0.0, 13.847760200500488, 0.0]
alpha/beta optimization time: 0.2582378387451172
This batch time : update_bounds func: 0.2773	 prepare: 0.0096	 bound: 0.2586	 transfer: 0.0032	 finalize: 0.0056
Accumulated time: update_bounds func: 4.0118	 prepare: 0.1958	 bound: 3.5423	 transfer: 0.0032	 finalize: 0.1684
batch bounding time:  0.27753758430480957
Current worst splitting domains [lb, ub] (depth):
[-0.01568,   inf] (35), [-0.01331,   inf] (35), [-0.01177,   inf] (35), [-0.01122,   inf] (35), [-0.01003,   inf] (35), [-0.00942,   inf] (35), [-0.00891,   inf] (35), [-0.00777,   inf] (35), [-0.00748,   inf] (35), [-0.00633,   inf] (35), [-0.00606,   inf] (35), [-0.00561,   inf] (35), [-0.00529,   inf] (35), [-0.00523,   inf] (35), [-0.00395,   inf] (35), [-0.00387,   inf] (35), [-0.00384,   inf] (35), [-0.00331,   inf] (35), [-0.00285,   inf] (35), [-0.00254,   inf] (35), 
length of domains: 26
Total time: 0.3311	 pickout: 0.0081	 decision: 0.0439	 get_bound: 0.2777	 add_domain: 0.0014
Current lb:-0.015682458877563477
1882 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.227374076843262

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([26, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([26, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 538] [1, 538] [1, 538] [1, 538] [1, 538] [1, 538] [1, 538] [1, 538] [1, 538] [1, 538] 
regular batch size: 2*26, diving batch size 1*0
best_l after optimization: -0.2648710012435913 with beta sum per layer: [0.0, 6.272701263427734, 0.0]
alpha/beta optimization time: 0.25179266929626465
This batch time : update_bounds func: 0.2634	 prepare: 0.0062	 bound: 0.2521	 transfer: 0.0017	 finalize: 0.0032
Accumulated time: update_bounds func: 4.2753	 prepare: 0.2021	 bound: 3.7944	 transfer: 0.0017	 finalize: 0.1716
batch bounding time:  0.2635834217071533
Current worst splitting domains [lb, ub] (depth):
[-0.01049,   inf] (37), [-0.00813,   inf] (37), [-0.00689,   inf] (37), [-0.00597,   inf] (37), [-0.00484,   inf] (37), [-0.00454,   inf] (37), [-0.00370,   inf] (37), [-0.00251,   inf] (37), [-0.00248,   inf] (37), [-0.00121,   inf] (37), [-0.00119,   inf] (37), [-0.00034,   inf] (37), [-0.00024,   inf] (37), [-0.00018,   inf] (37), 
length of domains: 14
Total time: 0.2985	 pickout: 0.0043	 decision: 0.0298	 get_bound: 0.2637	 add_domain: 0.0008
Current lb:-0.01049374882131815
1934 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.52650761604309

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([14, 16, 16, 16]) pre split depth:  2
batch:  torch.Size([14, 16, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [1, 558] [1, 558] [1, 558] [1, 558] [1, 558] [1, 558] [1, 558] [1, 558] [1, 558] [1, 558] 
split level 1: [1, 1115] [1, 1115] [1, 977] [1, 1115] [1, 1115] [1, 977] [1, 1115] [1, 1115] [1, 977] [1, 1115] 
regular batch size: 2*28, diving batch size 1*0
best_l after optimization: -0.7563616037368774 with beta sum per layer: [0.0, 4.853294372558594, 0.0]
alpha/beta optimization time: 0.25040721893310547
This batch time : update_bounds func: 0.2656	 prepare: 0.0084	 bound: 0.2507	 transfer: 0.0029	 finalize: 0.0034
Accumulated time: update_bounds func: 4.5409	 prepare: 0.2105	 bound: 4.0451	 transfer: 0.0029	 finalize: 0.1750
batch bounding time:  0.2658088207244873
Current worst splitting domains [lb, ub] (depth):
[-0.00009,   inf] (40), 
length of domains: 1
Total time: 0.3127	 pickout: 0.0027	 decision: 0.0401	 get_bound: 0.2697	 add_domain: 0.0002
Current lb:-8.52346420288086e-05
1990 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.83974289894104

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 16, 16]) pre split depth:  6
batch:  torch.Size([1, 16, 16, 16]) post split depth:  6
splitting decisions: 
split level 0: [1, 970] 
split level 1: [1, 977] 
split level 2: [1, 686] 
split level 3: [2, 28] 
split level 4: [1, 1838] 
split level 5: [1, 2034] 
regular batch size: 2*32, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -4.080269813537598 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.008893966674804688
This batch time : update_bounds func: 0.0232	 prepare: 0.0071	 bound: 0.0092	 transfer: 0.0030	 finalize: 0.0038
Accumulated time: update_bounds func: 4.5641	 prepare: 0.2175	 bound: 4.0543	 transfer: 0.0030	 finalize: 0.1787
batch bounding time:  0.023290157318115234
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.1017	 pickout: 0.0008	 decision: 0.0694	 get_bound: 0.0315	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 14.94184422492981

Image 94 label 7 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 15.023234844207764
94 1.0000000116860974e-07
Result: image 94 verification success (with branch and bound)!
Wall time: 15.069456100463867

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 1): [94]
verification failure idx (total 0): []
final verified acc: 100.0%[1]
verifier is called on 1 examples.
total verified: 1
mean time [cnt:1] (excluding attack success): 15.023234844207764
