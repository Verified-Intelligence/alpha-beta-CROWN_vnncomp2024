Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: specify-target
  complete_verifier: bab
  enable_incomplete_verification: false
  get_crown_verified_acc: false
model:
  path: cifar_wide.pth
  name: cifar_model_wide
data:
  start: 89
  end: 90
  num_outputs: 10
  mean: [0.485, 0.456, 0.406]
  std: [0.225, 0.225, 0.225]
  pkl_path: wide_100.pkl
  dataset: CIFAR
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: null
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 1024
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 450
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: fsb
    candidates: 1
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Tue May  3 01:34:28 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Flatten()
  (5): Linear(in_features=2048, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=10, bias=True)
)
No epsilon defined!
Files already downloaded and verified
Overwrite epsilon that saved in .pkl file, they should be after normalized!
Task length: 1
saving results to Verified_ret_[cifar_model_wide]_start=89_end=90_iter=20_b=1024_timeout=450_branching=fsb-min-1_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 89 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 1, correct label 1, image norm 1299.51806640625, logits tensor([ 0.6876,  2.2791, -0.1883, -1.3983, -0.0946, -1.3440,  0.0106, -1.7596,
         0.7654,  1.0421], device='cuda:0', grad_fn=<SelectBackward>)
##### [0:89] Tested against 0 ######
Model prediction is: tensor([[ 0.6876,  2.2791, -0.1883, -1.3983, -0.0946, -1.3440,  0.0106, -1.7596,
          0.7654,  1.0421]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-0.7961]], device='cuda:0') None
best_l after optimization: 0.6387386322021484 with beta sum per layer: []
alpha/beta optimization time: 7.12980842590332
initial alpha-CROWN bounds: tensor([[-0.6387]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.6387, device='cuda:0', grad_fn=<MinBackward1>)
-0.6387386322021484
layer 0 size torch.Size([4096]) unstable 612
layer 1 size torch.Size([2048]) unstable 261
layer 2 size torch.Size([100]) unstable 31
-----------------
# of unstable neurons: 904
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 16, 16]) pre split depth:  6
batch:  torch.Size([1, 16, 16, 16]) post split depth:  6
splitting decisions: 
split level 0: [2, 85] 
split level 1: [2, 43] 
split level 2: [2, 31] 
split level 3: [2, 10] 
split level 4: [2, 98] 
split level 5: [2, 66] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: -12.729637145996094 with beta sum per layer: [0.0, 0.0, 7.320920467376709]
alpha/beta optimization time: 0.27272629737854004
This batch time : update_bounds func: 0.2849	 prepare: 0.0057	 bound: 0.2730	 transfer: 0.0020	 finalize: 0.0039
Accumulated time: update_bounds func: 0.2849	 prepare: 0.0057	 bound: 0.2730	 transfer: 0.0020	 finalize: 0.0039
batch bounding time:  0.2850522994995117
Current worst splitting domains [lb, ub] (depth):
[-0.21307,   inf] (7), [-0.20637,   inf] (7), [-0.19779,   inf] (7), [-0.18196,   inf] (7), [-0.18140,   inf] (7), [-0.17680,   inf] (7), [-0.16378,   inf] (7), [-0.16052,   inf] (7), [-0.05799,   inf] (7), [-0.05363,   inf] (7), [-0.04958,   inf] (7), [-0.04757,   inf] (7), [-0.01381,   inf] (7), [-0.00745,   inf] (7), 
length of domains: 14
Total time: 0.3652	 pickout: 0.0009	 decision: 0.0713	 get_bound: 0.2925	 add_domain: 0.0005
Current lb:-0.21307381987571716
64 neurons visited
0 diving domains visited
Global ub: tensor([[inf]], device='cuda:0'), batch ub: inf
Cumulative time: 9.246215581893921

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([14, 16, 16, 16]) pre split depth:  2
batch:  torch.Size([14, 16, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [2, 89] [2, 89] [2, 89] [2, 89] [2, 89] [2, 89] [2, 89] [2, 89] [2, 89] [2, 89] 
split level 1: [2, 6] [2, 6] [2, 6] [2, 6] [2, 6] [2, 6] [2, 6] [2, 6] [2, 6] [2, 6] 
regular batch size: 2*28, diving batch size 1*0
best_l after optimization: -1.924161434173584 with beta sum per layer: [0.0, 0.0, 27.40994644165039]
alpha/beta optimization time: 0.24684810638427734
This batch time : update_bounds func: 0.2584	 prepare: 0.0060	 bound: 0.2471	 transfer: 0.0018	 finalize: 0.0033
Accumulated time: update_bounds func: 0.5432	 prepare: 0.0117	 bound: 0.5201	 transfer: 0.0018	 finalize: 0.0071
batch bounding time:  0.25852179527282715
Current worst splitting domains [lb, ub] (depth):
[-0.15299,   inf] (10), [-0.14600,   inf] (10), [-0.13595,   inf] (10), [-0.12025,   inf] (10), [-0.11794,   inf] (10), [-0.11248,   inf] (10), [-0.09877,   inf] (10), [-0.09641,   inf] (10), 
length of domains: 8
Total time: 0.3062	 pickout: 0.0028	 decision: 0.0408	 get_bound: 0.2622	 add_domain: 0.0003
Current lb:-0.1529904305934906
120 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.552839279174805

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 16, 16]) pre split depth:  3
batch:  torch.Size([8, 16, 16, 16]) post split depth:  3
splitting decisions: 
split level 0: [2, 34] [2, 34] [2, 34] [2, 34] [2, 34] [2, 34] [2, 34] [2, 34] 
split level 1: [2, 50] [2, 50] [2, 50] [2, 50] [2, 50] [2, 50] [2, 50] [2, 50] 
split level 2: [2, 59] [2, 59] [2, 59] [2, 59] [2, 59] [2, 59] [2, 59] [2, 59] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: -4.31817626953125 with beta sum per layer: [0.0, 0.0, 30.30057144165039]
alpha/beta optimization time: 0.2450869083404541
This batch time : update_bounds func: 0.2608	 prepare: 0.0072	 bound: 0.2454	 transfer: 0.0031	 finalize: 0.0048
Accumulated time: update_bounds func: 0.8040	 prepare: 0.0189	 bound: 0.7655	 transfer: 0.0031	 finalize: 0.0119
batch bounding time:  0.26096296310424805
Current worst splitting domains [lb, ub] (depth):
[-0.10166,   inf] (14), [-0.09402,   inf] (14), [-0.08320,   inf] (14), [-0.06756,   inf] (14), [-0.06317,   inf] (14), [-0.05916,   inf] (14), [-0.04527,   inf] (14), [-0.04209,   inf] (14), 
length of domains: 8
Total time: 0.3219	 pickout: 0.0019	 decision: 0.0492	 get_bound: 0.2702	 add_domain: 0.0006
Current lb:-0.10166345536708832
184 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.87516713142395

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 16, 16]) pre split depth:  3
batch:  torch.Size([8, 16, 16, 16]) post split depth:  3
splitting decisions: 
split level 0: [2, 88] [2, 88] [2, 88] [2, 88] [2, 88] [2, 88] [2, 88] [2, 88] 
split level 1: [1, 533] [1, 533] [1, 533] [1, 793] [1, 1449] [1, 533] [1, 533] [1, 1449] 
split level 2: [1, 1466] [1, 1466] [1, 1466] [1, 1466] [1, 533] [1, 1466] [1, 539] [1, 813] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: -0.0569460391998291 with beta sum per layer: [0.0, 9.76690673828125, 19.614322662353516]
alpha/beta optimization time: 0.24861645698547363
This batch time : update_bounds func: 0.2630	 prepare: 0.0069	 bound: 0.2489	 transfer: 0.0032	 finalize: 0.0038
Accumulated time: update_bounds func: 1.0670	 prepare: 0.0258	 bound: 1.0144	 transfer: 0.0032	 finalize: 0.0157
batch bounding time:  0.2632267475128174
Current worst splitting domains [lb, ub] (depth):
[-0.08645,   inf] (18), [-0.08099,   inf] (18), [-0.07939,   inf] (18), [-0.07441,   inf] (18), [-0.06882,   inf] (18), [-0.06797,   inf] (18), [-0.06357,   inf] (18), [-0.06267,   inf] (18), [-0.05955,   inf] (18), [-0.05464,   inf] (18), [-0.05298,   inf] (18), [-0.05212,   inf] (18), [-0.04964,   inf] (18), [-0.04771,   inf] (18), [-0.04495,   inf] (18), [-0.04356,   inf] (18), [-0.03912,   inf] (18), [-0.03865,   inf] (18), [-0.03661,   inf] (18), [-0.03534,   inf] (18), 
length of domains: 32
Total time: 0.3233	 pickout: 0.0020	 decision: 0.0505	 get_bound: 0.2694	 add_domain: 0.0014
Current lb:-0.08644895255565643
248 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.198843240737915

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([32, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([32, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 820] [1, 820] [1, 820] [1, 820] [1, 820] [1, 1449] [1, 820] [1, 1449] [1, 820] [1, 820] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: 2.373861789703369 with beta sum per layer: [0.0, 6.543704509735107, 12.054465293884277]
alpha/beta optimization time: 0.2785329818725586
This batch time : update_bounds func: 0.2936	 prepare: 0.0074	 bound: 0.2789	 transfer: 0.0019	 finalize: 0.0054
Accumulated time: update_bounds func: 1.3607	 prepare: 0.0332	 bound: 1.2933	 transfer: 0.0019	 finalize: 0.0211
batch bounding time:  0.2938354015350342
Current worst splitting domains [lb, ub] (depth):
[-0.08081,   inf] (20), [-0.08014,   inf] (20), [-0.07520,   inf] (20), [-0.07454,   inf] (20), [-0.07350,   inf] (20), [-0.07237,   inf] (20), [-0.06838,   inf] (20), [-0.06726,   inf] (20), [-0.06291,   inf] (20), [-0.06242,   inf] (20), [-0.06163,   inf] (20), [-0.05731,   inf] (20), [-0.05685,   inf] (20), [-0.05610,   inf] (20), [-0.05571,   inf] (20), [-0.05354,   inf] (20), [-0.05264,   inf] (20), [-0.05023,   inf] (20), [-0.04848,   inf] (20), [-0.04758,   inf] (20), 
length of domains: 64
Total time: 0.3355	 pickout: 0.0056	 decision: 0.0333	 get_bound: 0.2939	 add_domain: 0.0027
Current lb:-0.08081155270338058
312 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.53487229347229

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([64, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 793] [1, 793] [1, 793] [1, 793] [1, 793] [1, 793] [1, 793] [1, 793] [1, 793] [1, 793] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 3.3580360412597656 with beta sum per layer: [0.0, 15.71051025390625, 24.274398803710938]
alpha/beta optimization time: 0.2965221405029297
This batch time : update_bounds func: 0.3340	 prepare: 0.0200	 bound: 0.2969	 transfer: 0.0058	 finalize: 0.0110
Accumulated time: update_bounds func: 1.6947	 prepare: 0.0532	 bound: 1.5902	 transfer: 0.0058	 finalize: 0.0322
batch bounding time:  0.3342611789703369
Current worst splitting domains [lb, ub] (depth):
[-0.07528,   inf] (22), [-0.07469,   inf] (22), [-0.07463,   inf] (22), [-0.07404,   inf] (22), [-0.06953,   inf] (22), [-0.06893,   inf] (22), [-0.06885,   inf] (22), [-0.06826,   inf] (22), [-0.06787,   inf] (22), [-0.06706,   inf] (22), [-0.06674,   inf] (22), [-0.06592,   inf] (22), [-0.06264,   inf] (22), [-0.06181,   inf] (22), [-0.06151,   inf] (22), [-0.06068,   inf] (22), [-0.05719,   inf] (22), [-0.05671,   inf] (22), [-0.05660,   inf] (22), [-0.05612,   inf] (22), 
length of domains: 114
Total time: 0.4221	 pickout: 0.0135	 decision: 0.0692	 get_bound: 0.3345	 add_domain: 0.0048
Current lb:-0.0752820298075676
440 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.957911968231201

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([114, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([114, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 60] [2, 60] [2, 60] [2, 60] [2, 60] [2, 60] [2, 60] [2, 60] [2, 60] [2, 60] 
regular batch size: 2*114, diving batch size 1*0
best_l after optimization: 1.2573280334472656 with beta sum per layer: [0.0, 33.450042724609375, 45.319549560546875]
alpha/beta optimization time: 0.3144841194152832
This batch time : update_bounds func: 0.3812	 prepare: 0.0339	 bound: 0.3148	 transfer: 0.0125	 finalize: 0.0194
Accumulated time: update_bounds func: 2.0759	 prepare: 0.0871	 bound: 1.9050	 transfer: 0.0125	 finalize: 0.0516
batch bounding time:  0.3815171718597412
Current worst splitting domains [lb, ub] (depth):
[-0.07127,   inf] (24), [-0.07067,   inf] (24), [-0.07061,   inf] (24), [-0.07001,   inf] (24), [-0.06535,   inf] (24), [-0.06474,   inf] (24), [-0.06469,   inf] (24), [-0.06410,   inf] (24), [-0.06391,   inf] (24), [-0.06313,   inf] (24), [-0.06279,   inf] (24), [-0.06201,   inf] (24), [-0.05848,   inf] (24), [-0.05770,   inf] (24), [-0.05740,   inf] (24), [-0.05662,   inf] (24), [-0.05301,   inf] (24), [-0.05249,   inf] (24), [-0.05241,   inf] (24), [-0.05190,   inf] (24), 
length of domains: 147
Total time: 0.5230	 pickout: 0.0228	 decision: 0.1119	 get_bound: 0.3819	 add_domain: 0.0065
Current lb:-0.07126712799072266
668 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.48272156715393

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([147, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([147, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 987] [1, 987] [1, 987] [1, 987] [1, 987] [1, 987] [1, 987] [1, 987] [1, 813] [1, 813] 
regular batch size: 2*147, diving batch size 1*0
best_l after optimization: 5.084375381469727 with beta sum per layer: [0.0, 54.53076934814453, 48.120643615722656]
alpha/beta optimization time: 0.327392578125
This batch time : update_bounds func: 0.4110	 prepare: 0.0442	 bound: 0.3278	 transfer: 0.0117	 finalize: 0.0266
Accumulated time: update_bounds func: 2.4869	 prepare: 0.1314	 bound: 2.2328	 transfer: 0.0117	 finalize: 0.0782
batch bounding time:  0.41135191917419434
Current worst splitting domains [lb, ub] (depth):
[-0.06780,   inf] (26), [-0.06713,   inf] (26), [-0.06711,   inf] (26), [-0.06645,   inf] (26), [-0.06187,   inf] (26), [-0.06121,   inf] (26), [-0.06118,   inf] (26), [-0.06052,   inf] (26), [-0.06021,   inf] (26), [-0.05946,   inf] (26), [-0.05943,   inf] (26), [-0.05926,   inf] (26), [-0.05907,   inf] (26), [-0.05882,   inf] (26), [-0.05864,   inf] (26), [-0.05830,   inf] (26), [-0.05478,   inf] (26), [-0.05400,   inf] (26), [-0.05364,   inf] (26), [-0.05343,   inf] (26), 
length of domains: 242
Total time: 0.5901	 pickout: 0.0296	 decision: 0.1379	 get_bound: 0.4118	 add_domain: 0.0108
Current lb:-0.06779813766479492
962 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.075166463851929

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([242, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([242, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1449] [1, 1449] [1, 1449] [1, 1449] [1, 1449] [1, 1449] [1, 1449] [1, 1449] [1, 539] [1, 1449] 
regular batch size: 2*242, diving batch size 1*0
best_l after optimization: 6.427764892578125 with beta sum per layer: [0.0, 102.92422485351562, 66.09732055664062]
alpha/beta optimization time: 0.3818318843841553
This batch time : update_bounds func: 0.5176	 prepare: 0.0733	 bound: 0.3823	 transfer: 0.0182	 finalize: 0.0427
Accumulated time: update_bounds func: 3.0045	 prepare: 0.2046	 bound: 2.6150	 transfer: 0.0182	 finalize: 0.1210
batch bounding time:  0.5182254314422607
Current worst splitting domains [lb, ub] (depth):
[-0.06363,   inf] (28), [-0.06298,   inf] (28), [-0.06294,   inf] (28), [-0.06228,   inf] (28), [-0.05915,   inf] (28), [-0.05850,   inf] (28), [-0.05841,   inf] (28), [-0.05780,   inf] (28), [-0.05768,   inf] (28), [-0.05705,   inf] (28), [-0.05698,   inf] (28), [-0.05636,   inf] (28), [-0.05595,   inf] (28), [-0.05524,   inf] (28), [-0.05521,   inf] (28), [-0.05507,   inf] (28), [-0.05480,   inf] (28), [-0.05456,   inf] (28), [-0.05441,   inf] (28), [-0.05408,   inf] (28), 
length of domains: 369
Total time: 0.8013	 pickout: 0.0478	 decision: 0.2174	 get_bound: 0.5190	 add_domain: 0.0171
Current lb:-0.06363227963447571
1446 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.880827903747559

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([369, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([369, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 419] [1, 419] [1, 419] [1, 419] [1, 419] [1, 419] [1, 419] [1, 419] [1, 419] [1, 419] 
regular batch size: 2*369, diving batch size 1*0
best_l after optimization: 6.05751371383667 with beta sum per layer: [0.0, 169.21881103515625, 86.12596893310547]
alpha/beta optimization time: 0.47111988067626953
This batch time : update_bounds func: 0.6622	 prepare: 0.1045	 bound: 0.4715	 transfer: 0.0229	 finalize: 0.0616
Accumulated time: update_bounds func: 3.6667	 prepare: 0.3091	 bound: 3.0866	 transfer: 0.0229	 finalize: 0.1826
batch bounding time:  0.6629507541656494
Current worst splitting domains [lb, ub] (depth):
[-0.05995,   inf] (30), [-0.05929,   inf] (30), [-0.05927,   inf] (30), [-0.05861,   inf] (30), [-0.05486,   inf] (30), [-0.05429,   inf] (30), [-0.05419,   inf] (30), [-0.05398,   inf] (30), [-0.05359,   inf] (30), [-0.05336,   inf] (30), [-0.05329,   inf] (30), [-0.05267,   inf] (30), [-0.05228,   inf] (30), [-0.05160,   inf] (30), [-0.05113,   inf] (30), [-0.05093,   inf] (30), [-0.05074,   inf] (30), [-0.05049,   inf] (30), [-0.05047,   inf] (30), [-0.05028,   inf] (30), 
length of domains: 489
Total time: 1.1418	 pickout: 0.0751	 decision: 0.3787	 get_bound: 0.6641	 add_domain: 0.0239
Current lb:-0.05995170399546623
2184 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.028706550598145

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([489, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([489, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 813] [1, 813] [1, 813] [1, 813] [1, 813] [1, 813] [1, 813] [1, 813] [1, 813] [1, 813] 
regular batch size: 2*489, diving batch size 1*0
best_l after optimization: 13.316025733947754 with beta sum per layer: [0.0, 263.3490295410156, 92.06827545166016]
alpha/beta optimization time: 0.5645480155944824
This batch time : update_bounds func: 0.8169	 prepare: 0.1378	 bound: 0.5649	 transfer: 0.0275	 finalize: 0.0842
Accumulated time: update_bounds func: 4.4836	 prepare: 0.4469	 bound: 3.6515	 transfer: 0.0275	 finalize: 0.2668
batch bounding time:  0.8181111812591553
Current worst splitting domains [lb, ub] (depth):
[-0.05635,   inf] (32), [-0.05569,   inf] (32), [-0.05567,   inf] (32), [-0.05500,   inf] (32), [-0.05087,   inf] (32), [-0.05038,   inf] (32), [-0.05027,   inf] (32), [-0.05022,   inf] (32), [-0.04973,   inf] (32), [-0.04968,   inf] (32), [-0.04955,   inf] (32), [-0.04905,   inf] (32), [-0.04752,   inf] (32), [-0.04733,   inf] (32), [-0.04714,   inf] (32), [-0.04689,   inf] (32), [-0.04680,   inf] (32), [-0.04672,   inf] (32), [-0.04666,   inf] (32), [-0.04649,   inf] (32), 
length of domains: 755
Total time: 1.4336	 pickout: 0.0989	 decision: 0.4281	 get_bound: 0.8196	 add_domain: 0.0870
Current lb:-0.05635404586791992
3162 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.470426082611084

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([755, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([755, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1065] [1, 1065] [1, 1065] [1, 1065] [1, 1065] [1, 1065] [1, 1065] [1, 1065] [1, 1065] [1, 1065] 
regular batch size: 2*755, diving batch size 1*0
best_l after optimization: 18.3884220123291 with beta sum per layer: [0.0, 475.54827880859375, 95.54345703125]
alpha/beta optimization time: 0.7705936431884766
This batch time : update_bounds func: 1.1532	 prepare: 0.2130	 bound: 0.7710	 transfer: 0.0390	 finalize: 0.1264
Accumulated time: update_bounds func: 5.6368	 prepare: 0.6599	 bound: 4.4225	 transfer: 0.0390	 finalize: 0.3932
batch bounding time:  1.15462064743042
Current worst splitting domains [lb, ub] (depth):
[-0.05290,   inf] (34), [-0.05224,   inf] (34), [-0.05223,   inf] (34), [-0.05157,   inf] (34), [-0.04694,   inf] (34), [-0.04685,   inf] (34), [-0.04666,   inf] (34), [-0.04626,   inf] (34), [-0.04625,   inf] (34), [-0.04618,   inf] (34), [-0.04615,   inf] (34), [-0.04603,   inf] (34), [-0.04590,   inf] (34), [-0.04561,   inf] (34), [-0.04554,   inf] (34), [-0.04521,   inf] (34), [-0.04388,   inf] (34), [-0.04375,   inf] (34), [-0.04341,   inf] (34), [-0.04322,   inf] (34), 
length of domains: 1117
Total time: 2.1040	 pickout: 0.1638	 decision: 0.6587	 get_bound: 1.1569	 add_domain: 0.1246
Current lb:-0.05289561673998833
4672 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.587786197662354

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 539] [1, 539] [1, 539] [1, 539] [1, 539] [1, 539] [1, 539] [1, 539] [1, 539] [1, 539] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 24.483381271362305 with beta sum per layer: [0.0, 738.4376831054688, 47.07997131347656]
alpha/beta optimization time: 0.989732027053833
This batch time : update_bounds func: 1.5703	 prepare: 0.2883	 bound: 0.9901	 transfer: 0.0648	 finalize: 0.2218
Accumulated time: update_bounds func: 7.2071	 prepare: 0.9482	 bound: 5.4127	 transfer: 0.0648	 finalize: 0.6149
batch bounding time:  1.5720579624176025
Current worst splitting domains [lb, ub] (depth):
[-0.04882,   inf] (36), [-0.04815,   inf] (36), [-0.04807,   inf] (36), [-0.04742,   inf] (36), [-0.04285,   inf] (36), [-0.04262,   inf] (36), [-0.04254,   inf] (36), [-0.04219,   inf] (36), [-0.04210,   inf] (36), [-0.04199,   inf] (36), [-0.04196,   inf] (36), [-0.04189,   inf] (36), [-0.04186,   inf] (36), [-0.04184,   inf] (36), [-0.04169,   inf] (36), [-0.04145,   inf] (36), [-0.04131,   inf] (36), [-0.04121,   inf] (36), [-0.04117,   inf] (36), [-0.04104,   inf] (36), 
length of domains: 1806
Total time: 2.7835	 pickout: 0.2171	 decision: 0.8999	 get_bound: 1.5752	 add_domain: 0.0913
Current lb:-0.04881653934717178
6720 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 20.38931655883789

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1776] [1, 1776] [1, 1776] [1, 1776] [1, 1776] [1, 1776] [1, 1776] [1, 1776] [1, 1776] [1, 1776] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 31.727603912353516 with beta sum per layer: [0.0, 700.6117553710938, 9.86290168762207]
alpha/beta optimization time: 0.9892034530639648
This batch time : update_bounds func: 1.5371	 prepare: 0.2994	 bound: 0.9897	 transfer: 0.0693	 finalize: 0.1729
Accumulated time: update_bounds func: 8.7442	 prepare: 1.2475	 bound: 6.4024	 transfer: 0.0693	 finalize: 0.7878
batch bounding time:  1.5391895771026611
Current worst splitting domains [lb, ub] (depth):
[-0.04415,   inf] (38), [-0.04398,   inf] (38), [-0.04349,   inf] (38), [-0.04338,   inf] (38), [-0.04332,   inf] (38), [-0.04323,   inf] (38), [-0.04273,   inf] (38), [-0.04257,   inf] (38), [-0.03821,   inf] (38), [-0.03816,   inf] (38), [-0.03799,   inf] (38), [-0.03789,   inf] (38), [-0.03759,   inf] (38), [-0.03756,   inf] (38), [-0.03752,   inf] (38), [-0.03744,   inf] (38), [-0.03739,   inf] (38), [-0.03735,   inf] (38), [-0.03725,   inf] (38), [-0.03725,   inf] (38), 
length of domains: 2830
Total time: 2.9030	 pickout: 0.2177	 decision: 0.9411	 get_bound: 1.5427	 add_domain: 0.2015
Current lb:-0.04414796829223633
8768 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 23.308042287826538

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 700] [1, 700] [1, 700] [1, 700] [1, 700] [1, 700] [1, 700] [1, 700] [1, 700] [1, 700] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 35.05897521972656 with beta sum per layer: [0.0, 641.52685546875, 3.0345544815063477]
alpha/beta optimization time: 0.9817245006561279
This batch time : update_bounds func: 1.5964	 prepare: 0.2898	 bound: 0.9822	 transfer: 0.0704	 finalize: 0.2489
Accumulated time: update_bounds func: 10.3407	 prepare: 1.5373	 bound: 7.3846	 transfer: 0.0704	 finalize: 1.0367
batch bounding time:  1.5986053943634033
Current worst splitting domains [lb, ub] (depth):
[-0.03997,   inf] (40), [-0.03983,   inf] (40), [-0.03980,   inf] (40), [-0.03966,   inf] (40), [-0.03922,   inf] (40), [-0.03907,   inf] (40), [-0.03907,   inf] (40), [-0.03901,   inf] (40), [-0.03893,   inf] (40), [-0.03884,   inf] (40), [-0.03825,   inf] (40), [-0.03811,   inf] (40), [-0.03672,   inf] (40), [-0.03655,   inf] (40), [-0.03598,   inf] (40), [-0.03583,   inf] (40), [-0.03398,   inf] (40), [-0.03392,   inf] (40), [-0.03384,   inf] (40), [-0.03383,   inf] (40), 
length of domains: 3854
Total time: 2.8270	 pickout: 0.2213	 decision: 0.8858	 get_bound: 1.6020	 add_domain: 0.1179
Current lb:-0.039970822632312775
10816 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 26.150716304779053

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1638] [1, 1638] [1, 1638] [1, 1638] [1, 1638] [1, 1638] [1, 1638] [1, 1638] [1, 1638] [1, 1638] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 35.819305419921875 with beta sum per layer: [0.0, 552.3827514648438, 0.3417760729789734]
alpha/beta optimization time: 0.9683914184570312
This batch time : update_bounds func: 1.5153	 prepare: 0.2963	 bound: 0.9689	 transfer: 0.0703	 finalize: 0.1744
Accumulated time: update_bounds func: 11.8559	 prepare: 1.8336	 bound: 8.3534	 transfer: 0.0703	 finalize: 1.2111
batch bounding time:  1.5173256397247314
Current worst splitting domains [lb, ub] (depth):
[-0.03562,   inf] (42), [-0.03548,   inf] (42), [-0.03545,   inf] (42), [-0.03531,   inf] (42), [-0.03531,   inf] (42), [-0.03517,   inf] (42), [-0.03514,   inf] (42), [-0.03500,   inf] (42), [-0.03486,   inf] (42), [-0.03473,   inf] (42), [-0.03472,   inf] (42), [-0.03465,   inf] (42), [-0.03458,   inf] (42), [-0.03455,   inf] (42), [-0.03448,   inf] (42), [-0.03442,   inf] (42), [-0.03442,   inf] (42), [-0.03434,   inf] (42), [-0.03428,   inf] (42), [-0.03417,   inf] (42), 
length of domains: 4878
Total time: 2.9404	 pickout: 0.2202	 decision: 0.9781	 get_bound: 1.5207	 add_domain: 0.2214
Current lb:-0.03561633080244064
12864 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 29.10538959503174

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 27] [2, 27] [2, 27] [2, 27] [2, 27] [2, 27] [2, 27] [2, 27] [2, 27] [2, 27] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 20.37980842590332 with beta sum per layer: [0.0, 450.4459228515625, 341.7554626464844]
alpha/beta optimization time: 0.9855971336364746
This batch time : update_bounds func: 1.6599	 prepare: 0.2991	 bound: 0.9861	 transfer: 0.0691	 finalize: 0.3002
Accumulated time: update_bounds func: 13.5158	 prepare: 2.1327	 bound: 9.3395	 transfer: 0.0691	 finalize: 1.5113
batch bounding time:  1.661992073059082
Current worst splitting domains [lb, ub] (depth):
[-0.03382,   inf] (44), [-0.03368,   inf] (44), [-0.03365,   inf] (44), [-0.03351,   inf] (44), [-0.03350,   inf] (44), [-0.03337,   inf] (44), [-0.03333,   inf] (44), [-0.03320,   inf] (44), [-0.03305,   inf] (44), [-0.03292,   inf] (44), [-0.03291,   inf] (44), [-0.03284,   inf] (44), [-0.03278,   inf] (44), [-0.03274,   inf] (44), [-0.03267,   inf] (44), [-0.03261,   inf] (44), [-0.03260,   inf] (44), [-0.03252,   inf] (44), [-0.03247,   inf] (44), [-0.03235,   inf] (44), 
length of domains: 5231
Total time: 2.8517	 pickout: 0.2171	 decision: 0.8858	 get_bound: 1.6654	 add_domain: 0.0834
Current lb:-0.0338154137134552
14912 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 31.975762128829956

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1049] [1, 1049] [1, 1049] [1, 1049] [1, 1049] [1, 1049] [1, 1049] [1, 1049] [1, 1049] [1, 1049] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 11.847453117370605 with beta sum per layer: [0.0, 569.1099853515625, 29.673635482788086]
alpha/beta optimization time: 0.9776718616485596
This batch time : update_bounds func: 1.5229	 prepare: 0.2971	 bound: 0.9781	 transfer: 0.0664	 finalize: 0.1760
Accumulated time: update_bounds func: 15.0388	 prepare: 2.4298	 bound: 10.3177	 transfer: 0.0664	 finalize: 1.6873
batch bounding time:  1.5246901512145996
Current worst splitting domains [lb, ub] (depth):
[-0.03288,   inf] (46), [-0.03275,   inf] (46), [-0.03271,   inf] (46), [-0.03258,   inf] (46), [-0.03257,   inf] (46), [-0.03245,   inf] (46), [-0.03240,   inf] (46), [-0.03227,   inf] (46), [-0.03200,   inf] (46), [-0.03190,   inf] (46), [-0.03186,   inf] (46), [-0.03183,   inf] (46), [-0.03173,   inf] (46), [-0.03171,   inf] (46), [-0.03169,   inf] (46), [-0.03160,   inf] (46), [-0.03155,   inf] (46), [-0.03152,   inf] (46), [-0.03143,   inf] (46), [-0.03140,   inf] (46), 
length of domains: 5324
Total time: 2.8175	 pickout: 0.2182	 decision: 1.0029	 get_bound: 1.5278	 add_domain: 0.0687
Current lb:-0.032882653176784515
16960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 34.81397032737732

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 417] [1, 417] [1, 417] [1, 417] [1, 417] [1, 417] [1, 417] [1, 417] [1, 417] [1, 417] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 23.349716186523438 with beta sum per layer: [0.0, 534.8764038085938, 79.448486328125]
alpha/beta optimization time: 0.9732072353363037
This batch time : update_bounds func: 1.5133	 prepare: 0.2935	 bound: 0.9736	 transfer: 0.0692	 finalize: 0.1714
Accumulated time: update_bounds func: 16.5521	 prepare: 2.7234	 bound: 11.2913	 transfer: 0.0692	 finalize: 1.8587
batch bounding time:  1.515232801437378
Current worst splitting domains [lb, ub] (depth):
[-0.02886,   inf] (48), [-0.02874,   inf] (48), [-0.02869,   inf] (48), [-0.02857,   inf] (48), [-0.02855,   inf] (48), [-0.02843,   inf] (48), [-0.02838,   inf] (48), [-0.02826,   inf] (48), [-0.02797,   inf] (48), [-0.02788,   inf] (48), [-0.02784,   inf] (48), [-0.02782,   inf] (48), [-0.02772,   inf] (48), [-0.02768,   inf] (48), [-0.02768,   inf] (48), [-0.02757,   inf] (48), [-0.02753,   inf] (48), [-0.02751,   inf] (48), [-0.02740,   inf] (48), [-0.02737,   inf] (48), 
length of domains: 6081
Total time: 2.9746	 pickout: 0.2237	 decision: 0.9989	 get_bound: 1.5183	 add_domain: 0.2337
Current lb:-0.02886056900024414
19008 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 37.8063006401062

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2041] [1, 2041] [1, 2041] [1, 2041] [1, 2041] [1, 2041] [1, 2041] [1, 2041] [1, 2041] [1, 2041] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 21.28436279296875 with beta sum per layer: [0.0, 518.4701538085938, 47.43523406982422]
alpha/beta optimization time: 0.9600450992584229
This batch time : update_bounds func: 1.5868	 prepare: 0.2950	 bound: 0.9604	 transfer: 0.0666	 finalize: 0.2593
Accumulated time: update_bounds func: 18.1389	 prepare: 3.0184	 bound: 12.2517	 transfer: 0.0666	 finalize: 2.1180
batch bounding time:  1.5885217189788818
Current worst splitting domains [lb, ub] (depth):
[-0.02487,   inf] (50), [-0.02473,   inf] (50), [-0.02470,   inf] (50), [-0.02457,   inf] (50), [-0.02455,   inf] (50), [-0.02442,   inf] (50), [-0.02439,   inf] (50), [-0.02426,   inf] (50), [-0.02402,   inf] (50), [-0.02398,   inf] (50), [-0.02389,   inf] (50), [-0.02388,   inf] (50), [-0.02386,   inf] (50), [-0.02383,   inf] (50), [-0.02372,   inf] (50), [-0.02370,   inf] (50), [-0.02369,   inf] (50), [-0.02369,   inf] (50), [-0.02368,   inf] (50), [-0.02358,   inf] (50), 
length of domains: 6825
Total time: 2.8092	 pickout: 0.2223	 decision: 0.8854	 get_bound: 1.5915	 add_domain: 0.1100
Current lb:-0.024869441986083984
21056 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 40.633469581604004

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1777] [1, 1777] [1, 1777] [1, 1777] [1, 1777] [1, 1777] [1, 1777] [1, 1777] [1, 1777] [1, 1777] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 7.335818767547607 with beta sum per layer: [0.0, 502.55706787109375, 36.42803955078125]
alpha/beta optimization time: 0.9457094669342041
This batch time : update_bounds func: 1.4880	 prepare: 0.2041	 bound: 0.9460	 transfer: 0.0671	 finalize: 0.2652
Accumulated time: update_bounds func: 19.6270	 prepare: 3.2224	 bound: 13.1977	 transfer: 0.0671	 finalize: 2.3832
batch bounding time:  1.4898171424865723
Current worst splitting domains [lb, ub] (depth):
[-0.02257,   inf] (52), [-0.02243,   inf] (52), [-0.02237,   inf] (52), [-0.02226,   inf] (52), [-0.02223,   inf] (52), [-0.02212,   inf] (52), [-0.02206,   inf] (52), [-0.02192,   inf] (52), [-0.02168,   inf] (52), [-0.02168,   inf] (52), [-0.02159,   inf] (52), [-0.02156,   inf] (52), [-0.02155,   inf] (52), [-0.02149,   inf] (52), [-0.02139,   inf] (52), [-0.02138,   inf] (52), [-0.02137,   inf] (52), [-0.02136,   inf] (52), [-0.02128,   inf] (52), [-0.02128,   inf] (52), 
length of domains: 7043
Total time: 2.4117	 pickout: 0.1659	 decision: 0.6720	 get_bound: 1.4929	 add_domain: 0.0809
Current lb:-0.022566795349121094
23104 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 43.06890058517456

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 982] [1, 982] [1, 982] [1, 982] [1, 982] [1, 982] [1, 982] [1, 982] [1, 982] [1, 982] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5.243974685668945 with beta sum per layer: [0.0, 579.9070434570312, 52.69207000732422]
alpha/beta optimization time: 0.955467939376831
This batch time : update_bounds func: 1.3654	 prepare: 0.2042	 bound: 0.9558	 transfer: 0.0689	 finalize: 0.1303
Accumulated time: update_bounds func: 20.9924	 prepare: 3.4267	 bound: 14.1535	 transfer: 0.0689	 finalize: 2.5136
batch bounding time:  1.3672196865081787
Current worst splitting domains [lb, ub] (depth):
[-0.02145,   inf] (54), [-0.02132,   inf] (54), [-0.02126,   inf] (54), [-0.02114,   inf] (54), [-0.02113,   inf] (54), [-0.02101,   inf] (54), [-0.02094,   inf] (54), [-0.02081,   inf] (54), [-0.02057,   inf] (54), [-0.02055,   inf] (54), [-0.02048,   inf] (54), [-0.02044,   inf] (54), [-0.02042,   inf] (54), [-0.02038,   inf] (54), [-0.02027,   inf] (54), [-0.02026,   inf] (54), [-0.02025,   inf] (54), [-0.02024,   inf] (54), [-0.02017,   inf] (54), [-0.02016,   inf] (54), 
length of domains: 7390
Total time: 2.4495	 pickout: 0.1683	 decision: 0.8231	 get_bound: 1.3702	 add_domain: 0.0879
Current lb:-0.021450042724609375
25152 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 45.542720794677734

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 893] [1, 893] [1, 893] [1, 893] [1, 893] [1, 893] [1, 893] [1, 893] [1, 893] [1, 893] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 13.884654998779297 with beta sum per layer: [0.0, 528.9639892578125, 42.62438201904297]
alpha/beta optimization time: 0.9576027393341064
This batch time : update_bounds func: 1.3611	 prepare: 0.2019	 bound: 0.9579	 transfer: 0.0669	 finalize: 0.1278
Accumulated time: update_bounds func: 22.3534	 prepare: 3.6285	 bound: 15.1115	 transfer: 0.0669	 finalize: 2.6414
batch bounding time:  1.3629815578460693
Current worst splitting domains [lb, ub] (depth):
[-0.01791,   inf] (56), [-0.01772,   inf] (56), [-0.01762,   inf] (56), [-0.01760,   inf] (56), [-0.01758,   inf] (56), [-0.01752,   inf] (56), [-0.01742,   inf] (56), [-0.01741,   inf] (56), [-0.01740,   inf] (56), [-0.01732,   inf] (56), [-0.01731,   inf] (56), [-0.01728,   inf] (56), [-0.01721,   inf] (56), [-0.01711,   inf] (56), [-0.01709,   inf] (56), [-0.01708,   inf] (56), [-0.01703,   inf] (56), [-0.01702,   inf] (56), [-0.01701,   inf] (56), [-0.01690,   inf] (56), 
length of domains: 8038
Total time: 2.4868	 pickout: 0.1695	 decision: 0.8410	 get_bound: 1.3662	 add_domain: 0.1101
Current lb:-0.017908301204442978
27200 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 48.05134987831116

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 531] [1, 531] [1, 531] [1, 531] [1, 531] [1, 531] [1, 531] [1, 531] [1, 531] [1, 531] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 11.876668930053711 with beta sum per layer: [0.0, 528.8511962890625, 47.638755798339844]
alpha/beta optimization time: 0.9630827903747559
This batch time : update_bounds func: 1.3767	 prepare: 0.2051	 bound: 0.9634	 transfer: 0.0699	 finalize: 0.1321
Accumulated time: update_bounds func: 23.7301	 prepare: 3.8336	 bound: 16.0749	 transfer: 0.0699	 finalize: 2.7735
batch bounding time:  1.3785717487335205
Current worst splitting domains [lb, ub] (depth):
[-0.01458,   inf] (58), [-0.01439,   inf] (58), [-0.01429,   inf] (58), [-0.01426,   inf] (58), [-0.01425,   inf] (58), [-0.01419,   inf] (58), [-0.01410,   inf] (58), [-0.01407,   inf] (58), [-0.01406,   inf] (58), [-0.01400,   inf] (58), [-0.01397,   inf] (58), [-0.01394,   inf] (58), [-0.01387,   inf] (58), [-0.01379,   inf] (58), [-0.01375,   inf] (58), [-0.01372,   inf] (58), [-0.01368,   inf] (58), [-0.01368,   inf] (58), [-0.01367,   inf] (58), [-0.01363,   inf] (58), 
length of domains: 8638
Total time: 2.6930	 pickout: 0.1690	 decision: 0.8382	 get_bound: 1.3817	 add_domain: 0.3042
Current lb:-0.014575481414794922
29248 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 50.766237020492554

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 308] [1, 308] [1, 308] [1, 308] [1, 308] [1, 308] [1, 308] [1, 308] [1, 308] [1, 308] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 8.58193588256836 with beta sum per layer: [0.0, 586.8460083007812, 32.8099365234375]
alpha/beta optimization time: 0.9549870491027832
This batch time : update_bounds func: 1.3584	 prepare: 0.2008	 bound: 0.9553	 transfer: 0.0683	 finalize: 0.1277
Accumulated time: update_bounds func: 25.0886	 prepare: 4.0344	 bound: 17.0302	 transfer: 0.0683	 finalize: 2.9012
batch bounding time:  1.360243320465088
Current worst splitting domains [lb, ub] (depth):
[-0.01247,   inf] (60), [-0.01229,   inf] (60), [-0.01220,   inf] (60), [-0.01216,   inf] (60), [-0.01209,   inf] (60), [-0.01201,   inf] (60), [-0.01200,   inf] (60), [-0.01197,   inf] (60), [-0.01191,   inf] (60), [-0.01188,   inf] (60), [-0.01182,   inf] (60), [-0.01178,   inf] (60), [-0.01170,   inf] (60), [-0.01169,   inf] (60), [-0.01166,   inf] (50), [-0.01166,   inf] (50), [-0.01165,   inf] (42), [-0.01165,   inf] (44), [-0.01165,   inf] (40), [-0.01165,   inf] (52), 
length of domains: 9108
Total time: 2.3118	 pickout: 0.1728	 decision: 0.6785	 get_bound: 1.3633	 add_domain: 0.0971
Current lb:-0.012470497749745846
31296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 53.10199737548828

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1147] [1, 1147] [1, 1147] [1, 1147] [1, 1147] [1, 1147] [1, 1147] [1, 1147] [1, 1147] [1, 1147] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 7.480751037597656 with beta sum per layer: [0.0, 599.556640625, 36.42913818359375]
alpha/beta optimization time: 0.9556436538696289
This batch time : update_bounds func: 1.3637	 prepare: 0.1998	 bound: 0.9560	 transfer: 0.0714	 finalize: 0.1300
Accumulated time: update_bounds func: 26.4522	 prepare: 4.2343	 bound: 17.9862	 transfer: 0.0714	 finalize: 3.0312
batch bounding time:  1.3655436038970947
Current worst splitting domains [lb, ub] (depth):
[-0.01111,   inf] (44), [-0.01111,   inf] (38), [-0.01111,   inf] (48), [-0.01111,   inf] (38), [-0.01111,   inf] (48), [-0.01111,   inf] (42), [-0.01111,   inf] (50), [-0.01111,   inf] (46), [-0.01110,   inf] (44), [-0.01110,   inf] (60), [-0.01110,   inf] (58), [-0.01110,   inf] (54), [-0.01110,   inf] (46), [-0.01110,   inf] (44), [-0.01110,   inf] (56), [-0.01110,   inf] (48), [-0.01110,   inf] (44), [-0.01110,   inf] (52), [-0.01110,   inf] (40), [-0.01110,   inf] (44), 
length of domains: 9621
Total time: 2.5155	 pickout: 0.1737	 decision: 0.8718	 get_bound: 1.3687	 add_domain: 0.1013
Current lb:-0.011110068298876286
33344 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 55.642107248306274

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1777] [1, 700] [1, 2041] [1, 700] [1, 2041] [1, 1638] [1, 1777] [1, 417] [1, 1049] [1, 1147] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 6.308455467224121 with beta sum per layer: [0.0, 622.4599609375, 37.40382385253906]
alpha/beta optimization time: 0.9553601741790771
This batch time : update_bounds func: 1.3746	 prepare: 0.2060	 bound: 0.9557	 transfer: 0.0687	 finalize: 0.1358
Accumulated time: update_bounds func: 27.8268	 prepare: 4.4403	 bound: 18.9419	 transfer: 0.0687	 finalize: 3.1670
batch bounding time:  1.3765208721160889
Current worst splitting domains [lb, ub] (depth):
[-0.01059,   inf] (50), [-0.01059,   inf] (48), [-0.01059,   inf] (60), [-0.01059,   inf] (46), [-0.01059,   inf] (40), [-0.01059,   inf] (44), [-0.01059,   inf] (42), [-0.01059,   inf] (46), [-0.01059,   inf] (50), [-0.01059,   inf] (48), [-0.01059,   inf] (44), [-0.01059,   inf] (46), [-0.01059,   inf] (44), [-0.01059,   inf] (56), [-0.01059,   inf] (38), [-0.01059,   inf] (40), [-0.01059,   inf] (50), [-0.01059,   inf] (48), [-0.01059,   inf] (48), [-0.01059,   inf] (44), 
length of domains: 10129
Total time: 2.5502	 pickout: 0.1734	 decision: 0.8933	 get_bound: 1.3798	 add_domain: 0.1037
Current lb:-0.010594367980957031
35392 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 58.217084646224976

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1777] [1, 2041] [1, 1147] [1, 417] [1, 1638] [1, 1049] [2, 27] [1, 417] [1, 1777] [1, 2041] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5.881190299987793 with beta sum per layer: [0.0, 617.9844360351562, 33.045692443847656]
alpha/beta optimization time: 0.9621663093566895
This batch time : update_bounds func: 1.3682	 prepare: 0.1998	 bound: 0.9625	 transfer: 0.0686	 finalize: 0.1308
Accumulated time: update_bounds func: 29.1950	 prepare: 4.6401	 bound: 19.9044	 transfer: 0.0686	 finalize: 3.2978
batch bounding time:  1.3701121807098389
Current worst splitting domains [lb, ub] (depth):
[-0.01011,   inf] (50), [-0.01011,   inf] (54), [-0.01011,   inf] (42), [-0.01011,   inf] (48), [-0.01011,   inf] (44), [-0.01011,   inf] (46), [-0.01011,   inf] (46), [-0.01010,   inf] (42), [-0.01010,   inf] (42), [-0.01010,   inf] (58), [-0.01010,   inf] (50), [-0.01010,   inf] (42), [-0.01010,   inf] (42), [-0.01010,   inf] (54), [-0.01010,   inf] (46), [-0.01010,   inf] (56), [-0.01010,   inf] (38), [-0.01010,   inf] (42), [-0.01010,   inf] (48), [-0.01010,   inf] (38), 
length of domains: 10674
Total time: 2.5665	 pickout: 0.1737	 decision: 0.9155	 get_bound: 1.3733	 add_domain: 0.1040
Current lb:-0.010106873698532581
37440 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 60.808565855026245

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1777] [1, 893] [2, 27] [1, 2041] [1, 1777] [1, 417] [1, 417] [2, 27] [1, 1638] [1, 308] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5.177204132080078 with beta sum per layer: [0.0, 636.1527099609375, 38.91373062133789]
alpha/beta optimization time: 0.9569649696350098
This batch time : update_bounds func: 1.3516	 prepare: 0.1982	 bound: 0.9573	 transfer: 0.0562	 finalize: 0.1333
Accumulated time: update_bounds func: 30.5465	 prepare: 4.8383	 bound: 20.8617	 transfer: 0.0562	 finalize: 3.4312
batch bounding time:  1.3534977436065674
Current worst splitting domains [lb, ub] (depth):
[-0.00968,   inf] (42), [-0.00968,   inf] (48), [-0.00968,   inf] (48), [-0.00968,   inf] (48), [-0.00968,   inf] (44), [-0.00968,   inf] (44), [-0.00968,   inf] (52), [-0.00968,   inf] (42), [-0.00968,   inf] (52), [-0.00968,   inf] (48), [-0.00968,   inf] (42), [-0.00968,   inf] (54), [-0.00968,   inf] (50), [-0.00968,   inf] (40), [-0.00968,   inf] (50), [-0.00968,   inf] (52), [-0.00968,   inf] (50), [-0.00967,   inf] (46), [-0.00967,   inf] (38), [-0.00967,   inf] (50), 
length of domains: 11234
Total time: 2.5687	 pickout: 0.1693	 decision: 0.9364	 get_bound: 1.3568	 add_domain: 0.1063
Current lb:-0.009681224822998047
39488 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 63.40310859680176

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1638] [1, 2041] [1, 2041] [1, 2041] [1, 1049] [1, 1777] [1, 893] [1, 1638] [1, 982] [1, 2041] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 4.181585311889648 with beta sum per layer: [0.0, 642.793701171875, 42.26531982421875]
alpha/beta optimization time: 0.9583327770233154
This batch time : update_bounds func: 1.3726	 prepare: 0.2041	 bound: 0.9587	 transfer: 0.0684	 finalize: 0.1344
Accumulated time: update_bounds func: 31.9191	 prepare: 5.0424	 bound: 21.8204	 transfer: 0.0684	 finalize: 3.5656
batch bounding time:  1.3744721412658691
Current worst splitting domains [lb, ub] (depth):
[-0.00924,   inf] (50), [-0.00923,   inf] (52), [-0.00923,   inf] (52), [-0.00923,   inf] (46), [-0.00923,   inf] (46), [-0.00923,   inf] (58), [-0.00923,   inf] (50), [-0.00923,   inf] (38), [-0.00923,   inf] (48), [-0.00923,   inf] (40), [-0.00923,   inf] (46), [-0.00923,   inf] (56), [-0.00923,   inf] (42), [-0.00923,   inf] (50), [-0.00923,   inf] (42), [-0.00923,   inf] (48), [-0.00923,   inf] (54), [-0.00923,   inf] (50), [-0.00923,   inf] (44), [-0.00923,   inf] (52), 
length of domains: 11765
Total time: 2.5936	 pickout: 0.1736	 decision: 0.9405	 get_bound: 1.3776	 add_domain: 0.1019
Current lb:-0.009235858917236328
41536 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 66.02283787727356

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1777] [1, 893] [1, 982] [2, 27] [2, 27] [1, 308] [1, 1777] [1, 700] [1, 2041] [1, 2041] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 3.641602039337158 with beta sum per layer: [0.0, 638.5452880859375, 35.835968017578125]
alpha/beta optimization time: 0.9549307823181152
This batch time : update_bounds func: 1.6329	 prepare: 0.2001	 bound: 0.9553	 transfer: 0.0684	 finalize: 0.4024
Accumulated time: update_bounds func: 33.5520	 prepare: 5.2425	 bound: 22.7757	 transfer: 0.0684	 finalize: 3.9681
batch bounding time:  1.6347694396972656
Current worst splitting domains [lb, ub] (depth):
[-0.00884,   inf] (44), [-0.00884,   inf] (52), [-0.00884,   inf] (56), [-0.00884,   inf] (44), [-0.00884,   inf] (48), [-0.00884,   inf] (50), [-0.00884,   inf] (40), [-0.00884,   inf] (50), [-0.00884,   inf] (56), [-0.00884,   inf] (50), [-0.00884,   inf] (40), [-0.00884,   inf] (56), [-0.00884,   inf] (36), [-0.00884,   inf] (46), [-0.00883,   inf] (40), [-0.00883,   inf] (48), [-0.00883,   inf] (54), [-0.00883,   inf] (48), [-0.00883,   inf] (52), [-0.00883,   inf] (42), 
length of domains: 12258
Total time: 2.5969	 pickout: 0.1733	 decision: 0.6831	 get_bound: 1.6380	 add_domain: 0.1025
Current lb:-0.008840560913085938
43584 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 68.64692497253418

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1777] [1, 893] [1, 531] [1, 1777] [1, 1049] [1, 982] [1, 1638] [1, 1777] [1, 531] [1, 1777] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 3.010232448577881 with beta sum per layer: [0.0, 660.571533203125, 39.35170364379883]
alpha/beta optimization time: 0.956334114074707
This batch time : update_bounds func: 1.6554	 prepare: 0.2025	 bound: 0.9567	 transfer: 0.0684	 finalize: 0.4210
Accumulated time: update_bounds func: 35.2074	 prepare: 5.4449	 bound: 23.7323	 transfer: 0.0684	 finalize: 4.3891
batch bounding time:  1.6577260494232178
Current worst splitting domains [lb, ub] (depth):
[-0.00844,   inf] (52), [-0.00844,   inf] (52), [-0.00844,   inf] (56), [-0.00844,   inf] (46), [-0.00843,   inf] (50), [-0.00843,   inf] (48), [-0.00843,   inf] (50), [-0.00843,   inf] (40), [-0.00843,   inf] (56), [-0.00843,   inf] (52), [-0.00843,   inf] (48), [-0.00843,   inf] (56), [-0.00843,   inf] (48), [-0.00843,   inf] (46), [-0.00843,   inf] (54), [-0.00843,   inf] (50), [-0.00843,   inf] (42), [-0.00843,   inf] (52), [-0.00843,   inf] (50), [-0.00843,   inf] (40), 
length of domains: 12757
Total time: 2.6235	 pickout: 0.1758	 decision: 0.6851	 get_bound: 1.6613	 add_domain: 0.1013
Current lb:-0.008436203002929688
45632 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 71.29507493972778

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 982] [1, 982] [1, 531] [2, 27] [1, 1777] [1, 2041] [1, 1777] [1, 2041] [1, 531] [1, 982] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 2.3340282440185547 with beta sum per layer: [0.0, 643.218017578125, 36.997161865234375]
alpha/beta optimization time: 0.9576263427734375
This batch time : update_bounds func: 1.3682	 prepare: 0.2014	 bound: 0.9580	 transfer: 0.0684	 finalize: 0.1337
Accumulated time: update_bounds func: 36.5756	 prepare: 5.6463	 bound: 24.6903	 transfer: 0.0684	 finalize: 4.5228
batch bounding time:  1.3701610565185547
Current worst splitting domains [lb, ub] (depth):
[-0.00807,   inf] (54), [-0.00807,   inf] (48), [-0.00807,   inf] (46), [-0.00806,   inf] (46), [-0.00806,   inf] (48), [-0.00806,   inf] (44), [-0.00806,   inf] (52), [-0.00806,   inf] (52), [-0.00806,   inf] (54), [-0.00806,   inf] (46), [-0.00806,   inf] (56), [-0.00806,   inf] (58), [-0.00806,   inf] (50), [-0.00806,   inf] (48), [-0.00806,   inf] (38), [-0.00806,   inf] (42), [-0.00806,   inf] (46), [-0.00806,   inf] (56), [-0.00806,   inf] (50), [-0.00806,   inf] (56), 
length of domains: 13235
Total time: 2.3350	 pickout: 0.1745	 decision: 0.6848	 get_bound: 1.3734	 add_domain: 0.1022
Current lb:-0.008065912872552872
47680 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 73.65713500976562

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 893] [1, 2041] [2, 27] [1, 417] [1, 1049] [1, 1777] [1, 982] [1, 982] [1, 893] [1, 417] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 2.2910261154174805 with beta sum per layer: [0.0, 651.4934692382812, 35.152015686035156]
alpha/beta optimization time: 0.9585542678833008
This batch time : update_bounds func: 1.3743	 prepare: 0.2045	 bound: 0.9589	 transfer: 0.0684	 finalize: 0.1353
Accumulated time: update_bounds func: 37.9499	 prepare: 5.8508	 bound: 25.6492	 transfer: 0.0684	 finalize: 4.6581
batch bounding time:  1.3762907981872559
Current worst splitting domains [lb, ub] (depth):
[-0.00774,   inf] (50), [-0.00774,   inf] (48), [-0.00774,   inf] (52), [-0.00774,   inf] (42), [-0.00774,   inf] (58), [-0.00774,   inf] (54), [-0.00774,   inf] (44), [-0.00773,   inf] (42), [-0.00773,   inf] (52), [-0.00773,   inf] (44), [-0.00773,   inf] (58), [-0.00773,   inf] (42), [-0.00773,   inf] (54), [-0.00773,   inf] (40), [-0.00773,   inf] (54), [-0.00773,   inf] (54), [-0.00773,   inf] (56), [-0.00773,   inf] (42), [-0.00773,   inf] (54), [-0.00773,   inf] (56), 
length of domains: 13730
Total time: 2.6442	 pickout: 0.1740	 decision: 0.9880	 get_bound: 1.3796	 add_domain: 0.1027
Current lb:-0.007737814448773861
49728 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 76.3292179107666

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 982] [1, 2041] [1, 893] [2, 27] [1, 308] [1, 893] [1, 1049] [2, 27] [1, 982] [1, 1049] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1.7147812843322754 with beta sum per layer: [0.0, 638.7567749023438, 34.858116149902344]
alpha/beta optimization time: 0.9574770927429199
This batch time : update_bounds func: 1.6967	 prepare: 0.2033	 bound: 0.9578	 transfer: 0.0686	 finalize: 0.1340
Accumulated time: update_bounds func: 39.6466	 prepare: 6.0541	 bound: 26.6070	 transfer: 0.0686	 finalize: 4.7921
batch bounding time:  1.6986839771270752
Current worst splitting domains [lb, ub] (depth):
[-0.00740,   inf] (56), [-0.00740,   inf] (54), [-0.00740,   inf] (54), [-0.00740,   inf] (54), [-0.00739,   inf] (38), [-0.00739,   inf] (46), [-0.00739,   inf] (46), [-0.00739,   inf] (40), [-0.00739,   inf] (42), [-0.00739,   inf] (52), [-0.00739,   inf] (50), [-0.00739,   inf] (56), [-0.00739,   inf] (44), [-0.00739,   inf] (46), [-0.00739,   inf] (50), [-0.00739,   inf] (44), [-0.00739,   inf] (48), [-0.00739,   inf] (44), [-0.00739,   inf] (56), [-0.00739,   inf] (62), 
length of domains: 14210
Total time: 2.6640	 pickout: 0.1728	 decision: 0.6865	 get_bound: 1.7020	 add_domain: 0.1027
Current lb:-0.007396221160888672
51776 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 79.02092742919922

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 531] [1, 1147] [1, 1147] [1, 893] [1, 700] [1, 417] [1, 417] [1, 2041] [2, 27] [1, 893] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1.0742769241333008 with beta sum per layer: [0.0, 636.0411987304688, 39.31517028808594]
alpha/beta optimization time: 0.9594957828521729
This batch time : update_bounds func: 1.7221	 prepare: 0.2061	 bound: 0.9599	 transfer: 0.0617	 finalize: 0.4874
Accumulated time: update_bounds func: 41.3687	 prepare: 6.2602	 bound: 27.5669	 transfer: 0.0617	 finalize: 5.2795
batch bounding time:  1.7244210243225098
Current worst splitting domains [lb, ub] (depth):
[-0.00709,   inf] (48), [-0.00709,   inf] (52), [-0.00709,   inf] (42), [-0.00709,   inf] (48), [-0.00709,   inf] (44), [-0.00709,   inf] (54), [-0.00709,   inf] (56), [-0.00709,   inf] (52), [-0.00709,   inf] (44), [-0.00709,   inf] (52), [-0.00709,   inf] (50), [-0.00709,   inf] (50), [-0.00709,   inf] (42), [-0.00709,   inf] (52), [-0.00709,   inf] (40), [-0.00709,   inf] (54), [-0.00709,   inf] (46), [-0.00709,   inf] (44), [-0.00708,   inf] (56), [-0.00708,   inf] (56), 
length of domains: 14699
Total time: 2.6894	 pickout: 0.1703	 decision: 0.6882	 get_bound: 1.7281	 add_domain: 0.1028
Current lb:-0.007089788559824228
53824 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 81.73804354667664

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2041] [1, 982] [2, 27] [1, 1049] [1, 1049] [1, 893] [1, 531] [1, 982] [1, 1049] [1, 982] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 0.8035949468612671 with beta sum per layer: [0.0, 643.899169921875, 36.21929931640625]
alpha/beta optimization time: 0.9604010581970215
This batch time : update_bounds func: 1.3641	 prepare: 0.2031	 bound: 0.9608	 transfer: 0.0575	 finalize: 0.1357
Accumulated time: update_bounds func: 42.7329	 prepare: 6.4633	 bound: 28.5277	 transfer: 0.0575	 finalize: 5.4152
batch bounding time:  1.3661084175109863
Current worst splitting domains [lb, ub] (depth):
[-0.00679,   inf] (52), [-0.00679,   inf] (42), [-0.00679,   inf] (48), [-0.00679,   inf] (40), [-0.00679,   inf] (56), [-0.00679,   inf] (58), [-0.00679,   inf] (38), [-0.00679,   inf] (38), [-0.00679,   inf] (46), [-0.00679,   inf] (50), [-0.00679,   inf] (42), [-0.00679,   inf] (46), [-0.00679,   inf] (52), [-0.00679,   inf] (40), [-0.00679,   inf] (62), [-0.00679,   inf] (42), [-0.00679,   inf] (44), [-0.00679,   inf] (58), [-0.00679,   inf] (56), [-0.00679,   inf] (46), 
length of domains: 15180
Total time: 2.3347	 pickout: 0.1719	 decision: 0.6889	 get_bound: 1.3695	 add_domain: 0.1044
Current lb:-0.0067920684814453125
55872 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 84.1023850440979

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 893] [2, 27] [1, 2041] [1, 1638] [1, 531] [1, 538] [1, 700] [1, 700] [2, 27] [1, 1777] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 0.211911141872406 with beta sum per layer: [0.0, 642.2239990234375, 36.65812301635742]
alpha/beta optimization time: 0.9509663581848145
This batch time : update_bounds func: 1.3680	 prepare: 0.2026	 bound: 0.9513	 transfer: 0.0686	 finalize: 0.1383
Accumulated time: update_bounds func: 44.1008	 prepare: 6.6659	 bound: 29.4790	 transfer: 0.0686	 finalize: 5.5535
batch bounding time:  1.3699543476104736
Current worst splitting domains [lb, ub] (depth):
[-0.00651,   inf] (54), [-0.00651,   inf] (36), [-0.00651,   inf] (42), [-0.00651,   inf] (48), [-0.00651,   inf] (56), [-0.00651,   inf] (42), [-0.00651,   inf] (54), [-0.00651,   inf] (46), [-0.00651,   inf] (44), [-0.00651,   inf] (50), [-0.00651,   inf] (58), [-0.00651,   inf] (54), [-0.00651,   inf] (54), [-0.00651,   inf] (52), [-0.00651,   inf] (56), [-0.00651,   inf] (42), [-0.00651,   inf] (42), [-0.00651,   inf] (48), [-0.00651,   inf] (52), [-0.00651,   inf] (40), 
length of domains: 15625
Total time: 2.7020	 pickout: 0.1784	 decision: 1.0502	 get_bound: 1.3733	 add_domain: 0.1001
Current lb:-0.006510734558105469
57920 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 86.8330430984497

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 893] [1, 1776] [2, 27] [1, 2041] [1, 531] [2, 27] [1, 1147] [1, 417] [1, 1777] [1, 982] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -0.5694997310638428 with beta sum per layer: [0.0, 637.821533203125, 34.414817810058594]
alpha/beta optimization time: 0.9519734382629395
This batch time : update_bounds func: 1.7494	 prepare: 0.2077	 bound: 0.9523	 transfer: 0.0685	 finalize: 0.5137
Accumulated time: update_bounds func: 45.8502	 prepare: 6.8737	 bound: 30.4313	 transfer: 0.0685	 finalize: 6.0672
batch bounding time:  1.7514843940734863
Current worst splitting domains [lb, ub] (depth):
[-0.00624,   inf] (42), [-0.00624,   inf] (46), [-0.00624,   inf] (46), [-0.00624,   inf] (58), [-0.00624,   inf] (42), [-0.00624,   inf] (46), [-0.00624,   inf] (56), [-0.00624,   inf] (42), [-0.00624,   inf] (40), [-0.00624,   inf] (42), [-0.00624,   inf] (42), [-0.00624,   inf] (50), [-0.00624,   inf] (42), [-0.00624,   inf] (58), [-0.00624,   inf] (50), [-0.00624,   inf] (54), [-0.00624,   inf] (46), [-0.00624,   inf] (52), [-0.00624,   inf] (46), [-0.00624,   inf] (42), 
length of domains: 15998
Total time: 2.7180	 pickout: 0.1761	 decision: 0.6902	 get_bound: 1.7549	 add_domain: 0.0968
Current lb:-0.006243228912353516
59968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 89.58044219017029

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 27] [1, 417] [1, 417] [1, 308] [2, 27] [1, 417] [1, 531] [2, 27] [1, 1638] [2, 27] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -1.1001319885253906 with beta sum per layer: [0.0, 657.34814453125, 29.14096450805664]
alpha/beta optimization time: 0.9514553546905518
This batch time : update_bounds func: 1.3731	 prepare: 0.2053	 bound: 0.9518	 transfer: 0.0684	 finalize: 0.1409
Accumulated time: update_bounds func: 47.2233	 prepare: 7.0790	 bound: 31.3831	 transfer: 0.0684	 finalize: 6.2081
batch bounding time:  1.375326156616211
Current worst splitting domains [lb, ub] (depth):
[-0.00596,   inf] (56), [-0.00596,   inf] (46), [-0.00596,   inf] (44), [-0.00596,   inf] (58), [-0.00596,   inf] (48), [-0.00596,   inf] (50), [-0.00596,   inf] (44), [-0.00596,   inf] (44), [-0.00596,   inf] (54), [-0.00596,   inf] (52), [-0.00596,   inf] (42), [-0.00596,   inf] (50), [-0.00596,   inf] (44), [-0.00596,   inf] (64), [-0.00596,   inf] (44), [-0.00596,   inf] (58), [-0.00596,   inf] (50), [-0.00596,   inf] (54), [-0.00596,   inf] (36), [-0.00596,   inf] (58), 
length of domains: 16348
Total time: 2.3453	 pickout: 0.1781	 decision: 0.6925	 get_bound: 1.3789	 add_domain: 0.0958
Current lb:-0.005962371826171875
62016 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 91.95608687400818

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 531] [1, 417] [1, 1777] [1, 308] [1, 1049] [1, 982] [1, 1049] [1, 1777] [1, 1147] [1, 893] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -1.5192158222198486 with beta sum per layer: [0.0, 672.5029296875, 30.583953857421875]
alpha/beta optimization time: 0.9490320682525635
This batch time : update_bounds func: 1.3681	 prepare: 0.2053	 bound: 0.9494	 transfer: 0.0685	 finalize: 0.1379
Accumulated time: update_bounds func: 48.5914	 prepare: 7.2842	 bound: 32.3325	 transfer: 0.0685	 finalize: 6.3460
batch bounding time:  1.3700034618377686
Current worst splitting domains [lb, ub] (depth):
[-0.00570,   inf] (58), [-0.00570,   inf] (38), [-0.00570,   inf] (52), [-0.00570,   inf] (44), [-0.00570,   inf] (48), [-0.00570,   inf] (56), [-0.00570,   inf] (52), [-0.00570,   inf] (48), [-0.00570,   inf] (56), [-0.00570,   inf] (50), [-0.00570,   inf] (44), [-0.00570,   inf] (42), [-0.00570,   inf] (48), [-0.00570,   inf] (48), [-0.00570,   inf] (44), [-0.00570,   inf] (40), [-0.00570,   inf] (48), [-0.00570,   inf] (52), [-0.00570,   inf] (56), [-0.00570,   inf] (44), 
length of domains: 16686
Total time: 2.7366	 pickout: 0.1775	 decision: 1.0917	 get_bound: 1.3734	 add_domain: 0.0941
Current lb:-0.005701513960957527
64064 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 94.72242498397827

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 308] [1, 700] [1, 982] [1, 1049] [1, 2041] [1, 531] [1, 893] [1, 2041] [1, 531] [1, 982] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -2.2954959869384766 with beta sum per layer: [0.0, 665.5986328125, 27.530948638916016]
alpha/beta optimization time: 0.9562070369720459
This batch time : update_bounds func: 1.8160	 prepare: 0.2216	 bound: 0.9566	 transfer: 0.0685	 finalize: 0.5623
Accumulated time: update_bounds func: 50.4074	 prepare: 7.5058	 bound: 33.2890	 transfer: 0.0685	 finalize: 6.9083
batch bounding time:  1.818009853363037
Current worst splitting domains [lb, ub] (depth):
[-0.00546,   inf] (50), [-0.00546,   inf] (44), [-0.00546,   inf] (46), [-0.00546,   inf] (58), [-0.00546,   inf] (48), [-0.00546,   inf] (62), [-0.00546,   inf] (42), [-0.00546,   inf] (42), [-0.00546,   inf] (54), [-0.00546,   inf] (50), [-0.00546,   inf] (44), [-0.00546,   inf] (46), [-0.00546,   inf] (36), [-0.00546,   inf] (50), [-0.00546,   inf] (58), [-0.00546,   inf] (56), [-0.00546,   inf] (54), [-0.00546,   inf] (42), [-0.00546,   inf] (38), [-0.00546,   inf] (36), 
length of domains: 16996
Total time: 2.7881	 pickout: 0.1780	 decision: 0.6964	 get_bound: 1.8214	 add_domain: 0.0924
Current lb:-0.005459251813590527
66112 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 97.54109859466553

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1777] [1, 1777] [2, 27] [1, 308] [1, 1049] [1, 418] [1, 1638] [2, 27] [1, 893] [1, 1777] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -1.9459176063537598 with beta sum per layer: [0.0, 642.0778198242188, 28.716949462890625]
alpha/beta optimization time: 0.9500887393951416
This batch time : update_bounds func: 1.3841	 prepare: 0.2173	 bound: 0.9504	 transfer: 0.0702	 finalize: 0.1390
Accumulated time: update_bounds func: 51.7915	 prepare: 7.7231	 bound: 34.2395	 transfer: 0.0702	 finalize: 7.0473
batch bounding time:  1.3861536979675293
Current worst splitting domains [lb, ub] (depth):
[-0.00521,   inf] (58), [-0.00521,   inf] (52), [-0.00521,   inf] (54), [-0.00521,   inf] (50), [-0.00521,   inf] (64), [-0.00521,   inf] (60), [-0.00521,   inf] (58), [-0.00521,   inf] (58), [-0.00521,   inf] (52), [-0.00521,   inf] (38), [-0.00521,   inf] (50), [-0.00521,   inf] (56), [-0.00521,   inf] (42), [-0.00521,   inf] (50), [-0.00521,   inf] (42), [-0.00521,   inf] (40), [-0.00521,   inf] (46), [-0.00521,   inf] (50), [-0.00521,   inf] (48), [-0.00521,   inf] (58), 
length of domains: 17299
Total time: 2.3548	 pickout: 0.1780	 decision: 0.6941	 get_bound: 1.3896	 add_domain: 0.0931
Current lb:-0.005213737487792969
68160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 99.92694449424744

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 308] [1, 982] [1, 893] [1, 1049] [1, 990] [1, 1147] [1, 538] [1, 308] [1, 982] [1, 700] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -2.098029851913452 with beta sum per layer: [0.0, 633.893798828125, 23.426836013793945]
alpha/beta optimization time: 0.9487423896789551
This batch time : update_bounds func: 1.3697	 prepare: 0.2049	 bound: 0.9491	 transfer: 0.0695	 finalize: 0.1394
Accumulated time: update_bounds func: 53.1613	 prepare: 7.9280	 bound: 35.1886	 transfer: 0.0695	 finalize: 7.1867
batch bounding time:  1.3717284202575684
Current worst splitting domains [lb, ub] (depth):
[-0.00497,   inf] (54), [-0.00497,   inf] (44), [-0.00497,   inf] (50), [-0.00497,   inf] (48), [-0.00497,   inf] (64), [-0.00497,   inf] (50), [-0.00497,   inf] (58), [-0.00497,   inf] (52), [-0.00497,   inf] (54), [-0.00497,   inf] (52), [-0.00497,   inf] (52), [-0.00497,   inf] (48), [-0.00497,   inf] (48), [-0.00497,   inf] (48), [-0.00497,   inf] (58), [-0.00497,   inf] (58), [-0.00497,   inf] (62), [-0.00497,   inf] (54), [-0.00497,   inf] (52), [-0.00497,   inf] (46), 
length of domains: 17586
Total time: 2.7579	 pickout: 0.1774	 decision: 1.1122	 get_bound: 1.3752	 add_domain: 0.0931
Current lb:-0.004974842071533203
70208 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 102.71552419662476

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 893] [1, 1049] [1, 1777] [1, 1049] [1, 990] [1, 1777] [1, 538] [1, 982] [1, 538] [1, 982] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -2.9632959365844727 with beta sum per layer: [0.0, 637.4468383789062, 33.5192985534668]
alpha/beta optimization time: 0.9493296146392822
This batch time : update_bounds func: 1.3726	 prepare: 0.2144	 bound: 0.9497	 transfer: 0.0611	 finalize: 0.1405
Accumulated time: update_bounds func: 54.5339	 prepare: 8.1424	 bound: 36.1382	 transfer: 0.0611	 finalize: 7.3272
batch bounding time:  1.374680757522583
Current worst splitting domains [lb, ub] (depth):
[-0.00474,   inf] (60), [-0.00474,   inf] (60), [-0.00474,   inf] (52), [-0.00474,   inf] (54), [-0.00474,   inf] (60), [-0.00474,   inf] (48), [-0.00474,   inf] (58), [-0.00474,   inf] (56), [-0.00474,   inf] (58), [-0.00474,   inf] (60), [-0.00474,   inf] (50), [-0.00474,   inf] (40), [-0.00474,   inf] (42), [-0.00474,   inf] (42), [-0.00474,   inf] (56), [-0.00474,   inf] (58), [-0.00474,   inf] (44), [-0.00474,   inf] (58), [-0.00474,   inf] (64), [-0.00474,   inf] (52), 
length of domains: 17778
Total time: 2.7884	 pickout: 0.1742	 decision: 0.6928	 get_bound: 1.3782	 add_domain: 0.5432
Current lb:-0.004744052886962891
72256 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 105.53675818443298

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1147] [1, 1147] [1, 982] [1, 893] [1, 417] [1, 2041] [1, 538] [1, 531] [1, 308] [1, 1147] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -2.74761962890625 with beta sum per layer: [0.0, 632.2958984375, 27.352428436279297]
alpha/beta optimization time: 0.9487273693084717
This batch time : update_bounds func: 1.3751	 prepare: 0.2086	 bound: 0.9491	 transfer: 0.0690	 finalize: 0.1411
Accumulated time: update_bounds func: 55.9090	 prepare: 8.3510	 bound: 37.0873	 transfer: 0.0690	 finalize: 7.4684
batch bounding time:  1.3771865367889404
Current worst splitting domains [lb, ub] (depth):
[-0.00453,   inf] (38), [-0.00453,   inf] (40), [-0.00453,   inf] (54), [-0.00453,   inf] (50), [-0.00453,   inf] (54), [-0.00453,   inf] (40), [-0.00453,   inf] (42), [-0.00453,   inf] (54), [-0.00453,   inf] (46), [-0.00453,   inf] (48), [-0.00453,   inf] (40), [-0.00453,   inf] (56), [-0.00453,   inf] (42), [-0.00453,   inf] (56), [-0.00453,   inf] (42), [-0.00453,   inf] (58), [-0.00453,   inf] (56), [-0.00453,   inf] (54), [-0.00453,   inf] (38), [-0.00453,   inf] (58), 
length of domains: 17962
Total time: 2.3660	 pickout: 0.1787	 decision: 0.7184	 get_bound: 1.3808	 add_domain: 0.0881
Current lb:-0.004530812613666058
74304 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 107.9356939792633

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1437] [1, 1638] [1, 1147] [1, 1777] [1, 893] [1, 1638] [2, 27] [1, 893] [1, 417] [1, 2041] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -2.9488680362701416 with beta sum per layer: [0.0, 637.57958984375, 23.380931854248047]
alpha/beta optimization time: 0.9474191665649414
This batch time : update_bounds func: 1.8262	 prepare: 0.2037	 bound: 0.9478	 transfer: 0.0690	 finalize: 0.5985
Accumulated time: update_bounds func: 57.7353	 prepare: 8.5547	 bound: 38.0351	 transfer: 0.0690	 finalize: 8.0668
batch bounding time:  1.8281826972961426
Current worst splitting domains [lb, ub] (depth):
[-0.00432,   inf] (56), [-0.00432,   inf] (46), [-0.00432,   inf] (60), [-0.00432,   inf] (46), [-0.00432,   inf] (46), [-0.00432,   inf] (58), [-0.00432,   inf] (58), [-0.00432,   inf] (46), [-0.00432,   inf] (50), [-0.00432,   inf] (60), [-0.00432,   inf] (50), [-0.00432,   inf] (50), [-0.00432,   inf] (42), [-0.00432,   inf] (56), [-0.00432,   inf] (62), [-0.00432,   inf] (60), [-0.00432,   inf] (50), [-0.00432,   inf] (48), [-0.00432,   inf] (60), [-0.00431,   inf] (50), 
length of domains: 18135
Total time: 2.7888	 pickout: 0.1800	 decision: 0.6916	 get_bound: 1.8317	 add_domain: 0.0856
Current lb:-0.0043182373046875
76352 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 110.7573595046997

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 531] [2, 27] [1, 1147] [2, 27] [1, 417] [1, 308] [1, 308] [1, 417] [1, 982] [1, 1147] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -3.4210729598999023 with beta sum per layer: [0.0, 628.88916015625, 27.647197723388672]
alpha/beta optimization time: 0.9483809471130371
This batch time : update_bounds func: 1.3722	 prepare: 0.2085	 bound: 0.9487	 transfer: 0.0650	 finalize: 0.1426
Accumulated time: update_bounds func: 59.1074	 prepare: 8.7631	 bound: 38.9838	 transfer: 0.0650	 finalize: 8.2094
batch bounding time:  1.374192476272583
Current worst splitting domains [lb, ub] (depth):
[-0.00411,   inf] (54), [-0.00411,   inf] (46), [-0.00411,   inf] (46), [-0.00411,   inf] (50), [-0.00411,   inf] (58), [-0.00411,   inf] (54), [-0.00411,   inf] (60), [-0.00411,   inf] (50), [-0.00411,   inf] (60), [-0.00411,   inf] (44), [-0.00411,   inf] (62), [-0.00411,   inf] (40), [-0.00411,   inf] (44), [-0.00411,   inf] (60), [-0.00411,   inf] (52), [-0.00411,   inf] (52), [-0.00411,   inf] (60), [-0.00411,   inf] (54), [-0.00411,   inf] (48), [-0.00411,   inf] (56), 
length of domains: 18207
Total time: 2.3291	 pickout: 0.1789	 decision: 0.6924	 get_bound: 1.3777	 add_domain: 0.0800
Current lb:-0.0041103363037109375
78400 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 113.12008118629456

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1147] [1, 417] [1, 417] [1, 1777] [1, 538] [1, 893] [1, 417] [1, 982] [1, 1147] [1, 1777] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -3.749959945678711 with beta sum per layer: [0.0, 631.6127319335938, 24.640310287475586]
alpha/beta optimization time: 0.94828200340271
This batch time : update_bounds func: 1.8113	 prepare: 0.2085	 bound: 0.9486	 transfer: 0.0530	 finalize: 0.1453
Accumulated time: update_bounds func: 60.9187	 prepare: 8.9716	 bound: 39.9324	 transfer: 0.0530	 finalize: 8.3547
batch bounding time:  1.813300609588623
Current worst splitting domains [lb, ub] (depth):
[-0.00392,   inf] (58), [-0.00392,   inf] (48), [-0.00392,   inf] (48), [-0.00392,   inf] (44), [-0.00392,   inf] (56), [-0.00392,   inf] (58), [-0.00392,   inf] (48), [-0.00392,   inf] (56), [-0.00392,   inf] (54), [-0.00392,   inf] (58), [-0.00392,   inf] (46), [-0.00391,   inf] (56), [-0.00391,   inf] (44), [-0.00391,   inf] (48), [-0.00391,   inf] (56), [-0.00391,   inf] (54), [-0.00391,   inf] (62), [-0.00391,   inf] (46), [-0.00391,   inf] (50), [-0.00391,   inf] (58), 
length of domains: 18221
Total time: 2.7673	 pickout: 0.1788	 decision: 0.6957	 get_bound: 1.8168	 add_domain: 0.0759
Current lb:-0.003917217254638672
80448 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 115.92331790924072

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 308] [1, 1049] [1, 2041] [1, 1777] [1, 531] [1, 308] [1, 1049] [1, 531] [1, 1147] [1, 308] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -4.22606086730957 with beta sum per layer: [0.0, 643.1436157226562, 24.70246696472168]
alpha/beta optimization time: 0.9470024108886719
This batch time : update_bounds func: 1.3558	 prepare: 0.2074	 bound: 0.9474	 transfer: 0.0489	 finalize: 0.1452
Accumulated time: update_bounds func: 62.2746	 prepare: 9.1790	 bound: 40.8798	 transfer: 0.0489	 finalize: 8.4999
batch bounding time:  1.357914686203003
Current worst splitting domains [lb, ub] (depth):
[-0.00373,   inf] (58), [-0.00373,   inf] (50), [-0.00373,   inf] (44), [-0.00373,   inf] (56), [-0.00373,   inf] (64), [-0.00373,   inf] (52), [-0.00373,   inf] (50), [-0.00373,   inf] (66), [-0.00373,   inf] (40), [-0.00373,   inf] (56), [-0.00373,   inf] (56), [-0.00373,   inf] (50), [-0.00373,   inf] (50), [-0.00373,   inf] (42), [-0.00373,   inf] (48), [-0.00373,   inf] (56), [-0.00373,   inf] (58), [-0.00373,   inf] (52), [-0.00373,   inf] (48), [-0.00373,   inf] (44), 
length of domains: 18102
Total time: 2.2964	 pickout: 0.1775	 decision: 0.6904	 get_bound: 1.3615	 add_domain: 0.0670
Current lb:-0.0037271042820066214
82496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 118.25652980804443

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 308] [1, 1777] [1, 1777] [1, 531] [1, 990] [1, 982] [1, 982] [1, 777] [1, 2041] [1, 531] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -4.204044342041016 with beta sum per layer: [0.0, 645.9751586914062, 25.905250549316406]
alpha/beta optimization time: 0.9458150863647461
This batch time : update_bounds func: 1.3810	 prepare: 0.2098	 bound: 0.9462	 transfer: 0.0691	 finalize: 0.1480
Accumulated time: update_bounds func: 63.6555	 prepare: 9.3888	 bound: 41.8260	 transfer: 0.0691	 finalize: 8.6479
batch bounding time:  1.383277416229248
Current worst splitting domains [lb, ub] (depth):
[-0.00353,   inf] (50), [-0.00353,   inf] (52), [-0.00353,   inf] (46), [-0.00353,   inf] (48), [-0.00353,   inf] (44), [-0.00353,   inf] (48), [-0.00353,   inf] (50), [-0.00353,   inf] (40), [-0.00353,   inf] (52), [-0.00353,   inf] (50), [-0.00353,   inf] (50), [-0.00353,   inf] (56), [-0.00353,   inf] (56), [-0.00353,   inf] (52), [-0.00353,   inf] (64), [-0.00353,   inf] (62), [-0.00353,   inf] (56), [-0.00353,   inf] (46), [-0.00353,   inf] (42), [-0.00353,   inf] (42), 
length of domains: 17870
Total time: 2.7680	 pickout: 0.1779	 decision: 1.1401	 get_bound: 1.3871	 add_domain: 0.0629
Current lb:-0.0035343170166015625
84544 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 121.06064248085022

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 982] [1, 982] [1, 417] [1, 2041] [1, 1777] [1, 1049] [1, 982] [1, 2041] [1, 982] [1, 1777] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -4.9785614013671875 with beta sum per layer: [0.0, 641.6202392578125, 25.605396270751953]
alpha/beta optimization time: 0.9484438896179199
This batch time : update_bounds func: 1.3827	 prepare: 0.2110	 bound: 0.9488	 transfer: 0.0694	 finalize: 0.1462
Accumulated time: update_bounds func: 65.0383	 prepare: 9.5998	 bound: 42.7748	 transfer: 0.0694	 finalize: 8.7941
batch bounding time:  1.3847875595092773
Current worst splitting domains [lb, ub] (depth):
[-0.00334,   inf] (44), [-0.00334,   inf] (48), [-0.00334,   inf] (58), [-0.00334,   inf] (56), [-0.00334,   inf] (56), [-0.00334,   inf] (46), [-0.00334,   inf] (50), [-0.00334,   inf] (60), [-0.00334,   inf] (48), [-0.00334,   inf] (64), [-0.00334,   inf] (48), [-0.00334,   inf] (42), [-0.00334,   inf] (42), [-0.00334,   inf] (46), [-0.00334,   inf] (52), [-0.00334,   inf] (60), [-0.00334,   inf] (42), [-0.00334,   inf] (42), [-0.00334,   inf] (44), [-0.00334,   inf] (52), 
length of domains: 17575
Total time: 2.8188	 pickout: 0.1842	 decision: 0.7052	 get_bound: 1.3884	 add_domain: 0.5409
Current lb:-0.0033431053161621094
86592 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 123.91620683670044

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1437] [1, 982] [1, 308] [1, 531] [1, 531] [1, 417] [1, 1777] [1, 1147] [1, 2041] [1, 990] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -5.448053359985352 with beta sum per layer: [0.0, 651.4561157226562, 28.53466033935547]
alpha/beta optimization time: 0.945512056350708
This batch time : update_bounds func: 1.3870	 prepare: 0.2143	 bound: 0.9459	 transfer: 0.0691	 finalize: 0.1505
Accumulated time: update_bounds func: 66.4253	 prepare: 9.8141	 bound: 43.7207	 transfer: 0.0691	 finalize: 8.9446
batch bounding time:  1.3891358375549316
Current worst splitting domains [lb, ub] (depth):
[-0.00316,   inf] (58), [-0.00316,   inf] (46), [-0.00316,   inf] (44), [-0.00316,   inf] (40), [-0.00316,   inf] (60), [-0.00316,   inf] (58), [-0.00316,   inf] (50), [-0.00316,   inf] (42), [-0.00316,   inf] (58), [-0.00316,   inf] (56), [-0.00316,   inf] (44), [-0.00316,   inf] (60), [-0.00316,   inf] (42), [-0.00316,   inf] (50), [-0.00316,   inf] (50), [-0.00316,   inf] (44), [-0.00316,   inf] (52), [-0.00316,   inf] (60), [-0.00316,   inf] (62), [-0.00316,   inf] (46), 
length of domains: 17185
Total time: 2.3155	 pickout: 0.1772	 decision: 0.6968	 get_bound: 1.3928	 add_domain: 0.0487
Current lb:-0.0031614303588867188
88640 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 126.27447414398193

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 308] [1, 417] [1, 1049] [1, 841] [1, 1147] [1, 308] [1, 1777] [2, 27] [1, 308] [1, 531] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -5.54307746887207 with beta sum per layer: [0.0, 643.1436767578125, 23.573213577270508]
alpha/beta optimization time: 0.9490108489990234
This batch time : update_bounds func: 1.3748	 prepare: 0.2109	 bound: 0.9494	 transfer: 0.0567	 finalize: 0.1504
Accumulated time: update_bounds func: 67.8000	 prepare: 10.0250	 bound: 44.6700	 transfer: 0.0567	 finalize: 9.0950
batch bounding time:  1.3769500255584717
Current worst splitting domains [lb, ub] (depth):
[-0.00297,   inf] (60), [-0.00297,   inf] (56), [-0.00297,   inf] (50), [-0.00297,   inf] (40), [-0.00297,   inf] (60), [-0.00297,   inf] (44), [-0.00297,   inf] (50), [-0.00297,   inf] (54), [-0.00297,   inf] (44), [-0.00297,   inf] (38), [-0.00297,   inf] (50), [-0.00297,   inf] (58), [-0.00297,   inf] (58), [-0.00297,   inf] (52), [-0.00297,   inf] (60), [-0.00297,   inf] (50), [-0.00297,   inf] (52), [-0.00297,   inf] (48), [-0.00297,   inf] (42), [-0.00297,   inf] (62), 
length of domains: 16770
Total time: 2.7765	 pickout: 0.1768	 decision: 0.6979	 get_bound: 1.3809	 add_domain: 0.5210
Current lb:-0.002970071043819189
90688 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 129.0891261100769

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 417] [1, 531] [1, 982] [1, 1638] [1, 1147] [1, 1777] [1, 982] [1, 1147] [1, 1049] [1, 700] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -6.211580276489258 with beta sum per layer: [0.0, 666.30078125, 26.35305404663086]
alpha/beta optimization time: 0.9490232467651367
This batch time : update_bounds func: 1.4087	 prepare: 0.2273	 bound: 0.9494	 transfer: 0.0690	 finalize: 0.1558
Accumulated time: update_bounds func: 69.2088	 prepare: 10.2523	 bound: 45.6194	 transfer: 0.0690	 finalize: 9.2508
batch bounding time:  1.410829782485962
Current worst splitting domains [lb, ub] (depth):
[-0.00279,   inf] (60), [-0.00279,   inf] (46), [-0.00279,   inf] (50), [-0.00279,   inf] (52), [-0.00279,   inf] (52), [-0.00279,   inf] (60), [-0.00279,   inf] (58), [-0.00279,   inf] (52), [-0.00279,   inf] (60), [-0.00279,   inf] (60), [-0.00279,   inf] (44), [-0.00279,   inf] (50), [-0.00279,   inf] (66), [-0.00279,   inf] (52), [-0.00279,   inf] (44), [-0.00278,   inf] (58), [-0.00278,   inf] (46), [-0.00278,   inf] (52), [-0.00278,   inf] (36), [-0.00278,   inf] (50), 
length of domains: 16292
Total time: 2.3479	 pickout: 0.1839	 decision: 0.7065	 get_bound: 1.4146	 add_domain: 0.0429
Current lb:-0.002788543701171875
92736 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 131.47639989852905

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1147] [2, 27] [1, 1049] [1, 893] [1, 893] [1, 1147] [1, 308] [1, 982] [1, 1147] [1, 1147] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -6.6355438232421875 with beta sum per layer: [0.0, 670.4539184570312, 23.120494842529297]
alpha/beta optimization time: 0.9671969413757324
This batch time : update_bounds func: 1.8912	 prepare: 0.2141	 bound: 0.9676	 transfer: 0.0804	 finalize: 0.6222
Accumulated time: update_bounds func: 71.1000	 prepare: 10.4664	 bound: 46.5870	 transfer: 0.0804	 finalize: 9.8730
batch bounding time:  1.8934097290039062
Current worst splitting domains [lb, ub] (depth):
[-0.00261,   inf] (52), [-0.00261,   inf] (60), [-0.00261,   inf] (56), [-0.00260,   inf] (46), [-0.00260,   inf] (50), [-0.00260,   inf] (42), [-0.00260,   inf] (54), [-0.00260,   inf] (60), [-0.00260,   inf] (54), [-0.00260,   inf] (38), [-0.00260,   inf] (48), [-0.00260,   inf] (56), [-0.00260,   inf] (36), [-0.00260,   inf] (60), [-0.00260,   inf] (48), [-0.00260,   inf] (54), [-0.00260,   inf] (42), [-0.00260,   inf] (34), [-0.00260,   inf] (36), [-0.00260,   inf] (50), 
length of domains: 15785
Total time: 2.8145	 pickout: 0.1850	 decision: 0.6946	 get_bound: 1.8970	 add_domain: 0.0379
Current lb:-0.002605915069580078
94784 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 134.32937693595886

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 982] [1, 1147] [1, 531] [2, 27] [1, 1777] [1, 1638] [1, 1147] [1, 1147] [1, 893] [1, 700] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -6.296911716461182 with beta sum per layer: [0.0, 645.2536010742188, 21.901111602783203]
alpha/beta optimization time: 0.9526369571685791
This batch time : update_bounds func: 1.4016	 prepare: 0.2199	 bound: 0.9530	 transfer: 0.0696	 finalize: 0.1517
Accumulated time: update_bounds func: 72.5016	 prepare: 10.6863	 bound: 47.5400	 transfer: 0.0696	 finalize: 10.0247
batch bounding time:  1.4036409854888916
Current worst splitting domains [lb, ub] (depth):
[-0.00243,   inf] (56), [-0.00243,   inf] (48), [-0.00243,   inf] (58), [-0.00243,   inf] (58), [-0.00243,   inf] (46), [-0.00243,   inf] (52), [-0.00243,   inf] (60), [-0.00243,   inf] (58), [-0.00243,   inf] (38), [-0.00243,   inf] (54), [-0.00243,   inf] (58), [-0.00243,   inf] (54), [-0.00243,   inf] (58), [-0.00243,   inf] (58), [-0.00243,   inf] (54), [-0.00243,   inf] (44), [-0.00243,   inf] (40), [-0.00242,   inf] (36), [-0.00242,   inf] (54), [-0.00242,   inf] (54), 
length of domains: 15230
Total time: 2.3627	 pickout: 0.1956	 decision: 0.7227	 get_bound: 1.4072	 add_domain: 0.0372
Current lb:-0.0024271162692457438
96832 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 136.732186794281

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 531] [1, 2041] [1, 308] [1, 308] [2, 27] [1, 982] [1, 1147] [1, 308] [1, 1437] [1, 1147] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -6.291069507598877 with beta sum per layer: [0.0, 674.8291015625, 6.053269863128662]
alpha/beta optimization time: 0.9742865562438965
This batch time : update_bounds func: 1.8977	 prepare: 0.2124	 bound: 0.9747	 transfer: 0.0694	 finalize: 0.2053
Accumulated time: update_bounds func: 74.3993	 prepare: 10.8988	 bound: 48.5147	 transfer: 0.0694	 finalize: 10.2300
batch bounding time:  1.9000556468963623
Current worst splitting domains [lb, ub] (depth):
[-0.00225,   inf] (54), [-0.00225,   inf] (38), [-0.00225,   inf] (52), [-0.00225,   inf] (46), [-0.00225,   inf] (52), [-0.00225,   inf] (42), [-0.00225,   inf] (58), [-0.00225,   inf] (48), [-0.00225,   inf] (44), [-0.00225,   inf] (42), [-0.00225,   inf] (58), [-0.00225,   inf] (58), [-0.00225,   inf] (48), [-0.00225,   inf] (60), [-0.00225,   inf] (42), [-0.00225,   inf] (38), [-0.00225,   inf] (56), [-0.00225,   inf] (46), [-0.00225,   inf] (48), [-0.00225,   inf] (44), 
length of domains: 14630
Total time: 2.8368	 pickout: 0.2036	 decision: 0.6974	 get_bound: 1.9039	 add_domain: 0.0319
Current lb:-0.0022530555725097656
98880 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 139.61008667945862

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 893] [1, 1437] [1, 982] [2, 27] [1, 982] [1, 1638] [1, 308] [1, 1049] [1, 1049] [2, 27] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -6.536230087280273 with beta sum per layer: [0.0, 660.74365234375, 10.004518508911133]
alpha/beta optimization time: 0.9679980278015137
This batch time : update_bounds func: 1.5290	 prepare: 0.3296	 bound: 0.9684	 transfer: 0.0675	 finalize: 0.1562
Accumulated time: update_bounds func: 75.9283	 prepare: 11.2284	 bound: 49.4831	 transfer: 0.0675	 finalize: 10.3862
batch bounding time:  1.5312132835388184
Current worst splitting domains [lb, ub] (depth):
[-0.00209,   inf] (52), [-0.00209,   inf] (54), [-0.00208,   inf] (48), [-0.00208,   inf] (40), [-0.00208,   inf] (58), [-0.00208,   inf] (46), [-0.00208,   inf] (40), [-0.00208,   inf] (42), [-0.00208,   inf] (38), [-0.00208,   inf] (54), [-0.00208,   inf] (58), [-0.00208,   inf] (52), [-0.00208,   inf] (50), [-0.00208,   inf] (52), [-0.00208,   inf] (58), [-0.00208,   inf] (50), [-0.00208,   inf] (52), [-0.00208,   inf] (42), [-0.00208,   inf] (50), [-0.00208,   inf] (58), 
length of domains: 13894
Total time: 2.7425	 pickout: 0.2510	 decision: 0.9316	 get_bound: 1.5349	 add_domain: 0.0250
Current lb:-0.0020852088928222656
100928 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 142.39657831192017

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 982] [1, 893] [1, 1049] [1, 1638] [1, 538] [2, 27] [1, 2041] [2, 27] [1, 700] [1, 893] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -6.671265602111816 with beta sum per layer: [0.0, 665.7703857421875, 8.175115585327148]
alpha/beta optimization time: 0.9482109546661377
This batch time : update_bounds func: 1.3834	 prepare: 0.2120	 bound: 0.9486	 transfer: 0.0682	 finalize: 0.1479
Accumulated time: update_bounds func: 77.3117	 prepare: 11.4403	 bound: 50.4317	 transfer: 0.0682	 finalize: 10.5341
batch bounding time:  1.3855040073394775
Current worst splitting domains [lb, ub] (depth):
[-0.00191,   inf] (56), [-0.00191,   inf] (62), [-0.00191,   inf] (54), [-0.00191,   inf] (54), [-0.00191,   inf] (52), [-0.00191,   inf] (60), [-0.00191,   inf] (60), [-0.00191,   inf] (54), [-0.00191,   inf] (50), [-0.00191,   inf] (50), [-0.00191,   inf] (42), [-0.00191,   inf] (44), [-0.00191,   inf] (44), [-0.00191,   inf] (36), [-0.00191,   inf] (48), [-0.00191,   inf] (46), [-0.00191,   inf] (58), [-0.00191,   inf] (42), [-0.00191,   inf] (50), [-0.00191,   inf] (50), 
length of domains: 13146
Total time: 2.6990	 pickout: 0.2054	 decision: 1.0814	 get_bound: 1.3892	 add_domain: 0.0230
Current lb:-0.0019110642606392503
102976 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 145.1368751525879

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 531] [1, 990] [1, 1147] [1, 1147] [1, 982] [1, 1147] [1, 1147] [1, 893] [1, 1777] [1, 1777] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -7.324785232543945 with beta sum per layer: [0.0, 652.762451171875, 7.653432846069336]
alpha/beta optimization time: 0.9550619125366211
This batch time : update_bounds func: 1.8098	 prepare: 0.2322	 bound: 0.9555	 transfer: 0.0705	 finalize: 0.5425
Accumulated time: update_bounds func: 79.1215	 prepare: 11.6726	 bound: 51.3872	 transfer: 0.0705	 finalize: 11.0767
batch bounding time:  1.8118140697479248
Current worst splitting domains [lb, ub] (depth):
[-0.00175,   inf] (60), [-0.00175,   inf] (46), [-0.00175,   inf] (42), [-0.00175,   inf] (58), [-0.00175,   inf] (60), [-0.00175,   inf] (44), [-0.00175,   inf] (56), [-0.00175,   inf] (62), [-0.00175,   inf] (52), [-0.00175,   inf] (46), [-0.00175,   inf] (54), [-0.00175,   inf] (54), [-0.00175,   inf] (42), [-0.00175,   inf] (68), [-0.00175,   inf] (52), [-0.00175,   inf] (56), [-0.00175,   inf] (44), [-0.00175,   inf] (44), [-0.00175,   inf] (56), [-0.00175,   inf] (66), 
length of domains: 12356
Total time: 2.7387	 pickout: 0.2073	 decision: 0.6953	 get_bound: 1.8153	 add_domain: 0.0209
Current lb:-0.0017514228820800781
105024 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 147.91710209846497

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1147] [1, 417] [1, 1638] [1, 308] [1, 1147] [1, 1437] [1, 531] [1, 990] [1, 893] [2, 27] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -7.244035243988037 with beta sum per layer: [0.0, 672.4678955078125, 6.077657699584961]
alpha/beta optimization time: 0.9531567096710205
This batch time : update_bounds func: 1.3977	 prepare: 0.2129	 bound: 0.9536	 transfer: 0.0693	 finalize: 0.1553
Accumulated time: update_bounds func: 80.5192	 prepare: 11.8855	 bound: 52.3408	 transfer: 0.0693	 finalize: 11.2320
batch bounding time:  1.3997220993041992
Current worst splitting domains [lb, ub] (depth):
[-0.00160,   inf] (50), [-0.00160,   inf] (52), [-0.00160,   inf] (46), [-0.00160,   inf] (44), [-0.00160,   inf] (50), [-0.00160,   inf] (48), [-0.00160,   inf] (56), [-0.00160,   inf] (54), [-0.00160,   inf] (58), [-0.00160,   inf] (54), [-0.00160,   inf] (54), [-0.00160,   inf] (48), [-0.00160,   inf] (52), [-0.00160,   inf] (50), [-0.00160,   inf] (58), [-0.00160,   inf] (54), [-0.00160,   inf] (50), [-0.00160,   inf] (54), [-0.00160,   inf] (60), [-0.00160,   inf] (52), 
length of domains: 11529
Total time: 2.3211	 pickout: 0.1940	 decision: 0.7081	 get_bound: 1.4032	 add_domain: 0.0158
Current lb:-0.0015997886657714844
107072 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 150.28293085098267

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1777] [1, 982] [2, 27] [1, 1049] [1, 982] [1, 2041] [1, 531] [1, 893] [1, 308] [1, 1147] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -7.69069766998291 with beta sum per layer: [0.0, 658.791259765625, 6.658904552459717]
alpha/beta optimization time: 0.9589519500732422
This batch time : update_bounds func: 1.3952	 prepare: 0.2190	 bound: 0.9593	 transfer: 0.0580	 finalize: 0.1523
Accumulated time: update_bounds func: 81.9144	 prepare: 12.1045	 bound: 53.3002	 transfer: 0.0580	 finalize: 11.3843
batch bounding time:  1.397254467010498
Current worst splitting domains [lb, ub] (depth):
[-0.00144,   inf] (46), [-0.00144,   inf] (60), [-0.00144,   inf] (34), [-0.00144,   inf] (44), [-0.00144,   inf] (48), [-0.00144,   inf] (56), [-0.00144,   inf] (62), [-0.00144,   inf] (46), [-0.00144,   inf] (58), [-0.00144,   inf] (42), [-0.00144,   inf] (52), [-0.00144,   inf] (42), [-0.00144,   inf] (44), [-0.00144,   inf] (54), [-0.00144,   inf] (54), [-0.00144,   inf] (44), [-0.00144,   inf] (58), [-0.00144,   inf] (40), [-0.00144,   inf] (58), [-0.00144,   inf] (62), 
length of domains: 10720
Total time: 2.6282	 pickout: 0.1909	 decision: 1.0197	 get_bound: 1.4008	 add_domain: 0.0168
Current lb:-0.0014443397521972656
109120 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 152.95497059822083

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 27] [1, 1147] [1, 419] [1, 1777] [1, 1049] [1, 531] [1, 418] [1, 417] [1, 308] [1, 1638] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -7.50942325592041 with beta sum per layer: [0.0, 647.1204833984375, 9.799853324890137]
alpha/beta optimization time: 0.9447510242462158
This batch time : update_bounds func: 1.6645	 prepare: 0.2143	 bound: 0.9451	 transfer: 0.0567	 finalize: 0.4419
Accumulated time: update_bounds func: 83.5788	 prepare: 12.3188	 bound: 54.2453	 transfer: 0.0567	 finalize: 11.8261
batch bounding time:  1.6665105819702148
Current worst splitting domains [lb, ub] (depth):
[-0.00130,   inf] (38), [-0.00130,   inf] (54), [-0.00130,   inf] (60), [-0.00130,   inf] (46), [-0.00130,   inf] (48), [-0.00130,   inf] (56), [-0.00130,   inf] (44), [-0.00130,   inf] (52), [-0.00130,   inf] (48), [-0.00130,   inf] (48), [-0.00130,   inf] (58), [-0.00130,   inf] (56), [-0.00130,   inf] (52), [-0.00130,   inf] (52), [-0.00130,   inf] (48), [-0.00130,   inf] (42), [-0.00130,   inf] (54), [-0.00130,   inf] (54), [-0.00130,   inf] (48), [-0.00130,   inf] (54), 
length of domains: 9826
Total time: 2.5604	 pickout: 0.1872	 decision: 0.6926	 get_bound: 1.6700	 add_domain: 0.0106
Current lb:-0.0012980244355276227
111168 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 155.55727863311768

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 700] [1, 1147] [1, 417] [1, 417] [1, 2041] [1, 531] [1, 1777] [1, 982] [1, 1049] [1, 1049] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -7.927229404449463 with beta sum per layer: [0.0, 655.092041015625, 6.974172592163086]
alpha/beta optimization time: 0.9330716133117676
This batch time : update_bounds func: 1.6744	 prepare: 0.2135	 bound: 0.9334	 transfer: 0.0688	 finalize: 0.4526
Accumulated time: update_bounds func: 85.2533	 prepare: 12.5323	 bound: 55.1787	 transfer: 0.0688	 finalize: 12.2788
batch bounding time:  1.6766512393951416
Current worst splitting domains [lb, ub] (depth):
[-0.00115,   inf] (58), [-0.00115,   inf] (44), [-0.00115,   inf] (56), [-0.00115,   inf] (56), [-0.00115,   inf] (60), [-0.00115,   inf] (44), [-0.00115,   inf] (62), [-0.00115,   inf] (54), [-0.00115,   inf] (50), [-0.00115,   inf] (58), [-0.00115,   inf] (52), [-0.00115,   inf] (56), [-0.00115,   inf] (56), [-0.00115,   inf] (56), [-0.00115,   inf] (50), [-0.00115,   inf] (62), [-0.00115,   inf] (52), [-0.00115,   inf] (60), [-0.00115,   inf] (44), [-0.00115,   inf] (54), 
length of domains: 8928
Total time: 2.5851	 pickout: 0.2046	 decision: 0.6901	 get_bound: 1.6802	 add_domain: 0.0103
Current lb:-0.001153079210780561
113216 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 158.1859712600708

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 308] [1, 1777] [1, 531] [1, 531] [1, 1147] [1, 1049] [1, 418] [1, 893] [1, 1777] [1, 308] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -8.333834648132324 with beta sum per layer: [0.0, 657.337646484375, 8.089534759521484]
alpha/beta optimization time: 0.9326648712158203
This batch time : update_bounds func: 1.3690	 prepare: 0.2157	 bound: 0.9331	 transfer: 0.0694	 finalize: 0.1448
Accumulated time: update_bounds func: 86.6223	 prepare: 12.7480	 bound: 56.1117	 transfer: 0.0694	 finalize: 12.4235
batch bounding time:  1.371230125427246
Current worst splitting domains [lb, ub] (depth):
[-0.00101,   inf] (56), [-0.00101,   inf] (52), [-0.00101,   inf] (44), [-0.00101,   inf] (64), [-0.00101,   inf] (60), [-0.00101,   inf] (56), [-0.00101,   inf] (50), [-0.00101,   inf] (42), [-0.00101,   inf] (54), [-0.00101,   inf] (50), [-0.00101,   inf] (60), [-0.00101,   inf] (42), [-0.00101,   inf] (56), [-0.00101,   inf] (60), [-0.00101,   inf] (48), [-0.00101,   inf] (46), [-0.00101,   inf] (68), [-0.00101,   inf] (46), [-0.00101,   inf] (42), [-0.00101,   inf] (58), 
length of domains: 7952
Total time: 2.2729	 pickout: 0.1998	 decision: 0.6939	 get_bound: 1.3747	 add_domain: 0.0045
Current lb:-0.0010089874267578125
115264 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 160.50375890731812

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 531] [1, 982] [1, 1437] [1, 990] [1, 1147] [1, 1147] [1, 1777] [1, 1638] [1, 1147] [1, 982] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -8.484604835510254 with beta sum per layer: [0.0, 655.2722778320312, 9.44478702545166]
alpha/beta optimization time: 0.9167840480804443
This batch time : update_bounds func: 1.3374	 prepare: 0.2053	 bound: 0.9171	 transfer: 0.0607	 finalize: 0.1482
Accumulated time: update_bounds func: 87.9597	 prepare: 12.9533	 bound: 57.0289	 transfer: 0.0607	 finalize: 12.5717
batch bounding time:  1.3397619724273682
Current worst splitting domains [lb, ub] (depth):
[-0.00087,   inf] (48), [-0.00087,   inf] (44), [-0.00087,   inf] (50), [-0.00087,   inf] (44), [-0.00087,   inf] (58), [-0.00087,   inf] (48), [-0.00087,   inf] (48), [-0.00087,   inf] (56), [-0.00087,   inf] (44), [-0.00087,   inf] (56), [-0.00087,   inf] (54), [-0.00087,   inf] (60), [-0.00087,   inf] (48), [-0.00087,   inf] (54), [-0.00087,   inf] (54), [-0.00087,   inf] (58), [-0.00087,   inf] (62), [-0.00087,   inf] (58), [-0.00087,   inf] (56), [-0.00087,   inf] (62), 
length of domains: 6940
Total time: 2.4715	 pickout: 0.1909	 decision: 0.9352	 get_bound: 1.3434	 add_domain: 0.0020
Current lb:-0.0008683204650878906
117312 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 163.0215117931366

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2041] [1, 1049] [1, 1777] [1, 1777] [1, 538] [1, 1049] [1, 1049] [1, 531] [1, 1049] [1, 531] 
regular batch size: 2*1024, diving batch size 1*0

all verified at 17th iter
best_l after optimization: -8.619226455688477 with beta sum per layer: [0.0, 661.4029541015625, 12.67280101776123]
alpha/beta optimization time: 0.7481718063354492
This batch time : update_bounds func: 1.1676	 prepare: 0.2038	 bound: 0.7485	 transfer: 0.0691	 finalize: 0.1402
Accumulated time: update_bounds func: 89.1273	 prepare: 13.1570	 bound: 57.7774	 transfer: 0.0691	 finalize: 12.7119
batch bounding time:  1.1694726943969727
Current worst splitting domains [lb, ub] (depth):
[-0.00073,   inf] (42), [-0.00073,   inf] (54), [-0.00073,   inf] (64), [-0.00073,   inf] (46), [-0.00073,   inf] (44), [-0.00073,   inf] (54), [-0.00073,   inf] (48), [-0.00073,   inf] (46), [-0.00073,   inf] (54), [-0.00073,   inf] (56), [-0.00073,   inf] (56), [-0.00073,   inf] (62), [-0.00073,   inf] (64), [-0.00073,   inf] (56), [-0.00073,   inf] (70), [-0.00073,   inf] (46), [-0.00073,   inf] (42), [-0.00073,   inf] (58), [-0.00073,   inf] (44), [-0.00073,   inf] (58), 
length of domains: 5916
Total time: 2.2645	 pickout: 0.1947	 decision: 0.8960	 get_bound: 1.1728	 add_domain: 0.0011
Current lb:-0.0007333755493164062
119360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 165.33249020576477

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1638] [1, 1147] [1, 990] [2, 27] [1, 1049] [1, 893] [1, 2041] [1, 417] [1, 893] [1, 531] 
regular batch size: 2*1024, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -9.128393173217773 with beta sum per layer: [0.0, 661.1348876953125, 11.287043571472168]
alpha/beta optimization time: 0.028321504592895508
This batch time : update_bounds func: 0.4420	 prepare: 0.1995	 bound: 0.0286	 transfer: 0.0685	 finalize: 0.1393
Accumulated time: update_bounds func: 89.5692	 prepare: 13.3565	 bound: 57.8060	 transfer: 0.0685	 finalize: 12.8512
batch bounding time:  0.4438042640686035
Current worst splitting domains [lb, ub] (depth):
[-0.00061,   inf] (50), [-0.00060,   inf] (42), [-0.00060,   inf] (42), [-0.00060,   inf] (44), [-0.00060,   inf] (42), [-0.00060,   inf] (50), [-0.00060,   inf] (50), [-0.00060,   inf] (48), [-0.00060,   inf] (48), [-0.00060,   inf] (48), [-0.00060,   inf] (54), [-0.00060,   inf] (56), [-0.00060,   inf] (58), [-0.00060,   inf] (56), [-0.00060,   inf] (48), [-0.00060,   inf] (48), [-0.00060,   inf] (60), [-0.00060,   inf] (64), [-0.00060,   inf] (58), [-0.00060,   inf] (36), 
length of domains: 4892
Total time: 1.5136	 pickout: 0.1937	 decision: 0.8718	 get_bound: 0.4471	 add_domain: 0.0011
Current lb:-0.0006051063537597656
121408 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 166.88983798027039

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 982] [2, 27] [1, 1638] [1, 1777] [2, 27] [1, 982] [1, 1777] [1, 2041] [1, 2041] [1, 2041] 
regular batch size: 2*1024, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -9.183797836303711 with beta sum per layer: [0.0, 658.2388916015625, 9.102628707885742]
alpha/beta optimization time: 0.02832770347595215
This batch time : update_bounds func: 0.4264	 prepare: 0.2014	 bound: 0.0286	 transfer: 0.0507	 finalize: 0.1398
Accumulated time: update_bounds func: 89.9956	 prepare: 13.5580	 bound: 57.8346	 transfer: 0.0507	 finalize: 12.9910
batch bounding time:  0.4282262325286865
Current worst splitting domains [lb, ub] (depth):
[-0.00047,   inf] (58), [-0.00047,   inf] (54), [-0.00047,   inf] (58), [-0.00047,   inf] (36), [-0.00047,   inf] (58), [-0.00047,   inf] (58), [-0.00047,   inf] (58), [-0.00047,   inf] (36), [-0.00047,   inf] (42), [-0.00047,   inf] (58), [-0.00047,   inf] (66), [-0.00047,   inf] (62), [-0.00047,   inf] (56), [-0.00047,   inf] (56), [-0.00047,   inf] (56), [-0.00047,   inf] (54), [-0.00047,   inf] (58), [-0.00047,   inf] (58), [-0.00047,   inf] (60), [-0.00047,   inf] (50), 
length of domains: 3868
Total time: 1.4703	 pickout: 0.1915	 decision: 0.8462	 get_bound: 0.4315	 add_domain: 0.0011
Current lb:-0.0004725456237792969
123456 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 168.40300297737122

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 308] [1, 893] [1, 538] [1, 1437] [1, 308] [1, 308] [1, 308] [1, 1776] [2, 27] [1, 538] 
regular batch size: 2*1024, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -9.503836631774902 with beta sum per layer: [0.0, 660.95068359375, 8.906478881835938]
alpha/beta optimization time: 0.028349876403808594
This batch time : update_bounds func: 0.5547	 prepare: 0.2024	 bound: 0.0286	 transfer: 0.0392	 finalize: 0.2787
Accumulated time: update_bounds func: 90.5503	 prepare: 13.7604	 bound: 57.8633	 transfer: 0.0392	 finalize: 13.2696
batch bounding time:  0.5567035675048828
Current worst splitting domains [lb, ub] (depth):
[-0.00035,   inf] (44), [-0.00035,   inf] (44), [-0.00035,   inf] (56), [-0.00035,   inf] (56), [-0.00035,   inf] (42), [-0.00035,   inf] (62), [-0.00035,   inf] (52), [-0.00035,   inf] (52), [-0.00035,   inf] (52), [-0.00035,   inf] (54), [-0.00035,   inf] (58), [-0.00035,   inf] (44), [-0.00035,   inf] (52), [-0.00035,   inf] (54), [-0.00035,   inf] (50), [-0.00035,   inf] (62), [-0.00035,   inf] (52), [-0.00035,   inf] (58), [-0.00035,   inf] (62), [-0.00035,   inf] (50), 
length of domains: 2844
Total time: 1.5665	 pickout: 0.1909	 decision: 0.8145	 get_bound: 0.5601	 add_domain: 0.0011
Current lb:-0.0003495671262498945
125504 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 170.01371121406555

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1777] [1, 1777] [1, 531] [1, 531] [2, 27] [1, 990] [1, 982] [1, 982] [1, 893] [1, 1147] 
regular batch size: 2*1024, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -9.670851707458496 with beta sum per layer: [0.0, 653.6890869140625, 9.88189697265625]
alpha/beta optimization time: 0.02836298942565918
This batch time : update_bounds func: 0.5161	 prepare: 0.2005	 bound: 0.0287	 transfer: 0.0375	 finalize: 0.2435
Accumulated time: update_bounds func: 91.0664	 prepare: 13.9610	 bound: 57.8920	 transfer: 0.0375	 finalize: 13.5131
batch bounding time:  0.5178499221801758
Current worst splitting domains [lb, ub] (depth):
[-0.00022,   inf] (54), [-0.00022,   inf] (52), [-0.00022,   inf] (54), [-0.00022,   inf] (54), [-0.00022,   inf] (58), [-0.00022,   inf] (44), [-0.00022,   inf] (56), [-0.00022,   inf] (58), [-0.00022,   inf] (62), [-0.00022,   inf] (64), [-0.00022,   inf] (58), [-0.00022,   inf] (44), [-0.00022,   inf] (44), [-0.00022,   inf] (62), [-0.00022,   inf] (62), [-0.00022,   inf] (64), [-0.00022,   inf] (54), [-0.00022,   inf] (50), [-0.00022,   inf] (62), [-0.00022,   inf] (58), 
length of domains: 1820
Total time: 1.3974	 pickout: 0.1931	 decision: 0.6822	 get_bound: 0.5210	 add_domain: 0.0010
Current lb:-0.00022459030151367188
127552 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 171.45059156417847

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1147] [1, 982] [1, 893] [1, 893] [1, 538] [1, 1777] [1, 531] [1, 538] [1, 418] [1, 990] 
regular batch size: 2*1024, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -10.345224380493164 with beta sum per layer: [0.0, 656.510009765625, 14.114128112792969]
alpha/beta optimization time: 0.028326988220214844
This batch time : update_bounds func: 0.4668	 prepare: 0.2003	 bound: 0.0286	 transfer: 0.0229	 finalize: 0.1259
Accumulated time: update_bounds func: 91.5332	 prepare: 14.1613	 bound: 57.9206	 transfer: 0.0229	 finalize: 13.6390
batch bounding time:  0.4684927463531494
Current worst splitting domains [lb, ub] (depth):
[-0.00010,   inf] (44), [-0.00010,   inf] (56), [-0.00010,   inf] (46), [-0.00010,   inf] (60), [-0.00010,   inf] (52), [-0.00010,   inf] (42), [-0.00010,   inf] (52), [-0.00010,   inf] (56), [-0.00010,   inf] (48), [-0.00010,   inf] (72), [-0.00010,   inf] (48), [-0.00010,   inf] (42), [-0.00010,   inf] (56), [-0.00010,   inf] (58), [-0.00010,   inf] (58), [-0.00010,   inf] (62), [-0.00010,   inf] (64), [-0.00010,   inf] (64), [-0.00010,   inf] (52), [-0.00010,   inf] (56), 
length of domains: 796
Total time: 1.3544	 pickout: 0.2002	 decision: 0.6815	 get_bound: 0.4717	 add_domain: 0.0010
Current lb:-9.679794311523438e-05
129600 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 172.84367489814758

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([796, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([796, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1437] [1, 531] [2, 27] [1, 417] [1, 893] [1, 1638] [1, 982] [1, 531] [1, 1049] [1, 414] 
regular batch size: 2*796, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -8.069740295410156 with beta sum per layer: [0.0, 519.5614624023438, 7.305856704711914]
alpha/beta optimization time: 0.023935794830322266
This batch time : update_bounds func: 0.3465	 prepare: 0.1542	 bound: 0.0242	 transfer: 0.0170	 finalize: 0.0948
Accumulated time: update_bounds func: 91.8797	 prepare: 14.3155	 bound: 57.9448	 transfer: 0.0170	 finalize: 13.7338
batch bounding time:  0.34787583351135254
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 1.0587	 pickout: 0.1799	 decision: 0.5278	 get_bound: 0.3502	 add_domain: 0.0008
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 173.96643137931824

Image 89 label 0 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 174.0485966205597
89 1.0000000116860974e-07
Result: image 89 verification success (with branch and bound)!
Wall time: 174.0797016620636

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 1): [89]
verification failure idx (total 0): []
final verified acc: 100.0%[1]
verifier is called on 1 examples.
total verified: 1
mean time [cnt:1] (excluding attack success): 174.0485966205597
