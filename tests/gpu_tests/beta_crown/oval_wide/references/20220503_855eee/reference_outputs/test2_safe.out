Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: specify-target
  complete_verifier: bab
  enable_incomplete_verification: false
  get_crown_verified_acc: false
model:
  path: cifar_wide.pth
  name: cifar_model_wide
data:
  start: 34
  end: 35
  num_outputs: 10
  mean: [0.485, 0.456, 0.406]
  std: [0.225, 0.225, 0.225]
  pkl_path: wide_100.pkl
  dataset: CIFAR
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: null
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 1024
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 72
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: fsb
    candidates: 1
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Tue May  3 01:33:42 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Flatten()
  (5): Linear(in_features=2048, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=10, bias=True)
)
No epsilon defined!
Files already downloaded and verified
Overwrite epsilon that saved in .pkl file, they should be after normalized!
Task length: 1
saving results to Verified_ret_[cifar_model_wide]_start=34_end=35_iter=20_b=1024_timeout=72_branching=fsb-min-1_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 34 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 8, correct label 8, image norm 4008.830078125, logits tensor([ 2.0235,  1.6131, -1.0751, -0.9034, -0.5226, -2.0158, -1.4809, -2.7890,
         3.2524,  1.8978], device='cuda:0', grad_fn=<SelectBackward>)
##### [0:34] Tested against 9 ######
Model prediction is: tensor([[ 2.0235,  1.6131, -1.0751, -0.9034, -0.5226, -2.0158, -1.4809, -2.7890,
          3.2524,  1.8978]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-0.6049]], device='cuda:0') None
best_l after optimization: 0.3888099789619446 with beta sum per layer: []
alpha/beta optimization time: 7.521622896194458
initial alpha-CROWN bounds: tensor([[-0.3888]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.3888, device='cuda:0', grad_fn=<MinBackward1>)
-0.3888099789619446
layer 0 size torch.Size([4096]) unstable 482
layer 1 size torch.Size([2048]) unstable 198
layer 2 size torch.Size([100]) unstable 18
-----------------
# of unstable neurons: 698
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 16, 16]) pre split depth:  6
batch:  torch.Size([1, 16, 16, 16]) post split depth:  6
splitting decisions: 
split level 0: [2, 20] 
split level 1: [2, 32] 
split level 2: [2, 23] 
split level 3: [1, 1300] 
split level 4: [1, 28] 
split level 5: [1, 706] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: -1.6480672359466553 with beta sum per layer: [0.0, 1.077180027961731, 5.705569267272949]
alpha/beta optimization time: 0.2932155132293701
This batch time : update_bounds func: 0.3111	 prepare: 0.0087	 bound: 0.2936	 transfer: 0.0029	 finalize: 0.0056
Accumulated time: update_bounds func: 0.3111	 prepare: 0.0087	 bound: 0.2936	 transfer: 0.0029	 finalize: 0.0056
batch bounding time:  0.3112945556640625
Current worst splitting domains [lb, ub] (depth):
[-0.11100,   inf] (7), [-0.10511,   inf] (7), [-0.09889,   inf] (7), [-0.09711,   inf] (7), [-0.09308,   inf] (7), [-0.09064,   inf] (7), [-0.08495,   inf] (7), [-0.07853,   inf] (7), [-0.02313,   inf] (7), [-0.01777,   inf] (7), [-0.01465,   inf] (7), [-0.01317,   inf] (7), [-0.01115,   inf] (7), [-0.00801,   inf] (7), [-0.00706,   inf] (7), [-0.00623,   inf] (7), [-0.00579,   inf] (7), [-0.00171,   inf] (7), [-0.00117,   inf] (7), 
length of domains: 19
Total time: 0.4123	 pickout: 0.0011	 decision: 0.0883	 get_bound: 0.3221	 add_domain: 0.0007
Current lb:-0.11100000143051147
64 neurons visited
0 diving domains visited
Global ub: tensor([[inf]], device='cuda:0'), batch ub: inf
Cumulative time: 9.730815172195435

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([19, 16, 16, 16]) pre split depth:  2
batch:  torch.Size([19, 16, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [1, 877] [1, 877] [1, 877] [1, 1309] [1, 877] [1, 1309] [1, 1309] [1, 1309] [1, 877] [1, 877] 
split level 1: [1, 1309] [1, 1309] [1, 1309] [1, 877] [1, 1309] [1, 877] [1, 877] [1, 877] [1, 1309] [1, 1309] 
regular batch size: 2*38, diving batch size 1*0
best_l after optimization: 1.8006607294082642 with beta sum per layer: [0.0, 2.7827959060668945, 7.302440643310547]
alpha/beta optimization time: 0.28600168228149414
This batch time : update_bounds func: 0.3081	 prepare: 0.0122	 bound: 0.2864	 transfer: 0.0031	 finalize: 0.0063
Accumulated time: update_bounds func: 0.6193	 prepare: 0.0209	 bound: 0.5799	 transfer: 0.0031	 finalize: 0.0119
batch bounding time:  0.3083016872406006
Current worst splitting domains [lb, ub] (depth):
[-0.09220,   inf] (10), [-0.08910,   inf] (10), [-0.08717,   inf] (10), [-0.08606,   inf] (10), [-0.08430,   inf] (10), [-0.08295,   inf] (10), [-0.08191,   inf] (10), [-0.08009,   inf] (10), [-0.07905,   inf] (10), [-0.07711,   inf] (10), [-0.07700,   inf] (10), [-0.07530,   inf] (10), [-0.07502,   inf] (10), [-0.07434,   inf] (10), [-0.07401,   inf] (10), [-0.07253,   inf] (10), [-0.07215,   inf] (10), [-0.07094,   inf] (10), [-0.07074,   inf] (10), [-0.06983,   inf] (10), 
length of domains: 34
Total time: 0.3788	 pickout: 0.0048	 decision: 0.0575	 get_bound: 0.3153	 add_domain: 0.0013
Current lb:-0.09220393002033234
140 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.110069274902344

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([34, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([34, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 876] [1, 876] [1, 876] [1, 876] [1, 876] [1, 876] [1, 876] [1, 876] [1, 876] [1, 876] 
regular batch size: 2*34, diving batch size 1*0
best_l after optimization: 3.1226534843444824 with beta sum per layer: [0.0, 8.792121887207031, 0.4101071357727051]
alpha/beta optimization time: 0.2858762741088867
This batch time : update_bounds func: 0.3070	 prepare: 0.0129	 bound: 0.2863	 transfer: 0.0020	 finalize: 0.0056
Accumulated time: update_bounds func: 0.9263	 prepare: 0.0338	 bound: 0.8662	 transfer: 0.0020	 finalize: 0.0175
batch bounding time:  0.3072390556335449
Current worst splitting domains [lb, ub] (depth):
[-0.08596,   inf] (12), [-0.08220,   inf] (12), [-0.08089,   inf] (12), [-0.07986,   inf] (12), [-0.07731,   inf] (12), [-0.07618,   inf] (12), [-0.07570,   inf] (12), [-0.07383,   inf] (12), [-0.07208,   inf] (12), [-0.07082,   inf] (12), [-0.07008,   inf] (12), [-0.06908,   inf] (12), [-0.06873,   inf] (12), [-0.06778,   inf] (12), [-0.06749,   inf] (12), [-0.06583,   inf] (12), [-0.06519,   inf] (12), [-0.06450,   inf] (12), [-0.06407,   inf] (12), [-0.06357,   inf] (12), 
length of domains: 64
Total time: 0.3611	 pickout: 0.0076	 decision: 0.0439	 get_bound: 0.3074	 add_domain: 0.0022
Current lb:-0.08595933020114899
208 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.471686363220215

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([64, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1382] [1, 1382] [1, 1382] [1, 1382] [1, 1382] [1, 1382] [1, 1382] [1, 1382] [1, 1382] [1, 1382] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.040645599365234 with beta sum per layer: [0.0, 18.249134063720703, 0.0]
alpha/beta optimization time: 0.29285144805908203
This batch time : update_bounds func: 0.3297	 prepare: 0.0193	 bound: 0.2932	 transfer: 0.0058	 finalize: 0.0110
Accumulated time: update_bounds func: 1.2559	 prepare: 0.0531	 bound: 1.1594	 transfer: 0.0058	 finalize: 0.0286
batch bounding time:  0.3299214839935303
Current worst splitting domains [lb, ub] (depth):
[-0.07747,   inf] (14), [-0.07432,   inf] (14), [-0.07350,   inf] (14), [-0.07145,   inf] (14), [-0.07129,   inf] (14), [-0.07108,   inf] (14), [-0.06997,   inf] (14), [-0.06814,   inf] (14), [-0.06767,   inf] (14), [-0.06739,   inf] (14), [-0.06688,   inf] (14), [-0.06623,   inf] (14), [-0.06535,   inf] (14), [-0.06491,   inf] (14), [-0.06475,   inf] (14), [-0.06250,   inf] (14), [-0.06224,   inf] (14), [-0.06161,   inf] (14), [-0.06151,   inf] (14), [-0.06139,   inf] (14), 
length of domains: 128
Total time: 0.4155	 pickout: 0.0133	 decision: 0.0675	 get_bound: 0.3302	 add_domain: 0.0045
Current lb:-0.07747180014848709
336 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.887832880020142

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([128, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([128, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 884] [1, 884] [1, 884] [1, 884] [1, 884] [1, 884] [1, 884] [1, 884] [1, 884] [1, 884] 
regular batch size: 2*128, diving batch size 1*0
best_l after optimization: 6.979771614074707 with beta sum per layer: [0.0, 46.5472297668457, 0.0]
alpha/beta optimization time: 0.3155937194824219
This batch time : update_bounds func: 0.3859	 prepare: 0.0367	 bound: 0.3160	 transfer: 0.0117	 finalize: 0.0210
Accumulated time: update_bounds func: 1.6418	 prepare: 0.0898	 bound: 1.4754	 transfer: 0.0117	 finalize: 0.0495
batch bounding time:  0.3861994743347168
Current worst splitting domains [lb, ub] (depth):
[-0.07052,   inf] (16), [-0.06743,   inf] (16), [-0.06659,   inf] (16), [-0.06448,   inf] (16), [-0.06433,   inf] (16), [-0.06428,   inf] (16), [-0.06338,   inf] (16), [-0.06300,   inf] (16), [-0.06123,   inf] (16), [-0.06071,   inf] (16), [-0.06039,   inf] (16), [-0.06035,   inf] (16), [-0.05997,   inf] (16), [-0.05962,   inf] (16), [-0.05925,   inf] (16), [-0.05839,   inf] (16), [-0.05808,   inf] (16), [-0.05778,   inf] (16), [-0.05734,   inf] (16), [-0.05733,   inf] (16), 
length of domains: 219
Total time: 0.5422	 pickout: 0.0256	 decision: 0.1212	 get_bound: 0.3867	 add_domain: 0.0087
Current lb:-0.0705232173204422
592 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.431713581085205

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([219, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([219, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1294] [1, 1294] [1, 1294] [1, 1294] [1, 1294] [1, 1294] [1, 1294] [1, 1294] [1, 1294] [1, 1294] 
regular batch size: 2*219, diving batch size 1*0
best_l after optimization: 9.862510681152344 with beta sum per layer: [0.0, 70.09527587890625, 0.0]
alpha/beta optimization time: 0.3636138439178467
This batch time : update_bounds func: 0.4805	 prepare: 0.0616	 bound: 0.3640	 transfer: 0.0175	 finalize: 0.0365
Accumulated time: update_bounds func: 2.1223	 prepare: 0.1514	 bound: 1.8393	 transfer: 0.0175	 finalize: 0.0861
batch bounding time:  0.48093366622924805
Current worst splitting domains [lb, ub] (depth):
[-0.06345,   inf] (18), [-0.06040,   inf] (18), [-0.05946,   inf] (18), [-0.05753,   inf] (18), [-0.05740,   inf] (18), [-0.05723,   inf] (18), [-0.05723,   inf] (18), [-0.05630,   inf] (18), [-0.05592,   inf] (18), [-0.05455,   inf] (18), [-0.05418,   inf] (18), [-0.05360,   inf] (18), [-0.05350,   inf] (18), [-0.05331,   inf] (18), [-0.05326,   inf] (18), [-0.05288,   inf] (18), [-0.05249,   inf] (18), [-0.05221,   inf] (18), [-0.05143,   inf] (18), [-0.05141,   inf] (18), 
length of domains: 370
Total time: 0.7413	 pickout: 0.0431	 decision: 0.2025	 get_bound: 0.4816	 add_domain: 0.0140
Current lb:-0.0634472668170929
1030 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.17577314376831

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([370, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([370, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1302] [1, 1302] [1, 1302] [1, 1302] [1, 1302] [1, 1302] [1, 1302] [1, 1302] [1, 1302] [1, 1302] 
regular batch size: 2*370, diving batch size 1*0
best_l after optimization: 13.181151390075684 with beta sum per layer: [0.0, 100.0758056640625, 0.0]
alpha/beta optimization time: 0.4712531566619873
This batch time : update_bounds func: 0.7250	 prepare: 0.1023	 bound: 0.4716	 transfer: 0.0273	 finalize: 0.1219
Accumulated time: update_bounds func: 2.8472	 prepare: 0.2537	 bound: 2.3110	 transfer: 0.0273	 finalize: 0.2079
batch bounding time:  0.7257437705993652
Current worst splitting domains [lb, ub] (depth):
[-0.05717,   inf] (20), [-0.05416,   inf] (20), [-0.05316,   inf] (20), [-0.05172,   inf] (20), [-0.05100,   inf] (20), [-0.05083,   inf] (20), [-0.05066,   inf] (20), [-0.05025,   inf] (20), [-0.05018,   inf] (20), [-0.05000,   inf] (20), [-0.04792,   inf] (20), [-0.04780,   inf] (20), [-0.04771,   inf] (20), [-0.04721,   inf] (20), [-0.04719,   inf] (20), [-0.04704,   inf] (20), [-0.04682,   inf] (20), [-0.04681,   inf] (20), [-0.04664,   inf] (20), [-0.04643,   inf] (20), 
length of domains: 617
Total time: 1.1480	 pickout: 0.0726	 decision: 0.3232	 get_bound: 0.7269	 add_domain: 0.0253
Current lb:-0.05717293545603752
1770 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.32882308959961

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([617, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([617, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 76] [2, 76] [2, 76] [1, 1301] [2, 76] [1, 1301] [2, 76] [1, 1301] [2, 76] [2, 76] 
regular batch size: 2*617, diving batch size 1*0
best_l after optimization: 5.609724998474121 with beta sum per layer: [0.0, 175.00784301757812, 4.410482406616211]
alpha/beta optimization time: 0.6593830585479736
This batch time : update_bounds func: 0.9837	 prepare: 0.1769	 bound: 0.6598	 transfer: 0.0384	 finalize: 0.1056
Accumulated time: update_bounds func: 3.8310	 prepare: 0.4306	 bound: 2.9708	 transfer: 0.0384	 finalize: 0.3136
batch bounding time:  0.9849021434783936
Current worst splitting domains [lb, ub] (depth):
[-0.05327,   inf] (22), [-0.05029,   inf] (22), [-0.04920,   inf] (22), [-0.04709,   inf] (22), [-0.04678,   inf] (22), [-0.04674,   inf] (22), [-0.04638,   inf] (22), [-0.04623,   inf] (22), [-0.04607,   inf] (22), [-0.04525,   inf] (22), [-0.04380,   inf] (22), [-0.04328,   inf] (22), [-0.04326,   inf] (22), [-0.04314,   inf] (22), [-0.04292,   inf] (22), [-0.04287,   inf] (22), [-0.04271,   inf] (22), [-0.04238,   inf] (22), [-0.04228,   inf] (22), [-0.04221,   inf] (22), 
length of domains: 733
Total time: 1.7234	 pickout: 0.1254	 decision: 0.5303	 get_bound: 0.9868	 add_domain: 0.0808
Current lb:-0.053273603320121765
3004 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.062376737594604

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([733, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([733, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1301] [1, 1301] [1, 1301] [1, 1301] [1, 1301] [2, 76] [2, 76] [1, 1301] [1, 1301] [2, 76] 
regular batch size: 2*733, diving batch size 1*0
best_l after optimization: 2.55898380279541 with beta sum per layer: [0.0, 186.04660034179688, 0.7119796872138977]
alpha/beta optimization time: 0.7510442733764648
This batch time : update_bounds func: 1.1186	 prepare: 0.2076	 bound: 0.7514	 transfer: 0.0326	 finalize: 0.1233
Accumulated time: update_bounds func: 4.9496	 prepare: 0.6381	 bound: 3.7222	 transfer: 0.0326	 finalize: 0.4369
batch bounding time:  1.1199383735656738
Current worst splitting domains [lb, ub] (depth):
[-0.04950,   inf] (24), [-0.04647,   inf] (24), [-0.04543,   inf] (24), [-0.04334,   inf] (24), [-0.04328,   inf] (24), [-0.04326,   inf] (24), [-0.04281,   inf] (24), [-0.04252,   inf] (24), [-0.04226,   inf] (24), [-0.04133,   inf] (24), [-0.04034,   inf] (24), [-0.04022,   inf] (24), [-0.03979,   inf] (24), [-0.03944,   inf] (24), [-0.03930,   inf] (24), [-0.03926,   inf] (24), [-0.03924,   inf] (24), [-0.03898,   inf] (24), [-0.03853,   inf] (24), [-0.03834,   inf] (24), 
length of domains: 800
Total time: 1.9859	 pickout: 0.1498	 decision: 0.6286	 get_bound: 1.1223	 add_domain: 0.0852
Current lb:-0.04949678108096123
4470 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.061848163604736

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([800, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([800, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 26] [1, 26] [1, 26] [1, 26] [1, 26] [1, 26] [1, 26] [1, 26] [1, 26] [1, 26] 
regular batch size: 2*800, diving batch size 1*0
best_l after optimization: 10.912443161010742 with beta sum per layer: [0.0, 175.2276611328125, 0.0]
alpha/beta optimization time: 0.7990603446960449
This batch time : update_bounds func: 1.2501	 prepare: 0.2247	 bound: 0.7994	 transfer: 0.0336	 finalize: 0.1885
Accumulated time: update_bounds func: 6.1997	 prepare: 0.8628	 bound: 4.5216	 transfer: 0.0336	 finalize: 0.6254
batch bounding time:  1.2518432140350342
Current worst splitting domains [lb, ub] (depth):
[-0.04555,   inf] (26), [-0.04254,   inf] (26), [-0.04146,   inf] (26), [-0.03937,   inf] (26), [-0.03930,   inf] (26), [-0.03918,   inf] (26), [-0.03883,   inf] (26), [-0.03853,   inf] (26), [-0.03828,   inf] (26), [-0.03737,   inf] (26), [-0.03639,   inf] (26), [-0.03621,   inf] (26), [-0.03581,   inf] (26), [-0.03571,   inf] (26), [-0.03547,   inf] (26), [-0.03534,   inf] (26), [-0.03527,   inf] (26), [-0.03512,   inf] (26), [-0.03502,   inf] (26), [-0.03452,   inf] (26), 
length of domains: 1103
Total time: 2.1557	 pickout: 0.1675	 decision: 0.6850	 get_bound: 1.2545	 add_domain: 0.0487
Current lb:-0.04554739594459534
6070 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 19.23021149635315

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 869] [1, 869] [1, 869] [1, 869] [1, 869] [1, 869] [1, 869] [1, 869] [1, 869] [1, 869] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1.720170021057129 with beta sum per layer: [0.0, 188.50375366210938, 0.0]
alpha/beta optimization time: 0.9643914699554443
This batch time : update_bounds func: 1.4906	 prepare: 0.2853	 bound: 0.9648	 transfer: 0.0511	 finalize: 0.1839
Accumulated time: update_bounds func: 7.6903	 prepare: 1.1481	 bound: 5.4864	 transfer: 0.0511	 finalize: 0.8094
batch bounding time:  1.49226713180542
Current worst splitting domains [lb, ub] (depth):
[-0.03926,   inf] (28), [-0.03768,   inf] (28), [-0.03705,   inf] (28), [-0.03474,   inf] (28), [-0.03417,   inf] (28), [-0.03355,   inf] (28), [-0.03308,   inf] (28), [-0.03294,   inf] (28), [-0.03227,   inf] (28), [-0.03205,   inf] (28), [-0.03197,   inf] (28), [-0.03192,   inf] (28), [-0.03186,   inf] (28), [-0.03149,   inf] (28), [-0.03144,   inf] (28), [-0.03143,   inf] (28), [-0.03127,   inf] (28), [-0.03091,   inf] (28), [-0.03074,   inf] (28), [-0.03066,   inf] (28), 
length of domains: 1357
Total time: 2.6578	 pickout: 0.2225	 decision: 0.8799	 get_bound: 1.4951	 add_domain: 0.0603
Current lb:-0.03925633430480957
8118 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 21.906005144119263

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1307] [1, 1307] [1, 1307] [1, 1307] [1, 1307] [1, 1307] [1, 1307] [1, 1307] [1, 1307] [1, 1307] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 8.958595275878906 with beta sum per layer: [0.0, 166.61480712890625, 0.0]
alpha/beta optimization time: 0.9525814056396484
This batch time : update_bounds func: 1.3294	 prepare: 0.1860	 bound: 0.9529	 transfer: 0.0668	 finalize: 0.1186
Accumulated time: update_bounds func: 9.0197	 prepare: 1.3341	 bound: 6.4393	 transfer: 0.0668	 finalize: 0.9280
batch bounding time:  1.331047534942627
Current worst splitting domains [lb, ub] (depth):
[-0.03548,   inf] (30), [-0.03397,   inf] (30), [-0.03326,   inf] (30), [-0.03098,   inf] (30), [-0.03038,   inf] (30), [-0.02978,   inf] (30), [-0.02938,   inf] (30), [-0.02933,   inf] (30), [-0.02849,   inf] (30), [-0.02823,   inf] (30), [-0.02820,   inf] (30), [-0.02815,   inf] (30), [-0.02808,   inf] (30), [-0.02805,   inf] (30), [-0.02781,   inf] (30), [-0.02774,   inf] (30), [-0.02773,   inf] (30), [-0.02714,   inf] (30), [-0.02711,   inf] (30), [-0.02670,   inf] (30), 
length of domains: 1693
Total time: 2.3297	 pickout: 0.1590	 decision: 0.7078	 get_bound: 1.3339	 add_domain: 0.1290
Current lb:-0.03548040613532066
10166 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 24.253253698349

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 797] [1, 797] [1, 797] [1, 797] [1, 797] [1, 797] [1, 797] [1, 797] [1, 797] [1, 797] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 4.082812309265137 with beta sum per layer: [0.0, 162.0249481201172, 0.0]
alpha/beta optimization time: 0.9509584903717041
This batch time : update_bounds func: 1.3869	 prepare: 0.1875	 bound: 0.9513	 transfer: 0.0665	 finalize: 0.1764
Accumulated time: update_bounds func: 10.4066	 prepare: 1.5217	 bound: 7.3906	 transfer: 0.0665	 finalize: 1.1044
batch bounding time:  1.3885788917541504
Current worst splitting domains [lb, ub] (depth):
[-0.03188,   inf] (32), [-0.03033,   inf] (32), [-0.02918,   inf] (32), [-0.02718,   inf] (32), [-0.02612,   inf] (32), [-0.02608,   inf] (32), [-0.02574,   inf] (32), [-0.02539,   inf] (32), [-0.02460,   inf] (32), [-0.02416,   inf] (32), [-0.02415,   inf] (32), [-0.02414,   inf] (32), [-0.02389,   inf] (32), [-0.02375,   inf] (32), [-0.02360,   inf] (32), [-0.02310,   inf] (32), [-0.02305,   inf] (32), [-0.02296,   inf] (32), [-0.02285,   inf] (32), [-0.02275,   inf] (32), 
length of domains: 1754
Total time: 2.2682	 pickout: 0.1618	 decision: 0.6601	 get_bound: 1.3915	 add_domain: 0.0548
Current lb:-0.03188059478998184
12214 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 26.54161286354065

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1316] [1, 1316] [1, 1316] [1, 1316] [1, 1316] [1, 1316] [1, 1316] [1, 1316] [1, 1316] [1, 1316] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 0.9064291715621948 with beta sum per layer: [0.0, 159.3193359375, 0.0]
alpha/beta optimization time: 0.9723968505859375
This batch time : update_bounds func: 1.4960	 prepare: 0.2744	 bound: 0.9728	 transfer: 0.0674	 finalize: 0.1758
Accumulated time: update_bounds func: 11.9026	 prepare: 1.7961	 bound: 8.3634	 transfer: 0.0674	 finalize: 1.2802
batch bounding time:  1.4978160858154297
Current worst splitting domains [lb, ub] (depth):
[-0.02609,   inf] (34), [-0.02481,   inf] (34), [-0.02397,   inf] (34), [-0.02341,   inf] (34), [-0.02180,   inf] (34), [-0.02168,   inf] (34), [-0.02129,   inf] (34), [-0.02070,   inf] (34), [-0.02032,   inf] (34), [-0.01995,   inf] (34), [-0.01961,   inf] (34), [-0.01914,   inf] (34), [-0.01888,   inf] (34), [-0.01865,   inf] (34), [-0.01856,   inf] (34), [-0.01848,   inf] (34), [-0.01843,   inf] (34), [-0.01838,   inf] (34), [-0.01834,   inf] (34), [-0.01808,   inf] (34), 
length of domains: 1596
Total time: 2.4249	 pickout: 0.1615	 decision: 0.7167	 get_bound: 1.5013	 add_domain: 0.0455
Current lb:-0.02609020657837391
14262 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 28.989436626434326

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 64] [2, 64] [2, 64] [2, 64] [2, 64] [2, 64] [2, 64] [2, 64] [2, 64] [2, 64] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -14.858518600463867 with beta sum per layer: [0.0, 152.17190551757812, 0.0]
alpha/beta optimization time: 0.9674558639526367
This batch time : update_bounds func: 1.5734	 prepare: 0.2946	 bound: 0.9679	 transfer: 0.0665	 finalize: 0.2395
Accumulated time: update_bounds func: 13.4760	 prepare: 2.0907	 bound: 9.3313	 transfer: 0.0665	 finalize: 1.5197
batch bounding time:  1.5756781101226807
Current worst splitting domains [lb, ub] (depth):
[-0.02346,   inf] (36), [-0.02222,   inf] (36), [-0.02113,   inf] (36), [-0.02081,   inf] (36), [-0.01921,   inf] (36), [-0.01891,   inf] (36), [-0.01845,   inf] (36), [-0.01811,   inf] (36), [-0.01770,   inf] (36), [-0.01734,   inf] (36), [-0.01698,   inf] (36), [-0.01625,   inf] (36), [-0.01623,   inf] (36), [-0.01608,   inf] (36), [-0.01589,   inf] (36), [-0.01583,   inf] (36), [-0.01575,   inf] (36), [-0.01573,   inf] (36), [-0.01567,   inf] (36), [-0.01549,   inf] (36), 
length of domains: 1127
Total time: 2.7606	 pickout: 0.2205	 decision: 0.9317	 get_bound: 1.5794	 add_domain: 0.0290
Current lb:-0.02345946431159973
16310 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 31.77308702468872

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 564] [1, 564] [1, 564] [1, 564] [1, 564] [1, 564] [1, 564] [1, 564] [1, 564] [1, 564] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -30.610153198242188 with beta sum per layer: [0.0, 161.7632598876953, 0.0]
alpha/beta optimization time: 0.9548349380493164
This batch time : update_bounds func: 1.4461	 prepare: 0.1934	 bound: 0.9552	 transfer: 0.0665	 finalize: 0.2252
Accumulated time: update_bounds func: 14.9221	 prepare: 2.2841	 bound: 10.2865	 transfer: 0.0665	 finalize: 1.7449
batch bounding time:  1.4480128288269043
Current worst splitting domains [lb, ub] (depth):
[-0.02209,   inf] (38), [-0.02088,   inf] (38), [-0.01961,   inf] (38), [-0.01948,   inf] (38), [-0.01787,   inf] (38), [-0.01735,   inf] (38), [-0.01690,   inf] (38), [-0.01676,   inf] (38), [-0.01633,   inf] (38), [-0.01597,   inf] (38), [-0.01473,   inf] (38), [-0.01472,   inf] (38), [-0.01467,   inf] (38), [-0.01452,   inf] (38), [-0.01449,   inf] (38), [-0.01437,   inf] (38), [-0.01418,   inf] (38), [-0.01415,   inf] (38), [-0.01373,   inf] (38), [-0.01350,   inf] (38), 
length of domains: 512
Total time: 2.4147	 pickout: 0.2195	 decision: 0.7209	 get_bound: 1.4513	 add_domain: 0.0230
Current lb:-0.02209162712097168
18358 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 34.21286869049072

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([512, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1451] [1, 1451] [1, 1451] [1, 1451] [1, 1451] [1, 1451] [1, 1451] [1, 1451] [1, 1451] [1, 1451] 
regular batch size: 2*512, diving batch size 1*0
best_l after optimization: -4.854981422424316 with beta sum per layer: [0.0, 68.11018371582031, 0.0]
alpha/beta optimization time: 0.5507409572601318
This batch time : update_bounds func: 0.7991	 prepare: 0.1009	 bound: 0.5511	 transfer: 0.0200	 finalize: 0.1241
Accumulated time: update_bounds func: 15.7212	 prepare: 2.3851	 bound: 10.8376	 transfer: 0.0200	 finalize: 1.8690
batch bounding time:  0.8003392219543457
Current worst splitting domains [lb, ub] (depth):
[-0.01643,   inf] (40), [-0.01538,   inf] (40), [-0.01523,   inf] (40), [-0.01416,   inf] (40), [-0.01387,   inf] (40), [-0.01368,   inf] (40), [-0.01283,   inf] (40), [-0.01282,   inf] (40), [-0.01219,   inf] (40), [-0.01150,   inf] (40), [-0.01132,   inf] (40), [-0.01116,   inf] (40), [-0.01103,   inf] (40), [-0.01069,   inf] (40), [-0.01039,   inf] (40), [-0.01030,   inf] (40), [-0.01016,   inf] (40), [-0.01007,   inf] (40), [-0.00985,   inf] (40), [-0.00974,   inf] (40), 
length of domains: 276
Total time: 1.3319	 pickout: 0.1116	 decision: 0.4036	 get_bound: 0.8021	 add_domain: 0.0146
Current lb:-0.0164334774017334
19382 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 35.56055760383606

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([276, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([276, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 717] [1, 717] [1, 717] [1, 717] [1, 717] [1, 717] [1, 717] [1, 717] [1, 717] [1, 717] 
regular batch size: 2*276, diving batch size 1*0
best_l after optimization: -4.7060441970825195 with beta sum per layer: [0.0, 26.46811294555664, 0.0]
alpha/beta optimization time: 0.37979626655578613
This batch time : update_bounds func: 0.4780	 prepare: 0.0509	 bound: 0.3801	 transfer: 0.0098	 finalize: 0.0360
Accumulated time: update_bounds func: 16.1993	 prepare: 2.4360	 bound: 11.2177	 transfer: 0.0098	 finalize: 1.9050
batch bounding time:  0.4786849021911621
Current worst splitting domains [lb, ub] (depth):
[-0.01530,   inf] (42), [-0.01425,   inf] (42), [-0.01410,   inf] (42), [-0.01303,   inf] (42), [-0.01271,   inf] (42), [-0.01247,   inf] (42), [-0.01168,   inf] (42), [-0.01162,   inf] (42), [-0.01107,   inf] (42), [-0.01022,   inf] (42), [-0.01019,   inf] (42), [-0.01000,   inf] (42), [-0.00989,   inf] (42), [-0.00955,   inf] (42), [-0.00917,   inf] (42), [-0.00900,   inf] (42), [-0.00896,   inf] (42), [-0.00892,   inf] (42), [-0.00874,   inf] (42), [-0.00862,   inf] (42), 
length of domains: 211
Total time: 0.7227	 pickout: 0.0450	 decision: 0.1864	 get_bound: 0.4796	 add_domain: 0.0118
Current lb:-0.015300064347684383
19934 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 36.29153561592102

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([211, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([211, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1129] [1, 1129] [1, 1129] [1, 1129] [1, 1129] [1, 1129] [1, 1129] [1, 1129] [1, 1129] [1, 1129] 
regular batch size: 2*211, diving batch size 1*0
best_l after optimization: -0.9907082915306091 with beta sum per layer: [0.0, 20.218700408935547, 0.0]
alpha/beta optimization time: 0.33665919303894043
This batch time : update_bounds func: 0.4095	 prepare: 0.0393	 bound: 0.3370	 transfer: 0.0076	 finalize: 0.0247
Accumulated time: update_bounds func: 16.6088	 prepare: 2.4753	 bound: 11.5547	 transfer: 0.0076	 finalize: 1.9297
batch bounding time:  0.40998411178588867
Current worst splitting domains [lb, ub] (depth):
[-0.01153,   inf] (44), [-0.01050,   inf] (44), [-0.01033,   inf] (44), [-0.00926,   inf] (44), [-0.00895,   inf] (44), [-0.00868,   inf] (44), [-0.00793,   inf] (44), [-0.00780,   inf] (44), [-0.00730,   inf] (44), [-0.00644,   inf] (44), [-0.00638,   inf] (44), [-0.00623,   inf] (44), [-0.00604,   inf] (44), [-0.00578,   inf] (44), [-0.00539,   inf] (44), [-0.00518,   inf] (44), [-0.00517,   inf] (44), [-0.00515,   inf] (44), [-0.00500,   inf] (44), [-0.00487,   inf] (44), 
length of domains: 93
Total time: 0.5937	 pickout: 0.0326	 decision: 0.1445	 get_bound: 0.4107	 add_domain: 0.0060
Current lb:-0.01153254508972168
20356 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 36.88932728767395

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([93, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([93, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 29] [1, 29] [1, 29] [1, 29] [1, 1800] [1, 29] [1, 1800] [1, 29] [1, 29] [1, 29] 
regular batch size: 2*93, diving batch size 1*0
best_l after optimization: -1.0844329595565796 with beta sum per layer: [0.0, 7.494105339050293, 0.0]
alpha/beta optimization time: 0.27086305618286133
This batch time : update_bounds func: 0.3037	 prepare: 0.0181	 bound: 0.2712	 transfer: 0.0032	 finalize: 0.0108
Accumulated time: update_bounds func: 16.9125	 prepare: 2.4934	 bound: 11.8259	 transfer: 0.0032	 finalize: 1.9405
batch bounding time:  0.3039684295654297
Current worst splitting domains [lb, ub] (depth):
[-0.01015,   inf] (46), [-0.00911,   inf] (46), [-0.00901,   inf] (46), [-0.00866,   inf] (46), [-0.00794,   inf] (46), [-0.00765,   inf] (46), [-0.00724,   inf] (46), [-0.00631,   inf] (46), [-0.00598,   inf] (46), [-0.00513,   inf] (46), [-0.00505,   inf] (46), [-0.00485,   inf] (46), [-0.00477,   inf] (46), [-0.00437,   inf] (46), [-0.00434,   inf] (46), [-0.00387,   inf] (46), [-0.00379,   inf] (46), [-0.00374,   inf] (46), [-0.00370,   inf] (46), [-0.00346,   inf] (46), 
length of domains: 60
Total time: 0.3910	 pickout: 0.0144	 decision: 0.0690	 get_bound: 0.3043	 add_domain: 0.0034
Current lb:-0.010148763656616211
20542 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 37.282249212265015

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([60, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([60, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1800] [1, 1800] [1, 1800] [1, 29] [1, 1800] [1, 29] [1, 1800] [1, 1800] [1, 1800] [1, 1800] 
regular batch size: 2*60, diving batch size 1*0
best_l after optimization: -0.6041836738586426 with beta sum per layer: [0.0, 3.9400277137756348, 0.0]
alpha/beta optimization time: 0.24462175369262695
This batch time : update_bounds func: 0.2674	 prepare: 0.0123	 bound: 0.2449	 transfer: 0.0027	 finalize: 0.0072
Accumulated time: update_bounds func: 17.1799	 prepare: 2.5056	 bound: 12.0708	 transfer: 0.0027	 finalize: 1.9477
batch bounding time:  0.26754021644592285
Current worst splitting domains [lb, ub] (depth):
[-0.00988,   inf] (48), [-0.00885,   inf] (48), [-0.00875,   inf] (48), [-0.00768,   inf] (48), [-0.00709,   inf] (48), [-0.00694,   inf] (48), [-0.00605,   inf] (48), [-0.00599,   inf] (48), [-0.00571,   inf] (48), [-0.00487,   inf] (48), [-0.00476,   inf] (48), [-0.00451,   inf] (48), [-0.00410,   inf] (48), [-0.00405,   inf] (48), [-0.00361,   inf] (48), [-0.00353,   inf] (48), [-0.00340,   inf] (48), [-0.00320,   inf] (48), [-0.00319,   inf] (48), [-0.00313,   inf] (48), 
length of domains: 54
Total time: 0.3310	 pickout: 0.0096	 decision: 0.0506	 get_bound: 0.2677	 add_domain: 0.0030
Current lb:-0.009882963262498379
20662 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 37.61418318748474

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([54, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([54, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 818] [1, 818] [1, 818] [1, 818] [1, 818] [1, 818] [1, 818] [1, 818] [1, 818] [1, 818] 
regular batch size: 2*54, diving batch size 1*0
best_l after optimization: -0.9379425048828125 with beta sum per layer: [0.0, 3.499286413192749, 0.0]
alpha/beta optimization time: 0.23848772048950195
This batch time : update_bounds func: 0.2583	 prepare: 0.0111	 bound: 0.2388	 transfer: 0.0020	 finalize: 0.0062
Accumulated time: update_bounds func: 17.4382	 prepare: 2.5167	 bound: 12.3095	 transfer: 0.0020	 finalize: 1.9539
batch bounding time:  0.25847291946411133
Current worst splitting domains [lb, ub] (depth):
[-0.00688,   inf] (50), [-0.00585,   inf] (50), [-0.00574,   inf] (50), [-0.00467,   inf] (50), [-0.00410,   inf] (50), [-0.00393,   inf] (50), [-0.00304,   inf] (50), [-0.00295,   inf] (50), [-0.00272,   inf] (50), [-0.00186,   inf] (50), [-0.00171,   inf] (50), [-0.00151,   inf] (50), [-0.00111,   inf] (50), [-0.00101,   inf] (50), [-0.00061,   inf] (50), [-0.00053,   inf] (50), [-0.00041,   inf] (50), [-0.00021,   inf] (50), [-0.00019,   inf] (50), [-0.00010,   inf] (50), 
length of domains: 20
Total time: 0.3135	 pickout: 0.0084	 decision: 0.0452	 get_bound: 0.2586	 add_domain: 0.0012
Current lb:-0.006883144378662109
20770 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 37.9288592338562

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([20, 16, 16, 16]) pre split depth:  2
batch:  torch.Size([20, 16, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [1, 1628] [1, 1628] [1, 1628] [1, 1628] [1, 1628] [1, 1628] [1, 1450] [1, 1628] [1, 1628] [1, 1628] 
split level 1: [1, 1450] [1, 1450] [1, 1450] [1, 1450] [1, 1450] [1, 1450] [1, 988] [1, 1450] [1, 1450] [1, 1450] 
regular batch size: 2*40, diving batch size 1*0

all verified at 5th iter
best_l after optimization: -0.7852263450622559 with beta sum per layer: [0.0, 2.1052026748657227, 0.0]
alpha/beta optimization time: 0.07011175155639648
This batch time : update_bounds func: 0.0868	 prepare: 0.0088	 bound: 0.0704	 transfer: 0.0028	 finalize: 0.0046
Accumulated time: update_bounds func: 17.5249	 prepare: 2.5255	 bound: 12.3799	 transfer: 0.0028	 finalize: 1.9584
batch bounding time:  0.08691024780273438
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.1439	 pickout: 0.0037	 decision: 0.0477	 get_bound: 0.0924	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 38.07358384132385

Image 34 label 9 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 38.13991904258728
34 1.0000000116860974e-07
Result: image 34 verification success (with branch and bound)!
Wall time: 38.18778133392334

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 1): [34]
verification failure idx (total 0): []
final verified acc: 100.0%[1]
verifier is called on 1 examples.
total verified: 1
mean time [cnt:1] (excluding attack success): 38.13991904258728
