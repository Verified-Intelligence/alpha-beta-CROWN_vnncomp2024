Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  sparse_alpha: true
  save_adv_example: false
  precompile_jit: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
  csv_name: null
  results_file: null
  root_path: ''
model:
  path: mnist_conv_big_diffai.pth
  cache_onnx_conversion: false
  onnx_quirks: null
  name: mnist_conv_big
  onnx_path: null
  onnx_path_prefix: ''
  onnx_optimization_flags: none
data:
  start: 232
  end: 233
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: MNIST_ERAN
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.3
  vnnlib_path: null
  vnnlib_path_prefix: ''
solver:
  batch_size: 256
  no_float64_last_iter: true
  no_amp: false
  early_stop_patience: 10
  start_save_best: 2
  bound_prop_method: alpha-crown
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
    full_conv_alpha: true
  beta-crown:
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  multi_class:
    multi_class_method: allclass_domain
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
bab:
  initial_max_domains: 1
  max_domains: 200000
  decision_thresh: 0
  timeout: 180
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_intermediate_layers: ''
  interm_transfer: true
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 100
    batch_size_primal: 100
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    max_num: 1000000000
    fixed_cuts: false
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
    lr: 0.01
  branching:
    method: kfsb
    candidates: 3
    reduceop: max
    sb_coeff_thresh: 0.001
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      sort_domain_interval: -1
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 100
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  attack_mode: PGD
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 5000000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
  enable_mip_attack: false
  cex_path: ./test_cex.txt
debug:
  lp_test: null

Experiments at Tue Aug 23 16:04:08 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (5): ReLU()
  (6): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (7): ReLU()
  (8): Flatten()
  (9): Linear(in_features=3136, out_features=512, bias=True)
  (10): ReLU()
  (11): Linear(in_features=512, out_features=512, bias=True)
  (12): ReLU()
  (13): Linear(in_features=512, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([1000, 1, 28, 28]) torch.Size([1000]) torch.Size([1000])
X range: tensor(2.82148671) tensor(-0.42421296) tensor(-0.02737886)
Note runnerup label is empty here!
############################
saving results to Verified_ret_[mnist_conv_big]_start=232_end=233_iter=20_b=256_timeout=180_branching=kfsb-max-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before_cplex_cuts=False_multiclass=allclass_domain.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 232 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Attack parameters: initialization=uniform, steps=100, restarts=100, alpha=0.24342750012874603, initialization=uniform, GAMA=False
model output: tensor([[-1.50842750, -2.78271246, -3.05500746, -2.76670456, -2.05510044,
          3.06344867,  2.96421409, -5.58440161,  4.34885550, -0.61086601]],
       device='cuda:0')
pgd prediction: tensor([[[-1.31334388, -2.79716325, -3.17139125, -2.98145580, -2.12220645,
           3.11683607,  4.09379196, -5.83988762,  4.26124191, -0.49534240],
         [-1.31334388, -2.79716325, -3.17139125, -2.98145580, -2.12220645,
           3.11683607,  4.09379196, -5.83988762,  4.26124191, -0.49534240]]],
       device='cuda:0')
pgd attack margin tensor([[[ 5.57458591,  7.05840492,  7.43263340,  7.24269772,  6.38344860,
           1.14440584,  0.16744995, 10.10112953,  4.75658417]]],
       device='cuda:0')
number of violation:  0
Attack finished in 2.6753 seconds.
pgd attack failed
Model prediction is: tensor([[-1.50842750, -2.78271246, -3.05500746, -2.76670456, -2.05510044,
          3.06344867,  2.96421409, -5.58440161,  4.34885550, -0.61086601]],
       device='cuda:0')
layer /input.4 using sparse-features alpha with shape [593]; unstable size 593; total size 25088 (torch.Size([1, 32, 28, 28]))
layer /input.4 start_node /input.8 using sparse-spec alpha with unstable size 48 total_size 6272 output_shape (32, 14, 14)
layer /input.4 start_node /input.16 using sparse-spec alpha with unstable size 34 total_size 12544 output_shape (64, 14, 14)
layer /input.4 start_node /input.24 using sparse-spec alpha with unstable size 22 total_size 3136 output_shape (64, 7, 7)
layer /input.4 start_node /input.28 using sparse-spec alpha with unstable size 4 total_size 512 output_shape torch.Size([512])
layer /input.4 start_node /input.32 using sparse-spec alpha with unstable size 11 total_size 512 output_shape torch.Size([512])
layer /input.4 start_node /35 using full alpha with unstable size None total_size 9 output_shape 9
layer /input.12 using sparse-features alpha with shape [48]; unstable size 48; total size 6272 (torch.Size([1, 32, 14, 14]))
layer /input.12 start_node /input.16 using sparse-spec alpha with unstable size 34 total_size 12544 output_shape (64, 14, 14)
layer /input.12 start_node /input.24 using sparse-spec alpha with unstable size 22 total_size 3136 output_shape (64, 7, 7)
layer /input.12 start_node /input.28 using sparse-spec alpha with unstable size 4 total_size 512 output_shape torch.Size([512])
layer /input.12 start_node /input.32 using sparse-spec alpha with unstable size 11 total_size 512 output_shape torch.Size([512])
layer /input.12 start_node /35 using full alpha with unstable size None total_size 9 output_shape 9
layer /input.20 using sparse-features alpha with shape [34]; unstable size 34; total size 12544 (torch.Size([1, 64, 14, 14]))
layer /input.20 start_node /input.24 using sparse-spec alpha with unstable size 22 total_size 3136 output_shape (64, 7, 7)
layer /input.20 start_node /input.28 using sparse-spec alpha with unstable size 4 total_size 512 output_shape torch.Size([512])
layer /input.20 start_node /input.32 using sparse-spec alpha with unstable size 11 total_size 512 output_shape torch.Size([512])
layer /input.20 start_node /35 using full alpha with unstable size None total_size 9 output_shape 9
layer /22 using sparse-features alpha with shape [22]; unstable size 22; total size 3136 (torch.Size([1, 64, 7, 7]))
layer /22 start_node /input.28 using sparse-spec alpha with unstable size 4 total_size 512 output_shape torch.Size([512])
layer /22 start_node /input.32 using sparse-spec alpha with unstable size 11 total_size 512 output_shape torch.Size([512])
layer /22 start_node /35 using full alpha with unstable size None total_size 9 output_shape 9
layer /32 using sparse-features alpha with shape [4]; unstable size 4; total size 512 (torch.Size([1, 512]))
layer /32 start_node /input.32 using sparse-spec alpha with unstable size 11 total_size 512 output_shape torch.Size([512])
layer /32 start_node /35 using full alpha with unstable size None total_size 9 output_shape 9
layer /34 using sparse-features alpha with shape [11]; unstable size 11; total size 512 (torch.Size([1, 512]))
layer /34 start_node /35 using full alpha with unstable size None total_size 9 output_shape 9
Optimizable variables initialized.
initial CROWN bounds: tensor([[ 4.66079330,  5.06178713,  5.61804676,  4.95026398,  3.18083572,
         -0.66849524, -1.44434464,  7.45653296,  2.78505588]], device='cuda:0') None
best_l after optimization: 42.06475067138672 with beta sum per layer: []
alpha/beta optimization time: 13.176512479782104
initial alpha-CROWN bounds: tensor([[ 5.19139242,  6.41232014,  6.47227383,  5.69582415,  5.27674580,
          0.19792476, -0.10909885,  8.75563145,  4.17173386]], device='cuda:0')
Worst class: (+ rhs) -0.10909885168075562
Total VNNLIB file length: 9, max property batch size: 1, total number of batches: 9
lA shape: [torch.Size([1, 9, 32, 28, 28]), torch.Size([1, 9, 32, 14, 14]), torch.Size([1, 9, 64, 14, 14]), torch.Size([1, 9, 64, 7, 7]), torch.Size([1, 9, 512]), torch.Size([1, 9, 512])]

Properties batch 0, size 1
Remaining timeout: 160.12969589233398
##### [0] Spec matrix: [[[-1.  0.  0.  0.  0.  0.  0.  0.  1.  0.]]], thresh: [0] ######
Init opt crown verified for spec index [0] with bound tensor([[5.19139242]], device='cuda:0').

Properties batch 1, size 1
Remaining timeout: 160.03268837928772
##### [0] Spec matrix: [[[ 0. -1.  0.  0.  0.  0.  0.  0.  1.  0.]]], thresh: [0] ######
Init opt crown verified for spec index [0] with bound tensor([[6.41232014]], device='cuda:0').

Properties batch 2, size 1
Remaining timeout: 159.99102139472961
##### [0] Spec matrix: [[[ 0.  0. -1.  0.  0.  0.  0.  0.  1.  0.]]], thresh: [0] ######
Init opt crown verified for spec index [0] with bound tensor([[6.47227383]], device='cuda:0').

Properties batch 3, size 1
Remaining timeout: 159.9500012397766
##### [0] Spec matrix: [[[ 0.  0.  0. -1.  0.  0.  0.  0.  1.  0.]]], thresh: [0] ######
Init opt crown verified for spec index [0] with bound tensor([[5.69582415]], device='cuda:0').

Properties batch 4, size 1
Remaining timeout: 159.9065568447113
##### [0] Spec matrix: [[[ 0.  0.  0.  0. -1.  0.  0.  0.  1.  0.]]], thresh: [0] ######
Init opt crown verified for spec index [0] with bound tensor([[5.27674580]], device='cuda:0').

Properties batch 5, size 1
Remaining timeout: 159.86450695991516
##### [0] Spec matrix: [[[ 0.  0.  0.  0.  0. -1.  0.  0.  1.  0.]]], thresh: [0] ######
Init opt crown verified for spec index [0] with bound tensor([[0.19792476]], device='cuda:0').

Properties batch 6, size 1
Remaining timeout: 159.82415056228638
##### [0] Spec matrix: [[[ 0.  0.  0.  0.  0.  0. -1.  0.  1.  0.]]], thresh: [0] ######
Remaining spec index [0] with bounds tensor([[-0.10909885]], device='cuda:0') need to verify.
Model prediction is: tensor([-1.50842750, -2.78271246, -3.05500746, -2.76670456, -2.05510044,
         3.06344867,  2.96421409, -5.58440161,  4.34885550, -0.61086601],
       device='cuda:0')
build_the_model_with_refined_bounds batch [0/1]
setting alpha for layer /input.4 start_node /35 with alignment adjustment
setting alpha for layer /input.12 start_node /35 with alignment adjustment
setting alpha for layer /input.20 start_node /35 with alignment adjustment
setting alpha for layer /22 start_node /35 with alignment adjustment
setting alpha for layer /32 start_node /35 with alignment adjustment
setting alpha for layer /34 start_node /35 with alignment adjustment
all slope initialized
directly get lb and ub from refined bounds
lA shapes: [torch.Size([1, 1, 32, 28, 28]), torch.Size([1, 1, 32, 14, 14]), torch.Size([1, 1, 64, 14, 14]), torch.Size([1, 1, 64, 7, 7]), torch.Size([1, 1, 512]), torch.Size([1, 1, 512])]
c shape: torch.Size([1, 1, 10])
alpha-CROWN with fixed intermediate bounds: tensor([[-0.10909885]], device='cuda:0') tensor([[inf]], device='cuda:0')
Keeping slopes for these layers: ['/35']
Keeping slopes for these layers: ['/35']
layer 0 size torch.Size([25088]) unstable 593
layer 1 size torch.Size([6272]) unstable 46
layer 2 size torch.Size([12544]) unstable 31
layer 3 size torch.Size([3136]) unstable 21
layer 4 size torch.Size([512]) unstable 3
layer 5 size torch.Size([512]) unstable 8
-----------------
# of unstable neurons: 702
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 28, 28]) pre split depth:  4
batch:  torch.Size([1, 32, 28, 28]) post split depth:  4
splitting decisions: 
split level 0: [2, 4571] 
split level 1: [2, 4586] 
split level 2: [3, 1530] 
split level 3: [3, 2444] 
regular batch size: 2*8, diving batch size 1*0
(16, 1, 28, 28) torch.Size([16, 1, 10]) torch.Size([16, 1])
pruning_in_iteration open status: True
ratio of positive domain = 15 / 16 = 0.9375
pruning-in-iteration extra time: 0.014337778091430664
Tensors transferred: pre=1.4668M lA=0.0458M alpha=0.0217M beta=0.0001M
This batch time : update_bounds func: 0.7886	 prepare: 0.0046	 bound: 0.7797	 transfer: 0.0033	 finalize: 0.0008
Accumulated time: update_bounds func: 0.7886	 prepare: 0.0046	 bound: 0.7797	 transfer: 0.0033	 finalize: 0.0008
batch bounding time:  0.7886464595794678
Current worst splitting domains lb-rhs (depth):
-0.06020 (4), 
length of domains: 1
Total time: 1.2346	 pickout: 0.0016	 decision: 0.4377	 get_bound: 0.7917	 add_domain: 0.0036
Accumulated time:	 pickout: 0.0016	 decision: 0.4377	 get_bound: 0.7917	 add_domain: 0.0036
Current (lb-rhs): -0.0601961612701416
15 domains visited
Cumulative time: 1.5928764343261719

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 28, 28]) pre split depth:  4
batch:  torch.Size([1, 32, 28, 28]) post split depth:  4
splitting decisions: 
split level 0: [3, 2097] 
split level 1: [2, 4622] 
split level 2: [3, 2069] 
split level 3: [2, 4545] 
regular batch size: 2*8, diving batch size 1*0
(16, 1, 28, 28) torch.Size([16, 1, 10]) torch.Size([16, 1])
pruning_in_iteration open status: True
ratio of positive domain = 15 / 16 = 0.9375
pruning-in-iteration extra time: 0.014290094375610352
Tensors transferred: pre=1.4668M lA=0.0458M alpha=0.0217M beta=0.0001M
This batch time : update_bounds func: 0.3799	 prepare: 0.0045	 bound: 0.3713	 transfer: 0.0032	 finalize: 0.0008
Accumulated time: update_bounds func: 1.1685	 prepare: 0.0091	 bound: 1.1511	 transfer: 0.0065	 finalize: 0.0015
batch bounding time:  0.37995028495788574
Current worst splitting domains lb-rhs (depth):
-0.00014 (8), 
length of domains: 1
Total time: 0.4281	 pickout: 0.0015	 decision: 0.0403	 get_bound: 0.3831	 add_domain: 0.0033
Accumulated time:	 pickout: 0.0031	 decision: 0.4780	 get_bound: 1.1748	 add_domain: 0.0069
Current (lb-rhs): -0.0001442432403564453
30 domains visited
Cumulative time: 2.021308422088623

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 28, 28]) pre split depth:  4
batch:  torch.Size([1, 32, 28, 28]) post split depth:  4
splitting decisions: 
split level 0: [2, 4558]/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:678: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(eps_temp / std).reshape(1, -1, 1, 1)
/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/abcrown.py:95: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_new.cpp:210.)
  arguments.Config["bab"]["decision_thresh"] = torch.tensor([item[1] for item in vnnlib[1]]).to(data)
/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/batch_branch_and_bound.py:420: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return torch.tensor(arguments.Config["bab"]["decision_thresh"] + 1e-7), np.inf
 
split level 1: [2, 4557] 
split level 2: [2, 4670] 
split level 3: [3, 2066] 
regular batch size: 2*8, diving batch size 1*0
(16, 1, 28, 28) torch.Size([16, 1, 10]) torch.Size([16, 1])

all verified at 3th iter
pruning_in_iteration open status: True
ratio of positive domain = 16 / 16 = 1.0
pruning-in-iteration extra time: 0.0021047592163085938
Tensors transferred: pre=1.4668M lA=0.0458M alpha=0.0217M beta=0.0002M
This batch time : update_bounds func: 0.0787	 prepare: 0.0045	 bound: 0.0689	 transfer: 0.0045	 finalize: 0.0008
Accumulated time: update_bounds func: 1.2472	 prepare: 0.0136	 bound: 1.2200	 transfer: 0.0110	 finalize: 0.0023
batch bounding time:  0.07879853248596191
length of domains: 0
Total time: 0.1258	 pickout: 0.0014	 decision: 0.0406	 get_bound: 0.0820	 add_domain: 0.0018
Accumulated time:	 pickout: 0.0045	 decision: 0.5186	 get_bound: 1.2567	 add_domain: 0.0087
No domains left, verification finished!
46 domains visited
Cumulative time: 2.1478421688079834


Properties batch 7, size 1
Remaining timeout: 157.51838898658752
##### [0] Spec matrix: [[[ 0.  0.  0.  0.  0.  0.  0. -1.  1.  0.]]], thresh: [0] ######
Init opt crown verified for spec index [0] with bound tensor([[8.75563145]], device='cuda:0').

Properties batch 8, size 1
Remaining timeout: 157.46704697608948
##### [0] Spec matrix: [[[ 0.  0.  0.  0.  0.  0.  0.  0.  1. -1.]]], thresh: [0] ######
Init opt crown verified for spec index [0] with bound tensor([[4.17173386]], device='cuda:0').
Result: safe in 22.5746 seconds
############# Summary #############
Final verified acc: 100.0% [total 1 examples]
Total verification count: 1 , total verified safe: 1 , verified unsafe: 0 , timeout: 0
mean time (bab) [total:1]: 2.7031805515289307
mean time [1] 22.574554204940796 max time 22.574554204940796
safe (total 1): [0]
