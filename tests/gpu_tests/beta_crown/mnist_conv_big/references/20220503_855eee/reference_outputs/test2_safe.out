Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: mnist_conv_big_diffai.pth
  name: mnist_conv_big
data:
  start: 232
  end: 233
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: MNIST_ERAN
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.3
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 256
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 180
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 100
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Tue May  3 01:09:56 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (5): ReLU()
  (6): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (7): ReLU()
  (8): Flatten()
  (9): Linear(in_features=3136, out_features=512, bias=True)
  (10): ReLU()
  (11): Linear(in_features=512, out_features=512, bias=True)
  (12): ReLU()
  (13): Linear(in_features=512, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([1000, 1, 28, 28]) torch.Size([1000]) torch.Size([1000])
X range: tensor(2.8215) tensor(-0.4242) tensor(-0.0274)
Note runnerup label is empty here!
############################
epsilon after preprocessing: tensor([[[[0.9737]]]]), data_max = tensor([[[[2.8215]]]]), data_min = tensor([[[[-0.4242]]]])
Task length: 1
saving results to Verified_ret_[mnist_conv_big]_start=232_end=233_iter=20_b=256_timeout=180_branching=kfsb-max-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 232 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 8, correct label 8, image norm 580.3990478515625, logits tensor([-1.5076, -2.7838, -3.0578, -2.7687, -2.0720,  3.0698,  2.9731, -5.5850,
         4.3475, -0.6103], device='cuda:0', grad_fn=<SelectBackward>)
##### PGD attack: True label: 8, Tested against: ['all'] ######
pgd prediction: tensor([-1.3133, -2.7972, -3.1714, -2.9815, -2.1221,  3.1169,  4.0938, -5.8399,
         4.2613, -0.4954], device='cuda:0', grad_fn=<SqueezeBackward1>)
attack margin tensor([ 5.5746,  7.0584,  7.4327,  7.2427,  6.3834,  1.1443,  0.1675, 10.1011,
            inf,  4.7566], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[-1.5076, -2.7838, -3.0578, -2.7687, -2.0720,  3.0698,  2.9731, -5.5850,
          4.3475, -0.6103]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 4.6608,  5.0618,  5.6180,  4.9503,  3.1808, -0.6685, -1.4443,  7.4565,
          2.7851]], device='cuda:0') None
best_l after optimization: -42.06255340576172 with beta sum per layer: []
alpha/beta optimization time: 18.92378854751587
initial alpha-CROWN bounds: tensor([[ 5.1912,  6.4121,  6.4722,  5.6954,  5.2766,  0.1978, -0.1093,  8.7555,
          4.1710]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.1093, device='cuda:0', grad_fn=<MinBackward1>)
Sorted order for labels to verify: [6, 5, 9, 0, 4, 1, 3, 2, 7, 8]
##### [0:232] Tested against 6 ######
Model prediction is: tensor([[-1.5076, -2.7838, -3.0578, -2.7687, -2.0720,  3.0698,  2.9731, -5.5850,
          4.3475, -0.6103]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /16 start_node /17
setting alpha for layer /16 start_node /19
setting alpha for layer /16 start_node /21
setting alpha for layer /16 start_node /31
setting alpha for layer /16 start_node /33
not setting layer /16 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 32, 28, 28]) != torch.Size([2, 9, 1, 32, 28, 28]))
setting alpha for layer /18 start_node /19
setting alpha for layer /18 start_node /21
setting alpha for layer /18 start_node /31
setting alpha for layer /18 start_node /33
not setting layer /18 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 32, 14, 14]) != torch.Size([2, 9, 1, 32, 14, 14]))
setting alpha for layer /20 start_node /21
setting alpha for layer /20 start_node /31
setting alpha for layer /20 start_node /33
not setting layer /20 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 64, 14, 14]) != torch.Size([2, 9, 1, 64, 14, 14]))
setting alpha for layer /22 start_node /31
setting alpha for layer /22 start_node /33
not setting layer /22 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 64, 7, 7]) != torch.Size([2, 9, 1, 64, 7, 7]))
setting alpha for layer /32 start_node /33
not setting layer /32 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 512]) != torch.Size([2, 9, 1, 512]))
not setting layer /34 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 512]) != torch.Size([2, 9, 1, 512]))
0 /15 torch.Size([1, 32, 28, 28])
1 /17 torch.Size([1, 32, 14, 14])
2 /19 torch.Size([1, 64, 14, 14])
3 /21 torch.Size([1, 64, 7, 7])
4 /31 torch.Size([1, 512])
5 /33 torch.Size([1, 512])
best_l after optimization: 0.10883623361587524 with beta sum per layer: []
alpha/beta optimization time: 3.1240391731262207
alpha-CROWN with fixed intermediate bounds: tensor([[-0.1088]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.10883623361587524
layer 0 size torch.Size([25088]) unstable 593
layer 1 size torch.Size([6272]) unstable 48
layer 2 size torch.Size([12544]) unstable 31
layer 3 size torch.Size([3136]) unstable 21
layer 4 size torch.Size([512]) unstable 3
layer 5 size torch.Size([512]) unstable 8
-----------------
# of unstable neurons: 704
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 28, 28]) pre split depth:  4
batch:  torch.Size([1, 32, 28, 28]) post split depth:  4
splitting decisions: 
split level 0: [2, 4571] 
split level 1: [2, 4586] 
split level 2: [3, 1530] 
split level 3: [3, 2444] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -8.5574369430542 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.4469923973083496
This batch time : update_bounds func: 0.4569	 prepare: 0.0039	 bound: 0.4474	 transfer: 0.0035	 finalize: 0.0021/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:556: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(eps_temp / std).reshape(1, -1, 1, 1)

Accumulated time: update_bounds func: 0.4569	 prepare: 0.0039	 bound: 0.4474	 transfer: 0.0035	 finalize: 0.0021
batch bounding time:  0.45719122886657715
Current worst splitting domains [lb, ub] (depth):
[-0.05989,   inf] (5), 
length of domains: 1
Total time: 0.5053	 pickout: 0.0019	 decision: 0.0429	 get_bound: 0.4603	 add_domain: 0.0001
Current lb:-0.05988648906350136
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.48974347114563

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 28, 28]) pre split depth:  4
batch:  torch.Size([1, 32, 28, 28]) post split depth:  4
splitting decisions: 
split level 0: [3, 2097] 
split level 1: [2, 4622] 
split level 2: [3, 2069] 
split level 3: [2, 4545] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -1.8805091381072998 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.4437367916107178
This batch time : update_bounds func: 0.4544	 prepare: 0.0044	 bound: 0.4441	 transfer: 0.0037	 finalize: 0.0021
Accumulated time: update_bounds func: 0.9114	 prepare: 0.0083	 bound: 0.8915	 transfer: 0.0037	 finalize: 0.0042
batch bounding time:  0.45459747314453125
Current worst splitting domains [lb, ub] (depth):
[-0.00826,   inf] (10), 
length of domains: 1
Total time: 0.4994	 pickout: 0.0019	 decision: 0.0396	 get_bound: 0.4577	 add_domain: 0.0001
Current lb:-0.008255962282419205
32 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.9893834590911865

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 28, 28]) pre split depth:  4
batch:  torch.Size([1, 32, 28, 28]) post split depth:  4
splitting decisions: 
split level 0: [2, 4558] 
split level 1: [2, 4557] 
split level 2: [2, 4670] 
split level 3: [3, 2066] 
regular batch size: 2*8, diving batch size 1*0

all verified at 12th iter
best_l after optimization: -1.5556352138519287 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.281402587890625
This batch time : update_bounds func: 0.2943	 prepare: 0.0044	 bound: 0.2818	 transfer: 0.0060	 finalize: 0.0021
Accumulated time: update_bounds func: 1.2057	 prepare: 0.0127	 bound: 1.1733	 transfer: 0.0060	 finalize: 0.0063
batch bounding time:  0.2945218086242676
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.3396	 pickout: 0.0019	 decision: 0.0399	 get_bound: 0.2977	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 5.329253673553467

Image 232 label 6 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 5.440851926803589
232 1.0000000116860974e-07
##### [0:232] Tested against 5 ######
Initial alpha-CROWN verified for label 5 with bound 0.19780045747756958
Image 232 label 5 verification end, final lower bound 0.19780045747756958, upper bound inf, time: 0.0004830360412597656
232 0.19780045747756958
##### [0:232] Tested against 9 ######
Initial alpha-CROWN verified for label 9 with bound 4.171014785766602
Image 232 label 9 verification end, final lower bound 4.171014785766602, upper bound inf, time: 0.0005059242248535156
232 4.171014785766602
##### [0:232] Tested against 0 ######
Initial alpha-CROWN verified for label 0 with bound 5.1912431716918945
Image 232 label 0 verification end, final lower bound 5.1912431716918945, upper bound inf, time: 0.00046563148498535156
232 5.1912431716918945
##### [0:232] Tested against 4 ######
Initial alpha-CROWN verified for label 4 with bound 5.276628494262695
Image 232 label 4 verification end, final lower bound 5.276628494262695, upper bound inf, time: 0.00047206878662109375
232 5.276628494262695
##### [0:232] Tested against 1 ######
Initial alpha-CROWN verified for label 1 with bound 6.412112236022949
Image 232 label 1 verification end, final lower bound 6.412112236022949, upper bound inf, time: 0.00047206878662109375
232 6.412112236022949
##### [0:232] Tested against 3 ######
Initial alpha-CROWN verified for label 3 with bound 5.69541597366333
Image 232 label 3 verification end, final lower bound 5.69541597366333, upper bound inf, time: 0.0004723072052001953
232 5.69541597366333
##### [0:232] Tested against 2 ######
Initial alpha-CROWN verified for label 2 with bound 6.472194194793701
Image 232 label 2 verification end, final lower bound 6.472194194793701, upper bound inf, time: 0.00046372413635253906
232 6.472194194793701
##### [0:232] Tested against 7 ######
Initial alpha-CROWN verified for label 7 with bound 8.755485534667969
Image 232 label 7 verification end, final lower bound 8.755485534667969, upper bound inf, time: 0.0004699230194091797
232 8.755485534667969
##### [0:232] Tested against 8 ######
groundtruth label, skip!
Result: image 232 verification success (with branch and bound)!
Wall time: 29.712646961212158

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 1): [232]
verification failure idx (total 0): []
final verified acc: 100.0%[1]
verifier is called on 1 examples.
total verified: 1
mean time [cnt:1] (excluding attack success): 26.27694535255432
