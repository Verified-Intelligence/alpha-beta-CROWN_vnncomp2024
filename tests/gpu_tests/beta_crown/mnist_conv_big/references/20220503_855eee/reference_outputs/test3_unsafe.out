Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: mnist_conv_big_diffai.pth
  name: mnist_conv_big
data:
  start: 355
  end: 356
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: MNIST_ERAN
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.3
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 256
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 180
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 100
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Tue May  3 01:10:31 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (5): ReLU()
  (6): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (7): ReLU()
  (8): Flatten()
  (9): Linear(in_features=3136, out_features=512, bias=True)
  (10): ReLU()
  (11): Linear(in_features=512, out_features=512, bias=True)
  (12): ReLU()
  (13): Linear(in_features=512, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([1000, 1, 28, 28]) torch.Size([1000]) torch.Size([1000])
X range: tensor(2.8215) tensor(-0.4242) tensor(-0.0274)
Note runnerup label is empty here!
############################
epsilon after preprocessing: tensor([[[[0.9737]]]]), data_max = tensor([[[[2.8215]]]]), data_min = tensor([[[[-0.4242]]]])
Task length: 1
saving results to Verified_ret_[mnist_conv_big]_start=355_end=356_iter=20_b=256_timeout=180_branching=kfsb-max-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 355 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 8, correct label 8, image norm 545.6498413085938, logits tensor([-1.5944, -1.8428, -2.6798, -1.7802, -0.3354,  0.6565,  1.0539, -4.1042,
         3.8608, -0.0721], device='cuda:0', grad_fn=<SelectBackward>)
Model prediction is: tensor([[-1.5944, -1.8428, -2.6798, -1.7802, -0.3354,  0.6565,  1.0539, -4.1042,
          3.8608, -0.0721]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-3.0267, -0.0734,  0.1874,  0.3006, -7.2964, -6.4318, -4.1488, -2.4043,
         -4.7210]], device='cuda:0') None
best_l after optimization: -9.372152328491211 with beta sum per layer: []
alpha/beta optimization time: 18.89911937713623
initial alpha-CROWN bounds: tensor([[ 1.6079,  2.1491,  2.8336,  2.9259, -1.2160, -1.1233, -0.2454,  2.2780,
          0.1622]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-1.2160, device='cuda:0', grad_fn=<MinBackward1>)
##### [0:355] Tested against 4 ######
Model prediction is: tensor([[-1.5944, -1.8428, -2.6798, -1.7802, -0.3354,  0.6565,  1.0539, -4.1042,
          3.8608, -0.0721]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /16 start_node /17
setting alpha for layer /16 start_node /19
setting alpha for layer /16 start_node /21
setting alpha for layer /16 start_node /31
setting alpha for layer /16 start_node /33
not setting layer /16 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 32, 28, 28]) != torch.Size([2, 9, 1, 32, 28, 28]))
setting alpha for layer /18 start_node /19
setting alpha for layer /18 start_node /21
setting alpha for layer /18 start_node /31
setting alpha for layer /18 start_node /33
not setting layer /18 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 32, 14, 14]) != torch.Size([2, 9, 1, 32, 14, 14]))
setting alpha for layer /20 start_node /21
setting alpha for layer /20 start_node /31
setting alpha for layer /20 start_node /33
not setting layer /20 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 64, 14, 14]) != torch.Size([2, 9, 1, 64, 14, 14]))
setting alpha for layer /22 start_node /31
setting alpha for layer /22 start_node /33
not setting layer /22 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 64, 7, 7]) != torch.Size([2, 9, 1, 64, 7, 7]))
setting alpha for layer /32 start_node /33
not setting layer /32 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 512]) != torch.Size([2, 9, 1, 512]))
not setting layer /34 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 512]) != torch.Size([2, 9, 1, 512]))
0 /15 torch.Size([1, 32, 28, 28])
1 /17 torch.Size([1, 32, 14, 14])
2 /19 torch.Size([1, 64, 14, 14])
3 /21 torch.Size([1, 64, 7, 7])
4 /31 torch.Size([1, 512])
5 /33 torch.Size([1, 512])
best_l after optimization: 1.2111425399780273 with beta sum per layer: []
alpha/beta optimization time: 2.833101987838745
alpha-CROWN with fixed intermediate bounds: tensor([[-1.2111]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-1.2111425399780273
layer 0 size torch.Size([25088]) unstable 625
layer 1 size torch.Size([6272]) unstable 65
layer 2 size torch.Size([12544]) unstable 37
layer 3 size torch.Size([3136]) unstable 33
layer 4 size torch.Size([512]) unstable 10
layer 5 size torch.Size([512]) unstable 17
-----------------
# of unstable neurons: 787
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 28, 28]) pre split depth:  4
batch:  torch.Size([1, 32, 28, 28]) post split depth:  4
splitting decisions: 
split level 0: [4, 247] 
split level 1: [2, 4655] 
split level 2: [5, 102] 
split level 3: [3, 2412] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -9.719566345214844 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.5209652185440063]
alpha/beta optimization time: 0.5137388706207275
This batch time : update_bounds func: 0.5243	 prepare: 0.0041	 bound: 0.5142	 transfer: 0.0035	 finalize: 0.0023
Accumulated time: update_bounds func: 0.5243	 prepare: 0.0041	 bound: 0.5142	 transfer: 0.0035	 finalize: 0.0023
batch bounding time:  0.5245585441589355
Current worst splitting domains [lb, ub] (depth):
[-0.45248,   inf] (5), [-0.08852,   inf] (5), 
length of domains: 2
Total time: 0.5711	 pickout: 0.0019	 decision: 0.0413	 get_bound: 0.5276	 add_domain: 0.0003
Current lb:-0.4524836540222168
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.2756664752960205

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2, 32, 28, 28]) pre split depth:  3
batch:  torch.Size([2, 32, 28, 28]) post split depth:  3
splitting decisions: 
split level 0: [5, 404] [5, 404] 
split level 1: [4, 419] [4, 419] 
split level 2: [2, 4589] [2, 4589] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -7.568317413330078 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 4.1794328689575195]
alpha/beta optimization time: 0.43298888206481934
This batch time : update_bounds func: 0.4446	 prepare: 0.0048	 bound: 0.4334	 transfer: 0.0042	 finalize: 0.0021
Accumulated time: update_bounds func: 0.9688	 prepare: 0.0089	 bound: 0.9476	 transfer: 0.0042	 finalize: 0.0044
batch bounding time:  0.44475698471069336
Current worst splitting domains [lb, ub] (depth):
[-0.37428,   inf] (9), [-0.15536,   inf] (9), [-0.14650,   inf] (9), 
length of domains: 3
Total time: 0.4837	 pickout: 0.0026	 decision: 0.0333	 get_bound: 0.4475	 add_domain: 0.0003
Current lb:-0.37427952885627747
32 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.759671688079834

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3, 32, 28, 28]) pre split depth:  3
batch:  torch.Size([3, 32, 28, 28]) post split depth:  3
splitting decisions: 
split level 0: [3, 1554] [3, 1554] [3, 1554] 
split level 1: [2, 4650] [2, 4650] [2, 4650] 
split level 2: [2, 4515] [2, 4515] [2, 4515] 
regular batch size: 2*12, diving batch size 1*0
best_l after optimization: -14.445305824279785 with beta sum per layer: [0.0, 0.0, 1.1034955978393555, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.46019577980041504
This batch time : update_bounds func: 0.4779	 prepare: 0.0062	 bound: 0.4606	 transfer: 0.0081	 finalize: 0.0029
Accumulated time: update_bounds func: 1.4468	 prepare: 0.0151	 bound: 1.4083	 transfer: 0.0081	 finalize: 0.0073
batch bounding time:  0.4781196117401123
Current worst splitting domains [lb, ub] (depth):
[-0.34207,   inf] (13), [-0.14258,   inf] (13), [-0.11480,   inf] (13), [-0.02882,   inf] (13), 
length of domains: 4
Total time: 0.5178	 pickout: 0.0031	 decision: 0.0323	 get_bound: 0.4820	 add_domain: 0.0004
Current lb:-0.3420668840408325
56 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.277786731719971

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 32, 28, 28]) pre split depth:  2
batch:  torch.Size([4, 32, 28, 28]) post split depth:  2
splitting decisions: 
split level 0: [4, 436] [4, 436] [4, 436] [4, 436] 
split level 1: [3, 1523] [3, 1523] [3, 1523] [3, 1523] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.3136821985244751 with beta sum per layer: [0.0, 0.0, 1.6265971660614014, 0.20137514173984528, 0.908679723739624, 0.0]
alpha/beta optimization time: 0.4348173141479492
This batch time : update_bounds func: 0.4459	 prepare: 0.0050	 bound: 0.4353	 transfer: 0.0035	 finalize: 0.0021
Accumulated time: update_bounds func: 1.8926	 prepare: 0.0200	 bound: 1.8435	 transfer: 0.0035	 finalize: 0.0094
batch bounding time:  0.44605302810668945
Current worst splitting domains [lb, ub] (depth):
[-0.20002,   inf] (16), [-0.16692,   inf] (16), [-0.01056,   inf] (16), [-0.01045,   inf] (16), 
length of domains: 4
Total time: 0.4881	 pickout: 0.0036	 decision: 0.0360	 get_bound: 0.4482	 add_domain: 0.0004
Current lb:-0.20001620054244995
72 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.766248464584351

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 32, 28, 28]) pre split depth:  2
batch:  torch.Size([4, 32, 28, 28]) post split depth:  2
splitting decisions: 
split level 0: [5, 68] [5, 68] [5, 68] [5, 68] 
split level 1: [3, 2405] [3, 2405] [3, 2405] [3, 2405] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.7763642072677612 with beta sum per layer: [0.0, 0.0, 0.3411340117454529, 0.9339107871055603, 1.8220685720443726, 0.19694800674915314]
alpha/beta optimization time: 0.4453542232513428
This batch time : update_bounds func: 0.4563	 prepare: 0.0048	 bound: 0.4458	 transfer: 0.0035	 finalize: 0.0021
Accumulated time: update_bounds func: 2.3489	 prepare: 0.0249	 bound: 2.2893	 transfer: 0.0035	 finalize: 0.0115
batch bounding time:  0.4564945697784424
Current worst splitting domains [lb, ub] (depth):
[-0.15671,   inf] (19), [-0.09471,   inf] (19), [-0.06899,   inf] (19), [-0.02127,   inf] (19), 
length of domains: 4
Total time: 0.4954	 pickout: 0.0036	 decision: 0.0327	 get_bound: 0.4586	 add_domain: 0.0004
Current lb:-0.15670910477638245
88 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.261978626251221

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 32, 28, 28]) pre split depth:  2
batch:  torch.Size([4, 32, 28, 28]) post split depth:  2
splitting decisions: 
split level 0: [0, 7973] [5, 320] [0, 7973] [5, 320] 
split level 1: [0, 12677] [3, 1531] [3, 1531] [3, 1531] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -1.004424810409546 with beta sum per layer: [0.5882651805877686, 0.0, 0.0, 2.8243460655212402, 0.0, 0.0]
alpha/beta optimization time: 0.43528246879577637
This batch time : update_bounds func: 0.4464	 prepare: 0.0051	 bound: 0.4357	 transfer: 0.0035	 finalize: 0.0020
Accumulated time: update_bounds func: 2.7953	 prepare: 0.0299	 bound: 2.7250	 transfer: 0.0035	 finalize: 0.0135
batch bounding time:  0.44650697708129883
Current worst splitting domains [lb, ub] (depth):
[-0.13811,   inf] (22), [-0.00678,   inf] (22), 
length of domains: 2
Total time: 0.4854	 pickout: 0.0035	 decision: 0.0328	 get_bound: 0.4488	 add_domain: 0.0002
Current lb:-0.13810797035694122
104 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.7476372718811035

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2, 32, 28, 28]) pre split depth:  3
batch:  torch.Size([2, 32, 28, 28]) post split depth:  3
splitting decisions: 
split level 0: [5, 320] [0, 12670] 
split level 1: [3, 1531] [0, 7966] 
split level 2: [2, 4526] [2, 4526] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.6446779370307922 with beta sum per layer: [0.0, 0.0, 0.0, 2.6207776069641113, 0.0, 0.0]
alpha/beta optimization time: 0.4427192211151123
This batch time : update_bounds func: 0.4533	 prepare: 0.0050	 bound: 0.4432	 transfer: 0.0026	 finalize: 0.0024
Accumulated time: update_bounds func: 3.2486	 prepare: 0.0349	 bound: 3.1682	 transfer: 0.0026	 finalize: 0.0159
batch bounding time:  0.4534785747528076
Current worst splitting domains [lb, ub] (depth):
[-0.07250,   inf] (26), [-0.04745,   inf] (26), [-0.01343,   inf] (26), 
length of domains: 3
Total time: 0.4908	 pickout: 0.0024	 decision: 0.0316	 get_bound: 0.4564	 add_domain: 0.0004
Current lb:-0.07250034809112549
120 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.238762617111206

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3, 32, 28, 28]) pre split depth:  3
batch:  torch.Size([3, 32, 28, 28]) post split depth:  3
splitting decisions: 
split level 0: [3, 2061] [3, 2061] [3, 2061] 
split level 1: [2, 4636] [2, 4636] [0, 8193] 
split level 2: [3, 1563] [3, 1563] [2, 4636] 
regular batch size: 2*12, diving batch size 1*0
best_l after optimization: -0.3231242895126343 with beta sum per layer: [0.0, 0.0, 0.0, 0.46978887915611267, 0.0, 0.0]
alpha/beta optimization time: 0.4402625560760498
This batch time : update_bounds func: 0.4549	 prepare: 0.0065	 bound: 0.4407	 transfer: 0.0047	 finalize: 0.0029
Accumulated time: update_bounds func: 3.7035	 prepare: 0.0415	 bound: 3.6089	 transfer: 0.0047	 finalize: 0.0189
batch bounding time:  0.4551045894622803
Current worst splitting domains [lb, ub] (depth):
[-0.06837,   inf] (30), [-0.06658,   inf] (30), [-0.04943,   inf] (30), [-0.04762,   inf] (30), [-0.03270,   inf] (30), [-0.03099,   inf] (30), [-0.01378,   inf] (30), [-0.01207,   inf] (30), 
length of domains: 8
Total time: 0.4945	 pickout: 0.0027	 decision: 0.0317	 get_bound: 0.4592	 add_domain: 0.0009
Current lb:-0.06836666166782379
144 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.733702659606934

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([8, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 8193] [0, 8193] [0, 8193] [0, 8193] [0, 8193] [0, 8193] [0, 8193] [0, 8193] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.43598443269729614 with beta sum per layer: [0.1079796776175499, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.401259183883667
This batch time : update_bounds func: 0.4125	 prepare: 0.0051	 bound: 0.4017	 transfer: 0.0035	 finalize: 0.0021
Accumulated time: update_bounds func: 4.1159	 prepare: 0.0466	 bound: 4.0106	 transfer: 0.0035	 finalize: 0.0210
batch bounding time:  0.41261911392211914
Current worst splitting domains [lb, ub] (depth):
[-0.06462,   inf] (32), [-0.06152,   inf] (32), [-0.04583,   inf] (32), [-0.04426,   inf] (32), [-0.04268,   inf] (32), [-0.04100,   inf] (32), [-0.03179,   inf] (32), [-0.02862,   inf] (32), [-0.02531,   inf] (32), [-0.02211,   inf] (32), [-0.01286,   inf] (32), [-0.01087,   inf] (32), [-0.00964,   inf] (32), [-0.00764,   inf] (32), 
length of domains: 14
Total time: 0.4558	 pickout: 0.0057	 decision: 0.0359	 get_bound: 0.4127	 add_domain: 0.0015
Current lb:-0.06461954116821289
160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.18979001045227

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([14, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([14, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 12897] [0, 12897] [0, 12897] [0, 12897] [0, 12897] [0, 12897] [0, 12897] [0, 12897] [0, 12897] [0, 12897] 
regular batch size: 2*14, diving batch size 1*0
best_l after optimization: 0.4678516685962677 with beta sum per layer: [1.306544303894043, 0.0, 0.0004182430275250226, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.4401204586029053
This batch time : update_bounds func: 0.4587	 prepare: 0.0072	 bound: 0.4405	 transfer: 0.0074	 finalize: 0.0035
Accumulated time: update_bounds func: 4.5746	 prepare: 0.0537	 bound: 4.4511	 transfer: 0.0074	 finalize: 0.0245
batch bounding time:  0.4588584899902344
Current worst splitting domains [lb, ub] (depth):
[-0.06357,   inf] (34), [-0.05908,   inf] (34), [-0.04469,   inf] (34), [-0.04022,   inf] (34), [-0.03665,   inf] (34), [-0.03251,   inf] (34), [-0.03046,   inf] (34), [-0.02756,   inf] (34), [-0.02596,   inf] (34), [-0.02575,   inf] (34), [-0.02306,   inf] (34), [-0.02112,   inf] (34), [-0.01806,   inf] (34), [-0.01390,   inf] (34), [-0.01164,   inf] (34), [-0.00861,   inf] (34), [-0.00719,   inf] (34), [-0.00682,   inf] (34), [-0.00407,   inf] (34), [-0.00223,   inf] (34), 
length of domains: 20
Total time: 0.5102	 pickout: 0.0100	 decision: 0.0391	 get_bound: 0.4589	 add_domain: 0.0022
Current lb:-0.06356668472290039
188 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.700501203536987

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([20, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([20, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 12670] [0, 12670] [0, 12670] [0, 12670] [0, 12670] [0, 12670] [0, 12670] [0, 12670] [0, 12670] [0, 12670] 
regular batch size: 2*20, diving batch size 1*0
best_l after optimization: 0.6039012670516968 with beta sum per layer: [2.1716742515563965, 0.0, 0.004665226209908724, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.4528019428253174
This batch time : update_bounds func: 0.4837	 prepare: 0.0093	 bound: 0.4533	 transfer: 0.0138	 finalize: 0.0072
Accumulated time: update_bounds func: 5.0583	 prepare: 0.0630	 bound: 4.9044	 transfer: 0.0138	 finalize: 0.0316
batch bounding time:  0.48394060134887695
Current worst splitting domains [lb, ub] (depth):
[-0.06194,   inf] (36), [-0.05676,   inf] (36), [-0.04643,   inf] (36), [-0.04331,   inf] (36), [-0.04126,   inf] (36), [-0.03813,   inf] (36), [-0.02973,   inf] (36), [-0.02780,   inf] (36), [-0.02673,   inf] (36), [-0.02591,   inf] (36), [-0.02521,   inf] (36), [-0.02460,   inf] (36), [-0.02257,   inf] (36), [-0.02150,   inf] (36), [-0.02072,   inf] (36), [-0.02005,   inf] (36), [-0.01423,   inf] (36), [-0.01186,   inf] (36), [-0.01104,   inf] (36), [-0.01100,   inf] (36), 
length of domains: 32
Total time: 0.5449	 pickout: 0.0121	 decision: 0.0441	 get_bound: 0.4841	 add_domain: 0.0046
Current lb:-0.06194138526916504
228 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.246541976928711

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([32, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([32, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 7966] [0, 7966] [0, 7966] [0, 7966] [0, 7966] [0, 7966] [0, 7966] [0, 7966] [0, 7966] [0, 7966] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: 0.6856609582901001 with beta sum per layer: [5.8376874923706055, 0.0, 0.0023245031479746103, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.5682718753814697
This batch time : update_bounds func: 0.6173	 prepare: 0.0204	 bound: 0.5688	 transfer: 0.0206	 finalize: 0.0073
Accumulated time: update_bounds func: 5.6756	 prepare: 0.0834	 bound: 5.4732	 transfer: 0.0206	 finalize: 0.0390
batch bounding time:  0.6175601482391357
Current worst splitting domains [lb, ub] (depth):
[-0.06193,   inf] (38), [-0.05675,   inf] (38), [-0.04330,   inf] (38), [-0.03974,   inf] (38), [-0.03917,   inf] (38), [-0.03812,   inf] (38), [-0.03521,   inf] (38), [-0.03474,   inf] (38), [-0.03373,   inf] (38), [-0.03012,   inf] (38), [-0.02972,   inf] (38), [-0.02673,   inf] (38), [-0.02591,   inf] (38), [-0.02521,   inf] (38), [-0.02458,   inf] (38), [-0.02150,   inf] (38), [-0.02118,   inf] (38), [-0.02072,   inf] (38), [-0.02015,   inf] (38), [-0.02005,   inf] (38), 
length of domains: 44
Total time: 0.7070	 pickout: 0.0220	 decision: 0.0621	 get_bound: 0.6177	 add_domain: 0.0052
Current lb:-0.061931610107421875
292 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.954738855361938

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([44, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([44, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 12706] [0, 12706] [0, 12706] [0, 12706] [0, 12706] [0, 12706] [0, 12706] [0, 12706] [0, 12706] [0, 12706] 
regular batch size: 2*44, diving batch size 1*0
best_l after optimization: 0.9405257701873779 with beta sum per layer: [8.527502059936523, 0.0, 0.005851994268596172, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.5606410503387451
This batch time : update_bounds func: 0.6197	 prepare: 0.0174	 bound: 0.5611	 transfer: 0.0302	 finalize: 0.0108
Accumulated time: update_bounds func: 6.2953	 prepare: 0.1008	 bound: 6.0343	 transfer: 0.0302	 finalize: 0.0497
batch bounding time:  0.619938850402832
Current worst splitting domains [lb, ub] (depth):
[-0.06191,   inf] (40), [-0.05672,   inf] (40), [-0.04862,   inf] (40), [-0.04343,   inf] (40), [-0.04328,   inf] (40), [-0.03972,   inf] (40), [-0.03885,   inf] (40), [-0.03809,   inf] (40), [-0.03472,   inf] (40), [-0.03404,   inf] (40), [-0.03365,   inf] (40), [-0.02999,   inf] (40), [-0.02970,   inf] (40), [-0.02887,   inf] (40), [-0.02673,   inf] (40), [-0.02601,   inf] (40), [-0.02589,   inf] (40), [-0.02533,   inf] (40), [-0.02518,   inf] (40), [-0.02480,   inf] (40), 
length of domains: 62
Total time: 0.7135	 pickout: 0.0241	 decision: 0.0621	 get_bound: 0.6201	 add_domain: 0.0073
Current lb:-0.06190681457519531
380 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.669568538665771

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([62, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([62, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [2, 4553] [2, 4553] [2, 4553] [2, 4553] [2, 4553] [2, 4553] [2, 4553] [2, 4553] [2, 4553] [2, 4553] 
regular batch size: 2*62, diving batch size 1*0
best_l after optimization: 1.1530169248580933 with beta sum per layer: [9.959447860717773, 0.0, 0.011360259726643562, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.565140962600708
This batch time : update_bounds func: 0.6394	 prepare: 0.0239	 bound: 0.5656	 transfer: 0.0352	 finalize: 0.0143
Accumulated time: update_bounds func: 6.9347	 prepare: 0.1247	 bound: 6.5999	 transfer: 0.0352	 finalize: 0.0640
batch bounding time:  0.6396639347076416
Current worst splitting domains [lb, ub] (depth):
[-0.06190,   inf] (42), [-0.05672,   inf] (42), [-0.04862,   inf] (42), [-0.04450,   inf] (42), [-0.04343,   inf] (42), [-0.04328,   inf] (42), [-0.03972,   inf] (42), [-0.03932,   inf] (42), [-0.03885,   inf] (42), [-0.03809,   inf] (42), [-0.03472,   inf] (42), [-0.03404,   inf] (42), [-0.03365,   inf] (42), [-0.03121,   inf] (42), [-0.02999,   inf] (42), [-0.02969,   inf] (42), [-0.02887,   inf] (42), [-0.02672,   inf] (42), [-0.02603,   inf] (42), [-0.02589,   inf] (42), 
length of domains: 89
Total time: 0.7591	 pickout: 0.0329	 decision: 0.0757	 get_bound: 0.6399	 add_domain: 0.0106
Current lb:-0.0619049072265625
504 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.430483341217041

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([89, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([89, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [5, 397] [5, 397] [5, 397] [5, 397] [5, 397] [5, 397] [5, 397] [5, 397] [5, 397] [5, 397] 
regular batch size: 2*89, diving batch size 1*0
best_l after optimization: -2.722403049468994 with beta sum per layer: [13.455275535583496, 0.0, 2.1653246879577637, 0.0, 0.0, 5.087393283843994]
alpha/beta optimization time: 0.7631111145019531
This batch time : update_bounds func: 0.8525	 prepare: 0.0329	 bound: 0.7636	 transfer: 0.0344	 finalize: 0.0211
Accumulated time: update_bounds func: 7.7872	 prepare: 0.1576	 bound: 7.3635	 transfer: 0.0344	 finalize: 0.0851
batch bounding time:  0.8528327941894531
Current worst splitting domains [lb, ub] (depth):
[-0.06085,   inf] (44), [-0.05567,   inf] (44), [-0.04655,   inf] (44), [-0.04347,   inf] (44), [-0.04222,   inf] (44), [-0.04127,   inf] (44), [-0.03916,   inf] (44), [-0.03829,   inf] (44), [-0.03829,   inf] (44), [-0.03703,   inf] (44), [-0.03416,   inf] (44), [-0.03330,   inf] (44), [-0.03309,   inf] (44), [-0.02995,   inf] (44), [-0.02861,   inf] (44), [-0.02813,   inf] (44), [-0.02760,   inf] (44), [-0.02485,   inf] (44), [-0.02465,   inf] (44), [-0.02377,   inf] (44), 
length of domains: 81
Total time: 1.0210	 pickout: 0.0586	 decision: 0.0991	 get_bound: 0.8532	 add_domain: 0.0102
Current lb:-0.06084847450256348
682 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.455206871032715

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([81, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([81, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 8002] [0, 8002] [0, 8002] [0, 8002] [0, 8002] [0, 8002] [0, 8002] [0, 8002] [0, 8002] [0, 8002] 
regular batch size: 2*81, diving batch size 1*0
best_l after optimization: 1.3911335468292236 with beta sum per layer: [16.427623748779297, 0.0, 0.061809249222278595, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.7006254196166992
This batch time : update_bounds func: 0.7710	 prepare: 0.0298	 bound: 0.7011	 transfer: 0.0215	 finalize: 0.0182
Accumulated time: update_bounds func: 8.5582	 prepare: 0.1875	 bound: 8.0646	 transfer: 0.0215	 finalize: 0.1033
batch bounding time:  0.7713804244995117
Current worst splitting domains [lb, ub] (depth):
[-0.06071,   inf] (46), [-0.05553,   inf] (46), [-0.04334,   inf] (46), [-0.04208,   inf] (46), [-0.03921,   inf] (46), [-0.03903,   inf] (46), [-0.03815,   inf] (46), [-0.03815,   inf] (46), [-0.03690,   inf] (46), [-0.03649,   inf] (46), [-0.03489,   inf] (46), [-0.03437,   inf] (46), [-0.03402,   inf] (46), [-0.03316,   inf] (46), [-0.03295,   inf] (46), [-0.03120,   inf] (46), [-0.02971,   inf] (46), [-0.02799,   inf] (46), [-0.02714,   inf] (46), [-0.02471,   inf] (46), 
length of domains: 112
Total time: 0.9165	 pickout: 0.0412	 decision: 0.0898	 get_bound: 0.7716	 add_domain: 0.0139
Current lb:-0.06071019172668457
844 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.374634742736816

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([112, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([112, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [3, 1524] [3, 1524] [3, 1524] [3, 1524] [3, 1524] [3, 1524] [3, 1524] [3, 1524] [3, 1524] [3, 1524] 
regular batch size: 2*112, diving batch size 1*0
best_l after optimization: 1.9359163045883179 with beta sum per layer: [23.72820281982422, 0.0, 0.06349752098321915, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.8524606227874756
This batch time : update_bounds func: 0.9592	 prepare: 0.0408	 bound: 0.8529	 transfer: 0.0408	 finalize: 0.0241
Accumulated time: update_bounds func: 9.5174	 prepare: 0.2283	 bound: 8.9175	 transfer: 0.0408	 finalize: 0.1274
batch bounding time:  0.9595506191253662
Current worst splitting domains [lb, ub] (depth):
[-0.05783,   inf] (48), [-0.05265,   inf] (48), [-0.05227,   inf] (48), [-0.04709,   inf] (48), [-0.04046,   inf] (48), [-0.03920,   inf] (48), [-0.03632,   inf] (48), [-0.03615,   inf] (48), [-0.03528,   inf] (48), [-0.03527,   inf] (48), [-0.03489,   inf] (48), [-0.03402,   inf] (48), [-0.03332,   inf] (48), [-0.03191,   inf] (48), [-0.03190,   inf] (48), [-0.03137,   inf] (48), [-0.03115,   inf] (48), [-0.03050,   inf] (48), [-0.03028,   inf] (48), [-0.03007,   inf] (48), 
length of domains: 156
Total time: 1.1655	 pickout: 0.0716	 decision: 0.1139	 get_bound: 0.9599	 add_domain: 0.0201
Current lb:-0.057830810546875
1068 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.543640851974487

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([156, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([156, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 12669] [0, 12669] [0, 12669] [0, 12669] [0, 12669] [0, 12669] [0, 12669] [0, 12669] [0, 12669] [0, 12669] 
regular batch size: 2*156, diving batch size 1*0
best_l after optimization: 3.1773109436035156 with beta sum per layer: [29.114675521850586, 0.0, 0.0670381635427475, 0.0, 0.0, 0.0]
alpha/beta optimization time: 1.0651264190673828
This batch time : update_bounds func: 1.2156	 prepare: 0.0563	 bound: 1.0656	 transfer: 0.0590	 finalize: 0.0341
Accumulated time: update_bounds func: 10.7330	 prepare: 0.2846	 bound: 9.9831	 transfer: 0.0590	 finalize: 0.1615
batch bounding time:  1.21616530418396
Current worst splitting domains [lb, ub] (depth):
[-0.05776,   inf] (50), [-0.05258,   inf] (50), [-0.05219,   inf] (50), [-0.05112,   inf] (50), [-0.04701,   inf] (50), [-0.04594,   inf] (50), [-0.04555,   inf] (50), [-0.04038,   inf] (50), [-0.04037,   inf] (50), [-0.03913,   inf] (50), [-0.03625,   inf] (50), [-0.03610,   inf] (50), [-0.03523,   inf] (50), [-0.03521,   inf] (50), [-0.03482,   inf] (50), [-0.03394,   inf] (50), [-0.03374,   inf] (50), [-0.03249,   inf] (50), [-0.03242,   inf] (50), [-0.03184,   inf] (50), 
length of domains: 251
Total time: 1.5690	 pickout: 0.0961	 decision: 0.2225	 get_bound: 1.2166	 add_domain: 0.0338
Current lb:-0.05775642395019531
1380 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.118231058120728

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([251, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([251, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 12898] [0, 12898] [0, 12898] [0, 12898] [0, 12898] [0, 12898] [0, 12898] [0, 12898] [0, 12898] [0, 12898] 
regular batch size: 2*251, diving batch size 1*0
best_l after optimization: 4.910652160644531 with beta sum per layer: [45.360130310058594, 0.0, 0.24260213971138, 0.3576829433441162, 0.0, 0.0]
alpha/beta optimization time: 1.5464937686920166
This batch time : update_bounds func: 1.7877	 prepare: 0.0900	 bound: 1.5471	 transfer: 0.0933	 finalize: 0.0560
Accumulated time: update_bounds func: 12.5207	 prepare: 0.3746	 bound: 11.5302	 transfer: 0.0933	 finalize: 0.2175
batch bounding time:  1.7883801460266113
Current worst splitting domains [lb, ub] (depth):
[-0.05774,   inf] (52), [-0.05256,   inf] (52), [-0.05180,   inf] (52), [-0.05110,   inf] (52), [-0.05107,   inf] (52), [-0.04658,   inf] (52), [-0.04592,   inf] (52), [-0.04589,   inf] (52), [-0.04550,   inf] (52), [-0.04542,   inf] (52), [-0.04443,   inf] (52), [-0.04036,   inf] (52), [-0.04033,   inf] (52), [-0.04016,   inf] (52), [-0.03925,   inf] (52), [-0.03911,   inf] (52), [-0.03886,   inf] (52), [-0.03623,   inf] (52), [-0.03608,   inf] (52), [-0.03521,   inf] (52), 
length of domains: 403
Total time: 2.2284	 pickout: 0.1527	 decision: 0.2310	 get_bound: 1.7891	 add_domain: 0.0555
Current lb:-0.057737112045288086
1882 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.356619596481323

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 8194] [0, 8194] [0, 8194] [0, 8194] [3, 2416] [0, 8194] [0, 8194] [3, 2416] [3, 2416] [0, 8194] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 6.090198516845703 with beta sum per layer: [47.964115142822266, 0.0, 2.8916468620300293, 5.781266212463379, 0.0, 0.0]
alpha/beta optimization time: 1.5598509311676025
This batch time : update_bounds func: 1.8644	 prepare: 0.0952	 bound: 1.5606	 transfer: 0.1468	 finalize: 0.0603
Accumulated time: update_bounds func: 14.3851	 prepare: 0.4697	 bound: 13.0908	 transfer: 0.1468	 finalize: 0.2778
batch bounding time:  1.8650588989257812
Current worst splitting domains [lb, ub] (depth):
[-0.05763,   inf] (54), [-0.05245,   inf] (54), [-0.05099,   inf] (54), [-0.05094,   inf] (54), [-0.05089,   inf] (54), [-0.04953,   inf] (54), [-0.04581,   inf] (54), [-0.04577,   inf] (54), [-0.04572,   inf] (54), [-0.04538,   inf] (54), [-0.04431,   inf] (54), [-0.04430,   inf] (54), [-0.04422,   inf] (54), [-0.04298,   inf] (54), [-0.04128,   inf] (54), [-0.04026,   inf] (54), [-0.04020,   inf] (54), [-0.03912,   inf] (54), [-0.03906,   inf] (54), [-0.03900,   inf] (54), 
length of domains: 582
Total time: 2.3725	 pickout: 0.1545	 decision: 0.2908	 get_bound: 1.8659	 add_domain: 0.0614
Current lb:-0.05762839317321777
2394 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 20.738505601882935

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [3, 2416] [3, 2416] [3, 2416] [0, 8194] [3, 2416] [3, 2416] [3, 2416] [0, 8194] [3, 2416] [0, 8194] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 4.717031478881836 with beta sum per layer: [51.052635192871094, 0.0, 8.262025833129883, 17.673784255981445, 0.0, 0.0]
alpha/beta optimization time: 1.5578200817108154
This batch time : update_bounds func: 1.8666	 prepare: 0.0937	 bound: 1.5584	 transfer: 0.1514	 finalize: 0.0615
Accumulated time: update_bounds func: 16.2516	 prepare: 0.5634	 bound: 14.6492	 transfer: 0.1514	 finalize: 0.3393
batch bounding time:  1.8672235012054443
Current worst splitting domains [lb, ub] (depth):
[-0.05750,   inf] (56), [-0.05233,   inf] (56), [-0.05086,   inf] (56), [-0.05075,   inf] (56), [-0.04785,   inf] (56), [-0.04750,   inf] (56), [-0.04568,   inf] (56), [-0.04558,   inf] (56), [-0.04462,   inf] (56), [-0.04409,   inf] (56), [-0.04284,   inf] (56), [-0.04232,   inf] (56), [-0.04215,   inf] (56), [-0.04122,   inf] (56), [-0.04115,   inf] (56), [-0.04099,   inf] (56), [-0.04019,   inf] (56), [-0.03944,   inf] (56), [-0.03894,   inf] (56), [-0.03892,   inf] (56), 
length of domains: 672
Total time: 2.3120	 pickout: 0.1622	 decision: 0.2314	 get_bound: 1.8680	 add_domain: 0.0503
Current lb:-0.057502031326293945
2906 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 23.05997085571289

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [2, 4539] [2, 4539] [2, 4539] [2, 4539] [2, 4539] [2, 4539] [2, 4539] [2, 4539] [2, 4539] [2, 4539] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: -30.803775787353516 with beta sum per layer: [44.32290267944336, 0.0, 0.2251759022474289, 0.6020468473434448, 0.0, 0.0]
alpha/beta optimization time: 1.57187819480896
This batch time : update_bounds func: 1.8811	 prepare: 0.0926	 bound: 1.5724	 transfer: 0.1551	 finalize: 0.0598
Accumulated time: update_bounds func: 18.1327	 prepare: 0.6560	 bound: 16.2216	 transfer: 0.1551	 finalize: 0.3991
batch bounding time:  1.8817973136901855
Current worst splitting domains [lb, ub] (depth):
[-0.05750,   inf] (58), [-0.05232,   inf] (58), [-0.05086,   inf] (58), [-0.05075,   inf] (58), [-0.04738,   inf] (58), [-0.04699,   inf] (58), [-0.04568,   inf] (58), [-0.04558,   inf] (58), [-0.04462,   inf] (58), [-0.04408,   inf] (58), [-0.04212,   inf] (58), [-0.04173,   inf] (58), [-0.04115,   inf] (58), [-0.04074,   inf] (58), [-0.04071,   inf] (58), [-0.04039,   inf] (58), [-0.04019,   inf] (58), [-0.03944,   inf] (58), [-0.03894,   inf] (58), [-0.03892,   inf] (58), 
length of domains: 675
Total time: 2.4178	 pickout: 0.1418	 decision: 0.3527	 get_bound: 1.8826	 add_domain: 0.0408
Current lb:-0.057502031326293945
3418 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 25.487935304641724

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [5, 457] [5, 457] [5, 457] [5, 457] [5, 457] [5, 457] [5, 457] [5, 457] [5, 457] [5, 457] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 0.3623940348625183 with beta sum per layer: [53.371341705322266, 0.0, 2.4313361644744873, 0.8219856023788452, 0.0, 55.73651885986328]
alpha/beta optimization time: 1.5691304206848145
This batch time : update_bounds func: 1.8792	 prepare: 0.0947	 bound: 1.5697	 transfer: 0.1511	 finalize: 0.0625
Accumulated time: update_bounds func: 20.0120	 prepare: 0.7507	 bound: 17.7912	 transfer: 0.1511	 finalize: 0.4616
batch bounding time:  1.8799107074737549
Current worst splitting domains [lb, ub] (depth):
[-0.05500,   inf] (60), [-0.04982,   inf] (60), [-0.04836,   inf] (60), [-0.04836,   inf] (60), [-0.04493,   inf] (60), [-0.04346,   inf] (60), [-0.04319,   inf] (60), [-0.04318,   inf] (60), [-0.04212,   inf] (60), [-0.04169,   inf] (60), [-0.03967,   inf] (60), [-0.03864,   inf] (60), [-0.03825,   inf] (60), [-0.03823,   inf] (60), [-0.03822,   inf] (60), [-0.03791,   inf] (60), [-0.03749,   inf] (60), [-0.03694,   inf] (60), [-0.03653,   inf] (60), [-0.03647,   inf] (60), 
length of domains: 675
Total time: 2.3045	 pickout: 0.1566	 decision: 0.2288	 get_bound: 1.8807	 add_domain: 0.0384
Current lb:-0.055002689361572266
3930 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 27.802464246749878

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 7965] [0, 7965] [0, 7965] [0, 7965] [0, 7965] [0, 7965] [0, 7965] [0, 7965] [0, 7965] [0, 7965] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 2.6401283740997314 with beta sum per layer: [49.59093475341797, 0.0, 0.6625069379806519, 1.1695090532302856, 0.0, 0.49797096848487854]
alpha/beta optimization time: 1.5551528930664062
This batch time : update_bounds func: 1.8611	 prepare: 0.0919	 bound: 1.5557	 transfer: 0.1532	 finalize: 0.0592
Accumulated time: update_bounds func: 21.8730	 prepare: 0.8426	 bound: 19.3469	 transfer: 0.1532	 finalize: 0.5208
batch bounding time:  1.8617846965789795
Current worst splitting domains [lb, ub] (depth):
[-0.05491,   inf] (62), [-0.04973,   inf] (62), [-0.04874,   inf] (62), [-0.04827,   inf] (62), [-0.04827,   inf] (62), [-0.04483,   inf] (62), [-0.04356,   inf] (62), [-0.04336,   inf] (62), [-0.04310,   inf] (62), [-0.04309,   inf] (62), [-0.04209,   inf] (62), [-0.04208,   inf] (62), [-0.04202,   inf] (62), [-0.04160,   inf] (62), [-0.03957,   inf] (62), [-0.03866,   inf] (62), [-0.03854,   inf] (62), [-0.03817,   inf] (62), [-0.03815,   inf] (62), [-0.03812,   inf] (62), 
length of domains: 890
Total time: 2.3709	 pickout: 0.1435	 decision: 0.2941	 get_bound: 1.8626	 add_domain: 0.0707
Current lb:-0.05490541458129883
4442 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 30.18137526512146

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [3, 1776] [3, 1776] [3, 1776] [3, 1562] [3, 1776] [3, 1776] [3, 1776] [3, 1776] [3, 1562] [3, 1776] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 9.824668884277344 with beta sum per layer: [48.014251708984375, 0.0, 0.21200095117092133, 1.630408763885498, 0.0, 1.8998603820800781]
alpha/beta optimization time: 1.5404565334320068
This batch time : update_bounds func: 1.9191	 prepare: 0.0931	 bound: 1.5410	 transfer: 0.1513	 finalize: 0.1326
Accumulated time: update_bounds func: 23.7921	 prepare: 0.9356	 bound: 20.8878	 transfer: 0.1513	 finalize: 0.6534
batch bounding time:  1.9198904037475586
Current worst splitting domains [lb, ub] (depth):
[-0.05485,   inf] (64), [-0.04968,   inf] (64), [-0.04868,   inf] (64), [-0.04822,   inf] (64), [-0.04691,   inf] (64), [-0.04554,   inf] (64), [-0.04477,   inf] (64), [-0.04354,   inf] (64), [-0.04350,   inf] (64), [-0.04331,   inf] (64), [-0.04304,   inf] (64), [-0.04203,   inf] (64), [-0.04197,   inf] (64), [-0.04181,   inf] (64), [-0.04148,   inf] (64), [-0.04073,   inf] (64), [-0.04020,   inf] (64), [-0.03992,   inf] (64), [-0.03952,   inf] (64), [-0.03949,   inf] (64), 
length of domains: 1130
Total time: 2.3658	 pickout: 0.1416	 decision: 0.2277	 get_bound: 1.9207	 add_domain: 0.0757
Current lb:-0.054851531982421875
4954 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 32.55393433570862

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [3, 1562] [3, 2356] [3, 1562] [3, 1562] [3, 1562] [1, 4391] [3, 1562] [1, 4391] [3, 2356] [3, 1562] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 11.911556243896484 with beta sum per layer: [43.63966369628906, 0.07426922023296356, 0.0933801531791687, 4.291310787200928, 0.0, 0.0]
alpha/beta optimization time: 1.530125617980957
This batch time : update_bounds func: 1.8353	 prepare: 0.0959	 bound: 1.5306	 transfer: 0.1488	 finalize: 0.0585
Accumulated time: update_bounds func: 25.6275	 prepare: 1.0316	 bound: 22.4185	 transfer: 0.1488	 finalize: 0.7120
batch bounding time:  1.8359568119049072
Current worst splitting domains [lb, ub] (depth):
[-0.05213,   inf] (66), [-0.05013,   inf] (66), [-0.04937,   inf] (66), [-0.04596,   inf] (66), [-0.04549,   inf] (66), [-0.04505,   inf] (66), [-0.04406,   inf] (66), [-0.04395,   inf] (66), [-0.04334,   inf] (66), [-0.04320,   inf] (66), [-0.04305,   inf] (66), [-0.04293,   inf] (66), [-0.04274,   inf] (66), [-0.04264,   inf] (66), [-0.04205,   inf] (66), [-0.04157,   inf] (66), [-0.04064,   inf] (66), [-0.04058,   inf] (66), [-0.04033,   inf] (66), [-0.04024,   inf] (66), 
length of domains: 1373
Total time: 2.2886	 pickout: 0.1423	 decision: 0.2294	 get_bound: 1.8367	 add_domain: 0.0801
Current lb:-0.05212759971618652
5466 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 34.85056209564209

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [2, 5325] [2, 5325] [2, 5325] [2, 5325] [2, 5325] [2, 5325] [2, 5325] [2, 5325] [2, 5325] [2, 5325] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 5.077964782714844 with beta sum per layer: [44.949562072753906, 0.11035868525505066, 1.4254019260406494, 19.21977996826172, 0.0, 0.0]
alpha/beta optimization time: 1.5625965595245361
This batch time : update_bounds func: 1.9322	 prepare: 0.0973	 bound: 1.5631	 transfer: 0.1498	 finalize: 0.1208
Accumulated time: update_bounds func: 27.5597	 prepare: 1.1289	 bound: 23.9816	 transfer: 0.1498	 finalize: 0.8327
batch bounding time:  1.9328677654266357
Current worst splitting domains [lb, ub] (depth):
[-0.05211,   inf] (68), [-0.05011,   inf] (68), [-0.04936,   inf] (68), [-0.04570,   inf] (68), [-0.04504,   inf] (68), [-0.04404,   inf] (68), [-0.04369,   inf] (68), [-0.04306,   inf] (68), [-0.04303,   inf] (68), [-0.04294,   inf] (68), [-0.04263,   inf] (68), [-0.04204,   inf] (68), [-0.04132,   inf] (68), [-0.04120,   inf] (68), [-0.04063,   inf] (68), [-0.04057,   inf] (68), [-0.04022,   inf] (68), [-0.04004,   inf] (68), [-0.03972,   inf] (68), [-0.03941,   inf] (68), 
length of domains: 1429
Total time: 2.3561	 pickout: 0.1421	 decision: 0.2296	 get_bound: 1.9336	 add_domain: 0.0507
Current lb:-0.05211472511291504
5978 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 37.21602177619934

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [3, 2356] [3, 2356] [3, 1562] [3, 2356] [3, 1776] [3, 2356] [3, 2356] [3, 2356] [3, 1776] [3, 1562] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 9.640195846557617 with beta sum per layer: [47.1453971862793, 0.5421351194381714, 0.485262930393219, 21.055522918701172, 0.0, 0.0]
alpha/beta optimization time: 1.5566229820251465
This batch time : update_bounds func: 1.8659	 prepare: 0.0972	 bound: 1.5571	 transfer: 0.1508	 finalize: 0.0597
Accumulated time: update_bounds func: 29.4256	 prepare: 1.2261	 bound: 25.5387	 transfer: 0.1508	 finalize: 0.8924
batch bounding time:  1.8665680885314941
Current worst splitting domains [lb, ub] (depth):
[-0.05181,   inf] (70), [-0.04981,   inf] (70), [-0.04699,   inf] (70), [-0.04618,   inf] (70), [-0.04540,   inf] (70), [-0.04539,   inf] (70), [-0.04422,   inf] (70), [-0.04339,   inf] (70), [-0.04302,   inf] (70), [-0.04295,   inf] (70), [-0.04276,   inf] (70), [-0.04210,   inf] (70), [-0.04194,   inf] (70), [-0.04182,   inf] (70), [-0.04174,   inf] (70), [-0.04101,   inf] (70), [-0.04057,   inf] (70), [-0.04027,   inf] (70), [-0.03982,   inf] (70), [-0.03981,   inf] (70), 
length of domains: 1598
Total time: 2.3102	 pickout: 0.1434	 decision: 0.2294	 get_bound: 1.8674	 add_domain: 0.0701
Current lb:-0.051812171936035156
6490 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 39.534793853759766

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [5, 151] [5, 151] [5, 151] [5, 151] [2, 4516] [5, 151] [3, 2356] [5, 151] [2, 4516] [2, 4516] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: -10.84221363067627 with beta sum per layer: [59.534263610839844, 0.45779192447662354, 8.889845848083496, 43.94230651855469, 0.0, 27.174455642700195]
alpha/beta optimization time: 1.5877735614776611
This batch time : update_bounds func: 1.9793	 prepare: 0.1014	 bound: 1.5883	 transfer: 0.1501	 finalize: 0.0625
Accumulated time: update_bounds func: 31.4049	 prepare: 1.3275	 bound: 27.1270	 transfer: 0.1501	 finalize: 0.9549
batch bounding time:  1.9801161289215088
Current worst splitting domains [lb, ub] (depth):
[-0.05161,   inf] (72), [-0.04961,   inf] (72), [-0.04680,   inf] (72), [-0.04598,   inf] (72), [-0.04519,   inf] (72), [-0.04376,   inf] (72), [-0.04319,   inf] (72), [-0.04285,   inf] (72), [-0.04256,   inf] (72), [-0.04174,   inf] (72), [-0.04163,   inf] (72), [-0.04155,   inf] (72), [-0.04151,   inf] (72), [-0.04135,   inf] (72), [-0.04081,   inf] (72), [-0.04037,   inf] (72), [-0.03975,   inf] (72), [-0.03965,   inf] (72), [-0.03960,   inf] (72), [-0.03956,   inf] (72), 
length of domains: 1657
Total time: 2.4279	 pickout: 0.1584	 decision: 0.2337	 get_bound: 1.9810	 add_domain: 0.0549
Current lb:-0.05161404609680176
7002 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 41.97643041610718

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [1, 4391] [1, 4391] [1, 4391] [1, 4391] [1, 4391] [2, 4516] [1, 4391] [5, 151] [1, 4391] [0, 8084] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 7.087125301361084 with beta sum per layer: [55.22343444824219, 1.9357879161834717, 2.3835105895996094, 7.989630699157715, 0.0, 4.691875457763672]
alpha/beta optimization time: 1.5609636306762695
This batch time : update_bounds func: 1.8719	 prepare: 0.0985	 bound: 1.5615	 transfer: 0.1507	 finalize: 0.0600
Accumulated time: update_bounds func: 33.2769	 prepare: 1.4260	 bound: 28.6885	 transfer: 0.1507	 finalize: 1.0149
batch bounding time:  1.8725945949554443
Current worst splitting domains [lb, ub] (depth):
[-0.05112,   inf] (74), [-0.04911,   inf] (74), [-0.04869,   inf] (74), [-0.04653,   inf] (74), [-0.04630,   inf] (74), [-0.04548,   inf] (74), [-0.04469,   inf] (74), [-0.04386,   inf] (74), [-0.04376,   inf] (74), [-0.04306,   inf] (74), [-0.04269,   inf] (74), [-0.04262,   inf] (74), [-0.04227,   inf] (74), [-0.04206,   inf] (74), [-0.04173,   inf] (74), [-0.04163,   inf] (74), [-0.04151,   inf] (74), [-0.04135,   inf] (74), [-0.04104,   inf] (74), [-0.04032,   inf] (74), 
length of domains: 1796
Total time: 2.3452	 pickout: 0.1731	 decision: 0.2304	 get_bound: 1.8734	 add_domain: 0.0683
Current lb:-0.051116943359375
7514 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 44.33141732215881

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [2, 4600] [2, 4600] [2, 4600] [0, 8084] [2, 4600] [2, 4600] [2, 4600] [0, 8084] [0, 8084] [2, 4600] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: -9.978300094604492 with beta sum per layer: [56.369773864746094, 1.0051703453063965, 16.023189544677734, 11.177375793457031, 0.0, 32.563385009765625]
alpha/beta optimization time: 1.5763177871704102
This batch time : update_bounds func: 1.8901	 prepare: 0.1018	 bound: 1.5769	 transfer: 0.1499	 finalize: 0.0603
Accumulated time: update_bounds func: 35.1670	 prepare: 1.5278	 bound: 30.2654	 transfer: 0.1499	 finalize: 1.0752
batch bounding time:  1.8908195495605469
Current worst splitting domains [lb, ub] (depth):
[-0.05082,   inf] (76), [-0.04942,   inf] (76), [-0.04881,   inf] (76), [-0.04840,   inf] (76), [-0.04742,   inf] (76), [-0.04699,   inf] (76), [-0.04652,   inf] (76), [-0.04588,   inf] (76), [-0.04519,   inf] (76), [-0.04460,   inf] (76), [-0.04440,   inf] (76), [-0.04379,   inf] (76), [-0.04376,   inf] (76), [-0.04355,   inf] (76), [-0.04300,   inf] (76), [-0.04276,   inf] (76), [-0.04206,   inf] (76), [-0.04198,   inf] (76), [-0.04158,   inf] (76), [-0.04158,   inf] (76), 
length of domains: 1879
Total time: 2.4093	 pickout: 0.1453	 decision: 0.3126	 get_bound: 1.8916	 add_domain: 0.0598
Current lb:-0.050817251205444336
8026 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 46.75168204307556

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 8084] [0, 8084] [0, 8084] [0, 8084] [0, 8084] [0, 8084] [0, 12788] [0, 8084] [0, 8084] [0, 8084] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: -0.6278432607650757 with beta sum per layer: [53.20296859741211, 2.6875085830688477, 6.834644317626953, 2.890634536743164, 0.0, 8.513557434082031]
alpha/beta optimization time: 1.5759985446929932
This batch time : update_bounds func: 1.8895	 prepare: 0.1004	 bound: 1.5765	 transfer: 0.1510	 finalize: 0.0604
Accumulated time: update_bounds func: 37.0565	 prepare: 1.6282	 bound: 31.8419	 transfer: 0.1510	 finalize: 1.1356
batch bounding time:  1.8902382850646973
Current worst splitting domains [lb, ub] (depth):
[-0.05081,   inf] (78), [-0.04942,   inf] (78), [-0.04874,   inf] (78), [-0.04839,   inf] (78), [-0.04741,   inf] (78), [-0.04698,   inf] (78), [-0.04651,   inf] (78), [-0.04587,   inf] (78), [-0.04518,   inf] (78), [-0.04460,   inf] (78), [-0.04439,   inf] (78), [-0.04378,   inf] (78), [-0.04364,   inf] (78), [-0.04325,   inf] (78), [-0.04299,   inf] (78), [-0.04276,   inf] (78), [-0.04197,   inf] (78), [-0.04174,   inf] (78), [-0.04158,   inf] (78), [-0.04136,   inf] (78), 
length of domains: 1923
Total time: 2.3343	 pickout: 0.1581	 decision: 0.2310	 get_bound: 1.8911	 add_domain: 0.0542
Current lb:-0.05081367492675781
8538 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 49.0968804359436

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [1, 4336] [0, 12788] [1, 4336] [0, 12788] [0, 12788] [0, 12788] [1, 4336] [1, 4336] [1, 4336] [0, 12788] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: -11.396860122680664 with beta sum per layer: [48.566036224365234, 2.2187089920043945, 10.123199462890625, 4.510746955871582, 0.0, 2.733717918395996]
alpha/beta optimization time: 1.5684642791748047
This batch time : update_bounds func: 1.8859	 prepare: 0.1023	 bound: 1.5692	 transfer: 0.1498	 finalize: 0.0634
Accumulated time: update_bounds func: 38.9425	 prepare: 1.7305	 bound: 33.4112	 transfer: 0.1498	 finalize: 1.1991
batch bounding time:  1.8866145610809326
Current worst splitting domains [lb, ub] (depth):
[-0.05081,   inf] (80), [-0.04941,   inf] (80), [-0.04872,   inf] (80), [-0.04839,   inf] (80), [-0.04741,   inf] (80), [-0.04698,   inf] (80), [-0.04650,   inf] (80), [-0.04586,   inf] (80), [-0.04518,   inf] (80), [-0.04460,   inf] (80), [-0.04439,   inf] (80), [-0.04378,   inf] (80), [-0.04363,   inf] (80), [-0.04325,   inf] (80), [-0.04299,   inf] (80), [-0.04276,   inf] (80), [-0.04197,   inf] (80), [-0.04174,   inf] (80), [-0.04135,   inf] (80), [-0.04123,   inf] (80), 
length of domains: 1997
Total time: 2.3977	 pickout: 0.1443	 decision: 0.3062	 get_bound: 1.8874	 add_domain: 0.0597
Current lb:-0.05081343650817871
9050 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 51.505131006240845

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [2, 5326] [1, 4336] [2, 5326] [1, 4336] [1, 4336] [1, 4336] [2, 5326] [2, 5326] [2, 5326] [1, 4336] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: -9.064024925231934 with beta sum per layer: [47.74111557006836, 1.255048394203186, 17.014328002929688, 1.855715274810791, 0.0, 4.069698810577393]
alpha/beta optimization time: 1.5614583492279053
This batch time : update_bounds func: 1.8774	 prepare: 0.1021	 bound: 1.5620	 transfer: 0.1514	 finalize: 0.0608
Accumulated time: update_bounds func: 40.8199	 prepare: 1.8325	 bound: 34.9732	 transfer: 0.1514	 finalize: 1.2598
batch bounding time:  1.8780956268310547
Current worst splitting domains [lb, ub] (depth):
[-0.04988,   inf] (82), [-0.04941,   inf] (82), [-0.04839,   inf] (82), [-0.04779,   inf] (82), [-0.04741,   inf] (82), [-0.04698,   inf] (82), [-0.04557,   inf] (82), [-0.04493,   inf] (82), [-0.04459,   inf] (82), [-0.04425,   inf] (82), [-0.04378,   inf] (82), [-0.04345,   inf] (82), [-0.04299,   inf] (82), [-0.04276,   inf] (82), [-0.04270,   inf] (82), [-0.04232,   inf] (82), [-0.04197,   inf] (82), [-0.04135,   inf] (82), [-0.04112,   inf] (82), [-0.04081,   inf] (82), 
length of domains: 2105
Total time: 2.4152	 pickout: 0.1466	 decision: 0.2307	 get_bound: 1.8789	 add_domain: 0.1591
Current lb:-0.04988288879394531
9562 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 53.93059754371643

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 12788] [2, 5326] [2, 5326] [2, 5383] [2, 5326] [2, 5326] [0, 12676] [2, 5383] [2, 5326] [0, 12788] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 6.906789779663086 with beta sum per layer: [50.534671783447266, 0.9788139462471008, 20.63657569885254, 1.8621126413345337, 0.0, 10.423135757446289]
alpha/beta optimization time: 1.562295913696289
This batch time : update_bounds func: 1.8787	 prepare: 0.1006	 bound: 1.5628	 transfer: 0.1537	 finalize: 0.0605
Accumulated time: update_bounds func: 42.6986	 prepare: 1.9331	 bound: 36.5360	 transfer: 0.1537	 finalize: 1.3203
batch bounding time:  1.87939453125
Current worst splitting domains [lb, ub] (depth):
[-0.04988,   inf] (84), [-0.04848,   inf] (84), [-0.04746,   inf] (84), [-0.04721,   inf] (84), [-0.04648,   inf] (84), [-0.04605,   inf] (84), [-0.04557,   inf] (84), [-0.04435,   inf] (84), [-0.04425,   inf] (84), [-0.04366,   inf] (84), [-0.04345,   inf] (84), [-0.04285,   inf] (84), [-0.04269,   inf] (84), [-0.04205,   inf] (84), [-0.04183,   inf] (84), [-0.04134,   inf] (84), [-0.04103,   inf] (84), [-0.04095,   inf] (84), [-0.04042,   inf] (84), [-0.04029,   inf] (84), 
length of domains: 2287
Total time: 2.3361	 pickout: 0.1449	 decision: 0.2300	 get_bound: 1.8802	 add_domain: 0.0811
Current lb:-0.0498814582824707
10074 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 56.27622175216675

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [5, 507] [5, 507] [5, 507] [0, 12676] [5, 507] [5, 507] [0, 7972] [0, 12676] [5, 507] [5, 507] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 11.098542213439941 with beta sum per layer: [43.04011917114258, 0.9607657194137573, 8.232843399047852, 2.5168979167938232, 0.0, 23.185930252075195]
alpha/beta optimization time: 1.5635511875152588
This batch time : update_bounds func: 1.8886	 prepare: 0.1087	 bound: 1.5643	 transfer: 0.1505	 finalize: 0.0640
Accumulated time: update_bounds func: 44.5873	 prepare: 2.0418	 bound: 38.1002	 transfer: 0.1505	 finalize: 1.3843
batch bounding time:  1.8893320560455322
Current worst splitting domains [lb, ub] (depth):
[-0.04890,   inf] (86), [-0.04748,   inf] (86), [-0.04715,   inf] (86), [-0.04647,   inf] (86), [-0.04633,   inf] (86), [-0.04580,   inf] (86), [-0.04557,   inf] (86), [-0.04548,   inf] (86), [-0.04504,   inf] (86), [-0.04501,   inf] (86), [-0.04435,   inf] (86), [-0.04350,   inf] (86), [-0.04326,   inf] (86), [-0.04315,   inf] (86), [-0.04266,   inf] (86), [-0.04247,   inf] (86), [-0.04184,   inf] (86), [-0.04170,   inf] (86), [-0.04134,   inf] (86), [-0.04105,   inf] (86), 
length of domains: 2493
Total time: 2.4852	 pickout: 0.1622	 decision: 0.2302	 get_bound: 1.8902	 add_domain: 0.2026
Current lb:-0.04889535903930664
10586 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 58.770612716674805

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 12676] [0, 12676] [0, 7972] [0, 12676] [0, 12676] [0, 12676] [2, 4600] [0, 12676] [0, 12676] [0, 12676] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 13.366942405700684 with beta sum per layer: [40.57710266113281, 2.1551198959350586, 10.258024215698242, 3.555131435394287, 0.0, 26.122364044189453]
alpha/beta optimization time: 1.5593688488006592
This batch time : update_bounds func: 1.8598	 prepare: 0.1040	 bound: 1.5599	 transfer: 0.1306	 finalize: 0.0640
Accumulated time: update_bounds func: 46.4471	 prepare: 2.1458	 bound: 39.6602	 transfer: 0.1306	 finalize: 1.4483
batch bounding time:  1.860600471496582
Current worst splitting domains [lb, ub] (depth):
[-0.04889,   inf] (88), [-0.04748,   inf] (88), [-0.04711,   inf] (88), [-0.04647,   inf] (88), [-0.04621,   inf] (88), [-0.04548,   inf] (88), [-0.04527,   inf] (88), [-0.04504,   inf] (88), [-0.04501,   inf] (88), [-0.04435,   inf] (88), [-0.04376,   inf] (88), [-0.04326,   inf] (88), [-0.04306,   inf] (88), [-0.04266,   inf] (88), [-0.04247,   inf] (88), [-0.04184,   inf] (88), [-0.04180,   inf] (88), [-0.04153,   inf] (88), [-0.04134,   inf] (88), [-0.04130,   inf] (88), 
length of domains: 2699
Total time: 2.3300	 pickout: 0.1459	 decision: 0.2325	 get_bound: 1.8615	 add_domain: 0.0900
Current lb:-0.04889392852783203
11098 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 61.11367893218994

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 7972] [0, 7972] [2, 5385] [0, 7972] [2, 5383] [0, 7972] [5, 507] [0, 7972] [0, 7972] [0, 12788] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 12.298603057861328 with beta sum per layer: [33.41370391845703, 2.4764890670776367, 25.524999618530273, 26.49420166015625, 0.0, 31.536161422729492]
alpha/beta optimization time: 1.5761744976043701
This batch time : update_bounds func: 2.0006	 prepare: 0.1046	 bound: 1.5767	 transfer: 0.1497	 finalize: 0.1684
Accumulated time: update_bounds func: 48.4477	 prepare: 2.2503	 bound: 41.2369	 transfer: 0.1497	 finalize: 1.6167
batch bounding time:  2.0013349056243896
Current worst splitting domains [lb, ub] (depth):
[-0.04889,   inf] (90), [-0.04748,   inf] (90), [-0.04693,   inf] (90), [-0.04647,   inf] (90), [-0.04562,   inf] (90), [-0.04548,   inf] (90), [-0.04504,   inf] (90), [-0.04501,   inf] (90), [-0.04457,   inf] (90), [-0.04434,   inf] (90), [-0.04429,   inf] (90), [-0.04335,   inf] (90), [-0.04326,   inf] (90), [-0.04306,   inf] (90), [-0.04275,   inf] (90), [-0.04266,   inf] (90), [-0.04247,   inf] (90), [-0.04222,   inf] (90), [-0.04193,   inf] (90), [-0.04184,   inf] (90), 
length of domains: 2901
Total time: 2.4976	 pickout: 0.1688	 decision: 0.2374	 get_bound: 2.0021	 add_domain: 0.0893
Current lb:-0.048892974853515625
11610 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 63.62164640426636

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [2, 5385] [2, 5385] [5, 507] [2, 5385] [0, 7972] [2, 5385] [2, 5385] [3, 2440] [5, 507] [1, 4390] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 11.800947189331055 with beta sum per layer: [32.822757720947266, 9.681249618530273, 31.97159767150879, 24.75371742248535, 0.0, 25.21111297607422]
alpha/beta optimization time: 1.565087080001831
This batch time : update_bounds func: 1.8883	 prepare: 0.1048	 bound: 1.5657	 transfer: 0.1540	 finalize: 0.0627
Accumulated time: update_bounds func: 50.3360	 prepare: 2.3551	 bound: 42.8026	 transfer: 0.1540	 finalize: 1.6794
batch bounding time:  1.8890705108642578
Current worst splitting domains [lb, ub] (depth):
[-0.04872,   inf] (92), [-0.04731,   inf] (92), [-0.04658,   inf] (92), [-0.04597,   inf] (92), [-0.04593,   inf] (92), [-0.04577,   inf] (92), [-0.04562,   inf] (92), [-0.04531,   inf] (92), [-0.04522,   inf] (92), [-0.04516,   inf] (92), [-0.04501,   inf] (92), [-0.04454,   inf] (92), [-0.04434,   inf] (92), [-0.04433,   inf] (92), [-0.04379,   inf] (92), [-0.04359,   inf] (92), [-0.04356,   inf] (92), [-0.04318,   inf] (92), [-0.04316,   inf] (92), [-0.04309,   inf] (92), 
length of domains: 3088
Total time: 2.3671	 pickout: 0.1590	 decision: 0.2304	 get_bound: 1.8899	 add_domain: 0.0878
Current lb:-0.048723697662353516
12122 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 65.99990582466125

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [2, 5383] [3, 2440] [2, 5383] [2, 5383] [1, 4390] [2, 5383] [2, 5385] [3, 2440] [1, 4390] [0, 8083] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 7.175085544586182 with beta sum per layer: [46.20615768432617, 8.232955932617188, 53.96872329711914, 31.305984497070312, 0.0, 23.299406051635742]
alpha/beta optimization time: 1.5676462650299072
This batch time : update_bounds func: 2.0012	 prepare: 0.1026	 bound: 1.5682	 transfer: 0.1503	 finalize: 0.1790
Accumulated time: update_bounds func: 52.3372	 prepare: 2.4577	 bound: 44.3708	 transfer: 0.1503	 finalize: 1.8584
batch bounding time:  2.0019140243530273
Current worst splitting domains [lb, ub] (depth):
[-0.04827,   inf] (94), [-0.04731,   inf] (94), [-0.04613,   inf] (94), [-0.04591,   inf] (94), [-0.04552,   inf] (94), [-0.04545,   inf] (94), [-0.04532,   inf] (94), [-0.04531,   inf] (94), [-0.04516,   inf] (94), [-0.04486,   inf] (94), [-0.04462,   inf] (94), [-0.04454,   inf] (94), [-0.04434,   inf] (94), [-0.04415,   inf] (94), [-0.04400,   inf] (94), [-0.04380,   inf] (94), [-0.04356,   inf] (94), [-0.04341,   inf] (94), [-0.04334,   inf] (94), [-0.04329,   inf] (94), 
length of domains: 3214
Total time: 2.4619	 pickout: 0.1515	 decision: 0.2311	 get_bound: 2.0027	 add_domain: 0.0765
Current lb:-0.04826951026916504
12634 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 68.47329449653625

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [3, 2440] [1, 1268] [3, 2440] [0, 8083] [3, 2440] [0, 12845] [3, 2440] [1, 1268] [0, 12787] [0, 7971] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 10.185418128967285 with beta sum per layer: [31.00096893310547, 24.991514205932617, 49.92538070678711, 59.667144775390625, 0.0, 24.458030700683594]
alpha/beta optimization time: 1.5663213729858398
This batch time : update_bounds func: 1.8830	 prepare: 0.1032	 bound: 1.5669	 transfer: 0.1506	 finalize: 0.0608
Accumulated time: update_bounds func: 54.2202	 prepare: 2.5609	 bound: 45.9377	 transfer: 0.1506	 finalize: 1.9193
batch bounding time:  1.883667230606079
Current worst splitting domains [lb, ub] (depth):
[-0.04827,   inf] (96), [-0.04716,   inf] (96), [-0.04613,   inf] (96), [-0.04591,   inf] (96), [-0.04577,   inf] (96), [-0.04552,   inf] (96), [-0.04545,   inf] (96), [-0.04532,   inf] (96), [-0.04516,   inf] (96), [-0.04516,   inf] (96), [-0.04486,   inf] (96), [-0.04471,   inf] (96), [-0.04462,   inf] (96), [-0.04454,   inf] (96), [-0.04434,   inf] (96), [-0.04411,   inf] (96), [-0.04409,   inf] (96), [-0.04400,   inf] (96), [-0.04389,   inf] (96), [-0.04380,   inf] (96), 
length of domains: 3400
Total time: 2.3493	 pickout: 0.1444	 decision: 0.2307	 get_bound: 1.8845	 add_domain: 0.0897
Current lb:-0.04826951026916504
13146 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 70.83272194862366

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [1, 4390] [0, 7971] [1, 4390] [3, 2440] [0, 12787] [1, 4390] [0, 8141] [1, 4390] [3, 2440] [0, 7971] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 6.771114349365234 with beta sum per layer: [30.456741333007812, 26.45677375793457, 56.04644775390625, 67.1432876586914, 0.0, 24.792749404907227]
alpha/beta optimization time: 1.5654025077819824
This batch time : update_bounds func: 2.0080	 prepare: 0.1021	 bound: 1.5660	 transfer: 0.1492	 finalize: 0.1894
Accumulated time: update_bounds func: 56.2282	 prepare: 2.6629	 bound: 47.5037	 transfer: 0.1492	 finalize: 2.1087
batch bounding time:  2.0087125301361084
Current worst splitting domains [lb, ub] (depth):
[-0.04826,   inf] (98), [-0.04716,   inf] (98), [-0.04612,   inf] (98), [-0.04591,   inf] (98), [-0.04577,   inf] (98), [-0.04551,   inf] (98), [-0.04545,   inf] (98), [-0.04531,   inf] (98), [-0.04516,   inf] (98), [-0.04516,   inf] (98), [-0.04486,   inf] (98), [-0.04470,   inf] (98), [-0.04461,   inf] (98), [-0.04454,   inf] (98), [-0.04434,   inf] (98), [-0.04411,   inf] (98), [-0.04408,   inf] (98), [-0.04399,   inf] (98), [-0.04388,   inf] (98), [-0.04379,   inf] (98), 
length of domains: 3512
Total time: 2.4631	 pickout: 0.1461	 decision: 0.2310	 get_bound: 2.0095	 add_domain: 0.0764
Current lb:-0.04825925827026367
13658 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 73.30650448799133

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 7971] [2, 5356] [0, 7971] [0, 7971] [2, 5356] [0, 7971] [1, 4390] [0, 7971] [1, 1268] [2, 5356] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 4.216683387756348 with beta sum per layer: [34.85190963745117, 35.208412170410156, 67.32197570800781, 39.51878356933594, 0.0, 26.242938995361328]
alpha/beta optimization time: 1.5722150802612305
This batch time : update_bounds func: 1.8901	 prepare: 0.1019	 bound: 1.5727	 transfer: 0.1528	 finalize: 0.0614
Accumulated time: update_bounds func: 58.1183	 prepare: 2.7648	 bound: 49.0764	 transfer: 0.1528	 finalize: 2.1701
batch bounding time:  1.8907954692840576
Current worst splitting domains [lb, ub] (depth):
[-0.04826,   inf] (100), [-0.04715,   inf] (100), [-0.04612,   inf] (100), [-0.04591,   inf] (100), [-0.04556,   inf] (100), [-0.04551,   inf] (100), [-0.04544,   inf] (100), [-0.04531,   inf] (100), [-0.04515,   inf] (100), [-0.04501,   inf] (100), [-0.04465,   inf] (100), [-0.04456,   inf] (100), [-0.04439,   inf] (100), [-0.04436,   inf] (100), [-0.04435,   inf] (100), [-0.04419,   inf] (100), [-0.04402,   inf] (100), [-0.04397,   inf] (100), [-0.04394,   inf] (100), [-0.04383,   inf] (100), 
length of domains: 3619
Total time: 2.3456	 pickout: 0.1463	 decision: 0.2314	 get_bound: 1.8916	 add_domain: 0.0763
Current lb:-0.04825925827026367
14170 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 75.66316843032837

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [2, 5356] [1, 4390] [2, 5356] [2, 5356] [3, 2440] [2, 5356] [3, 2440] [2, 5356] [1, 4390] [0, 7971] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 4.498144149780273 with beta sum per layer: [28.47086524963379, 29.949186325073242, 65.90101623535156, 31.506610870361328, 0.0, 25.77028465270996]
alpha/beta optimization time: 1.5916988849639893
This batch time : update_bounds func: 2.1255	 prepare: 0.1018	 bound: 1.5923	 transfer: 0.1288	 finalize: 0.3013
Accumulated time: update_bounds func: 60.2438	 prepare: 2.8666	 bound: 50.6687	 transfer: 0.1288	 finalize: 2.4715
batch bounding time:  2.12662410736084
Current worst splitting domains [lb, ub] (depth):
[-0.04825,   inf] (102), [-0.04714,   inf] (102), [-0.04611,   inf] (102), [-0.04574,   inf] (102), [-0.04556,   inf] (102), [-0.04550,   inf] (102), [-0.04544,   inf] (102), [-0.04530,   inf] (102), [-0.04514,   inf] (102), [-0.04501,   inf] (102), [-0.04465,   inf] (102), [-0.04456,   inf] (102), [-0.04439,   inf] (102), [-0.04436,   inf] (102), [-0.04435,   inf] (102), [-0.04419,   inf] (102), [-0.04414,   inf] (102), [-0.04402,   inf] (102), [-0.04394,   inf] (102), [-0.04383,   inf] (102), 
length of domains: 3732
Total time: 2.5975	 pickout: 0.1545	 decision: 0.2331	 get_bound: 2.1277	 add_domain: 0.0822
Current lb:-0.04825425148010254
14682 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 78.27567720413208

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [1, 1268] [0, 12675] [0, 12675] [0, 8134] [0, 7971] [0, 12675] [0, 7971] [0, 12675] [0, 12675] [1, 4390] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 9.369335174560547 with beta sum per layer: [22.383071899414062, 53.87898254394531, 52.169227600097656, 35.94611358642578, 0.0, 26.763458251953125]
alpha/beta optimization time: 1.5944404602050781
This batch time : update_bounds func: 1.9468	 prepare: 0.1551	 bound: 1.5952	 transfer: 0.1321	 finalize: 0.0631
Accumulated time: update_bounds func: 62.1907	 prepare: 3.0217	 bound: 52.2639	 transfer: 0.1321	 finalize: 2.5346
batch bounding time:  1.9475417137145996
Current worst splitting domains [lb, ub] (depth):
[-0.04812,   inf] (104), [-0.04714,   inf] (104), [-0.04611,   inf] (104), [-0.04574,   inf] (104), [-0.04556,   inf] (104), [-0.04550,   inf] (104), [-0.04544,   inf] (104), [-0.04530,   inf] (104), [-0.04514,   inf] (104), [-0.04500,   inf] (104), [-0.04471,   inf] (104), [-0.04450,   inf] (104), [-0.04441,   inf] (104), [-0.04438,   inf] (104), [-0.04435,   inf] (104), [-0.04422,   inf] (104), [-0.04418,   inf] (104), [-0.04414,   inf] (104), [-0.04402,   inf] (104), [-0.04388,   inf] (104), 
length of domains: 3892
Total time: 2.4847	 pickout: 0.1874	 decision: 0.2586	 get_bound: 1.9484	 add_domain: 0.0902
Current lb:-0.04811501502990723
15194 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 80.77158617973328

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 12675] [0, 8133] [0, 8134] [0, 12675] [0, 8134] [0, 8134] [2, 5356] [0, 8134] [0, 8133] [2, 5356] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 12.363130569458008 with beta sum per layer: [16.30809783935547, 38.719329833984375, 53.15589904785156, 3.4677698612213135, 0.0, 25.18455696105957]
alpha/beta optimization time: 1.5620746612548828
This batch time : update_bounds func: 1.8633	 prepare: 0.1045	 bound: 1.5627	 transfer: 0.1294	 finalize: 0.0655
Accumulated time: update_bounds func: 64.0540	 prepare: 3.1262	 bound: 53.8265	 transfer: 0.1294	 finalize: 2.6000
batch bounding time:  1.8641295433044434
Current worst splitting domains [lb, ub] (depth):
[-0.04812,   inf] (106), [-0.04714,   inf] (106), [-0.04611,   inf] (106), [-0.04589,   inf] (106), [-0.04574,   inf] (106), [-0.04556,   inf] (106), [-0.04550,   inf] (106), [-0.04543,   inf] (106), [-0.04530,   inf] (106), [-0.04514,   inf] (106), [-0.04508,   inf] (106), [-0.04500,   inf] (106), [-0.04471,   inf] (106), [-0.04452,   inf] (106), [-0.04450,   inf] (106), [-0.04447,   inf] (106), [-0.04441,   inf] (106), [-0.04438,   inf] (106), [-0.04427,   inf] (106), [-0.04425,   inf] (106), 
length of domains: 4080
Total time: 2.5783	 pickout: 0.1566	 decision: 0.2354	 get_bound: 1.8650	 add_domain: 0.3213
Current lb:-0.04811501502990723
15706 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 83.36383819580078

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 8134] [0, 8141] [1, 1268] [0, 8134] [0, 12838] [0, 12675] [0, 8133] [0, 12675] [0, 8133] [0, 8141] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 13.350625991821289 with beta sum per layer: [19.073795318603516, 41.105812072753906, 63.980987548828125, 6.7001633644104, 0.24752357602119446, 22.828384399414062]
alpha/beta optimization time: 1.5666992664337158
This batch time : update_bounds func: 1.9114	 prepare: 0.1055	 bound: 1.5673	 transfer: 0.1697	 finalize: 0.0677
Accumulated time: update_bounds func: 65.9654	 prepare: 3.2317	 bound: 55.3939	 transfer: 0.1697	 finalize: 2.6677
batch bounding time:  1.9120633602142334
Current worst splitting domains [lb, ub] (depth):
[-0.04811,   inf] (108), [-0.04714,   inf] (108), [-0.04708,   inf] (108), [-0.04597,   inf] (108), [-0.04589,   inf] (108), [-0.04574,   inf] (108), [-0.04556,   inf] (108), [-0.04550,   inf] (108), [-0.04543,   inf] (108), [-0.04530,   inf] (108), [-0.04514,   inf] (108), [-0.04508,   inf] (108), [-0.04500,   inf] (108), [-0.04486,   inf] (108), [-0.04473,   inf] (108), [-0.04471,   inf] (108), [-0.04452,   inf] (108), [-0.04449,   inf] (108), [-0.04447,   inf] (108), [-0.04440,   inf] (108), 
length of domains: 4275
Total time: 2.4134	 pickout: 0.1652	 decision: 0.2337	 get_bound: 1.9129	 add_domain: 0.1016
Current lb:-0.04811406135559082
16218 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 85.78915238380432

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 12838] [0, 12845] [0, 12838] [0, 8133] [0, 12838] [0, 8133] [0, 12838] [1, 1268] [1, 1199] [0, 12837] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 15.904458999633789 with beta sum per layer: [12.689724922180176, 44.69820785522461, 51.825965881347656, 8.660263061523438, 0.0, 18.40534782409668]
alpha/beta optimization time: 1.5608813762664795
This batch time : update_bounds func: 1.8792	 prepare: 0.1037	 bound: 1.5614	 transfer: 0.1506	 finalize: 0.0624
Accumulated time: update_bounds func: 67.8446	 prepare: 3.3354	 bound: 56.9553	 transfer: 0.1506	 finalize: 2.7301
batch bounding time:  1.8799104690551758
Current worst splitting domains [lb, ub] (depth):
[-0.04811,   inf] (110), [-0.04714,   inf] (110), [-0.04711,   inf] (110), [-0.04708,   inf] (110), [-0.04609,   inf] (110), [-0.04597,   inf] (110), [-0.04589,   inf] (110), [-0.04574,   inf] (110), [-0.04555,   inf] (110), [-0.04536,   inf] (110), [-0.04533,   inf] (110), [-0.04530,   inf] (110), [-0.04514,   inf] (110), [-0.04499,   inf] (110), [-0.04494,   inf] (110), [-0.04489,   inf] (110), [-0.04486,   inf] (110), [-0.04473,   inf] (110), [-0.04471,   inf] (110), [-0.04471,   inf] (110), 
length of domains: 4501
Total time: 2.3738	 pickout: 0.1518	 decision: 0.2327	 get_bound: 1.8808	 add_domain: 0.1085
Current lb:-0.048113107681274414
16730 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 88.17280602455139

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 8133] [0, 12837] [0, 8133] [0, 8133] [0, 8133] [0, 12837] [0, 12837] [0, 12837] [0, 8133] [0, 12837] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 14.967220306396484 with beta sum per layer: [13.2205810546875, 37.944461822509766, 43.14894485473633, 3.121800184249878, 0.0, 14.564188003540039]
alpha/beta optimization time: 1.56184983253479
This batch time : update_bounds func: 1.8777	 prepare: 0.1032	 bound: 1.5627	 transfer: 0.1500	 finalize: 0.0607
Accumulated time: update_bounds func: 69.7223	 prepare: 3.4387	 bound: 58.5180	 transfer: 0.1500	 finalize: 2.7908
batch bounding time:  1.8783724308013916
Current worst splitting domains [lb, ub] (depth):
[-0.04811,   inf] (112), [-0.04714,   inf] (112), [-0.04711,   inf] (112), [-0.04708,   inf] (112), [-0.04686,   inf] (112), [-0.04609,   inf] (112), [-0.04597,   inf] (112), [-0.04591,   inf] (112), [-0.04589,   inf] (112), [-0.04585,   inf] (112), [-0.04583,   inf] (112), [-0.04574,   inf] (112), [-0.04555,   inf] (112), [-0.04536,   inf] (112), [-0.04533,   inf] (112), [-0.04530,   inf] (112), [-0.04514,   inf] (112), [-0.04499,   inf] (112), [-0.04494,   inf] (112), [-0.04489,   inf] (112), 
length of domains: 4722
Total time: 2.5402	 pickout: 0.1506	 decision: 0.4019	 get_bound: 1.8792	 add_domain: 0.1085
Current lb:-0.048113107681274414
17242 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 90.72370433807373

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 8141] [1, 1199] [0, 8141] [0, 8141] [0, 8083] [0, 8141] [0, 12838] [0, 8134] [0, 8141] [0, 8083] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 9.24679946899414 with beta sum per layer: [18.46915054321289, 40.608028411865234, 57.444847106933594, 1.5376508235931396, 0.0, 11.575526237487793]
alpha/beta optimization time: 1.5648643970489502
This batch time : update_bounds func: 1.8851	 prepare: 0.1026	 bound: 1.5654	 transfer: 0.1535	 finalize: 0.0624
Accumulated time: update_bounds func: 71.6074	 prepare: 3.5413	 bound: 60.0834	 transfer: 0.1535	 finalize: 2.8532
batch bounding time:  1.8858153820037842
Current worst splitting domains [lb, ub] (depth):
[-0.04811,   inf] (114), [-0.04711,   inf] (114), [-0.04708,   inf] (114), [-0.04704,   inf] (114), [-0.04686,   inf] (114), [-0.04627,   inf] (114), [-0.04609,   inf] (114), [-0.04597,   inf] (114), [-0.04591,   inf] (114), [-0.04589,   inf] (114), [-0.04585,   inf] (114), [-0.04582,   inf] (114), [-0.04561,   inf] (114), [-0.04555,   inf] (114), [-0.04536,   inf] (114), [-0.04533,   inf] (114), [-0.04527,   inf] (114), [-0.04524,   inf] (114), [-0.04516,   inf] (114), [-0.04504,   inf] (114), 
length of domains: 4925
Total time: 2.3861	 pickout: 0.1612	 decision: 0.2323	 get_bound: 1.8867	 add_domain: 0.1059
Current lb:-0.04811263084411621
17754 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 93.12072706222534

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 12845] [0, 12845] [0, 12845] [2, 5383] [0, 12787] [0, 12787] [0, 12845] [1, 1199] [0, 12838] [0, 12845] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 13.840197563171387 with beta sum per layer: [13.198665618896484, 57.463462829589844, 38.037315368652344, 1.7323524951934814, 0.0, 9.860502243041992]
alpha/beta optimization time: 1.5620176792144775
This batch time : update_bounds func: 2.0483	 prepare: 0.1002	 bound: 1.5625	 transfer: 0.1500	 finalize: 0.2344
Accumulated time: update_bounds func: 73.6557	 prepare: 3.6415	 bound: 61.6459	 transfer: 0.1500	 finalize: 3.0875
batch bounding time:  2.0489985942840576
Current worst splitting domains [lb, ub] (depth):
[-0.04811,   inf] (116), [-0.04710,   inf] (116), [-0.04708,   inf] (116), [-0.04686,   inf] (116), [-0.04674,   inf] (116), [-0.04627,   inf] (116), [-0.04618,   inf] (116), [-0.04609,   inf] (116), [-0.04591,   inf] (116), [-0.04589,   inf] (116), [-0.04587,   inf] (116), [-0.04585,   inf] (116), [-0.04582,   inf] (116), [-0.04551,   inf] (116), [-0.04546,   inf] (116), [-0.04535,   inf] (116), [-0.04533,   inf] (116), [-0.04533,   inf] (116), [-0.04527,   inf] (116), [-0.04526,   inf] (116), 
length of domains: 5144
Total time: 2.5428	 pickout: 0.1453	 decision: 0.2317	 get_bound: 2.0499	 add_domain: 0.1159
Current lb:-0.04811239242553711
18266 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 95.67827367782593

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 12837] [0, 12837] [0, 12837] [0, 8141] [0, 8134] [1, 4363] [1, 4363] [0, 12837] [1, 1199] [1, 1199] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 17.3609676361084 with beta sum per layer: [9.559660911560059, 39.45103073120117, 25.551822662353516, 0.0, 0.0, 6.456063270568848]
alpha/beta optimization time: 1.5625333786010742
This batch time : update_bounds func: 1.8596	 prepare: 0.1011	 bound: 1.5631	 transfer: 0.1287	 finalize: 0.0655
Accumulated time: update_bounds func: 75.5153	 prepare: 3.7426	 bound: 63.2090	 transfer: 0.1287	 finalize: 3.1530
batch bounding time:  1.8604793548583984
Current worst splitting domains [lb, ub] (depth):
[-0.04811,   inf] (118), [-0.04710,   inf] (118), [-0.04708,   inf] (118), [-0.04687,   inf] (118), [-0.04685,   inf] (118), [-0.04674,   inf] (118), [-0.04626,   inf] (118), [-0.04609,   inf] (118), [-0.04608,   inf] (118), [-0.04587,   inf] (118), [-0.04586,   inf] (118), [-0.04585,   inf] (118), [-0.04584,   inf] (118), [-0.04582,   inf] (118), [-0.04581,   inf] (118), [-0.04579,   inf] (118), [-0.04571,   inf] (118), [-0.04551,   inf] (118), [-0.04534,   inf] (118), [-0.04533,   inf] (118), 
length of domains: 5366
Total time: 2.4004	 pickout: 0.1860	 decision: 0.2317	 get_bound: 1.8615	 add_domain: 0.1213
Current lb:-0.0481107234954834
18778 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 98.0943820476532

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [1, 1199] [1, 1199] [1, 1199] [0, 8083] [0, 12845] [0, 12838] [1, 1199] [1, 1199] [1, 1199] [1, 4332] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 15.775103569030762 with beta sum per layer: [12.278096199035645, 24.562156677246094, 19.1523380279541, 0.0, 0.0, 6.5746564865112305]
alpha/beta optimization time: 1.5622448921203613
This batch time : update_bounds func: 1.8761	 prepare: 0.1001	 bound: 1.5628	 transfer: 0.1511	 finalize: 0.0608
Accumulated time: update_bounds func: 77.3914	 prepare: 3.8427	 bound: 64.7719	 transfer: 0.1511	 finalize: 3.2137
batch bounding time:  1.8768274784088135
Current worst splitting domains [lb, ub] (depth):
[-0.04801,   inf] (120), [-0.04701,   inf] (120), [-0.04698,   inf] (120), [-0.04687,   inf] (120), [-0.04685,   inf] (120), [-0.04674,   inf] (120), [-0.04628,   inf] (120), [-0.04616,   inf] (120), [-0.04599,   inf] (120), [-0.04598,   inf] (120), [-0.04587,   inf] (120), [-0.04586,   inf] (120), [-0.04585,   inf] (120), [-0.04584,   inf] (120), [-0.04582,   inf] (120), [-0.04581,   inf] (120), [-0.04579,   inf] (120), [-0.04574,   inf] (120), [-0.04571,   inf] (120), [-0.04551,   inf] (120), 
length of domains: 5584
Total time: 2.3745	 pickout: 0.1488	 decision: 0.2328	 get_bound: 1.8777	 add_domain: 0.1153
Current lb:-0.04801321029663086
19290 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 100.48115801811218

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [1, 1200] [1, 1200] [1, 1200] [0, 12787] [1, 1199] [1, 1200] [0, 12787] [0, 8141] [1, 1200] [0, 8168] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 12.614133834838867 with beta sum per layer: [13.82214641571045, 22.96778678894043, 28.225479125976562, 0.0, 0.0, 7.887104511260986]
alpha/beta optimization time: 1.56300950050354
This batch time : update_bounds func: 1.8811	 prepare: 0.1006	 bound: 1.5636	 transfer: 0.1525	 finalize: 0.0632
Accumulated time: update_bounds func: 79.2725	 prepare: 3.9434	 bound: 66.3354	 transfer: 0.1525	 finalize: 3.2770
batch bounding time:  1.8819530010223389
Current worst splitting domains [lb, ub] (depth):
[-0.04801,   inf] (122), [-0.04701,   inf] (122), [-0.04698,   inf] (122), [-0.04687,   inf] (122), [-0.04683,   inf] (122), [-0.04676,   inf] (122), [-0.04674,   inf] (122), [-0.04628,   inf] (122), [-0.04616,   inf] (122), [-0.04599,   inf] (122), [-0.04598,   inf] (122), [-0.04595,   inf] (122), [-0.04594,   inf] (122), [-0.04592,   inf] (122), [-0.04587,   inf] (122), [-0.04586,   inf] (122), [-0.04584,   inf] (122), [-0.04575,   inf] (122), [-0.04574,   inf] (122), [-0.04572,   inf] (122), 
length of domains: 5796
Total time: 2.6205	 pickout: 0.1653	 decision: 0.4582	 get_bound: 1.8829	 add_domain: 0.1141
Current lb:-0.04801321029663086
19802 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 103.11312413215637

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 8168] [0, 8168] [0, 8168] [1, 1199] [0, 8083] [0, 12837] [0, 8168] [1, 4363] [0, 12845] [0, 8168] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 15.327005386352539 with beta sum per layer: [10.239500999450684, 26.392715454101562, 23.914875030517578, 0.0, 0.0, 11.353544235229492]
alpha/beta optimization time: 1.5604610443115234
This batch time : update_bounds func: 1.8730	 prepare: 0.1003	 bound: 1.5610	 transfer: 0.1497	 finalize: 0.0608
Accumulated time: update_bounds func: 81.1455	 prepare: 4.0437	 bound: 67.8964	 transfer: 0.1497	 finalize: 3.3378
batch bounding time:  1.873687982559204
Current worst splitting domains [lb, ub] (depth):
[-0.04801,   inf] (124), [-0.04701,   inf] (124), [-0.04698,   inf] (124), [-0.04677,   inf] (124), [-0.04676,   inf] (124), [-0.04674,   inf] (124), [-0.04641,   inf] (124), [-0.04627,   inf] (124), [-0.04616,   inf] (124), [-0.04599,   inf] (124), [-0.04598,   inf] (124), [-0.04594,   inf] (124), [-0.04592,   inf] (124), [-0.04587,   inf] (124), [-0.04587,   inf] (124), [-0.04576,   inf] (124), [-0.04575,   inf] (124), [-0.04574,   inf] (124), [-0.04574,   inf] (124), [-0.04572,   inf] (124), 
length of domains: 6006
Total time: 2.3659	 pickout: 0.1457	 decision: 0.2312	 get_bound: 1.8745	 add_domain: 0.1145
Current lb:-0.048012733459472656
20314 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 105.49040985107422

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [1, 4332] [1, 4332] [1, 4332] [1, 1200] [1, 1200] [1, 4332] [1, 4332] [1, 1199] [0, 12837] [1, 4332] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 15.177332878112793 with beta sum per layer: [6.753958702087402, 29.80927276611328, 27.335113525390625, 0.0, 0.0, 9.1588134765625]
alpha/beta optimization time: 1.5598299503326416
This batch time : update_bounds func: 1.8730	 prepare: 0.1000	 bound: 1.5604	 transfer: 0.1509	 finalize: 0.0605
Accumulated time: update_bounds func: 83.0185	 prepare: 4.1438	 bound: 69.4568	 transfer: 0.1509	 finalize: 3.3983
batch bounding time:  1.8737144470214844
Current worst splitting domains [lb, ub] (depth):
[-0.04801,   inf] (126), [-0.04700,   inf] (126), [-0.04698,   inf] (126), [-0.04677,   inf] (126), [-0.04676,   inf] (126), [-0.04674,   inf] (126), [-0.04641,   inf] (126), [-0.04618,   inf] (126), [-0.04616,   inf] (126), [-0.04599,   inf] (126), [-0.04598,   inf] (126), [-0.04594,   inf] (126), [-0.04592,   inf] (126), [-0.04587,   inf] (126), [-0.04578,   inf] (126), [-0.04576,   inf] (126), [-0.04575,   inf] (126), [-0.04574,   inf] (126), [-0.04573,   inf] (126), [-0.04572,   inf] (126), 
length of domains: 6215
Total time: 2.5872	 pickout: 0.1484	 decision: 0.2320	 get_bound: 1.8746	 add_domain: 0.3323
Current lb:-0.04801154136657715
20826 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 108.09017705917358

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 12872] [0, 12872] [0, 12872] [0, 8168] [0, 8168] [0, 12872] [0, 12872] [1, 1200] [1, 1200] [0, 12872] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 19.892255783081055 with beta sum per layer: [4.72697114944458, 23.61298942565918, 21.791961669921875, 0.0, 0.0, 5.708742141723633]
alpha/beta optimization time: 1.5492887496948242
This batch time : update_bounds func: 1.8613	 prepare: 0.1000	 bound: 1.5498	 transfer: 0.1498	 finalize: 0.0604
Accumulated time: update_bounds func: 84.8798	 prepare: 4.2437	 bound: 71.0066	 transfer: 0.1498	 finalize: 3.4587
batch bounding time:  1.8619518280029297
Current worst splitting domains [lb, ub] (depth):
[-0.04801,   inf] (128), [-0.04700,   inf] (128), [-0.04698,   inf] (128), [-0.04677,   inf] (128), [-0.04676,   inf] (128), [-0.04674,   inf] (128), [-0.04655,   inf] (128), [-0.04641,   inf] (128), [-0.04618,   inf] (128), [-0.04616,   inf] (128), [-0.04599,   inf] (128), [-0.04598,   inf] (128), [-0.04594,   inf] (128), [-0.04592,   inf] (128), [-0.04587,   inf] (128), [-0.04578,   inf] (128), [-0.04576,   inf] (128), [-0.04575,   inf] (128), [-0.04574,   inf] (128), [-0.04573,   inf] (128), 
length of domains: 6449
Total time: 2.3770	 pickout: 0.1591	 decision: 0.2318	 get_bound: 1.8628	 add_domain: 0.1233
Current lb:-0.04801130294799805
21338 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 110.47765278816223

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 8083] [0, 8083] [0, 8083] [1, 4332] [1, 4332] [0, 8083] [0, 8083] [0, 8083] [0, 8168] [0, 8168] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 19.371450424194336 with beta sum per layer: [5.1641082763671875, 17.14664077758789, 20.08902931213379, 0.0, 0.0, 4.417215347290039]
alpha/beta optimization time: 1.5595614910125732
This batch time : update_bounds func: 1.8745	 prepare: 0.1001	 bound: 1.5601	 transfer: 0.1524	 finalize: 0.0607
Accumulated time: update_bounds func: 86.7543	 prepare: 4.3438	 bound: 72.5667	 transfer: 0.1524	 finalize: 3.5194
batch bounding time:  1.8751575946807861
Current worst splitting domains [lb, ub] (depth):
[-0.04801,   inf] (130), [-0.04718,   inf] (130), [-0.04700,   inf] (130), [-0.04698,   inf] (130), [-0.04677,   inf] (130), [-0.04675,   inf] (130), [-0.04674,   inf] (130), [-0.04655,   inf] (130), [-0.04642,   inf] (130), [-0.04641,   inf] (130), [-0.04639,   inf] (130), [-0.04617,   inf] (130), [-0.04616,   inf] (130), [-0.04615,   inf] (130), [-0.04598,   inf] (130), [-0.04598,   inf] (130), [-0.04596,   inf] (130), [-0.04594,   inf] (130), [-0.04591,   inf] (130), [-0.04586,   inf] (130), 
length of domains: 6689
Total time: 2.3791	 pickout: 0.1447	 decision: 0.2319	 get_bound: 1.8760	 add_domain: 0.1265
Current lb:-0.04801011085510254
21850 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 112.86807656288147

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 12787] [1, 4363] [0, 12787] [0, 12787] [0, 12872] [0, 12872] [0, 12787] [0, 12787] [1, 4363] [0, 12787] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 14.060174942016602 with beta sum per layer: [18.026853561401367, 26.49247169494629, 30.72992706298828, 0.0, 0.0, 4.377496242523193]
alpha/beta optimization time: 1.5622532367706299
This batch time : update_bounds func: 1.8754	 prepare: 0.0999	 bound: 1.5628	 transfer: 0.1506	 finalize: 0.0609
Accumulated time: update_bounds func: 88.6296	 prepare: 4.4437	 bound: 74.1295	 transfer: 0.1506	 finalize: 3.5803
batch bounding time:  1.8760442733764648
Current worst splitting domains [lb, ub] (depth):
[-0.04801,   inf] (132), [-0.04710,   inf] (132), [-0.04700,   inf] (132), [-0.04698,   inf] (132), [-0.04677,   inf] (132), [-0.04675,   inf] (132), [-0.04674,   inf] (132), [-0.04655,   inf] (132), [-0.04648,   inf] (132), [-0.04641,   inf] (132), [-0.04641,   inf] (132), [-0.04638,   inf] (132), [-0.04624,   inf] (132), [-0.04617,   inf] (132), [-0.04616,   inf] (132), [-0.04614,   inf] (132), [-0.04605,   inf] (132), [-0.04598,   inf] (132), [-0.04598,   inf] (132), [-0.04595,   inf] (132), 
length of domains: 6882
Total time: 2.6106	 pickout: 0.1463	 decision: 0.2315	 get_bound: 1.8769	 add_domain: 0.3559
Current lb:-0.04800868034362793
22362 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 115.49120116233826

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 8077] [0, 8077] [0, 8077] [0, 8077] [0, 12734] [0, 12734] [0, 8077] [0, 8077] [1, 4363] [0, 12787] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 14.003143310546875 with beta sum per layer: [24.747596740722656, 20.262521743774414, 39.84303283691406, 0.0, 0.0, 5.248283386230469]
alpha/beta optimization time: 1.564666509628296
This batch time : update_bounds func: 1.8794	 prepare: 0.1029	 bound: 1.5652	 transfer: 0.1503	 finalize: 0.0598
Accumulated time: update_bounds func: 90.5090	 prepare: 4.5466	 bound: 75.6948	 transfer: 0.1503	 finalize: 3.6401
batch bounding time:  1.880096197128296
Current worst splitting domains [lb, ub] (depth):
[-0.04801,   inf] (134), [-0.04755,   inf] (134), [-0.04710,   inf] (134), [-0.04700,   inf] (134), [-0.04698,   inf] (134), [-0.04677,   inf] (134), [-0.04675,   inf] (134), [-0.04674,   inf] (134), [-0.04665,   inf] (134), [-0.04655,   inf] (134), [-0.04655,   inf] (134), [-0.04652,   inf] (134), [-0.04647,   inf] (134), [-0.04641,   inf] (134), [-0.04641,   inf] (134), [-0.04638,   inf] (134), [-0.04636,   inf] (134), [-0.04635,   inf] (134), [-0.04628,   inf] (134), [-0.04623,   inf] (134), 
length of domains: 7072
Total time: 2.3731	 pickout: 0.1451	 decision: 0.2310	 get_bound: 1.8810	 add_domain: 0.1160
Current lb:-0.04800868034362793
22874 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 117.8766279220581

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [1, 4363] [1, 4363] [0, 12781] [1, 4363] [1, 4363] [1, 4351] [1, 4351] [1, 4363] [0, 12781] [1, 4363] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 14.883085250854492 with beta sum per layer: [15.141287803649902, 25.64889144897461, 45.69213104248047, 0.0, 0.0, 3.785581111907959]
alpha/beta optimization time: 1.5592751502990723
This batch time : update_bounds func: 1.8722	 prepare: 0.1007	 bound: 1.5598	 transfer: 0.1504	 finalize: 0.0600
Accumulated time: update_bounds func: 92.3812	 prepare: 4.6473	 bound: 77.2546	 transfer: 0.1504	 finalize: 3.7001
batch bounding time:  1.872950792312622
Current worst splitting domains [lb, ub] (depth):
[-0.04801,   inf] (136), [-0.04755,   inf] (136), [-0.04710,   inf] (136), [-0.04700,   inf] (136), [-0.04698,   inf] (136), [-0.04673,   inf] (136), [-0.04666,   inf] (136), [-0.04665,   inf] (136), [-0.04655,   inf] (136), [-0.04655,   inf] (136), [-0.04653,   inf] (136), [-0.04652,   inf] (136), [-0.04652,   inf] (136), [-0.04647,   inf] (136), [-0.04644,   inf] (136), [-0.04643,   inf] (136), [-0.04641,   inf] (136), [-0.04641,   inf] (136), [-0.04638,   inf] (136), [-0.04628,   inf] (136), 
length of domains: 7255
Total time: 2.3699	 pickout: 0.1486	 decision: 0.2319	 get_bound: 1.8738	 add_domain: 0.1156
Current lb:-0.04800820350646973
23386 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 120.25889730453491

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 12781] [0, 12781] [0, 8027] [0, 12781] [0, 12781] [0, 12781] [0, 8027] [0, 8027] [0, 12781] [0, 12781] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 22.0032958984375 with beta sum per layer: [6.708202838897705, 13.434189796447754, 8.018375396728516, 0.0, 0.0, 1.752429485321045]
alpha/beta optimization time: 1.5567209720611572
This batch time : update_bounds func: 1.8680	 prepare: 0.1013	 bound: 1.5573	 transfer: 0.1490	 finalize: 0.0593
Accumulated time: update_bounds func: 94.2493	 prepare: 4.7486	 bound: 78.8119	 transfer: 0.1490	 finalize: 3.7594
batch bounding time:  1.868718147277832
Current worst splitting domains [lb, ub] (depth):
[-0.04801,   inf] (138), [-0.04756,   inf] (138), [-0.04755,   inf] (138), [-0.04711,   inf] (138), [-0.04710,   inf] (138), [-0.04700,   inf] (138), [-0.04698,   inf] (138), [-0.04673,   inf] (138), [-0.04666,   inf] (138), [-0.04665,   inf] (138), [-0.04655,   inf] (138), [-0.04655,   inf] (138), [-0.04655,   inf] (138), [-0.04653,   inf] (138), [-0.04653,   inf] (138), [-0.04652,   inf] (138), [-0.04652,   inf] (138), [-0.04648,   inf] (138), [-0.04647,   inf] (138), [-0.04644,   inf] (138), 
length of domains: 7498
Total time: 2.3826	 pickout: 0.1474	 decision: 0.2324	 get_bound: 1.8696	 add_domain: 0.1332
Current lb:-0.048007965087890625
23898 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 122.6526391506195

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 8027] [0, 8027] [0, 8027] [0, 8027] [0, 12734] [0, 8027] [0, 8027] [0, 8027] [0, 12734] [0, 12734] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 23.11082649230957 with beta sum per layer: [5.5811767578125, 17.034788131713867, 1.478458046913147, 0.0, 0.0, 0.4966380000114441]
alpha/beta optimization time: 1.4832797050476074
This batch time : update_bounds func: 1.8002	 prepare: 0.1026	 bound: 1.4838	 transfer: 0.1511	 finalize: 0.0615
Accumulated time: update_bounds func: 96.0495	 prepare: 4.8513	 bound: 80.2957	 transfer: 0.1511	 finalize: 3.8209
batch bounding time:  1.8009302616119385
Current worst splitting domains [lb, ub] (depth):
[-0.04801,   inf] (140), [-0.04756,   inf] (140), [-0.04755,   inf] (140), [-0.04740,   inf] (140), [-0.04711,   inf] (140), [-0.04710,   inf] (140), [-0.04700,   inf] (140), [-0.04698,   inf] (140), [-0.04696,   inf] (140), [-0.04695,   inf] (140), [-0.04673,   inf] (140), [-0.04670,   inf] (140), [-0.04666,   inf] (140), [-0.04665,   inf] (140), [-0.04655,   inf] (140), [-0.04655,   inf] (140), [-0.04655,   inf] (140), [-0.04653,   inf] (140), [-0.04653,   inf] (140), [-0.04653,   inf] (140), 
length of domains: 7754
Total time: 2.5703	 pickout: 0.1461	 decision: 0.4855	 get_bound: 1.8018	 add_domain: 0.1370
Current lb:-0.048007965087890625
24410 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 125.23541378974915

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 12734] [0, 12734] [0, 12734] [0, 12734] [0, 12734] [0, 12731] [0, 12734] [0, 12734] [0, 12734] [0, 12734] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 20.951610565185547 with beta sum per layer: [9.012842178344727, 18.62413787841797, 16.604785919189453, 0.0, 0.0, 0.7673053741455078]
alpha/beta optimization time: 1.5634980201721191
This batch time : update_bounds func: 1.8831	 prepare: 0.1063	 bound: 1.5641	 transfer: 0.1504	 finalize: 0.0608
Accumulated time: update_bounds func: 97.9325	 prepare: 4.9575	 bound: 81.8598	 transfer: 0.1504	 finalize: 3.8817
batch bounding time:  1.8837642669677734
Current worst splitting domains [lb, ub] (depth):
[-0.04801,   inf] (142), [-0.04760,   inf] (142), [-0.04756,   inf] (142), [-0.04755,   inf] (142), [-0.04740,   inf] (142), [-0.04716,   inf] (142), [-0.04715,   inf] (142), [-0.04711,   inf] (142), [-0.04710,   inf] (142), [-0.04700,   inf] (142), [-0.04700,   inf] (142), [-0.04697,   inf] (142), [-0.04696,   inf] (142), [-0.04695,   inf] (142), [-0.04673,   inf] (142), [-0.04670,   inf] (142), [-0.04670,   inf] (142), [-0.04666,   inf] (142), [-0.04665,   inf] (142), [-0.04660,   inf] (142), 
length of domains: 7983
Total time: 2.4056	 pickout: 0.1538	 decision: 0.2354	 get_bound: 1.8846	 add_domain: 0.1317
Current lb:-0.04800677299499512
24922 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 127.65308213233948

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 12731] [0, 12731] [0, 12731] [0, 12731] [0, 12731] [0, 12731] [0, 12731] [0, 12731] [1, 4351] [0, 12731] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 22.347667694091797 with beta sum per layer: [5.29737663269043, 18.868267059326172, 3.2111220359802246, 0.5472052693367004, 0.0, 0.026965845376253128]
alpha/beta optimization time: 1.5553584098815918
This batch time : update_bounds func: 1.8695	 prepare: 0.1032	 bound: 1.5559	 transfer: 0.1495	 finalize: 0.0598
Accumulated time: update_bounds func: 99.8020	 prepare: 5.0607	 bound: 83.4157	 transfer: 0.1495	 finalize: 3.9416
batch bounding time:  1.8702640533447266
Current worst splitting domains [lb, ub] (depth):
[-0.04801,   inf] (144), [-0.04760,   inf] (144), [-0.04756,   inf] (144), [-0.04755,   inf] (144), [-0.04745,   inf] (144), [-0.04740,   inf] (144), [-0.04716,   inf] (144), [-0.04715,   inf] (144), [-0.04711,   inf] (144), [-0.04705,   inf] (144), [-0.04701,   inf] (144), [-0.04700,   inf] (144), [-0.04700,   inf] (144), [-0.04700,   inf] (144), [-0.04697,   inf] (144), [-0.04696,   inf] (144), [-0.04695,   inf] (144), [-0.04687,   inf] (144), [-0.04685,   inf] (144), [-0.04677,   inf] (144), 
length of domains: 8234
Total time: 2.4041	 pickout: 0.1596	 decision: 0.2343	 get_bound: 1.8711	 add_domain: 0.1392
Current lb:-0.04800677299499512
25434 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 130.06894373893738

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [1, 4351] [1, 4351] [1, 4351] [1, 4351] [1, 4351] [1, 4351] [1, 4351] [1, 4351] [1, 4351] [1, 4351] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 20.97028923034668 with beta sum per layer: [10.21273422241211, 38.739322662353516, 13.868058204650879, 0.004106520675122738, 0.0, 0.03732848912477493]
alpha/beta optimization time: 1.5359447002410889
This batch time : update_bounds func: 2.1395	 prepare: 0.1032	 bound: 1.5365	 transfer: 0.1537	 finalize: 0.3449
Accumulated time: update_bounds func: 101.9415	 prepare: 5.1638	 bound: 84.9522	 transfer: 0.1537	 finalize: 4.2865
batch bounding time:  2.140241861343384
Current worst splitting domains [lb, ub] (depth):
[-0.04778,   inf] (146), [-0.04768,   inf] (146), [-0.04739,   inf] (146), [-0.04733,   inf] (146), [-0.04732,   inf] (146), [-0.04725,   inf] (146), [-0.04723,   inf] (146), [-0.04722,   inf] (146), [-0.04722,   inf] (146), [-0.04717,   inf] (146), [-0.04713,   inf] (146), [-0.04708,   inf] (146), [-0.04694,   inf] (146), [-0.04694,   inf] (146), [-0.04688,   inf] (146), [-0.04687,   inf] (146), [-0.04684,   inf] (146), [-0.04680,   inf] (146), [-0.04680,   inf] (146), [-0.04679,   inf] (146), 
length of domains: 8465
Total time: 2.6533	 pickout: 0.1464	 decision: 0.2308	 get_bound: 2.1411	 add_domain: 0.1350
Current lb:-0.0477752685546875
25946 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 132.73370480537415

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 8030] [0, 8030] [0, 8030] [0, 8030] [0, 8030] [0, 8030] [0, 8030] [0, 8030] [0, 8030] [0, 8030] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 22.683963775634766 with beta sum per layer: [4.076578617095947, 20.475933074951172, 4.017922401428223, 0.10570929944515228, 0.0, 0.10558056831359863]
alpha/beta optimization time: 1.5362350940704346
This batch time : update_bounds func: 1.8522	 prepare: 0.1036	 bound: 1.5368	 transfer: 0.1496	 finalize: 0.0609
Accumulated time: update_bounds func: 103.7937	 prepare: 5.2674	 bound: 86.4890	 transfer: 0.1496	 finalize: 4.3473
batch bounding time:  1.8528828620910645
Current worst splitting domains [lb, ub] (depth):
[-0.04777,   inf] (148), [-0.04768,   inf] (148), [-0.04750,   inf] (148), [-0.04739,   inf] (148), [-0.04733,   inf] (148), [-0.04733,   inf] (148), [-0.04732,   inf] (148), [-0.04725,   inf] (148), [-0.04723,   inf] (148), [-0.04722,   inf] (148), [-0.04722,   inf] (148), [-0.04717,   inf] (148), [-0.04712,   inf] (148), [-0.04711,   inf] (148), [-0.04707,   inf] (148), [-0.04705,   inf] (148), [-0.04704,   inf] (148), [-0.04695,   inf] (148), [-0.04694,   inf] (148), [-0.04694,   inf] (148), 
length of domains: 8709
Total time: 2.3854	 pickout: 0.1596	 decision: 0.2327	 get_bound: 1.8537	 add_domain: 0.1394
Current lb:-0.04777359962463379
26458 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 135.13089966773987

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [1, 1215] [0, 13197] [1, 1215] [1, 1215] [1, 1215] [0, 13197] [1, 1215] [0, 13197] [0, 13197] [0, 13197] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 22.181001663208008 with beta sum per layer: [3.7496721744537354, 20.7825927734375, 5.433481216430664, 0.8875270485877991, 0.0, 0.2684687077999115]
alpha/beta optimization time: 1.5496282577514648
This batch time : update_bounds func: 1.8648	 prepare: 0.1031	 bound: 1.5502	 transfer: 0.1499	 finalize: 0.0605
Accumulated time: update_bounds func: 105.6585	 prepare: 5.3705	 bound: 88.0392	 transfer: 0.1499	 finalize: 4.4078
batch bounding time:  1.8655540943145752
Current worst splitting domains [lb, ub] (depth):
[-0.04770,   inf] (150), [-0.04768,   inf] (150), [-0.04745,   inf] (150), [-0.04742,   inf] (150), [-0.04734,   inf] (150), [-0.04732,   inf] (150), [-0.04726,   inf] (150), [-0.04726,   inf] (150), [-0.04725,   inf] (150), [-0.04725,   inf] (150), [-0.04723,   inf] (150), [-0.04722,   inf] (150), [-0.04715,   inf] (150), [-0.04712,   inf] (150), [-0.04710,   inf] (150), [-0.04708,   inf] (150), [-0.04707,   inf] (150), [-0.04706,   inf] (150), [-0.04700,   inf] (150), [-0.04699,   inf] (150), 
length of domains: 8956
Total time: 2.3860	 pickout: 0.1456	 decision: 0.2319	 get_bound: 1.8664	 add_domain: 0.1421
Current lb:-0.04770207405090332
26970 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 137.52840971946716

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 13197] [1, 1215] [0, 13197] [1, 1215] [0, 13197] [1, 1215] [0, 13197] [0, 13197] [0, 13197] [1, 1215] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 23.392841339111328 with beta sum per layer: [1.3900268077850342, 9.388888359069824, 1.2230737209320068, 0.3298768997192383, 0.0, 0.09549211710691452]
alpha/beta optimization time: 1.5547285079956055
This batch time : update_bounds func: 1.8704	 prepare: 0.1030	 bound: 1.5553	 transfer: 0.1496	 finalize: 0.0613
Accumulated time: update_bounds func: 107.5289	 prepare: 5.4736	 bound: 89.5945	 transfer: 0.1496	 finalize: 4.4691
batch bounding time:  1.871201753616333
Current worst splitting domains [lb, ub] (depth):
[-0.04770,   inf] (152), [-0.04760,   inf] (152), [-0.04745,   inf] (152), [-0.04744,   inf] (152), [-0.04734,   inf] (152), [-0.04734,   inf] (152), [-0.04727,   inf] (152), [-0.04726,   inf] (152), [-0.04726,   inf] (152), [-0.04725,   inf] (152), [-0.04719,   inf] (152), [-0.04719,   inf] (152), [-0.04716,   inf] (152), [-0.04715,   inf] (152), [-0.04715,   inf] (152), [-0.04710,   inf] (152), [-0.04708,   inf] (152), [-0.04707,   inf] (152), [-0.04705,   inf] (152), [-0.04701,   inf] (152), 
length of domains: 9210
Total time: 2.3959	 pickout: 0.1463	 decision: 0.2319	 get_bound: 1.8721	 add_domain: 0.1457
Current lb:-0.04770207405090332
27482 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 139.93627095222473

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 8493] [0, 13225] [0, 8493] [0, 8493] [0, 13225] [0, 8493] [0, 13225] [0, 8493] [0, 8493] [0, 8493] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 23.346242904663086 with beta sum per layer: [2.342167854309082, 9.587037086486816, 2.1194732189178467, 0.17023757100105286, 0.0, 0.03541431203484535]
alpha/beta optimization time: 1.5201478004455566
This batch time : update_bounds func: 1.8345	 prepare: 0.1019	 bound: 1.5207	 transfer: 0.1503	 finalize: 0.0603
Accumulated time: update_bounds func: 109.3635	 prepare: 5.5755	 bound: 91.1152	 transfer: 0.1503	 finalize: 4.5294
batch bounding time:  1.8352501392364502
Current worst splitting domains [lb, ub] (depth):
[-0.04770,   inf] (154), [-0.04751,   inf] (154), [-0.04744,   inf] (154), [-0.04744,   inf] (154), [-0.04744,   inf] (154), [-0.04742,   inf] (154), [-0.04734,   inf] (154), [-0.04726,   inf] (154), [-0.04725,   inf] (154), [-0.04725,   inf] (154), [-0.04725,   inf] (154), [-0.04725,   inf] (154), [-0.04719,   inf] (154), [-0.04718,   inf] (154), [-0.04718,   inf] (154), [-0.04716,   inf] (154), [-0.04715,   inf] (154), [-0.04714,   inf] (154), [-0.04710,   inf] (154), [-0.04710,   inf] (154), 
length of domains: 9462
Total time: 2.6804	 pickout: 0.1531	 decision: 0.5450	 get_bound: 1.8361	 add_domain: 0.1461
Current lb:-0.04770064353942871
27994 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 142.62794995307922

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 13225] [0, 13225] [0, 13225] [0, 13225] [0, 8493] [0, 8493] [0, 13225] [0, 13225] [0, 13225] [0, 13225] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 23.450069427490234 with beta sum per layer: [1.4058113098144531, 6.619200229644775, 0.8148968815803528, 0.0, 0.0, 0.0]
alpha/beta optimization time: 1.5272536277770996
This batch time : update_bounds func: 1.8458	 prepare: 0.1016	 bound: 1.5278	 transfer: 0.1537	 finalize: 0.0612
Accumulated time: update_bounds func: 111.2093	 prepare: 5.6771	 bound: 92.6430	 transfer: 0.1537	 finalize: 4.5906
batch bounding time:  1.8465075492858887
Current worst splitting domains [lb, ub] (depth):
[-0.04753,   inf] (156), [-0.04751,   inf] (156), [-0.04743,   inf] (156), [-0.04742,   inf] (156), [-0.04734,   inf] (156), [-0.04732,   inf] (156), [-0.04728,   inf] (156), [-0.04727,   inf] (156), [-0.04726,   inf] (156), [-0.04725,   inf] (156), [-0.04724,   inf] (156), [-0.04723,   inf] (156), [-0.04717,   inf] (156), [-0.04717,   inf] (156), [-0.04716,   inf] (156), [-0.04715,   inf] (156), [-0.04710,   inf] (156), [-0.04709,   inf] (156), [-0.04709,   inf] (156), [-0.04709,   inf] (156), 
length of domains: 9713
Total time: 2.4121	 pickout: 0.1598	 decision: 0.2380	 get_bound: 1.8474	 add_domain: 0.1670
Current lb:-0.04753232002258301
28506 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 145.05160188674927

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 12889] [0, 12889] [0, 12678] [0, 12678] [0, 12889] [0, 12889] [0, 12889] [0, 12889] [0, 12889] [0, 12889] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 23.7220401763916 with beta sum per layer: [0.6762612462043762, 0.20671172440052032, 0.7797424793243408, 0.05603604018688202, 0.0, 0.051738571375608444]
alpha/beta optimization time: 1.5188207626342773
This batch time : update_bounds func: 1.8323	 prepare: 0.1010	 bound: 1.5194	 transfer: 0.1505	 finalize: 0.0603
Accumulated time: update_bounds func: 113.0416	 prepare: 5.7781	 bound: 94.1624	 transfer: 0.1505	 finalize: 4.6509
batch bounding time:  1.8329963684082031
Current worst splitting domains [lb, ub] (depth):
[-0.04753,   inf] (158), [-0.04751,   inf] (158), [-0.04738,   inf] (158), [-0.04736,   inf] (158), [-0.04734,   inf] (158), [-0.04732,   inf] (158), [-0.04732,   inf] (158), [-0.04731,   inf] (158), [-0.04730,   inf] (158), [-0.04729,   inf] (158), [-0.04727,   inf] (158), [-0.04727,   inf] (158), [-0.04726,   inf] (158), [-0.04725,   inf] (158), [-0.04719,   inf] (158), [-0.04717,   inf] (158), [-0.04717,   inf] (158), [-0.04715,   inf] (158), [-0.04713,   inf] (158), [-0.04712,   inf] (158), 
length of domains: 9967
Total time: 2.3684	 pickout: 0.1545	 decision: 0.2308	 get_bound: 1.8339	 add_domain: 0.1493
Current lb:-0.0475311279296875
29018 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 147.43091678619385

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [3, 2378] [3, 2378] [3, 2378] [3, 2378] [3, 2378] [3, 2378] [0, 12889] [0, 12889] [0, 12889] [0, 12889] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 17.633012771606445 with beta sum per layer: [15.857107162475586, 16.82344627380371, 3.042991876602173, 110.37936401367188, 0.0, 0.0]
alpha/beta optimization time: 1.5342364311218262
This batch time : update_bounds func: 1.8502	 prepare: 0.1006	 bound: 1.5348	 transfer: 0.1536	 finalize: 0.0601
Accumulated time: update_bounds func: 114.8918	 prepare: 5.8787	 bound: 95.6972	 transfer: 0.1536	 finalize: 4.7110
batch bounding time:  1.8508799076080322
Current worst splitting domains [lb, ub] (depth):
[-0.04753,   inf] (160), [-0.04751,   inf] (160), [-0.04738,   inf] (160), [-0.04736,   inf] (160), [-0.04734,   inf] (160), [-0.04732,   inf] (160), [-0.04732,   inf] (160), [-0.04731,   inf] (160), [-0.04730,   inf] (160), [-0.04729,   inf] (160), [-0.04727,   inf] (160), [-0.04727,   inf] (160), [-0.04725,   inf] (160), [-0.04725,   inf] (160), [-0.04718,   inf] (160), [-0.04717,   inf] (160), [-0.04717,   inf] (160), [-0.04716,   inf] (160), [-0.04716,   inf] (160), [-0.04715,   inf] (160), 
length of domains: 10203
Total time: 2.3793	 pickout: 0.1491	 decision: 0.2313	 get_bound: 1.8517	 add_domain: 0.1472
Current lb:-0.04752802848815918
29530 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 149.82152557373047

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 12678] [0, 12678] [0, 12678] [0, 12678] [0, 12678] [0, 12678] [0, 13226] [0, 13226] [0, 13226] [0, 13226] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 23.921142578125 with beta sum per layer: [0.004084008280187845, 0.0, 0.04050256311893463, 0.0, 0.0, 0.0]
alpha/beta optimization time: 1.462144136428833
This batch time : update_bounds func: 1.7776	 prepare: 0.1002	 bound: 1.4627	 transfer: 0.1530	 finalize: 0.0606
Accumulated time: update_bounds func: 116.6694	 prepare: 5.9789	 bound: 97.1599	 transfer: 0.1530	 finalize: 4.7716/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:556: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(eps_temp / std).reshape(1, -1, 1, 1)

batch bounding time:  1.778404951095581
Current worst splitting domains [lb, ub] (depth):
[-0.04741,   inf] (162), [-0.04740,   inf] (162), [-0.04740,   inf] (162), [-0.04738,   inf] (162), [-0.04726,   inf] (162), [-0.04725,   inf] (162), [-0.04725,   inf] (162), [-0.04724,   inf] (162), [-0.04724,   inf] (162), [-0.04723,   inf] (162), [-0.04723,   inf] (162), [-0.04722,   inf] (162), [-0.04722,   inf] (162), [-0.04721,   inf] (162), [-0.04721,   inf] (162), [-0.04720,   inf] (162), [-0.04720,   inf] (162), [-0.04719,   inf] (162), [-0.04719,   inf] (162), [-0.04718,   inf] (162), 
length of domains: 10459
Total time: 2.6476	 pickout: 0.1502	 decision: 0.5653	 get_bound: 1.7793	 add_domain: 0.1527
Current lb:-0.047411441802978516
30042 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 152.479905128479

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 13226] [0, 13226] [0, 13226] [0, 13226] [0, 13226] [3, 2378] [0, 13226] [0, 13226] [3, 2378] [0, 13226] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 19.304065704345703 with beta sum per layer: [6.1195173263549805, 68.03667449951172, 1.8444483280181885, 68.44003295898438, 0.0, 0.0]
alpha/beta optimization time: 1.5225727558135986
This batch time : update_bounds func: 1.8341	 prepare: 0.1006	 bound: 1.5234	 transfer: 0.1505	 finalize: 0.0585
Accumulated time: update_bounds func: 118.5035	 prepare: 6.0795	 bound: 98.6833	 transfer: 0.1505	 finalize: 4.8301
batch bounding time:  1.8348274230957031
Current worst splitting domains [lb, ub] (depth):
[-0.04734,   inf] (164), [-0.04733,   inf] (164), [-0.04732,   inf] (164), [-0.04731,   inf] (164), [-0.04730,   inf] (164), [-0.04729,   inf] (164), [-0.04728,   inf] (164), [-0.04727,   inf] (164), [-0.04725,   inf] (164), [-0.04724,   inf] (164), [-0.04722,   inf] (164), [-0.04721,   inf] (164), [-0.04720,   inf] (164), [-0.04719,   inf] (164), [-0.04719,   inf] (164), [-0.04719,   inf] (164), [-0.04718,   inf] (164), [-0.04717,   inf] (164), [-0.04717,   inf] (164), [-0.04716,   inf] (164), 
length of domains: 10675
Total time: 2.3669	 pickout: 0.1582	 decision: 0.2302	 get_bound: 1.8357	 add_domain: 0.1428
Current lb:-0.047344326972961426
30554 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 154.85835981369019

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [3, 1782] [3, 1789] [3, 1786] [3, 1789] [3, 1789] [3, 1789] [3, 1786] [3, 1782] [0, 12735] [0, 12735] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 23.993188858032227 with beta sum per layer: [0.19122539460659027, 5.724040985107422, 0.13098224997520447, 0.0431600920855999, 0.0, 0.0]
alpha/beta optimization time: 1.4747164249420166
This batch time : update_bounds func: 1.7907	 prepare: 0.1012	 bound: 1.4753	 transfer: 0.1527	 finalize: 0.0604
Accumulated time: update_bounds func: 120.2942	 prepare: 6.1807	 bound: 100.1585	 transfer: 0.1527	 finalize: 4.8905
batch bounding time:  1.7915089130401611
Current worst splitting domains [lb, ub] (depth):
[-0.04734,   inf] (166), [-0.04734,   inf] (166), [-0.04733,   inf] (166), [-0.04733,   inf] (166), [-0.04732,   inf] (166), [-0.04732,   inf] (166), [-0.04731,   inf] (166), [-0.04731,   inf] (166), [-0.04730,   inf] (166), [-0.04730,   inf] (166), [-0.04729,   inf] (166), [-0.04729,   inf] (166), [-0.04728,   inf] (166), [-0.04728,   inf] (166), [-0.04727,   inf] (166), [-0.04719,   inf] (166), [-0.04719,   inf] (166), [-0.04719,   inf] (166), [-0.04718,   inf] (166), [-0.04718,   inf] (166), 
length of domains: 10931
Total time: 2.3393	 pickout: 0.1588	 decision: 0.2312	 get_bound: 1.7924	 add_domain: 0.1569
Current lb:-0.047344326972961426
31066 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 157.20880508422852

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [3, 1786] [0, 8414] [3, 1782] [0, 8192] [0, 8185] [3, 1782] [3, 1786] [3, 1786] [3, 1782] [0, 12896] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 17.34832191467285 with beta sum per layer: [10.064459800720215, 2.8087387084960938, 5.2193098068237305, 3.665093421936035, 0.0, 0.06958536803722382]
alpha/beta optimization time: 1.5596721172332764
This batch time : update_bounds func: 1.8750	 prepare: 0.1029	 bound: 1.5602	 transfer: 0.1504	 finalize: 0.0603
Accumulated time: update_bounds func: 122.1692	 prepare: 6.2835	 bound: 101.7188	 transfer: 0.1504	 finalize: 4.9509
batch bounding time:  1.8756921291351318
Current worst splitting domains [lb, ub] (depth):
[-0.04734,   inf] (168), [-0.04734,   inf] (168), [-0.04734,   inf] (168), [-0.04733,   inf] (168), [-0.04733,   inf] (168), [-0.04733,   inf] (168), [-0.04733,   inf] (168), [-0.04732,   inf] (168), [-0.04732,   inf] (168), [-0.04732,   inf] (168), [-0.04731,   inf] (168), [-0.04731,   inf] (168), [-0.04731,   inf] (168), [-0.04731,   inf] (168), [-0.04730,   inf] (168), [-0.04730,   inf] (168), [-0.04730,   inf] (168), [-0.04730,   inf] (168), [-0.04729,   inf] (168), [-0.04729,   inf] (168), 
length of domains: 11157
Total time: 2.3990	 pickout: 0.1447	 decision: 0.2300	 get_bound: 1.8765	 add_domain: 0.1477
Current lb:-0.047344326972961426
31578 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Time out!!!!!!!!
Image 355 label 4 verification end, final lower bound -0.047344326972961426, upper bound inf, time: 160.12613892555237
355 -0.047344326972961426
Result: image 355 verification failure (with branch and bound).
Wall time: 181.08123064041138

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 0): []
verification failure idx (total 1): [355]
final verified acc: 0.0%[1]
verifier is called on 1 examples.
total verified: 0
mean time [cnt:1] (excluding attack success): 180.9641375541687
