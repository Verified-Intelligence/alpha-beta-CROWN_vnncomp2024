Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: mnist_conv_big_diffai.pth
  name: mnist_conv_big
data:
  start: 269
  end: 270
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: MNIST_ERAN
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.3
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 256
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 180
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 100
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Tue May  3 01:09:18 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (5): ReLU()
  (6): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (7): ReLU()
  (8): Flatten()
  (9): Linear(in_features=3136, out_features=512, bias=True)
  (10): ReLU()
  (11): Linear(in_features=512, out_features=512, bias=True)
  (12): ReLU()
  (13): Linear(in_features=512, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([1000, 1, 28, 28]) torch.Size([1000]) torch.Size([1000])
X range: tensor(2.8215) tensor(-0.4242) tensor(-0.0274)
Note runnerup label is empty here!
############################
epsilon after preprocessing: tensor([[[[0.9737]]]]), data_max = tensor([[[[2.8215]]]]), data_min = tensor([[[[-0.4242]]]])
Task length: 1
saving results to Verified_ret_[mnist_conv_big]_start=269_end=270_iter=20_b=256_timeout=180_branching=kfsb-max-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 269 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 0, correct label 0, image norm 512.2582397460938, logits tensor([ 8.7583, -3.1795,  0.4911,  0.7194, -3.7902,  0.5353, -0.4233, -0.0297,
        -1.9946,  0.9229], device='cuda:0', grad_fn=<SelectBackward>)
##### PGD attack: True label: 0, Tested against: ['all'] ######
pgd prediction: tensor([ 5.3954, -3.6045, -0.4761, -1.4249, -0.2226, -1.4115, -1.9890,  4.5554,
        -4.1297,  1.9355], device='cuda:0', grad_fn=<SqueezeBackward1>)
attack margin tensor([   inf, 8.9999, 5.8716, 6.8203, 5.6180, 6.8069, 7.3844, 0.8400, 9.5251,
        3.4599], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[ 8.7583, -3.1795,  0.4911,  0.7194, -3.7902,  0.5353, -0.4233, -0.0297,
         -1.9946,  0.9229]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ -2.7201, -11.9862,  -3.8397, -13.6874,  -5.9899,  -8.1225, -14.5618,
           0.8736, -13.8429]], device='cuda:0') None
best_l after optimization: -30.586042404174805 with beta sum per layer: []
alpha/beta optimization time: 19.48018503189087
initial alpha-CROWN bounds: tensor([[ 7.4066,  1.8435,  4.2468,  2.2953,  4.0483,  4.3071, -1.1115,  7.4194,
          0.1305]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-1.1115, device='cuda:0', grad_fn=<MinBackward1>)
Sorted order for labels to verify: [7, 9, 4, 2, 5, 3, 6, 1, 8, 0]
##### [0:269] Tested against 7 ######
Model prediction is: tensor([[ 8.7583, -3.1795,  0.4911,  0.7194, -3.7902,  0.5353, -0.4233, -0.0297,
         -1.9946,  0.9229]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /16 start_node /17
setting alpha for layer /16 start_node /19
setting alpha for layer /16 start_node /21
setting alpha for layer /16 start_node /31
setting alpha for layer /16 start_node /33
not setting layer /16 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 32, 28, 28]) != torch.Size([2, 9, 1, 32, 28, 28]))
setting alpha for layer /18 start_node /19
setting alpha for layer /18 start_node /21
setting alpha for layer /18 start_node /31
setting alpha for layer /18 start_node /33
not setting layer /18 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 32, 14, 14]) != torch.Size([2, 9, 1, 32, 14, 14]))
setting alpha for layer /20 start_node /21
setting alpha for layer /20 start_node /31
setting alpha for layer /20 start_node /33
not setting layer /20 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 64, 14, 14]) != torch.Size([2, 9, 1, 64, 14, 14]))
setting alpha for layer /22 start_node /31
setting alpha for layer /22 start_node /33
not setting layer /22 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 64, 7, 7]) != torch.Size([2, 9, 1, 64, 7, 7]))
setting alpha for layer /32 start_node /33
not setting layer /32 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 512]) != torch.Size([2, 9, 1, 512]))
not setting layer /34 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 512]) != torch.Size([2, 9, 1, 512]))
0 /15 torch.Size([1, 32, 28, 28])
1 /17 torch.Size([1, 32, 14, 14])
2 /19 torch.Size([1, 64, 14, 14])
3 /21 torch.Size([1, 64, 7, 7])
4 /31 torch.Size([1, 512])
5 /33 torch.Size([1, 512])
best_l after optimization: 1.1012194156646729 with beta sum per layer: []
alpha/beta optimization time: 2.8658759593963623
alpha-CROWN with fixed intermediate bounds: tensor([[-1.1012]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-1.1012194156646729
layer 0 size torch.Size([25088]) unstable 630
layer 1 size torch.Size([6272]) unstable 89
layer 2 size torch.Size([12544]) unstable 57
layer 3 size torch.Size([3136]) unstable 43
layer 4 size torch.Size([512]) unstable 10
layer 5 size torch.Size([512]) unstable 10
-----------------
# of unstable neurons: 839
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 28, 28]) pre split depth:  4
batch:  torch.Size([1, 32, 28, 28]) post split depth:  4
splitting decisions: 
split level 0: [4, 484] 
split level 1: [5, 102] 
split level 2: [3, 1800] 
split level 3: [3, 2094] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -22.277847290039062 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.4252035617828369
This batch time : update_bounds func: 0.4347	 prepare: 0.0040	 bound: 0.4257	 transfer: 0.0027	 finalize: 0.0023
Accumulated time: update_bounds func: 0.4347	 prepare: 0.0040	 bound: 0.4257	 transfer: 0.0027	 finalize: 0.0023
batch bounding time:  0.4350616931915283
Current worst splitting domains [lb, ub] (depth):
[-0.71873,   inf] (5), 
length of domains: 1
Total time: 0.4821	 pickout: 0.0018	 decision: 0.0419	 get_bound: 0.4383	 add_domain: 0.0002
Current lb:-0.7187301516532898
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.23698616027832

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 28, 28]) pre split depth:  4
batch:  torch.Size([1, 32, 28, 28]) post split depth:  4
splitting decisions: 
split level 0: [3, 2430] 
split level 1: [3, 2087] 
split level 2: [2, 4623] 
split level 3: [3, 1555] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -5.425240993499756 with beta sum per layer: [0.0, 0.0, 0.1831122636795044, 0.04446183145046234, 0.0, 0.0]
alpha/beta optimization time: 0.4685783386230469
This batch time : update_bounds func: 0.4802	 prepare: 0.0047	 bound: 0.4690	 transfer: 0.0043	 finalize: 0.0021
Accumulated time: update_bounds func: 0.9149	 prepare: 0.0087	 bound: 0.8947	 transfer: 0.0043	 finalize: 0.0043
batch bounding time:  0.4803426265716553
Current worst splitting domains [lb, ub] (depth):
[-0.52387,   inf] (10), [-0.07725,   inf] (10), [-0.02907,   inf] (10), 
length of domains: 3
Total time: 0.5268	 pickout: 0.0032	 decision: 0.0398	 get_bound: 0.4835	 add_domain: 0.0003
Current lb:-0.5238685607910156
32 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.764037132263184

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3, 32, 28, 28]) pre split depth:  3
batch:  torch.Size([3, 32, 28, 28]) post split depth:  3
splitting decisions: 
split level 0: [2, 4649] [3, 1803] [3, 1803] 
split level 1: [3, 1803] [2, 4651] [2, 4649] 
split level 2: [2, 4637] [2, 4637] [2, 4637] 
regular batch size: 2*12, diving batch size 1*0
best_l after optimization: -14.861896514892578 with beta sum per layer: [0.0, 0.0, 0.009905479848384857, 0.3864029347896576, 0.0, 0.0]
alpha/beta optimization time: 0.44089198112487793
This batch time : update_bounds func: 0.4587	 prepare: 0.0062	 bound: 0.4413	 transfer: 0.0082	 finalize: 0.0029
Accumulated time: update_bounds func: 1.3736	 prepare: 0.0149	 bound: 1.3360	 transfer: 0.0082	 finalize: 0.0072
batch bounding time:  0.45889902114868164
Current worst splitting domains [lb, ub] (depth):
[-0.49547,   inf] (14), [-0.11590,   inf] (14), [-0.04782,   inf] (14), [-0.00384,   inf] (14), 
length of domains: 4
Total time: 0.4995	 pickout: 0.0026	 decision: 0.0335	 get_bound: 0.4629	 add_domain: 0.0004
Current lb:-0.49547386169433594
56 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.263852834701538

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 32, 28, 28]) pre split depth:  2
batch:  torch.Size([4, 32, 28, 28]) post split depth:  2
splitting decisions: 
split level 0: [2, 4651] [2, 4651] [3, 2088] [3, 2088] 
split level 1: [2, 4652] [2, 4652] [2, 4652] [3, 2437] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -5.036664009094238 with beta sum per layer: [0.0, 0.0, 0.7887074947357178, 0.3411291539669037, 0.0, 0.0]
alpha/beta optimization time: 0.45072197914123535
This batch time : update_bounds func: 0.4619	 prepare: 0.0051	 bound: 0.4512	 transfer: 0.0035	 finalize: 0.0021
Accumulated time: update_bounds func: 1.8355	 prepare: 0.0200	 bound: 1.7872	 transfer: 0.0035	 finalize: 0.0093
batch bounding time:  0.46204686164855957
Current worst splitting domains [lb, ub] (depth):
[-0.49099,   inf] (17), [-0.10944,   inf] (17), [-0.02630,   inf] (17), 
length of domains: 3
Total time: 0.5010	 pickout: 0.0031	 decision: 0.0334	 get_bound: 0.4642	 add_domain: 0.0003
Current lb:-0.49098658561706543
72 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.765165090560913

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3, 32, 28, 28]) pre split depth:  3
batch:  torch.Size([3, 32, 28, 28]) post split depth:  3
splitting decisions: 
split level 0: [3, 2088] [3, 2088] [3, 2437] 
split level 1: [3, 2437] [3, 2437] [2, 4638] 
split level 2: [3, 1780] [3, 1780] [3, 1780] 
regular batch size: 2*12, diving batch size 1*0
best_l after optimization: -9.562724113464355 with beta sum per layer: [0.0, 0.0, 0.07680091261863708, 0.6321103572845459, 0.0, 0.0]
alpha/beta optimization time: 0.4498565196990967
This batch time : update_bounds func: 0.4642	 prepare: 0.0062	 bound: 0.4503	 transfer: 0.0048	 finalize: 0.0028
Accumulated time: update_bounds func: 2.2997	 prepare: 0.0262	 bound: 2.2375	 transfer: 0.0048	 finalize: 0.0121
batch bounding time:  0.46432948112487793
Current worst splitting domains [lb, ub] (depth):
[-0.20531,   inf] (21), [-0.19026,   inf] (21), [-0.05208,   inf] (21), [-0.03792,   inf] (21), 
length of domains: 4
Total time: 0.5047	 pickout: 0.0026	 decision: 0.0332	 get_bound: 0.4685	 add_domain: 0.0004
Current lb:-0.20531320571899414
96 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.270224094390869

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 32, 28, 28]) pre split depth:  2
batch:  torch.Size([4, 32, 28, 28]) post split depth:  2
splitting decisions: 
split level 0: [2, 4609] [2, 4609] [2, 4609] [2, 4609] 
split level 1: [2, 4638] [2, 4638] [2, 4638] [2, 4638] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -2.757678747177124 with beta sum per layer: [0.0, 0.0, 0.0, 2.2966604232788086, 0.0, 0.0]
alpha/beta optimization time: 0.41759777069091797
This batch time : update_bounds func: 0.4284	 prepare: 0.0050	 bound: 0.4181	 transfer: 0.0027	 finalize: 0.0026
Accumulated time: update_bounds func: 2.7281	 prepare: 0.0311	 bound: 2.6556	 transfer: 0.0027	 finalize: 0.0147
batch bounding time:  0.4286923408508301
Current worst splitting domains [lb, ub] (depth):
[-0.20101,   inf] (24), [-0.18815,   inf] (24), [-0.04479,   inf] (24), [-0.03173,   inf] (24), 
length of domains: 4
Total time: 0.4675	 pickout: 0.0030	 decision: 0.0331	 get_bound: 0.4309	 add_domain: 0.0005
Current lb:-0.20101261138916016
112 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.738124132156372

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 32, 28, 28]) pre split depth:  2
batch:  torch.Size([4, 32, 28, 28]) post split depth:  2
splitting decisions: 
split level 0: [3, 2093] [3, 2093] [3, 2093] [3, 2093] 
split level 1: [2, 4650] [2, 4650] [2, 4650] [2, 4650] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -1.4631681442260742 with beta sum per layer: [0.0, 0.0, 0.23732657730579376, 1.8746942281723022, 0.0, 0.0]
alpha/beta optimization time: 0.4513092041015625
This batch time : update_bounds func: 0.4655	 prepare: 0.0049	 bound: 0.4518	 transfer: 0.0065	 finalize: 0.0022
Accumulated time: update_bounds func: 3.1936	 prepare: 0.0360	 bound: 3.1073	 transfer: 0.0065	 finalize: 0.0170
batch bounding time:  0.46575140953063965
Current worst splitting domains [lb, ub] (depth):
[-0.19998,   inf] (27), [-0.18582,   inf] (27), [-0.03771,   inf] (27), [-0.02513,   inf] (27), 
length of domains: 4
Total time: 0.5051	 pickout: 0.0032	 decision: 0.0334	 get_bound: 0.4680	 add_domain: 0.0005
Current lb:-0.199981689453125
128 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.243598222732544

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 32, 28, 28]) pre split depth:  2
batch:  torch.Size([4, 32, 28, 28]) post split depth:  2
splitting decisions: 
split level 0: [2, 4528] [2, 4528] [2, 4528] [2, 4528] 
split level 1: [3, 1556] [3, 1556] [3, 1556] [3, 1556] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -1.0086967945098877 with beta sum per layer: [0.0, 0.0, 0.0, 2.1092305183410645, 0.0, 0.0]
alpha/beta optimization time: 0.4538700580596924
This batch time : update_bounds func: 0.4661	 prepare: 0.0049	 bound: 0.4543	 transfer: 0.0047	 finalize: 0.0021/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:556: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(eps_temp / std).reshape(1, -1, 1, 1)

Accumulated time: update_bounds func: 3.6597	 prepare: 0.0409	 bound: 3.5617	 transfer: 0.0047	 finalize: 0.0191
batch bounding time:  0.46645283699035645
Current worst splitting domains [lb, ub] (depth):
[-0.05406,   inf] (30), [-0.04644,   inf] (30), [-0.03939,   inf] (30), [-0.03221,   inf] (30), 
length of domains: 4
Total time: 0.5056	 pickout: 0.0033	 decision: 0.0329	 get_bound: 0.4687	 add_domain: 0.0007
Current lb:-0.054055653512477875
144 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.749553203582764

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 32, 28, 28]) pre split depth:  2
batch:  torch.Size([4, 32, 28, 28]) post split depth:  2
splitting decisions: 
split level 0: [2, 4654] [2, 4644] [2, 4654] [2, 4644] 
split level 1: [2, 4655] [2, 4655] [2, 4655] [2, 4655] 
regular batch size: 2*8, diving batch size 1*0

all verified at 8th iter
best_l after optimization: -1.560286045074463 with beta sum per layer: [0.0, 0.0, 0.0, 2.373321056365967, 0.0, 0.0]
alpha/beta optimization time: 0.19004607200622559
This batch time : update_bounds func: 0.2015	 prepare: 0.0050	 bound: 0.1905	 transfer: 0.0040	 finalize: 0.0020
Accumulated time: update_bounds func: 3.8611	 prepare: 0.0459	 bound: 3.7522	 transfer: 0.0040	 finalize: 0.0211
batch bounding time:  0.2015988826751709
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.2415	 pickout: 0.0038	 decision: 0.0338	 get_bound: 0.2039	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 7.991429328918457

Image 269 label 7 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 8.096287727355957
269 1.0000000116860974e-07
##### [0:269] Tested against 9 ######
Initial alpha-CROWN verified for label 9 with bound 0.13049963116645813
Image 269 label 9 verification end, final lower bound 0.13049963116645813, upper bound inf, time: 0.0005161762237548828
269 0.13049963116645813
##### [0:269] Tested against 4 ######
Initial alpha-CROWN verified for label 4 with bound 2.2952542304992676
Image 269 label 4 verification end, final lower bound 2.2952542304992676, upper bound inf, time: 0.0004048347473144531
269 2.2952542304992676
##### [0:269] Tested against 2 ######
Initial alpha-CROWN verified for label 2 with bound 1.8434853553771973
Image 269 label 2 verification end, final lower bound 1.8434853553771973, upper bound inf, time: 0.0004496574401855469
269 1.8434853553771973
##### [0:269] Tested against 5 ######
Initial alpha-CROWN verified for label 5 with bound 4.048341274261475
Image 269 label 5 verification end, final lower bound 4.048341274261475, upper bound inf, time: 0.00039315223693847656
269 4.048341274261475
##### [0:269] Tested against 3 ######
Initial alpha-CROWN verified for label 3 with bound 4.246772289276123
Image 269 label 3 verification end, final lower bound 4.246772289276123, upper bound inf, time: 0.00038123130798339844
269 4.246772289276123
##### [0:269] Tested against 6 ######
Initial alpha-CROWN verified for label 6 with bound 4.307144641876221
Image 269 label 6 verification end, final lower bound 4.307144641876221, upper bound inf, time: 0.00039839744567871094
269 4.307144641876221
##### [0:269] Tested against 1 ######
Initial alpha-CROWN verified for label 1 with bound 7.406565189361572
Image 269 label 1 verification end, final lower bound 7.406565189361572, upper bound inf, time: 0.0003974437713623047
269 7.406565189361572
##### [0:269] Tested against 8 ######
Initial alpha-CROWN verified for label 8 with bound 7.419436454772949
Image 269 label 8 verification end, final lower bound 7.419436454772949, upper bound inf, time: 0.0004010200500488281
269 7.419436454772949
##### [0:269] Tested against 0 ######
groundtruth label, skip!
Result: image 269 verification success (with branch and bound)!
Wall time: 32.90334701538086

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 1): [269]
verification failure idx (total 0): []
final verified acc: 100.0%[1]
verifier is called on 1 examples.
total verified: 1
mean time [cnt:1] (excluding attack success): 29.479677438735962
