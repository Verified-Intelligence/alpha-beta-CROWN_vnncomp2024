Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: mnist_conv_big_diffai.pth
  name: mnist_conv_big
data:
  start: 133
  end: 134
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: MNIST_ERAN
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.3
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 256
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 180
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 100
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Tue May  3 01:13:38 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (5): ReLU()
  (6): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (7): ReLU()
  (8): Flatten()
  (9): Linear(in_features=3136, out_features=512, bias=True)
  (10): ReLU()
  (11): Linear(in_features=512, out_features=512, bias=True)
  (12): ReLU()
  (13): Linear(in_features=512, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([1000, 1, 28, 28]) torch.Size([1000]) torch.Size([1000])
X range: tensor(2.8215) tensor(-0.4242) tensor(-0.0274)
Note runnerup label is empty here!
############################
epsilon after preprocessing: tensor([[[[0.9737]]]]), data_max = tensor([[[[2.8215]]]]), data_min = tensor([[[[-0.4242]]]])
Task length: 1
saving results to Verified_ret_[mnist_conv_big]_start=133_end=134_iter=20_b=256_timeout=180_branching=kfsb-max-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 133 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 7, correct label 7, image norm 602.640380859375, logits tensor([-3.9017, -2.2831,  2.1702,  1.4606, -1.2946, -1.9252, -5.2496,  3.8498,
        -2.2192, -0.4521], device='cuda:0', grad_fn=<SelectBackward>)
Model prediction is: tensor([[-3.9017, -2.2831,  2.1702,  1.4606, -1.2946, -1.9252, -5.2496,  3.8498,
         -2.2192, -0.4521]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 3.3864,  3.4989, -1.4408, -0.8244,  2.6005,  2.7564,  4.2601,  0.5957,
          2.9415]], device='cuda:0') None
best_l after optimization: -30.647424697875977 with beta sum per layer: []
alpha/beta optimization time: 19.139461040496826
initial alpha-CROWN bounds: tensor([[ 5.4291,  4.4082, -0.2972,  0.1597,  4.5510,  3.9093,  6.7328,  2.0655,
          3.6890]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.2972, device='cuda:0', grad_fn=<MinBackward1>)
##### [0:133] Tested against 2 ######
Model prediction is: tensor([[-3.9017, -2.2831,  2.1702,  1.4606, -1.2946, -1.9252, -5.2496,  3.8498,
         -2.2192, -0.4521]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /16 start_node /17
setting alpha for layer /16 start_node /19
setting alpha for layer /16 start_node /21
setting alpha for layer /16 start_node /31
setting alpha for layer /16 start_node /33
not setting layer /16 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 32, 28, 28]) != torch.Size([2, 9, 1, 32, 28, 28]))
setting alpha for layer /18 start_node /19
setting alpha for layer /18 start_node /21
setting alpha for layer /18 start_node /31
setting alpha for layer /18 start_node /33
not setting layer /18 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 32, 14, 14]) != torch.Size([2, 9, 1, 32, 14, 14]))
setting alpha for layer /20 start_node /21
setting alpha for layer /20 start_node /31
setting alpha for layer /20 start_node /33
not setting layer /20 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 64, 14, 14]) != torch.Size([2, 9, 1, 64, 14, 14]))
setting alpha for layer /22 start_node /31
setting alpha for layer /22 start_node /33
not setting layer /22 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 64, 7, 7]) != torch.Size([2, 9, 1, 64, 7, 7]))
setting alpha for layer /32 start_node /33
not setting layer /32 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 512]) != torch.Size([2, 9, 1, 512]))
not setting layer /34 start_node /35 because shape mismatch (torch.Size([2, 1, 1, 512]) != torch.Size([2, 9, 1, 512]))
0 /15 torch.Size([1, 32, 28, 28])
1 /17 torch.Size([1, 32, 14, 14])
2 /19 torch.Size([1, 64, 14, 14])
3 /21 torch.Size([1, 64, 7, 7])
4 /31 torch.Size([1, 512])
5 /33 torch.Size([1, 512])
best_l after optimization: 0.2967435121536255 with beta sum per layer: []
alpha/beta optimization time: 2.6831390857696533
alpha-CROWN with fixed intermediate bounds: tensor([[-0.2967]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.2967435121536255
layer 0 size torch.Size([25088]) unstable 584
layer 1 size torch.Size([6272]) unstable 63
layer 2 size torch.Size([12544]) unstable 45
layer 3 size torch.Size([3136]) unstable 29
layer 4 size torch.Size([512]) unstable 3
layer 5 size torch.Size([512]) unstable 9
-----------------
# of unstable neurons: 733
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 28, 28]) pre split depth:  4
batch:  torch.Size([1, 32, 28, 28]) post split depth:  4
splitting decisions: 
split level 0: [5, 324] 
split level 1: [3, 2086] 
split level 2: [4, 206] 
split level 3: [3, 2080] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -10.55848503112793 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.4305236339569092
This batch time : update_bounds func: 0.4403	 prepare: 0.0044	 bound: 0.4310	 transfer: 0.0026	 finalize: 0.0022
Accumulated time: update_bounds func: 0.4403	 prepare: 0.0044	 bound: 0.4310	 transfer: 0.0026	 finalize: 0.0022
batch bounding time:  0.4405684471130371
Current worst splitting domains [lb, ub] (depth):
[-0.07234,   inf] (5), 
length of domains: 1
Total time: 0.4877	 pickout: 0.0017	 decision: 0.0422	 get_bound: 0.4437	 add_domain: 0.0001
Current lb:-0.07234079390764236
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.051916837692261

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 28, 28]) pre split depth:  4
batch:  torch.Size([1, 32, 28, 28]) post split depth:  4
splitting decisions: 
split level 0: [2, 4621] 
split level 1: [3, 1792] 
split level 2: [2, 4629] 
split level 3: [0, 8244] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -4.77814245223999 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.4153733253479004
This batch time : update_bounds func: 0.4293	 prepare: 0.0047	 bound: 0.4158	 transfer: 0.0065	 finalize: 0.0022
Accumulated time: update_bounds func: 0.8696	 prepare: 0.0091	 bound: 0.8468	 transfer: 0.0065	 finalize: 0.0044
batch bounding time:  0.4294905662536621
Current worst splitting domains [lb, ub] (depth):
[-0.06960,   inf] (10), 
length of domains: 1
Total time: 0.4747	 pickout: 0.0023	 decision: 0.0397	 get_bound: 0.4326	 add_domain: 0.0002
Current lb:-0.06959718465805054
32 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.526932954788208

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 28, 28]) pre split depth:  4
batch:  torch.Size([1, 32, 28, 28]) post split depth:  4
splitting decisions: 
split level 0: [3, 2084] 
split level 1: [0, 12948] 
split level 2: [0, 12663] 
split level 3: [0, 7959] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -3.249556064605713 with beta sum per layer: [0.6318005323410034, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.4390122890472412
This batch time : update_bounds func: 0.4516	 prepare: 0.0051	 bound: 0.4395	 transfer: 0.0048	 finalize: 0.0022
Accumulated time: update_bounds func: 1.3212	 prepare: 0.0142	 bound: 1.2862	 transfer: 0.0048	 finalize: 0.0066
batch bounding time:  0.45183491706848145
Current worst splitting domains [lb, ub] (depth):
[-0.06783,   inf] (15), 
length of domains: 1
Total time: 0.4979	 pickout: 0.0016	 decision: 0.0410	 get_bound: 0.4551	 add_domain: 0.0002
Current lb:-0.06783115863800049
48 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.025146722793579

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 28, 28]) pre split depth:  4
batch:  torch.Size([1, 32, 28, 28]) post split depth:  4
splitting decisions: 
split level 0: [3, 1790] 
split level 1: [2, 4616] 
split level 2: [0, 8468] 
split level 3: [0, 13172] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -2.961604595184326 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.4370105266571045
This batch time : update_bounds func: 0.4501	 prepare: 0.0050	 bound: 0.4375	 transfer: 0.0055	 finalize: 0.0020
Accumulated time: update_bounds func: 1.7713	 prepare: 0.0192	 bound: 1.7237	 transfer: 0.0055	 finalize: 0.0087
batch bounding time:  0.45026707649230957
Current worst splitting domains [lb, ub] (depth):
[-0.06498,   inf] (20), 
length of domains: 1
Total time: 0.4978	 pickout: 0.0041	 decision: 0.0399	 get_bound: 0.4535	 add_domain: 0.0002
Current lb:-0.06497637182474136
64 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.523212432861328

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 28, 28]) pre split depth:  4
batch:  torch.Size([1, 32, 28, 28]) post split depth:  4
splitting decisions: 
split level 0: [2, 5323] 
split level 1: [5, 17] 
split level 2: [5, 367] 
split level 3: [2, 4536] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -1.0231385231018066 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.849755048751831]
alpha/beta optimization time: 0.4373769760131836
This batch time : update_bounds func: 0.4485	 prepare: 0.0051	 bound: 0.4378	 transfer: 0.0035	 finalize: 0.0020
Accumulated time: update_bounds func: 2.2198	 prepare: 0.0243	 bound: 2.1615	 transfer: 0.0035	 finalize: 0.0106
batch bounding time:  0.4486527442932129
Current worst splitting domains [lb, ub] (depth):
[-0.05588,   inf] (25), [-0.03756,   inf] (25), 
length of domains: 2
Total time: 0.4973	 pickout: 0.0034	 decision: 0.0416	 get_bound: 0.4520	 add_domain: 0.0003
Current lb:-0.05588282644748688
80 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.020764589309692

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2, 32, 28, 28]) pre split depth:  3
batch:  torch.Size([2, 32, 28, 28]) post split depth:  3
splitting decisions: 
split level 0: [2, 5394] [2, 5394] 
split level 1: [3, 2380] [3, 2380] 
split level 2: [2, 4509] [2, 4509] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -1.790693998336792 with beta sum per layer: [0.0, 0.0, 0.002863567788153887, 0.8945387601852417, 0.0, 0.0]
alpha/beta optimization time: 0.43924713134765625
This batch time : update_bounds func: 0.4503	 prepare: 0.0050	 bound: 0.4397	 transfer: 0.0035	 finalize: 0.0020
Accumulated time: update_bounds func: 2.6701	 prepare: 0.0293	 bound: 2.6012	 transfer: 0.0035	 finalize: 0.0126
batch bounding time:  0.45047450065612793
Current worst splitting domains [lb, ub] (depth):
[-0.05265,   inf] (29), [-0.04068,   inf] (29), [-0.03416,   inf] (29), [-0.02222,   inf] (29), 
length of domains: 4
Total time: 0.4884	 pickout: 0.0025	 decision: 0.0319	 get_bound: 0.4535	 add_domain: 0.0005
Current lb:-0.052651628851890564
96 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.5094358921051025

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 32, 28, 28]) pre split depth:  2
batch:  torch.Size([4, 32, 28, 28]) post split depth:  2
splitting decisions: 
split level 0: [3, 2402] [3, 2058] [3, 2402] [3, 2058] 
split level 1: [2, 4583] [3, 2402] [3, 2058] [3, 2402] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.06875236332416534 with beta sum per layer: [0.0, 0.0, 0.6176654696464539, 3.027665853500366, 0.0, 0.0]
alpha/beta optimization time: 0.43230652809143066
This batch time : update_bounds func: 0.4439	 prepare: 0.0052	 bound: 0.4327	 transfer: 0.0039	 finalize: 0.0020
Accumulated time: update_bounds func: 3.1140	 prepare: 0.0345	 bound: 3.0339	 transfer: 0.0039	 finalize: 0.0147
batch bounding time:  0.44408297538757324
Current worst splitting domains [lb, ub] (depth):
[-0.04903,   inf] (32), [-0.04852,   inf] (32), [-0.04792,   inf] (32), [-0.04737,   inf] (32), [-0.03389,   inf] (32), [-0.02890,   inf] (32), [-0.02829,   inf] (32), [-0.02808,   inf] (32), [-0.01675,   inf] (32), [-0.01668,   inf] (32), [-0.01083,   inf] (32), 
length of domains: 11
Total time: 0.4834	 pickout: 0.0036	 decision: 0.0323	 get_bound: 0.4463	 add_domain: 0.0013
Current lb:-0.04903335124254227
112 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.9930901527404785

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([11, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([11, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [1, 4441] [1, 4441] [1, 4441] [1, 4441] [1, 4441] [1, 4441] [1, 4441] [1, 4441] [1, 4441] [1, 4441] 
regular batch size: 2*11, diving batch size 1*0
best_l after optimization: 0.5320579409599304 with beta sum per layer: [0.0, 7.644587516784668, 0.01492159254848957, 3.244324207305908, 0.0, 0.0]
alpha/beta optimization time: 0.4529917240142822
This batch time : update_bounds func: 0.4717	 prepare: 0.0062	 bound: 0.4534	 transfer: 0.0087	 finalize: 0.0032
Accumulated time: update_bounds func: 3.5857	 prepare: 0.0407	 bound: 3.4873	 transfer: 0.0087	 finalize: 0.0179
batch bounding time:  0.4718489646911621
Current worst splitting domains [lb, ub] (depth):
[-0.04843,   inf] (34), [-0.04824,   inf] (34), [-0.04769,   inf] (34), [-0.04737,   inf] (34), [-0.03401,   inf] (34), [-0.03389,   inf] (34), [-0.03378,   inf] (34), [-0.03304,   inf] (34), [-0.03303,   inf] (34), [-0.02858,   inf] (34), [-0.02800,   inf] (34), [-0.02295,   inf] (34), [-0.01983,   inf] (34), [-0.01658,   inf] (34), [-0.01584,   inf] (34), [-0.01401,   inf] (34), [-0.01342,   inf] (34), [-0.00825,   inf] (34), [-0.00634,   inf] (34), [-0.00198,   inf] (34), 
length of domains: 21
Total time: 0.5188	 pickout: 0.0075	 decision: 0.0368	 get_bound: 0.4719	 add_domain: 0.0026
Current lb:-0.04842772334814072
134 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.512287139892578

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([21, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([21, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [2, 4602] [3, 2058] [2, 4602] [2, 4602] [3, 2058] [2, 4602] [2, 4602] [2, 4602] [3, 2058] [2, 4602] 
regular batch size: 2*21, diving batch size 1*0
best_l after optimization: 0.5904435515403748 with beta sum per layer: [0.0, 16.972719192504883, 0.9331598281860352, 6.489694118499756, 0.0, 0.0]
alpha/beta optimization time: 0.48067641258239746
This batch time : update_bounds func: 0.5146	 prepare: 0.0101	 bound: 0.4812	 transfer: 0.0176	 finalize: 0.0055
Accumulated time: update_bounds func: 4.1003	 prepare: 0.0509	 bound: 3.9685	 transfer: 0.0176	 finalize: 0.0234
batch bounding time:  0.514885663986206
Current worst splitting domains [lb, ub] (depth):
[-0.04819,   inf] (36), [-0.04769,   inf] (36), [-0.04737,   inf] (36), [-0.04699,   inf] (36), [-0.03389,   inf] (36), [-0.03322,   inf] (36), [-0.03282,   inf] (36), [-0.03200,   inf] (36), [-0.03158,   inf] (36), [-0.02858,   inf] (36), [-0.02753,   inf] (36), [-0.02354,   inf] (36), [-0.02324,   inf] (36), [-0.02292,   inf] (36), [-0.01959,   inf] (36), [-0.01906,   inf] (36), [-0.01868,   inf] (36), [-0.01619,   inf] (36), [-0.01584,   inf] (36), [-0.01401,   inf] (36), 
length of domains: 32
Total time: 0.5794	 pickout: 0.0139	 decision: 0.0469	 get_bound: 0.5150	 add_domain: 0.0036
Current lb:-0.048189133405685425
176 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.092552900314331

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([32, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([32, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [3, 2413] [3, 2413] [3, 2413] [3, 2413] [3, 2413] [3, 2413] [3, 2413] [3, 2413] [3, 2413] [3, 2413] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: -0.3477436304092407 with beta sum per layer: [0.0, 26.90593147277832, 0.6840753555297852, 8.31439208984375, 0.0, 0.0]
alpha/beta optimization time: 0.5041139125823975
This batch time : update_bounds func: 0.5461	 prepare: 0.0143	 bound: 0.5046	 transfer: 0.0197	 finalize: 0.0073
Accumulated time: update_bounds func: 4.6464	 prepare: 0.0652	 bound: 4.4731	 transfer: 0.0197	 finalize: 0.0308
batch bounding time:  0.5463531017303467
Current worst splitting domains [lb, ub] (depth):
[-0.04765,   inf] (38), [-0.04747,   inf] (38), [-0.04734,   inf] (38), [-0.04650,   inf] (38), [-0.03386,   inf] (38), [-0.03293,   inf] (38), [-0.03275,   inf] (38), [-0.03129,   inf] (38), [-0.03106,   inf] (38), [-0.02854,   inf] (38), [-0.02738,   inf] (38), [-0.01889,   inf] (38), [-0.01860,   inf] (38), [-0.01756,   inf] (38), [-0.01582,   inf] (38), [-0.01569,   inf] (38), [-0.01397,   inf] (38), [-0.01211,   inf] (38), [-0.01117,   inf] (38), [-0.01104,   inf] (38), 
length of domains: 26
Total time: 0.6219	 pickout: 0.0181	 decision: 0.0536	 get_bound: 0.5465	 add_domain: 0.0037
Current lb:-0.047651052474975586
240 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.717648983001709

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([26, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([26, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [2, 5435] [2, 5435] [2, 5435] [2, 4602] [2, 5435] [2, 5435] [2, 5435] [2, 4602] [2, 4602] [2, 5435] 
regular batch size: 2*26, diving batch size 1*0
best_l after optimization: 0.7388001680374146 with beta sum per layer: [0.0, 28.25899887084961, 11.55647087097168, 3.7146599292755127, 0.0, 0.0]
alpha/beta optimization time: 0.49071168899536133
This batch time : update_bounds func: 0.5199	 prepare: 0.0119	 bound: 0.4912	 transfer: 0.0107	 finalize: 0.0059
Accumulated time: update_bounds func: 5.1663	 prepare: 0.0772	 bound: 4.9643	 transfer: 0.0107	 finalize: 0.0367
batch bounding time:  0.520066499710083
Current worst splitting domains [lb, ub] (depth):
[-0.04759,   inf] (40), [-0.04741,   inf] (40), [-0.04728,   inf] (40), [-0.04647,   inf] (40), [-0.03774,   inf] (40), [-0.03761,   inf] (40), [-0.03736,   inf] (40), [-0.03380,   inf] (40), [-0.03191,   inf] (40), [-0.03170,   inf] (40), [-0.03110,   inf] (40), [-0.03106,   inf] (40), [-0.02848,   inf] (40), [-0.02732,   inf] (40), [-0.02533,   inf] (40), [-0.02521,   inf] (40), [-0.02433,   inf] (40), [-0.02157,   inf] (40), [-0.01881,   inf] (40), [-0.01799,   inf] (40), 
length of domains: 39
Total time: 0.5904	 pickout: 0.0166	 decision: 0.0491	 get_bound: 0.5202	 add_domain: 0.0045
Current lb:-0.047591567039489746
292 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.308940410614014

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([39, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([39, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 8380] [0, 8380] [3, 2058] [2, 5435] [5, 336] [5, 336] [3, 2058] [0, 8380] [5, 336] [5, 336] 
regular batch size: 2*39, diving batch size 1*0
best_l after optimization: 1.2064342498779297 with beta sum per layer: [0.021319199353456497, 50.65283966064453, 32.75884246826172, 5.020678520202637, 0.0, 7.753109455108643]
alpha/beta optimization time: 0.5275399684906006
This batch time : update_bounds func: 0.5719	 prepare: 0.0172	 bound: 0.5280	 transfer: 0.0172	 finalize: 0.0093
Accumulated time: update_bounds func: 5.7383	 prepare: 0.0944	 bound: 5.4922	 transfer: 0.0172	 finalize: 0.0460
batch bounding time:  0.5721707344055176
Current worst splitting domains [lb, ub] (depth):
[-0.04759,   inf] (42), [-0.04741,   inf] (42), [-0.04650,   inf] (42), [-0.04536,   inf] (42), [-0.04213,   inf] (42), [-0.04201,   inf] (42), [-0.03632,   inf] (42), [-0.03536,   inf] (42), [-0.03530,   inf] (42), [-0.03447,   inf] (42), [-0.03380,   inf] (42), [-0.03292,   inf] (42), [-0.03237,   inf] (42), [-0.03043,   inf] (42), [-0.02960,   inf] (42), [-0.02922,   inf] (42), [-0.02848,   inf] (42), [-0.02829,   inf] (42), [-0.02822,   inf] (42), [-0.02732,   inf] (42), 
length of domains: 64
Total time: 0.6615	 pickout: 0.0232	 decision: 0.0584	 get_bound: 0.5723	 add_domain: 0.0076
Current lb:-0.047589659690856934
370 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.971559762954712

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([64, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [5, 336] [5, 336] [0, 8380] [0, 8380] [5, 336] [5, 336] [2, 4607] [2, 4607] [2, 4607] [2, 4607] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: -0.243425190448761 with beta sum per layer: [0.050720516592264175, 69.3243408203125, 67.62336730957031, 10.843350410461426, 0.0, 25.466106414794922]
alpha/beta optimization time: 0.6473159790039062
This batch time : update_bounds func: 0.7258	 prepare: 0.0264	 bound: 0.6478	 transfer: 0.0365	 finalize: 0.0148
Accumulated time: update_bounds func: 6.4640	 prepare: 0.1208	 bound: 6.1400	 transfer: 0.0365	 finalize: 0.0608
batch bounding time:  0.7260539531707764
Current worst splitting domains [lb, ub] (depth):
[-0.04649,   inf] (44), [-0.04536,   inf] (44), [-0.04528,   inf] (44), [-0.04510,   inf] (44), [-0.04350,   inf] (44), [-0.04317,   inf] (44), [-0.04077,   inf] (44), [-0.04075,   inf] (44), [-0.03896,   inf] (44), [-0.03883,   inf] (44), [-0.03692,   inf] (44), [-0.03673,   inf] (44), [-0.03632,   inf] (44), [-0.03536,   inf] (44), [-0.03528,   inf] (44), [-0.03442,   inf] (44), [-0.03292,   inf] (44), [-0.03237,   inf] (44), [-0.03149,   inf] (44), [-0.03043,   inf] (44), 
length of domains: 83
Total time: 0.8512	 pickout: 0.0372	 decision: 0.0778	 get_bound: 0.7263	 add_domain: 0.0100
Current lb:-0.04648911952972412
498 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.824850797653198

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([83, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([83, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 13084] [0, 13084] [0, 13084] [0, 13084] [2, 4607] [2, 4607] [0, 13084] [0, 13084] [0, 13084] [0, 13084] 
regular batch size: 2*83, diving batch size 1*0
best_l after optimization: 1.3024917840957642 with beta sum per layer: [0.8186740279197693, 76.97071075439453, 78.7352294921875, 23.93341064453125, 0.0, 41.599761962890625]
alpha/beta optimization time: 0.7420213222503662
This batch time : update_bounds func: 0.8339	 prepare: 0.0333	 bound: 0.7425	 transfer: 0.0393	 finalize: 0.0185
Accumulated time: update_bounds func: 7.2979	 prepare: 0.1541	 bound: 6.8825	 transfer: 0.0393	 finalize: 0.0794
batch bounding time:  0.8342134952545166
Current worst splitting domains [lb, ub] (depth):
[-0.04649,   inf] (46), [-0.04536,   inf] (46), [-0.04528,   inf] (46), [-0.04510,   inf] (46), [-0.04322,   inf] (46), [-0.04317,   inf] (46), [-0.04077,   inf] (46), [-0.04074,   inf] (46), [-0.03916,   inf] (46), [-0.03862,   inf] (46), [-0.03848,   inf] (46), [-0.03773,   inf] (46), [-0.03761,   inf] (46), [-0.03743,   inf] (46), [-0.03719,   inf] (46), [-0.03696,   inf] (46), [-0.03692,   inf] (46), [-0.03673,   inf] (46), [-0.03663,   inf] (46), [-0.03627,   inf] (46), 
length of domains: 127
Total time: 0.9935	 pickout: 0.0479	 decision: 0.0943	 get_bound: 0.8344	 add_domain: 0.0169
Current lb:-0.04648697376251221
664 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.822447776794434

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([127, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([127, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [2, 4607] [2, 4607] [2, 4607] [2, 4607] [2, 4670] [2, 4670] [2, 4607] [2, 4607] [2, 4607] [2, 4607] 
regular batch size: 2*127, diving batch size 1*0
best_l after optimization: -1.796877145767212 with beta sum per layer: [2.7705211639404297, 112.82113647460938, 123.61983489990234, 47.801292419433594, 0.0, 54.09897232055664]
alpha/beta optimization time: 0.9425194263458252
This batch time : update_bounds func: 1.0859	 prepare: 0.0496	 bound: 0.9430	 transfer: 0.0611	 finalize: 0.0317
Accumulated time: update_bounds func: 8.3839	 prepare: 0.2036	 bound: 7.8255	 transfer: 0.0611	 finalize: 0.1111
batch bounding time:  1.0864005088806152
Current worst splitting domains [lb, ub] (depth):
[-0.04649,   inf] (48), [-0.04536,   inf] (48), [-0.04527,   inf] (48), [-0.04509,   inf] (48), [-0.04309,   inf] (48), [-0.04309,   inf] (48), [-0.04076,   inf] (48), [-0.04074,   inf] (48), [-0.03916,   inf] (48), [-0.03861,   inf] (48), [-0.03848,   inf] (48), [-0.03772,   inf] (48), [-0.03761,   inf] (48), [-0.03743,   inf] (48), [-0.03719,   inf] (48), [-0.03691,   inf] (48), [-0.03683,   inf] (48), [-0.03665,   inf] (48), [-0.03663,   inf] (48), [-0.03605,   inf] (48), 
length of domains: 150
Total time: 1.3232	 pickout: 0.0895	 decision: 0.1277	 get_bound: 1.0868	 add_domain: 0.0191
Current lb:-0.04648697376251221
918 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.150148868560791

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([150, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([150, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [5, 336] [5, 336] [3, 2434] [3, 2434] [3, 2434] [3, 2434] [5, 336] [5, 336] [5, 336] [3, 2434] 
regular batch size: 2*150, diving batch size 1*0
best_l after optimization: 0.43928730487823486 with beta sum per layer: [2.4506382942199707, 144.06362915039062, 130.9340362548828, 87.40090942382812, 0.0, 94.04694366455078]
alpha/beta optimization time: 1.0515339374542236
This batch time : update_bounds func: 1.2873	 prepare: 0.0582	 bound: 1.0520	 transfer: 0.0717	 finalize: 0.1047
Accumulated time: update_bounds func: 9.6712	 prepare: 0.2618	 bound: 8.8775	 transfer: 0.0717	 finalize: 0.2158
batch bounding time:  1.287804126739502
Current worst splitting domains [lb, ub] (depth):
[-0.04527,   inf] (50), [-0.04509,   inf] (50), [-0.04411,   inf] (50), [-0.04309,   inf] (50), [-0.04309,   inf] (50), [-0.04305,   inf] (50), [-0.04218,   inf] (50), [-0.04079,   inf] (50), [-0.03861,   inf] (50), [-0.03848,   inf] (50), [-0.03844,   inf] (50), [-0.03843,   inf] (50), [-0.03770,   inf] (50), [-0.03743,   inf] (50), [-0.03719,   inf] (50), [-0.03691,   inf] (50), [-0.03686,   inf] (50), [-0.03683,   inf] (50), [-0.03665,   inf] (50), [-0.03574,   inf] (50), 
length of domains: 232
Total time: 1.5563	 pickout: 0.0912	 decision: 0.1473	 get_bound: 1.2883	 add_domain: 0.0296
Current lb:-0.04527246952056885
1218 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.711038827896118

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([232, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([232, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [2, 4508] [2, 4508] [2, 4508] [0, 13084] [0, 13084] [2, 4508] [2, 4670] [2, 4670] [2, 4508] [2, 4508] 
regular batch size: 2*232, diving batch size 1*0
best_l after optimization: -0.04302099347114563 with beta sum per layer: [6.7141218185424805, 202.94281005859375, 195.42202758789062, 140.66888427734375, 0.0, 165.57647705078125]
alpha/beta optimization time: 1.4531681537628174
This batch time : update_bounds func: 1.7019	 prepare: 0.0881	 bound: 1.4536	 transfer: 0.1074	 finalize: 0.0518
Accumulated time: update_bounds func: 11.3731	 prepare: 0.3499	 bound: 10.3311	 transfer: 0.1074	 finalize: 0.2676
batch bounding time:  1.7024977207183838
Current worst splitting domains [lb, ub] (depth):
[-0.04527,   inf] (52), [-0.04509,   inf] (52), [-0.04385,   inf] (52), [-0.04309,   inf] (52), [-0.04309,   inf] (52), [-0.04305,   inf] (52), [-0.04208,   inf] (52), [-0.04068,   inf] (52), [-0.03861,   inf] (52), [-0.03848,   inf] (52), [-0.03843,   inf] (52), [-0.03776,   inf] (52), [-0.03762,   inf] (52), [-0.03750,   inf] (52), [-0.03743,   inf] (52), [-0.03718,   inf] (52), [-0.03691,   inf] (52), [-0.03686,   inf] (52), [-0.03662,   inf] (52), [-0.03643,   inf] (52), 
length of domains: 310
Total time: 2.0923	 pickout: 0.1353	 decision: 0.2109	 get_bound: 1.7032	 add_domain: 0.0429
Current lb:-0.045272231101989746
1682 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.81173300743103

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [1, 4329] [1, 4329] [1, 4329] [3, 2058] [3, 2077] [1, 4329] [3, 2434] [3, 2434] [1, 4329] [1, 4329] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: -3.5474178791046143 with beta sum per layer: [8.644678115844727, 159.40884399414062, 127.00105285644531, 161.99896240234375, 0.0, 182.68270874023438]
alpha/beta optimization time: 1.5719754695892334
This batch time : update_bounds func: 1.9259	 prepare: 0.0979	 bound: 1.5725	 transfer: 0.1216	 finalize: 0.1327
Accumulated time: update_bounds func: 13.2990	 prepare: 0.4479	 bound: 11.9036	 transfer: 0.1216	 finalize: 0.4004
batch bounding time:  1.926607370376587
Current worst splitting domains [lb, ub] (depth):
[-0.04526,   inf] (54), [-0.04509,   inf] (54), [-0.04384,   inf] (54), [-0.04304,   inf] (54), [-0.04231,   inf] (54), [-0.04228,   inf] (54), [-0.04208,   inf] (54), [-0.04149,   inf] (54), [-0.04068,   inf] (54), [-0.03861,   inf] (54), [-0.03846,   inf] (54), [-0.03842,   inf] (54), [-0.03774,   inf] (54), [-0.03762,   inf] (54), [-0.03742,   inf] (54), [-0.03718,   inf] (54), [-0.03690,   inf] (54), [-0.03685,   inf] (54), [-0.03645,   inf] (54), [-0.03630,   inf] (54), 
length of domains: 408
Total time: 2.3354	 pickout: 0.1312	 decision: 0.2289	 get_bound: 1.9274	 add_domain: 0.0479
Current lb:-0.04526233673095703
2194 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 19.156991720199585

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [2, 5434] [2, 5434] [2, 5434] [2, 5434] [2, 4508] [2, 4508] [2, 4508] [2, 4508] [2, 4508] [2, 5434] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: -4.503566265106201 with beta sum per layer: [8.711751937866211, 143.68753051757812, 171.75979614257812, 142.47573852539062, 0.0, 233.57632446289062]
alpha/beta optimization time: 1.565725564956665
This batch time : update_bounds func: 1.8738	 prepare: 0.0984	 bound: 1.5662	 transfer: 0.1482	 finalize: 0.0599
Accumulated time: update_bounds func: 15.1729	 prepare: 0.5462	 bound: 13.4699	 transfer: 0.1482	 finalize: 0.4603
batch bounding time:  1.8744511604309082
Current worst splitting domains [lb, ub] (depth):
[-0.04526,   inf] (56), [-0.04509,   inf] (56), [-0.04384,   inf] (56), [-0.04304,   inf] (56), [-0.04231,   inf] (56), [-0.04228,   inf] (56), [-0.04208,   inf] (56), [-0.04149,   inf] (56), [-0.04068,   inf] (56), [-0.03841,   inf] (56), [-0.03830,   inf] (56), [-0.03815,   inf] (56), [-0.03762,   inf] (56), [-0.03701,   inf] (56), [-0.03685,   inf] (56), [-0.03661,   inf] (56), [-0.03651,   inf] (56), [-0.03645,   inf] (56), [-0.03614,   inf] (56), [-0.03603,   inf] (56), 
length of domains: 496
Total time: 2.3184	 pickout: 0.1690	 decision: 0.2268	 get_bound: 1.8752	 add_domain: 0.0474
Current lb:-0.04526066780090332
2706 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 21.48457980155945

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 8351] [0, 8351] [3, 2434] [3, 2434] [2, 4588] [2, 5434] [2, 5434] [2, 5434] [2, 5434] [2, 5434] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: -5.292596817016602 with beta sum per layer: [8.84928035736084, 106.51659393310547, 175.26132202148438, 130.31967163085938, 0.0, 197.84683227539062]
alpha/beta optimization time: 1.561368703842163
This batch time : update_bounds func: 1.9466	 prepare: 0.0979	 bound: 1.5619	 transfer: 0.1487	 finalize: 0.1370
Accumulated time: update_bounds func: 17.1195	 prepare: 0.6442	 bound: 15.0317	 transfer: 0.1487	 finalize: 0.5973
batch bounding time:  1.9472322463989258
Current worst splitting domains [lb, ub] (depth):
[-0.04526,   inf] (58), [-0.04508,   inf] (58), [-0.04384,   inf] (58), [-0.04304,   inf] (58), [-0.04273,   inf] (58), [-0.04262,   inf] (58), [-0.04227,   inf] (58), [-0.04207,   inf] (58), [-0.04197,   inf] (58), [-0.04149,   inf] (58), [-0.04120,   inf] (58), [-0.04068,   inf] (58), [-0.03814,   inf] (58), [-0.03795,   inf] (58), [-0.03715,   inf] (58), [-0.03701,   inf] (58), [-0.03691,   inf] (58), [-0.03659,   inf] (58), [-0.03649,   inf] (58), [-0.03645,   inf] (58), 
length of domains: 651
Total time: 2.3749	 pickout: 0.1418	 decision: 0.2261	 get_bound: 1.9479	 add_domain: 0.0590
Current lb:-0.04525899887084961
3218 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 23.867493629455566

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 13112] [3, 2058] [0, 8351] [0, 8351] [0, 13112] [3, 2058] [1, 4329] [1, 4329] [2, 5434] [1, 4329] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 0.033394575119018555 with beta sum per layer: [11.280841827392578, 41.82215118408203, 155.8409423828125, 145.8663330078125, 0.0, 188.3643798828125]
alpha/beta optimization time: 1.5632965564727783
This batch time : update_bounds func: 1.8723	 prepare: 0.0988	 bound: 1.5638	 transfer: 0.1477	 finalize: 0.0608
Accumulated time: update_bounds func: 18.9917	 prepare: 0.7430	 bound: 16.5955	 transfer: 0.1477	 finalize: 0.6581
batch bounding time:  1.872868537902832
Current worst splitting domains [lb, ub] (depth):
[-0.04429,   inf] (60), [-0.04429,   inf] (60), [-0.04389,   inf] (60), [-0.04384,   inf] (60), [-0.04304,   inf] (60), [-0.04230,   inf] (60), [-0.04227,   inf] (60), [-0.04206,   inf] (60), [-0.04197,   inf] (60), [-0.04177,   inf] (60), [-0.04176,   inf] (60), [-0.04163,   inf] (60), [-0.04148,   inf] (60), [-0.04120,   inf] (60), [-0.04096,   inf] (60), [-0.04068,   inf] (60), [-0.03795,   inf] (60), [-0.03714,   inf] (60), [-0.03702,   inf] (60), [-0.03645,   inf] (60), 
length of domains: 792
Total time: 2.3145	 pickout: 0.1569	 decision: 0.2271	 get_bound: 1.8736	 add_domain: 0.0569
Current lb:-0.04429483413696289
3730 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 26.19099187850952

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [2, 4670] [2, 4670] [2, 4670] [2, 4670] [2, 4670] [2, 4670] [0, 8351] [0, 8351] [1, 4329] [2, 4670] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 9.335700988769531 with beta sum per layer: [15.904754638671875, 67.2587661743164, 177.03469848632812, 122.53295135498047, 0.0, 157.33828735351562]
alpha/beta optimization time: 1.5646171569824219
This batch time : update_bounds func: 1.8778	 prepare: 0.0985	 bound: 1.5651	 transfer: 0.1527	 finalize: 0.0602
Accumulated time: update_bounds func: 20.8695	 prepare: 0.8415	 bound: 18.1607	 transfer: 0.1527	 finalize: 0.7183
batch bounding time:  1.8783609867095947
Current worst splitting domains [lb, ub] (depth):
[-0.04428,   inf] (62), [-0.04428,   inf] (62), [-0.04382,   inf] (62), [-0.04382,   inf] (62), [-0.04302,   inf] (62), [-0.04228,   inf] (62), [-0.04226,   inf] (62), [-0.04206,   inf] (62), [-0.04196,   inf] (62), [-0.04175,   inf] (62), [-0.04174,   inf] (62), [-0.04150,   inf] (62), [-0.04148,   inf] (62), [-0.04119,   inf] (62), [-0.04094,   inf] (62), [-0.04068,   inf] (62), [-0.04008,   inf] (62), [-0.03963,   inf] (62), [-0.03934,   inf] (62), [-0.03853,   inf] (62), 
length of domains: 1015
Total time: 2.3836	 pickout: 0.1412	 decision: 0.2926	 get_bound: 1.8791	 add_domain: 0.0706
Current lb:-0.04427981376647949
4242 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 28.5824294090271

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 13055] [0, 13055] [0, 13055] [0, 13055] [0, 13055] [3, 2058] [0, 13112] [0, 13112] [0, 8351] [0, 13055] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 2.0335772037506104 with beta sum per layer: [16.512760162353516, 23.229808807373047, 187.03399658203125, 80.79623413085938, 0.0, 185.2776641845703]
alpha/beta optimization time: 1.5598299503326416
This batch time : update_bounds func: 1.8686	 prepare: 0.0991	 bound: 1.5603	 transfer: 0.1481	 finalize: 0.0598
Accumulated time: update_bounds func: 22.7381	 prepare: 0.9407	 bound: 19.7210	 transfer: 0.1481	 finalize: 0.7781
batch bounding time:  1.869206190109253
Current worst splitting domains [lb, ub] (depth):
[-0.04428,   inf] (64), [-0.04428,   inf] (64), [-0.04382,   inf] (64), [-0.04340,   inf] (64), [-0.04302,   inf] (64), [-0.04274,   inf] (64), [-0.04274,   inf] (64), [-0.04229,   inf] (64), [-0.04229,   inf] (64), [-0.04196,   inf] (64), [-0.04175,   inf] (64), [-0.04174,   inf] (64), [-0.04150,   inf] (64), [-0.04148,   inf] (64), [-0.04125,   inf] (64), [-0.04125,   inf] (64), [-0.04119,   inf] (64), [-0.04118,   inf] (64), [-0.04108,   inf] (64), [-0.04106,   inf] (64), 
length of domains: 1194
Total time: 2.3086	 pickout: 0.1459	 decision: 0.2278	 get_bound: 1.8700	 add_domain: 0.0649
Current lb:-0.04427933692932129
4754 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 30.899916172027588

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [3, 2077] [3, 2077] [0, 13112] [0, 13112] [0, 13112] [3, 2077] [3, 2077] [0, 13112] [0, 13112] [0, 13112] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 5.465818405151367 with beta sum per layer: [20.18416976928711, 3.453617811203003, 126.43038177490234, 44.01708221435547, 0.0, 132.06332397460938]
alpha/beta optimization time: 1.5601716041564941
This batch time : update_bounds func: 1.8781	 prepare: 0.0999	 bound: 1.5607	 transfer: 0.1530	 finalize: 0.0634
Accumulated time: update_bounds func: 24.6162	 prepare: 1.0405	 bound: 21.2818	 transfer: 0.1530	 finalize: 0.8415
batch bounding time:  1.8788056373596191
Current worst splitting domains [lb, ub] (depth):
[-0.04364,   inf] (66), [-0.04364,   inf] (66), [-0.04343,   inf] (66), [-0.04340,   inf] (66), [-0.04286,   inf] (66), [-0.04286,   inf] (66), [-0.04243,   inf] (66), [-0.04243,   inf] (66), [-0.04214,   inf] (66), [-0.04214,   inf] (66), [-0.04211,   inf] (66), [-0.04210,   inf] (66), [-0.04206,   inf] (66), [-0.04205,   inf] (66), [-0.04132,   inf] (66), [-0.04132,   inf] (66), [-0.04132,   inf] (66), [-0.04132,   inf] (66), [-0.04125,   inf] (66), [-0.04125,   inf] (66), 
length of domains: 1383
Total time: 2.3934	 pickout: 0.1436	 decision: 0.3009	 get_bound: 1.8796	 add_domain: 0.0693
Current lb:-0.04364156723022461
5266 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 33.30254578590393

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [2, 4588] [2, 4588] [2, 4574] [2, 4574] [2, 4574] [2, 4574] [2, 4574] [2, 4574] [2, 4574] [2, 4574] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 12.313369750976562 with beta sum per layer: [24.535926818847656, 0.9720410108566284, 85.37628936767578, 23.284496307373047, 0.0, 118.17561340332031]
alpha/beta optimization time: 1.559924602508545
This batch time : update_bounds func: 1.9689	 prepare: 0.0992	 bound: 1.5604	 transfer: 0.1484	 finalize: 0.1597
Accumulated time: update_bounds func: 26.5851	 prepare: 1.1398	 bound: 22.8422	 transfer: 0.1484	 finalize: 1.0012
batch bounding time:  1.9698195457458496
Current worst splitting domains [lb, ub] (depth):
[-0.04335,   inf] (68), [-0.04335,   inf] (68), [-0.04296,   inf] (68), [-0.04275,   inf] (68), [-0.04275,   inf] (68), [-0.04273,   inf] (68), [-0.04273,   inf] (68), [-0.04268,   inf] (68), [-0.04247,   inf] (68), [-0.04235,   inf] (68), [-0.04235,   inf] (68), [-0.04220,   inf] (68), [-0.04220,   inf] (68), [-0.04217,   inf] (68), [-0.04203,   inf] (68), [-0.04202,   inf] (68), [-0.04182,   inf] (68), [-0.04181,   inf] (68), [-0.04177,   inf] (68), [-0.04177,   inf] (68), 
length of domains: 1608
Total time: 2.4295	 pickout: 0.1541	 decision: 0.2288	 get_bound: 1.9707	 add_domain: 0.0758
Current lb:-0.0433497428894043
5778 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 35.74010515213013

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [2, 4574] [2, 4574] [1, 4457] [2, 4574] [2, 4574] [1, 4457] [1, 4457] [1, 4457] [1, 4457] [1, 4457] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: -2.7905516624450684 with beta sum per layer: [16.68398666381836, 0.0, 15.93326187133789, 12.648918151855469, 0.0, 104.96037292480469]
alpha/beta optimization time: 1.566051721572876
This batch time : update_bounds func: 1.8785	 prepare: 0.1024	 bound: 1.5666	 transfer: 0.1488	 finalize: 0.0596
Accumulated time: update_bounds func: 28.4636	 prepare: 1.2421	 bound: 24.4088	 transfer: 0.1488	 finalize: 1.0608
batch bounding time:  1.879124402999878
Current worst splitting domains [lb, ub] (depth):
[-0.04325,   inf] (70), [-0.04322,   inf] (70), [-0.04273,   inf] (70), [-0.04273,   inf] (70), [-0.04268,   inf] (70), [-0.04268,   inf] (70), [-0.04268,   inf] (70), [-0.04268,   inf] (70), [-0.04268,   inf] (70), [-0.04247,   inf] (70), [-0.04235,   inf] (70), [-0.04235,   inf] (70), [-0.04220,   inf] (70), [-0.04220,   inf] (70), [-0.04217,   inf] (70), [-0.04208,   inf] (70), [-0.04208,   inf] (70), [-0.04203,   inf] (70), [-0.04202,   inf] (70), [-0.04195,   inf] (70), 
length of domains: 1741
Total time: 2.3094	 pickout: 0.1402	 decision: 0.2277	 get_bound: 1.8799	 add_domain: 0.0616
Current lb:-0.04324721544981003
6290 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 38.05883836746216

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [1, 4457] [1, 4457] [2, 5419] [2, 5419] [1, 4457] [2, 5419] [1, 4457] [1, 4457] [1, 4457] [2, 5419] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 0.5264473557472229 with beta sum per layer: [17.023330688476562, 0.43654751777648926, 36.161659240722656, 7.544986724853516, 0.0, 116.49654388427734]
alpha/beta optimization time: 1.5627000331878662
This batch time : update_bounds func: 1.9635	 prepare: 0.1000	 bound: 1.5632	 transfer: 0.1519	 finalize: 0.1472
Accumulated time: update_bounds func: 30.4271	 prepare: 1.3421	 bound: 25.9720	 transfer: 0.1519	 finalize: 1.2080
batch bounding time:  1.964158535003662
Current worst splitting domains [lb, ub] (depth):
[-0.04322,   inf] (72), [-0.04302,   inf] (72), [-0.04273,   inf] (72), [-0.04272,   inf] (72), [-0.04268,   inf] (72), [-0.04268,   inf] (72), [-0.04268,   inf] (72), [-0.04268,   inf] (72), [-0.04266,   inf] (72), [-0.04247,   inf] (72), [-0.04235,   inf] (72), [-0.04233,   inf] (72), [-0.04220,   inf] (72), [-0.04218,   inf] (72), [-0.04215,   inf] (72), [-0.04208,   inf] (72), [-0.04208,   inf] (72), [-0.04202,   inf] (72), [-0.04201,   inf] (72), [-0.04195,   inf] (72), 
length of domains: 1901
Total time: 2.4301	 pickout: 0.1579	 decision: 0.2408	 get_bound: 1.9649	 add_domain: 0.0666
Current lb:-0.04321634769439697
6802 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 40.49827837944031

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [2, 5419] [2, 5419] [3, 2077] [3, 2077] [2, 5419] [2, 5419] [2, 5419] [2, 5419] [3, 2058] [0, 13111] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 13.699980735778809 with beta sum per layer: [18.594505310058594, 1.9739196300506592, 72.09040832519531, 10.625356674194336, 0.0, 158.498779296875]
alpha/beta optimization time: 1.5653245449066162
This batch time : update_bounds func: 1.8745	 prepare: 0.0999	 bound: 1.5661	 transfer: 0.1476	 finalize: 0.0598
Accumulated time: update_bounds func: 32.3016	 prepare: 1.4420	 bound: 27.5380	 transfer: 0.1476	 finalize: 1.2679
batch bounding time:  1.8752262592315674
Current worst splitting domains [lb, ub] (depth):
[-0.04322,   inf] (74), [-0.04300,   inf] (74), [-0.04268,   inf] (74), [-0.04268,   inf] (74), [-0.04266,   inf] (74), [-0.04266,   inf] (74), [-0.04247,   inf] (74), [-0.04236,   inf] (74), [-0.04232,   inf] (74), [-0.04210,   inf] (74), [-0.04208,   inf] (74), [-0.04208,   inf] (74), [-0.04206,   inf] (74), [-0.04202,   inf] (74), [-0.04201,   inf] (74), [-0.04199,   inf] (74), [-0.04198,   inf] (74), [-0.04197,   inf] (74), [-0.04195,   inf] (74), [-0.04190,   inf] (74), 
length of domains: 2120
Total time: 2.3254	 pickout: 0.1416	 decision: 0.2306	 get_bound: 1.8760	 add_domain: 0.0772
Current lb:-0.04321599006652832
7314 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 42.833439111709595

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 13111] [3, 2058] [0, 13111] [0, 13111] [0, 13111] [0, 13111] [3, 1531] [3, 1531] [3, 1531] [2, 4588] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 16.66046714782715 with beta sum per layer: [11.597892761230469, 12.126063346862793, 54.69026184082031, 15.819993019104004, 0.0, 90.30425262451172]
alpha/beta optimization time: 1.5913786888122559
This batch time : update_bounds func: 2.0698	 prepare: 0.1348	 bound: 1.5919	 transfer: 0.1543	 finalize: 0.0640
Accumulated time: update_bounds func: 34.3714	 prepare: 1.5768	 bound: 29.1300	 transfer: 0.1543	 finalize: 1.3319
batch bounding time:  2.070490598678589
Current worst splitting domains [lb, ub] (depth):
[-0.04322,   inf] (76), [-0.04272,   inf] (76), [-0.04268,   inf] (76), [-0.04268,   inf] (76), [-0.04266,   inf] (76), [-0.04266,   inf] (76), [-0.04246,   inf] (76), [-0.04218,   inf] (76), [-0.04217,   inf] (76), [-0.04216,   inf] (76), [-0.04216,   inf] (76), [-0.04208,   inf] (76), [-0.04207,   inf] (76), [-0.04206,   inf] (76), [-0.04202,   inf] (76), [-0.04200,   inf] (76), [-0.04196,   inf] (76), [-0.04193,   inf] (76), [-0.04192,   inf] (76), [-0.04188,   inf] (76), 
length of domains: 2346
Total time: 2.5287	 pickout: 0.1409	 decision: 0.2366	 get_bound: 2.0713	 add_domain: 0.0799
Current lb:-0.04321599006652832
7826 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 45.37105989456177

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [3, 1531] [3, 1531] [3, 1531] [3, 1531] [3, 1531] [3, 1531] [1, 4401] [3, 1531] [3, 1531] [3, 1531] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: -1.9163837432861328 with beta sum per layer: [7.939589500427246, 12.544281005859375, 31.76023292541504, 25.807241439819336, 0.0, 71.83113098144531]
alpha/beta optimization time: 1.570465087890625
This batch time : update_bounds func: 1.8797	 prepare: 0.0989	 bound: 1.5710	 transfer: 0.1481	 finalize: 0.0606
Accumulated time: update_bounds func: 36.2511	 prepare: 1.6757	 bound: 30.7010	 transfer: 0.1481	 finalize: 1.3925
batch bounding time:  1.8803210258483887
Current worst splitting domains [lb, ub] (depth):
[-0.04320,   inf] (78), [-0.04270,   inf] (78), [-0.04267,   inf] (78), [-0.04267,   inf] (78), [-0.04265,   inf] (78), [-0.04265,   inf] (78), [-0.04246,   inf] (78), [-0.04217,   inf] (78), [-0.04216,   inf] (78), [-0.04216,   inf] (78), [-0.04208,   inf] (78), [-0.04207,   inf] (78), [-0.04205,   inf] (78), [-0.04205,   inf] (78), [-0.04202,   inf] (78), [-0.04200,   inf] (78), [-0.04196,   inf] (78), [-0.04193,   inf] (78), [-0.04180,   inf] (78), [-0.04178,   inf] (78), 
length of domains: 2469
Total time: 2.3163	 pickout: 0.1417	 decision: 0.2289	 get_bound: 1.8811	 add_domain: 0.0646
Current lb:-0.043199777603149414
8338 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 47.69749855995178

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [1, 4401] [1, 4401] [1, 4401] [1, 4401] [1, 4401] [1, 4401] [1, 1335] [1, 4401] [1, 4401] [1, 4401] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: -22.552120208740234 with beta sum per layer: [7.7258124351501465, 35.85099792480469, 16.74822998046875, 13.309040069580078, 0.0, 77.49713134765625]
alpha/beta optimization time: 1.5742485523223877
This batch time : update_bounds func: 1.8861	 prepare: 0.1015	 bound: 1.5748	 transfer: 0.1483	 finalize: 0.0601
Accumulated time: update_bounds func: 38.1372	 prepare: 1.7772	 bound: 32.2758	 transfer: 0.1483	 finalize: 1.4527
batch bounding time:  1.8867781162261963
Current worst splitting domains [lb, ub] (depth):
[-0.04320,   inf] (80), [-0.04270,   inf] (80), [-0.04267,   inf] (80), [-0.04266,   inf] (80), [-0.04265,   inf] (80), [-0.04265,   inf] (80), [-0.04246,   inf] (80), [-0.04217,   inf] (80), [-0.04216,   inf] (80), [-0.04216,   inf] (80), [-0.04208,   inf] (80), [-0.04207,   inf] (80), [-0.04205,   inf] (80), [-0.04205,   inf] (80), [-0.04202,   inf] (80), [-0.04200,   inf] (80), [-0.04196,   inf] (80), [-0.04192,   inf] (80), [-0.04180,   inf] (80), [-0.04178,   inf] (80), 
length of domains: 2503
Total time: 2.4163	 pickout: 0.1418	 decision: 0.3371	 get_bound: 1.8875	 add_domain: 0.0498
Current lb:-0.043199777603149414
8850 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 50.124308586120605

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [1, 1335] [1, 1335] [1, 1335] [1, 1335] [1, 1335] [1, 1335] [0, 8245] [1, 1335] [1, 1335] [1, 1335] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: -5.3824005126953125 with beta sum per layer: [9.180451393127441, 50.57709884643555, 11.873205184936523, 23.117502212524414, 0.0, 63.852378845214844]
alpha/beta optimization time: 1.5870165824890137
This batch time : update_bounds func: 1.9033	 prepare: 0.1003	 bound: 1.5876	 transfer: 0.1538	 finalize: 0.0605
Accumulated time: update_bounds func: 40.0405	 prepare: 1.8774	 bound: 33.8633	 transfer: 0.1538	 finalize: 1.5132
batch bounding time:  1.9039180278778076
Current worst splitting domains [lb, ub] (depth):
[-0.04319,   inf] (82), [-0.04270,   inf] (82), [-0.04266,   inf] (82), [-0.04266,   inf] (82), [-0.04265,   inf] (82), [-0.04264,   inf] (82), [-0.04246,   inf] (82), [-0.04217,   inf] (82), [-0.04215,   inf] (82), [-0.04215,   inf] (82), [-0.04207,   inf] (82), [-0.04207,   inf] (82), [-0.04205,   inf] (82), [-0.04204,   inf] (82), [-0.04202,   inf] (82), [-0.04200,   inf] (82), [-0.04196,   inf] (82), [-0.04192,   inf] (82), [-0.04179,   inf] (82), [-0.04177,   inf] (82), 
length of domains: 2582
Total time: 2.3392	 pickout: 0.1472	 decision: 0.2287	 get_bound: 1.9048	 add_domain: 0.0585
Current lb:-0.04319405555725098
9362 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 52.473716735839844

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 8245] [0, 8245] [0, 8245] [0, 8245] [0, 8245] [0, 8245] [0, 12949] [0, 8245] [0, 8245] [0, 8245] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 8.885568618774414 with beta sum per layer: [6.700176239013672, 5.841747283935547, 11.353126525878906, 8.962177276611328, 0.0, 42.45002746582031]
alpha/beta optimization time: 1.5651519298553467
This batch time : update_bounds func: 1.8800	 prepare: 0.1003	 bound: 1.5657	 transfer: 0.1512	 finalize: 0.0616
Accumulated time: update_bounds func: 41.9205	 prepare: 1.9778	 bound: 35.4290	 transfer: 0.1512	 finalize: 1.5748
batch bounding time:  1.880709171295166
Current worst splitting domains [lb, ub] (depth):
[-0.04319,   inf] (84), [-0.04270,   inf] (84), [-0.04266,   inf] (84), [-0.04266,   inf] (84), [-0.04265,   inf] (84), [-0.04264,   inf] (84), [-0.04246,   inf] (84), [-0.04216,   inf] (84), [-0.04215,   inf] (84), [-0.04215,   inf] (84), [-0.04207,   inf] (84), [-0.04205,   inf] (84), [-0.04204,   inf] (84), [-0.04202,   inf] (84), [-0.04200,   inf] (84), [-0.04196,   inf] (84), [-0.04192,   inf] (84), [-0.04179,   inf] (84), [-0.04177,   inf] (84), [-0.04172,   inf] (84), 
length of domains: 2779
Total time: 2.4490	 pickout: 0.1459	 decision: 0.3418	 get_bound: 1.8815	 add_domain: 0.0799
Current lb:-0.04319357872009277
9874 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 54.931753158569336

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 12949] [0, 12949] [0, 12949] [0, 12949] [0, 12949] [0, 12949] [3, 2058] [0, 12949] [0, 12949] [0, 12949] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 16.51291847229004 with beta sum per layer: [15.475249290466309, 3.767998218536377, 1.1555691957473755, 9.549894332885742, 0.0, 12.225757598876953]
alpha/beta optimization time: 1.5583407878875732
This batch time : update_bounds func: 1.8727	 prepare: 0.1009	 bound: 1.5588	 transfer: 0.1502	 finalize: 0.0616
Accumulated time: update_bounds func: 43.7932	 prepare: 2.0787	 bound: 36.9879	 transfer: 0.1502	 finalize: 1.6363
batch bounding time:  1.8733689785003662
Current worst splitting domains [lb, ub] (depth):
[-0.04319,   inf] (86), [-0.04270,   inf] (86), [-0.04266,   inf] (86), [-0.04266,   inf] (86), [-0.04264,   inf] (86), [-0.04264,   inf] (86), [-0.04216,   inf] (86), [-0.04215,   inf] (86), [-0.04215,   inf] (86), [-0.04210,   inf] (86), [-0.04207,   inf] (86), [-0.04205,   inf] (86), [-0.04204,   inf] (86), [-0.04201,   inf] (86), [-0.04200,   inf] (86), [-0.04179,   inf] (86), [-0.04177,   inf] (86), [-0.04172,   inf] (86), [-0.04171,   inf] (86), [-0.04162,   inf] (86), 
length of domains: 3004
Total time: 2.4587	 pickout: 0.1476	 decision: 0.2294	 get_bound: 1.8741	 add_domain: 0.2075
Current lb:-0.04319310188293457
10386 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 57.399895668029785

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 8072] [0, 8072] [0, 8072] [0, 8072] [0, 8072] [0, 8072] [0, 8072] [0, 8072] [0, 8072] [0, 8072] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 15.019657135009766 with beta sum per layer: [14.404648780822754, 2.607450246810913, 1.762087345123291, 8.384819984436035, 0.0, 0.0]
alpha/beta optimization time: 1.5591356754302979
This batch time : update_bounds func: 1.8698	 prepare: 0.1007	 bound: 1.5596	 transfer: 0.1474	 finalize: 0.0609
Accumulated time: update_bounds func: 45.6630	 prepare: 2.1793	 bound: 38.5475	 transfer: 0.1474	 finalize: 1.6973
batch bounding time:  1.8704562187194824
Current worst splitting domains [lb, ub] (depth):
[-0.04319,   inf] (88), [-0.04275,   inf] (88), [-0.04269,   inf] (88), [-0.04266,   inf] (88), [-0.04266,   inf] (88), [-0.04264,   inf] (88), [-0.04264,   inf] (88), [-0.04225,   inf] (88), [-0.04221,   inf] (88), [-0.04221,   inf] (88), [-0.04219,   inf] (88), [-0.04219,   inf] (88), [-0.04216,   inf] (88), [-0.04215,   inf] (88), [-0.04215,   inf] (88), [-0.04210,   inf] (88), [-0.04207,   inf] (88), [-0.04205,   inf] (88), [-0.04204,   inf] (88), [-0.04201,   inf] (88), 
length of domains: 3227
Total time: 2.3277	 pickout: 0.1406	 decision: 0.2283	 get_bound: 1.8713	 add_domain: 0.0875
Current lb:-0.04319119453430176
10898 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 59.73675775527954

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 12776] [0, 12776] [0, 12776] [0, 12776] [0, 12776] [0, 12776] [0, 12776] [0, 12776] [0, 12776] [0, 12776] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 18.329532623291016 with beta sum per layer: [9.53857421875, 4.653538703918457, 1.9109686613082886, 7.5957865715026855, 0.0, 0.0]
alpha/beta optimization time: 1.5591850280761719
This batch time : update_bounds func: 1.8704	 prepare: 0.1007	 bound: 1.5597	 transfer: 0.1488	 finalize: 0.0598
Accumulated time: update_bounds func: 47.5334	 prepare: 2.2801	 bound: 40.1072	 transfer: 0.1488	 finalize: 1.7571
batch bounding time:  1.8710501194000244
Current worst splitting domains [lb, ub] (depth):
[-0.04319,   inf] (90), [-0.04275,   inf] (90), [-0.04275,   inf] (90), [-0.04269,   inf] (90), [-0.04266,   inf] (90), [-0.04266,   inf] (90), [-0.04264,   inf] (90), [-0.04264,   inf] (90), [-0.04231,   inf] (90), [-0.04226,   inf] (90), [-0.04225,   inf] (90), [-0.04222,   inf] (90), [-0.04222,   inf] (90), [-0.04221,   inf] (90), [-0.04221,   inf] (90), [-0.04220,   inf] (90), [-0.04220,   inf] (90), [-0.04219,   inf] (90), [-0.04219,   inf] (90), [-0.04216,   inf] (90), 
length of domains: 3458
Total time: 2.4789	 pickout: 0.1504	 decision: 0.2285	 get_bound: 1.8719	 add_domain: 0.2281
Current lb:-0.04319119453430176
11410 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 62.224762201309204

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [3, 2058] [3, 2058] [3, 2058] [3, 2058] [1, 1276] [3, 2058] [1, 1276] [3, 2058] [3, 2058] [3, 2058] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 17.88104820251465 with beta sum per layer: [9.402627944946289, 2.1557445526123047, 3.9082601070404053, 24.868343353271484, 0.0, 0.0]
alpha/beta optimization time: 1.5600676536560059
This batch time : update_bounds func: 1.8704	 prepare: 0.0999	 bound: 1.5606	 transfer: 0.1481	 finalize: 0.0607
Accumulated time: update_bounds func: 49.4038	 prepare: 2.3800	 bound: 41.6678	 transfer: 0.1481	 finalize: 1.8178
batch bounding time:  1.8710260391235352
Current worst splitting domains [lb, ub] (depth):
[-0.04265,   inf] (92), [-0.04263,   inf] (92), [-0.04241,   inf] (92), [-0.04239,   inf] (92), [-0.04237,   inf] (92), [-0.04235,   inf] (92), [-0.04235,   inf] (92), [-0.04221,   inf] (92), [-0.04220,   inf] (92), [-0.04219,   inf] (92), [-0.04218,   inf] (92), [-0.04215,   inf] (92), [-0.04214,   inf] (92), [-0.04214,   inf] (92), [-0.04205,   inf] (92), [-0.04204,   inf] (92), [-0.04204,   inf] (92), [-0.04203,   inf] (92), [-0.04197,   inf] (92), [-0.04197,   inf] (92), 
length of domains: 3670
Total time: 2.3321	 pickout: 0.1431	 decision: 0.2295	 get_bound: 1.8719	 add_domain: 0.0876
Current lb:-0.04264950752258301
11922 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 64.5665717124939

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [1, 4356] [1, 4356] [1, 4356] [1, 4356] [1, 4356] [1, 4356] [1, 4356] [1, 4356] [1, 4356] [1, 4356] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 18.282718658447266 with beta sum per layer: [5.08639669418335, 1.5493724346160889, 7.246548652648926, 8.620796203613281, 0.0, 0.0]
alpha/beta optimization time: 1.5599830150604248
This batch time : update_bounds func: 1.8740	 prepare: 0.0999	 bound: 1.5605	 transfer: 0.1510	 finalize: 0.0615
Accumulated time: update_bounds func: 51.2779	 prepare: 2.4799	 bound: 43.2283	 transfer: 0.1510	 finalize: 1.8793
batch bounding time:  1.8746881484985352
Current worst splitting domains [lb, ub] (depth):
[-0.04259,   inf] (94), [-0.04257,   inf] (94), [-0.04235,   inf] (94), [-0.04233,   inf] (94), [-0.04229,   inf] (94), [-0.04228,   inf] (94), [-0.04227,   inf] (94), [-0.04225,   inf] (94), [-0.04215,   inf] (94), [-0.04214,   inf] (94), [-0.04213,   inf] (94), [-0.04212,   inf] (94), [-0.04209,   inf] (94), [-0.04208,   inf] (94), [-0.04207,   inf] (94), [-0.04203,   inf] (94), [-0.04201,   inf] (94), [-0.04199,   inf] (94), [-0.04199,   inf] (94), [-0.04198,   inf] (94), 
length of domains: 3887
Total time: 2.4843	 pickout: 0.1405	 decision: 0.2285	 get_bound: 1.8755	 add_domain: 0.2397
Current lb:-0.042586565017700195
12434 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 67.06049728393555

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [3, 1783] [3, 1783] [3, 1783] [3, 1783] [3, 1783] [3, 1783] [3, 1783] [3, 1783] [3, 1783] [3, 1783] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 12.778474807739258 with beta sum per layer: [16.27898597717285, 10.086621284484863, 28.39167022705078, 48.10796356201172, 0.0, 0.0]
alpha/beta optimization time: 1.5711405277252197
This batch time : update_bounds func: 1.8917	 prepare: 0.1012	 bound: 1.5717	 transfer: 0.1539	 finalize: 0.0637
Accumulated time: update_bounds func: 53.1695	 prepare: 2.5811	 bound: 44.7999	 transfer: 0.1539	 finalize: 1.9431
batch bounding time:  1.8923778533935547
Current worst splitting domains [lb, ub] (depth):
[-0.04257,   inf] (96), [-0.04255,   inf] (96), [-0.04233,   inf] (96), [-0.04231,   inf] (96), [-0.04227,   inf] (96), [-0.04226,   inf] (96), [-0.04225,   inf] (96), [-0.04223,   inf] (96), [-0.04213,   inf] (96), [-0.04212,   inf] (96), [-0.04211,   inf] (96), [-0.04210,   inf] (96), [-0.04207,   inf] (96), [-0.04205,   inf] (96), [-0.04205,   inf] (96), [-0.04201,   inf] (96), [-0.04199,   inf] (96), [-0.04197,   inf] (96), [-0.04197,   inf] (96), [-0.04195,   inf] (96), 
length of domains: 4016
Total time: 2.3416	 pickout: 0.1410	 decision: 0.2295	 get_bound: 1.8933	 add_domain: 0.0778
Current lb:-0.04256772994995117
12946 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 69.41380286216736

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [2, 5349] [2, 5349] [2, 5349] [2, 5349] [2, 5349] [2, 5349] [1, 4442] [1, 4442] [2, 5349] [2, 5349] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 20.121143341064453 with beta sum per layer: [1.8189687728881836, 5.606910705566406, 0.19479301571846008, 5.022936820983887, 0.0, 0.0]
alpha/beta optimization time: 1.5504686832427979
This batch time : update_bounds func: 1.8655	 prepare: 0.1011	 bound: 1.5510	 transfer: 0.1509	 finalize: 0.0614
Accumulated time: update_bounds func: 55.0351	 prepare: 2.6821	 bound: 46.3510	 transfer: 0.1509	 finalize: 2.0044
batch bounding time:  1.8663065433502197
Current worst splitting domains [lb, ub] (depth):
[-0.04252,   inf] (98), [-0.04250,   inf] (98), [-0.04228,   inf] (98), [-0.04226,   inf] (98), [-0.04222,   inf] (98), [-0.04221,   inf] (98), [-0.04218,   inf] (98), [-0.04217,   inf] (98), [-0.04208,   inf] (98), [-0.04207,   inf] (98), [-0.04206,   inf] (98), [-0.04205,   inf] (98), [-0.04202,   inf] (98), [-0.04202,   inf] (98), [-0.04200,   inf] (98), [-0.04200,   inf] (98), [-0.04200,   inf] (98), [-0.04195,   inf] (98), [-0.04194,   inf] (98), [-0.04193,   inf] (98), 
length of domains: 4255
Total time: 2.3343	 pickout: 0.1409	 decision: 0.2294	 get_bound: 1.8671	 add_domain: 0.0970
Current lb:-0.042516231536865234
13458 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 71.75700402259827

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [2, 5450] [2, 5450] [2, 5450] [2, 5450] [2, 5450] [2, 5450] [2, 5450] [2, 5450] [2, 5450] [2, 5450] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 10.223786354064941 with beta sum per layer: [0.8231485486030579, 1.2255128622055054, 0.2318267524242401, 0.5995296239852905, 0.0, 0.0]
alpha/beta optimization time: 1.5643937587738037
This batch time : update_bounds func: 2.0801	 prepare: 0.1023	 bound: 1.5649	 transfer: 0.1479	 finalize: 0.0597
Accumulated time: update_bounds func: 57.1152	 prepare: 2.7844	 bound: 47.9159	 transfer: 0.1479	 finalize: 2.0642
batch bounding time:  2.0808181762695312
Current worst splitting domains [lb, ub] (depth):
[-0.04252,   inf] (100), [-0.04250,   inf] (100), [-0.04228,   inf] (100), [-0.04226,   inf] (100), [-0.04222,   inf] (100), [-0.04221,   inf] (100), [-0.04218,   inf] (100), [-0.04217,   inf] (100), [-0.04208,   inf] (100), [-0.04207,   inf] (100), [-0.04206,   inf] (100), [-0.04205,   inf] (100), [-0.04202,   inf] (100), [-0.04202,   inf] (100), [-0.04200,   inf] (100), [-0.04200,   inf] (100), [-0.04200,   inf] (100), [-0.04195,   inf] (100), [-0.04193,   inf] (100), [-0.04193,   inf] (100), 
length of domains: 4346
Total time: 2.5229	 pickout: 0.1424	 decision: 0.2294	 get_bound: 2.0817	 add_domain: 0.0694
Current lb:-0.042516231536865234
13970 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 74.29122400283813

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [1, 4442] [1, 4442] [1, 4442] [1, 4442] [1, 1276] [1, 1276] [1, 4442] [1, 4442] [1, 4442] [1, 4442] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 20.822452545166016 with beta sum per layer: [2.8414440155029297, 12.37536907196045, 8.482378959655762, 11.126598358154297, 0.0, 0.0]
alpha/beta optimization time: 1.541872501373291
This batch time : update_bounds func: 1.8509	 prepare: 0.0996	 bound: 1.5424	 transfer: 0.1483	 finalize: 0.0593
Accumulated time: update_bounds func: 58.9660	 prepare: 2.8840	 bound: 49.4583	 transfer: 0.1483	 finalize: 2.1235
batch bounding time:  1.8515210151672363
Current worst splitting domains [lb, ub] (depth):
[-0.04229,   inf] (102), [-0.04227,   inf] (102), [-0.04220,   inf] (102), [-0.04220,   inf] (102), [-0.04208,   inf] (102), [-0.04207,   inf] (102), [-0.04206,   inf] (102), [-0.04205,   inf] (102), [-0.04205,   inf] (102), [-0.04204,   inf] (102), [-0.04197,   inf] (102), [-0.04196,   inf] (102), [-0.04196,   inf] (102), [-0.04195,   inf] (102), [-0.04194,   inf] (102), [-0.04194,   inf] (102), [-0.04193,   inf] (102), [-0.04193,   inf] (102), [-0.04191,   inf] (102), [-0.04189,   inf] (102), 
length of domains: 4594
Total time: 2.3243	 pickout: 0.1422	 decision: 0.2290	 get_bound: 1.8523	 add_domain: 0.1007
Current lb:-0.04228949546813965
14482 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 76.62472009658813

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [3, 2058] [3, 2058] [1, 4442] [1, 4442] [0, 13085] [0, 13085] [0, 13085] [3, 2058] [0, 13085] [3, 2058] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 12.968340873718262 with beta sum per layer: [55.544891357421875, 39.41621780395508, 44.41324996948242, 66.8577651977539, 0.0, 0.0]
alpha/beta optimization time: 1.5587964057922363
This batch time : update_bounds func: 2.0246	 prepare: 0.0990	 bound: 1.5593	 transfer: 0.1471	 finalize: 0.2181
Accumulated time: update_bounds func: 60.9907	 prepare: 2.9830	 bound: 51.0176	 transfer: 0.1471	 finalize: 2.3415
batch bounding time:  2.025320053100586
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (104), [-0.04220,   inf] (104), [-0.04219,   inf] (104), [-0.04217,   inf] (104), [-0.04208,   inf] (104), [-0.04207,   inf] (104), [-0.04206,   inf] (104), [-0.04205,   inf] (104), [-0.04198,   inf] (104), [-0.04197,   inf] (104), [-0.04197,   inf] (104), [-0.04196,   inf] (104), [-0.04195,   inf] (104), [-0.04193,   inf] (104), [-0.04193,   inf] (104), [-0.04193,   inf] (104), [-0.04187,   inf] (104), [-0.04186,   inf] (104), [-0.04185,   inf] (104), [-0.04185,   inf] (104), 
length of domains: 4690
Total time: 2.4699	 pickout: 0.1436	 decision: 0.2289	 get_bound: 2.0261	 add_domain: 0.0713
Current lb:-0.04220390319824219
14994 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 79.10557913780212

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 13085] [0, 13085] [3, 2430] [0, 7958] [0, 8381] [0, 8381] [0, 8381] [0, 8381] [2, 4593] [3, 2430] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 17.82003402709961 with beta sum per layer: [6.953683376312256, 19.350666046142578, 9.381399154663086, 13.208365440368652, 0.0, 0.0]
alpha/beta optimization time: 1.5608153343200684
This batch time : update_bounds func: 1.8716	 prepare: 0.0997	 bound: 1.5613	 transfer: 0.1492	 finalize: 0.0602
Accumulated time: update_bounds func: 62.8623	 prepare: 3.0827	 bound: 52.5789	 transfer: 0.1492	 finalize: 2.4018
batch bounding time:  1.8722736835479736
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (106), [-0.04220,   inf] (106), [-0.04219,   inf] (106), [-0.04217,   inf] (106), [-0.04217,   inf] (106), [-0.04208,   inf] (106), [-0.04208,   inf] (106), [-0.04207,   inf] (106), [-0.04207,   inf] (106), [-0.04206,   inf] (106), [-0.04205,   inf] (106), [-0.04198,   inf] (106), [-0.04197,   inf] (106), [-0.04197,   inf] (106), [-0.04196,   inf] (106), [-0.04195,   inf] (106), [-0.04193,   inf] (106), [-0.04193,   inf] (106), [-0.04190,   inf] (106), [-0.04188,   inf] (106), 
length of domains: 4905
Total time: 2.3417	 pickout: 0.1419	 decision: 0.2297	 get_bound: 1.8731	 add_domain: 0.0971
Current lb:-0.04220390319824219
15506 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 81.45672273635864

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 8381] [0, 8381] [0, 13229] [2, 4593] [2, 4593] [0, 8382] [0, 8382] [0, 8382] [0, 8382] [0, 8382] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 9.851424217224121 with beta sum per layer: [6.922517776489258, 9.820699691772461, 4.397910118103027, 10.002728462219238, 0.0, 0.0]
alpha/beta optimization time: 1.5646121501922607
This batch time : update_bounds func: 1.8789	 prepare: 0.0995	 bound: 1.5652	 transfer: 0.1523	 finalize: 0.0607
Accumulated time: update_bounds func: 64.7412	 prepare: 3.1823	 bound: 54.1441	 transfer: 0.1523	 finalize: 2.4625
batch bounding time:  1.8795750141143799
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (108), [-0.04220,   inf] (108), [-0.04219,   inf] (108), [-0.04219,   inf] (108), [-0.04217,   inf] (108), [-0.04217,   inf] (108), [-0.04208,   inf] (108), [-0.04208,   inf] (108), [-0.04208,   inf] (108), [-0.04207,   inf] (108), [-0.04207,   inf] (108), [-0.04207,   inf] (108), [-0.04206,   inf] (108), [-0.04206,   inf] (108), [-0.04205,   inf] (108), [-0.04205,   inf] (108), [-0.04198,   inf] (108), [-0.04197,   inf] (108), [-0.04197,   inf] (108), [-0.04196,   inf] (108), 
length of domains: 4989
Total time: 2.3272	 pickout: 0.1444	 decision: 0.2310	 get_bound: 1.8804	 add_domain: 0.0713
Current lb:-0.04220390319824219
16018 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 83.79546403884888

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 8382] [0, 8382] [2, 4528] [2, 4593] [3, 2430] [0, 13229] [0, 13086] [0, 13086] [0, 13086] [0, 13086] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 17.71987533569336 with beta sum per layer: [12.284509658813477, 6.955432415008545, 2.7520158290863037, 12.1876859664917, 0.0, 0.0]
alpha/beta optimization time: 1.5597922801971436
This batch time : update_bounds func: 1.8680	 prepare: 0.0996	 bound: 1.5603	 transfer: 0.1477	 finalize: 0.0592
Accumulated time: update_bounds func: 66.6092	 prepare: 3.2818	 bound: 55.7044	 transfer: 0.1477	 finalize: 2.5217
batch bounding time:  1.8686432838439941
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (110), [-0.04220,   inf] (110), [-0.04220,   inf] (110), [-0.04220,   inf] (110), [-0.04219,   inf] (110), [-0.04219,   inf] (110), [-0.04219,   inf] (110), [-0.04217,   inf] (110), [-0.04217,   inf] (110), [-0.04212,   inf] (110), [-0.04208,   inf] (110), [-0.04208,   inf] (110), [-0.04208,   inf] (110), [-0.04208,   inf] (110), [-0.04208,   inf] (110), [-0.04207,   inf] (110), [-0.04207,   inf] (110), [-0.04207,   inf] (110), [-0.04207,   inf] (110), [-0.04207,   inf] (110), 
length of domains: 5189
Total time: 2.4978	 pickout: 0.1416	 decision: 0.3910	 get_bound: 1.8695	 add_domain: 0.0958
Current lb:-0.04220390319824219
16530 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 86.30365514755249

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 13086] [0, 13086] [0, 13086] [0, 13086] [0, 7958] [0, 7958] [0, 7958] [0, 13230] [3, 2430] [0, 13230] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 17.81450653076172 with beta sum per layer: [44.471370697021484, 21.384654998779297, 13.774921417236328, 40.9281120300293, 0.0, 0.0]
alpha/beta optimization time: 1.5614945888519287
This batch time : update_bounds func: 1.8699	 prepare: 0.0991	 bound: 1.5622	 transfer: 0.1484	 finalize: 0.0590
Accumulated time: update_bounds func: 68.4790	 prepare: 3.3809	 bound: 57.2666	 transfer: 0.1484	 finalize: 2.5807
batch bounding time:  1.8705580234527588
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (112), [-0.04220,   inf] (112), [-0.04220,   inf] (112), [-0.04220,   inf] (112), [-0.04220,   inf] (112), [-0.04220,   inf] (112), [-0.04220,   inf] (112), [-0.04220,   inf] (112), [-0.04219,   inf] (112), [-0.04219,   inf] (112), [-0.04219,   inf] (112), [-0.04219,   inf] (112), [-0.04218,   inf] (112), [-0.04217,   inf] (112), [-0.04217,   inf] (112), [-0.04212,   inf] (112), [-0.04212,   inf] (112), [-0.04208,   inf] (112), [-0.04208,   inf] (112), [-0.04208,   inf] (112), 
length of domains: 5420
Total time: 2.3490	 pickout: 0.1447	 decision: 0.2289	 get_bound: 1.8714	 add_domain: 0.1040
Current lb:-0.04220390319824219
17042 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 88.66251873970032

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 13113] [0, 13113] [0, 13113] [0, 13113] [0, 13113] [0, 13113] [0, 13113] [0, 13113] [2, 4636] [0, 8024] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 15.736099243164062 with beta sum per layer: [74.893798828125, 44.33826446533203, 27.182010650634766, 104.15957641601562, 0.0, 0.0]
alpha/beta optimization time: 1.5686275959014893
This batch time : update_bounds func: 1.8771	 prepare: 0.0989	 bound: 1.5692	 transfer: 0.1487	 finalize: 0.0593
Accumulated time: update_bounds func: 70.3561	 prepare: 3.4798	 bound: 58.8357	 transfer: 0.1487	 finalize: 2.6400
batch bounding time:  1.8778114318847656
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (114), [-0.04220,   inf] (114), [-0.04220,   inf] (114), [-0.04220,   inf] (114), [-0.04220,   inf] (114), [-0.04220,   inf] (114), [-0.04220,   inf] (114), [-0.04220,   inf] (114), [-0.04220,   inf] (114), [-0.04220,   inf] (114), [-0.04220,   inf] (114), [-0.04220,   inf] (114), [-0.04220,   inf] (114), [-0.04220,   inf] (114), [-0.04220,   inf] (114), [-0.04220,   inf] (114), [-0.04219,   inf] (114), [-0.04219,   inf] (114), [-0.04219,   inf] (114), [-0.04218,   inf] (114), 
length of domains: 5662
Total time: 2.5370	 pickout: 0.1435	 decision: 0.2289	 get_bound: 1.8786	 add_domain: 0.2859
Current lb:-0.04220390319824219
17554 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 91.2097806930542

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [2, 4593] [0, 13229] [2, 4593] [2, 4593] [2, 4593] [2, 4593] [2, 4593] [2, 4593] [0, 13229] [2, 4593] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 7.912350654602051 with beta sum per layer: [64.8772201538086, 57.85948181152344, 36.09801483154297, 30.208953857421875, 0.0, 0.0]
alpha/beta optimization time: 1.5698704719543457
This batch time : update_bounds func: 1.8807	 prepare: 0.1005	 bound: 1.5704	 transfer: 0.1485	 finalize: 0.0602
Accumulated time: update_bounds func: 72.2368	 prepare: 3.5803	 bound: 60.4061	 transfer: 0.1485	 finalize: 2.7002
batch bounding time:  1.8813960552215576
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (116), [-0.04220,   inf] (116), [-0.04220,   inf] (116), [-0.04220,   inf] (116), [-0.04220,   inf] (116), [-0.04220,   inf] (116), [-0.04220,   inf] (116), [-0.04220,   inf] (116), [-0.04220,   inf] (116), [-0.04220,   inf] (116), [-0.04220,   inf] (116), [-0.04220,   inf] (116), [-0.04220,   inf] (116), [-0.04220,   inf] (116), [-0.04220,   inf] (116), [-0.04220,   inf] (116), [-0.04220,   inf] (116), [-0.04219,   inf] (116), [-0.04218,   inf] (116), [-0.04218,   inf] (116), 
length of domains: 5792
Total time: 2.3403	 pickout: 0.1419	 decision: 0.2306	 get_bound: 1.8822	 add_domain: 0.0855
Current lb:-0.04220390319824219
18066 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 93.56213569641113

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 13229] [3, 2430] [2, 4593] [0, 13230] [0, 13229] [0, 13229] [0, 13229] [0, 13230] [3, 2430] [2, 4593] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 8.143377304077148 with beta sum per layer: [65.22764587402344, 48.2130126953125, 27.139680862426758, 35.29219055175781, 0.0, 0.0]
alpha/beta optimization time: 1.570847988128662
This batch time : update_bounds func: 1.8803	 prepare: 0.1003	 bound: 1.5714	 transfer: 0.1477	 finalize: 0.0598
Accumulated time: update_bounds func: 74.1171	 prepare: 3.6805	 bound: 61.9775	 transfer: 0.1477	 finalize: 2.7600
batch bounding time:  1.8810124397277832
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (118), [-0.04220,   inf] (118), [-0.04220,   inf] (118), [-0.04220,   inf] (118), [-0.04220,   inf] (118), [-0.04220,   inf] (118), [-0.04220,   inf] (118), [-0.04220,   inf] (118), [-0.04220,   inf] (118), [-0.04220,   inf] (118), [-0.04220,   inf] (118), [-0.04220,   inf] (118), [-0.04220,   inf] (118), [-0.04220,   inf] (118), [-0.04220,   inf] (118), [-0.04220,   inf] (118), [-0.04220,   inf] (118), [-0.04220,   inf] (118), [-0.04220,   inf] (118), [-0.04220,   inf] (118), 
length of domains: 5930
Total time: 2.3400	 pickout: 0.1421	 decision: 0.2284	 get_bound: 1.8818	 add_domain: 0.0877
Current lb:-0.04220390319824219
18578 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 95.9136381149292

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [2, 4528] [3, 2430] [0, 13230] [3, 2430] [2, 4528] [3, 2430] [3, 2430] [2, 4528] [2, 4528] [0, 13230] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 10.709766387939453 with beta sum per layer: [66.9818115234375, 42.84021759033203, 19.449003219604492, 31.067337036132812, 0.0, 0.0]
alpha/beta optimization time: 1.566535234451294
This batch time : update_bounds func: 2.0732	 prepare: 0.1006	 bound: 1.5671	 transfer: 0.1479	 finalize: 0.2563
Accumulated time: update_bounds func: 76.1903	 prepare: 3.7812	 bound: 63.5446	 transfer: 0.1479	 finalize: 3.0164
batch bounding time:  2.0740509033203125
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (120), [-0.04220,   inf] (120), [-0.04220,   inf] (120), [-0.04220,   inf] (120), [-0.04220,   inf] (120), [-0.04220,   inf] (120), [-0.04220,   inf] (120), [-0.04220,   inf] (120), [-0.04220,   inf] (120), [-0.04220,   inf] (120), [-0.04220,   inf] (120), [-0.04220,   inf] (120), [-0.04220,   inf] (120), [-0.04220,   inf] (120), [-0.04220,   inf] (120), [-0.04220,   inf] (120), [-0.04220,   inf] (120), [-0.04220,   inf] (120), [-0.04220,   inf] (120), [-0.04220,   inf] (120), 
length of domains: 6093
Total time: 2.5432	 pickout: 0.1459	 decision: 0.2281	 get_bound: 2.0750	 add_domain: 0.0943
Current lb:-0.04220390319824219
19090 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 98.46693658828735

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [3, 2430] [3, 2430] [2, 4528] [2, 4636] [2, 4636] [2, 4528] [2, 4636] [0, 13229] [0, 13229] [0, 13230] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 14.167411804199219 with beta sum per layer: [61.02639389038086, 25.35053253173828, 11.891485214233398, 22.8707218170166, 0.0, 0.0]
alpha/beta optimization time: 1.5595343112945557
This batch time : update_bounds func: 1.8684	 prepare: 0.1002	 bound: 1.5601	 transfer: 0.1475	 finalize: 0.0595
Accumulated time: update_bounds func: 78.0587	 prepare: 3.8814	 bound: 65.1046	 transfer: 0.1475	 finalize: 3.0758
batch bounding time:  1.869065761566162
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (122), [-0.04220,   inf] (122), [-0.04220,   inf] (122), [-0.04220,   inf] (122), [-0.04220,   inf] (122), [-0.04220,   inf] (122), [-0.04220,   inf] (122), [-0.04220,   inf] (122), [-0.04220,   inf] (122), [-0.04220,   inf] (122), [-0.04220,   inf] (122), [-0.04220,   inf] (122), [-0.04220,   inf] (122), [-0.04220,   inf] (122), [-0.04220,   inf] (122), [-0.04220,   inf] (122), [-0.04220,   inf] (122), [-0.04220,   inf] (122), [-0.04220,   inf] (122), [-0.04220,   inf] (122), 
length of domains: 6287
Total time: 2.3433	 pickout: 0.1429	 decision: 0.2288	 get_bound: 1.8698	 add_domain: 0.1017
Current lb:-0.04220390319824219
19602 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 100.82078456878662

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [2, 4636] [2, 4652] [2, 4636] [0, 13230] [2, 4593] [2, 4593] [2, 4528] [2, 4528] [0, 13230] [2, 4636] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 13.009136199951172 with beta sum per layer: [72.20732879638672, 29.33456802368164, 16.86974334716797, 26.120628356933594, 0.0, 0.0]
alpha/beta optimization time: 1.5581533908843994
This batch time : update_bounds func: 1.8661	 prepare: 0.1016	 bound: 1.5587	 transfer: 0.1447	 finalize: 0.0597
Accumulated time: update_bounds func: 79.9247	 prepare: 3.9830	 bound: 66.6634	 transfer: 0.1447	 finalize: 3.1356
batch bounding time:  1.8667888641357422
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (124), [-0.04220,   inf] (124), [-0.04220,   inf] (124), [-0.04220,   inf] (124), [-0.04220,   inf] (124), [-0.04220,   inf] (124), [-0.04220,   inf] (124), [-0.04220,   inf] (124), [-0.04220,   inf] (124), [-0.04220,   inf] (124), [-0.04220,   inf] (124), [-0.04220,   inf] (124), [-0.04220,   inf] (124), [-0.04220,   inf] (124), [-0.04220,   inf] (124), [-0.04220,   inf] (124), [-0.04220,   inf] (124), [-0.04220,   inf] (124), [-0.04220,   inf] (124), [-0.04220,   inf] (124), 
length of domains: 6472
Total time: 2.3570	 pickout: 0.1589	 decision: 0.2289	 get_bound: 1.8676	 add_domain: 0.1017
Current lb:-0.04220390319824219
20114 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 103.18918991088867

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 8306] [2, 4652] [2, 4636] [0, 13230] [0, 13230] [0, 8306] [2, 4636] [0, 8306] [2, 4528] [2, 4593] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 12.624120712280273 with beta sum per layer: [57.02277755737305, 18.911834716796875, 20.783981323242188, 22.608516693115234, 0.0, 0.0]
alpha/beta optimization time: 1.558868408203125
This batch time : update_bounds func: 1.8664	 prepare: 0.0999	 bound: 1.5594	 transfer: 0.1472	 finalize: 0.0588
Accumulated time: update_bounds func: 81.7912	 prepare: 4.0829	 bound: 68.2228	 transfer: 0.1472	 finalize: 3.1944
batch bounding time:  1.8671350479125977
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (126), [-0.04220,   inf] (126), [-0.04220,   inf] (126), [-0.04220,   inf] (126), [-0.04220,   inf] (126), [-0.04220,   inf] (126), [-0.04220,   inf] (126), [-0.04220,   inf] (126), [-0.04220,   inf] (126), [-0.04220,   inf] (126), [-0.04220,   inf] (126), [-0.04220,   inf] (126), [-0.04220,   inf] (126), [-0.04220,   inf] (126), [-0.04220,   inf] (126), [-0.04220,   inf] (126), [-0.04220,   inf] (126), [-0.04220,   inf] (126), [-0.04220,   inf] (126), [-0.04220,   inf] (126), 
length of domains: 6658
Total time: 2.3475	 pickout: 0.1482	 decision: 0.2286	 get_bound: 1.8680	 add_domain: 0.1027
Current lb:-0.04220390319824219
20626 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 105.54794836044312

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 13230] [2, 4652] [3, 2404] [0, 13230] [3, 2404] [2, 4652] [3, 2404] [0, 8306] [3, 2404] [2, 4636] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 13.28856086730957 with beta sum per layer: [41.2913818359375, 12.650066375732422, 28.62051773071289, 6.322734832763672, 0.0, 0.0]
alpha/beta optimization time: 1.561262607574463
This batch time : update_bounds func: 1.8707	 prepare: 0.1001	 bound: 1.5618	 transfer: 0.1479	 finalize: 0.0598
Accumulated time: update_bounds func: 83.6619	 prepare: 4.1830	 bound: 69.7846	 transfer: 0.1479	 finalize: 3.2541
batch bounding time:  1.871410846710205
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (128), [-0.04220,   inf] (128), [-0.04220,   inf] (128), [-0.04220,   inf] (128), [-0.04220,   inf] (128), [-0.04220,   inf] (128), [-0.04220,   inf] (128), [-0.04220,   inf] (128), [-0.04220,   inf] (128), [-0.04220,   inf] (128), [-0.04220,   inf] (128), [-0.04220,   inf] (128), [-0.04220,   inf] (128), [-0.04220,   inf] (128), [-0.04220,   inf] (128), [-0.04220,   inf] (128), [-0.04220,   inf] (128), [-0.04220,   inf] (128), [-0.04220,   inf] (128), [-0.04220,   inf] (128), 
length of domains: 6845
Total time: 2.5735	 pickout: 0.1576	 decision: 0.4389	 get_bound: 1.8722	 add_domain: 0.1047
Current lb:-0.04220390319824219
21138 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 108.13301205635071

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [3, 2404] [2, 4652] [3, 2404] [0, 13230] [2, 4529] [0, 8306] [0, 8306] [0, 13010] [0, 13230] [0, 13010] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 13.11327075958252 with beta sum per layer: [68.93280029296875, 15.154156684875488, 41.676578521728516, 15.285846710205078, 0.0, 0.0]
alpha/beta optimization time: 1.5573844909667969
This batch time : update_bounds func: 1.8670	 prepare: 0.0998	 bound: 1.5579	 transfer: 0.1487	 finalize: 0.0595
Accumulated time: update_bounds func: 85.5289	 prepare: 4.2828	 bound: 71.3425	 transfer: 0.1487	 finalize: 3.3136
batch bounding time:  1.867692470550537
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), 
length of domains: 7019
Total time: 2.3561	 pickout: 0.1577	 decision: 0.2284	 get_bound: 1.8684	 add_domain: 0.1016
Current lb:-0.04220390319824219
21650 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 110.50025391578674

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 13010] [2, 4652] [3, 2404] [0, 13230] [0, 13010] [0, 13010] [0, 8306] [0, 13010] [0, 13010] [3, 2404] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 15.317455291748047 with beta sum per layer: [50.40590286254883, 11.14547348022461, 32.159210205078125, 11.727950096130371, 0.0, 0.0]
alpha/beta optimization time: 1.561164379119873
This batch time : update_bounds func: 1.8737	 prepare: 0.1001	 bound: 1.5617	 transfer: 0.1512	 finalize: 0.0595
Accumulated time: update_bounds func: 87.4026	 prepare: 4.3829	 bound: 72.9042	 transfer: 0.1512	 finalize: 3.3731
batch bounding time:  1.8743624687194824
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), [-0.04220,   inf] (130), 
length of domains: 7213
Total time: 2.3525	 pickout: 0.1415	 decision: 0.2284	 get_bound: 1.8752	 add_domain: 0.1074
Current lb:-0.04220390319824219
22162 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 112.86407446861267

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 13010] [0, 12715] [2, 4652] [0, 13010] [0, 12715] [0, 13229] [0, 12715] [0, 13229] [0, 12715] [0, 12715] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 16.507610321044922 with beta sum per layer: [58.08024978637695, 10.380366325378418, 26.09732437133789, 14.96536636352539, 0.0, 0.0]
alpha/beta optimization time: 1.548264503479004
This batch time : update_bounds func: 1.8574	 prepare: 0.0998	 bound: 1.5488	 transfer: 0.1483	 finalize: 0.0591
Accumulated time: update_bounds func: 89.2601	 prepare: 4.4827	 bound: 74.4530	 transfer: 0.1483	 finalize: 3.4323
batch bounding time:  1.858246088027954
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), 
length of domains: 7415
Total time: 2.5813	 pickout: 0.1555	 decision: 0.4557	 get_bound: 1.8591	 add_domain: 0.1109
Current lb:-0.04220390319824219
22674 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 115.45655131340027

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 13010] [0, 12715] [0, 8084] [0, 12715] [0, 13010] [0, 8084] [0, 12715] [0, 13010] [0, 8084] [0, 13010] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 19.091304779052734 with beta sum per layer: [22.0019474029541, 5.572609901428223, 11.054304122924805, 9.172492980957031, 0.0, 0.0]
alpha/beta optimization time: 1.5419528484344482
This batch time : update_bounds func: 1.8508	 prepare: 0.0996	 bound: 1.5425	 transfer: 0.1480	 finalize: 0.0591
Accumulated time: update_bounds func: 91.1109	 prepare: 4.5823	 bound: 75.9955	 transfer: 0.1480	 finalize: 3.4914
batch bounding time:  1.8514678478240967
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), [-0.04220,   inf] (132), 
length of domains: 7642
Total time: 2.3405	 pickout: 0.1408	 decision: 0.2298	 get_bound: 1.8522	 add_domain: 0.1175
Current lb:-0.04220390319824219
23186 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 117.80734205245972

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [3, 2404] [3, 2404] [0, 8084] [0, 12715] [2, 4652] [0, 8084] [2, 4652] [2, 4652] [0, 8084] [0, 8084] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 17.795413970947266 with beta sum per layer: [46.39665985107422, 7.196943283081055, 21.656890869140625, 16.90732192993164, 0.0, 0.0]
alpha/beta optimization time: 1.5478227138519287
This batch time : update_bounds func: 1.8566	 prepare: 0.0992	 bound: 1.5484	 transfer: 0.1484	 finalize: 0.0595
Accumulated time: update_bounds func: 92.9675	 prepare: 4.6815	 bound: 77.5438	 transfer: 0.1484	 finalize: 3.5509
batch bounding time:  1.8572919368743896
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), 
length of domains: 7852
Total time: 2.3406	 pickout: 0.1413	 decision: 0.2274	 get_bound: 1.8581	 add_domain: 0.1139
Current lb:-0.04220390319824219
23698 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 120.1590986251831

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [2, 4529] [0, 13010] [0, 12715] [0, 12715] [3, 2404] [2, 4652] [0, 8084] [2, 4529] [0, 13010] [0, 13010] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 19.587738037109375 with beta sum per layer: [21.39934730529785, 4.2782745361328125, 11.210955619812012, 10.53432846069336, 0.0, 0.0]
alpha/beta optimization time: 1.5470798015594482
This batch time : update_bounds func: 2.1032	 prepare: 0.0997	 bound: 1.5476	 transfer: 0.1490	 finalize: 0.3057
Accumulated time: update_bounds func: 95.0706	 prepare: 4.7812	 bound: 79.0915	 transfer: 0.1490	 finalize: 3.8565
batch bounding time:  2.10406756401062
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), 
length of domains: 8081
Total time: 2.6148	 pickout: 0.1541	 decision: 0.2380	 get_bound: 2.1049	 add_domain: 0.1178
Current lb:-0.04220390319824219
24210 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 122.78494453430176

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 13010] [3, 2404] [3, 2404] [0, 7955] [0, 13010] [2, 4652] [0, 8084] [0, 7955] [0, 8084] [0, 12715] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 18.904457092285156 with beta sum per layer: [40.630924224853516, 8.587427139282227, 19.369230270385742, 19.15102195739746, 0.0, 0.0]
alpha/beta optimization time: 1.556950569152832
This batch time : update_bounds func: 1.8652	 prepare: 0.0993	 bound: 1.5575	 transfer: 0.1478	 finalize: 0.0593
Accumulated time: update_bounds func: 96.9358	 prepare: 4.8805	 bound: 80.6489	 transfer: 0.1478	 finalize: 3.9158
batch bounding time:  1.8658356666564941
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), [-0.04220,   inf] (134), 
length of domains: 8299
Total time: 2.3527	 pickout: 0.1421	 decision: 0.2290	 get_bound: 1.8667	 add_domain: 0.1150
Current lb:-0.04220390319824219
24722 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 125.14808416366577

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 13010] [0, 12715] [2, 4529] [0, 13010] [3, 2404] [0, 12715] [0, 12715] [0, 8306] [0, 8306] [0, 8084] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 19.779970169067383 with beta sum per layer: [39.13631057739258, 7.3458099365234375, 20.048133850097656, 15.135843276977539, 0.0, 0.0]
alpha/beta optimization time: 1.5301992893218994
This batch time : update_bounds func: 1.8385	 prepare: 0.0989	 bound: 1.5307	 transfer: 0.1473	 finalize: 0.0603
Accumulated time: update_bounds func: 98.7743	 prepare: 4.9795	 bound: 82.1796	 transfer: 0.1473	 finalize: 3.9762
batch bounding time:  1.8391835689544678
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), 
length of domains: 8528
Total time: 2.3334	 pickout: 0.1475	 decision: 0.2280	 get_bound: 1.8399	 add_domain: 0.1179
Current lb:-0.04220390319824219
25234 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 127.49203586578369

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 7955] [0, 8012] [0, 7955] [0, 8084] [0, 8084] [0, 8012] [0, 7955] [0, 8084] [2, 4529] [0, 7955] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 20.141883850097656 with beta sum per layer: [18.827110290527344, 3.9002692699432373, 10.433961868286133, 7.092861652374268, 0.0, 0.0]
alpha/beta optimization time: 1.5529792308807373
This batch time : update_bounds func: 1.8703	 prepare: 0.0990	 bound: 1.5535	 transfer: 0.1558	 finalize: 0.0604
Accumulated time: update_bounds func: 100.6446	 prepare: 5.0785	 bound: 83.7331	 transfer: 0.1558	 finalize: 4.0366
batch bounding time:  1.8710103034973145
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), 
length of domains: 8760
Total time: 2.3863	 pickout: 0.1675	 decision: 0.2279	 get_bound: 1.8718	 add_domain: 0.1191
Current lb:-0.04220390319824219
25746 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 129.88855457305908

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 8084] [0, 8084] [0, 12715] [0, 8084] [0, 8084] [0, 13010] [0, 8084] [3, 2404] [3, 2404] [0, 8012] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 20.404356002807617 with beta sum per layer: [17.68148422241211, 2.6682467460632324, 8.6187744140625, 9.872407913208008, 0.0, 0.0]
alpha/beta optimization time: 1.5266528129577637
This batch time : update_bounds func: 2.0950	 prepare: 0.1000	 bound: 1.5271	 transfer: 0.1504	 finalize: 0.0587
Accumulated time: update_bounds func: 102.7396	 prepare: 5.1785	 bound: 85.2603	 transfer: 0.1504	 finalize: 4.0953
batch bounding time:  2.095705032348633
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), 
length of domains: 8996
Total time: 2.6075	 pickout: 0.1610	 decision: 0.2285	 get_bound: 2.0965	 add_domain: 0.1215
Current lb:-0.04220390319824219
26258 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 132.5070571899414

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 12715] [0, 7955] [0, 12715] [0, 8012] [0, 7955] [0, 8084] [0, 7955] [0, 8306] [0, 8012] [2, 4528] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 19.882553100585938 with beta sum per layer: [19.0260009765625, 4.835054874420166, 9.258126258850098, 12.147110939025879, 0.0, 0.0]
alpha/beta optimization time: 1.5515170097351074
This batch time : update_bounds func: 1.8649	 prepare: 0.0993	 bound: 1.5521	 transfer: 0.1534	 finalize: 0.0590
Accumulated time: update_bounds func: 104.6045	 prepare: 5.2778	 bound: 86.8124	 transfer: 0.1534	 finalize: 4.1543
batch bounding time:  1.8655431270599365
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), 
length of domains: 9226
Total time: 2.3594	 pickout: 0.1441	 decision: 0.2290	 get_bound: 1.8663	 add_domain: 0.1200
Current lb:-0.04220390319824219
26770 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 134.87654399871826

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 8012] [0, 7955] [0, 8084] [0, 13010] [0, 13010] [0, 7955] [0, 12715] [0, 7955] [0, 7955] [0, 12715] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 19.337810516357422 with beta sum per layer: [32.3358154296875, 8.142725944519043, 9.953520774841309, 13.521646499633789, 0.0, 0.0]
alpha/beta optimization time: 1.5469365119934082
This batch time : update_bounds func: 1.8572	 prepare: 0.0989	 bound: 1.5475	 transfer: 0.1499	 finalize: 0.0598
Accumulated time: update_bounds func: 106.4616	 prepare: 5.3766	 bound: 88.3598	 transfer: 0.1499	 finalize: 4.2141
batch bounding time:  1.8578176498413086
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), 
length of domains: 9451
Total time: 2.3586	 pickout: 0.1544	 decision: 0.2273	 get_bound: 1.8586	 add_domain: 0.1183
Current lb:-0.04220390319824219
27282 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 137.2465624809265

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 8012] [0, 8012] [0, 7955] [0, 13010] [0, 13010] [0, 8306] [0, 8084] [0, 12715] [0, 8012] [0, 8012] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 20.25432014465332 with beta sum per layer: [15.96875286102295, 3.9273226261138916, 8.93544864654541, 14.553342819213867, 0.0, 0.0]
alpha/beta optimization time: 1.5417921543121338
This batch time : update_bounds func: 1.8304	 prepare: 0.0986	 bound: 1.5424	 transfer: 0.1285	 finalize: 0.0597
Accumulated time: update_bounds func: 108.2921	 prepare: 5.4753	 bound: 89.9022	 transfer: 0.1285	 finalize: 4.2737
batch bounding time:  1.8310985565185547
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), 
length of domains: 9682
Total time: 2.3288	 pickout: 0.1501	 decision: 0.2277	 get_bound: 1.8319	 add_domain: 0.1191
Current lb:-0.04220390319824219
27794 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 139.5854525566101

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 8084] [0, 8084] [0, 12715] [0, 8012] [0, 12715] [0, 12715] [0, 12715] [0, 7955] [0, 8012] [0, 13010] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 20.69955062866211 with beta sum per layer: [26.381938934326172, 5.08029317855835, 6.044765472412109, 8.224067687988281, 0.0, 0.0]
alpha/beta optimization time: 1.527696132659912
This batch time : update_bounds func: 1.8394	 prepare: 0.0998	 bound: 1.5282	 transfer: 0.1510	 finalize: 0.0590
Accumulated time: update_bounds func: 110.1315	 prepare: 5.5751	 bound: 91.4305	 transfer: 0.1510	 finalize: 4.3327
batch bounding time:  1.8400731086730957
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), [-0.04220,   inf] (136), 
length of domains: 9924
Total time: 2.6254	 pickout: 0.1523	 decision: 0.5093	 get_bound: 1.8408	 add_domain: 0.1230
Current lb:-0.04220390319824219
28306 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 142.22141003608704

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 12715] [0, 12715] [2, 4652] [0, 8012] [0, 8084] [3, 2404] [0, 7955] [0, 8012] [3, 2404] [0, 7955] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 21.771896362304688 with beta sum per layer: [33.385498046875, 4.420907497406006, 19.9465274810791, 4.680220603942871, 0.0, 0.0]
alpha/beta optimization time: 1.5167429447174072
This batch time : update_bounds func: 1.8260	 prepare: 0.0981	 bound: 1.5173	 transfer: 0.1500	 finalize: 0.0595
Accumulated time: update_bounds func: 111.9575	 prepare: 5.6732	 bound: 92.9477	 transfer: 0.1500	 finalize: 4.3923
batch bounding time:  1.8267264366149902
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), 
length of domains: 10174
Total time: 2.3296	 pickout: 0.1491	 decision: 0.2281	 get_bound: 1.8275	 add_domain: 0.1249
Current lb:-0.04220390319824219
28818 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 144.5609312057495

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 12788] [0, 8306] [0, 8306] [0, 7955] [0, 7955] [0, 8012] [0, 12788] [0, 7955] [0, 7955] [0, 7955] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 21.17998504638672 with beta sum per layer: [21.89628028869629, 2.443605899810791, 4.769120693206787, 5.226653099060059, 0.0, 0.0]
alpha/beta optimization time: 1.5313682556152344
This batch time : update_bounds func: 1.8401	 prepare: 0.0978	 bound: 1.5319	 transfer: 0.1500	 finalize: 0.0591
Accumulated time: update_bounds func: 113.7976	 prepare: 5.7711	 bound: 94.4796	 transfer: 0.1500	 finalize: 4.4514
batch bounding time:  1.840789556503296
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), 
length of domains: 10417
Total time: 2.3430	 pickout: 0.1502	 decision: 0.2283	 get_bound: 1.8416	 add_domain: 0.1229
Current lb:-0.04220390319824219
29330 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 146.91408848762512

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 12788] [0, 7955] [0, 8012] [0, 12788] [0, 7955] [0, 8012] [0, 8084] [0, 8084] [0, 7955] [0, 12788] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 21.17041015625 with beta sum per layer: [10.504718780517578, 3.053084135055542, 5.647271156311035, 10.3445463180542, 0.0, 0.0]
alpha/beta optimization time: 1.5367364883422852
This batch time : update_bounds func: 1.8468	 prepare: 0.0991	 bound: 1.5373	 transfer: 0.1501	 finalize: 0.0592
Accumulated time: update_bounds func: 115.6444	 prepare: 5.8702	 bound: 96.0169	 transfer: 0.1501	 finalize: 4.5106
batch bounding time:  1.8474864959716797
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), 
length of domains: 10655
Total time: 2.3489	 pickout: 0.1497	 decision: 0.2287	 get_bound: 1.8483	 add_domain: 0.1222
Current lb:-0.04220390319824219
29842 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 149.2733838558197

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 8084] [0, 8306] [0, 8084] [0, 8084] [0, 8306] [0, 8306] [0, 8012] [0, 8012] [0, 12788] [0, 7955] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 20.01142692565918 with beta sum per layer: [32.212276458740234, 4.336716651916504, 11.479071617126465, 13.851247787475586, 0.0, 0.0]
alpha/beta optimization time: 1.5257477760314941
This batch time : update_bounds func: 1.8357	 prepare: 0.0989	 bound: 1.5263	 transfer: 0.1499	 finalize: 0.0595
Accumulated time: update_bounds func: 117.4801	 prepare: 5.9691	 bound: 97.5432	 transfer: 0.1499	 finalize: 4.5701
batch bounding time:  1.8363840579986572
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), 
length of domains: 10884
Total time: 2.6516	 pickout: 0.1647	 decision: 0.5300	 get_bound: 1.8372	 add_domain: 0.1197
Current lb:-0.04220390319824219
30354 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 151.93527698516846

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth: /home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:556: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(eps_temp / std).reshape(1, -1, 1, 1)
 1
splitting decisions: 
split level 0: [0, 7955] [2, 4652] [0, 8012] [0, 12788] [2, 4652] [0, 8084] [0, 8012] [0, 12715] [0, 12715] [0, 8012] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 19.527488708496094 with beta sum per layer: [33.86420822143555, 6.587693214416504, 13.545018196105957, 12.970443725585938, 0.0, 0.0]
alpha/beta optimization time: 1.551539421081543
This batch time : update_bounds func: 1.8546	 prepare: 0.0984	 bound: 1.5523	 transfer: 0.1452	 finalize: 0.0576
Accumulated time: update_bounds func: 119.3347	 prepare: 6.0674	 bound: 99.0954	 transfer: 0.1452	 finalize: 4.6276
batch bounding time:  1.8552029132843018
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), 
length of domains: 11111
Total time: 2.3591	 pickout: 0.1556	 decision: 0.2284	 get_bound: 1.8559	 add_domain: 0.1192
Current lb:-0.04220390319824219
30866 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 154.3058454990387

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 8084] [0, 7955] [0, 8012] [2, 4529] [2, 4652] [2, 4652] [0, 8012] [2, 4652] [2, 4652] [2, 4652] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 20.6457462310791 with beta sum per layer: [15.217594146728516, 2.990933895111084, 10.411378860473633, 8.760505676269531, 0.0, 0.0]
alpha/beta optimization time: 1.5414447784423828
This batch time : update_bounds func: 1.8248	 prepare: 0.0979	 bound: 1.5420	 transfer: 0.1249	 finalize: 0.0589
Accumulated time: update_bounds func: 121.1595	 prepare: 6.1653	 bound: 100.6374	 transfer: 0.1249	 finalize: 4.6865
batch bounding time:  1.8254497051239014
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), 
length of domains: 11348
Total time: 2.3132	 pickout: 0.1354	 decision: 0.2287	 get_bound: 1.8263	 add_domain: 0.1229
Current lb:-0.04220390319824219
31378 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 156.6293363571167

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 28, 28]) pre split depth:  1
batch:  torch.Size([256, 32, 28, 28]) post split depth:  1
splitting decisions: 
split level 0: [0, 8084] [0, 7955] [0, 8084] [0, 8084] [0, 8084] [0, 8084] [0, 8084] [0, 8012] [0, 7955] [0, 7955] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 20.605945587158203 with beta sum per layer: [15.257669448852539, 2.662954092025757, 5.909250736236572, 9.827648162841797, 0.0, 0.0]
alpha/beta optimization time: 1.5264389514923096
This batch time : update_bounds func: 1.8336	 prepare: 0.0983	 bound: 1.5270	 transfer: 0.1491	 finalize: 0.0581
Accumulated time: update_bounds func: 122.9931	 prepare: 6.2636	 bound: 102.1643	 transfer: 0.1491	 finalize: 4.7447
batch bounding time:  1.8343029022216797
Current worst splitting domains [lb, ub] (depth):
[-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), [-0.04220,   inf] (138), 
length of domains: 11587
Total time: 2.3382	 pickout: 0.1512	 decision: 0.2284	 get_bound: 1.8351	 add_domain: 0.1234
Current lb:-0.04220390319824219
31890 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Time out!!!!!!!!
Image 133 label 2 verification end, final lower bound -0.04220390319824219, upper bound inf, time: 159.44562125205994
133 -0.04220390319824219
Result: image 133 verification failure (with branch and bound).
Wall time: 180.6280596256256

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 0): []
verification failure idx (total 1): [133]
final verified acc: 0.0%[1]
verifier is called on 1 examples.
total verified: 0
mean time [cnt:1] (excluding attack success): 180.501629114151
