Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_cnn_b_adv4.model
  name: cnn_4layer_b4
data:
  start: 95
  end: 96
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR_SDP
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.00784313725
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 256
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 60
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:14:51 2022 on diablo.cs.ucla.edu
Sequential(
  (0): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)
  (1): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2))
  (2): ReLU()
  (3): Conv2d(32, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (4): ReLU()
  (5): Flatten()
  (6): Linear(in_features=8192, out_features=250, bias=True)
  (7): ReLU()
  (8): Linear(in_features=250, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([200, 3, 32, 32]) torch.Size([200]) torch.Size([200])
X range: tensor(2.1256) tensor(-1.9889) tensor(-0.0131)
############################
epsilon after preprocessing: tensor([[[[0.0317]],

         [[0.0322]],

         [[0.0300]]]]), data_max = tensor([[[[2.0587]],

         [[2.1256]],

         [[2.1154]]]]), data_min = tensor([[[[-1.9889]],

         [[-1.9807]],

         [[-1.7076]]]])
Task length: 1
saving results to Verified_ret_[cnn_4layer_b4]_start=95_end=96_iter=20_b=256_timeout=60_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 95 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 1, correct label 1, image norm 2349.2333984375, logits tensor([-43.1365, -41.6500, -43.4775, -43.3514, -43.6991, -43.1254, -43.1545,
        -45.7754, -44.5673, -44.6309], device='cuda:0',
       grad_fn=<SelectBackward>)
##### PGD attack: True label: 1, Tested against: ['all'] ######
pgd prediction: tensor([-43.9218, -42.8572, -44.1528, -44.0306, -44.4122, -43.7976, -43.5932,
        -46.5778, -45.3489, -45.6302], device='cuda:0',
       grad_fn=<SqueezeBackward1>)
attack margin tensor([1.0646,    inf, 1.2956, 1.1735, 1.5550, 0.9405, 0.7360, 3.7207, 2.4918,
        2.7730], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[-43.1365, -41.6500, -43.4775, -43.3514, -43.6991, -43.1254, -43.1545,
         -45.7754, -44.5673, -44.6309]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-0.3058, -0.3440, -0.0530, -0.1881, -0.3368, -0.6795,  1.7664,  1.4442,
          1.7687]], device='cuda:0') None
best_l after optimization: -4.008355617523193 with beta sum per layer: []
alpha/beta optimization time: 8.369832515716553
initial alpha-CROWN bounds: tensor([[-0.1764, -0.2287,  0.0515, -0.0524, -0.2327, -0.5754,  1.8831,  1.5268,
          1.8126]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.5754, device='cuda:0', grad_fn=<MinBackward1>)
Sorted order for labels to verify: [6, 5, 0, 3, 2, 4, 8, 9, 7, 1]
##### [0:95] Tested against 6 ######
Model prediction is: tensor([[-43.1365, -41.6500, -43.4775, -43.3514, -43.6991, -43.1254, -43.1545,
         -45.7754, -44.5673, -44.6309]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /34 start_node /35
setting alpha for layer /34 start_node /45
not setting layer /34 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /36 start_node /45
not setting layer /36 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /46 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /33 torch.Size([1, 32, 16, 16])
1 /35 torch.Size([1, 128, 8, 8])
2 /45 torch.Size([1, 250])
best_l after optimization: 0.5753648281097412 with beta sum per layer: []
alpha/beta optimization time: 2.0464746952056885
alpha-CROWN with fixed intermediate bounds: tensor([[-0.5754]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.5753648281097412
layer 0 size torch.Size([8192]) unstable 1206
layer 1 size torch.Size([8192]) unstable 562
layer 2 size torch.Size([250]) unstable 34
-----------------
# of unstable neurons: 1802
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 140] 
split level 1: [2, 103] 
split level 2: [2, 186] 
split level 3: [2, 115] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.5234352350234985 with beta sum per layer: [0.0, 0.0, 0.7663397789001465]
alpha/beta optimization time: 0.30154848098754883
This batch time : update_bounds func: 0.3228	 prepare: 0.0175	 bound: 0.3027	 transfer: 0.0013	 finalize: 0.0012
Accumulated time: update_bounds func: 0.3228	 prepare: 0.0175	 bound: 0.3027	 transfer: 0.0013	 finalize: 0.0012
batch bounding time:  0.3229362964630127
Current worst splitting domains [lb, ub] (depth):
[-0.22365,   inf] (5), [-0.19532,   inf] (5), [-0.15071,   inf] (5), [-0.10977,   inf] (5), [-0.09595,   inf] (5), [-0.06164,   inf] (5), [-0.04028,   inf] (5), [-0.01361,   inf] (5), [-0.01217,   inf] (5), 
length of domains: 9
Total time: 0.3575	 pickout: 0.0009	 decision: 0.0311	 get_bound: 0.3250	 add_domain: 0.0004
Current lb:-0.22364972531795502
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.286914587020874

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([9, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([9, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 138] [2, 138] [2, 138] [2, 138] [2, 138] [2, 138] [2, 138] [2, 138] [2, 138] 
regular batch size: 2*9, diving batch size 1*0
best_l after optimization: 0.8092694282531738 with beta sum per layer: [0.0, 0.0, 1.1801409721374512]
alpha/beta optimization time: 0.27873682975769043
This batch time : update_bounds func: 0.2846	 prepare: 0.0029	 bound: 0.2791	 transfer: 0.0013	 finalize: 0.0013
Accumulated time: update_bounds func: 0.6074	 prepare: 0.0204	 bound: 0.5817	 transfer: 0.0013	 finalize: 0.0026
batch bounding time:  0.28484392166137695
Current worst splitting domains [lb, ub] (depth):
[-0.17523,   inf] (7), [-0.15912,   inf] (7), [-0.14691,   inf] (7), [-0.12688,   inf] (7), [-0.09963,   inf] (7), [-0.09352,   inf] (7), [-0.05575,   inf] (7), [-0.05075,   inf] (7), [-0.04455,   inf] (7), [-0.03674,   inf] (7), [-0.00675,   inf] (7), [-0.00577,   inf] (7), 
length of domains: 12
Total time: 0.3136	 pickout: 0.0027	 decision: 0.0255	 get_bound: 0.2849	 add_domain: 0.0005
Current lb:-0.17523127794265747
34 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.600780487060547

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([12, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([12, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 230] [2, 230] [2, 230] [2, 230] [2, 230] [2, 230] [2, 230] [2, 230] [2, 230] [2, 230] 
regular batch size: 2*12, diving batch size 1*0
best_l after optimization: 1.1719212532043457 with beta sum per layer: [0.0, 0.0, 1.544363021850586]
alpha/beta optimization time: 0.309751033782959
This batch time : update_bounds func: 0.3181	 prepare: 0.0035	 bound: 0.3101	 transfer: 0.0017	 finalize: 0.0027
Accumulated time: update_bounds func: 0.9255	 prepare: 0.0239	 bound: 0.8918	 transfer: 0.0017	 finalize: 0.0053
batch bounding time:  0.318331241607666
Current worst splitting domains [lb, ub] (depth):
[-0.14268,   inf] (9), [-0.13914,   inf] (9), [-0.12574,   inf] (9), [-0.12453,   inf] (9), [-0.11387,   inf] (9), [-0.11064,   inf] (9), [-0.09342,   inf] (9), [-0.09170,   inf] (9), [-0.06681,   inf] (9), [-0.06379,   inf] (9), [-0.06001,   inf] (9), [-0.05805,   inf] (9), [-0.02030,   inf] (9), [-0.01831,   inf] (9), [-0.01434,   inf] (9), [-0.01268,   inf] (9), [-0.01149,   inf] (9), [-0.00947,   inf] (9), [-0.00299,   inf] (9), [-0.00169,   inf] (9), 
length of domains: 20
Total time: 0.3510	 pickout: 0.0031	 decision: 0.0279	 get_bound: 0.3184	 add_domain: 0.0015
Current lb:-0.14268317818641663
58 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.952103853225708

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([20, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([20, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 7] [2, 7] [2, 7] [2, 7] [2, 7] [2, 7] [2, 7] [2, 7] [2, 7] [2, 7] 
regular batch size: 2*20, diving batch size 1*0
best_l after optimization: 1.3086037635803223 with beta sum per layer: [0.0, 0.0, 2.329674243927002]
alpha/beta optimization time: 0.28327441215515137
This batch time : update_bounds func: 0.2936	 prepare: 0.0047	 bound: 0.2836	 transfer: 0.0025	 finalize: 0.0026
Accumulated time: update_bounds func: 1.2191	 prepare: 0.0286	 bound: 1.1754	 transfer: 0.0025	 finalize: 0.0079
batch bounding time:  0.2937662601470947
Current worst splitting domains [lb, ub] (depth):
[-0.11129,   inf] (11), [-0.11119,   inf] (11), [-0.10827,   inf] (11), [-0.10759,   inf] (11), [-0.09445,   inf] (11), [-0.09420,   inf] (11), [-0.09333,   inf] (11), [-0.09305,   inf] (11), [-0.08313,   inf] (11), [-0.08089,   inf] (11), [-0.07936,   inf] (11), [-0.07830,   inf] (11), [-0.06240,   inf] (11), [-0.06067,   inf] (11), [-0.06035,   inf] (11), [-0.05925,   inf] (11), [-0.03553,   inf] (11), [-0.03545,   inf] (11), [-0.03270,   inf] (11), [-0.03209,   inf] (11), 
length of domains: 24
Total time: 0.3391	 pickout: 0.0060	 decision: 0.0380	 get_bound: 0.2938	 add_domain: 0.0012
Current lb:-0.11129232496023178
98 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.291609287261963

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([24, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([24, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 227] [2, 227] [2, 227] [2, 227] [2, 227] [2, 227] [2, 227] [2, 227] [2, 227] [2, 227] 
regular batch size: 2*24, diving batch size 1*0
best_l after optimization: -0.3520696759223938 with beta sum per layer: [0.0, 0.0, 3.1327617168426514]
alpha/beta optimization time: 0.3242180347442627
This batch time : update_bounds func: 0.3371	 prepare: 0.0054	 bound: 0.3245	 transfer: 0.0025	 finalize: 0.0046
Accumulated time: update_bounds func: 1.5562	 prepare: 0.0340	 bound: 1.4999	 transfer: 0.0025	 finalize: 0.0125
batch bounding time:  0.3372368812561035
Current worst splitting domains [lb, ub] (depth):
[-0.08670,   inf] (13), [-0.08641,   inf] (13), [-0.08417,   inf] (13), [-0.08339,   inf] (13), [-0.07041,   inf] (13), [-0.07022,   inf] (13), [-0.06942,   inf] (13), [-0.06930,   inf] (13), [-0.05741,   inf] (13), [-0.05537,   inf] (13), [-0.05400,   inf] (13), [-0.05307,   inf] (13), [-0.03678,   inf] (13), [-0.03524,   inf] (13), [-0.03509,   inf] (13), [-0.03456,   inf] (13), [-0.01162,   inf] (13), [-0.01157,   inf] (13), [-0.00900,   inf] (13), [-0.00850,   inf] (13), 
length of domains: 24
Total time: 0.3746	 pickout: 0.0057	 decision: 0.0303	 get_bound: 0.3373	 add_domain: 0.0013
Current lb:-0.08670433610677719
146 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.666647672653198

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([24, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([24, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 248] [2, 248] [2, 248] [2, 248] [2, 248] [2, 248] [2, 248] [2, 248] [2, 248] [2, 248] 
regular batch size: 2*24, diving batch size 1*0
best_l after optimization: -1.185717225074768 with beta sum per layer: [0.0, 0.0, 3.054823875427246]
alpha/beta optimization time: 0.30064868927001953
This batch time : update_bounds func: 0.3177	 prepare: 0.0078	 bound: 0.3010	 transfer: 0.0054	 finalize: 0.0033
Accumulated time: update_bounds func: 1.8738	 prepare: 0.0418	 bound: 1.8009	 transfer: 0.0054	 finalize: 0.0158
batch bounding time:  0.3178884983062744
Current worst splitting domains [lb, ub] (depth):
[-0.06360,   inf] (15), [-0.06317,   inf] (15), [-0.06149,   inf] (15), [-0.06054,   inf] (15), [-0.04806,   inf] (15), [-0.04768,   inf] (15), [-0.04740,   inf] (15), [-0.04737,   inf] (15), [-0.03321,   inf] (15), [-0.03110,   inf] (15), [-0.03019,   inf] (15), [-0.02915,   inf] (15), [-0.01313,   inf] (15), [-0.01206,   inf] (15), [-0.01173,   inf] (15), [-0.01140,   inf] (15), 
length of domains: 16
Total time: 0.3612	 pickout: 0.0070	 decision: 0.0353	 get_bound: 0.3180	 add_domain: 0.0009
Current lb:-0.06359897553920746
194 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.028581619262695

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([16, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([16, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 72] [2, 72] [2, 72] [2, 72] [2, 72] [2, 72] [2, 72] [2, 72] [2, 72] [2, 72] 
regular batch size: 2*16, diving batch size 1*0
best_l after optimization: 0.09881986677646637 with beta sum per layer: [0.0, 0.0, 1.1206326484680176]
alpha/beta optimization time: 0.28544020652770996
This batch time : update_bounds func: 0.2954	 prepare: 0.0041	 bound: 0.2857	 transfer: 0.0032	 finalize: 0.0022
Accumulated time: update_bounds func: 2.1692	 prepare: 0.0459	 bound: 2.0867	 transfer: 0.0032	 finalize: 0.0180
batch bounding time:  0.29557371139526367
Current worst splitting domains [lb, ub] (depth):
[-0.04373,   inf] (17), [-0.04330,   inf] (17), [-0.04166,   inf] (17), [-0.04072,   inf] (17), [-0.02843,   inf] (17), [-0.02782,   inf] (17), [-0.02770,   inf] (17), [-0.02766,   inf] (17), [-0.01249,   inf] (17), [-0.01028,   inf] (17), [-0.00938,   inf] (17), [-0.00844,   inf] (17), 
length of domains: 12
Total time: 0.3302	 pickout: 0.0047	 decision: 0.0291	 get_bound: 0.2956	 add_domain: 0.0008
Current lb:-0.043728847056627274
226 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.35922384262085

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([12, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([12, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 170] [2, 170] [2, 170] [2, 170] [2, 170] [2, 170] [2, 170] [2, 170] [2, 170] [2, 170] 
regular batch size: 2*12, diving batch size 1*0
best_l after optimization: -0.19745051860809326 with beta sum per layer: [0.0, 0.0, 0.5536537170410156]
alpha/beta optimization time: 0.2816348075866699
This batch time : update_bounds func: 0.2888	 prepare: 0.0034	 bound: 0.2819	 transfer: 0.0017	 finalize: 0.0017
Accumulated time: update_bounds func: 2.4580	 prepare: 0.0492	 bound: 2.3686	 transfer: 0.0017	 finalize: 0.0197
batch bounding time:  0.28897666931152344
Current worst splitting domains [lb, ub] (depth):
[-0.02512,   inf] (19), [-0.02481,   inf] (19), [-0.02295,   inf] (19), [-0.02207,   inf] (19), [-0.00991,   inf] (19), [-0.00929,   inf] (19), [-0.00903,   inf] (19), [-0.00896,   inf] (19), 
length of domains: 8
Total time: 0.3189	 pickout: 0.0033	 decision: 0.0261	 get_bound: 0.2890	 add_domain: 0.0005
Current lb:-0.0251179076731205
250 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.678452730178833

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([8, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 10] [2, 10] [2, 10] [2, 10] [2, 10] [2, 10] [2, 10] [2, 10] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.27805837988853455 with beta sum per layer: [0.0, 0.0, 0.2193363904953003]
alpha/beta optimization time: 0.2742195129394531
This batch time : update_bounds func: 0.2799	 prepare: 0.0027	 bound: 0.2745	 transfer: 0.0014	 finalize: 0.0012
Accumulated time: update_bounds func: 2.7379	 prepare: 0.0519	 bound: 2.6431	 transfer: 0.0014	 finalize: 0.0209
batch bounding time:  0.2800445556640625
Current worst splitting domains [lb, ub] (depth):
[-0.00947,   inf] (21), [-0.00915,   inf] (21), [-0.00720,   inf] (21), [-0.00631,   inf] (21), 
length of domains: 4
Total time: 0.3074	 pickout: 0.0024	 decision: 0.0246	 get_bound: 0.2801	 add_domain: 0.0003
Current lb:-0.009470462799072266
266 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.986060380935669

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 32, 16, 16]) pre split depth:  2
batch:  torch.Size([4, 32, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [2, 154] [2, 154] [2, 154] [2, 154] 
split level 1: [2, 16] [2, 16] [2, 16] [2, 16] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -1.1980352401733398 with beta sum per layer: [0.0, 0.0, 0.016130026429891586]
alpha/beta optimization time: 0.01015329360961914
This batch time : update_bounds func: 0.0154	 prepare: 0.0027	 bound: 0.0104	 transfer: 0.0012	 finalize: 0.0010
Accumulated time: update_bounds func: 2.7533	 prepare: 0.0546	 bound: 2.6535	 transfer: 0.0012	 finalize: 0.0219
batch bounding time:  0.015444755554199219
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0422	 pickout: 0.0016	 decision: 0.0237	 get_bound: 0.0170	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 6.02851414680481

Image 95 label 6 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 6.118047475814819
95 1.0000000116860974e-07
##### [0:95] Tested against 5 ######
Model prediction is: tensor([[-43.1365, -41.6500, -43.4775, -43.3514, -43.6991, -43.1254, -43.1545,
         -45.7754, -44.5673, -44.6309]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /34 start_node /35
setting alpha for layer /34 start_node /45
not setting layer /34 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /36 start_node /45
not setting layer /36 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /46 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /33 torch.Size([1, 32, 16, 16])
1 /35 torch.Size([1, 128, 8, 8])
2 /45 torch.Size([1, 250])
best_l after optimization: 0.23263151943683624 with beta sum per layer: []
alpha/beta optimization time: 1.1841082572937012
alpha-CROWN with fixed intermediate bounds: tensor([[-0.2326]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.23263151943683624
layer 0 size torch.Size([8192]) unstable 1206
layer 1 size torch.Size([8192]) unstable 562
layer 2 size torch.Size([250]) unstable 34
-----------------
# of unstable neurons: 1802
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 186] 
split level 1: [2, 248] 
split level 2: [2, 115] 
split level 3: [2, 157] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -3.6229257583618164 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.29907989501953125
This batch time : update_bounds func: 0.3101	 prepare: 0.0069	 bound: 0.2997	 transfer: 0.0022	 finalize: 0.0012
Accumulated time: update_bounds func: 3.0634	 prepare: 0.0615	 bound: 2.9532	 transfer: 0.0022	 finalize: 0.0231
batch bounding time:  0.310239315032959
Current worst splitting domains [lb, ub] (depth):
[-0.00895,   inf] (5), [-0.00477,   inf] (5), 
length of domains: 2
Total time: 0.3456	 pickout: 0.0010	 decision: 0.0320	 get_bound: 0.3123	 add_domain: 0.0002
Current lb:-0.008954867720603943
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.5604279041290283

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2, 32, 16, 16]) pre split depth:  3
batch:  torch.Size([2, 32, 16, 16]) post split depth:  3
splitting decisions: 
split level 0: [2, 230] [2, 230] 
split level 1: [2, 7] [2, 7] 
split level 2: [2, 18] [2, 18] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -2.039703845977783 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.010094642639160156
This batch time : update_bounds func: 0.0160	 prepare: 0.0027	 bound: 0.0103	 transfer: 0.0018	 finalize: 0.0010
Accumulated time: update_bounds func: 3.0794	 prepare: 0.0642	 bound: 2.9636	 transfer: 0.0018	 finalize: 0.0242
batch bounding time:  0.016047954559326172
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0422	 pickout: 0.0011	 decision: 0.0231	 get_bound: 0.0180	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.6028339862823486

Image 95 label 5 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.6847336292266846
95 1.0000000116860974e-07
##### [0:95] Tested against 0 ######
Model prediction is: tensor([[-43.1365, -41.6500, -43.4775, -43.3514, -43.6991, -43.1254, -43.1545,
         -45.7754, -44.5673, -44.6309]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /34 start_node /35
setting alpha for layer /34 start_node /45
not setting layer /34 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /36 start_node /45
not setting layer /36 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /46 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /33 torch.Size([1, 32, 16, 16])
1 /35 torch.Size([1, 128, 8, 8])
2 /45 torch.Size([1, 250])
best_l after optimization: 0.17637956142425537 with beta sum per layer: []
alpha/beta optimization time: 1.1999423503875732
alpha-CROWN with fixed intermediate bounds: tensor([[-0.1764]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.17637956142425537
layer 0 size torch.Size([8192]) unstable 1206/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:462: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(preprocess_cifar(eps_temp, perturbation=True)).reshape(1,-1,1,1)

layer 1 size torch.Size([8192]) unstable 562
layer 2 size torch.Size([250]) unstable 34
-----------------
# of unstable neurons: 1802
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 186] 
split level 1: [2, 138] 
split level 2: [2, 16] 
split level 3: [2, 18] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -5.960830211639404 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.015357255935668945
This batch time : update_bounds func: 0.0263	 prepare: 0.0056	 bound: 0.0167	 transfer: 0.0024	 finalize: 0.0015
Accumulated time: update_bounds func: 3.1057	 prepare: 0.0699	 bound: 2.9802	 transfer: 0.0024	 finalize: 0.0257
batch bounding time:  0.02634572982788086
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0583	 pickout: 0.0008	 decision: 0.0290	 get_bound: 0.0284	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.294102430343628

Image 95 label 0 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.3900859355926514
95 1.0000000116860974e-07
##### [0:95] Tested against 3 ######
Initial alpha-CROWN verified for label 3 with bound 0.0514586940407753
Image 95 label 3 verification end, final lower bound 0.0514586940407753, upper bound inf, time: 0.000446319580078125
95 0.0514586940407753
##### [0:95] Tested against 2 ######
Model prediction is: tensor([[-43.1365, -41.6500, -43.4775, -43.3514, -43.6991, -43.1254, -43.1545,
         -45.7754, -44.5673, -44.6309]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /34 start_node /35
setting alpha for layer /34 start_node /45
not setting layer /34 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /36 start_node /45
not setting layer /36 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /46 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /33 torch.Size([1, 32, 16, 16])
1 /35 torch.Size([1, 128, 8, 8])
2 /45 torch.Size([1, 250])
best_l after optimization: 0.22864675521850586 with beta sum per layer: []
alpha/beta optimization time: 1.183359146118164
alpha-CROWN with fixed intermediate bounds: tensor([[-0.2286]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.22864675521850586
layer 0 size torch.Size([8192]) unstable 1206
layer 1 size torch.Size([8192]) unstable 562
layer 2 size torch.Size([250]) unstable 34
-----------------
# of unstable neurons: 1802
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 186] 
split level 1: [2, 72] 
split level 2: [2, 227] 
split level 3: [2, 138] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -5.696053504943848 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.011064291000366211
This batch time : update_bounds func: 0.0181	 prepare: 0.0041	 bound: 0.0117	 transfer: 0.0012	 finalize: 0.0010
Accumulated time: update_bounds func: 3.1237	 prepare: 0.0740	 bound: 2.9919	 transfer: 0.0012	 finalize: 0.0267
batch bounding time:  0.018110036849975586
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0500	 pickout: 0.0009	 decision: 0.0289	 get_bound: 0.0202	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.2651946544647217

Image 95 label 2 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.3524115085601807
95 1.0000000116860974e-07
##### [0:95] Tested against 4 ######
Model prediction is: tensor([[-43.1365, -41.6500, -43.4775, -43.3514, -43.6991, -43.1254, -43.1545,
         -45.7754, -44.5673, -44.6309]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /34 start_node /35
setting alpha for layer /34 start_node /45
not setting layer /34 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /36 start_node /45
not setting layer /36 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /46 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /33 torch.Size([1, 32, 16, 16])
1 /35 torch.Size([1, 128, 8, 8])
2 /45 torch.Size([1, 250])
best_l after optimization: 0.0523982048034668 with beta sum per layer: []
alpha/beta optimization time: 1.200855016708374
alpha-CROWN with fixed intermediate bounds: tensor([[-0.0524]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.0523982048034668
layer 0 size torch.Size([8192]) unstable 1206
layer 1 size torch.Size([8192]) unstable 562
layer 2 size torch.Size([250]) unstable 34
-----------------
# of unstable neurons: 1802
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 230] 
split level 1: [2, 115] 
split level 2: [2, 186] 
split level 3: [2, 10] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -9.686640739440918 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.012919425964355469
This batch time : update_bounds func: 0.0199	 prepare: 0.0031	 bound: 0.0134	 transfer: 0.0022	 finalize: 0.0011
Accumulated time: update_bounds func: 3.1437	 prepare: 0.0770	 bound: 3.0053	 transfer: 0.0022	 finalize: 0.0278
batch bounding time:  0.019986629486083984
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0523	 pickout: 0.0009	 decision: 0.0293	 get_bound: 0.0221	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.284773349761963

Image 95 label 4 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.406566858291626
95 1.0000000116860974e-07
##### [0:95] Tested against 8 ######
Initial alpha-CROWN verified for label 8 with bound 1.526841640472412
Image 95 label 8 verification end, final lower bound 1.526841640472412, upper bound inf, time: 0.0003762245178222656
95 1.526841640472412
##### [0:95] Tested against 9 ######
Initial alpha-CROWN verified for label 9 with bound 1.8125706911087036
Image 95 label 9 verification end, final lower bound 1.8125706911087036, upper bound inf, time: 0.00036787986755371094
95 1.8125706911087036
##### [0:95] Tested against 7 ######
Initial alpha-CROWN verified for label 7 with bound 1.8831281661987305
Image 95 label 7 verification end, final lower bound 1.8831281661987305, upper bound inf, time: 0.000392913818359375
95 1.8831281661987305
##### [0:95] Tested against 1 ######
groundtruth label, skip!
Result: image 95 verification success (with branch and bound)!
Wall time: 24.365391731262207

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 1): [95]
verification failure idx (total 0): []
final verified acc: 100.0%[1]
verifier is called on 1 examples.
total verified: 1
mean time [cnt:1] (excluding attack success): 21.996264696121216
