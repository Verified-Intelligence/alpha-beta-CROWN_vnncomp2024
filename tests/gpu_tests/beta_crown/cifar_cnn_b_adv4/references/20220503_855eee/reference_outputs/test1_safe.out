Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_cnn_b_adv4.model
  name: cnn_4layer_b4
data:
  start: 13
  end: 14
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR_SDP
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.00784313725
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 256
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 60
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:14:01 2022 on diablo.cs.ucla.edu
Sequential(
  (0): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)
  (1): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2))
  (2): ReLU()
  (3): Conv2d(32, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (4): ReLU()
  (5): Flatten()
  (6): Linear(in_features=8192, out_features=250, bias=True)
  (7): ReLU()
  (8): Linear(in_features=250, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([200, 3, 32, 32]) torch.Size([200]) torch.Size([200])
X range: tensor(2.1256) tensor(-1.9889) tensor(-0.0131)
############################
epsilon after preprocessing: tensor([[[[0.0317]],

         [[0.0322]],

         [[0.0300]]]]), data_max = tensor([[[[2.0587]],

         [[2.1256]],

         [[2.1154]]]]), data_min = tensor([[[[-1.9889]],

         [[-1.9807]],

         [[-1.7076]]]])
Task length: 1
saving results to Verified_ret_[cnn_4layer_b4]_start=13_end=14_iter=20_b=256_timeout=60_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 13 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 1, correct label 1, image norm 2000.8524169921875, logits tensor([-69.5804, -68.2390, -72.2027, -73.9836, -74.2991, -74.8349, -73.7351,
        -76.1907, -70.3856, -71.3245], device='cuda:0',
       grad_fn=<SelectBackward>)
##### PGD attack: True label: 1, Tested against: ['all'] ######
pgd prediction: tensor([-67.1816, -66.6194, -69.7446, -71.6599, -71.7837, -72.5129, -71.3946,
        -73.7710, -68.0119, -69.3857], device='cuda:0',
       grad_fn=<SqueezeBackward1>)
attack margin tensor([0.5622,    inf, 3.1252, 5.0405, 5.1643, 5.8935, 4.7752, 7.1516, 1.3925,
        2.7663], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[-69.5804, -68.2390, -72.2027, -73.9836, -74.2991, -74.8349, -73.7351,
         -76.1907, -70.3856, -71.3245]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-0.5070,  1.6392,  3.6869,  3.4012,  4.4871,  3.3828,  5.0388,  0.3471,
          2.0109]], device='cuda:0') None
best_l after optimization: -24.182859420776367 with beta sum per layer: []
alpha/beta optimization time: 8.364998817443848
initial alpha-CROWN bounds: tensor([[-0.4432,  1.7155,  3.7651,  3.4988,  4.5655,  3.4551,  5.1522,  0.4165,
          2.0573]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.4432, device='cuda:0', grad_fn=<MinBackward1>)
Sorted order for labels to verify: [0, 8, 9, 2, 6, 3, 4, 5, 7, 1]
##### [0:13] Tested against 0 ######
Model prediction is: tensor([[-69.5804, -68.2390, -72.2027, -73.9836, -74.2991, -74.8349, -73.7351,
         -76.1907, -70.3856, -71.3245]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /34 start_node /35
setting alpha for layer /34 start_node /45
not setting layer /34 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /36 start_node /45
not setting layer /36 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /46 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /33 torch.Size([1, 32, 16, 16])
1 /35 torch.Size([1, 128, 8, 8])
2 /45 torch.Size([1, 250])
best_l after optimization: 0.44314098358154297 with beta sum per layer: []
alpha/beta optimization time: 2.0458641052246094
alpha-CROWN with fixed intermediate bounds: tensor([[-0.4431]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.44314098358154297
layer 0 size torch.Size([8192]) unstable 1364
layer 1 size torch.Size([8192]) unstable 469
layer 2 size torch.Size([250]) unstable 32
-----------------
# of unstable neurons: 1865
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 28] 
split level 1: [2, 54] 
split level 2: [2, 95] 
split level 3: [2, 18] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.6657754182815552 with beta sum per layer: [0.0, 0.0, 0.5300604104995728]
alpha/beta optimization time: 0.297224760055542
This batch time : update_bounds func: 0.3027	 prepare: 0.0025	 bound: 0.2975	 transfer: 0.0014	 finalize: 0.0013
Accumulated time: update_bounds func: 0.3027	 prepare: 0.0025	 bound: 0.2975	 transfer: 0.0014	 finalize: 0.0013
batch bounding time:  0.3028531074523926
Current worst splitting domains [lb, ub] (depth):
[-0.11933,   inf] (5), [-0.11538,   inf] (5), 
length of domains: 2
Total time: 0.3367	 pickout: 0.0011	 decision: 0.0303	 get_bound: 0.3051	 add_domain: 0.0002
Current lb:-0.11933231353759766
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.2582225799560547

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2, 32, 16, 16]) pre split depth:  3
batch:  torch.Size([2, 32, 16, 16]) post split depth:  3
splitting decisions: 
split level 0: [2, 31] [2, 31] 
split level 1: [2, 145] [2, 145] 
split level 2: [2, 97] [2, 97] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.17577749490737915 with beta sum per layer: [0.0, 0.0, 0.06313078850507736]
alpha/beta optimization time: 0.28489136695861816
This batch time : update_bounds func: 0.2908	 prepare: 0.0030	 bound: 0.2853	 transfer: 0.0012	 finalize: 0.0013
Accumulated time: update_bounds func: 0.5936	 prepare: 0.0055	 bound: 0.5828	 transfer: 0.0012	 finalize: 0.0025/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:462: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(preprocess_cifar(eps_temp, perturbation=True)).reshape(1,-1,1,1)

batch bounding time:  0.2911238670349121
Current worst splitting domains [lb, ub] (depth):
[-0.02110,   inf] (9), [-0.02032,   inf] (9), [-0.01806,   inf] (9), [-0.01742,   inf] (9), [-0.00862,   inf] (9), [-0.00827,   inf] (9), [-0.00687,   inf] (9), [-0.00664,   inf] (9), 
length of domains: 8
Total time: 0.3211	 pickout: 0.0011	 decision: 0.0265	 get_bound: 0.2931	 add_domain: 0.0004
Current lb:-0.021103166043758392
32 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.5795247554779053

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([8, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 171] [2, 171] [2, 171] [2, 171] [2, 171] [2, 171] [2, 171] [2, 171] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.14939706027507782 with beta sum per layer: [0.0, 0.0, 0.12626157701015472]
alpha/beta optimization time: 0.28111958503723145
This batch time : update_bounds func: 0.2876	 prepare: 0.0027	 bound: 0.2814	 transfer: 0.0020	 finalize: 0.0014
Accumulated time: update_bounds func: 0.8811	 prepare: 0.0082	 bound: 0.8642	 transfer: 0.0020	 finalize: 0.0039
batch bounding time:  0.2877645492553711
Current worst splitting domains [lb, ub] (depth):
[-0.00194,   inf] (11), [-0.00126,   inf] (11), 
length of domains: 2
Total time: 0.3155	 pickout: 0.0025	 decision: 0.0250	 get_bound: 0.2878	 add_domain: 0.0003
Current lb:-0.0019356193952262402
48 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.8953447341918945

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2, 32, 16, 16]) pre split depth:  3
batch:  torch.Size([2, 32, 16, 16]) post split depth:  3
splitting decisions: 
split level 0: [1, 6819] [1, 6819] 
split level 1: [2, 24] [2, 24] 
split level 2: [2, 212] [2, 212] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -1.1833915710449219 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.010479211807250977
This batch time : update_bounds func: 0.0166	 prepare: 0.0029	 bound: 0.0108	 transfer: 0.0017	 finalize: 0.0011
Accumulated time: update_bounds func: 0.8977	 prepare: 0.0111	 bound: 0.8750	 transfer: 0.0017	 finalize: 0.0051
batch bounding time:  0.01661539077758789
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0438	 pickout: 0.0012	 decision: 0.0239	 get_bound: 0.0187	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 3.939410924911499

Image 13 label 0 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 4.029708623886108
13 1.0000000116860974e-07
##### [0:13] Tested against 8 ######
Initial alpha-CROWN verified for label 8 with bound 0.416473388671875
Image 13 label 8 verification end, final lower bound 0.416473388671875, upper bound inf, time: 0.000415802001953125
13 0.416473388671875
##### [0:13] Tested against 9 ######
Initial alpha-CROWN verified for label 9 with bound 2.057316303253174
Image 13 label 9 verification end, final lower bound 2.057316303253174, upper bound inf, time: 0.0005116462707519531
13 2.057316303253174
##### [0:13] Tested against 2 ######
Initial alpha-CROWN verified for label 2 with bound 1.7155389785766602
Image 13 label 2 verification end, final lower bound 1.7155389785766602, upper bound inf, time: 0.00040602684020996094
13 1.7155389785766602
##### [0:13] Tested against 6 ######
Initial alpha-CROWN verified for label 6 with bound 3.4551334381103516
Image 13 label 6 verification end, final lower bound 3.4551334381103516, upper bound inf, time: 0.0003905296325683594
13 3.4551334381103516
##### [0:13] Tested against 3 ######
Initial alpha-CROWN verified for label 3 with bound 3.7651009559631348
Image 13 label 3 verification end, final lower bound 3.7651009559631348, upper bound inf, time: 0.00037932395935058594
13 3.7651009559631348
##### [0:13] Tested against 4 ######
Initial alpha-CROWN verified for label 4 with bound 3.4988460540771484
Image 13 label 4 verification end, final lower bound 3.4988460540771484, upper bound inf, time: 0.0003991127014160156
13 3.4988460540771484
##### [0:13] Tested against 5 ######
Initial alpha-CROWN verified for label 5 with bound 4.565493106842041
Image 13 label 5 verification end, final lower bound 4.565493106842041, upper bound inf, time: 0.0005335807800292969
13 4.565493106842041
##### [0:13] Tested against 7 ######
Initial alpha-CROWN verified for label 7 with bound 5.152196884155273
Image 13 label 7 verification end, final lower bound 5.152196884155273, upper bound inf, time: 0.0004248619079589844
13 5.152196884155273
##### [0:13] Tested against 1 ######
groundtruth label, skip!
Result: image 13 verification success (with branch and bound)!
Wall time: 16.465718746185303

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 1): [13]
verification failure idx (total 0): []
final verified acc: 100.0%[1]
verifier is called on 1 examples.
total verified: 1
mean time [cnt:1] (excluding attack success): 14.087389945983887
