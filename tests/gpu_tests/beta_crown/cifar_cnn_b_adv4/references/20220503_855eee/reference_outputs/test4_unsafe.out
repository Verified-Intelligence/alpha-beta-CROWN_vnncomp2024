Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_cnn_b_adv4.model
  name: cnn_4layer_b4
data:
  start: 167
  end: 168
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR_SDP
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.00784313725
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 256
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 60
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:15:21 2022 on diablo.cs.ucla.edu
Sequential(
  (0): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)
  (1): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2))
  (2): ReLU()
  (3): Conv2d(32, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (4): ReLU()
  (5): Flatten()
  (6): Linear(in_features=8192, out_features=250, bias=True)
  (7): ReLU()
  (8): Linear(in_features=250, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([200, 3, 32, 32]) torch.Size([200]) torch.Size([200])
X range: tensor(2.1256) tensor(-1.9889) tensor(-0.0131)
############################
epsilon after preprocessing: tensor([[[[0.0317]],

         [[0.0322]],

         [[0.0300]]]]), data_max = tensor([[[[2.0587]],

         [[2.1256]],

         [[2.1154]]]]), data_min = tensor([[[[-1.9889]],

         [[-1.9807]],

         [[-1.7076]]]])
Task length: 1
saving results to Verified_ret_[cnn_4layer_b4]_start=167_end=168_iter=20_b=256_timeout=60_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 167 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 0, correct label 0, image norm 2189.13134765625, logits tensor([-34.1157, -37.5360, -34.5235, -34.8107, -35.8718, -35.0469, -35.9611,
        -36.5355, -35.0861, -36.5753], device='cuda:0',
       grad_fn=<SelectBackward>)
Model prediction is: tensor([[-34.1157, -37.5360, -34.5235, -34.8107, -35.8718, -35.0469, -35.9611,
         -36.5355, -35.0861, -36.5753]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 1.5840, -1.2509, -0.8609, -0.1339, -0.6723,  0.2464,  0.3609, -0.5061,
          0.4767]], device='cuda:0') None
best_l after optimization: -0.12575072050094604 with beta sum per layer: []
alpha/beta optimization time: 8.18176555633545
initial alpha-CROWN bounds: tensor([[ 1.7138, -1.1615, -0.7864, -0.0315, -0.5966,  0.3188,  0.4772, -0.4128,
          0.6048]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-1.1615, device='cuda:0', grad_fn=<MinBackward1>)
##### [0:167] Tested against 2 ######
Model prediction is: tensor([[-34.1157, -37.5360, -34.5235, -34.8107, -35.8718, -35.0469, -35.9611,
         -36.5355, -35.0861, -36.5753]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /34 start_node /35
setting alpha for layer /34 start_node /45
not setting layer /34 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /36 start_node /45
not setting layer /36 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /46 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /33 torch.Size([1, 32, 16, 16])
1 /35 torch.Size([1, 128, 8, 8])
2 /45 torch.Size([1, 250])
best_l after optimization: 1.1613514423370361 with beta sum per layer: []
alpha/beta optimization time: 2.1086528301239014
alpha-CROWN with fixed intermediate bounds: tensor([[-1.1614]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-1.1613514423370361
layer 0 size torch.Size([8192]) unstable 1438
layer 1 size torch.Size([8192]) unstable 654
layer 2 size torch.Size([250]) unstable 37
-----------------
# of unstable neurons: 2129
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 104] 
split level 1: [2, 111] 
split level 2: [2, 171] 
split level 3: [2, 72] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 9.664277076721191 with beta sum per layer: [0.0, 0.0, 0.5774093270301819]
alpha/beta optimization time: 0.28936219215393066
This batch time : update_bounds func: 0.2957	 prepare: 0.0031	 bound: 0.2898	 transfer: 0.0014	 finalize: 0.0013
Accumulated time: update_bounds func: 0.2957	 prepare: 0.0031	 bound: 0.2898	 transfer: 0.0014	 finalize: 0.0013
batch bounding time:  0.2957956790924072
Current worst splitting domains [lb, ub] (depth):
[-0.75647,   inf] (5), [-0.75471,   inf] (5), [-0.75424,   inf] (5), [-0.75384,   inf] (5), [-0.75193,   inf] (5), [-0.74886,   inf] (5), [-0.74735,   inf] (5), [-0.74722,   inf] (5), [-0.53839,   inf] (5), [-0.52731,   inf] (5), [-0.52229,   inf] (5), [-0.50834,   inf] (5), [-0.40636,   inf] (5), [-0.39937,   inf] (5), [-0.37918,   inf] (5), [-0.36843,   inf] (5), 
length of domains: 16
Total time: 0.3305	 pickout: 0.0010	 decision: 0.0310	 get_bound: 0.2979	 add_domain: 0.0006
Current lb:-0.7564672827720642
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.321808338165283

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([16, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([16, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 115] [2, 115] [2, 115] [2, 115] [2, 215] [2, 227] [2, 215] [2, 227] [2, 215] [2, 115] 
regular batch size: 2*16, diving batch size 1*0
best_l after optimization: 16.344417572021484 with beta sum per layer: [0.0, 0.0, 1.5588223934173584]
alpha/beta optimization time: 0.27866315841674805
This batch time : update_bounds func: 0.2874	 prepare: 0.0039	 bound: 0.2789	 transfer: 0.0024	 finalize: 0.0021
Accumulated time: update_bounds func: 0.5831	 prepare: 0.0070	 bound: 0.5688	 transfer: 0.0024	 finalize: 0.0033
batch bounding time:  0.2875328063964844
Current worst splitting domains [lb, ub] (depth):
[-0.69497,   inf] (7), [-0.69153,   inf] (7), [-0.69091,   inf] (7), [-0.68915,   inf] (7), [-0.68912,   inf] (7), [-0.68574,   inf] (7), [-0.68476,   inf] (7), [-0.68359,   inf] (7), [-0.66157,   inf] (7), [-0.66086,   inf] (7), [-0.66064,   inf] (7), [-0.66011,   inf] (7), [-0.62860,   inf] (7), [-0.61558,   inf] (7), [-0.53654,   inf] (7), [-0.52927,   inf] (7), [-0.46400,   inf] (7), [-0.45721,   inf] (7), [-0.44785,   inf] (7), [-0.43629,   inf] (7), 
length of domains: 32
Total time: 0.3205	 pickout: 0.0036	 decision: 0.0279	 get_bound: 0.2876	 add_domain: 0.0014
Current lb:-0.6949712038040161
48 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.642629623413086

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([32, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([32, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 215] [2, 215] [2, 227] [2, 227] [2, 227] [2, 115] [2, 115] [2, 115] [2, 215] [2, 227] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: 26.02490997314453 with beta sum per layer: [0.0, 0.0, 5.0522613525390625]
alpha/beta optimization time: 0.2972126007080078
This batch time : update_bounds func: 0.3159	 prepare: 0.0063	 bound: 0.2975	 transfer: 0.0079	 finalize: 0.0040
Accumulated time: update_bounds func: 0.8990	 prepare: 0.0133	 bound: 0.8663	 transfer: 0.0079	 finalize: 0.0073
batch bounding time:  0.31606483459472656
Current worst splitting domains [lb, ub] (depth):
[-0.63328,   inf] (9), [-0.63215,   inf] (9), [-0.62792,   inf] (9), [-0.62768,   inf] (9), [-0.62556,   inf] (9), [-0.62387,   inf] (9), [-0.62372,   inf] (9), [-0.62052,   inf] (9), [-0.60379,   inf] (9), [-0.60377,   inf] (9), [-0.59900,   inf] (9), [-0.59764,   inf] (9), [-0.58784,   inf] (9), [-0.58643,   inf] (9), [-0.58541,   inf] (9), [-0.57786,   inf] (9), [-0.57124,   inf] (9), [-0.56253,   inf] (9), [-0.55781,   inf] (9), [-0.51909,   inf] (9), 
length of domains: 64
Total time: 0.3604	 pickout: 0.0066	 decision: 0.0351	 get_bound: 0.3162	 add_domain: 0.0025
Current lb:-0.633284866809845
112 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.003479242324829

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([64, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 227] [2, 227] [2, 115] [2, 215] [2, 215] [2, 227] [2, 215] [2, 215] [2, 227] [2, 215] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 32.799171447753906 with beta sum per layer: [0.0, 0.0, 22.348308563232422]
alpha/beta optimization time: 0.38167405128479004
This batch time : update_bounds func: 0.4212	 prepare: 0.0116	 bound: 0.3820	 transfer: 0.0187	 finalize: 0.0085
Accumulated time: update_bounds func: 1.3201	 prepare: 0.0249	 bound: 1.2483	 transfer: 0.0187	 finalize: 0.0159
batch bounding time:  0.4214346408843994
Current worst splitting domains [lb, ub] (depth):
[-0.57309,   inf] (11), [-0.57150,   inf] (11), [-0.56730,   inf] (11), [-0.56686,   inf] (11), [-0.56559,   inf] (11), [-0.56236,   inf] (11), [-0.56155,   inf] (11), [-0.56017,   inf] (11), [-0.54767,   inf] (11), [-0.54528,   inf] (11), [-0.54205,   inf] (11), [-0.54164,   inf] (11), [-0.53315,   inf] (11), [-0.53000,   inf] (11), [-0.52918,   inf] (11), [-0.52811,   inf] (11), [-0.51929,   inf] (11), [-0.51393,   inf] (11), [-0.50532,   inf] (11), [-0.50168,   inf] (11), 
length of domains: 107
Total time: 0.5000	 pickout: 0.0171	 decision: 0.0567	 get_bound: 0.4216	 add_domain: 0.0046
Current lb:-0.573093593120575
240 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.504330635070801

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([107, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([107, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 13] [2, 13] [2, 13] [2, 13] [2, 13] [2, 13] [2, 13] [2, 13] [2, 13] [2, 13] 
regular batch size: 2*107, diving batch size 1*0
best_l after optimization: 44.66426086425781 with beta sum per layer: [0.0, 0.0, 40.99370193481445]
alpha/beta optimization time: 0.4749889373779297
This batch time : update_bounds func: 0.5279	 prepare: 0.0180	 bound: 0.4753	 transfer: 0.0212	 finalize: 0.0129
Accumulated time: update_bounds func: 1.8481	 prepare: 0.0429	 bound: 1.7236	 transfer: 0.0212	 finalize: 0.0288
batch bounding time:  0.5282940864562988
Current worst splitting domains [lb, ub] (depth):
[-0.51856,   inf] (13), [-0.51724,   inf] (13), [-0.51320,   inf] (13), [-0.51139,   inf] (13), [-0.51096,   inf] (13), [-0.50883,   inf] (13), [-0.50848,   inf] (13), [-0.50706,   inf] (13), [-0.49498,   inf] (13), [-0.49103,   inf] (13), [-0.48821,   inf] (13), [-0.48655,   inf] (13), [-0.48249,   inf] (13), [-0.47895,   inf] (13), [-0.47789,   inf] (13), [-0.47637,   inf] (13), [-0.46082,   inf] (13), [-0.45843,   inf] (13), [-0.45539,   inf] (13), [-0.44802,   inf] (13), 
length of domains: 174
Total time: 0.6346	 pickout: 0.0210	 decision: 0.0772	 get_bound: 0.5286	 add_domain: 0.0078
Current lb:-0.5185551047325134
454 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.140720367431641

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([174, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([174, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 23] [2, 23] [2, 23] [2, 23] [2, 23] [2, 23] [2, 23] [2, 23] [2, 23] [2, 23] 
regular batch size: 2*174, diving batch size 1*0
best_l after optimization: 71.68882751464844 with beta sum per layer: [0.0, 0.0, 56.611961364746094]
alpha/beta optimization time: 0.6300222873687744
This batch time : update_bounds func: 0.7077	 prepare: 0.0287	 bound: 0.6303	 transfer: 0.0274	 finalize: 0.0204
Accumulated time: update_bounds func: 2.5557	 prepare: 0.0716	 bound: 2.3539	 transfer: 0.0274	 finalize: 0.0492
batch bounding time:  0.7080857753753662
Current worst splitting domains [lb, ub] (depth):
[-0.48426,   inf] (15), [-0.48210,   inf] (15), [-0.47572,   inf] (15), [-0.47558,   inf] (15), [-0.47414,   inf] (15), [-0.47180,   inf] (15), [-0.47050,   inf] (15), [-0.46963,   inf] (15), [-0.46083,   inf] (15), [-0.45555,   inf] (15), [-0.45178,   inf] (15), [-0.44942,   inf] (15), [-0.44443,   inf] (15), [-0.44199,   inf] (15), [-0.43897,   inf] (15), [-0.43708,   inf] (15), [-0.43502,   inf] (15), [-0.43244,   inf] (15), [-0.42886,   inf] (15), [-0.42680,   inf] (15), 
length of domains: 320
Total time: 0.8675	 pickout: 0.0361	 decision: 0.1073	 get_bound: 0.7086	 add_domain: 0.0155
Current lb:-0.48426440358161926
802 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.010699272155762

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 64] [2, 64] [2, 64] [2, 64] [2, 64] [2, 64] [2, 64] [2, 64] [2, 64] [2, 64] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 118.9195556640625 with beta sum per layer: [0.0, 0.0, 63.94776916503906]
alpha/beta optimization time: 0.8274545669555664
This batch time : update_bounds func: 0.9604	 prepare: 0.0443	 bound: 0.8278	 transfer: 0.0552	 finalize: 0.0318
Accumulated time: update_bounds func: 3.5162	 prepare: 0.1159	 bound: 3.1817	 transfer: 0.0552	 finalize: 0.0810
batch bounding time:  0.9610121250152588
Current worst splitting domains [lb, ub] (depth):
[-0.45195,   inf] (17), [-0.44921,   inf] (17), [-0.44485,   inf] (17), [-0.44404,   inf] (17), [-0.44299,   inf] (17), [-0.44110,   inf] (17), [-0.43961,   inf] (17), [-0.43954,   inf] (17), [-0.43903,   inf] (17), [-0.43861,   inf] (17), [-0.43754,   inf] (17), [-0.43597,   inf] (17), [-0.43545,   inf] (17), [-0.43480,   inf] (17), [-0.43250,   inf] (17), [-0.43238,   inf] (17), [-0.42656,   inf] (17), [-0.42327,   inf] (17), [-0.42020,   inf] (17), [-0.41984,   inf] (17), 
length of domains: 576
Total time: 1.2476	 pickout: 0.0527	 decision: 0.1484	 get_bound: 0.9618	 add_domain: 0.0847
Current lb:-0.4519504904747009
1314 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.261753797531128

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 230] [2, 230] [2, 230] [2, 230] [2, 225] [2, 230] [2, 225] [2, 230] [2, 230] [2, 230] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 120.06057739257812 with beta sum per layer: [0.0, 0.0, 61.63786315917969]
alpha/beta optimization time: 0.8286962509155273
This batch time : update_bounds func: 0.9604	 prepare: 0.0417	 bound: 0.8290	 transfer: 0.0584	 finalize: 0.0301
Accumulated time: update_bounds func: 4.4766	 prepare: 0.1576	 bound: 4.0108	 transfer: 0.0584	 finalize: 0.1111
batch bounding time:  0.961003303527832
Current worst splitting domains [lb, ub] (depth):
[-0.42457,   inf] (19), [-0.42242,   inf] (19), [-0.41754,   inf] (19), [-0.41723,   inf] (19), [-0.41699,   inf] (19), [-0.41466,   inf] (19), [-0.41263,   inf] (19), [-0.41240,   inf] (19), [-0.41238,   inf] (19), [-0.41226,   inf] (19), [-0.41122,   inf] (19), [-0.40928,   inf] (19), [-0.40902,   inf] (19), [-0.40828,   inf] (19), [-0.40624,   inf] (19), [-0.40497,   inf] (19), [-0.40071,   inf] (19), [-0.39813,   inf] (19), [-0.39655,   inf] (19), [-0.39457,   inf] (19), 
length of domains: 829
Total time: 1.1886	 pickout: 0.0538	 decision: 0.1452	 get_bound: 0.9618	 add_domain: 0.0278
Current lb:-0.42456740140914917
1826 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.453830242156982

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 225] [2, 225] [2, 160] [2, 230] [2, 225] [2, 225] [2, 225] [2, 160] [2, 160] [2, 230] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 120.57046508789062 with beta sum per layer: [0.0, 0.0, 54.23301696777344]
alpha/beta optimization time: 0.8220210075378418
This batch time : update_bounds func: 0.9538	 prepare: 0.0421	 bound: 0.8223	 transfer: 0.0564	 finalize: 0.0318
Accumulated time: update_bounds func: 5.4304	 prepare: 0.1997	 bound: 4.8331	 transfer: 0.0564	 finalize: 0.1430
batch bounding time:  0.9544129371643066
Current worst splitting domains [lb, ub] (depth):
[-0.39775,   inf] (21), [-0.39769,   inf] (21), [-0.39260,   inf] (21), [-0.39185,   inf] (21), [-0.39142,   inf] (21), [-0.38867,   inf] (21), [-0.38775,   inf] (21), [-0.38669,   inf] (21), [-0.38644,   inf] (21), [-0.38613,   inf] (21), [-0.38551,   inf] (21), [-0.38389,   inf] (21), [-0.38312,   inf] (21), [-0.38298,   inf] (21), [-0.38174,   inf] (21), [-0.38071,   inf] (21), [-0.37905,   inf] (21), [-0.37303,   inf] (21), [-0.37290,   inf] (21), [-0.37047,   inf] (21), 
length of domains: 1083
Total time: 1.1835	 pickout: 0.0539	 decision: 0.1455	 get_bound: 0.9552	 add_domain: 0.0289
Current lb:-0.3977470099925995
2338 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.64120364189148

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 160] [2, 160] [2, 225] [2, 160] [2, 160] [2, 160] [2, 160] [2, 225] [2, 225] [2, 225] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 111.03732299804688 with beta sum per layer: [0.0, 0.0, 56.979148864746094]
alpha/beta optimization time: 0.8218464851379395
This batch time : update_bounds func: 0.9481	 prepare: 0.0420	 bound: 0.8222	 transfer: 0.0515	 finalize: 0.0312
Accumulated time: update_bounds func: 6.3785	 prepare: 0.2418	 bound: 5.6553	 transfer: 0.0515	 finalize: 0.1742
batch bounding time:  0.948681116104126
Current worst splitting domains [lb, ub] (depth):
[-0.37500,   inf] (23), [-0.37293,   inf] (23), [-0.36870,   inf] (23), [-0.36869,   inf] (23), [-0.36640,   inf] (23), [-0.36561,   inf] (23), [-0.36423,   inf] (23), [-0.36326,   inf] (23), [-0.36273,   inf] (23), [-0.36237,   inf] (23), [-0.36150,   inf] (23), [-0.36007,   inf] (23), [-0.35928,   inf] (23), [-0.35885,   inf] (23), [-0.35883,   inf] (23), [-0.35729,   inf] (23), [-0.35586,   inf] (23), [-0.35116,   inf] (23), [-0.35026,   inf] (23), [-0.34814,   inf] (23), 
length of domains: 1338
Total time: 1.2328	 pickout: 0.0543	 decision: 0.1976	 get_bound: 0.9495	 add_domain: 0.0314
Current lb:-0.37500327825546265
2850 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.877772569656372

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 10] [2, 10] [2, 10] [2, 10] [2, 10] [2, 10] [2, 10] [2, 10] [2, 10] [2, 10] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 108.93008422851562 with beta sum per layer: [0.0, 0.0, 58.758113861083984]
alpha/beta optimization time: 0.8317177295684814
This batch time : update_bounds func: 0.9636	 prepare: 0.0428	 bound: 0.8320	 transfer: 0.0564	 finalize: 0.0311
Accumulated time: update_bounds func: 7.3421	 prepare: 0.2846	 bound: 6.4873	 transfer: 0.0564	 finalize: 0.2053
batch bounding time:  0.9641401767730713
Current worst splitting domains [lb, ub] (depth):
[-0.35748,   inf] (25), [-0.35554,   inf] (25), [-0.35085,   inf] (25), [-0.35042,   inf] (25), [-0.34829,   inf] (25), [-0.34720,   inf] (25), [-0.34578,   inf] (25), [-0.34537,   inf] (25), [-0.34457,   inf] (25), [-0.34425,   inf] (25), [-0.34291,   inf] (25), [-0.34151,   inf] (25), [-0.34122,   inf] (25), [-0.34057,   inf] (25), [-0.33961,   inf] (25), [-0.33786,   inf] (25), [-0.33670,   inf] (25), [-0.33329,   inf] (25), [-0.33167,   inf] (25), [-0.32978,   inf] (25), 
length of domains: 1591
Total time: 1.2284	 pickout: 0.0841	 decision: 0.1462	 get_bound: 0.9649	 add_domain: 0.0332
Current lb:-0.35748109221458435
3362 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.110211849212646

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 84] [2, 84] [2, 84] [2, 84] [2, 84] [2, 84] [2, 84] [2, 24] [2, 84] [2, 84] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 94.97410583496094 with beta sum per layer: [0.0, 0.0, 65.2807846069336]
alpha/beta optimization time: 0.8164124488830566
This batch time : update_bounds func: 1.0182	 prepare: 0.0423	 bound: 0.8167	 transfer: 0.0553	 finalize: 0.1027
Accumulated time: update_bounds func: 8.3603	 prepare: 0.3269	 bound: 7.3040	 transfer: 0.0553	 finalize: 0.3080
batch bounding time:  1.0188548564910889
Current worst splitting domains [lb, ub] (depth):
[-0.34516,   inf] (27), [-0.34345,   inf] (27), [-0.33884,   inf] (27), [-0.33824,   inf] (27), [-0.33580,   inf] (27), [-0.33462,   inf] (27), [-0.33353,   inf] (27), [-0.33332,   inf] (27), [-0.33257,   inf] (27), [-0.33177,   inf] (27), [-0.33065,   inf] (27), [-0.32912,   inf] (27), [-0.32866,   inf] (27), [-0.32812,   inf] (27), [-0.32747,   inf] (27), [-0.32559,   inf] (27), [-0.32430,   inf] (27), [-0.32002,   inf] (27), [-0.31921,   inf] (27), [-0.31678,   inf] (27), 
length of domains: 1845
Total time: 1.2549	 pickout: 0.0571	 decision: 0.1444	 get_bound: 1.0197	 add_domain: 0.0338
Current lb:-0.34515610337257385
3874 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.369112968444824

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 24] [2, 24] [2, 24] [2, 24] [2, 24] [2, 24] [2, 84] [2, 24] [2, 24] [2, 24] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 96.98812866210938 with beta sum per layer: [0.0, 0.0, 57.814125061035156]
alpha/beta optimization time: 0.819016695022583
This batch time : update_bounds func: 0.9496	 prepare: 0.0425	 bound: 0.8193	 transfer: 0.0535	 finalize: 0.0331
Accumulated time: update_bounds func: 9.3099	 prepare: 0.3694	 bound: 8.1233	 transfer: 0.0535	 finalize: 0.3411
batch bounding time:  0.9501991271972656
Current worst splitting domains [lb, ub] (depth):
[-0.33478,   inf] (29), [-0.33168,   inf] (29), [-0.32790,   inf] (29), [-0.32703,   inf] (29), [-0.32465,   inf] (29), [-0.32438,   inf] (29), [-0.32325,   inf] (29), [-0.32177,   inf] (29), [-0.32149,   inf] (29), [-0.32095,   inf] (29), [-0.31907,   inf] (29), [-0.31883,   inf] (29), [-0.31864,   inf] (29), [-0.31682,   inf] (29), [-0.31621,   inf] (29), [-0.31549,   inf] (29), [-0.31393,   inf] (29), [-0.30996,   inf] (29), [-0.30911,   inf] (29), [-0.30657,   inf] (29), 
length of domains: 2097
Total time: 1.1878	 pickout: 0.0559	 decision: 0.1457	 get_bound: 0.9510	 add_domain: 0.0353
Current lb:-0.33477798104286194
4386 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.56117057800293

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 190] [2, 190] [2, 190] [2, 190] [2, 190] [2, 190] [2, 190] [2, 190] [2, 82] [2, 190] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 89.36869049072266 with beta sum per layer: [0.0, 0.0, 70.3642807006836]
alpha/beta optimization time: 0.8204896450042725
This batch time : update_bounds func: 0.9530	 prepare: 0.0432	 bound: 0.8208	 transfer: 0.0565	 finalize: 0.0312
Accumulated time: update_bounds func: 10.2629	 prepare: 0.4126	 bound: 8.9441	 transfer: 0.0565	 finalize: 0.3723
batch bounding time:  0.9535806179046631
Current worst splitting domains [lb, ub] (depth):
[-0.32660,   inf] (31), [-0.32364,   inf] (31), [-0.31975,   inf] (31), [-0.31905,   inf] (31), [-0.31683,   inf] (31), [-0.31642,   inf] (31), [-0.31550,   inf] (31), [-0.31390,   inf] (31), [-0.31339,   inf] (31), [-0.31316,   inf] (31), [-0.31184,   inf] (31), [-0.31100,   inf] (31), [-0.31072,   inf] (31), [-0.31045,   inf] (31), [-0.30893,   inf] (31), [-0.30836,   inf] (31), [-0.30753,   inf] (31), [-0.30744,   inf] (31), [-0.30570,   inf] (31), [-0.30445,   inf] (31), 
length of domains: 2337
Total time: 1.2749	 pickout: 0.0631	 decision: 0.1523	 get_bound: 0.9544	 add_domain: 0.1052
Current lb:-0.32660114765167236
4898 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.840103387832642

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 82] [2, 82] [2, 82] [2, 82] [2, 82] [2, 82] [2, 82] [2, 82] [2, 190] [2, 82] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 97.70060729980469 with beta sum per layer: [0.0, 0.0, 55.384437561035156]
alpha/beta optimization time: 0.8197858333587646
This batch time : update_bounds func: 0.9517	 prepare: 0.0438	 bound: 0.8201	 transfer: 0.0536	 finalize: 0.0330
Accumulated time: update_bounds func: 11.2147	 prepare: 0.4564	 bound: 9.7642	 transfer: 0.0536	 finalize: 0.4053
batch bounding time:  0.9523277282714844
Current worst splitting domains [lb, ub] (depth):
[-0.31885,   inf] (33), [-0.31600,   inf] (33), [-0.31478,   inf] (33), [-0.31208,   inf] (33), [-0.31150,   inf] (33), [-0.31037,   inf] (33), [-0.30937,   inf] (33), [-0.30847,   inf] (33), [-0.30804,   inf] (33), [-0.30799,   inf] (33), [-0.30652,   inf] (33), [-0.30650,   inf] (33), [-0.30585,   inf] (33), [-0.30581,   inf] (33), [-0.30548,   inf] (33), [-0.30405,   inf] (33), [-0.30304,   inf] (33), [-0.30290,   inf] (33), [-0.30256,   inf] (33), [-0.30197,   inf] (33), 
length of domains: 2576
Total time: 1.1937	 pickout: 0.0579	 decision: 0.1465	 get_bound: 0.9531	 add_domain: 0.0362
Current lb:-0.3188539445400238
5410 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.03835153579712

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 8] [1, 8115] [2, 8] [2, 8] [2, 8] [1, 8115] [2, 8] [1, 7794] [2, 8] [2, 8] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 81.94132995605469 with beta sum per layer: [0.0, 0.42966747283935547, 66.85513305664062]
alpha/beta optimization time: 0.8175375461578369
This batch time : update_bounds func: 0.9484	 prepare: 0.0436	 bound: 0.8179	 transfer: 0.0537	 finalize: 0.0318
Accumulated time: update_bounds func: 12.1630	 prepare: 0.5000	 bound: 10.5821	 transfer: 0.0537	 finalize: 0.4371
batch bounding time:  0.9489231109619141
Current worst splitting domains [lb, ub] (depth):
[-0.31272,   inf] (35), [-0.31035,   inf] (35), [-0.30949,   inf] (35), [-0.30856,   inf] (35), [-0.30595,   inf] (35), [-0.30585,   inf] (35), [-0.30410,   inf] (35), [-0.30407,   inf] (35), [-0.30317,   inf] (35), [-0.30172,   inf] (35), [-0.30172,   inf] (35), [-0.30167,   inf] (35), [-0.30118,   inf] (35), [-0.30069,   inf] (35), [-0.30051,   inf] (35), [-0.29992,   inf] (35), [-0.29953,   inf] (35), [-0.29888,   inf] (35), [-0.29813,   inf] (35), [-0.29800,   inf] (35), 
length of domains: 2749
Total time: 1.1867	 pickout: 0.0570	 decision: 0.1460	 get_bound: 0.9497	 add_domain: 0.0340
Current lb:-0.3127242624759674
5922 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.229671239852905

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1794] [2, 8] [2, 8] [1, 1794] [1, 1794] [1, 8115] [2, 8] [2, 8] [1, 1794] [1, 8115] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 112.19620513916016 with beta sum per layer: [0.0, 7.112235069274902, 33.851348876953125]
alpha/beta optimization time: 0.8139948844909668
This batch time : update_bounds func: 0.9468	 prepare: 0.0451	 bound: 0.8143	 transfer: 0.0534	 finalize: 0.0329
Accumulated time: update_bounds func: 13.1099	 prepare: 0.5450	 bound: 11.3964	 transfer: 0.0534	 finalize: 0.4700
batch bounding time:  0.9474234580993652
Current worst splitting domains [lb, ub] (depth):
[-0.30759,   inf] (37), [-0.30566,   inf] (37), [-0.30475,   inf] (37), [-0.30394,   inf] (37), [-0.30341,   inf] (37), [-0.30166,   inf] (37), [-0.30059,   inf] (37), [-0.30054,   inf] (37), [-0.30013,   inf] (37), [-0.29914,   inf] (37), [-0.29844,   inf] (37), [-0.29839,   inf] (37), [-0.29801,   inf] (37), [-0.29785,   inf] (37), [-0.29664,   inf] (37), [-0.29639,   inf] (37), [-0.29617,   inf] (37), [-0.29568,   inf] (37), [-0.29557,   inf] (37), [-0.29540,   inf] (37), 
length of domains: 2970
Total time: 1.2724	 pickout: 0.0557	 decision: 0.2307	 get_bound: 0.9482	 add_domain: 0.0378
Current lb:-0.307587206363678
6434 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 19.506283044815063

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 410] [1, 410] [1, 410] [1, 410] [1, 410] [1, 410] [1, 2368] [1, 1794] [1, 1794] [1, 2368] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 131.02706909179688 with beta sum per layer: [0.0, 9.871726989746094, 15.387469291687012]
alpha/beta optimization time: 0.81571364402771
This batch time : update_bounds func: 0.9551	 prepare: 0.0473	 bound: 0.8161	 transfer: 0.0556	 finalize: 0.0349
Accumulated time: update_bounds func: 14.0650	 prepare: 0.5923	 bound: 12.2124	 transfer: 0.0556	 finalize: 0.5049
batch bounding time:  0.9557831287384033
Current worst splitting domains [lb, ub] (depth):
[-0.30368,   inf] (39), [-0.30173,   inf] (39), [-0.30136,   inf] (39), [-0.29943,   inf] (39), [-0.29942,   inf] (39), [-0.29935,   inf] (39), [-0.29862,   inf] (39), [-0.29764,   inf] (39), [-0.29759,   inf] (39), [-0.29702,   inf] (39), [-0.29672,   inf] (39), [-0.29623,   inf] (39), [-0.29591,   inf] (39), [-0.29575,   inf] (39), [-0.29574,   inf] (39), [-0.29529,   inf] (39), [-0.29511,   inf] (39), [-0.29474,   inf] (39), [-0.29402,   inf] (39), [-0.29360,   inf] (39), 
length of domains: 3219
Total time: 1.2042	 pickout: 0.0563	 decision: 0.1458	 get_bound: 0.9566	 add_domain: 0.0455
Current lb:-0.3036781847476959
6946 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 20.71548080444336

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1795] [1, 1795] [1, 2651] [1, 1795] [1, 1794] [1, 7126] [1, 1794] [1, 2368] [1, 7126] [1, 1794] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 135.56089782714844 with beta sum per layer: [0.0, 18.435073852539062, 9.680757522583008]
alpha/beta optimization time: 0.8297851085662842
This batch time : update_bounds func: 1.0776	 prepare: 0.0502	 bound: 0.8302	 transfer: 0.0630	 finalize: 0.1328
Accumulated time: update_bounds func: 15.1426	 prepare: 0.6425	 bound: 13.0426	 transfer: 0.0630	 finalize: 0.6377
batch bounding time:  1.078261375427246
Current worst splitting domains [lb, ub] (depth):
[-0.29950,   inf] (41), [-0.29870,   inf] (41), [-0.29781,   inf] (41), [-0.29737,   inf] (41), [-0.29734,   inf] (41), [-0.29552,   inf] (41), [-0.29506,   inf] (41), [-0.29503,   inf] (41), [-0.29483,   inf] (41), [-0.29406,   inf] (41), [-0.29383,   inf] (41), [-0.29370,   inf] (41), [-0.29367,   inf] (41), [-0.29311,   inf] (41), [-0.29278,   inf] (41), [-0.29257,   inf] (41), [-0.29239,   inf] (41), [-0.29209,   inf] (41), [-0.29206,   inf] (41), [-0.29182,   inf] (41), 
length of domains: 3470
Total time: 1.3295	 pickout: 0.0582	 decision: 0.1465	 get_bound: 1.0791	 add_domain: 0.0457
Current lb:-0.2995043992996216
7458 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 22.04955267906189

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 8115] [1, 2651] [1, 1795] [1, 8115] [1, 8115] [1, 2368] [1, 2651] [1, 8115] [1, 1795] [1, 1795] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 132.85467529296875 with beta sum per layer: [0.0, 42.90311813354492, 10.277956008911133]
alpha/beta optimization time: 0.8350591659545898
This batch time : update_bounds func: 0.9866	 prepare: 0.0478	 bound: 0.8354	 transfer: 0.0606	 finalize: 0.0415
Accumulated time: update_bounds func: 16.1292	 prepare: 0.6902	 bound: 13.8781	 transfer: 0.0606	 finalize: 0.6793
batch bounding time:  0.9872028827667236
Current worst splitting domains [lb, ub] (depth):
[-0.29537,   inf] (43), [-0.29514,   inf] (43), [-0.29444,   inf] (43), [-0.29365,   inf] (43), [-0.29321,   inf] (43), [-0.29320,   inf] (43), [-0.29283,   inf] (43), [-0.29228,   inf] (43), [-0.29225,   inf] (43), [-0.29174,   inf] (43), [-0.29150,   inf] (43), [-0.29115,   inf] (43), [-0.29090,   inf] (43), [-0.29037,   inf] (43), [-0.29009,   inf] (43), [-0.28996,   inf] (43), [-0.28991,   inf] (43), [-0.28984,   inf] (43), [-0.28967,   inf] (43), [-0.28960,   inf] (43), 
length of domains: 3711
Total time: 1.2490	 pickout: 0.0560	 decision: 0.1471	 get_bound: 0.9880	 add_domain: 0.0579
Current lb:-0.295369952917099
7970 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 23.305453300476074

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2651] [1, 8115] [1, 2651] [1, 8115] [1, 2651] [1, 2651] [1, 8115] [1, 2651] [1, 2651] [1, 8115] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 141.5528106689453 with beta sum per layer: [0.0, 30.994001388549805, 3.089080333709717]
alpha/beta optimization time: 0.841977596282959
This batch time : update_bounds func: 0.9864	 prepare: 0.0574	 bound: 0.8423	 transfer: 0.0543	 finalize: 0.0311
Accumulated time: update_bounds func: 17.1157	 prepare: 0.7477	 bound: 14.7204	 transfer: 0.0543	 finalize: 0.7103
batch bounding time:  0.9870195388793945
Current worst splitting domains [lb, ub] (depth):
[-0.29182,   inf] (45), [-0.29099,   inf] (45), [-0.29086,   inf] (45), [-0.29006,   inf] (45), [-0.28965,   inf] (45), [-0.28964,   inf] (45), [-0.28951,   inf] (45), [-0.28868,   inf] (45), [-0.28868,   inf] (45), [-0.28866,   inf] (45), [-0.28859,   inf] (45), [-0.28777,   inf] (45), [-0.28765,   inf] (45), [-0.28735,   inf] (45), [-0.28734,   inf] (45), [-0.28710,   inf] (45), [-0.28644,   inf] (45), [-0.28642,   inf] (45), [-0.28638,   inf] (45), [-0.28621,   inf] (45), 
length of domains: 3967
Total time: 1.2577	 pickout: 0.0723	 decision: 0.1511	 get_bound: 0.9878	 add_domain: 0.0466
Current lb:-0.29182296991348267
8482 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 24.56814980506897

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2368] [1, 7126] [1, 2368] [1, 2368] [1, 2368] [1, 2368] [1, 7126] [1, 2368] [1, 7126] [1, 2368] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 140.76998901367188 with beta sum per layer: [0.0, 66.99501037597656, 3.01910400390625]
alpha/beta optimization time: 0.8420469760894775
This batch time : update_bounds func: 0.9759	 prepare: 0.0471	 bound: 0.8424	 transfer: 0.0542	 finalize: 0.0310
Accumulated time: update_bounds func: 18.0916	 prepare: 0.7947	 bound: 15.5627	 transfer: 0.0542	 finalize: 0.7413
batch bounding time:  0.9765288829803467
Current worst splitting domains [lb, ub] (depth):
[-0.28811,   inf] (47), [-0.28747,   inf] (47), [-0.28735,   inf] (47), [-0.28709,   inf] (47), [-0.28634,   inf] (47), [-0.28629,   inf] (47), [-0.28600,   inf] (47), [-0.28575,   inf] (47), [-0.28575,   inf] (47), [-0.28560,   inf] (47), [-0.28558,   inf] (47), [-0.28552,   inf] (47), [-0.28515,   inf] (47), [-0.28497,   inf] (47), [-0.28483,   inf] (47), [-0.28474,   inf] (47), [-0.28470,   inf] (47), [-0.28460,   inf] (47), [-0.28458,   inf] (47), [-0.28446,   inf] (47), 
length of domains: 4223
Total time: 1.3309	 pickout: 0.0576	 decision: 0.2459	 get_bound: 0.9773	 add_domain: 0.0502
Current lb:-0.28811269998550415
8994 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 25.90380835533142

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7126] [1, 2368] [1, 7126] [1, 7126] [1, 7126] [1, 7126] [1, 2368] [1, 7126] [1, 7126] [1, 7126] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 139.91128540039062 with beta sum per layer: [0.0, 66.22555541992188, 2.2376182079315186]
alpha/beta optimization time: 0.8542697429656982
This batch time : update_bounds func: 0.9973	 prepare: 0.0536	 bound: 0.8547	 transfer: 0.0551	 finalize: 0.0326
Accumulated time: update_bounds func: 19.0889	 prepare: 0.8483	 bound: 16.4174	 transfer: 0.0551	 finalize: 0.7738
batch bounding time:  0.997913122177124
Current worst splitting domains [lb, ub] (depth):
[-0.28463,   inf] (49), [-0.28385,   inf] (49), [-0.28376,   inf] (49), [-0.28361,   inf] (49), [-0.28297,   inf] (49), [-0.28287,   inf] (49), [-0.28280,   inf] (49), [-0.28229,   inf] (49), [-0.28228,   inf] (49), [-0.28226,   inf] (49), [-0.28218,   inf] (49), [-0.28210,   inf] (49), [-0.28206,   inf] (49), [-0.28203,   inf] (49), [-0.28152,   inf] (49), [-0.28147,   inf] (49), [-0.28140,   inf] (49), [-0.28135,   inf] (49), [-0.28130,   inf] (49), [-0.28126,   inf] (49), 
length of domains: 4479
Total time: 1.2716	 pickout: 0.0659	 decision: 0.1579	 get_bound: 0.9987	 add_domain: 0.0491
Current lb:-0.2846265137195587
9506 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 27.180860996246338

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1802] [1, 1802] [1, 1802] [1, 1802] [1, 1802] [1, 1802] [1, 1802] [1, 1802] [1, 1802] [1, 1802] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 139.13941955566406 with beta sum per layer: [0.0, 66.3669204711914, 2.8000521659851074]
alpha/beta optimization time: 0.8318591117858887
This batch time : update_bounds func: 1.0742	 prepare: 0.0478	 bound: 0.8322	 transfer: 0.0541	 finalize: 0.1386
Accumulated time: update_bounds func: 20.1631	 prepare: 0.8961	 bound: 17.2496	 transfer: 0.0541	 finalize: 0.9125
batch bounding time:  1.074796438217163
Current worst splitting domains [lb, ub] (depth):
[-0.28099,   inf] (51), [-0.28024,   inf] (51), [-0.28000,   inf] (51), [-0.27997,   inf] (51), [-0.27995,   inf] (51), [-0.27957,   inf] (51), [-0.27954,   inf] (51), [-0.27922,   inf] (51), [-0.27900,   inf] (51), [-0.27895,   inf] (51), [-0.27890,   inf] (51), [-0.27886,   inf] (51), [-0.27871,   inf] (51), [-0.27858,   inf] (51), [-0.27857,   inf] (51), [-0.27855,   inf] (51), [-0.27848,   inf] (51), [-0.27836,   inf] (51), [-0.27822,   inf] (51), [-0.27813,   inf] (51), 
length of domains: 4735
Total time: 1.3329	 pickout: 0.0587	 decision: 0.1476	 get_bound: 1.0756	 add_domain: 0.0510
Current lb:-0.28098636865615845
10018 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 28.51901626586914

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2467] [1, 2467] [1, 2467] [1, 2467] [1, 2467] [1, 2467] [1, 2467] [1, 2467] [1, 2467] [1, 2467] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 138.06776428222656 with beta sum per layer: [0.0, 57.77271270751953, 2.159895420074463]
alpha/beta optimization time: 0.837744951248169
This batch time : update_bounds func: 0.9698	 prepare: 0.0475	 bound: 0.8381	 transfer: 0.0508	 finalize: 0.0322
Accumulated time: update_bounds func: 21.1330	 prepare: 0.9436	 bound: 18.0877	 transfer: 0.0508	 finalize: 0.9447
batch bounding time:  0.9704179763793945
Current worst splitting domains [lb, ub] (depth):
[-0.27843,   inf] (53), [-0.27771,   inf] (53), [-0.27747,   inf] (53), [-0.27744,   inf] (53), [-0.27741,   inf] (53), [-0.27704,   inf] (53), [-0.27701,   inf] (53), [-0.27672,   inf] (53), [-0.27650,   inf] (53), [-0.27644,   inf] (53), [-0.27636,   inf] (53), [-0.27632,   inf] (53), [-0.27608,   inf] (53), [-0.27606,   inf] (53), [-0.27602,   inf] (53), [-0.27599,   inf] (53), [-0.27595,   inf] (53), [-0.27581,   inf] (53), [-0.27569,   inf] (53), [-0.27560,   inf] (53), 
length of domains: 4991
Total time: 1.2254	 pickout: 0.0559	 decision: 0.1473	 get_bound: 0.9712	 add_domain: 0.0510
Current lb:-0.27843403816223145
10530 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 29.749248266220093

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2659] [1, 2659] [1, 2659] [1, 2659] [1, 2659] [1, 2659] [1, 2659] [1, 2659] [1, 2659] [1, 2659] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 137.02084350585938 with beta sum per layer: [0.0, 87.29978942871094, 2.934196710586548]
alpha/beta optimization time: 0.8315696716308594
This batch time : update_bounds func: 0.9621	 prepare: 0.0480	 bound: 0.8319	 transfer: 0.0491	 finalize: 0.0316
Accumulated time: update_bounds func: 22.0950	 prepare: 0.9916	 bound: 18.9197	 transfer: 0.0491	 finalize: 0.9763
batch bounding time:  0.9626302719116211
Current worst splitting domains [lb, ub] (depth):
[-0.27597,   inf] (55), [-0.27525,   inf] (55), [-0.27501,   inf] (55), [-0.27500,   inf] (55), [-0.27496,   inf] (55), [-0.27456,   inf] (55), [-0.27456,   inf] (55), [-0.27429,   inf] (55), [-0.27407,   inf] (55), [-0.27402,   inf] (55), [-0.27391,   inf] (55), [-0.27386,   inf] (55), [-0.27365,   inf] (55), [-0.27364,   inf] (55), [-0.27351,   inf] (55), [-0.27351,   inf] (55), [-0.27349,   inf] (55), [-0.27332,   inf] (55), [-0.27323,   inf] (55), [-0.27315,   inf] (55), 
length of domains: 5247
Total time: 1.2202	 pickout: 0.0576	 decision: 0.1477	 get_bound: 0.9634	 add_domain: 0.0515
Current lb:-0.2759682834148407
11042 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 30.97431206703186

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2643] [1, 2643] [1, 2643] [1, 2643] [1, 2643] [1, 2643] [1, 2643] [1, 2643] [1, 2643] [1, 2643] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 136.3999481201172 with beta sum per layer: [0.0, 91.18902587890625, 2.7828264236450195]
alpha/beta optimization time: 0.8318672180175781
This batch time : update_bounds func: 0.9625	 prepare: 0.0473	 bound: 0.8322	 transfer: 0.0489	 finalize: 0.0327
Accumulated time: update_bounds func: 23.0575	 prepare: 1.0389	 bound: 19.7519	 transfer: 0.0489	 finalize: 1.0090
batch bounding time:  0.9630789756774902
Current worst splitting domains [lb, ub] (depth):
[-0.27321,   inf] (57), [-0.27245,   inf] (57), [-0.27225,   inf] (57), [-0.27224,   inf] (57), [-0.27222,   inf] (57), [-0.27209,   inf] (43), [-0.27208,   inf] (45), [-0.27208,   inf] (53), [-0.27208,   inf] (47), [-0.27208,   inf] (47), [-0.27208,   inf] (49), [-0.27207,   inf] (55), [-0.27207,   inf] (41), [-0.27207,   inf] (51), [-0.27207,   inf] (49), [-0.27207,   inf] (49), [-0.27206,   inf] (55), [-0.27206,   inf] (51), [-0.27206,   inf] (41), [-0.27206,   inf] (45), 
length of domains: 5503
Total time: 1.3333	 pickout: 0.0561	 decision: 0.2607	 get_bound: 0.9639	 add_domain: 0.0526
Current lb:-0.2732062041759491
11554 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 32.313477993011475

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1803] [2, 235] [1, 1803] [1, 1803] [2, 235] [1, 7126] [1, 2651] [1, 2659] [1, 1795] [1, 518] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 133.44444274902344 with beta sum per layer: [0.0, 82.72245788574219, 5.072053909301758]
alpha/beta optimization time: 0.8282647132873535
This batch time : update_bounds func: 0.9676	 prepare: 0.0486	 bound: 0.8286	 transfer: 0.0549	 finalize: 0.0343
Accumulated time: update_bounds func: 24.0251	 prepare: 1.0875	 bound: 20.5805	 transfer: 0.0549	 finalize: 1.0432
batch bounding time:  0.968207836151123
Current worst splitting domains [lb, ub] (depth):
[-0.27141,   inf] (51), [-0.27141,   inf] (51), [-0.27141,   inf] (47), [-0.27141,   inf] (55), [-0.27140,   inf] (49), [-0.27140,   inf] (51), [-0.27140,   inf] (47), [-0.27140,   inf] (55), [-0.27139,   inf] (51), [-0.27139,   inf] (47), [-0.27139,   inf] (49), [-0.27139,   inf] (43), [-0.27139,   inf] (53), [-0.27138,   inf] (53), [-0.27138,   inf] (49), [-0.27138,   inf] (53), [-0.27138,   inf] (43), [-0.27138,   inf] (49), [-0.27138,   inf] (51), [-0.27137,   inf] (45), 
length of domains: 5754
Total time: 1.2234	 pickout: 0.0579	 decision: 0.1462	 get_bound: 0.9690	 add_domain: 0.0502
Current lb:-0.27141180634498596
12066 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 33.54231381416321

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2467] [1, 722] [1, 1803] [1, 2643] [1, 518] [1, 722] [1, 518] [1, 2643] [1, 722] [1, 1795] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 132.0230255126953 with beta sum per layer: [0.0, 91.7209701538086, 5.121358871459961]
alpha/beta optimization time: 0.8592469692230225
This batch time : update_bounds func: 1.0048	 prepare: 0.0486	 bound: 0.8596	 transfer: 0.0571	 finalize: 0.0380
Accumulated time: update_bounds func: 25.0299	 prepare: 1.1360	 bound: 21.4401	 transfer: 0.0571	 finalize: 1.0813
batch bounding time:  1.005448579788208
Current worst splitting domains [lb, ub] (depth):
[-0.27072,   inf] (55), [-0.27072,   inf] (57), [-0.27072,   inf] (45), [-0.27071,   inf] (53), [-0.27071,   inf] (45), [-0.27071,   inf] (47), [-0.27071,   inf] (47), [-0.27070,   inf] (49), [-0.27070,   inf] (53), [-0.27070,   inf] (49), [-0.27069,   inf] (47), [-0.27069,   inf] (49), [-0.27069,   inf] (45), [-0.27069,   inf] (51), [-0.27069,   inf] (47), [-0.27069,   inf] (43), [-0.27069,   inf] (43), [-0.27069,   inf] (53), [-0.27068,   inf] (49), [-0.27068,   inf] (51), 
length of domains: 6003
Total time: 1.2711	 pickout: 0.0603	 decision: 0.1494	 get_bound: 1.0064	 add_domain: 0.0550
Current lb:-0.27071696519851685
12578 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 34.81919884681702

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2643] [1, 1803] [1, 2467] [1, 722] [1, 1802] [1, 1795] [1, 6874] [1, 8115] [1, 2659] [1, 2467] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 131.25314331054688 with beta sum per layer: [0.0, 88.44251251220703, 6.557265281677246]
alpha/beta optimization time: 0.8604292869567871
This batch time : update_bounds func: 1.0283	 prepare: 0.0565	 bound: 0.8608	 transfer: 0.0563	 finalize: 0.0528
Accumulated time: update_bounds func: 26.0582	 prepare: 1.1926	 bound: 22.3009	 transfer: 0.0563	 finalize: 1.1341
batch bounding time:  1.0294666290283203
Current worst splitting domains [lb, ub] (depth):
[-0.27012,   inf] (51), [-0.27012,   inf] (49), [-0.27011,   inf] (55), [-0.27011,   inf] (51), [-0.27011,   inf] (53), [-0.27010,   inf] (49), [-0.27010,   inf] (51), [-0.27010,   inf] (47), [-0.27010,   inf] (43), [-0.27010,   inf] (45), [-0.27009,   inf] (53), [-0.27008,   inf] (49), [-0.27008,   inf] (49), [-0.27008,   inf] (47), [-0.27008,   inf] (53), [-0.27008,   inf] (41), [-0.27008,   inf] (49), [-0.27008,   inf] (53), [-0.27008,   inf] (51), [-0.27007,   inf] (51), 
length of domains: 6251
Total time: 1.4539	 pickout: 0.0612	 decision: 0.2996	 get_bound: 1.0311	 add_domain: 0.0622
Current lb:-0.27011656761169434
13090 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 36.27869486808777

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 235] [1, 518] [1, 722] [1, 722] [1, 2659] [1, 2467] [1, 2659] [1, 3786] [1, 1795] [1, 2651] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 129.85194396972656 with beta sum per layer: [0.0, 96.87872314453125, 7.075324535369873]
alpha/beta optimization time: 0.8316998481750488
This batch time : update_bounds func: 0.9795	 prepare: 0.0584	 bound: 0.8321	 transfer: 0.0534	 finalize: 0.0339
Accumulated time: update_bounds func: 27.0377	 prepare: 1.2510	 bound: 23.1331	 transfer: 0.0534	 finalize: 1.1680
batch bounding time:  0.9800612926483154
Current worst splitting domains [lb, ub] (depth):
[-0.26951,   inf] (47), [-0.26951,   inf] (53), [-0.26950,   inf] (51), [-0.26950,   inf] (53), [-0.26950,   inf] (51), [-0.26950,   inf] (41), [-0.26949,   inf] (49), [-0.26949,   inf] (51), [-0.26949,   inf] (49), [-0.26949,   inf] (47), [-0.26949,   inf] (41), [-0.26949,   inf] (45), [-0.26948,   inf] (47), [-0.26948,   inf] (51), [-0.26948,   inf] (47), [-0.26948,   inf] (59), [-0.26948,   inf] (51), [-0.26948,   inf] (49), [-0.26948,   inf] (49), [-0.26947,   inf] (53), 
length of domains: 6497
Total time: 1.2595	 pickout: 0.0675	 decision: 0.1597	 get_bound: 0.9809	 add_domain: 0.0514
Current lb:-0.26951128244400024
13602 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 37.54365420341492

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2651] [1, 2659] [1, 2467] [1, 2659] [1, 2467] [1, 7126] [1, 6874] [1, 722] [1, 722] [1, 2467] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 128.57296752929688 with beta sum per layer: [0.0, 96.57469940185547, 7.368832588195801]
alpha/beta optimization time: 0.8311820030212402
This batch time : update_bounds func: 0.9688	 prepare: 0.0486	 bound: 0.8315	 transfer: 0.0536	 finalize: 0.0335
Accumulated time: update_bounds func: 28.0065	 prepare: 1.2996	 bound: 23.9646	 transfer: 0.0536	 finalize: 1.2015
batch bounding time:  0.9694149494171143
Current worst splitting domains [lb, ub] (depth):
[-0.26903,   inf] (45), [-0.26903,   inf] (49), [-0.26903,   inf] (55), [-0.26903,   inf] (47), [-0.26903,   inf] (53), [-0.26902,   inf] (47), [-0.26902,   inf] (51), [-0.26902,   inf] (51), [-0.26901,   inf] (49), [-0.26901,   inf] (51), [-0.26901,   inf] (57), [-0.26901,   inf] (45), [-0.26900,   inf] (45), [-0.26900,   inf] (51), [-0.26900,   inf] (55), [-0.26900,   inf] (51), [-0.26900,   inf] (51), [-0.26900,   inf] (53), [-0.26900,   inf] (43), [-0.26899,   inf] (51), 
length of domains: 6741
Total time: 1.2316	 pickout: 0.0602	 decision: 0.1491	 get_bound: 0.9702	 add_domain: 0.0521
Current lb:-0.26903387904167175
14114 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 38.780648708343506

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2368] [1, 2659] [1, 2643] [1, 2467] [1, 2643] [1, 2466] [1, 2467] [1, 2467] [1, 8115] [1, 2659] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 128.3047637939453 with beta sum per layer: [0.0, 100.30906677246094, 7.543100357055664]
alpha/beta optimization time: 0.8346800804138184
This batch time : update_bounds func: 0.9761	 prepare: 0.0487	 bound: 0.8350	 transfer: 0.0579	 finalize: 0.0332
Accumulated time: update_bounds func: 28.9826	 prepare: 1.3483	 bound: 24.7996	 transfer: 0.0579	 finalize: 1.2347
batch bounding time:  0.9767544269561768
Current worst splitting domains [lb, ub] (depth):
[-0.26858,   inf] (53), [-0.26858,   inf] (53), [-0.26858,   inf] (53), [-0.26858,   inf] (43), [-0.26858,   inf] (51), [-0.26857,   inf] (43), [-0.26857,   inf] (57), [-0.26857,   inf] (55), [-0.26857,   inf] (55), [-0.26856,   inf] (49), [-0.26856,   inf] (45), [-0.26855,   inf] (49), [-0.26855,   inf] (43), [-0.26855,   inf] (51), [-0.26855,   inf] (49), [-0.26855,   inf] (49), [-0.26855,   inf] (45), [-0.26854,   inf] (51), [-0.26854,   inf] (47), [-0.26854,   inf] (53), 
length of domains: 6985
Total time: 1.3810	 pickout: 0.0578	 decision: 0.2939	 get_bound: 0.9775	 add_domain: 0.0518
Current lb:-0.2685832381248474
14626 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 40.16743779182434

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2659] [1, 7126] [1, 7126] [1, 2651] [1, 6874] [1, 785] [2, 235] [2, 235] [1, 722] [1, 6874] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 129.34988403320312 with beta sum per layer: [0.0, 107.90350341796875, 7.084169387817383]
alpha/beta optimization time: 0.8297650814056396
This batch time : update_bounds func: 0.9486	 prepare: 0.0488	 bound: 0.8301	 transfer: 0.0343	 finalize: 0.0338
Accumulated time: update_bounds func: 29.9312	 prepare: 1.3971	 bound: 25.6297	 transfer: 0.0343	 finalize: 1.2685
batch bounding time:  0.9491667747497559
Current worst splitting domains [lb, ub] (depth):
[-0.26811,   inf] (45), [-0.26811,   inf] (53), [-0.26811,   inf] (51), [-0.26811,   inf] (55), [-0.26810,   inf] (51), [-0.26810,   inf] (51), [-0.26810,   inf] (43), [-0.26810,   inf] (47), [-0.26810,   inf] (53), [-0.26810,   inf] (53), [-0.26810,   inf] (49), [-0.26810,   inf] (53), [-0.26810,   inf] (53), [-0.26809,   inf] (49), [-0.26809,   inf] (55), [-0.26809,   inf] (57), [-0.26809,   inf] (45), [-0.26809,   inf] (49), [-0.26809,   inf] (51), [-0.26809,   inf] (47), 
length of domains: 7231
Total time: 1.2067	 pickout: 0.0579	 decision: 0.1478	 get_bound: 0.9500	 add_domain: 0.0510
Current lb:-0.26811113953590393
15138 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 41.37938070297241

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2368] [1, 722] [1, 722] [2, 235] [1, 2467] [1, 722] [1, 3786] [1, 2466] [1, 722] [1, 2643] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 125.84107971191406 with beta sum per layer: [0.0, 102.21337890625, 8.830517768859863]
alpha/beta optimization time: 0.8303489685058594
This batch time : update_bounds func: 0.9730	 prepare: 0.0492	 bound: 0.8307	 transfer: 0.0582	 finalize: 0.0335
Accumulated time: update_bounds func: 30.9042	 prepare: 1.4462	 bound: 26.4604	 transfer: 0.0582	 finalize: 1.3020
batch bounding time:  0.9736297130584717
Current worst splitting domains [lb, ub] (depth):
[-0.26775,   inf] (51), [-0.26775,   inf] (47), [-0.26775,   inf] (41), [-0.26775,   inf] (59), [-0.26775,   inf] (43), [-0.26774,   inf] (49), [-0.26774,   inf] (49), [-0.26774,   inf] (51), [-0.26774,   inf] (47), [-0.26774,   inf] (49), [-0.26773,   inf] (59), [-0.26773,   inf] (45), [-0.26773,   inf] (53), [-0.26773,   inf] (51), [-0.26773,   inf] (57), [-0.26772,   inf] (53), [-0.26772,   inf] (47), [-0.26772,   inf] (55), [-0.26772,   inf] (59), [-0.26772,   inf] (47), 
length of domains: 7471
Total time: 1.2325	 pickout: 0.0567	 decision: 0.1493	 get_bound: 0.9745	 add_domain: 0.0520
Current lb:-0.26775264739990234
15650 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 42.617430210113525

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6874] [1, 2651] [1, 2467] [1, 722] [1, 3786] [1, 6874] [1, 722] [1, 2467] [1, 2368] [1, 722] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 128.4656982421875 with beta sum per layer: [0.0, 108.6903076171875, 6.937436103820801]
alpha/beta optimization time: 0.8299844264984131
This batch time : update_bounds func: 1.1365	 prepare: 0.0488	 bound: 0.8304	 transfer: 0.0561	 finalize: 0.1996
Accumulated time: update_bounds func: 32.0407	 prepare: 1.4951	 bound: 27.2908	 transfer: 0.0561	 finalize: 1.5017
batch bounding time:  1.1372003555297852
Current worst splitting domains [lb, ub] (depth):
[-0.26735,   inf] (49), [-0.26735,   inf] (53), [-0.26735,   inf] (47), [-0.26735,   inf] (57), [-0.26735,   inf] (53), [-0.26735,   inf] (53), [-0.26734,   inf] (55), [-0.26734,   inf] (49), [-0.26734,   inf] (51), [-0.26734,   inf] (55), [-0.26734,   inf] (51), [-0.26734,   inf] (45), [-0.26734,   inf] (43), [-0.26734,   inf] (61), [-0.26733,   inf] (51), [-0.26733,   inf] (53), [-0.26733,   inf] (53), [-0.26733,   inf] (53), [-0.26733,   inf] (43), [-0.26732,   inf] (53), 
length of domains: 7716
Total time: 1.3974	 pickout: 0.0594	 decision: 0.1485	 get_bound: 1.1381	 add_domain: 0.0515
Current lb:-0.2673516273498535
16162 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 44.02044439315796

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 722] [1, 7126] [1, 2368] [1, 722] [1, 2659] [1, 2659] [1, 2643] [1, 2467] [1, 722] [2, 235] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 127.16184997558594 with beta sum per layer: [0.0, 107.6371841430664, 7.223284721374512]
alpha/beta optimization time: 0.8395721912384033
This batch time : update_bounds func: 0.9892	 prepare: 0.0539	 bound: 0.8399	 transfer: 0.0570	 finalize: 0.0369
Accumulated time: update_bounds func: 33.0299	 prepare: 1.5490	 bound: 28.1307	 transfer: 0.0570	 finalize: 1.5385
batch bounding time:  0.9899246692657471
Current worst splitting domains [lb, ub] (depth):
[-0.26695,   inf] (51), [-0.26695,   inf] (51), [-0.26695,   inf] (51), [-0.26695,   inf] (53), [-0.26695,   inf] (55), [-0.26695,   inf] (55), [-0.26695,   inf] (47), [-0.26695,   inf] (45), [-0.26695,   inf] (49), [-0.26695,   inf] (51), [-0.26695,   inf] (49), [-0.26695,   inf] (47), [-0.26694,   inf] (51), [-0.26694,   inf] (49), [-0.26694,   inf] (49), [-0.26694,   inf] (43), [-0.26694,   inf] (57), [-0.26694,   inf] (49), [-0.26694,   inf] (57), [-0.26693,   inf] (53), 
length of domains: 7959
Total time: 1.2608	 pickout: 0.0594	 decision: 0.1554	 get_bound: 0.9908	 add_domain: 0.0551
Current lb:-0.26695311069488525
16674 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 45.28748917579651

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 722] [1, 722] [1, 2467] [1, 2659] [1, 2643] [2, 235] [1, 2772] [1, 2467] [1, 2466] [1, 722] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 127.01667022705078 with beta sum per layer: [0.0, 115.45587921142578, 7.584537029266357]
alpha/beta optimization time: 0.8382081985473633
This batch time : update_bounds func: 0.9789	 prepare: 0.0496	 bound: 0.8386	 transfer: 0.0559	 finalize: 0.0331
Accumulated time: update_bounds func: 34.0087	 prepare: 1.5986	 bound: 28.9693	 transfer: 0.0559	 finalize: 1.5717
batch bounding time:  0.9794762134552002
Current worst splitting domains [lb, ub] (depth):
[-0.26659,   inf] (51), [-0.26658,   inf] (47), [-0.26658,   inf] (51), [-0.26658,   inf] (45), [-0.26658,   inf] (45), [-0.26658,   inf] (47), [-0.26658,   inf] (57), [-0.26658,   inf] (51), [-0.26658,   inf] (55), [-0.26658,   inf] (51), [-0.26658,   inf] (49), [-0.26658,   inf] (45), [-0.26657,   inf] (53), [-0.26657,   inf] (59), [-0.26657,   inf] (49), [-0.26657,   inf] (51), [-0.26657,   inf] (51), [-0.26657,   inf] (45), [-0.26656,   inf] (49), [-0.26656,   inf] (45), 
length of domains: 8202
Total time: 1.2473	 pickout: 0.0622	 decision: 0.1507	 get_bound: 0.9803	 add_domain: 0.0540
Current lb:-0.2665861248970032
17186 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 46.540985345840454

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 722] [1, 2651] [1, 722] [1, 7126] [1, 2368] [1, 3786] [2, 235] [1, 2467] [1, 2643] [1, 2651] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 127.17549133300781 with beta sum per layer: [0.0, 119.29985046386719, 7.5112690925598145]
alpha/beta optimization time: 0.8313398361206055
This batch time : update_bounds func: 0.9703	 prepare: 0.0494	 bound: 0.8317	 transfer: 0.0536	 finalize: 0.0341/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:462: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(preprocess_cifar(eps_temp, perturbation=True)).reshape(1,-1,1,1)

Accumulated time: update_bounds func: 34.9790	 prepare: 1.6480	 bound: 29.8010	 transfer: 0.0536	 finalize: 1.6058
batch bounding time:  0.9710018634796143
Current worst splitting domains [lb, ub] (depth):
[-0.26624,   inf] (49), [-0.26623,   inf] (51), [-0.26623,   inf] (55), [-0.26623,   inf] (53), [-0.26623,   inf] (55), [-0.26623,   inf] (57), [-0.26623,   inf] (51), [-0.26623,   inf] (53), [-0.26623,   inf] (49), [-0.26622,   inf] (53), [-0.26622,   inf] (57), [-0.26622,   inf] (49), [-0.26622,   inf] (51), [-0.26622,   inf] (53), [-0.26622,   inf] (53), [-0.26622,   inf] (51), [-0.26621,   inf] (47), [-0.26621,   inf] (45), [-0.26621,   inf] (49), [-0.26621,   inf] (59), 
length of domains: 8446
Total time: 1.2347	 pickout: 0.0615	 decision: 0.1495	 get_bound: 0.9718	 add_domain: 0.0518
Current lb:-0.2662350833415985
17698 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 47.781479597091675

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2467] [1, 722] [1, 2659] [1, 2643] [2, 235] [1, 2643] [1, 722] [1, 2659] [1, 722] [1, 2659] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 126.44508361816406 with beta sum per layer: [0.0, 118.30474853515625, 8.119874954223633]
alpha/beta optimization time: 0.8380262851715088
This batch time : update_bounds func: 0.9775	 prepare: 0.0491	 bound: 0.8384	 transfer: 0.0548	 finalize: 0.0337
Accumulated time: update_bounds func: 35.9565	 prepare: 1.6971	 bound: 30.6393	 transfer: 0.0548	 finalize: 1.6395
batch bounding time:  0.9781827926635742
Current worst splitting domains [lb, ub] (depth):
[-0.26589,   inf] (53), [-0.26589,   inf] (53), [-0.26589,   inf] (53), [-0.26589,   inf] (53), [-0.26589,   inf] (47), [-0.26588,   inf] (45), [-0.26588,   inf] (61), [-0.26588,   inf] (49), [-0.26588,   inf] (47), [-0.26588,   inf] (49), [-0.26588,   inf] (55), [-0.26588,   inf] (47), [-0.26588,   inf] (51), [-0.26588,   inf] (53), [-0.26588,   inf] (51), [-0.26588,   inf] (59), [-0.26588,   inf] (51), [-0.26588,   inf] (47), [-0.26587,   inf] (49), [-0.26587,   inf] (45), 
length of domains: 8689
Total time: 1.4441	 pickout: 0.0593	 decision: 0.3506	 get_bound: 0.9790	 add_domain: 0.0552
Current lb:-0.2658911943435669
18210 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 49.23165202140808

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2659] [1, 722] [1, 2659] [1, 7126] [1, 3786] [1, 7126] [1, 2395] [1, 3786] [1, 2772] [1, 6874] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 126.9991455078125 with beta sum per layer: [0.0, 119.44943237304688, 7.835628986358643]
alpha/beta optimization time: 0.8298931121826172
This batch time : update_bounds func: 0.9699	 prepare: 0.0490	 bound: 0.8302	 transfer: 0.0547	 finalize: 0.0341
Accumulated time: update_bounds func: 36.9264	 prepare: 1.7461	 bound: 31.4696	 transfer: 0.0547	 finalize: 1.6736
batch bounding time:  0.9705202579498291
Current worst splitting domains [lb, ub] (depth):
[-0.26559,   inf] (49), [-0.26559,   inf] (61), [-0.26559,   inf] (47), [-0.26559,   inf] (43), [-0.26559,   inf] (45), [-0.26559,   inf] (55), [-0.26559,   inf] (45), [-0.26559,   inf] (45), [-0.26559,   inf] (43), [-0.26558,   inf] (49), [-0.26558,   inf] (51), [-0.26558,   inf] (47), [-0.26558,   inf] (53), [-0.26558,   inf] (47), [-0.26558,   inf] (47), [-0.26557,   inf] (53), [-0.26557,   inf] (49), [-0.26557,   inf] (47), [-0.26556,   inf] (47), [-0.26556,   inf] (59), 
length of domains: 8933
Total time: 1.2362	 pickout: 0.0611	 decision: 0.1500	 get_bound: 0.9714	 add_domain: 0.0537
Current lb:-0.2655946910381317
18722 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Time out!!!!!!!!
Image 167 label 2 verification end, final lower bound -0.2655946910381317, upper bound inf, time: 50.70542764663696
167 -0.2655946910381317
Result: image 167 verification failure (with branch and bound).
Wall time: 60.65968465805054

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 0): []
verification failure idx (total 1): [167]
final verified acc: 0.0%[1]
verifier is called on 1 examples.
total verified: 0
mean time [cnt:1] (excluding attack success): 60.59862518310547
