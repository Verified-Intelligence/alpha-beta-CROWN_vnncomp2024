Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_cnn_b_adv4.model
  name: cnn_4layer_b4
data:
  start: 54
  end: 55
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR_SDP
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.00784313725
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 256
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 60
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:14:23 2022 on diablo.cs.ucla.edu
Sequential(
  (0): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)
  (1): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2))
  (2): ReLU()
  (3): Conv2d(32, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (4): ReLU()
  (5): Flatten()
  (6): Linear(in_features=8192, out_features=250, bias=True)
  (7): ReLU()
  (8): Linear(in_features=250, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([200, 3, 32, 32]) torch.Size([200]) torch.Size([200])
X range: tensor(2.1256) tensor(-1.9889) tensor(-0.0131)
############################
epsilon after preprocessing: tensor([[[[0.0317]],

         [[0.0322]],

         [[0.0300]]]]), data_max = tensor([[[[2.0587]],

         [[2.1256]],

         [[2.1154]]]]), data_min = tensor([[[[-1.9889]],

         [[-1.9807]],

         [[-1.7076]]]])
Task length: 1
saving results to Verified_ret_[cnn_4layer_b4]_start=54_end=55_iter=20_b=256_timeout=60_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 54 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 8, correct label 8, image norm 2592.00244140625, logits tensor([-41.8377, -41.9733, -40.8050, -40.9257, -41.3554, -41.1641, -41.6287,
        -39.6171, -38.4065, -41.4018], device='cuda:0',
       grad_fn=<SelectBackward>)
##### PGD attack: True label: 8, Tested against: ['all'] ######
pgd prediction: tensor([-41.3030, -41.5132, -39.9748, -40.0518, -40.4661, -40.2703, -40.7894,
        -38.5711, -38.1086, -40.8928], device='cuda:0',
       grad_fn=<SqueezeBackward1>)
attack margin tensor([3.1943, 3.4045, 1.8661, 1.9431, 2.3575, 2.1616, 2.6807, 0.4624,    inf,
        2.7842], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[-41.8377, -41.9733, -40.8050, -40.9257, -41.3554, -41.1641, -41.6287,
         -39.6171, -38.4065, -41.4018]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 2.3601,  2.0813,  0.7255,  1.0174,  1.1267,  1.2118,  1.6011, -0.3854,
          1.8968]], device='cuda:0') None
best_l after optimization: -12.693795204162598 with beta sum per layer: []
alpha/beta optimization time: 8.315950393676758
initial alpha-CROWN bounds: tensor([[ 2.4209,  2.2783,  0.8371,  1.1136,  1.2310,  1.3112,  1.7032, -0.2841,
          2.0827]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.2841, device='cuda:0', grad_fn=<MinBackward1>)
Sorted order for labels to verify: [7, 2, 3, 5, 4, 6, 9, 0, 1, 8]
##### [0:54] Tested against 7 ######
Model prediction is: tensor([[-41.8377, -41.9733, -40.8050, -40.9257, -41.3554, -41.1641, -41.6287,
         -39.6171, -38.4065, -41.4018]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /34 start_node /35
setting alpha for layer /34 start_node /45
not setting layer /34 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /36 start_node /45
not setting layer /36 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /46 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /33 torch.Size([1, 32, 16, 16])
1 /35 torch.Size([1, 128, 8, 8])
2 /45 torch.Size([1, 250])
best_l after optimization: 0.28399577736854553 with beta sum per layer: []
alpha/beta optimization time: 2.083357334136963
alpha-CROWN with fixed intermediate bounds: tensor([[-0.2840]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.2839958071708679
layer 0 size torch.Size([8192]) unstable 1450
layer 1 size torch.Size([8192]) unstable 549
layer 2 size torch.Size([250]) unstable 19
-----------------
# of unstable neurons: 2018
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 10] 
split level 1: [2, 186] 
split level 2: [2, 115] 
split level 3: [2, 95] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -1.2510581016540527 with beta sum per layer: [0.0, 0.0, 1.5219775438308716]
alpha/beta optimization time: 0.29403138160705566
This batch time : update_bounds func: 0.3032	 prepare: 0.0059	 bound: 0.2948	 transfer: 0.0011	 finalize: 0.0012
Accumulated time: update_bounds func: 0.3032	 prepare: 0.0059	 bound: 0.2948	 transfer: 0.0011	 finalize: 0.0012
batch bounding time:  0.30332398414611816
Current worst splitting domains [lb, ub] (depth):
[-0.13116,   inf] (5), [-0.12292,   inf] (5), 
length of domains: 2
Total time: 0.3407	 pickout: 0.0010	 decision: 0.0339	 get_bound: 0.3055	 add_domain: 0.0002
Current lb:-0.13116350769996643
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.2905831336975098

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2, 32, 16, 16]) pre split depth:  3
batch:  torch.Size([2, 32, 16, 16]) post split depth:  3
splitting decisions: 
split level 0: [2, 235] [2, 235] 
split level 1: [2, 64] [2, 64] 
split level 2: [2, 103] [2, 103] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -1.162974238395691 with beta sum per layer: [0.0, 0.0, 2.477191686630249]
alpha/beta optimization time: 0.27689051628112793
This batch time : update_bounds func: 0.2824	 prepare: 0.0027	 bound: 0.2772	 transfer: 0.0012	 finalize: 0.0013
Accumulated time: update_bounds func: 0.5856	 prepare: 0.0086	 bound: 0.5720	 transfer: 0.0012	 finalize: 0.0025
batch bounding time:  0.28261828422546387
Current worst splitting domains [lb, ub] (depth):
[-0.07685,   inf] (9), [-0.06848,   inf] (9), [-0.04030,   inf] (9), [-0.03420,   inf] (9), 
length of domains: 4
Total time: 0.3089	 pickout: 0.0011	 decision: 0.0230	 get_bound: 0.2845	 add_domain: 0.0003
Current lb:-0.07685054838657379
32 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.5996999740600586

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 32, 16, 16]) pre split depth:  2
batch:  torch.Size([4, 32, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [1, 804] [1, 804] [1, 804] [1, 804] 
split level 1: [2, 248] [2, 248] [2, 248] [2, 248] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.7885842323303223 with beta sum per layer: [0.0, 0.0, 0.9383745789527893]
alpha/beta optimization time: 0.28617143630981445
This batch time : update_bounds func: 0.2922	 prepare: 0.0028	 bound: 0.2865	 transfer: 0.0015	 finalize: 0.0013
Accumulated time: update_bounds func: 0.8777	 prepare: 0.0114	 bound: 0.8584	 transfer: 0.0015	 finalize: 0.0038
batch bounding time:  0.2923398017883301
Current worst splitting domains [lb, ub] (depth):
[-0.06004,   inf] (12), [-0.05946,   inf] (12), [-0.05204,   inf] (12), [-0.05082,   inf] (12), [-0.02070,   inf] (12), [-0.01906,   inf] (12), [-0.01503,   inf] (12), [-0.01262,   inf] (12), 
length of domains: 8
Total time: 0.3205	 pickout: 0.0016	 decision: 0.0246	 get_bound: 0.2938	 add_domain: 0.0005
Current lb:-0.06003948673605919
48 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.9203970432281494

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([8, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2924] [1, 2924] [1, 809] [1, 809] [1, 809] [1, 809] [1, 2924] [1, 2924] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.3235974907875061 with beta sum per layer: [0.0, 1.4373555183410645, 0.46490997076034546]
alpha/beta optimization time: 0.32044458389282227
This batch time : update_bounds func: 0.3261	 prepare: 0.0029	 bound: 0.3207	 transfer: 0.0012	 finalize: 0.0012
Accumulated time: update_bounds func: 1.2039	 prepare: 0.0143	 bound: 1.1792	 transfer: 0.0012	 finalize: 0.0050
batch bounding time:  0.3262786865234375
Current worst splitting domains [lb, ub] (depth):
[-0.05424,   inf] (14), [-0.05358,   inf] (14), [-0.04628,   inf] (14), [-0.04506,   inf] (14), [-0.04343,   inf] (14), [-0.04221,   inf] (14), [-0.01450,   inf] (14), [-0.01267,   inf] (14), [-0.01121,   inf] (14), [-0.00949,   inf] (14), [-0.00923,   inf] (14), [-0.00671,   inf] (14), 
length of domains: 12
Total time: 0.3548	 pickout: 0.0025	 decision: 0.0252	 get_bound: 0.3263	 add_domain: 0.0007
Current lb:-0.054236091673374176
64 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.275363445281982

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([12, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([12, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 809] [1, 809] [1, 2924] [1, 2924] [1, 2924] [1, 2924] [1, 2924] [1, 2924] [1, 2924] [1, 2924] 
regular batch size: 2*12, diving batch size 1*0
best_l after optimization: 0.2662550210952759 with beta sum per layer: [0.0, 2.572573184967041, 0.705082356929779]
alpha/beta optimization time: 0.29314088821411133
This batch time : update_bounds func: 0.3038	 prepare: 0.0037	 bound: 0.2935	 transfer: 0.0047	 finalize: 0.0019
Accumulated time: update_bounds func: 1.5077	 prepare: 0.0180	 bound: 1.4726	 transfer: 0.0047	 finalize: 0.0069
batch bounding time:  0.30405664443969727
Current worst splitting domains [lb, ub] (depth):
[-0.04787,   inf] (16), [-0.04717,   inf] (16), [-0.04565,   inf] (16), [-0.04493,   inf] (16), [-0.04070,   inf] (16), [-0.03947,   inf] (16), [-0.03787,   inf] (16), [-0.03662,   inf] (16), [-0.00852,   inf] (16), [-0.00673,   inf] (16), [-0.00536,   inf] (16), [-0.00350,   inf] (16), [-0.00339,   inf] (16), [-0.00065,   inf] (16), 
length of domains: 14
Total time: 0.3344	 pickout: 0.0031	 decision: 0.0262	 get_bound: 0.3041	 add_domain: 0.0010
Current lb:-0.04786711931228638
88 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.610117435455322

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([14, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([14, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 89] [2, 89] [2, 89] [2, 89] [2, 89] [2, 89] [2, 89] [2, 89] [2, 89] [2, 89] 
regular batch size: 2*14, diving batch size 1*0
best_l after optimization: -0.0235828198492527 with beta sum per layer: [0.0, 0.043274059891700745, 1.356849193572998]
alpha/beta optimization time: 0.3196227550506592
This batch time : update_bounds func: 0.3308	 prepare: 0.0041	 bound: 0.3200	 transfer: 0.0029	 finalize: 0.0037
Accumulated time: update_bounds func: 1.8385	 prepare: 0.0221	 bound: 1.7927	 transfer: 0.0029	 finalize: 0.0105
batch bounding time:  0.33107805252075195
Current worst splitting domains [lb, ub] (depth):
[-0.04245,   inf] (18), [-0.04169,   inf] (18), [-0.04021,   inf] (18), [-0.03944,   inf] (18), [-0.03523,   inf] (18), [-0.03399,   inf] (18), [-0.03237,   inf] (18), [-0.03112,   inf] (18), [-0.00239,   inf] (18), [-0.00070,   inf] (18), 
length of domains: 10
Total time: 0.3640	 pickout: 0.0040	 decision: 0.0275	 get_bound: 0.3312	 add_domain: 0.0013
Current lb:-0.0424494743347168
116 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.974668979644775

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([10, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([10, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 5355] [1, 2468] [1, 5355] [1, 2468] [1, 397] [1, 2468] [1, 397] [1, 2468] [1, 2468] [1, 2468] 
regular batch size: 2*10, diving batch size 1*0
best_l after optimization: 0.4181755781173706 with beta sum per layer: [0.0, 1.1953349113464355, 0.24199146032333374]
alpha/beta optimization time: 0.306882381439209
This batch time : update_bounds func: 0.3140	 prepare: 0.0034	 bound: 0.3072	 transfer: 0.0018	 finalize: 0.0015
Accumulated time: update_bounds func: 2.1526	 prepare: 0.0255	 bound: 2.0999	 transfer: 0.0018	 finalize: 0.0121
batch bounding time:  0.31418800354003906
Current worst splitting domains [lb, ub] (depth):
[-0.03641,   inf] (20), [-0.03618,   inf] (20), [-0.03588,   inf] (20), [-0.03420,   inf] (20), [-0.03393,   inf] (20), [-0.03354,   inf] (20), [-0.03012,   inf] (20), [-0.02857,   inf] (20), [-0.02725,   inf] (20), [-0.02606,   inf] (20), [-0.02571,   inf] (20), [-0.02319,   inf] (20), [-0.02294,   inf] (20), [-0.02071,   inf] (20), [-0.01825,   inf] (20), [-0.01534,   inf] (20), 
length of domains: 16
Total time: 0.3489	 pickout: 0.0050	 decision: 0.0286	 get_bound: 0.3142	 add_domain: 0.0011
Current lb:-0.036406345665454865
136 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.323850631713867

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([16, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([16, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2468] [1, 5355] [1, 2468] [1, 2468] [1, 5355] [1, 2468] [1, 2468] [1, 397] [1, 2468] [1, 2468] 
regular batch size: 2*16, diving batch size 1*0
best_l after optimization: 0.5718183517456055 with beta sum per layer: [0.0, 6.179930210113525, 0.0]
alpha/beta optimization time: 0.28801465034484863
This batch time : update_bounds func: 0.2974	 prepare: 0.0044	 bound: 0.2883	 transfer: 0.0020	 finalize: 0.0026
Accumulated time: update_bounds func: 2.4499	 prepare: 0.0299	 bound: 2.3882	 transfer: 0.0020	 finalize: 0.0147
batch bounding time:  0.29753708839416504
Current worst splitting domains [lb, ub] (depth):
[-0.03161,   inf] (22), [-0.03108,   inf] (22), [-0.03002,   inf] (22), [-0.02956,   inf] (22), [-0.02941,   inf] (22), [-0.02872,   inf] (22), [-0.02781,   inf] (22), [-0.02720,   inf] (22), [-0.02548,   inf] (22), [-0.02344,   inf] (22), [-0.02263,   inf] (22), [-0.02133,   inf] (22), [-0.02057,   inf] (22), [-0.01935,   inf] (22), [-0.01848,   inf] (22), [-0.01663,   inf] (22), [-0.01648,   inf] (22), [-0.01592,   inf] (22), [-0.01446,   inf] (22), [-0.01360,   inf] (22), 
length of domains: 32
Total time: 0.3314	 pickout: 0.0041	 decision: 0.0273	 get_bound: 0.2976	 add_domain: 0.0023
Current lb:-0.03161457180976868
168 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.655490398406982

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([32, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([32, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 397] [1, 397] [1, 397] [1, 397] [1, 397] [1, 397] [1, 397] [1, 397] [2, 166] [2, 166] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: 0.028530210256576538 with beta sum per layer: [0.0, 14.190692901611328, 0.23732657730579376]
alpha/beta optimization time: 0.2978699207305908
This batch time : update_bounds func: 0.3185	 prepare: 0.0091	 bound: 0.2982	 transfer: 0.0071	 finalize: 0.0040
Accumulated time: update_bounds func: 2.7685	 prepare: 0.0390	 bound: 2.6864	 transfer: 0.0071	 finalize: 0.0187
batch bounding time:  0.31871843338012695
Current worst splitting domains [lb, ub] (depth):
[-0.02665,   inf] (24), [-0.02610,   inf] (24), [-0.02501,   inf] (24), [-0.02457,   inf] (24), [-0.02445,   inf] (24), [-0.02374,   inf] (24), [-0.02280,   inf] (24), [-0.02220,   inf] (24), [-0.02204,   inf] (24), [-0.02149,   inf] (24), [-0.02093,   inf] (24), [-0.02000,   inf] (24), [-0.01985,   inf] (24), [-0.01941,   inf] (24), [-0.01928,   inf] (24), [-0.01920,   inf] (24), [-0.01858,   inf] (24), [-0.01781,   inf] (24), [-0.01763,   inf] (24), [-0.01712,   inf] (24), 
length of domains: 46
Total time: 0.3717	 pickout: 0.0069	 decision: 0.0428	 get_bound: 0.3188	 add_domain: 0.0032
Current lb:-0.026652395725250244
232 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.027871131896973

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([46, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([46, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2459] [1, 2459] [1, 2459] [1, 2459] [1, 2459] [1, 2459] [1, 2459] [1, 2459] [1, 7349] [1, 2459] 
regular batch size: 2*46, diving batch size 1*0
best_l after optimization: 0.5699700713157654 with beta sum per layer: [0.0, 23.931766510009766, 0.0]
alpha/beta optimization time: 0.32059144973754883
This batch time : update_bounds func: 0.3488	 prepare: 0.0101	 bound: 0.3209	 transfer: 0.0116	 finalize: 0.0059
Accumulated time: update_bounds func: 3.1172	 prepare: 0.0491	 bound: 3.0072	 transfer: 0.0116	 finalize: 0.0246
batch bounding time:  0.3489816188812256
Current worst splitting domains [lb, ub] (depth):
[-0.02132,   inf] (26), [-0.02074,   inf] (26), [-0.01971,   inf] (26), [-0.01954,   inf] (26), [-0.01925,   inf] (26), [-0.01912,   inf] (26), [-0.01902,   inf] (26), [-0.01839,   inf] (26), [-0.01768,   inf] (26), [-0.01768,   inf] (26), [-0.01751,   inf] (26), [-0.01733,   inf] (26), [-0.01727,   inf] (26), [-0.01689,   inf] (26), [-0.01668,   inf] (26), [-0.01602,   inf] (26), [-0.01566,   inf] (26), [-0.01547,   inf] (26), [-0.01544,   inf] (26), [-0.01491,   inf] (26), 
length of domains: 59
Total time: 0.4014	 pickout: 0.0099	 decision: 0.0382	 get_bound: 0.3491	 add_domain: 0.0041
Current lb:-0.021321622654795647
324 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.430018663406372

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([59, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([59, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7349] [1, 7349] [1, 7349] [1, 7349] [1, 7349] [1, 7349] [1, 7349] [1, 7349] [1, 7349] [1, 398] 
regular batch size: 2*59, diving batch size 1*0
best_l after optimization: 0.4025229215621948 with beta sum per layer: [0.0, 33.28136444091797, 0.0]
alpha/beta optimization time: 0.3579292297363281
This batch time : update_bounds func: 0.3971	 prepare: 0.0188	 bound: 0.3583	 transfer: 0.0116	 finalize: 0.0081
Accumulated time: update_bounds func: 3.5143	 prepare: 0.0679	 bound: 3.3656	 transfer: 0.0116	 finalize: 0.0327
batch bounding time:  0.39734554290771484
Current worst splitting domains [lb, ub] (depth):
[-0.01698,   inf] (28), [-0.01640,   inf] (28), [-0.01537,   inf] (28), [-0.01515,   inf] (28), [-0.01489,   inf] (28), [-0.01478,   inf] (28), [-0.01464,   inf] (28), [-0.01438,   inf] (28), [-0.01405,   inf] (28), [-0.01325,   inf] (28), [-0.01316,   inf] (28), [-0.01294,   inf] (28), [-0.01283,   inf] (28), [-0.01254,   inf] (28), [-0.01234,   inf] (28), [-0.01229,   inf] (28), [-0.01158,   inf] (28), [-0.01154,   inf] (28), [-0.01104,   inf] (28), [-0.01097,   inf] (28), 
length of domains: 74
Total time: 0.4784	 pickout: 0.0123	 decision: 0.0631	 get_bound: 0.3975	 add_domain: 0.0055
Current lb:-0.01698082685470581
442 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.9094648361206055

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([74, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([74, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 5546] [1, 5546] [1, 5546] [1, 5546] [1, 5546] [1, 5546] [1, 5546] [1, 4395] [1, 5546] [1, 5546] 
regular batch size: 2*74, diving batch size 1*0
best_l after optimization: 0.25306710600852966 with beta sum per layer: [0.0, 36.45258331298828, 0.0]
alpha/beta optimization time: 0.3701777458190918
This batch time : update_bounds func: 0.4107	 prepare: 0.0155	 bound: 0.3705	 transfer: 0.0147	 finalize: 0.0096
Accumulated time: update_bounds func: 3.9250	 prepare: 0.0833	 bound: 3.7361	 transfer: 0.0147	 finalize: 0.0423
batch bounding time:  0.4110145568847656
Current worst splitting domains [lb, ub] (depth):
[-0.01146,   inf] (30), [-0.01136,   inf] (30), [-0.01094,   inf] (30), [-0.01064,   inf] (30), [-0.00985,   inf] (30), [-0.00979,   inf] (30), [-0.00974,   inf] (30), [-0.00960,   inf] (30), [-0.00956,   inf] (30), [-0.00952,   inf] (30), [-0.00942,   inf] (30), [-0.00915,   inf] (30), [-0.00912,   inf] (30), [-0.00891,   inf] (30), [-0.00882,   inf] (30), [-0.00822,   inf] (30), [-0.00820,   inf] (30), [-0.00789,   inf] (30), [-0.00784,   inf] (30), [-0.00763,   inf] (30), 
length of domains: 89
Total time: 0.4986	 pickout: 0.0187	 decision: 0.0616	 get_bound: 0.4113	 add_domain: 0.0071
Current lb:-0.011458694003522396
590 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.409738779067993

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([89, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([89, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 166] [2, 166] [2, 166] [2, 166] [2, 166] [2, 166] [2, 166] [1, 2459] [2, 166] [2, 166] 
regular batch size: 2*89, diving batch size 1*0
best_l after optimization: -1.4456422328948975 with beta sum per layer: [0.0, 27.766098022460938, 0.0]
alpha/beta optimization time: 0.3944518566131592
This batch time : update_bounds func: 0.4360	 prepare: 0.0180	 bound: 0.3948	 transfer: 0.0127	 finalize: 0.0101
Accumulated time: update_bounds func: 4.3610	 prepare: 0.1013	 bound: 4.1308	 transfer: 0.0127	 finalize: 0.0524
batch bounding time:  0.4362790584564209
Current worst splitting domains [lb, ub] (depth):
[-0.00796,   inf] (32), [-0.00786,   inf] (32), [-0.00747,   inf] (32), [-0.00716,   inf] (32), [-0.00635,   inf] (32), [-0.00631,   inf] (32), [-0.00623,   inf] (32), [-0.00603,   inf] (32), [-0.00596,   inf] (32), [-0.00595,   inf] (32), [-0.00565,   inf] (32), [-0.00563,   inf] (32), [-0.00545,   inf] (32), [-0.00531,   inf] (32), [-0.00498,   inf] (32), [-0.00472,   inf] (32), [-0.00470,   inf] (32), [-0.00438,   inf] (32), [-0.00436,   inf] (32), [-0.00408,   inf] (32), 
length of domains: 51
Total time: 0.5263	 pickout: 0.0184	 decision: 0.0669	 get_bound: 0.4365	 add_domain: 0.0044/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:462: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(preprocess_cifar(eps_temp, perturbation=True)).reshape(1,-1,1,1)

Current lb:-0.007964578457176685
768 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.937920570373535

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([51, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([51, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 398] [1, 398] [1, 398] [1, 398] [1, 398] [1, 398] [1, 398] [1, 398] [1, 398] [1, 398] 
regular batch size: 2*51, diving batch size 1*0
best_l after optimization: -0.407835990190506 with beta sum per layer: [0.0, 7.333640098571777, 0.0]
alpha/beta optimization time: 0.336956262588501
This batch time : update_bounds func: 0.3578	 prepare: 0.0109	 bound: 0.3373	 transfer: 0.0034	 finalize: 0.0060
Accumulated time: update_bounds func: 4.7188	 prepare: 0.1122	 bound: 4.4681	 transfer: 0.0034	 finalize: 0.0584
batch bounding time:  0.35799288749694824
Current worst splitting domains [lb, ub] (depth):
[-0.00471,   inf] (34), [-0.00461,   inf] (34), [-0.00423,   inf] (34), [-0.00392,   inf] (34), [-0.00307,   inf] (34), [-0.00306,   inf] (34), [-0.00296,   inf] (34), [-0.00272,   inf] (34), [-0.00270,   inf] (34), [-0.00266,   inf] (34), [-0.00238,   inf] (34), [-0.00233,   inf] (34), [-0.00220,   inf] (34), [-0.00200,   inf] (34), [-0.00190,   inf] (34), [-0.00146,   inf] (34), [-0.00141,   inf] (34), [-0.00112,   inf] (34), [-0.00106,   inf] (34), [-0.00075,   inf] (34), 
length of domains: 25
Total time: 0.4177	 pickout: 0.0111	 decision: 0.0463	 get_bound: 0.3582	 add_domain: 0.0022
Current lb:-0.004711952060461044
870 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.356833219528198

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([25, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([25, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2915] [1, 2915] [1, 2915] [1, 2915] [1, 2915] [1, 2915] [1, 2915] [1, 2915] [1, 2915] [1, 2915] 
regular batch size: 2*25, diving batch size 1*0
best_l after optimization: -0.6243083477020264 with beta sum per layer: [0.0, 1.141141414642334, 0.0]
alpha/beta optimization time: 0.29398012161254883
This batch time : update_bounds func: 0.3059	 prepare: 0.0061	 bound: 0.2943	 transfer: 0.0022	 finalize: 0.0031
Accumulated time: update_bounds func: 5.0247	 prepare: 0.1183	 bound: 4.7624	 transfer: 0.0022	 finalize: 0.0615
batch bounding time:  0.3060567378997803
Current worst splitting domains [lb, ub] (depth):
[-0.00150,   inf] (36), [-0.00137,   inf] (36), [-0.00128,   inf] (36), [-0.00093,   inf] (36), 
length of domains: 4
Total time: 0.3431	 pickout: 0.0059	 decision: 0.0306	 get_bound: 0.3061	 add_domain: 0.0005
Current lb:-0.0015035405522212386
920 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.702079772949219

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 32, 16, 16]) pre split depth:  2
batch:  torch.Size([4, 32, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [1, 4395] [1, 4395] [1, 4395] [1, 4395] 
split level 1: [1, 787] [1, 787] [1, 787] [1, 787] 
regular batch size: 2*8, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -0.16372191905975342 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.010130882263183594
This batch time : update_bounds func: 0.0157	 prepare: 0.0029	 bound: 0.0104	 transfer: 0.0012	 finalize: 0.0011
Accumulated time: update_bounds func: 5.0403	 prepare: 0.1212	 bound: 4.7728	 transfer: 0.0012	 finalize: 0.0626
batch bounding time:  0.01571941375732422
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0427	 pickout: 0.0016	 decision: 0.0237	 get_bound: 0.0174	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 8.744991540908813

Image 54 label 7 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 8.83305811882019
54 1.0000000116860974e-07
##### [0:54] Tested against 2 ######
Initial alpha-CROWN verified for label 2 with bound 0.8370561599731445
Image 54 label 2 verification end, final lower bound 0.8370561599731445, upper bound inf, time: 0.0004181861877441406
54 0.8370561599731445
##### [0:54] Tested against 3 ######
Initial alpha-CROWN verified for label 3 with bound 1.1135586500167847
Image 54 label 3 verification end, final lower bound 1.1135586500167847, upper bound inf, time: 0.00039839744567871094
54 1.1135586500167847
##### [0:54] Tested against 5 ######
Initial alpha-CROWN verified for label 5 with bound 1.3112270832061768
Image 54 label 5 verification end, final lower bound 1.3112270832061768, upper bound inf, time: 0.00040030479431152344
54 1.3112270832061768
##### [0:54] Tested against 4 ######
Initial alpha-CROWN verified for label 4 with bound 1.230953574180603
Image 54 label 4 verification end, final lower bound 1.230953574180603, upper bound inf, time: 0.0003757476806640625
54 1.230953574180603
##### [0:54] Tested against 6 ######
Initial alpha-CROWN verified for label 6 with bound 1.7032051086425781
Image 54 label 6 verification end, final lower bound 1.7032051086425781, upper bound inf, time: 0.0003936290740966797
54 1.7032051086425781
##### [0:54] Tested against 9 ######
Initial alpha-CROWN verified for label 9 with bound 2.082664728164673
Image 54 label 9 verification end, final lower bound 2.082664728164673, upper bound inf, time: 0.0003848075866699219
54 2.082664728164673
##### [0:54] Tested against 0 ######
Initial alpha-CROWN verified for label 0 with bound 2.4209492206573486
Image 54 label 0 verification end, final lower bound 2.4209492206573486, upper bound inf, time: 0.0003819465637207031
54 2.4209492206573486
##### [0:54] Tested against 1 ######
Initial alpha-CROWN verified for label 1 with bound 2.2782697677612305
Image 54 label 1 verification end, final lower bound 2.2782697677612305, upper bound inf, time: 0.00038313865661621094
54 2.2782697677612305
##### [0:54] Tested against 8 ######
groundtruth label, skip!
Result: image 54 verification success (with branch and bound)!
Wall time: 21.28766894340515

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 1): [54]
verification failure idx (total 0): []
final verified acc: 100.0%[1]
verifier is called on 1 examples.
total verified: 1
mean time [cnt:1] (excluding attack success): 18.865623235702515
