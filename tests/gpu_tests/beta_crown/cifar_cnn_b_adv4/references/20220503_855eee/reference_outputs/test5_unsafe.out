Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_cnn_b_adv4.model
  name: cnn_4layer_b4
data:
  start: 67
  end: 68
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR_SDP
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.00784313725
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 256
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 60
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:16:28 2022 on diablo.cs.ucla.edu
Sequential(
  (0): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)
  (1): Conv2d(3, 32, kernel_size=(5, 5), stride=(2, 2))
  (2): ReLU()
  (3): Conv2d(32, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (4): ReLU()
  (5): Flatten()
  (6): Linear(in_features=8192, out_features=250, bias=True)
  (7): ReLU()
  (8): Linear(in_features=250, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([200, 3, 32, 32]) torch.Size([200]) torch.Size([200])
X range: tensor(2.1256) tensor(-1.9889) tensor(-0.0131)
############################
epsilon after preprocessing: tensor([[[[0.0317]],

         [[0.0322]],

         [[0.0300]]]]), data_max = tensor([[[[2.0587]],

         [[2.1256]],

         [[2.1154]]]]), data_min = tensor([[[[-1.9889]],

         [[-1.9807]],

         [[-1.7076]]]])
Task length: 1
saving results to Verified_ret_[cnn_4layer_b4]_start=67_end=68_iter=20_b=256_timeout=60_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 67 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 2, correct label 2, image norm 1075.746826171875, logits tensor([-24.0829, -28.2649, -19.6425, -22.5056, -19.7969, -22.5362, -21.5319,
        -22.8265, -26.2445, -27.6397], device='cuda:0',
       grad_fn=<SelectBackward>)
Model prediction is: tensor([[-24.0829, -28.2649, -19.6425, -22.5056, -19.7969, -22.5362, -21.5319,
         -22.8265, -26.2445, -27.6397]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 3.5402,  7.1439,  2.1355, -0.3645,  2.1468,  0.9747,  2.0482,  5.4889,
          6.5619]], device='cuda:0') None
best_l after optimization: -30.131067276000977 with beta sum per layer: []
alpha/beta optimization time: 8.338789939880371
initial alpha-CROWN bounds: tensor([[ 3.6055,  7.2284,  2.1606, -0.3385,  2.1751,  1.0140,  2.0973,  5.5647,
          6.6240]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.3385, device='cuda:0', grad_fn=<MinBackward1>)
##### [0:67] Tested against 4 ######
Model prediction is: tensor([[-24.0829, -28.2649, -19.6425, -22.5056, -19.7969, -22.5362, -21.5319,
         -22.8265, -26.2445, -27.6397]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /34 start_node /35
setting alpha for layer /34 start_node /45
not setting layer /34 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /36 start_node /45
not setting layer /36 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 128, 8, 8]) != torch.Size([2, 9, 1, 128, 8, 8]))
not setting layer /46 start_node /47 because shape mismatch (torch.Size([2, 1, 1, 250]) != torch.Size([2, 9, 1, 250]))
0 /33 torch.Size([1, 32, 16, 16])
1 /35 torch.Size([1, 128, 8, 8])
2 /45 torch.Size([1, 250])
best_l after optimization: 0.3384242057800293 with beta sum per layer: []
alpha/beta optimization time: 1.9997649192810059
alpha-CROWN with fixed intermediate bounds: tensor([[-0.3384]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.3384242057800293
layer 0 size torch.Size([8192]) unstable 1691
layer 1 size torch.Size([8192]) unstable 544
layer 2 size torch.Size([250]) unstable 37
-----------------
# of unstable neurons: 2272
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 32, 16, 16]) pre split depth:  4
batch:  torch.Size([1, 32, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [2, 225] 
split level 1: [2, 115] 
split level 2: [2, 230] 
split level 3: [2, 208] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.8074434995651245 with beta sum per layer: [0.0, 0.0, 3.5708959102630615]
alpha/beta optimization time: 0.2992897033691406
This batch time : update_bounds func: 0.3056	 prepare: 0.0031	 bound: 0.2998	 transfer: 0.0014	 finalize: 0.0013
Accumulated time: update_bounds func: 0.3056	 prepare: 0.0031	 bound: 0.2998	 transfer: 0.0014	 finalize: 0.0013
batch bounding time:  0.3057861328125
Current worst splitting domains [lb, ub] (depth):
[-0.24105,   inf] (5), [-0.23928,   inf] (5), [-0.18273,   inf] (5), [-0.17612,   inf] (5), [-0.16111,   inf] (5), [-0.15482,   inf] (5), [-0.08599,   inf] (5), [-0.08572,   inf] (5), [-0.06752,   inf] (5), [-0.06087,   inf] (5), [-0.01738,   inf] (5), [-0.01115,   inf] (5), 
length of domains: 12
Total time: 0.3409	 pickout: 0.0013	 decision: 0.0311	 get_bound: 0.3080	 add_domain: 0.0006
Current lb:-0.24105285108089447
16 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.1992545127868652

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([12, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([12, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 31] [2, 31] [2, 31] [2, 31] [2, 31] [2, 84] [2, 31] [2, 31] [2, 31] [2, 84] 
regular batch size: 2*12, diving batch size 1*0
best_l after optimization: 2.6352620124816895 with beta sum per layer: [0.0, 0.0, 2.4641544818878174]
alpha/beta optimization time: 0.28574037551879883
This batch time : update_bounds func: 0.2929	 prepare: 0.0035	 bound: 0.2860	 transfer: 0.0015	 finalize: 0.0017
Accumulated time: update_bounds func: 0.5985	 prepare: 0.0067	 bound: 0.5858	 transfer: 0.0015	 finalize: 0.0030
batch bounding time:  0.2930333614349365
Current worst splitting domains [lb, ub] (depth):
[-0.22989,   inf] (7), [-0.22881,   inf] (7), [-0.22792,   inf] (7), [-0.22334,   inf] (7), [-0.17003,   inf] (7), [-0.16974,   inf] (7), [-0.16451,   inf] (7), [-0.16166,   inf] (7), [-0.14901,   inf] (7), [-0.14774,   inf] (7), [-0.14271,   inf] (7), [-0.14242,   inf] (7), [-0.07141,   inf] (7), [-0.07136,   inf] (7), [-0.07104,   inf] (7), [-0.06921,   inf] (7), [-0.05402,   inf] (7), [-0.05369,   inf] (7), [-0.04790,   inf] (7), [-0.04746,   inf] (7), 
length of domains: 20
Total time: 0.3234	 pickout: 0.0032	 decision: 0.0261	 get_bound: 0.2931	 add_domain: 0.0011
Current lb:-0.2298937439918518
40 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.522886276245117

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([20, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([20, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 84] [2, 84] [2, 84] [2, 84] [2, 84] [2, 84] [2, 84] [2, 84] [2, 84] [2, 84] 
regular batch size: 2*20, diving batch size 1*0
best_l after optimization: 4.737952709197998 with beta sum per layer: [0.0, 0.0, 2.9460315704345703]
alpha/beta optimization time: 0.27673959732055664
This batch time : update_bounds func: 0.2878	 prepare: 0.0046	 bound: 0.2770	 transfer: 0.0035	 finalize: 0.0025
Accumulated time: update_bounds func: 0.8863	 prepare: 0.0113	 bound: 0.8628	 transfer: 0.0035	 finalize: 0.0055
batch bounding time:  0.2879672050476074
Current worst splitting domains [lb, ub] (depth):
[-0.22028,   inf] (9), [-0.21887,   inf] (9), [-0.21811,   inf] (9), [-0.21362,   inf] (9), [-0.21296,   inf] (9), [-0.21295,   inf] (9), [-0.21166,   inf] (9), [-0.20922,   inf] (9), [-0.16046,   inf] (9), [-0.16012,   inf] (9), [-0.15513,   inf] (9), [-0.15233,   inf] (9), [-0.14785,   inf] (9), [-0.14717,   inf] (9), [-0.14375,   inf] (9), [-0.14226,   inf] (9), [-0.13687,   inf] (9), [-0.13678,   inf] (9), [-0.13568,   inf] (9), [-0.13561,   inf] (9), 
length of domains: 40
Total time: 0.3227	 pickout: 0.0046	 decision: 0.0284	 get_bound: 0.2880	 add_domain: 0.0017
Current lb:-0.22028309106826782
80 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.845916748046875

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([40, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([40, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 248] [2, 248] [2, 248] [2, 248] [2, 248] [2, 248] [2, 248] [2, 248] [2, 248] [2, 248] 
regular batch size: 2*40, diving batch size 1*0
best_l after optimization: 8.420799255371094 with beta sum per layer: [0.0, 0.0, 6.512696743011475]
alpha/beta optimization time: 0.33222389221191406
This batch time : update_bounds func: 0.3551	 prepare: 0.0082	 bound: 0.3325	 transfer: 0.0095	 finalize: 0.0047
Accumulated time: update_bounds func: 1.2414	 prepare: 0.0194	 bound: 1.1954	 transfer: 0.0095	 finalize: 0.0102
batch bounding time:  0.3553276062011719
Current worst splitting domains [lb, ub] (depth):
[-0.21124,   inf] (11), [-0.21024,   inf] (11), [-0.20879,   inf] (11), [-0.20459,   inf] (11), [-0.20397,   inf] (11), [-0.20375,   inf] (11), [-0.20368,   inf] (11), [-0.20272,   inf] (11), [-0.20220,   inf] (11), [-0.20058,   inf] (11), [-0.19984,   inf] (11), [-0.19769,   inf] (11), [-0.19739,   inf] (11), [-0.19700,   inf] (11), [-0.19674,   inf] (11), [-0.19385,   inf] (11), [-0.15056,   inf] (11), [-0.15001,   inf] (11), [-0.14742,   inf] (11), [-0.14721,   inf] (11), 
length of domains: 80
Total time: 0.4038	 pickout: 0.0086	 decision: 0.0362	 get_bound: 0.3555	 add_domain: 0.0035
Current lb:-0.21123845875263214
160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.250366926193237

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([80, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([80, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 73] [2, 73] [2, 73] [2, 73] [2, 73] [2, 73] [2, 73] [2, 73] [2, 73] [2, 73] 
regular batch size: 2*80, diving batch size 1*0
best_l after optimization: 6.254293918609619 with beta sum per layer: [0.0, 0.0, 26.461610794067383]
alpha/beta optimization time: 0.3746073246002197
This batch time : update_bounds func: 0.4140	 prepare: 0.0144	 bound: 0.3749	 transfer: 0.0147	 finalize: 0.0097
Accumulated time: update_bounds func: 1.6554	 prepare: 0.0338	 bound: 1.5703	 transfer: 0.0147	 finalize: 0.0199
batch bounding time:  0.4142577648162842
Current worst splitting domains [lb, ub] (depth):
[-0.20613,   inf] (13), [-0.20507,   inf] (13), [-0.20371,   inf] (13), [-0.19942,   inf] (13), [-0.19889,   inf] (13), [-0.19886,   inf] (13), [-0.19856,   inf] (13), [-0.19779,   inf] (13), [-0.19707,   inf] (13), [-0.19565,   inf] (13), [-0.19477,   inf] (13), [-0.19246,   inf] (13), [-0.19238,   inf] (13), [-0.19205,   inf] (13), [-0.19180,   inf] (13), [-0.18894,   inf] (13), [-0.14471,   inf] (13), [-0.14417,   inf] (13), [-0.14178,   inf] (13), [-0.14177,   inf] (13), 
length of domains: 106
Total time: 0.4969	 pickout: 0.0159	 decision: 0.0615	 get_bound: 0.4145	 add_domain: 0.0050
Current lb:-0.20613110065460205
320 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.748379468917847

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([106, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([106, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 188] [2, 188] [2, 188] [2, 188] [2, 188] [2, 188] [2, 188] [2, 188] [2, 188] [2, 188] 
regular batch size: 2*106, diving batch size 1*0
best_l after optimization: 15.212057113647461 with beta sum per layer: [0.0, 0.0, 24.500274658203125]
alpha/beta optimization time: 0.45937228202819824
This batch time : update_bounds func: 0.5077	 prepare: 0.0186	 bound: 0.4597	 transfer: 0.0169	 finalize: 0.0119
Accumulated time: update_bounds func: 2.1631	 prepare: 0.0524	 bound: 2.0300	 transfer: 0.0169	 finalize: 0.0318
batch bounding time:  0.5079779624938965
Current worst splitting domains [lb, ub] (depth):
[-0.20033,   inf] (15), [-0.19926,   inf] (15), [-0.19846,   inf] (15), [-0.19800,   inf] (15), [-0.19750,   inf] (15), [-0.19556,   inf] (15), [-0.19359,   inf] (15), [-0.19311,   inf] (15), [-0.19274,   inf] (15), [-0.19270,   inf] (15), [-0.19191,   inf] (15), [-0.19179,   inf] (15), [-0.19175,   inf] (15), [-0.19135,   inf] (15), [-0.19110,   inf] (15), [-0.19072,   inf] (15), [-0.19053,   inf] (15), [-0.18943,   inf] (15), [-0.18906,   inf] (15), [-0.18905,   inf] (15), 
length of domains: 167
Total time: 0.6107	 pickout: 0.0208	 decision: 0.0730	 get_bound: 0.5083	 add_domain: 0.0086
Current lb:-0.20033326745033264
532 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.360654830932617

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([167, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([167, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 190] [2, 190] [2, 190] [2, 190] [2, 190] [2, 190] [2, 190] [2, 190] [2, 190] [2, 190] 
regular batch size: 2*167, diving batch size 1*0
best_l after optimization: 26.301433563232422 with beta sum per layer: [0.0, 1.4385664463043213, 37.102420806884766]
alpha/beta optimization time: 0.6121528148651123
This batch time : update_bounds func: 0.6924	 prepare: 0.0295	 bound: 0.6125	 transfer: 0.0291	 finalize: 0.0205
Accumulated time: update_bounds func: 2.8555	 prepare: 0.0819	 bound: 2.6424	 transfer: 0.0291	 finalize: 0.0522
batch bounding time:  0.6928822994232178
Current worst splitting domains [lb, ub] (depth):
[-0.19541,   inf] (17), [-0.19461,   inf] (17), [-0.19351,   inf] (17), [-0.19292,   inf] (17), [-0.19281,   inf] (17), [-0.19046,   inf] (17), [-0.18893,   inf] (17), [-0.18826,   inf] (17), [-0.18781,   inf] (17), [-0.18779,   inf] (17), [-0.18711,   inf] (17), [-0.18692,   inf] (17), [-0.18668,   inf] (17), [-0.18636,   inf] (17), [-0.18602,   inf] (17), [-0.18569,   inf] (17), [-0.18545,   inf] (17), [-0.18478,   inf] (17), [-0.18425,   inf] (17), [-0.18420,   inf] (17), 
length of domains: 316
Total time: 0.8478	 pickout: 0.0339	 decision: 0.1032	 get_bound: 0.6934	 add_domain: 0.0174
Current lb:-0.19540724158287048
866 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.21156120300293

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 157] [2, 157] [2, 157] [2, 145] [2, 157] [2, 145] [2, 157] [2, 157] [2, 145] [2, 157] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 27.30536460876465 with beta sum per layer: [0.0, 0.6216342449188232, 79.71048736572266]
alpha/beta optimization time: 0.8265810012817383
This batch time : update_bounds func: 1.0593	 prepare: 0.0451	 bound: 0.8269	 transfer: 0.0396	 finalize: 0.1464
Accumulated time: update_bounds func: 3.9148	 prepare: 0.1270	 bound: 3.4694	 transfer: 0.0396	 finalize: 0.1987
batch bounding time:  1.0599961280822754
Current worst splitting domains [lb, ub] (depth):
[-0.19135,   inf] (19), [-0.19050,   inf] (19), [-0.18946,   inf] (19), [-0.18874,   inf] (19), [-0.18858,   inf] (19), [-0.18639,   inf] (19), [-0.18480,   inf] (19), [-0.18403,   inf] (19), [-0.18375,   inf] (19), [-0.18370,   inf] (19), [-0.18299,   inf] (19), [-0.18276,   inf] (19), [-0.18248,   inf] (19), [-0.18222,   inf] (19), [-0.18178,   inf] (19), [-0.18166,   inf] (19), [-0.18130,   inf] (19), [-0.18055,   inf] (19), [-0.18003,   inf] (19), [-0.18001,   inf] (19), 
length of domains: 457
Total time: 1.2946	 pickout: 0.0537	 decision: 0.1581	 get_bound: 1.0608	 add_domain: 0.0219
Current lb:-0.19134998321533203
1378 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.509991407394409

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 145] [2, 145] [2, 145] [2, 157] [2, 145] [2, 157] [2, 145] [2, 145] [2, 157] [2, 145] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 16.947921752929688 with beta sum per layer: [0.0, 0.0, 100.3696060180664]
alpha/beta optimization time: 0.8149991035461426
This batch time : update_bounds func: 0.9367	 prepare: 0.0433	 bound: 0.8153	 transfer: 0.0476	 finalize: 0.0291
Accumulated time: update_bounds func: 4.8514	 prepare: 0.1703	 bound: 4.2847	 transfer: 0.0476	 finalize: 0.2278
batch bounding time:  0.93723464012146
Current worst splitting domains [lb, ub] (depth):
[-0.18733,   inf] (21), [-0.18659,   inf] (21), [-0.18540,   inf] (21), [-0.18470,   inf] (21), [-0.18467,   inf] (21), [-0.18235,   inf] (21), [-0.18088,   inf] (21), [-0.18007,   inf] (21), [-0.17971,   inf] (21), [-0.17955,   inf] (21), [-0.17894,   inf] (21), [-0.17868,   inf] (21), [-0.17833,   inf] (21), [-0.17826,   inf] (21), [-0.17784,   inf] (21), [-0.17760,   inf] (21), [-0.17715,   inf] (21), [-0.17648,   inf] (21), [-0.17607,   inf] (21), [-0.17596,   inf] (21), 
length of domains: 516
Total time: 1.1578	 pickout: 0.0549	 decision: 0.1459	 get_bound: 0.9380	 add_domain: 0.0191
Current lb:-0.1873263567686081
1890 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.673028469085693

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 180] [2, 180] [2, 180] [2, 180] [2, 180] [2, 180] [2, 180] [2, 180] [2, 180] [2, 180] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 37.54692840576172 with beta sum per layer: [0.0, 0.0, 71.01261901855469]
alpha/beta optimization time: 0.8297715187072754
This batch time : update_bounds func: 0.9592	 prepare: 0.0445	 bound: 0.8301	 transfer: 0.0538	 finalize: 0.0294
Accumulated time: update_bounds func: 5.8106	 prepare: 0.2148	 bound: 5.1148	 transfer: 0.0538	 finalize: 0.2572
batch bounding time:  0.9598531723022461
Current worst splitting domains [lb, ub] (depth):
[-0.18399,   inf] (23), [-0.18319,   inf] (23), [-0.18204,   inf] (23), [-0.18127,   inf] (23), [-0.18126,   inf] (23), [-0.17895,   inf] (23), [-0.17736,   inf] (23), [-0.17666,   inf] (23), [-0.17618,   inf] (23), [-0.17617,   inf] (23), [-0.17541,   inf] (23), [-0.17523,   inf] (23), [-0.17487,   inf] (23), [-0.17470,   inf] (23), [-0.17439,   inf] (23), [-0.17406,   inf] (23), [-0.17376,   inf] (23), [-0.17308,   inf] (23), [-0.17254,   inf] (23), [-0.17249,   inf] (23), 
length of domains: 721
Total time: 1.2003	 pickout: 0.0592	 decision: 0.1509	 get_bound: 0.9606	 add_domain: 0.0295
Current lb:-0.18399153649806976
2402 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.87825345993042

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2796] [1, 2796] [1, 2796] [1, 2796] [1, 2796] [1, 2796] [1, 2796] [1, 2796] [1, 2796] [1, 2796] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 57.966461181640625 with beta sum per layer: [0.0, 20.911882400512695, 39.78430938720703]
alpha/beta optimization time: 0.8314216136932373
This batch time : update_bounds func: 0.9591	 prepare: 0.0447	 bound: 0.8318	 transfer: 0.0514	 finalize: 0.0298
Accumulated time: update_bounds func: 6.7698	 prepare: 0.2595	 bound: 5.9466	 transfer: 0.0514	 finalize: 0.2871
batch bounding time:  0.9597554206848145
Current worst splitting domains [lb, ub] (depth):
[-0.18150,   inf] (25), [-0.18142,   inf] (25), [-0.18064,   inf] (25), [-0.18059,   inf] (25), [-0.17942,   inf] (25), [-0.17941,   inf] (25), [-0.17881,   inf] (25), [-0.17874,   inf] (25), [-0.17860,   inf] (25), [-0.17852,   inf] (25), [-0.17629,   inf] (25), [-0.17628,   inf] (25), [-0.17483,   inf] (25), [-0.17450,   inf] (25), [-0.17415,   inf] (25), [-0.17403,   inf] (25), [-0.17364,   inf] (25), [-0.17352,   inf] (25), [-0.17338,   inf] (25), [-0.17316,   inf] (25), 
length of domains: 977
Total time: 1.2694	 pickout: 0.0577	 decision: 0.2167	 get_bound: 0.9605	 add_domain: 0.0345
Current lb:-0.18150249123573303
2914 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.152119159698486

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1188] [1, 4571] [1, 1188] [1, 1188] [1, 4571] [1, 1188] [1, 4571] [1, 4571] [1, 1188] [1, 1188] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 68.66818237304688 with beta sum per layer: [0.0, 25.885147094726562, 29.025239944458008]
alpha/beta optimization time: 0.8607432842254639
This batch time : update_bounds func: 0.9911	 prepare: 0.0486	 bound: 0.8611	 transfer: 0.0492	 finalize: 0.0310
Accumulated time: update_bounds func: 7.7609	 prepare: 0.3081	 bound: 6.8077	 transfer: 0.0492	 finalize: 0.3181
batch bounding time:  0.9916725158691406
Current worst splitting domains [lb, ub] (depth):
[-0.17950,   inf] (27), [-0.17950,   inf] (27), [-0.17860,   inf] (27), [-0.17837,   inf] (27), [-0.17818,   inf] (27), [-0.17812,   inf] (27), [-0.17794,   inf] (27), [-0.17748,   inf] (27), [-0.17737,   inf] (27), [-0.17731,   inf] (27), [-0.17688,   inf] (27), [-0.17679,   inf] (27), [-0.17653,   inf] (27), [-0.17631,   inf] (27), [-0.17613,   inf] (27), [-0.17605,   inf] (27), [-0.17590,   inf] (27), [-0.17534,   inf] (27), [-0.17494,   inf] (27), [-0.17494,   inf] (27), 
length of domains: 1233
Total time: 1.2405	 pickout: 0.0614	 decision: 0.1519	 get_bound: 0.9924	 add_domain: 0.0348
Current lb:-0.17949843406677246
3426 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.39684271812439

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 4570] [1, 4570] [1, 4570] [1, 4570] [1, 7924] [1, 7924] [1, 4570] [1, 7924] [1, 4570] [1, 7924] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 79.42761993408203 with beta sum per layer: [0.0, 34.714805603027344, 17.839933395385742]
alpha/beta optimization time: 0.8157849311828613
This batch time : update_bounds func: 0.9993	 prepare: 0.0483	 bound: 0.8161	 transfer: 0.0492	 finalize: 0.0845
Accumulated time: update_bounds func: 8.7602	 prepare: 0.3564	 bound: 7.6238	 transfer: 0.0492	 finalize: 0.4026
batch bounding time:  0.999946117401123
Current worst splitting domains [lb, ub] (depth):
[-0.17737,   inf] (29), [-0.17727,   inf] (29), [-0.17699,   inf] (29), [-0.17683,   inf] (29), [-0.17636,   inf] (29), [-0.17616,   inf] (29), [-0.17610,   inf] (29), [-0.17587,   inf] (29), [-0.17583,   inf] (29), [-0.17573,   inf] (29), [-0.17563,   inf] (29), [-0.17537,   inf] (29), [-0.17535,   inf] (29), [-0.17531,   inf] (29), [-0.17528,   inf] (29), [-0.17524,   inf] (29), [-0.17503,   inf] (29), [-0.17489,   inf] (29), [-0.17486,   inf] (29), [-0.17445,   inf] (29), 
length of domains: 1489
Total time: 1.2440	 pickout: 0.0576	 decision: 0.1480	 get_bound: 1.0008	 add_domain: 0.0376
Current lb:-0.17736783623695374
3938 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.645233869552612

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7924] [1, 7924] [1, 4571] [1, 7924] [1, 7924] [1, 7924] [1, 4571] [1, 4570] [1, 4570] [1, 7924] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 83.33653259277344 with beta sum per layer: [0.0, 36.7558479309082, 9.03183364868164]
alpha/beta optimization time: 0.8186912536621094
This batch time : update_bounds func: 0.9480	 prepare: 0.0492	 bound: 0.8190	 transfer: 0.0475	 finalize: 0.0310
Accumulated time: update_bounds func: 9.7082	 prepare: 0.4056	 bound: 8.4429	 transfer: 0.0475	 finalize: 0.4336
batch bounding time:  0.9486396312713623
Current worst splitting domains [lb, ub] (depth):
[-0.17548,   inf] (31), [-0.17527,   inf] (31), [-0.17495,   inf] (31), [-0.17492,   inf] (31), [-0.17434,   inf] (31), [-0.17407,   inf] (31), [-0.17398,   inf] (31), [-0.17362,   inf] (31), [-0.17360,   inf] (31), [-0.17355,   inf] (31), [-0.17350,   inf] (31), [-0.17346,   inf] (31), [-0.17346,   inf] (31), [-0.17339,   inf] (31), [-0.17333,   inf] (31), [-0.17312,   inf] (31), [-0.17311,   inf] (31), [-0.17310,   inf] (31), [-0.17305,   inf] (31), [-0.17301,   inf] (31), 
length of domains: 1745
Total time: 1.1951	 pickout: 0.0568	 decision: 0.1472	 get_bound: 0.9495	 add_domain: 0.0416
Current lb:-0.17548105120658875
4450 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.8447425365448

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1188] [1, 4571] [1, 1188] [1, 7924] [1, 4571] [1, 7924] [1, 485] [1, 485] [1, 485] [1, 485] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 84.09711456298828 with beta sum per layer: [0.0, 42.777793884277344, 6.117129325866699]
alpha/beta optimization time: 0.8190486431121826
This batch time : update_bounds func: 0.9468	 prepare: 0.0482	 bound: 0.8194	 transfer: 0.0474	 finalize: 0.0307
Accumulated time: update_bounds func: 10.6551	 prepare: 0.4538	 bound: 9.2622	 transfer: 0.0474	 finalize: 0.4643
batch bounding time:  0.9474241733551025
Current worst splitting domains [lb, ub] (depth):
[-0.17379,   inf] (33), [-0.17343,   inf] (33), [-0.17326,   inf] (33), [-0.17291,   inf] (33), [-0.17256,   inf] (33), [-0.17223,   inf] (33), [-0.17206,   inf] (33), [-0.17193,   inf] (33), [-0.17186,   inf] (33), [-0.17179,   inf] (33), [-0.17177,   inf] (33), [-0.17175,   inf] (33), [-0.17166,   inf] (33), [-0.17165,   inf] (33), [-0.17156,   inf] (33), [-0.17142,   inf] (33), [-0.17138,   inf] (33), [-0.17137,   inf] (33), [-0.17135,   inf] (33), [-0.17131,   inf] (33), 
length of domains: 2001
Total time: 1.1920	 pickout: 0.0574	 decision: 0.1465	 get_bound: 0.9482	 add_domain: 0.0400
Current lb:-0.17379139363765717
4962 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.04092788696289

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 7892] [1, 7892] [1, 7892] [1, 7892] [1, 7892] [1, 2596] [1, 7892] [1, 7892] [1, 7892] [1, 7892] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 84.21443176269531 with beta sum per layer: [0.0, 60.760093688964844, 3.666189193725586]
alpha/beta optimization time: 0.818626880645752
This batch time : update_bounds func: 0.9495	 prepare: 0.0517	 bound: 0.8190	 transfer: 0.0473	 finalize: 0.0300
Accumulated time: update_bounds func: 11.6045	 prepare: 0.5055	 bound: 10.0813	 transfer: 0.0473	 finalize: 0.4943
batch bounding time:  0.9500529766082764
Current worst splitting domains [lb, ub] (depth):
[-0.17215,   inf] (35), [-0.17179,   inf] (35), [-0.17164,   inf] (35), [-0.17128,   inf] (35), [-0.17094,   inf] (35), [-0.17062,   inf] (35), [-0.17044,   inf] (35), [-0.17033,   inf] (35), [-0.17030,   inf] (35), [-0.17026,   inf] (35), [-0.17025,   inf] (35), [-0.17022,   inf] (35), [-0.17001,   inf] (35), [-0.16996,   inf] (35), [-0.16989,   inf] (35), [-0.16984,   inf] (35), [-0.16983,   inf] (35), [-0.16980,   inf] (35), [-0.16979,   inf] (35), [-0.16974,   inf] (35), 
length of domains: 2257
Total time: 1.2722	 pickout: 0.0588	 decision: 0.2208	 get_bound: 0.9508	 add_domain: 0.0418
Current lb:-0.17215144634246826
5474 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.31730580329895

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 4892] [1, 4892] [1, 4892] [1, 4892] [1, 4892] [1, 7892] [1, 4892] [1, 1173] [1, 4892] [1, 4892] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 84.06132507324219 with beta sum per layer: [0.0, 71.36096954345703, 1.9832987785339355]
alpha/beta optimization time: 0.8207972049713135
This batch time : update_bounds func: 0.9497	 prepare: 0.0494	 bound: 0.8211	 transfer: 0.0472	 finalize: 0.0309
Accumulated time: update_bounds func: 12.5542	 prepare: 0.5549	 bound: 10.9024	 transfer: 0.0472	 finalize: 0.5252
batch bounding time:  0.9502530097961426
Current worst splitting domains [lb, ub] (depth):
[-0.17026,   inf] (37), [-0.17002,   inf] (37), [-0.16995,   inf] (37), [-0.16975,   inf] (37), [-0.16960,   inf] (37), [-0.16950,   inf] (37), [-0.16944,   inf] (37), [-0.16919,   inf] (37), [-0.16909,   inf] (37), [-0.16909,   inf] (37), [-0.16883,   inf] (37), [-0.16875,   inf] (37), [-0.16870,   inf] (37), [-0.16868,   inf] (37), [-0.16858,   inf] (37), [-0.16855,   inf] (37), [-0.16848,   inf] (37), [-0.16831,   inf] (37), [-0.16831,   inf] (37), [-0.16829,   inf] (37), 
length of domains: 2513
Total time: 1.2005	 pickout: 0.0598	 decision: 0.1469	 get_bound: 0.9510	 add_domain: 0.0427
Current lb:-0.170263409614563
5986 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.522228479385376

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2581] [1, 2581] [1, 2581] [1, 2581] [1, 2581] [1, 2581] [1, 2581] [1, 2581] [1, 1173] [1, 2581] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 83.60829162597656 with beta sum per layer: [0.0, 68.61004638671875, 1.228309154510498]
alpha/beta optimization time: 0.8198807239532471
This batch time : update_bounds func: 0.9486	 prepare: 0.0495	 bound: 0.8202	 transfer: 0.0473	 finalize: 0.0304
Accumulated time: update_bounds func: 13.5028	 prepare: 0.6044	 bound: 11.7226	 transfer: 0.0473	 finalize: 0.5556
batch bounding time:  0.9492993354797363
Current worst splitting domains [lb, ub] (depth):
[-0.16875,   inf] (39), [-0.16850,   inf] (39), [-0.16844,   inf] (39), [-0.16824,   inf] (39), [-0.16809,   inf] (39), [-0.16798,   inf] (39), [-0.16793,   inf] (39), [-0.16769,   inf] (39), [-0.16759,   inf] (39), [-0.16757,   inf] (39), [-0.16732,   inf] (39), [-0.16729,   inf] (39), [-0.16720,   inf] (39), [-0.16718,   inf] (39), [-0.16707,   inf] (39), [-0.16707,   inf] (39), [-0.16698,   inf] (39), [-0.16683,   inf] (39), [-0.16681,   inf] (39), [-0.16679,   inf] (39), 
length of domains: 2769
Total time: 1.2709	 pickout: 0.0580	 decision: 0.2179	 get_bound: 0.9501	 add_domain: 0.0450
Current lb:-0.1687537431716919
6498 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 19.797513484954834

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2587] [1, 2587] [1, 2587] [1, 2587] [1, 2587] [1, 2587] [1, 2587] [1, 2587] [1, 6229] [1, 2587] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 83.08660125732422 with beta sum per layer: [0.0, 64.59909057617188, 1.191469430923462]
alpha/beta optimization time: 0.8241121768951416
This batch time : update_bounds func: 0.9554	 prepare: 0.0510	 bound: 0.8245	 transfer: 0.0474	 finalize: 0.0312
Accumulated time: update_bounds func: 14.4582	 prepare: 0.6553	 bound: 12.5471	 transfer: 0.0474	 finalize: 0.5868
batch bounding time:  0.9559578895568848
Current worst splitting domains [lb, ub] (depth):
[-0.16725,   inf] (41), [-0.16702,   inf] (41), [-0.16692,   inf] (41), [-0.16679,   inf] (41), [-0.16660,   inf] (41), [-0.16656,   inf] (41), [-0.16646,   inf] (41), [-0.16614,   inf] (41), [-0.16614,   inf] (41), [-0.16612,   inf] (41), [-0.16586,   inf] (41), [-0.16583,   inf] (41), [-0.16574,   inf] (41), [-0.16567,   inf] (41), [-0.16555,   inf] (41), [-0.16538,   inf] (41), [-0.16537,   inf] (41), [-0.16536,   inf] (41), [-0.16535,   inf] (41), [-0.16527,   inf] (41), 
length of domains: 3025
Total time: 1.2100	 pickout: 0.0578	 decision: 0.1481	 get_bound: 0.9567	 add_domain: 0.0474
Current lb:-0.1672477424144745
7010 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 21.012190341949463

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2596] [1, 2596] [1, 2596] [1, 2596] [1, 2596] [1, 2596] [1, 2596] [1, 2596] [1, 7652] [1, 7652] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 82.60617065429688 with beta sum per layer: [0.0, 68.52099609375, 1.3984580039978027]
alpha/beta optimization time: 0.8233475685119629
This batch time : update_bounds func: 1.0473	 prepare: 0.0501	 bound: 0.8237	 transfer: 0.0479	 finalize: 0.1244
Accumulated time: update_bounds func: 15.5055	 prepare: 0.7054	 bound: 13.3707	 transfer: 0.0479	 finalize: 0.7112
batch bounding time:  1.0481204986572266
Current worst splitting domains [lb, ub] (depth):
[-0.16577,   inf] (43), [-0.16556,   inf] (43), [-0.16551,   inf] (43), [-0.16531,   inf] (43), [-0.16520,   inf] (43), [-0.16510,   inf] (43), [-0.16505,   inf] (43), [-0.16475,   inf] (43), [-0.16473,   inf] (43), [-0.16458,   inf] (43), [-0.16435,   inf] (43), [-0.16423,   inf] (43), [-0.16422,   inf] (43), [-0.16413,   inf] (43), [-0.16402,   inf] (43), [-0.16389,   inf] (43), [-0.16388,   inf] (43), [-0.16386,   inf] (43), [-0.16386,   inf] (43), [-0.16385,   inf] (43), 
length of domains: 3281
Total time: 1.3022	 pickout: 0.0588	 decision: 0.1469	 get_bound: 1.0491	 add_domain: 0.0475
Current lb:-0.1657707542181015
7522 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 22.318729877471924

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 6229] [1, 6229] [1, 6229] [1, 6229] [1, 6229] [1, 6229] [1, 6229] [1, 4571] [1, 6229] [1, 6229] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 82.24581909179688 with beta sum per layer: [0.0, 69.17328643798828, 2.0127947330474854]
alpha/beta optimization time: 0.8287947177886963
This batch time : update_bounds func: 0.9820	 prepare: 0.0747	 bound: 0.8292	 transfer: 0.0461	 finalize: 0.0307
Accumulated time: update_bounds func: 16.4875	 prepare: 0.7801	 bound: 14.1999	 transfer: 0.0461	 finalize: 0.7419
batch bounding time:  0.9825832843780518
Current worst splitting domains [lb, ub] (depth):
[-0.16416,   inf] (45), [-0.16396,   inf] (45), [-0.16391,   inf] (45), [-0.16371,   inf] (45), [-0.16360,   inf] (45), [-0.16357,   inf] (45), [-0.16349,   inf] (45), [-0.16345,   inf] (45), [-0.16345,   inf] (45), [-0.16324,   inf] (45), [-0.16320,   inf] (45), [-0.16315,   inf] (45), [-0.16313,   inf] (45), [-0.16308,   inf] (45), [-0.16307,   inf] (45), [-0.16299,   inf] (45), [-0.16298,   inf] (45), [-0.16295,   inf] (35), [-0.16295,   inf] (37), [-0.16295,   inf] (43), 
length of domains: 3537
Total time: 1.2728	 pickout: 0.0740	 decision: 0.1688	 get_bound: 0.9834	 add_domain: 0.0467
Current lb:-0.16415955126285553
8034 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 23.596100330352783

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 4579] [1, 4579] [1, 7652] [1, 4579] [1, 7652] [2, 129] [1, 4579] [1, 7652] [1, 4579] [1, 4579] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 80.61799621582031 with beta sum per layer: [0.0, 70.6983642578125, 3.5727217197418213]
alpha/beta optimization time: 0.8177735805511475
This batch time : update_bounds func: 0.9434	 prepare: 0.0506	 bound: 0.8181	 transfer: 0.0415	 finalize: 0.0318
Accumulated time: update_bounds func: 17.4309	 prepare: 0.8307	 bound: 15.0180	 transfer: 0.0415	 finalize: 0.7737
batch bounding time:  0.9439828395843506
Current worst splitting domains [lb, ub] (depth):
[-0.16299,   inf] (47), [-0.16276,   inf] (47), [-0.16262,   inf] (47), [-0.16255,   inf] (37), [-0.16255,   inf] (37), [-0.16255,   inf] (41), [-0.16254,   inf] (39), [-0.16254,   inf] (35), [-0.16254,   inf] (45), [-0.16254,   inf] (39), [-0.16254,   inf] (45), [-0.16254,   inf] (43), [-0.16254,   inf] (33), [-0.16254,   inf] (39), [-0.16254,   inf] (43), [-0.16254,   inf] (47), [-0.16254,   inf] (45), [-0.16253,   inf] (41), [-0.16253,   inf] (37), [-0.16253,   inf] (35), 
length of domains: 3785
Total time: 1.1987	 pickout: 0.0589	 decision: 0.1489	 get_bound: 0.9448	 add_domain: 0.0462
Current lb:-0.1629934012889862
8546 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 24.799949169158936

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2579] [1, 2579] [1, 2579] [1, 2596] [1, 2581] [1, 7652] [1, 6229] [1, 2581] [2, 129] [1, 2596] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 80.38740539550781 with beta sum per layer: [0.0, 81.27978515625, 3.3839526176452637]
alpha/beta optimization time: 0.819105863571167
This batch time : update_bounds func: 0.9458	 prepare: 0.0510	 bound: 0.8194	 transfer: 0.0415	 finalize: 0.0325
Accumulated time: update_bounds func: 18.3766	 prepare: 0.8817	 bound: 15.8375	 transfer: 0.0415	 finalize: 0.8062
batch bounding time:  0.9463546276092529
Current worst splitting domains [lb, ub] (depth):
[-0.16216,   inf] (31), [-0.16216,   inf] (47), [-0.16216,   inf] (37), [-0.16215,   inf] (43), [-0.16215,   inf] (45), [-0.16215,   inf] (39), [-0.16215,   inf] (31), [-0.16215,   inf] (31), [-0.16215,   inf] (39), [-0.16215,   inf] (39), [-0.16215,   inf] (41), [-0.16215,   inf] (45), [-0.16215,   inf] (37), [-0.16214,   inf] (43), [-0.16214,   inf] (37), [-0.16214,   inf] (43), [-0.16214,   inf] (39), [-0.16214,   inf] (37), [-0.16214,   inf] (41), [-0.16214,   inf] (45), 
length of domains: 4033
Total time: 1.2905	 pickout: 0.0584	 decision: 0.2390	 get_bound: 0.9471	 add_domain: 0.0459
Current lb:-0.16215863823890686
9058 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 26.095444440841675

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2596] [1, 2579] [1, 2596] [2, 129] [1, 7652] [1, 4892] [1, 4571] [1, 485] [1, 4892] [1, 2596] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 80.06999969482422 with beta sum per layer: [0.0, 76.04695892333984, 3.804110527038574]
alpha/beta optimization time: 0.8200931549072266
This batch time : update_bounds func: 0.9484	 prepare: 0.0519	 bound: 0.8204	 transfer: 0.0416	 finalize: 0.0329
Accumulated time: update_bounds func: 19.3251	 prepare: 0.9337	 bound: 16.6579	 transfer: 0.0416	 finalize: 0.8391
batch bounding time:  0.9490599632263184
Current worst splitting domains [lb, ub] (depth):
[-0.16183,   inf] (33), [-0.16182,   inf] (43), [-0.16182,   inf] (45), [-0.16182,   inf] (41), [-0.16182,   inf] (41), [-0.16182,   inf] (37), [-0.16182,   inf] (41), [-0.16182,   inf] (45), [-0.16181,   inf] (43), [-0.16181,   inf] (41), [-0.16181,   inf] (39), [-0.16181,   inf] (41), [-0.16181,   inf] (37), [-0.16181,   inf] (33), [-0.16181,   inf] (47), [-0.16181,   inf] (41), [-0.16181,   inf] (35), [-0.16181,   inf] (45), [-0.16181,   inf] (31), [-0.16181,   inf] (39), 
length of domains: 4280
Total time: 1.2076	 pickout: 0.0601	 decision: 0.1506	 get_bound: 0.9499	 add_domain: 0.0471
Current lb:-0.16182518005371094
9570 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 27.308301210403442

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 4570] [1, 6229] [1, 7652] [1, 7652] [1, 2587] [1, 7652] [1, 7652] [2, 129] [1, 4571] [1, 2596] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 78.78285217285156 with beta sum per layer: [0.0, 76.57664489746094, 4.968616485595703]
alpha/beta optimization time: 0.8168110847473145
This batch time : update_bounds func: 1.0592	 prepare: 0.0517	 bound: 0.8172	 transfer: 0.0509	 finalize: 0.1379
Accumulated time: update_bounds func: 20.3843	 prepare: 0.9854	 bound: 17.4751	 transfer: 0.0509	 finalize: 0.9770
batch bounding time:  1.0598998069763184
Current worst splitting domains [lb, ub] (depth):
[-0.16156,   inf] (43), [-0.16156,   inf] (41), [-0.16156,   inf] (43), [-0.16156,   inf] (39), [-0.16156,   inf] (43), [-0.16156,   inf] (41), [-0.16156,   inf] (43), [-0.16156,   inf] (47), [-0.16156,   inf] (49), [-0.16155,   inf] (43), [-0.16155,   inf] (35), [-0.16155,   inf] (41), [-0.16155,   inf] (45), [-0.16155,   inf] (37), [-0.16155,   inf] (41), [-0.16155,   inf] (35), [-0.16154,   inf] (33), [-0.16154,   inf] (45), [-0.16154,   inf] (39), [-0.16154,   inf] (35), 
length of domains: 4520
Total time: 1.3176	 pickout: 0.0621	 decision: 0.1494	 get_bound: 1.0608	 add_domain: 0.0453
Current lb:-0.16156212985515594
10082 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 28.630934238433838

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 4571] [1, 2587] [1, 4571] [1, 4892] [1, 4571] [1, 2587] [1, 4571] [1, 2579] [1, 2581] [1, 2587] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 78.63568115234375 with beta sum per layer: [0.0, 84.06968688964844, 4.62119197845459]
alpha/beta optimization time: 0.8227143287658691
This batch time : update_bounds func: 0.9593	 prepare: 0.0512	 bound: 0.8230	 transfer: 0.0509	 finalize: 0.0327
Accumulated time: update_bounds func: 21.3436	 prepare: 1.0366	 bound: 18.2981	 transfer: 0.0509	 finalize: 1.0097
batch bounding time:  0.9599647521972656
Current worst splitting domains [lb, ub] (depth):
[-0.16126,   inf] (37), [-0.16126,   inf] (37), [-0.16126,   inf] (49), [-0.16126,   inf] (41), [-0.16126,   inf] (39), [-0.16125,   inf] (47), [-0.16125,   inf] (33), [-0.16125,   inf] (41), [-0.16125,   inf] (35), [-0.16125,   inf] (41), [-0.16125,   inf] (35), [-0.16125,   inf] (37), [-0.16125,   inf] (45), [-0.16125,   inf] (41), [-0.16125,   inf] (39), [-0.16125,   inf] (41), [-0.16125,   inf] (37), [-0.16125,   inf] (43), [-0.16125,   inf] (43), [-0.16125,   inf] (35), 
length of domains: 4760
Total time: 1.2176	 pickout: 0.0583	 decision: 0.1503	 get_bound: 0.9608	 add_domain: 0.0482
Current lb:-0.16125695407390594
10594 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 29.853986024856567

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1173] [1, 7892] [1, 7652] [1, 7652] [1, 6229] [1, 2590] [1, 1188] [1, 2587] [1, 2596] [1, 2587] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 78.1544189453125 with beta sum per layer: [0.0, 80.72920227050781, 5.179771423339844]
alpha/beta optimization time: 0.8306312561035156
This batch time : update_bounds func: 0.9668	 prepare: 0.0523	 bound: 0.8310	 transfer: 0.0469	 finalize: 0.0351
Accumulated time: update_bounds func: 22.3104	 prepare: 1.0889	 bound: 19.1291	 transfer: 0.0469	 finalize: 1.0447
batch bounding time:  0.9674925804138184
Current worst splitting domains [lb, ub] (depth):
[-0.16103,   inf] (37), [-0.16103,   inf] (43), [-0.16103,   inf] (47), [-0.16103,   inf] (33), [-0.16103,   inf] (35), [-0.16103,   inf] (37), [-0.16103,   inf] (39), [-0.16102,   inf] (31), [-0.16102,   inf] (39), [-0.16102,   inf] (37), [-0.16102,   inf] (39), [-0.16102,   inf] (35), [-0.16102,   inf] (41), [-0.16102,   inf] (41), [-0.16102,   inf] (47), [-0.16102,   inf] (41), [-0.16102,   inf] (35), [-0.16102,   inf] (33), [-0.16102,   inf] (49), [-0.16102,   inf] (41), 
length of domains: 4998
Total time: 1.2277	 pickout: 0.0608	 decision: 0.1501	 get_bound: 0.9684	 add_domain: 0.0484
Current lb:-0.16102932393550873
11106 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 31.08735990524292

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1173] [1, 4571] [1, 2590] [1, 485] [1, 7892] [1, 2596] [1, 6229] [1, 4570] [1, 6229] [1, 2587] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 78.54283905029297 with beta sum per layer: [0.0, 83.53338623046875, 4.980729103088379]
alpha/beta optimization time: 0.8324058055877686
This batch time : update_bounds func: 0.9667	 prepare: 0.0520	 bound: 0.8328	 transfer: 0.0466	 finalize: 0.0333
Accumulated time: update_bounds func: 23.2772	 prepare: 1.1409	 bound: 19.9619	 transfer: 0.0466	 finalize: 1.0780
batch bounding time:  0.9673600196838379
Current worst splitting domains [lb, ub] (depth):
[-0.16080,   inf] (33), [-0.16080,   inf] (43), [-0.16080,   inf] (43), [-0.16080,   inf] (33), [-0.16080,   inf] (47), [-0.16079,   inf] (43), [-0.16079,   inf] (41), [-0.16079,   inf] (39), [-0.16079,   inf] (39), [-0.16079,   inf] (43), [-0.16079,   inf] (49), [-0.16079,   inf] (31), [-0.16079,   inf] (33), [-0.16079,   inf] (43), [-0.16079,   inf] (49), [-0.16079,   inf] (37), [-0.16079,   inf] (35), [-0.16078,   inf] (43), [-0.16078,   inf] (39), [-0.16078,   inf] (37), 
length of domains: 5239
Total time: 1.3562	 pickout: 0.0611	 decision: 0.2807	 get_bound: 0.9682	 add_domain: 0.0462
Current lb:-0.1607988029718399
11618 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 32.44900321960449

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1188] [1, 6229] [1, 4571] [1, 7892] [1, 2579] [1, 6229] [1, 7652] [1, 6229] [1, 2587] [1, 2285] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 77.27938842773438 with beta sum per layer: [0.0, 80.00517272949219, 5.782219886779785]
alpha/beta optimization time: 0.8248653411865234
This batch time : update_bounds func: 0.9571	 prepare: 0.0506	 bound: 0.8252	 transfer: 0.0466	 finalize: 0.0332
Accumulated time: update_bounds func: 24.2343	 prepare: 1.1914	 bound: 20.7871	 transfer: 0.0466	 finalize: 1.1112
batch bounding time:  0.9577584266662598
Current worst splitting domains [lb, ub] (depth):
[-0.16059,   inf] (35), [-0.16059,   inf] (47), [-0.16059,   inf] (41), [-0.16059,   inf] (43), [-0.16059,   inf] (41), [-0.16059,   inf] (41), [-0.16059,   inf] (43), [-0.16059,   inf] (41), [-0.16059,   inf] (45), [-0.16058,   inf] (43), [-0.16058,   inf] (39), [-0.16058,   inf] (45), [-0.16058,   inf] (43), [-0.16058,   inf] (43), [-0.16058,   inf] (47), [-0.16058,   inf] (41), [-0.16058,   inf] (45), [-0.16058,   inf] (43), [-0.16058,   inf] (37), [-0.16058,   inf] (37), 
length of domains: 5473
Total time: 1.2178	 pickout: 0.0611	 decision: 0.1506	 get_bound: 0.9586	 add_domain: 0.0475
Current lb:-0.16059350967407227
12130 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 33.67234253883362

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2596] [1, 2579] [1, 2596] [1, 4571] [1, 7652] [1, 7652] [1, 4571] [1, 4571] [2, 129] [1, 2285] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 76.86874389648438 with beta sum per layer: [0.0, 86.55549621582031, 5.7141923904418945]
alpha/beta optimization time: 0.8205277919769287
This batch time : update_bounds func: 0.9574	 prepare: 0.0515	 bound: 0.8209	 transfer: 0.0512	 finalize: 0.0322
Accumulated time: update_bounds func: 25.1917	 prepare: 1.2429	 bound: 21.6080	 transfer: 0.0512	 finalize: 1.1434
batch bounding time:  0.9580023288726807
Current worst splitting domains [lb, ub] (depth):
[-0.16038,   inf] (47), [-0.16038,   inf] (39), [-0.16038,   inf] (45), [-0.16038,   inf] (37), [-0.16038,   inf] (45), [-0.16038,   inf] (35), [-0.16038,   inf] (43), [-0.16037,   inf] (39), [-0.16037,   inf] (35), [-0.16037,   inf] (41), [-0.16037,   inf] (41), [-0.16037,   inf] (41), [-0.16037,   inf] (37), [-0.16037,   inf] (41), [-0.16037,   inf] (37), [-0.16037,   inf] (43), [-0.16037,   inf] (43), [-0.16037,   inf] (41), [-0.16037,   inf] (35), [-0.16037,   inf] (41), 
length of domains: 5706
Total time: 1.3574	 pickout: 0.0610	 decision: 0.1509	 get_bound: 0.9588	 add_domain: 0.1866
Current lb:-0.16038186848163605
12642 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 35.035072803497314

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2590] [1, 2587] [2, 129] [1, 4892] [2, 129] [1, 2587] [1, 4571] [1, 6229] [1, 2581] [1, 2587] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 75.95669555664062 with beta sum per layer: [0.0, 84.24583435058594, 6.703598976135254]
alpha/beta optimization time: 0.8231425285339355
This batch time : update_bounds func: 0.9586	 prepare: 0.0509	 bound: 0.8235	 transfer: 0.0493	 finalize: 0.0333
Accumulated time: update_bounds func: 26.1502	 prepare: 1.2938	 bound: 22.4315	 transfer: 0.0493	 finalize: 1.1768
batch bounding time:  0.9591994285583496
Current worst splitting domains [lb, ub] (depth):
[-0.16020,   inf] (39), [-0.16020,   inf] (39), [-0.16020,   inf] (49), [-0.16019,   inf] (31), [-0.16019,   inf] (37), [-0.16019,   inf] (37), [-0.16019,   inf] (43), [-0.16019,   inf] (43), [-0.16019,   inf] (37), [-0.16019,   inf] (39), [-0.16019,   inf] (41), [-0.16019,   inf] (41), [-0.16019,   inf] (45), [-0.16019,   inf] (37), [-0.16019,   inf] (41), [-0.16018,   inf] (47), [-0.16018,   inf] (35), [-0.16018,   inf] (39), [-0.16018,   inf] (35), [-0.16018,   inf] (43), 
length of domains: 5934
Total time: 1.2163	 pickout: 0.0592	 decision: 0.1511	 get_bound: 0.9600	 add_domain: 0.0459
Current lb:-0.16019976139068604
13154 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 36.25695753097534

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2587] [1, 2596] [1, 2581] [1, 2596] [1, 7652] [1, 7892] [1, 6229] [1, 4571] [1, 7892] [1, 8036] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 76.84382629394531 with beta sum per layer: [0.0, 86.4381103515625, 5.431629180908203]
alpha/beta optimization time: 0.8434174060821533
This batch time : update_bounds func: 0.9893	 prepare: 0.0507	 bound: 0.8438	 transfer: 0.0469	 finalize: 0.0465
Accumulated time: update_bounds func: 27.1396	 prepare: 1.3445	 bound: 23.2752	 transfer: 0.0469	 finalize: 1.2232
batch bounding time:  0.9900221824645996
Current worst splitting domains [lb, ub] (depth):
[-0.16003,   inf] (43), [-0.16003,   inf] (43), [-0.16003,   inf] (39), [-0.16002,   inf] (33), [-0.16002,   inf] (35), [-0.16002,   inf] (49), [-0.16002,   inf] (35), [-0.16002,   inf] (45), [-0.16002,   inf] (45), [-0.16002,   inf] (45), [-0.16002,   inf] (35), [-0.16002,   inf] (41), [-0.16002,   inf] (39), [-0.16002,   inf] (47), [-0.16002,   inf] (43), [-0.16002,   inf] (43), [-0.16002,   inf] (43), [-0.16001,   inf] (41), [-0.16001,   inf] (37), [-0.16001,   inf] (37), 
length of domains: 6167
Total time: 1.2543	 pickout: 0.0612	 decision: 0.1516	 get_bound: 0.9909	 add_domain: 0.0505
Current lb:-0.16002577543258667
13666 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 37.516833543777466

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 4571] [2, 129] [1, 6229] [1, 7892] [1, 2587] [1, 4579] [1, 7892] [2, 129] [1, 2596] [1, 6229] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 76.23291015625 with beta sum per layer: [0.0, 92.7821273803711, 6.496951103210449]
alpha/beta optimization time: 0.8227009773254395
This batch time : update_bounds func: 0.9805	 prepare: 0.0762	 bound: 0.8231	 transfer: 0.0464	 finalize: 0.0332
Accumulated time: update_bounds func: 28.1201	 prepare: 1.4206	 bound: 24.0984	 transfer: 0.0464	 finalize: 1.2564
batch bounding time:  0.9811322689056396
Current worst splitting domains [lb, ub] (depth):
[-0.15985,   inf] (33), [-0.15985,   inf] (45), [-0.15985,   inf] (41), [-0.15985,   inf] (41), [-0.15985,   inf] (41), [-0.15985,   inf] (37), [-0.15985,   inf] (41), [-0.15985,   inf] (43), [-0.15985,   inf] (51), [-0.15984,   inf] (45), [-0.15984,   inf] (41), [-0.15984,   inf] (31), [-0.15984,   inf] (37), [-0.15984,   inf] (45), [-0.15984,   inf] (41), [-0.15984,   inf] (39), [-0.15984,   inf] (41), [-0.15984,   inf] (47), [-0.15984,   inf] (35), [-0.15984,   inf] (43), 
length of domains: 6397
Total time: 1.4267	 pickout: 0.0774	 decision: 0.1699	 get_bound: 0.9820	 add_domain: 0.1974
Current lb:-0.15984876453876495
14178 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 38.94890761375427

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 485] [2, 129] [1, 7652] [1, 7652] [1, 7652] [1, 2596] [1, 7652] [1, 6229] [1, 4578] [1, 6229] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 75.84986877441406 with beta sum per layer: [0.0, 96.00445556640625, 5.830826759338379]
alpha/beta optimization time: 0.8241114616394043
This batch time : update_bounds func: 0.9642	 prepare: 0.0540	 bound: 0.8245	 transfer: 0.0509	 finalize: 0.0331
Accumulated time: update_bounds func: 29.0842	 prepare: 1.4746	 bound: 24.9228	 transfer: 0.0509	 finalize: 1.2896
batch bounding time:  0.9647808074951172
Current worst splitting domains [lb, ub] (depth):
[-0.15970,   inf] (45), [-0.15970,   inf] (33), [-0.15970,   inf] (39), [-0.15970,   inf] (39), [-0.15970,   inf] (47), [-0.15970,   inf] (49), [-0.15970,   inf] (45), [-0.15970,   inf] (47), [-0.15970,   inf] (45), [-0.15970,   inf] (39), [-0.15970,   inf] (41), [-0.15970,   inf] (43), [-0.15970,   inf] (43), [-0.15970,   inf] (43), [-0.15969,   inf] (39), [-0.15969,   inf] (47), [-0.15969,   inf] (49), [-0.15969,   inf] (39), [-0.15969,   inf] (39), [-0.15969,   inf] (45), 
length of domains: 6626
Total time: 1.2238	 pickout: 0.0605	 decision: 0.1514	 get_bound: 0.9656	 add_domain: 0.0463
Current lb:-0.1597018539905548
14690 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 40.17819261550903

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2596] [1, 2581] [1, 2587] [1, 6229] [1, 1173] [1, 2581] [1, 4579] [1, 4578] [2, 129] [1, 4892] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 75.56578063964844 with beta sum per layer: [0.0, 89.12074279785156, 6.552515983581543]
alpha/beta optimization time: 0.8191626071929932
This batch time : update_bounds func: 0.9538	 prepare: 0.0508	 bound: 0.8195	 transfer: 0.0490	 finalize: 0.0327
Accumulated time: update_bounds func: 30.0380	 prepare: 1.5255	 bound: 25.7423	 transfer: 0.0490	 finalize: 1.3222
batch bounding time:  0.9544262886047363
Current worst splitting domains [lb, ub] (depth):
[-0.15955,   inf] (45), [-0.15955,   inf] (31), [-0.15955,   inf] (41), [-0.15955,   inf] (45), [-0.15955,   inf] (33), [-0.15955,   inf] (33), [-0.15955,   inf] (39), [-0.15955,   inf] (39), [-0.15954,   inf] (43), [-0.15954,   inf] (31), [-0.15954,   inf] (45), [-0.15954,   inf] (41), [-0.15954,   inf] (39), [-0.15954,   inf] (45), [-0.15954,   inf] (43), [-0.15954,   inf] (45), [-0.15954,   inf] (37), [-0.15954,   inf] (41), [-0.15954,   inf] (37), [-0.15954,   inf] (43), 
length of domains: 6853
Total time: 1.2141	 pickout: 0.0588	 decision: 0.1515	 get_bound: 0.9553	 add_domain: 0.0485
Current lb:-0.15954835712909698
15202 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 41.39907145500183

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2596] [1, 7924] [1, 4571] [2, 129] [1, 8036] [1, 7892] [1, 2587] [1, 4892] [1, 8036] [1, 7924] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 75.0195541381836 with beta sum per layer: [0.0, 93.37915802001953, 7.094006538391113]
alpha/beta optimization time: 0.8310062885284424
This batch time : update_bounds func: 0.9776	 prepare: 0.0516	 bound: 0.8314	 transfer: 0.0466	 finalize: 0.0464
Accumulated time: update_bounds func: 31.0156	 prepare: 1.5771	 bound: 26.5737	 transfer: 0.0466	 finalize: 1.3686
batch bounding time:  0.9783041477203369
Current worst splitting domains [lb, ub] (depth):
[-0.15940,   inf] (47), [-0.15940,   inf] (47), [-0.15940,   inf] (47), [-0.15940,   inf] (49), [-0.15940,   inf] (39), [-0.15940,   inf] (37), [-0.15940,   inf] (43), [-0.15940,   inf] (31), [-0.15939,   inf] (39), [-0.15939,   inf] (39), [-0.15939,   inf] (41), [-0.15939,   inf] (41), [-0.15939,   inf] (41), [-0.15939,   inf] (45), [-0.15939,   inf] (45), [-0.15939,   inf] (39), [-0.15939,   inf] (51), [-0.15938,   inf] (39), [-0.15938,   inf] (53), [-0.15938,   inf] (43), 
length of domains: 7077
Total time: 1.2412	 pickout: 0.0614	 decision: 0.1516	 get_bound: 0.9792	 add_domain: 0.0490
Current lb:-0.15939894318580627
15714 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 42.64613914489746

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2579] [1, 2590] [1, 1173] [1, 4579] [1, 4892] [1, 6229] [2, 129] [1, 2596] [1, 4892] [1, 4892] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 75.22224426269531 with beta sum per layer: [0.0, 89.85711669921875, 6.964176177978516]
alpha/beta optimization time: 0.8414285182952881
This batch time : update_bounds func: 1.0127	 prepare: 0.0763	 bound: 0.8418	 transfer: 0.0466	 finalize: 0.0462
Accumulated time: update_bounds func: 32.0283	 prepare: 1.6534	 bound: 27.4155	 transfer: 0.0466	 finalize: 1.4148
batch bounding time:  1.013331651687622
Current worst splitting domains [lb, ub] (depth):
[-0.15926,   inf] (41), [-0.15926,   inf] (43), [-0.15926,   inf] (39), [-0.15926,   inf] (43), [-0.15926,   inf] (39), [-0.15926,   inf] (39), [-0.15926,   inf] (33), [-0.15926,   inf] (39), [-0.15926,   inf] (49), [-0.15926,   inf] (45), [-0.15926,   inf] (35), [-0.15926,   inf] (37), [-0.15926,   inf] (45), [-0.15926,   inf] (47), [-0.15926,   inf] (47), [-0.15926,   inf] (39), [-0.15926,   inf] (45), [-0.15926,   inf] (41), [-0.15926,   inf] (37), [-0.15926,   inf] (41), 
length of domains: 7304
Total time: 1.4797	 pickout: 0.0778	 decision: 0.3377	 get_bound: 1.0142	 add_domain: 0.0500
Current lb:-0.15926118195056915
16226 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 44.131720304489136

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2587] [1, 4571] [1, 4571] [1, 4571] [1, 8036] [1, 6229] [1, 2581] [1, 2596] [1, 2581] [1, 6229] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 75.96595764160156 with beta sum per layer: [0.0, 94.30599212646484, 6.15541934967041]
alpha/beta optimization time: 0.8395180702209473
This batch time : update_bounds func: 1.0017	 prepare: 0.0767	 bound: 0.8399	 transfer: 0.0513	 finalize: 0.0322
Accumulated time: update_bounds func: 33.0300	 prepare: 1.7302	 bound: 28.2555	 transfer: 0.0513	 finalize: 1.4471
batch bounding time:  1.002326250076294
Current worst splitting domains [lb, ub] (depth):
[-0.15913,   inf] (45), [-0.15913,   inf] (35), [-0.15913,   inf] (41), [-0.15913,   inf] (41), [-0.15913,   inf] (35), [-0.15912,   inf] (45), [-0.15912,   inf] (45), [-0.15912,   inf] (43), [-0.15912,   inf] (49), [-0.15912,   inf] (37), [-0.15912,   inf] (43), [-0.15912,   inf] (37), [-0.15912,   inf] (43), [-0.15912,   inf] (35), [-0.15912,   inf] (37), [-0.15912,   inf] (37), [-0.15912,   inf] (47), [-0.15912,   inf] (45), [-0.15912,   inf] (43), [-0.15912,   inf] (43), 
length of domains: 7535
Total time: 1.3012	 pickout: 0.0775	 decision: 0.1723	 get_bound: 1.0032	 add_domain: 0.0482
Current lb:-0.15912804007530212
16738 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 45.43858051300049

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 4579] [1, 2581] [1, 4571] [1, 2596] [1, 2581] [1, 7652] [2, 129] [1, 4571] [1, 7652] [1, 1173] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 75.88202667236328 with beta sum per layer: [0.0, 89.58894348144531, 6.24267578125]
alpha/beta optimization time: 0.8237040042877197
This batch time : update_bounds func: 0.9591	 prepare: 0.0509	 bound: 0.8240	 transfer: 0.0491	 finalize: 0.0336/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:462: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(preprocess_cifar(eps_temp, perturbation=True)).reshape(1,-1,1,1)

Accumulated time: update_bounds func: 33.9891	 prepare: 1.7810	 bound: 29.0795	 transfer: 0.0491	 finalize: 1.4807
batch bounding time:  0.9597833156585693
Current worst splitting domains [lb, ub] (depth):
[-0.15901,   inf] (43), [-0.15901,   inf] (39), [-0.15901,   inf] (43), [-0.15901,   inf] (47), [-0.15901,   inf] (35), [-0.15901,   inf] (43), [-0.15901,   inf] (45), [-0.15901,   inf] (41), [-0.15901,   inf] (45), [-0.15901,   inf] (35), [-0.15901,   inf] (35), [-0.15901,   inf] (37), [-0.15901,   inf] (35), [-0.15901,   inf] (43), [-0.15900,   inf] (35), [-0.15900,   inf] (41), [-0.15900,   inf] (45), [-0.15900,   inf] (39), [-0.15900,   inf] (37), [-0.15900,   inf] (47), 
length of domains: 7765
Total time: 1.2182	 pickout: 0.0584	 decision: 0.1502	 get_bound: 0.9606	 add_domain: 0.0490
Current lb:-0.15901213884353638
17250 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 46.662797689437866

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2587] [1, 485] [1, 4571] [1, 1173] [1, 2581] [1, 4571] [1, 4579] [1, 7652] [2, 129] [1, 7892] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 74.09078979492188 with beta sum per layer: [0.0, 93.8995361328125, 7.700277328491211]
alpha/beta optimization time: 0.8201568126678467
This batch time : update_bounds func: 0.9519	 prepare: 0.0512	 bound: 0.8205	 transfer: 0.0464	 finalize: 0.0323
Accumulated time: update_bounds func: 34.9410	 prepare: 1.8322	 bound: 29.9000	 transfer: 0.0464	 finalize: 1.5130
batch bounding time:  0.9525096416473389
Current worst splitting domains [lb, ub] (depth):
[-0.15887,   inf] (49), [-0.15887,   inf] (41), [-0.15887,   inf] (51), [-0.15887,   inf] (35), [-0.15887,   inf] (41), [-0.15887,   inf] (43), [-0.15887,   inf] (51), [-0.15887,   inf] (45), [-0.15887,   inf] (39), [-0.15887,   inf] (47), [-0.15887,   inf] (43), [-0.15887,   inf] (45), [-0.15887,   inf] (41), [-0.15887,   inf] (41), [-0.15887,   inf] (45), [-0.15887,   inf] (33), [-0.15887,   inf] (35), [-0.15887,   inf] (35), [-0.15886,   inf] (37), [-0.15886,   inf] (39), 
length of domains: 7985
Total time: 1.4036	 pickout: 0.0601	 decision: 0.1532	 get_bound: 0.9534	 add_domain: 0.2370
Current lb:-0.15887242555618286
17762 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 48.07248592376709

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 2581] [1, 4571] [1, 4578] [1, 7892] [1, 7652] [1, 1173] [1, 1173] [1, 4579] [1, 4892] [1, 4578] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 74.66673278808594 with beta sum per layer: [0.0, 100.91270446777344, 6.683850288391113]
alpha/beta optimization time: 0.8291234970092773
This batch time : update_bounds func: 0.9612	 prepare: 0.0510	 bound: 0.8295	 transfer: 0.0464	 finalize: 0.0326
Accumulated time: update_bounds func: 35.9021	 prepare: 1.8832	 bound: 30.7295	 transfer: 0.0464	 finalize: 1.5455
batch bounding time:  0.9617702960968018
Current worst splitting domains [lb, ub] (depth):
[-0.15875,   inf] (43), [-0.15875,   inf] (45), [-0.15875,   inf] (45), [-0.15875,   inf] (47), [-0.15875,   inf] (43), [-0.15875,   inf] (43), [-0.15875,   inf] (41), [-0.15875,   inf] (41), [-0.15875,   inf] (45), [-0.15875,   inf] (39), [-0.15875,   inf] (43), [-0.15875,   inf] (37), [-0.15875,   inf] (41), [-0.15875,   inf] (47), [-0.15875,   inf] (41), [-0.15875,   inf] (45), [-0.15875,   inf] (39), [-0.15875,   inf] (35), [-0.15875,   inf] (43), [-0.15875,   inf] (41), 
length of domains: 8209
Total time: 1.2269	 pickout: 0.0619	 decision: 0.1544	 get_bound: 0.9626	 add_domain: 0.0480
Current lb:-0.1587538868188858
18274 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 49.30532217025757

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 32, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 32, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 4571] [2, 129] [1, 6229] [1, 2590] [1, 4571] [1, 2285] [1, 2587] [1, 4571] [1, 6229] [1, 4892] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 74.9638671875 with beta sum per layer: [0.0, 98.56263732910156, 6.380586624145508]
alpha/beta optimization time: 0.8184607028961182
This batch time : update_bounds func: 0.9534	 prepare: 0.0512	 bound: 0.8188	 transfer: 0.0478	 finalize: 0.0341
Accumulated time: update_bounds func: 36.8555	 prepare: 1.9344	 bound: 31.5483	 transfer: 0.0478	 finalize: 1.5797
batch bounding time:  0.9540426731109619
Current worst splitting domains [lb, ub] (depth):
[-0.15864,   inf] (47), [-0.15864,   inf] (45), [-0.15864,   inf] (47), [-0.15864,   inf] (33), [-0.15864,   inf] (43), [-0.15864,   inf] (43), [-0.15864,   inf] (37), [-0.15864,   inf] (43), [-0.15864,   inf] (49), [-0.15864,   inf] (43), [-0.15863,   inf] (41), [-0.15863,   inf] (41), [-0.15863,   inf] (43), [-0.15863,   inf] (45), [-0.15863,   inf] (49), [-0.15863,   inf] (35), [-0.15863,   inf] (43), [-0.15863,   inf] (37), [-0.15863,   inf] (47), [-0.15863,   inf] (51), 
length of domains: 8435
Total time: 1.2164	 pickout: 0.0605	 decision: 0.1530	 get_bound: 0.9549	 add_domain: 0.0479
Current lb:-0.1586391180753708
18786 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Time out!!!!!!!!
Image 67 label 4 verification end, final lower bound -0.1586391180753708, upper bound inf, time: 50.75518822669983
67 -0.1586391180753708
Result: image 67 verification failure (with branch and bound).
Wall time: 60.91604948043823

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 0): []
verification failure idx (total 1): [67]
final verified acc: 0.0%[1]
verifier is called on 1 examples.
total verified: 0
mean time [cnt:1] (excluding attack success): 60.84123229980469
