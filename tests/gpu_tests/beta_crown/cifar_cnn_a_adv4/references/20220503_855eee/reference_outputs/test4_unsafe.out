Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_cnn_a_adv4.model
  name: cnn_4layer_adv4
data:
  start: 132
  end: 133
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR_SDP
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.00784313725
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 4096
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 30
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 20:54:00 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Flatten()
  (5): Linear(in_features=2048, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([200, 3, 32, 32]) torch.Size([200]) torch.Size([200])
X range: tensor(2.1256) tensor(-1.9889) tensor(-0.0131)
############################
epsilon after preprocessing: tensor([[[[0.0317]],

         [[0.0322]],

         [[0.0300]]]]), data_max = tensor([[[[2.0587]],

         [[2.1256]],

         [[2.1154]]]]), data_min = tensor([[[[-1.9889]],

         [[-1.9807]],

         [[-1.7076]]]])
Task length: 1
saving results to Verified_ret_[cnn_4layer_adv4]_start=132_end=133_iter=20_b=4096_timeout=30_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 132 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 1, correct label 1, image norm 3034.08544921875, logits tensor([-16.9577, -15.7462, -20.8146, -22.2311, -21.1959, -22.5957, -22.3001,
        -21.6833, -16.5570, -15.9207], device='cuda:0',
       grad_fn=<SelectBackward>)
Model prediction is: tensor([[-16.9577, -15.7462, -20.8146, -22.2311, -21.1959, -22.5957, -22.3001,
         -21.6833, -16.5570, -15.9207]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 0.6845,  4.3126,  5.6933,  4.5616,  6.0420,  5.7353,  5.0560,  0.2425,
         -0.0681]], device='cuda:0') None
best_l after optimization: -32.3914794921875 with beta sum per layer: []
alpha/beta optimization time: 7.667781352996826
initial alpha-CROWN bounds: tensor([[ 0.6940,  4.3272,  5.7119,  4.5808,  6.0608,  5.7544,  5.0704,  0.2538,
         -0.0617]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.0617, device='cuda:0', grad_fn=<MinBackward1>)
##### [0:132] Tested against 9 ######
Model prediction is: tensor([[-16.9577, -15.7462, -20.8146, -22.2311, -21.1959, -22.5957, -22.3001,
         -21.6833, -16.5570, -15.9207]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 16, 16]) != torch.Size([2, 9, 1, 16, 16, 16]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 8, 8]) != torch.Size([2, 9, 1, 32, 8, 8]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 16, 16])
1 /11 torch.Size([1, 32, 8, 8])
2 /21 torch.Size([1, 100])
best_l after optimization: 0.06167757511138916 with beta sum per layer: []
alpha/beta optimization time: 2.0731284618377686
alpha-CROWN with fixed intermediate bounds: tensor([[-0.0617]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.06167757511138916
layer 0 size torch.Size([4096]) unstable 432
layer 1 size torch.Size([2048]) unstable 131
layer 2 size torch.Size([100]) unstable 2
-----------------
# of unstable neurons: 565
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 16, 16]) pre split depth:  8
batch:  torch.Size([1, 16, 16, 16]) post split depth:  8
splitting decisions: 
split level 0: [1, 1252] 
split level 1: [1, 1570] 
split level 2: [1, 1436] 
split level 3: [1, 1699] 
split level 4: [1, 915] 
split level 5: [1, 1446] 
split level 6: [1, 1428] 
split level 7: [1, 1106] 
regular batch size: 2*128, diving batch size 1*0
best_l after optimization: 8.850821495056152 with beta sum per layer: [0.0, 73.2423324584961, 0.0]
alpha/beta optimization time: 0.3000471591949463
This batch time : update_bounds func: 0.3481	 prepare: 0.0184	 bound: 0.3029	 transfer: 0.0101	 finalize: 0.0159
Accumulated time: update_bounds func: 0.3481	 prepare: 0.0184	 bound: 0.3029	 transfer: 0.0101	 finalize: 0.0159
batch bounding time:  0.34850597381591797
Current worst splitting domains [lb, ub] (depth):
[-0.04456,   inf] (9), [-0.04449,   inf] (9), [-0.04410,   inf] (9), [-0.04403,   inf] (9), [-0.04366,   inf] (9), [-0.04361,   inf] (9), [-0.04357,   inf] (9), [-0.04351,   inf] (9), [-0.04318,   inf] (9), [-0.04316,   inf] (9), [-0.04312,   inf] (9), [-0.04311,   inf] (9), [-0.04308,   inf] (9), [-0.04301,   inf] (9), [-0.04258,   inf] (9), [-0.04258,   inf] (9), [-0.04251,   inf] (9), [-0.04250,   inf] (9), [-0.04241,   inf] (9), [-0.04235,   inf] (9), 
length of domains: 256
Total time: 0.6636	 pickout: 0.0010	 decision: 0.2695	 get_bound: 0.3814	 add_domain: 0.0118
Current lb:-0.04455732926726341
256 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.5901310443878174

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([256, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([256, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 38] [1, 38] [1, 38] [1, 38] [1, 38] [1, 38] [1, 38] [1, 38] [1, 38] [1, 38] 
regular batch size: 2*256, diving batch size 1*0
best_l after optimization: 16.727251052856445 with beta sum per layer: [6.506165027618408, 143.88955688476562, 0.0]
alpha/beta optimization time: 0.38485193252563477
This batch time : update_bounds func: 0.4828	 prepare: 0.0443	 bound: 0.3852	 transfer: 0.0212	 finalize: 0.0310
Accumulated time: update_bounds func: 0.8310	 prepare: 0.0627	 bound: 0.6881	 transfer: 0.0212	 finalize: 0.0469/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:462: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(preprocess_cifar(eps_temp, perturbation=True)).reshape(1,-1,1,1)

batch bounding time:  0.4834601879119873
Current worst splitting domains [lb, ub] (depth):
[-0.04310,   inf] (11), [-0.04304,   inf] (11), [-0.04303,   inf] (11), [-0.04297,   inf] (11), [-0.04263,   inf] (11), [-0.04258,   inf] (11), [-0.04249,   inf] (11), [-0.04243,   inf] (11), [-0.04217,   inf] (11), [-0.04213,   inf] (11), [-0.04212,   inf] (11), [-0.04207,   inf] (11), [-0.04206,   inf] (11), [-0.04199,   inf] (11), [-0.04199,   inf] (11), [-0.04192,   inf] (11), [-0.04172,   inf] (11), [-0.04169,   inf] (11), [-0.04165,   inf] (11), [-0.04165,   inf] (11), 
length of domains: 512
Total time: 0.6458	 pickout: 0.0421	 decision: 0.0942	 get_bound: 0.4842	 add_domain: 0.0254
Current lb:-0.04309716448187828
768 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.239452838897705

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([512, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([512, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1698] [1, 1698] [1, 1698] [1, 1698] [1, 1698] [1, 1698] [1, 1698] [1, 1698] [1, 1698] [1, 1698] 
regular batch size: 2*512, diving batch size 1*0
best_l after optimization: 31.195837020874023 with beta sum per layer: [12.339706420898438, 336.51287841796875, 0.0]
alpha/beta optimization time: 0.6345119476318359
This batch time : update_bounds func: 0.8515	 prepare: 0.0892	 bound: 0.6349	 transfer: 0.0382	 finalize: 0.0868
Accumulated time: update_bounds func: 1.6824	 prepare: 0.1520	 bound: 1.3230	 transfer: 0.0382	 finalize: 0.1337
batch bounding time:  0.8525846004486084
Current worst splitting domains [lb, ub] (depth):
[-0.04186,   inf] (13), [-0.04181,   inf] (13), [-0.04180,   inf] (13), [-0.04175,   inf] (13), [-0.04141,   inf] (13), [-0.04136,   inf] (13), [-0.04127,   inf] (13), [-0.04122,   inf] (13), [-0.04093,   inf] (13), [-0.04091,   inf] (13), [-0.04090,   inf] (13), [-0.04088,   inf] (13), [-0.04085,   inf] (13), [-0.04083,   inf] (13), [-0.04083,   inf] (13), [-0.04075,   inf] (13), [-0.04049,   inf] (13), [-0.04044,   inf] (13), [-0.04044,   inf] (13), [-0.04043,   inf] (13), 
length of domains: 1024
Total time: 1.2145	 pickout: 0.0807	 decision: 0.2229	 get_bound: 0.8544	 add_domain: 0.0565
Current lb:-0.04186272621154785
1792 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.461233139038086

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1024, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 1160] [0, 3672] [0, 1160] [0, 3672] [1, 1771] [0, 3672] [1, 1771] [0, 3672] [1, 1771] [1, 1771] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 56.951175689697266 with beta sum per layer: [39.32933807373047, 886.867431640625, 0.0]
alpha/beta optimization time: 1.0467700958251953
This batch time : update_bounds func: 1.4685	 prepare: 0.2309	 bound: 1.0472	 transfer: 0.0623	 finalize: 0.1236
Accumulated time: update_bounds func: 3.1510	 prepare: 0.3828	 bound: 2.3702	 transfer: 0.0623	 finalize: 0.2572
batch bounding time:  1.470306158065796
Current worst splitting domains [lb, ub] (depth):
[-0.04083,   inf] (15), [-0.04075,   inf] (15), [-0.04051,   inf] (15), [-0.04043,   inf] (15), [-0.04028,   inf] (15), [-0.04028,   inf] (15), [-0.04020,   inf] (15), [-0.04015,   inf] (15), [-0.04005,   inf] (15), [-0.03991,   inf] (15), [-0.03989,   inf] (15), [-0.03989,   inf] (15), [-0.03984,   inf] (15), [-0.03984,   inf] (15), [-0.03981,   inf] (15), [-0.03969,   inf] (15), [-0.03968,   inf] (15), [-0.03961,   inf] (15), [-0.03959,   inf] (15), [-0.03952,   inf] (15), 
length of domains: 2048
Total time: 2.2539	 pickout: 0.2222	 decision: 0.3745	 get_bound: 1.4733	 add_domain: 0.1838
Current lb:-0.04082810878753662
3840 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.7295331954956055

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2048, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([2048, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1771] [1, 1771] [0, 1160] [0, 1160] [0, 1160] [0, 1160] [0, 1160] [0, 1160] [1, 1771] [1, 1771] 
regular batch size: 2*2048, diving batch size 1*0
best_l after optimization: 99.70211791992188 with beta sum per layer: [291.9388122558594, 2149.01220703125, 0.0]
alpha/beta optimization time: 2.00016188621521
This batch time : update_bounds func: 2.8112	 prepare: 0.3554	 bound: 2.0006	 transfer: 0.1241	 finalize: 0.3221
Accumulated time: update_bounds func: 5.9622	 prepare: 0.7383	 bound: 4.3708	 transfer: 0.1241	 finalize: 0.5793
batch bounding time:  2.8148574829101562
Current worst splitting domains [lb, ub] (depth):
[-0.03983,   inf] (17), [-0.03976,   inf] (17), [-0.03952,   inf] (17), [-0.03944,   inf] (17), [-0.03928,   inf] (17), [-0.03925,   inf] (17), [-0.03920,   inf] (17), [-0.03912,   inf] (17), [-0.03899,   inf] (17), [-0.03899,   inf] (17), [-0.03897,   inf] (17), [-0.03893,   inf] (17), [-0.03892,   inf] (17), [-0.03883,   inf] (17), [-0.03873,   inf] (17), [-0.03867,   inf] (17), [-0.03859,   inf] (17), [-0.03859,   inf] (17), [-0.03849,   inf] (17), [-0.03844,   inf] (17), 
length of domains: 4096
Total time: 4.1921	 pickout: 0.3597	 decision: 0.7639	 get_bound: 2.8219	 add_domain: 0.2466
Current lb:-0.039832569658756256
7936 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.955710172653198

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4096, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([4096, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [0, 3672] [0, 3672] [1, 1771] [1, 1771] [1, 1771] [0, 3672] [1, 1771] [0, 3672] [1, 867] [0, 3672] 
regular batch size: 2*4096, diving batch size 1*0
best_l after optimization: 181.7783203125 with beta sum per layer: [655.5809326171875, 4768.82568359375, 0.0]
alpha/beta optimization time: 3.8565280437469482
This batch time : update_bounds func: 5.6356	 prepare: 0.7318	 bound: 3.8570	 transfer: 0.2777	 finalize: 0.7508
Accumulated time: update_bounds func: 11.5978	 prepare: 1.4701	 bound: 8.2278	 transfer: 0.2777	 finalize: 1.3300
batch bounding time:  5.643781661987305
Current worst splitting domains [lb, ub] (depth):
[-0.03867,   inf] (19), [-0.03859,   inf] (19), [-0.03856,   inf] (19), [-0.03853,   inf] (19), [-0.03849,   inf] (19), [-0.03845,   inf] (19), [-0.03829,   inf] (19), [-0.03821,   inf] (19), [-0.03808,   inf] (19), [-0.03797,   inf] (19), [-0.03796,   inf] (19), [-0.03795,   inf] (19), [-0.03794,   inf] (19), [-0.03789,   inf] (19), [-0.03787,   inf] (19), [-0.03784,   inf] (19), [-0.03782,   inf] (19), [-0.03781,   inf] (19), [-0.03780,   inf] (19), [-0.03775,   inf] (19), 
length of domains: 8115
Total time: 9.0094	 pickout: 0.7661	 decision: 1.9137	 get_bound: 5.6581	 add_domain: 0.6714
Current lb:-0.0386660099029541
16128 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Time out!!!!!!!!
Image 132 label 9 verification end, final lower bound -0.0386660099029541, upper bound inf, time: 21.190006494522095
132 -0.0386660099029541
Result: image 132 verification failure (with branch and bound).
Wall time: 30.843080282211304

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 0): []
verification failure idx (total 1): [132]
final verified acc: 0.0%[1]
verifier is called on 1 examples.
total verified: 0
mean time [cnt:1] (excluding attack success): 30.780009984970093
