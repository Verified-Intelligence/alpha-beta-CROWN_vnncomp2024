Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_cnn_a_adv4.model
  name: cnn_4layer_adv4
data:
  start: 128
  end: 129
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR_SDP
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.00784313725
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 4096
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 30
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 20:53:38 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Flatten()
  (5): Linear(in_features=2048, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([200, 3, 32, 32]) torch.Size([200]) torch.Size([200])
X range: tensor(2.1256) tensor(-1.9889) tensor(-0.0131)
############################
epsilon after preprocessing: tensor([[[[0.0317]],

         [[0.0322]],

         [[0.0300]]]]), data_max = tensor([[[[2.0587]],

         [[2.1256]],

         [[2.1154]]]]), data_min = tensor([[[[-1.9889]],

         [[-1.9807]],

         [[-1.7076]]]])
Task length: 1
saving results to Verified_ret_[cnn_4layer_adv4]_start=128_end=129_iter=20_b=4096_timeout=30_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 128 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 6, correct label 6, image norm 1789.16015625, logits tensor([ -8.4125, -10.1163,  -6.9753,  -7.7043,  -6.8037,  -7.7779,  -6.5721,
         -8.0261,  -9.9338,  -9.1586], device='cuda:0',
       grad_fn=<SelectBackward>)
##### PGD attack: True label: 6, Tested against: ['all'] ######
pgd prediction: tensor([-8.1221, -9.9174, -6.6099, -7.3783, -6.4317, -7.4457, -6.3864, -7.6607,
        -9.6185, -8.9270], device='cuda:0', grad_fn=<SqueezeBackward1>)
attack margin tensor([1.7357, 3.5310, 0.2236, 0.9919, 0.0453, 1.0593,    inf, 1.2744, 3.2321,
        2.5407], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[ -8.4125, -10.1163,  -6.9753,  -7.7043,  -6.8037,  -7.7779,  -6.5721,
          -8.0261,  -9.9338,  -9.1586]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 1.1762,  2.5300,  0.0365,  0.7829, -0.0908,  0.8451,  0.9296,  2.5093,
          1.6863]], device='cuda:0') None
best_l after optimization: -10.552764892578125 with beta sum per layer: []
alpha/beta optimization time: 7.720049858093262
initial alpha-CROWN bounds: tensor([[ 1.1982,  2.5535,  0.0534,  0.7909, -0.0817,  0.8533,  0.9426,  2.5367,
          1.7058]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.0817, device='cuda:0', grad_fn=<MinBackward1>)
Sorted order for labels to verify: [4, 2, 3, 5, 7, 0, 9, 8, 1, 6]
##### [0:128] Tested against 4 ######
Model prediction is: tensor([[ -8.4125, -10.1163,  -6.9753,  -7.7043,  -6.8037,  -7.7779,  -6.5721,
          -8.0261,  -9.9338,  -9.1586]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 16, 16]) != torch.Size([2, 9, 1, 16, 16, 16]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 8, 8]) != torch.Size([2, 9, 1, 32, 8, 8]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 16, 16])
1 /11 torch.Size([1, 32, 8, 8])
2 /21 torch.Size([1, 100])
best_l after optimization: 0.08163559436798096 with beta sum per layer: []
alpha/beta optimization time: 2.051816940307617
alpha-CROWN with fixed intermediate bounds: tensor([[-0.0816]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.08163559436798096
layer 0 size torch.Size([4096]) unstable 471
layer 1 size torch.Size([2048]) unstable 206
layer 2 size torch.Size([100]) unstable 4
-----------------
# of unstable neurons: 681
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 16, 16]) pre split depth:  8
batch:  torch.Size([1, 16, 16, 16]) post split depth:  8
splitting decisions: 
split level 0: [2, 50] 
split level 1: [2, 5] 
split level 2: [1, 1437] 
split level 3: [1, 28] 
split level 4: [1, 555] 
split level 5: [1, 1451] 
split level 6: [1, 313] 
split level 7: [1, 1457] 
regular batch size: 2*128, diving batch size 1*0
best_l after optimization: -0.0063711367547512054 with beta sum per layer: [0.0, 41.05299377441406, 0.09064002335071564]
alpha/beta optimization time: 0.28767871856689453
This batch time : update_bounds func: 0.3359	 prepare: 0.0196	 bound: 0.2880	 transfer: 0.0120	 finalize: 0.0156
Accumulated time: update_bounds func: 0.3359	 prepare: 0.0196	 bound: 0.2880	 transfer: 0.0120	 finalize: 0.0156
batch bounding time:  0.33620572090148926
Current worst splitting domains [lb, ub] (depth):
[-0.00925,   inf] (9), [-0.00843,   inf] (9), [-0.00823,   inf] (9), [-0.00799,   inf] (9), [-0.00782,   inf] (9), [-0.00758,   inf] (9), [-0.00755,   inf] (9), [-0.00743,   inf] (9), [-0.00741,   inf] (9), [-0.00717,   inf] (9), [-0.00697,   inf] (9), [-0.00689,   inf] (9), [-0.00668,   inf] (9), [-0.00663,   inf] (9), [-0.00651,   inf] (9), [-0.00617,   inf] (9), [-0.00594,   inf] (9), [-0.00580,   inf] (9), [-0.00558,   inf] (9), [-0.00553,   inf] (9), 
length of domains: 96
Total time: 0.6415	 pickout: 0.0009	 decision: 0.2668	 get_bound: 0.3693	 add_domain: 0.0045
Current lb:-0.009251350536942482
256 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.5467145442962646

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([96, 16, 16, 16]) pre split depth:  2
batch:  torch.Size([96, 16, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [1, 19] [1, 19] [1, 19] [1, 19] [1, 1458] [1, 1458] [1, 1458] [1, 19] [1, 1458] [1, 19] 
split level 1: [1, 1134] [1, 1134] [1, 1628] [1, 1134] [1, 1195] [1, 19] [1, 1195] [1, 1134] [1, 19] [1, 1134] 
regular batch size: 2*192, diving batch size 1*0
best_l after optimization: -0.33298617601394653 with beta sum per layer: [0.0, 46.77873992919922, 0.349843829870224]
alpha/beta optimization time: 0.3289492130279541
This batch time : update_bounds func: 0.4114	 prepare: 0.0371	 bound: 0.3293	 transfer: 0.0202	 finalize: 0.0238
Accumulated time: update_bounds func: 0.7473	 prepare: 0.0567	 bound: 0.6173	 transfer: 0.0202	 finalize: 0.0394
batch bounding time:  0.41190218925476074
Current worst splitting domains [lb, ub] (depth):
[-0.00608,   inf] (12), [-0.00528,   inf] (12), [-0.00526,   inf] (12), [-0.00494,   inf] (12), [-0.00489,   inf] (12), [-0.00449,   inf] (12), [-0.00435,   inf] (12), [-0.00408,   inf] (12), [-0.00406,   inf] (12), [-0.00406,   inf] (12), [-0.00374,   inf] (12), [-0.00372,   inf] (12), [-0.00372,   inf] (12), [-0.00360,   inf] (12), [-0.00356,   inf] (12), [-0.00353,   inf] (12), [-0.00350,   inf] (12), [-0.00332,   inf] (12), [-0.00331,   inf] (12), [-0.00329,   inf] (12), 
length of domains: 116
Total time: 0.5148	 pickout: 0.0153	 decision: 0.0550	 get_bound: 0.4383	 add_domain: 0.0062
Current lb:-0.006079918704926968
640 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.0641889572143555

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([116, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([116, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 52] [1, 52] [1, 52] [1, 52] [1, 52] [1, 52] [1, 52] [1, 52] [1, 52] [1, 52] 
regular batch size: 2*116, diving batch size 1*0
best_l after optimization: -0.054797377437353134 with beta sum per layer: [0.0, 17.112621307373047, 0.1740419715642929]
alpha/beta optimization time: 0.2768075466156006
This batch time : update_bounds func: 0.3223	 prepare: 0.0233	 bound: 0.2771	 transfer: 0.0078	 finalize: 0.0135
Accumulated time: update_bounds func: 1.0696	 prepare: 0.0800	 bound: 0.8944	 transfer: 0.0078	 finalize: 0.0529
batch bounding time:  0.3225586414337158
Current worst splitting domains [lb, ub] (depth):
[-0.00427,   inf] (14), [-0.00395,   inf] (14), [-0.00350,   inf] (14), [-0.00345,   inf] (14), [-0.00316,   inf] (14), [-0.00314,   inf] (14), [-0.00313,   inf] (14), [-0.00311,   inf] (14), [-0.00282,   inf] (14), [-0.00279,   inf] (14), [-0.00272,   inf] (14), [-0.00253,   inf] (14), [-0.00237,   inf] (14), [-0.00235,   inf] (14), [-0.00229,   inf] (14), [-0.00220,   inf] (14), [-0.00218,   inf] (14), [-0.00199,   inf] (14), [-0.00199,   inf] (14), [-0.00196,   inf] (14), 
length of domains: 80
Total time: 0.3990	 pickout: 0.0191	 decision: 0.0526	 get_bound: 0.3229	 add_domain: 0.0044
Current lb:-0.004270385485142469
872 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.465286016464233

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([80, 16, 16, 16]) pre split depth:  2
batch:  torch.Size([80, 16, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [1, 1674] [1, 1674] [1, 1674] [1, 1674] [1, 1674] [1, 1674] [1, 1674] [1, 1674] [1, 1674] [1, 1458] 
split level 1: [1, 1458] [1, 1458] [1, 1458] [1, 1458] [1, 1458] [1, 1458] [1, 1458] [1, 1458] [1, 1458] [1, 1674] 
regular batch size: 2*160, diving batch size 1*0
best_l after optimization: -0.6714545488357544 with beta sum per layer: [0.0, 15.600900650024414, 0.10516449809074402]
alpha/beta optimization time: 0.30841779708862305
This batch time : update_bounds func: 0.3811	 prepare: 0.0455	 bound: 0.3091	 transfer: 0.0065	 finalize: 0.0192
Accumulated time: update_bounds func: 1.4506	 prepare: 0.1255	 bound: 1.2035	 transfer: 0.0065	 finalize: 0.0721
batch bounding time:  0.38146114349365234
Current worst splitting domains [lb, ub] (depth):
[-0.00107,   inf] (17), [-0.00099,   inf] (17), [-0.00095,   inf] (17), [-0.00087,   inf] (17), [-0.00077,   inf] (17), [-0.00070,   inf] (17), [-0.00058,   inf] (17), [-0.00050,   inf] (17), [-0.00034,   inf] (17), [-0.00026,   inf] (17), [-0.00025,   inf] (17), [-0.00021,   inf] (17), [-0.00016,   inf] (17), [-0.00012,   inf] (17), [-0.00012,   inf] (17), [-0.00005,   inf] (17), [-0.00003,   inf] (17), 
length of domains: 17
Total time: 0.4820	 pickout: 0.0146	 decision: 0.0621	 get_bound: 0.4040	 add_domain: 0.0013
Current lb:-0.001072172774001956
1192 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.949702739715576

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([17, 16, 16, 16]) pre split depth:  4
batch:  torch.Size([17, 16, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [1, 148] [1, 148] [1, 148] [1, 148] [1, 148] [1, 148] [1, 148] [1, 148] [1, 148] [1, 148] 
split level 1: [1, 1195] [1, 1195] [1, 1195] [1, 1195] [1, 1628] [1, 1628] [1, 1628] [1, 1628] [1, 1195] [1, 1195] 
split level 2: [1, 1628] [1, 1628] [1, 1628] [1, 1628] [1, 1195] [1, 1195] [1, 1195] [1, 1195] [1, 1628] [1, 1628] 
split level 3: [1, 1443] [1, 1443] [1, 1443] [1, 1443] [1, 1443] [1, 1443] [1, 1443] [1, 1443] [1, 1443] [1, 1443] 
regular batch size: 2*136, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -2.36179780960083 with beta sum per layer: [0.0, 0.6458740234375, 0.0]
alpha/beta optimization time: 0.010613679885864258
This batch time : update_bounds func: 0.0593	 prepare: 0.0265	 bound: 0.0109	 transfer: 0.0054	 finalize: 0.0158
Accumulated time: update_bounds func: 1.5100	 prepare: 0.1520	 bound: 1.2144	 transfer: 0.0054	 finalize: 0.0879
batch bounding time:  0.05957365036010742
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.1311	 pickout: 0.0034	 decision: 0.0342	 get_bound: 0.0935	 add_domain: 0.0001
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 5.08228874206543

Image 128 label 4 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 5.145507097244263
128 1.0000000116860974e-07
##### [0:128] Tested against 2 ######
Initial alpha-CROWN verified for label 2 with bound 0.053399741649627686
Image 128 label 2 verification end, final lower bound 0.053399741649627686, upper bound inf, time: 0.00041961669921875
128 0.053399741649627686
##### [0:128] Tested against 3 ######
Initial alpha-CROWN verified for label 3 with bound 0.7909154891967773
Image 128 label 3 verification end, final lower bound 0.7909154891967773, upper bound inf, time: 0.00039768218994140625
128 0.7909154891967773
##### [0:128] Tested against 5 ######
Initial alpha-CROWN verified for label 5 with bound 0.8533028960227966
Image 128 label 5 verification end, final lower bound 0.8533028960227966, upper bound inf, time: 0.0003879070281982422
128 0.8533028960227966
##### [0:128] Tested against 7 ######
Initial alpha-CROWN verified for label 7 with bound 0.9426201581954956
Image 128 label 7 verification end, final lower bound 0.9426201581954956, upper bound inf, time: 0.0005025863647460938
128 0.9426201581954956
##### [0:128] Tested against 0 ######
Initial alpha-CROWN verified for label 0 with bound 1.1982014179229736
Image 128 label 0 verification end, final lower bound 1.1982014179229736, upper bound inf, time: 0.00038933753967285156
128 1.1982014179229736
##### [0:128] Tested against 9 ######
Initial alpha-CROWN verified for label 9 with bound 1.7057809829711914
Image 128 label 9 verification end, final lower bound 1.7057809829711914, upper bound inf, time: 0.0004031658172607422
128 1.7057809829711914
##### [0:128] Tested against 8 ######
Initial alpha-CROWN verified for label 8 with bound 2.5367071628570557
Image 128 label 8 verification end, final lower bound 2.5367071628570557, upper bound inf, time: 0.00039315223693847656
128 2.5367071628570557
##### [0:128] Tested against 1 ######
Initial alpha-CROWN verified for label 1 with bound 2.553497791290283
Image 128 label 1 verification end, final lower bound 2.553497791290283, upper bound inf, time: 0.0003905296325683594/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:462: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(preprocess_cifar(eps_temp, perturbation=True)).reshape(1,-1,1,1)

128 2.553497791290283
##### [0:128] Tested against 6 ######
groundtruth label, skip!
Result: image 128 verification success (with branch and bound)!
Wall time: 16.12809991836548

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 1): [128]
verification failure idx (total 0): []
final verified acc: 100.0%[1]
verifier is called on 1 examples.
total verified: 1
mean time [cnt:1] (excluding attack success): 14.829001903533936
