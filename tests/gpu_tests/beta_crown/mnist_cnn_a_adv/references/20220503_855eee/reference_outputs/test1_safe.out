Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: mnist_cnn_a_adv.model
  name: mnist_cnn_4layer
data:
  start: 2
  end: 3
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: MNIST_SDP
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.3
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 1024
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 180
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Tue May  3 01:01:49 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(1, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Flatten(start_dim=1, end_dim=-1)
  (5): Linear(in_features=1568, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=10, bias=True)
)
############################
Shape: torch.Size([200, 1, 28, 28]) torch.Size([200]) torch.Size([200])
X range: tensor(1.) tensor(0.) tensor(0.1340)
############################
epsilon after preprocessing: 0.30000001192092896, data_max = tensor([[[[1.]]]]), data_min = tensor([[[[0.]]]])
Task length: 1
saving results to Verified_ret_[mnist_cnn_4layer]_start=2_end=3_iter=20_b=1024_timeout=180_branching=kfsb-max-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 2 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 9, correct label 9, image norm 96.04313659667969, logits tensor([-4.2674, -7.4374, -3.7629, -2.6753,  1.5492, -3.0144, -6.5095, -0.8245,
        -1.0512,  3.9617], device='cuda:0', grad_fn=<SelectBackward>)
##### PGD attack: True label: 9, Tested against: ['all'] ######
pgd prediction: tensor([-5.3246, -6.1902, -3.9761, -3.1825,  2.2820, -2.8912, -3.6656, -1.6136,
        -2.1519,  3.0546], device='cuda:0', grad_fn=<SqueezeBackward1>)
attack margin tensor([8.3792, 9.2448, 7.0308, 6.2371, 0.7726, 5.9458, 6.7202, 4.6682, 5.2065,
           inf], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[-4.2674, -7.4374, -3.7629, -2.6753,  1.5492, -3.0144, -6.5095, -0.8245,
         -1.0512,  3.9617]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-4.1344, -3.3897, -5.1083, -5.2786, -1.5546, -6.7554, -6.6956, -4.9565,
         -4.3554]], device='cuda:0') None
best_l after optimization: 21.560155868530273 with beta sum per layer: []
alpha/beta optimization time: 7.241042375564575
initial alpha-CROWN bounds: tensor([[-1.6269, -0.6050, -2.5599, -2.6627, -0.8631, -3.7282, -3.4868, -3.4833,
         -2.5443]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-3.7282, device='cuda:0', grad_fn=<MinBackward1>)
Sorted order for labels to verify: [4, 7, 8, 5, 3, 6, 2, 0, 1, 9]
##### [0:2] Tested against 4 ######
Model prediction is: tensor([[-4.2674, -7.4374, -3.7629, -2.6753,  1.5492, -3.0144, -6.5095, -0.8245,
         -1.0512,  3.9617]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 16, 14, 14]) != torch.Size([2, 9, 1, 16, 14, 14]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 7, 7]) != torch.Size([2, 9, 1, 32, 7, 7]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 14, 14])
1 /11 torch.Size([1, 32, 7, 7])
2 /14 torch.Size([1, 100])
best_l after optimization: 0.8619893789291382 with beta sum per layer: []
alpha/beta optimization time: 1.698972463607788
alpha-CROWN with fixed intermediate bounds: tensor([[-0.8620]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.8619893789291382
layer 0 size torch.Size([3136]) unstable 1253
layer 1 size torch.Size([1568]) unstable 191
layer 2 size torch.Size([100]) unstable 25
-----------------
# of unstable neurons: 1469
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 14, 14]) pre split depth:  6
batch:  torch.Size([1, 16, 14, 14]) post split depth:  6
splitting decisions: 
split level 0: [2, 47] 
split level 1: [2, 45] 
split level 2: [1, 1046] 
split level 3: [2, 11] 
split level 4: [1, 556] 
split level 5: [1, 655] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: -69.41342163085938 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.24770021438598633
This batch time : update_bounds func: 0.2592	 prepare: 0.0057	 bound: 0.2480	 transfer: 0.0015	 finalize: 0.0038
Accumulated time: update_bounds func: 0.2592	 prepare: 0.0057	 bound: 0.2480	 transfer: 0.0015	 finalize: 0.0038
batch bounding time:  0.2594141960144043
Current worst splitting domains [lb, ub] (depth):
[-0.05880,   inf] (7), [-0.02898,   inf] (7), [-0.00944,   inf] (7), 
length of domains: 3
Total time: 0.3034	 pickout: 0.0008	 decision: 0.0349	 get_bound: 0.2675	 add_domain: 0.0002
Current lb:-0.058802101761102676
64 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.835657835006714

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3, 16, 14, 14]) pre split depth:  5
batch:  torch.Size([3, 16, 14, 14]) post split depth:  5
splitting decisions: 
split level 0: [2, 33] [2, 33] [2, 33] 
split level 1: [1, 648] [1, 606] [1, 648] 
split level 2: [1, 606] [1, 648] [1, 65] 
split level 3: [1, 65] [1, 65] [1, 606] 
split level 4: [1, 647] [1, 647] [1, 647] 
regular batch size: 2*48, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -55.26307678222656 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.008837223052978516
This batch time : update_bounds func: 0.0266	 prepare: 0.0099	 bound: 0.0091	 transfer: 0.0019	 finalize: 0.0054
Accumulated time: update_bounds func: 0.2858	 prepare: 0.0156	 bound: 0.2571	 transfer: 0.0019	 finalize: 0.0092
batch bounding time:  0.026706218719482422
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0706	 pickout: 0.0011	 decision: 0.0308	 get_bound: 0.0387	 add_domain: 0.0001
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 2.9067983627319336

Image 2 label 4 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 2.9639029502868652
2 1.0000000116860974e-07
##### [0:2] Tested against 7 ######
Model prediction is: tensor([[-4.2674, -7.4374, -3.7629, -2.6753,  1.5492, -3.0144, -6.5095, -0.8245,
         -1.0512,  3.9617]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 16, 14, 14]) != torch.Size([2, 9, 1, 16, 14, 14]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 7, 7]) != torch.Size([2, 9, 1, 32, 7, 7]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 14, 14])
1 /11 torch.Size([1, 32, 7, 7])
2 /14 torch.Size([1, 100])
best_l after optimization: 3.481218099594116 with beta sum per layer: []
alpha/beta optimization time: 0.9383926391601562
alpha-CROWN with fixed intermediate bounds: tensor([[-3.4812]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-3.481218099594116
layer 0 size torch.Size([3136]) unstable 1253
layer 1 size torch.Size([1568]) unstable 191
layer 2 size torch.Size([100]) unstable 25
-----------------
# of unstable neurons: 1469
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 14, 14]) pre split depth:  6
batch:  torch.Size([1, 16, 14, 14]) post split depth:  6
splitting decisions: 
split level 0: [2, 78] 
split level 1: [2, 22] 
split level 2: [2, 11] 
split level 3: [2, 67] 
split level 4: [1, 1052] 
split level 5: [2, 38] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: -18.705142974853516 with beta sum per layer: [0.0, 2.7538561820983887, 5.046350955963135]
alpha/beta optimization time: 0.2485196590423584
This batch time : update_bounds func: 0.2681	 prepare: 0.0084	 bound: 0.2489	 transfer: 0.0063	 finalize: 0.0042
Accumulated time: update_bounds func: 0.5539	 prepare: 0.0240	 bound: 0.5060	 transfer: 0.0063	 finalize: 0.0135
batch bounding time:  0.26831936836242676
Current worst splitting domains [lb, ub] (depth):
[-1.17439,   inf] (7), [-1.06676,   inf] (7), [-1.05163,   inf] (7), [-1.04680,   inf] (7), [-0.82959,   inf] (7), [-0.77568,   inf] (7), [-0.72645,   inf] (7), [-0.65903,   inf] (7), [-0.58746,   inf] (7), [-0.57499,   inf] (7), [-0.55395,   inf] (7), [-0.41672,   inf] (7), [-0.40242,   inf] (7), [-0.24931,   inf] (7), [-0.24823,   inf] (7), [-0.24740,   inf] (7), [-0.18691,   inf] (7), [-0.17177,   inf] (7), [-0.05559,   inf] (7), [-0.04089,   inf] (7), 
length of domains: 20
Total time: 0.3219	 pickout: 0.0010	 decision: 0.0402	 get_bound: 0.2796	 add_domain: 0.0010
Current lb:-1.174394965171814
64 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.278045415878296

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([20, 16, 14, 14]) pre split depth:  2
batch:  torch.Size([20, 16, 14, 14]) post split depth:  2
splitting decisions: 
split level 0: [1, 415] [1, 415] [1, 415] [1, 415] [1, 661] [1, 415] [1, 415] [1, 415] [1, 415] [1, 415] 
split level 1: [1, 661] [1, 618] [1, 618] [1, 618] [1, 618] [1, 618] [1, 618] [1, 618] [1, 905] [1, 905] 
regular batch size: 2*40, diving batch size 1*0
best_l after optimization: -22.070383071899414 with beta sum per layer: [0.0, 13.588764190673828, 11.201216697692871]
alpha/beta optimization time: 0.24858784675598145
This batch time : update_bounds func: 0.2652	 prepare: 0.0085	 bound: 0.2489	 transfer: 0.0029	 finalize: 0.0048
Accumulated time: update_bounds func: 0.8191	 prepare: 0.0325	 bound: 0.7549	 transfer: 0.0029	 finalize: 0.0183
batch bounding time:  0.2654249668121338
Current worst splitting domains [lb, ub] (depth):
[-0.64184,   inf] (10), [-0.57620,   inf] (10), [-0.50778,   inf] (10), [-0.47239,   inf] (10), [-0.41077,   inf] (10), [-0.38153,   inf] (10), [-0.34198,   inf] (10), [-0.30334,   inf] (10), [-0.25478,   inf] (10), [-0.19224,   inf] (10), [-0.17001,   inf] (10), [-0.14939,   inf] (10), [-0.10924,   inf] (10), [-0.09440,   inf] (10), [-0.07930,   inf] (10), [-0.00899,   inf] (10), [-0.00468,   inf] (10), [-0.00313,   inf] (10), [-0.00079,   inf] (10), 
length of domains: 19
Total time: 0.3015	 pickout: 0.0037	 decision: 0.0259	 get_bound: 0.2710	 add_domain: 0.0010
Current lb:-0.641836404800415
144 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.5802521705627441

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([19, 16, 14, 14]) pre split depth:  2
batch:  torch.Size([19, 16, 14, 14]) post split depth:  2
splitting decisions: 
split level 0: [1, 618] [1, 661] [1, 1059] [1, 661] [1, 661] [1, 415] [1, 415] [1, 612] [1, 618] [1, 661] 
split level 1: [1, 612] [1, 612] [1, 612] [1, 612] [1, 905] [1, 612] [1, 612] [1, 1059] [1, 612] [1, 1059] 
regular batch size: 2*38, diving batch size 1*0
best_l after optimization: -16.5687255859375 with beta sum per layer: [0.0, 16.015466690063477, 1.9795942306518555]
alpha/beta optimization time: 0.23649334907531738
This batch time : update_bounds func: 0.2518	 prepare: 0.0081	 bound: 0.2368	 transfer: 0.0019	 finalize: 0.0048
Accumulated time: update_bounds func: 1.0709	 prepare: 0.0406	 bound: 0.9917	 transfer: 0.0019	 finalize: 0.0230
batch bounding time:  0.2519519329071045
Current worst splitting domains [lb, ub] (depth):
[-0.38443,   inf] (13), [-0.23420,   inf] (13), [-0.22750,   inf] (13), [-0.18958,   inf] (13), [-0.08710,   inf] (13), [-0.07114,   inf] (13), [-0.06823,   inf] (13), [-0.06503,   inf] (13), [-0.03719,   inf] (13), [-0.03708,   inf] (13), 
length of domains: 10
Total time: 0.2856	 pickout: 0.0034	 decision: 0.0243	 get_bound: 0.2573	 add_domain: 0.0006
Current lb:-0.38443446159362793
220 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.866473913192749

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([10, 16, 14, 14]) pre split depth:  3
batch:  torch.Size([10, 16, 14, 14]) post split depth:  3
splitting decisions: 
split level 0: [2, 47] [2, 47] [2, 47] [2, 47] [2, 47] [2, 47] [2, 47] [1, 73] [2, 47] [2, 47] 
split level 1: [1, 1059] [1, 1059] [1, 905] [1, 661] [1, 1059] [1, 1059] [1, 661] [1, 612] [1, 1059] [1, 905] 
split level 2: [1, 906] [1, 906] [1, 563] [1, 414] [1, 906] [1, 906] [1, 414] [1, 414] [1, 906] [1, 563] 
regular batch size: 2*40, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -34.67109680175781 with beta sum per layer: [0.0, 4.931302547454834, 0.8479934334754944]
alpha/beta optimization time: 0.008612394332885742
This batch time : update_bounds func: 0.0236	 prepare: 0.0085	 bound: 0.0090	 transfer: 0.0016	 finalize: 0.0044
Accumulated time: update_bounds func: 1.0945	 prepare: 0.0490	 bound: 1.0006	 transfer: 0.0016	 finalize: 0.0275
batch bounding time:  0.02372455596923828
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0569	 pickout: 0.0022	 decision: 0.0226	 get_bound: 0.0320	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.9238557815551758

Image 2 label 7 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.977304458618164
2 1.0000000116860974e-07
##### [0:2] Tested against 8 ######
Model prediction is: tensor([[-4.2674, -7.4374, -3.7629, -2.6753,  1.5492, -3.0144, -6.5095, -0.8245,
         -1.0512,  3.9617]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 16, 14, 14]) != torch.Size([2, 9, 1, 16, 14, 14]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 7, 7]) != torch.Size([2, 9, 1, 32, 7, 7]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 14, 14])
1 /11 torch.Size([1, 32, 7, 7])
2 /14 torch.Size([1, 100])
best_l after optimization: 2.5426831245422363 with beta sum per layer: []
alpha/beta optimization time: 0.9105536937713623
alpha-CROWN with fixed intermediate bounds: tensor([[-2.5427]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-2.5426831245422363
layer 0 size torch.Size([3136]) unstable 1253
layer 1 size torch.Size([1568]) unstable 191
layer 2 size torch.Size([100]) unstable 25
-----------------
# of unstable neurons: 1469
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 14, 14]) pre split depth:  6
batch:  torch.Size([1, 16, 14, 14]) post split depth:  6
splitting decisions: 
split level 0: [2, 47] 
split level 1: [2, 83] 
split level 2: [2, 38] 
split level 3: [2, 67] 
split level 4: [2, 22] 
split level 5: [2, 85] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: -36.66361999511719 with beta sum per layer: [0.0, 0.0, 6.592494964599609]
alpha/beta optimization time: 0.23973560333251953
This batch time : update_bounds func: 0.2509	 prepare: 0.0055	 bound: 0.2400	 transfer: 0.0015	 finalize: 0.0037
Accumulated time: update_bounds func: 1.3454	 prepare: 0.0546	 bound: 1.2406	 transfer: 0.0015	 finalize: 0.0312
batch bounding time:  0.25105929374694824
Current worst splitting domains [lb, ub] (depth):
[-1.22843,   inf] (7), [-0.96881,   inf] (7), [-0.53447,   inf] (7), [-0.47105,   inf] (7), [-0.46648,   inf] (7), [-0.34743,   inf] (7), [-0.18811,   inf] (7), [-0.07125,   inf] (7), [-0.01188,   inf] (7), [-0.00459,   inf] (7), 
length of domains: 10
Total time: 0.2940	 pickout: 0.0008	 decision: 0.0338	 get_bound: 0.2590	 add_domain: 0.0005
Current lb:-1.2284327745437622
64 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.2243947982788086

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([10, 16, 14, 14]) pre split depth:  3
batch:  torch.Size([10, 16, 14, 14]) post split depth:  3
splitting decisions: 
split level 0: [1, 430] [1, 430] [2, 41] [1, 415] [1, 430] [1, 430] [2, 41] [1, 430] [2, 41] [1, 430] 
split level 1: [2, 41] [2, 41] [1, 430] [1, 414] [2, 41] [2, 41] [1, 430] [1, 415] [1, 430] [2, 41] 
split level 2: [1, 414] [1, 414] [1, 1207] [1, 905] [1, 410] [1, 1207] [1, 414] [1, 414] [1, 1207] [1, 410] 
regular batch size: 2*40, diving batch size 1*0
best_l after optimization: -26.589588165283203 with beta sum per layer: [0.0, 0.3889932334423065, 21.117490768432617]
alpha/beta optimization time: 0.24251198768615723
This batch time : update_bounds func: 0.2574	 prepare: 0.0080	 bound: 0.2429	 transfer: 0.0017	 finalize: 0.0047
Accumulated time: update_bounds func: 1.6029	 prepare: 0.0625	 bound: 1.4835	 transfer: 0.0017	 finalize: 0.0358
batch bounding time:  0.25763583183288574
Current worst splitting domains [lb, ub] (depth):
[-0.76710,   inf] (11), [-0.67179,   inf] (11), [-0.57589,   inf] (11), [-0.50344,   inf] (11), [-0.44729,   inf] (11), [-0.35234,   inf] (11), [-0.35016,   inf] (11), [-0.27330,   inf] (11), [-0.26724,   inf] (11), [-0.25660,   inf] (11), [-0.19395,   inf] (11), [-0.19330,   inf] (11), [-0.18240,   inf] (11), [-0.03553,   inf] (11), 
length of domains: 14
Total time: 0.2911	 pickout: 0.0020	 decision: 0.0227	 get_bound: 0.2657	 add_domain: 0.0008
Current lb:-0.7670961618423462
144 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.5160377025604248

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([14, 16, 14, 14]) pre split depth:  2
batch:  torch.Size([14, 16, 14, 14]) post split depth:  2
splitting decisions: 
split level 0: [2, 81] [1, 268] [2, 81] [2, 81] [1, 268] [1, 268] [2, 81] [2, 81] [2, 81] [2, 81] 
split level 1: [1, 268] [2, 81] [1, 1198] [1, 1198] [2, 81] [2, 81] [1, 1207] [1, 1207] [2, 79] [1, 1198] 
regular batch size: 2*28, diving batch size 1*0
best_l after optimization: 0.6015068292617798 with beta sum per layer: [0.0, 1.8972327709197998, 4.8389692306518555]
alpha/beta optimization time: 0.23505687713623047
This batch time : update_bounds func: 0.2469	 prepare: 0.0069	 bound: 0.2354	 transfer: 0.0012	 finalize: 0.0033
Accumulated time: update_bounds func: 1.8497	 prepare: 0.0695	 bound: 1.7189	 transfer: 0.0012	 finalize: 0.0391
batch bounding time:  0.24703621864318848
Current worst splitting domains [lb, ub] (depth):
[-0.53168,   inf] (14), [-0.43979,   inf] (14), [-0.40258,   inf] (14), [-0.36033,   inf] (14), [-0.34751,   inf] (14), [-0.31990,   inf] (14), [-0.24910,   inf] (14), [-0.21574,   inf] (14), [-0.21289,   inf] (14), [-0.19842,   inf] (14), [-0.19462,   inf] (14), [-0.16944,   inf] (14), [-0.16721,   inf] (14), [-0.11450,   inf] (14), [-0.11095,   inf] (14), [-0.10296,   inf] (14), [-0.09544,   inf] (14), [-0.06121,   inf] (14), [-0.05851,   inf] (14), [-0.03536,   inf] (14), 
length of domains: 23
Total time: 0.2787	 pickout: 0.0027	 decision: 0.0232	 get_bound: 0.2512	 add_domain: 0.0016
Current lb:-0.5316824316978455
200 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.7951157093048096

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([23, 16, 14, 14]) pre split depth:  2
batch:  torch.Size([23, 16, 14, 14]) post split depth:  2
splitting decisions: 
split level 0: [1, 415] [1, 415] [1, 1198] [1, 1198] [1, 415] [1, 415] [1, 415] [1, 415] [1, 1198] [1, 415] 
split level 1: [1, 1198] [1, 1198] [2, 79] [2, 79] [1, 1198] [1, 1207] [2, 79] [1, 1198] [2, 79] [1, 1207] 
regular batch size: 2*46, diving batch size 1*0
best_l after optimization: -8.986844062805176 with beta sum per layer: [0.0, 7.720691680908203, 9.181506156921387]
alpha/beta optimization time: 0.2358086109161377
This batch time : update_bounds func: 0.2530	 prepare: 0.0098	 bound: 0.2361	 transfer: 0.0016	 finalize: 0.0053
Accumulated time: update_bounds func: 2.1027	 prepare: 0.0793	 bound: 1.9550	 transfer: 0.0016	 finalize: 0.0444
batch bounding time:  0.2531912326812744
Current worst splitting domains [lb, ub] (depth):
[-0.38144,   inf] (17), [-0.32849,   inf] (17), [-0.22420,   inf] (17), [-0.19911,   inf] (17), [-0.18816,   inf] (17), [-0.13774,   inf] (17), [-0.10819,   inf] (17), [-0.08266,   inf] (17), [-0.07378,   inf] (17), [-0.07180,   inf] (17), [-0.06626,   inf] (17), [-0.05903,   inf] (17), [-0.04106,   inf] (17), [-0.03899,   inf] (17), [-0.03084,   inf] (17), [-0.02871,   inf] (17), [-0.01166,   inf] (17), 
length of domains: 17
Total time: 0.2901	 pickout: 0.0039	 decision: 0.0254	 get_bound: 0.2598	 add_domain: 0.0011
Current lb:-0.3814402222633362
292 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.0859344005584717

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([17, 16, 14, 14]) pre split depth:  2
batch:  torch.Size([17, 16, 14, 14]) post split depth:  2
splitting decisions: 
split level 0: [2, 79] [2, 79] [1, 415] [1, 415] [2, 79] [2, 79] [1, 415] [2, 79] [2, 79] [1, 415] 
split level 1: [1, 1207] [1, 1207] [1, 618] [1, 618] [1, 1207] [1, 1207] [1, 618] [1, 1207] [1, 1207] [1, 1207] 
regular batch size: 2*34, diving batch size 1*0
best_l after optimization: -8.761631965637207 with beta sum per layer: [0.0, 5.2063093185424805, 5.631756782531738]
alpha/beta optimization time: 0.24317097663879395
This batch time : update_bounds func: 0.2565	 prepare: 0.0075	 bound: 0.2435	 transfer: 0.0013	 finalize: 0.0040
Accumulated time: update_bounds func: 2.3593	 prepare: 0.0868	 bound: 2.1985	 transfer: 0.0013	 finalize: 0.0484
batch bounding time:  0.2567262649536133
Current worst splitting domains [lb, ub] (depth):
[-0.18650,   inf] (20), [-0.13439,   inf] (20), [-0.10804,   inf] (20), [-0.10755,   inf] (20), [-0.10114,   inf] (20), [-0.09149,   inf] (20), [-0.04922,   inf] (20), [-0.04524,   inf] (20), 
length of domains: 8
Total time: 0.2891	 pickout: 0.0030	 decision: 0.0236	 get_bound: 0.2618	 add_domain: 0.0006
Current lb:-0.18649625778198242
360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.3757028579711914

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 14, 14]) pre split depth:  3
batch:  torch.Size([8, 16, 14, 14]) post split depth:  3
splitting decisions: 
split level 0: [1, 1059] [1, 1059] [1, 277] [1, 914] [1, 1059] [1, 914] [1, 1059] [1, 277] 
split level 1: [1, 277] [1, 277] [1, 905] [1, 1207] [1, 725] [1, 1207] [1, 725] [1, 725] 
split level 2: [1, 725] [1, 725] [1, 725] [1, 277] [1, 277] [1, 277] [1, 277] [1, 905] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: -11.687005996704102 with beta sum per layer: [0.0, 0.0, 2.517443895339966]
alpha/beta optimization time: 0.2471790313720703
This batch time : update_bounds func: 0.2596	 prepare: 0.0070	 bound: 0.2475	 transfer: 0.0013	 finalize: 0.0037
Accumulated time: update_bounds func: 2.6189	 prepare: 0.0938	 bound: 2.4459	 transfer: 0.0013	 finalize: 0.0521
batch bounding time:  0.2598118782043457
Current worst splitting domains [lb, ub] (depth):
[-0.00902,   inf] (24), 
length of domains: 1
Total time: 0.2899	 pickout: 0.0018	 decision: 0.0211	 get_bound: 0.2668	 add_domain: 0.0002
Current lb:-0.009024489670991898
424 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.666121244430542

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 14, 14]) pre split depth:  6
batch:  torch.Size([1, 16, 14, 14]) post split depth:  6
splitting decisions: 
split level 0: [1, 914] 
split level 1: [1, 618] 
split level 2: [1, 711] 
split level 3: [1, 905] 
split level 4: [1, 715] 
split level 5: [1, 410] 
regular batch size: 2*32, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -31.3182315826416 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.008642196655273438
This batch time : update_bounds func: 0.0209	 prepare: 0.0070	 bound: 0.0089	 transfer: 0.0012	 finalize: 0.0036
Accumulated time: update_bounds func: 2.6399	 prepare: 0.1008	 bound: 2.4548	 transfer: 0.0012	 finalize: 0.0557
batch bounding time:  0.0210268497467041
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0653	 pickout: 0.0008	 decision: 0.0341	 get_bound: 0.0304	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 2.7317628860473633

Image 2 label 8 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 2.7859854698181152
2 1.0000000116860974e-07
##### [0:2] Tested against 5 ######
Model prediction is: tensor([[-4.2674, -7.4374, -3.7629, -2.6753,  1.5492, -3.0144, -6.5095, -0.8245,
         -1.0512,  3.9617]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 16, 14, 14]) != torch.Size([2, 9, 1, 16, 14, 14]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 7, 7]) != torch.Size([2, 9, 1, 32, 7, 7]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 14, 14])
1 /11 torch.Size([1, 32, 7, 7])
2 /14 torch.Size([1, 100])
best_l after optimization: 3.7252883911132812 with beta sum per layer: []
alpha/beta optimization time: 0.9397799968719482
alpha-CROWN with fixed intermediate bounds: tensor([[-3.7253]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-3.7252883911132812
layer 0 size torch.Size([3136]) unstable 1253
layer 1 size torch.Size([1568]) unstable 191
layer 2 size torch.Size([100]) unstable 25
-----------------
# of unstable neurons: 1469
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 14, 14]) pre split depth:  6
batch:  torch.Size([1, 16, 14, 14]) post split depth:  6
splitting decisions: 
split level 0: [2, 38] 
split level 1: [2, 83] 
split level 2: [2, 79] 
split level 3: [1, 1194] 
split level 4: [2, 81] 
split level 5: [2, 41] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: 11.927814483642578 with beta sum per layer: [0.0, 0.15244729816913605, 17.98443603515625]
alpha/beta optimization time: 0.24714303016662598
This batch time : update_bounds func: 0.2585	 prepare: 0.0057	 bound: 0.2474	 transfer: 0.0015	 finalize: 0.0037
Accumulated time: update_bounds func: 2.8983	 prepare: 0.1065	 bound: 2.7022	 transfer: 0.0015	 finalize: 0.0594
batch bounding time:  0.25864624977111816
Current worst splitting domains [lb, ub] (depth):
[-1.93508,   inf] (7), [-1.78316,   inf] (7), [-1.69299,   inf] (7), [-1.65375,   inf] (7), [-1.56065,   inf] (7), [-1.55756,   inf] (7), [-1.42423,   inf] (7), [-1.32020,   inf] (7), [-1.15387,   inf] (7), [-1.04133,   inf] (7), [-1.00482,   inf] (7), [-0.98596,   inf] (7), [-0.87974,   inf] (7), [-0.85943,   inf] (7), [-0.80471,   inf] (7), [-0.71889,   inf] (7), [-0.66437,   inf] (7), [-0.65822,   inf] (7), [-0.64939,   inf] (7), [-0.57812,   inf] (7), 
length of domains: 28
Total time: 0.3019	 pickout: 0.0007	 decision: 0.0335	 get_bound: 0.2665	 add_domain: 0.0012
Current lb:-1.9350804090499878
64 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.257652759552002

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([28, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([28, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [2, 85] [1, 430] [2, 85] [2, 85] [2, 85] [1, 410] [2, 85] [2, 85] [1, 430] [2, 85] 
regular batch size: 2*28, diving batch size 1*0
best_l after optimization: 24.991540908813477 with beta sum per layer: [0.0, 1.0993037223815918, 13.976067543029785]
alpha/beta optimization time: 0.24484491348266602
This batch time : update_bounds func: 0.2566	 prepare: 0.0066	 bound: 0.2451	 transfer: 0.0014	 finalize: 0.0034
Accumulated time: update_bounds func: 3.1549	 prepare: 0.1131	 bound: 2.9474	 transfer: 0.0014	 finalize: 0.0628
batch bounding time:  0.2567770481109619
Current worst splitting domains [lb, ub] (depth):
[-1.64586,   inf] (9), [-1.61762,   inf] (9), [-1.43065,   inf] (9), [-1.35889,   inf] (9), [-1.29420,   inf] (9), [-1.28183,   inf] (9), [-1.22960,   inf] (9), [-1.15818,   inf] (9), [-1.14875,   inf] (9), [-1.09123,   inf] (9), [-1.06160,   inf] (9), [-1.02987,   inf] (9), [-1.01327,   inf] (9), [-0.91660,   inf] (9), [-0.89942,   inf] (9), [-0.82160,   inf] (9), [-0.77424,   inf] (9), [-0.75442,   inf] (9), [-0.74193,   inf] (9), [-0.73806,   inf] (9), 
length of domains: 40
Total time: 0.2887	 pickout: 0.0045	 decision: 0.0255	 get_bound: 0.2569	 add_domain: 0.0018
Current lb:-1.6458568572998047
120 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.546881914138794

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([40, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([40, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 430] [2, 85] [1, 430] [2, 67] [1, 430] [1, 410] [2, 85] [1, 410] [1, 430] [1, 430] 
regular batch size: 2*40, diving batch size 1*0
best_l after optimization: 22.185871124267578 with beta sum per layer: [0.0, 2.8382492065429688, 25.188480377197266]
alpha/beta optimization time: 0.25592613220214844
This batch time : update_bounds func: 0.2715	 prepare: 0.0089	 bound: 0.2562	 transfer: 0.0015	 finalize: 0.0047
Accumulated time: update_bounds func: 3.4264	 prepare: 0.1220	 bound: 3.2036	 transfer: 0.0015	 finalize: 0.0675
batch bounding time:  0.2716968059539795
Current worst splitting domains [lb, ub] (depth):
[-1.52194,   inf] (11), [-1.33193,   inf] (11), [-1.29993,   inf] (11), [-1.23977,   inf] (11), [-1.14129,   inf] (11), [-1.04236,   inf] (11), [-0.97323,   inf] (11), [-0.96819,   inf] (11), [-0.93809,   inf] (11), [-0.91040,   inf] (11), [-0.90603,   inf] (11), [-0.89799,   inf] (11), [-0.80252,   inf] (11), [-0.77794,   inf] (11), [-0.76113,   inf] (11), [-0.75737,   inf] (11), [-0.70350,   inf] (11), [-0.67684,   inf] (11), [-0.63613,   inf] (11), [-0.63434,   inf] (11), 
length of domains: 51
Total time: 0.3190	 pickout: 0.0061	 decision: 0.0386	 get_bound: 0.2718	 add_domain: 0.0025
Current lb:-1.5219374895095825
200 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.866776466369629

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([51, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([51, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 410] [2, 67] [1, 410] [1, 430] [1, 410] [1, 410] [2, 67] [1, 410] [2, 67] [1, 410] 
regular batch size: 2*51, diving batch size 1*0
best_l after optimization: 14.861324310302734 with beta sum per layer: [0.0, 4.668631553649902, 32.07130432128906]
alpha/beta optimization time: 0.25045084953308105
This batch time : update_bounds func: 0.2707	 prepare: 0.0107	 bound: 0.2507	 transfer: 0.0028	 finalize: 0.0063
Accumulated time: update_bounds func: 3.6971	 prepare: 0.1327	 bound: 3.4544	 transfer: 0.0028	 finalize: 0.0737
batch bounding time:  0.270857572555542
Current worst splitting domains [lb, ub] (depth):
[-1.14082,   inf] (13), [-1.13835,   inf] (13), [-1.12694,   inf] (13), [-1.09365,   inf] (13), [-0.89293,   inf] (13), [-0.83540,   inf] (13), [-0.80358,   inf] (13), [-0.79262,   inf] (13), [-0.73403,   inf] (13), [-0.73330,   inf] (13), [-0.73288,   inf] (13), [-0.72371,   inf] (13), [-0.68618,   inf] (13), [-0.66571,   inf] (13), [-0.64009,   inf] (13), [-0.61990,   inf] (13), [-0.59366,   inf] (13), [-0.58880,   inf] (13), [-0.56866,   inf] (13), [-0.56224,   inf] (13), 
length of domains: 51
Total time: 0.3130	 pickout: 0.0077	 decision: 0.0319	 get_bound: 0.2710	 add_domain: 0.0025
Current lb:-1.1408190727233887
302 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.180621385574341

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([51, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([51, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [2, 47] [1, 410] [2, 67] [2, 67] [2, 67] [2, 67] [2, 47] [2, 85] [2, 85] [2, 47] 
regular batch size: 2*51, diving batch size 1*0
best_l after optimization: 3.9754695892333984 with beta sum per layer: [0.0, 3.913533926010132, 28.245548248291016]
alpha/beta optimization time: 0.2504746913909912
This batch time : update_bounds func: 0.2713	 prepare: 0.0106	 bound: 0.2508	 transfer: 0.0038	 finalize: 0.0059
Accumulated time: update_bounds func: 3.9684	 prepare: 0.1432	 bound: 3.7051	 transfer: 0.0038	 finalize: 0.0796
batch bounding time:  0.2714982032775879
Current worst splitting domains [lb, ub] (depth):
[-1.01777,   inf] (15), [-0.93688,   inf] (15), [-0.91252,   inf] (15), [-0.75119,   inf] (15), [-0.70987,   inf] (15), [-0.66336,   inf] (15), [-0.65193,   inf] (15), [-0.64308,   inf] (15), [-0.59416,   inf] (15), [-0.51550,   inf] (15), [-0.51156,   inf] (15), [-0.50133,   inf] (15), [-0.49804,   inf] (15), [-0.47232,   inf] (15), [-0.46537,   inf] (15), [-0.43013,   inf] (15), [-0.40056,   inf] (15), [-0.39651,   inf] (15), [-0.38246,   inf] (15), [-0.35975,   inf] (15), 
length of domains: 47
Total time: 0.3159	 pickout: 0.0077	 decision: 0.0340	 get_bound: 0.2717	 add_domain: 0.0025
Current lb:-1.0177655220031738
404 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.497549533843994

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([47, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([47, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [2, 45] [2, 47] [2, 47] [2, 47] [2, 47] [2, 45] [2, 47] [2, 47] [2, 45] [1, 430] 
regular batch size: 2*47, diving batch size 1*0
best_l after optimization: -3.5542683601379395 with beta sum per layer: [0.0, 2.774806022644043, 23.427696228027344]
alpha/beta optimization time: 0.2577073574066162
This batch time : update_bounds func: 0.2771	 prepare: 0.0114	 bound: 0.2580	 transfer: 0.0019	 finalize: 0.0056
Accumulated time: update_bounds func: 4.2456	 prepare: 0.1546	 bound: 3.9631	 transfer: 0.0019	 finalize: 0.0852
batch bounding time:  0.2773396968841553
Current worst splitting domains [lb, ub] (depth):
[-0.91718,   inf] (17), [-0.79184,   inf] (17), [-0.76852,   inf] (17), [-0.60689,   inf] (17), [-0.57031,   inf] (17), [-0.55387,   inf] (17), [-0.50420,   inf] (17), [-0.49545,   inf] (17), [-0.48631,   inf] (17), [-0.41256,   inf] (17), [-0.38795,   inf] (17), [-0.36076,   inf] (17), [-0.35653,   inf] (17), [-0.34489,   inf] (17), [-0.32840,   inf] (17), [-0.31096,   inf] (17), [-0.23216,   inf] (17), [-0.23213,   inf] (17), [-0.18395,   inf] (17), [-0.17994,   inf] (17), 
length of domains: 40
Total time: 0.3245	 pickout: 0.0072	 decision: 0.0376	 get_bound: 0.2775	 add_domain: 0.0022
Current lb:-0.9171805381774902
498 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.82300066947937

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([40, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([40, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 410] [2, 45] [2, 45] [2, 45] [2, 45] [1, 410] [2, 45] [2, 45] [1, 410] [2, 45] 
regular batch size: 2*40, diving batch size 1*0
best_l after optimization: -14.332579612731934 with beta sum per layer: [0.0, 2.3539493083953857, 14.491386413574219]
alpha/beta optimization time: 0.2424783706665039
This batch time : update_bounds func: 0.2595	 prepare: 0.0087	 bound: 0.2428	 transfer: 0.0017	 finalize: 0.0061
Accumulated time: update_bounds func: 4.5051	 prepare: 0.1633	 bound: 4.2059	 transfer: 0.0017	 finalize: 0.0913
batch bounding time:  0.259718656539917
Current worst splitting domains [lb, ub] (depth):
[-0.67357,   inf] (19), [-0.64795,   inf] (19), [-0.55738,   inf] (19), [-0.53226,   inf] (19), [-0.47184,   inf] (19), [-0.46231,   inf] (19), [-0.37129,   inf] (19), [-0.37026,   inf] (19), [-0.31793,   inf] (19), [-0.28641,   inf] (19), [-0.24986,   inf] (19), [-0.22934,   inf] (19), [-0.21836,   inf] (19), [-0.21086,   inf] (19), [-0.20432,   inf] (19), [-0.16461,   inf] (19), [-0.14809,   inf] (19), [-0.14048,   inf] (19), [-0.13251,   inf] (19), [-0.12065,   inf] (19), 
length of domains: 31
Total time: 0.2982	 pickout: 0.0063	 decision: 0.0303	 get_bound: 0.2599	 add_domain: 0.0018
Current lb:-0.673573911190033
578 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.1220548152923584

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([31, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([31, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [2, 78] [2, 78] [2, 78] [2, 78] [2, 78] [2, 78] [2, 78] [2, 78] [2, 78] [2, 78] 
regular batch size: 2*31, diving batch size 1*0
best_l after optimization: -0.9469244480133057 with beta sum per layer: [0.0, 1.6437208652496338, 9.078361511230469]
alpha/beta optimization time: 0.24495959281921387
This batch time : update_bounds func: 0.2582	 prepare: 0.0070	 bound: 0.2452	 transfer: 0.0014	 finalize: 0.0043
Accumulated time: update_bounds func: 4.7632	 prepare: 0.1703	 bound: 4.4512	 transfer: 0.0014	 finalize: 0.0956
batch bounding time:  0.2583327293395996
Current worst splitting domains [lb, ub] (depth):
[-0.44317,   inf] (21), [-0.42186,   inf] (21), [-0.40182,   inf] (21), [-0.37548,   inf] (21), [-0.33446,   inf] (21), [-0.32749,   inf] (21), [-0.26046,   inf] (21), [-0.24294,   inf] (21), [-0.23394,   inf] (21), [-0.23161,   inf] (21), [-0.19180,   inf] (21), [-0.16704,   inf] (21), [-0.14207,   inf] (21), [-0.13628,   inf] (21), [-0.12653,   inf] (21), [-0.10592,   inf] (21), [-0.10218,   inf] (21), [-0.06963,   inf] (21), [-0.03429,   inf] (21), [-0.01850,   inf] (21), 
length of domains: 22
Total time: 0.2907	 pickout: 0.0050	 decision: 0.0258	 get_bound: 0.2584	 add_domain: 0.0014
Current lb:-0.4431729018688202
640 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.4134762287139893

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([22, 16, 14, 14]) pre split depth:  2
batch:  torch.Size([22, 16, 14, 14]) post split depth:  2
splitting decisions: 
split level 0: [1, 414] [1, 414] [1, 414] [1, 414] [1, 263] [1, 263] [1, 263] [1, 263] [1, 414] [1, 414] 
split level 1: [1, 263] [1, 263] [1, 263] [1, 263] [1, 414] [1, 414] [1, 414] [1, 414] [1, 263] [1, 263] 
regular batch size: 2*44, diving batch size 1*0
best_l after optimization: -11.556303024291992 with beta sum per layer: [0.0, 0.746898889541626, 6.314218521118164]
alpha/beta optimization time: 0.24579715728759766
This batch time : update_bounds func: 0.2641	 prepare: 0.0092	 bound: 0.2462	 transfer: 0.0033	 finalize: 0.0052
Accumulated time: update_bounds func: 5.0273	 prepare: 0.1795	 bound: 4.6973	 transfer: 0.0033	 finalize: 0.1008
batch bounding time:  0.26425766944885254
Current worst splitting domains [lb, ub] (depth):
[-0.10858,   inf] (24), [-0.10685,   inf] (24), [-0.09575,   inf] (24), [-0.08702,   inf] (24), [-0.08237,   inf] (24), [-0.07394,   inf] (24), [-0.06578,   inf] (24), [-0.05902,   inf] (24), [-0.05666,   inf] (24), [-0.05436,   inf] (24), [-0.04846,   inf] (24), [-0.02369,   inf] (24), [-0.00801,   inf] (24), 
length of domains: 13
Total time: 0.3015	 pickout: 0.0038	 decision: 0.0260	 get_bound: 0.2708	 add_domain: 0.0009
Current lb:-0.10858123749494553
728 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.715771436691284

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([13, 16, 14, 14]) pre split depth:  2
batch:  torch.Size([13, 16, 14, 14]) post split depth:  2
splitting decisions: 
split level 0: [1, 1195] [1, 1195] [1, 1195] [1, 1195] [1, 1195] [1, 1195] [1, 1195] [1, 1195] [1, 1195] [1, 1195] 
split level 1: [1, 269] [1, 269] [1, 269] [1, 269] [1, 269] [1, 269] [1, 269] [1, 269] [1, 269] [1, 269] 
regular batch size: 2*26, diving batch size 1*0
best_l after optimization: -17.076169967651367 with beta sum per layer: [0.0, 0.1369016319513321, 0.04858536645770073]
alpha/beta optimization time: 0.24312973022460938
This batch time : update_bounds func: 0.2547	 prepare: 0.0060	 bound: 0.2434	 transfer: 0.0020	 finalize: 0.0031
Accumulated time: update_bounds func: 5.2820	 prepare: 0.1856	 bound: 4.9408	 transfer: 0.0020	 finalize: 0.1039
batch bounding time:  0.2549304962158203
Current worst splitting domains [lb, ub] (depth):
[-0.01913,   inf] (27), [-0.01472,   inf] (27), [-0.00361,   inf] (27), 
length of domains: 3
Total time: 0.2844	 pickout: 0.0025	 decision: 0.0225	 get_bound: 0.2590	 add_domain: 0.0004
Current lb:-0.019125549122691154
780 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.000723123550415

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3, 16, 14, 14]) pre split depth:  5
batch:  torch.Size([3, 16, 14, 14]) post split depth:  5
splitting decisions: 
split level 0: [2, 22] [2, 22] [2, 22] 
split level 1: [1, 416] [1, 416] [1, 416] 
split level 2: [1, 711] [1, 711] [1, 1207] 
split level 3: [1, 1207] [1, 1207] [1, 711] 
split level 4: [1, 725] [1, 725] [1, 725] 
regular batch size: 2*48, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -68.76052856445312 with beta sum per layer: [0.0, 0.0, 0.5800338983535767]
alpha/beta optimization time: 0.008818626403808594
This batch time : update_bounds func: 0.0275	 prepare: 0.0105	 bound: 0.0091	 transfer: 0.0022	 finalize: 0.0053
Accumulated time: update_bounds func: 5.3094	 prepare: 0.1961	 bound: 4.9499	 transfer: 0.0022	 finalize: 0.1092
batch bounding time:  0.02756476402282715
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0731	 pickout: 0.0011	 decision: 0.0310	 get_bound: 0.0409	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 4.0743231773376465

Image 2 label 5 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 4.127723932266235
2 1.0000000116860974e-07
##### [0:2] Tested against 3 ######
Model prediction is: tensor([[-4.2674, -7.4374, -3.7629, -2.6753,  1.5492, -3.0144, -6.5095, -0.8245,
         -1.0512,  3.9617]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 16, 14, 14]) != torch.Size([2, 9, 1, 16, 14, 14]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 7, 7]) != torch.Size([2, 9, 1, 32, 7, 7]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 14, 14])
1 /11 torch.Size([1, 32, 7, 7])
2 /14 torch.Size([1, 100])
best_l after optimization: 2.6607167720794678 with beta sum per layer: []
alpha/beta optimization time: 0.90244460105896
alpha-CROWN with fixed intermediate bounds: tensor([[-2.6607]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-2.660717010498047
layer 0 size torch.Size([3136]) unstable 1253
layer 1 size torch.Size([1568]) unstable 191
layer 2 size torch.Size([100]) unstable 25
-----------------
# of unstable neurons: 1469
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 14, 14]) pre split depth:  6
batch:  torch.Size([1, 16, 14, 14]) post split depth:  6
splitting decisions: 
split level 0: [2, 83] 
split level 1: [2, 22] 
split level 2: [2, 67] 
split level 3: [2, 38] 
split level 4: [2, 78] 
split level 5: [2, 41] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: -25.854938507080078 with beta sum per layer: [0.0, 0.0, 7.41126823425293]
alpha/beta optimization time: 0.23358845710754395
This batch time : update_bounds func: 0.2446	 prepare: 0.0055	 bound: 0.2339	 transfer: 0.0014	 finalize: 0.0037
Accumulated time: update_bounds func: 5.5540	 prepare: 0.2016	 bound: 5.1837	 transfer: 0.0014	 finalize: 0.1129
batch bounding time:  0.24471759796142578
Current worst splitting domains [lb, ub] (depth):
[-1.04038,   inf] (7), [-0.87142,   inf] (7), [-0.82607,   inf] (7), [-0.64021,   inf] (7), [-0.42570,   inf] (7), [-0.37307,   inf] (7), [-0.30669,   inf] (7), [-0.23488,   inf] (7), [-0.16935,   inf] (7), [-0.10244,   inf] (7), [-0.10162,   inf] (7), [-0.01237,   inf] (7), 
length of domains: 12
Total time: 0.2873	 pickout: 0.0008	 decision: 0.0334	 get_bound: 0.2525	 add_domain: 0.0006
Current lb:-1.0403820276260376
64 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.2060227394104004

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([12, 16, 14, 14]) pre split depth:  3
batch:  torch.Size([12, 16, 14, 14]) post split depth:  3
splitting decisions: 
split level 0: [1, 430] [1, 414] [1, 430] [2, 85] [2, 85] [1, 905] [2, 79] [1, 905] [2, 85] [1, 415] 
split level 1: [2, 85] [2, 79] [2, 85] [2, 79] [2, 79] [2, 79] [1, 414] [1, 415] [2, 79] [1, 905] 
split level 2: [2, 79] [2, 85] [2, 79] [1, 414] [1, 1207] [1, 414] [1, 905] [1, 414] [1, 1207] [1, 414] 
regular batch size: 2*48, diving batch size 1*0
best_l after optimization: -56.42447280883789 with beta sum per layer: [0.0, 0.2784317433834076, 27.43037223815918]
alpha/beta optimization time: 0.23722481727600098
This batch time : update_bounds func: 0.2552	 prepare: 0.0093	 bound: 0.2375	 transfer: 0.0023	 finalize: 0.0057
Accumulated time: update_bounds func: 5.8092	 prepare: 0.2109	 bound: 5.4212	 transfer: 0.0023	 finalize: 0.1187
batch bounding time:  0.2554631233215332
Current worst splitting domains [lb, ub] (depth):
[-0.45889,   inf] (11), [-0.25052,   inf] (11), [-0.23681,   inf] (11), [-0.20888,   inf] (11), [-0.13773,   inf] (11), [-0.10687,   inf] (11), [-0.05782,   inf] (11), [-0.03793,   inf] (11), [-0.03284,   inf] (11), 
length of domains: 9
Total time: 0.2904	 pickout: 0.0023	 decision: 0.0227	 get_bound: 0.2648	 add_domain: 0.0006
Current lb:-0.45888984203338623
160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.4970686435699463

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([9, 16, 14, 14]) pre split depth:  3
batch:  torch.Size([9, 16, 14, 14]) post split depth:  3
splitting decisions: 
split level 0: [2, 45] [2, 45] [2, 45] [2, 45] [2, 45] [2, 45] [2, 45] [2, 45] [2, 45] 
split level 1: [1, 414] [1, 414] [1, 414] [1, 414] [1, 414] [1, 430] [1, 414] [1, 414] [1, 430] 
split level 2: [1, 1207] [1, 1207] [1, 1207] [1, 1207] [1, 1207] [1, 905] [1, 1207] [1, 1207] [1, 905] 
regular batch size: 2*36, diving batch size 1*0
best_l after optimization: -59.4019775390625 with beta sum per layer: [0.0, 1.049365758895874, 5.132022857666016]
alpha/beta optimization time: 0.24569392204284668
This batch time : update_bounds func: 0.2599	 prepare: 0.0078	 bound: 0.2460	 transfer: 0.0016	 finalize: 0.0043
Accumulated time: update_bounds func: 6.0692	 prepare: 0.2187	 bound: 5.6672	 transfer: 0.0016	 finalize: 0.1230
batch bounding time:  0.26012492179870605
Current worst splitting domains [lb, ub] (depth):
[-0.00663,   inf] (15), 
length of domains: 1
Total time: 0.2928	 pickout: 0.0021	 decision: 0.0229	 get_bound: 0.2677	 add_domain: 0.0001
Current lb:-0.006626298651099205
232 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.7903504371643066

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 14, 14]) pre split depth:  6
batch:  torch.Size([1, 16, 14, 14]) post split depth:  6
splitting decisions: 
split level 0: [2, 5] 
split level 1: [2, 75] 
split level 2: [1, 905] 
split level 3: [1, 1198] 
split level 4: [1, 708] 
split level 5: [1, 612] 
regular batch size: 2*32, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -82.21959686279297 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.008786678314208984
This batch time : update_bounds func: 0.0213	 prepare: 0.0071	 bound: 0.0090	 transfer: 0.0015	 finalize: 0.0036
Accumulated time: update_bounds func: 6.0905	 prepare: 0.2258	 bound: 5.6763	 transfer: 0.0015	 finalize: 0.1265
batch bounding time:  0.02143383026123047
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0657	 pickout: 0.0008	 decision: 0.0344	 get_bound: 0.0304	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.856384038925171

Image 2 label 3 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.9105510711669922
2 1.0000000116860974e-07
##### [0:2] Tested against 6 ######
Model prediction is: tensor([[-4.2674, -7.4374, -3.7629, -2.6753,  1.5492, -3.0144, -6.5095, -0.8245,
         -1.0512,  3.9617]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 16, 14, 14]) != torch.Size([2, 9, 1, 16, 14, 14]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 7, 7]) != torch.Size([2, 9, 1, 32, 7, 7]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 14, 14])
1 /11 torch.Size([1, 32, 7, 7])
2 /14 torch.Size([1, 100])
best_l after optimization: 3.4822120666503906 with beta sum per layer: []
alpha/beta optimization time: 0.8930070400238037
alpha-CROWN with fixed intermediate bounds: tensor([[-3.4822]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-3.4822120666503906
layer 0 size torch.Size([3136]) unstable 1253
layer 1 size torch.Size([1568]) unstable 191
layer 2 size torch.Size([100]) unstable 25
-----------------
# of unstable neurons: 1469
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 14, 14]) pre split depth:  6
batch:  torch.Size([1, 16, 14, 14]) post split depth:  6
splitting decisions: 
split level 0: [2, 47] 
split level 1: [2, 79] 
split level 2: [2, 67] 
split level 3: [2, 41] 
split level 4: [2, 38] 
split level 5: [1, 410] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: -42.9642333984375 with beta sum per layer: [0.0, 0.662087082862854, 3.8962948322296143]
alpha/beta optimization time: 0.24679827690124512
This batch time : update_bounds func: 0.2578	 prepare: 0.0055	 bound: 0.2471	 transfer: 0.0013	 finalize: 0.0037
Accumulated time: update_bounds func: 6.3483	 prepare: 0.2314	 bound: 5.9233	 transfer: 0.0013	 finalize: 0.1302
batch bounding time:  0.2580068111419678
Current worst splitting domains [lb, ub] (depth):
[-0.90407,   inf] (7), [-0.84944,   inf] (7), [-0.71598,   inf] (7), [-0.62159,   inf] (7), [-0.59825,   inf] (7), [-0.58756,   inf] (7), [-0.51620,   inf] (7), [-0.51342,   inf] (7), [-0.50581,   inf] (7), [-0.38772,   inf] (7), [-0.37214,   inf] (7), [-0.33645,   inf] (7), [-0.31394,   inf] (7), [-0.25458,   inf] (7), [-0.20486,   inf] (7), [-0.15342,   inf] (7), 
length of domains: 16
Total time: 0.3006	 pickout: 0.0007	 decision: 0.0333	 get_bound: 0.2658	 add_domain: 0.0007
Current lb:-0.9040718078613281
64 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.221599817276001

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([16, 16, 14, 14]) pre split depth:  2
batch:  torch.Size([16, 16, 14, 14]) post split depth:  2
splitting decisions: 
split level 0: [2, 83] [2, 83] [2, 83] [2, 83] [2, 83] [2, 83] [2, 83] [2, 83] [2, 83] [2, 83] 
split level 1: [1, 1194] [1, 1194] [1, 1194] [1, 661] [1, 1194] [1, 1194] [1, 1194] [2, 85] [2, 85] [1, 661] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: -25.293912887573242 with beta sum per layer: [0.0, 1.2107515335083008, 7.214677810668945]
alpha/beta optimization time: 0.23941493034362793
This batch time : update_bounds func: 0.2522	 prepare: 0.0073	 bound: 0.2397	 transfer: 0.0013	 finalize: 0.0038
Accumulated time: update_bounds func: 6.6005	 prepare: 0.2386	 bound: 6.1630	 transfer: 0.0013	 finalize: 0.1340
batch bounding time:  0.25239086151123047
Current worst splitting domains [lb, ub] (depth):
[-0.23634,   inf] (10), [-0.18679,   inf] (10), [-0.16472,   inf] (10), [-0.15735,   inf] (10), [-0.07822,   inf] (10), [-0.04207,   inf] (10), [-0.02347,   inf] (10), 
length of domains: 7
Total time: 0.2833	 pickout: 0.0030	 decision: 0.0230	 get_bound: 0.2568	 add_domain: 0.0004
Current lb:-0.23633553087711334
128 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.5054113864898682

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([7, 16, 14, 14]) pre split depth:  3
batch:  torch.Size([7, 16, 14, 14]) post split depth:  3
splitting decisions: 
split level 0: [2, 85] [2, 85] [2, 85] [2, 85] [2, 85] [2, 75] [1, 1194] 
split level 1: [1, 1194] [1, 655] [1, 655] [1, 655] [1, 655] [2, 85] [1, 661] 
split level 2: [1, 655] [1, 661] [1, 661] [1, 661] [1, 661] [1, 661] [1, 655] 
regular batch size: 2*28, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -41.34318161010742 with beta sum per layer: [0.0, 0.0, 0.4491143822669983]
alpha/beta optimization time: 0.008528709411621094
This batch time : update_bounds func: 0.0198	 prepare: 0.0064	 bound: 0.0088	 transfer: 0.0013	 finalize: 0.0032
Accumulated time: update_bounds func: 6.6204	 prepare: 0.2450	 bound: 6.1718	 transfer: 0.0013	 finalize: 0.1372
batch bounding time:  0.019902944564819336
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0484	 pickout: 0.0016	 decision: 0.0211	 get_bound: 0.0256	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.5542149543762207

Image 2 label 6 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.6061766147613525
2 1.0000000116860974e-07
##### [0:2] Tested against 2 ######
Model prediction is: tensor([[-4.2674, -7.4374, -3.7629, -2.6753,  1.5492, -3.0144, -6.5095, -0.8245,
         -1.0512,  3.9617]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 16, 14, 14]) != torch.Size([2, 9, 1, 16, 14, 14]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 7, 7]) != torch.Size([2, 9, 1, 32, 7, 7]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 14, 14])
1 /11 torch.Size([1, 32, 7, 7])
2 /14 torch.Size([1, 100])
best_l after optimization: 2.5559439659118652 with beta sum per layer: []
alpha/beta optimization time: 0.8936212062835693
alpha-CROWN with fixed intermediate bounds: tensor([[-2.5559]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-2.5559439659118652
layer 0 size torch.Size([3136]) unstable 1253
layer 1 size torch.Size([1568]) unstable 191
layer 2 size torch.Size([100]) unstable 25
-----------------
# of unstable neurons: 1469
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 14, 14]) pre split depth:  6
batch:  torch.Size([1, 16, 14, 14]) post split depth:  6
splitting decisions: 
split level 0: [2, 22] 
split level 1: [1, 905] 
split level 2: [2, 67] 
split level 3: [2, 38] 
split level 4: [2, 47] 
split level 5: [2, 41] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: -47.73828125 with beta sum per layer: [0.0, 0.0, 0.34655171632766724]
alpha/beta optimization time: 0.24362587928771973
This batch time : update_bounds func: 0.2547	 prepare: 0.0056	 bound: 0.2439	 transfer: 0.0013	 finalize: 0.0037
Accumulated time: update_bounds func: 6.8750	 prepare: 0.2507	 bound: 6.4157	 transfer: 0.0013	 finalize: 0.1409
batch bounding time:  0.25485968589782715
Current worst splitting domains [lb, ub] (depth):
[-0.38030,   inf] (7), [-0.33092,   inf] (7), [-0.32614,   inf] (7), [-0.27608,   inf] (7), [-0.21704,   inf] (7), [-0.17998,   inf] (7), [-0.16053,   inf] (7), [-0.03364,   inf] (7), [-0.02643,   inf] (7), 
length of domains: 9
Total time: 0.2972	 pickout: 0.0007	 decision: 0.0333	 get_bound: 0.2627	 add_domain: 0.0004
Current lb:-0.380296528339386
64 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.206920862197876

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([9, 16, 14, 14]) pre split depth:  3
batch:  torch.Size([9, 16, 14, 14]) post split depth:  3
splitting decisions: 
split level 0: [2, 83] [2, 83] [2, 83] [1, 415] [1, 415] [2, 11] [2, 83] [2, 83] [2, 83] 
split level 1: [2, 11] [2, 11] [1, 415] [1, 414] [2, 83] [2, 83] [1, 414] [1, 612] [1, 612] 
split level 2: [1, 414] [1, 414] [1, 414] [2, 83] [1, 414] [1, 414] [1, 612] [1, 414] [1, 414] 
regular batch size: 2*36, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -46.039459228515625 with beta sum per layer: [0.0, 0.0, 0.6893524527549744]
alpha/beta optimization time: 0.008672952651977539
This batch time : update_bounds func: 0.0224	 prepare: 0.0079	 bound: 0.0089	 transfer: 0.0013	 finalize: 0.0040
Accumulated time: update_bounds func: 6.8974	 prepare: 0.2586	 bound: 6.4247	 transfer: 0.0013	 finalize: 0.1449
batch bounding time:  0.022463083267211914
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0533	 pickout: 0.0020	 decision: 0.0217	 get_bound: 0.0296	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.2606728076934814

Image 2 label 2 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.312889814376831
2 1.0000000116860974e-07
##### [0:2] Tested against 0 ######
Model prediction is: tensor([[-4.2674, -7.4374, -3.7629, -2.6753,  1.5492, -3.0144, -6.5095, -0.8245,
         -1.0512,  3.9617]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 16, 14, 14]) != torch.Size([2, 9, 1, 16, 14, 14]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 7, 7]) != torch.Size([2, 9, 1, 32, 7, 7]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 14, 14])
1 /11 torch.Size([1, 32, 7, 7])
2 /14 torch.Size([1, 100])
best_l after optimization: 1.6237773895263672 with beta sum per layer: []
alpha/beta optimization time: 0.9301598072052002
alpha-CROWN with fixed intermediate bounds: tensor([[-1.6238]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-1.6237773895263672
layer 0 size torch.Size([3136]) unstable 1253
layer 1 size torch.Size([1568]) unstable 191
layer 2 size torch.Size([100]) unstable 25
-----------------
# of unstable neurons: 1469
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 14, 14]) pre split depth:  6
batch:  torch.Size([1, 16, 14, 14]) post split depth:  6
splitting decisions: 
split level 0: [2, 22] 
split level 1: [2, 83] 
split level 2: [2, 67] 
split level 3: [1, 563] 
split level 4: [2, 85] 
split level 5: [2, 41] 
regular batch size: 2*32, diving batch size 1*0

all verified at 4th iter
best_l after optimization: -83.67681884765625 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.06242489814758301
This batch time : update_bounds func: 0.0738	 prepare: 0.0057	 bound: 0.0627	 transfer: 0.0015	 finalize: 0.0037
Accumulated time: update_bounds func: 6.9712	 prepare: 0.2643	 bound: 6.4874	 transfer: 0.0015	 finalize: 0.1485
batch bounding time:  0.07392334938049316
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.1172	 pickout: 0.0008	 decision: 0.0340	 get_bound: 0.0824	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.0715112686157227

Image 2 label 0 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.123532772064209
2 1.0000000116860974e-07
##### [0:2] Tested against 1 ######
Model prediction is: tensor([[-4.2674, -7.4374, -3.7629, -2.6753,  1.5492, -3.0144, -6.5095, -0.8245,
         -1.0512,  3.9617]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 16, 14, 14]) != torch.Size([2, 9, 1, 16, 14, 14]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 7, 7]) != torch.Size([2, 9, 1, 32, 7, 7]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 14, 14])
1 /11 torch.Size([1, 32, 7, 7])
2 /14 torch.Size([1, 100])
best_l after optimization: 0.6009006500244141 with beta sum per layer: []
alpha/beta optimization time: 1.0528485774993896
alpha-CROWN with fixed intermediate bounds: tensor([[-0.6009]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.6009006500244141
layer 0 size torch.Size([3136]) unstable 1253
layer 1 size torch.Size([1568]) unstable 191
layer 2 size torch.Size([100]) unstable 25
-----------------
# of unstable neurons: 1469
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 14, 14]) pre split depth:  6
batch:  torch.Size([1, 16, 14, 14]) post split depth:  6
splitting decisions: 
split level 0: [2, 47] 
split level 1: [2, 67] 
split level 2: [2, 79] 
split level 3: [2, 78] 
split level 4: [1, 655] 
split level 5: [2, 41] 
regular batch size: 2*32, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -193.2928009033203 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.012575149536132812
This batch time : update_bounds func: 0.0317	 prepare: 0.0085	 bound: 0.0129	 transfer: 0.0028	 finalize: 0.0073
Accumulated time: update_bounds func: 7.0028	 prepare: 0.2728	 bound: 6.5003	 transfer: 0.0028	 finalize: 0.1558
batch bounding time:  0.03178548812866211
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0849	 pickout: 0.0011	 decision: 0.0405	 get_bound: 0.0433	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.1579227447509766

Image 2 label 1 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.2171337604522705
2 1.0000000116860974e-07
##### [0:2] Tested against 9 ######
groundtruth label, skip!
Result: image 2 verification success (with branch and bound)!
Wall time: 29.216792583465576

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 1): [2]
verification failure idx (total 0): []
final verified acc: 100.0%[1]
verifier is called on 1 examples.
total verified: 1
mean time [cnt:1] (excluding attack success): 27.866634845733643
