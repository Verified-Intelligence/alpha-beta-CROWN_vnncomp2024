Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: mnist_cnn_a_adv.model
  name: mnist_cnn_4layer
data:
  start: 30
  end: 31
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: MNIST_SDP
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.3
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 1024
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 180
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Tue May  3 01:03:02 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(1, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Flatten(start_dim=1, end_dim=-1)
  (5): Linear(in_features=1568, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=10, bias=True)
)
############################
Shape: torch.Size([200, 1, 28, 28]) torch.Size([200]) torch.Size([200])
X range: tensor(1.) tensor(0.) tensor(0.1340)
############################
epsilon after preprocessing: 0.30000001192092896, data_max = tensor([[[[1.]]]]), data_min = tensor([[[[0.]]]])
Task length: 1
saving results to Verified_ret_[mnist_cnn_4layer]_start=30_end=31_iter=20_b=1024_timeout=180_branching=kfsb-max-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 30 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 8, correct label 8, image norm 72.62353515625, logits tensor([-5.3310, -1.0028, -4.5276, -2.1393, -0.4647, -2.5196, -3.9605, -3.0203,
         1.2645, -0.6715], device='cuda:0', grad_fn=<SelectBackward>)
Model prediction is: tensor([[-5.3310, -1.0028, -4.5276, -2.1393, -0.4647, -2.5196, -3.9605, -3.0203,
          1.2645, -0.6715]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-0.0989, -6.5361, -2.0298, -2.7632, -7.7899, -5.3838, -5.3464, -5.3312,
         -6.1815]], device='cuda:0') None
best_l after optimization: 23.71333885192871 with beta sum per layer: []
alpha/beta optimization time: 7.190553426742554
initial alpha-CROWN bounds: tensor([[ 1.5326, -4.5356, -0.1516, -1.4443, -5.5710, -3.2976, -2.9873, -3.1893,
         -4.0693]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-5.5710, device='cuda:0', grad_fn=<MinBackward1>)
##### [0:30] Tested against 4 ######
Model prediction is: tensor([[-5.3310, -1.0028, -4.5276, -2.1393, -0.4647, -2.5196, -3.9605, -3.0203,
          1.2645, -0.6715]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 16, 14, 14]) != torch.Size([2, 9, 1, 16, 14, 14]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 7, 7]) != torch.Size([2, 9, 1, 32, 7, 7]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 14, 14])
1 /11 torch.Size([1, 32, 7, 7])
2 /14 torch.Size([1, 100])
best_l after optimization: 5.56207275390625 with beta sum per layer: []
alpha/beta optimization time: 1.7036261558532715
alpha-CROWN with fixed intermediate bounds: tensor([[-5.5621]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-5.56207275390625
layer 0 size torch.Size([3136]) unstable 1274
layer 1 size torch.Size([1568]) unstable 160
layer 2 size torch.Size([100]) unstable 18
-----------------
# of unstable neurons: 1452
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 14, 14]) pre split depth:  6
batch:  torch.Size([1, 16, 14, 14]) post split depth:  6
splitting decisions: 
split level 0: [2, 33] 
split level 1: [1, 1206] 
split level 2: [2, 84] 
split level 3: [1, 674] 
split level 4: [2, 56] 
split level 5: [2, 78] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: 148.18772888183594 with beta sum per layer: [0.0, 15.413233757019043, 50.732200622558594]
alpha/beta optimization time: 0.24838805198669434
This batch time : update_bounds func: 0.2598	 prepare: 0.0057	 bound: 0.2487	 transfer: 0.0013	 finalize: 0.0039
Accumulated time: update_bounds func: 0.2598	 prepare: 0.0057	 bound: 0.2487	 transfer: 0.0013	 finalize: 0.0039
batch bounding time:  0.2599790096282959
Current worst splitting domains [lb, ub] (depth):
[-4.84624,   inf] (7), [-4.79793,   inf] (7), [-4.39988,   inf] (7), [-4.25457,   inf] (7), [-4.09393,   inf] (7), [-4.09316,   inf] (7), [-4.09276,   inf] (7), [-4.06313,   inf] (7), [-3.82648,   inf] (7), [-3.82499,   inf] (7), [-3.69444,   inf] (7), [-3.58672,   inf] (7), [-3.58279,   inf] (7), [-3.51049,   inf] (7), [-3.48939,   inf] (7), [-3.47052,   inf] (7), [-3.39344,   inf] (7), [-3.39332,   inf] (7), [-3.36057,   inf] (7), [-3.33360,   inf] (7), 
length of domains: 64
Total time: 0.3071	 pickout: 0.0008	 decision: 0.0357	 get_bound: 0.2680	 add_domain: 0.0026
Current lb:-4.8462443351745605
64 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.8408188819885254

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([64, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [2, 63] [2, 63] [2, 63] [2, 63] [2, 63] [2, 63] [2, 63] [2, 63] [2, 63] [2, 63] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 164.92962646484375 with beta sum per layer: [0.0, 28.74180793762207, 147.1247100830078]
alpha/beta optimization time: 0.2461717128753662
This batch time : update_bounds func: 0.2693	 prepare: 0.0131	 bound: 0.2465	 transfer: 0.0019	 finalize: 0.0075
Accumulated time: update_bounds func: 0.5291	 prepare: 0.0188	 bound: 0.4951	 transfer: 0.0019	 finalize: 0.0114
batch bounding time:  0.2694840431213379
Current worst splitting domains [lb, ub] (depth):
[-4.74215,   inf] (9), [-4.69204,   inf] (9), [-4.21220,   inf] (9), [-4.08029,   inf] (9), [-3.95574,   inf] (9), [-3.95297,   inf] (9), [-3.93561,   inf] (9), [-3.92527,   inf] (9), [-3.68356,   inf] (9), [-3.67808,   inf] (9), [-3.47570,   inf] (9), [-3.38246,   inf] (9), [-3.34462,   inf] (9), [-3.29276,   inf] (9), [-3.29095,   inf] (9), [-3.25836,   inf] (9), [-3.18022,   inf] (9), [-3.10295,   inf] (9), [-3.08970,   inf] (9), [-3.08301,   inf] (9), 
length of domains: 89
Total time: 0.3196	 pickout: 0.0092	 decision: 0.0368	 get_bound: 0.2697	 add_domain: 0.0039
Current lb:-4.7421464920043945
192 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.1613271236419678

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([89, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([89, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 87] [1, 87] [1, 87] [1, 87] [1, 87] [1, 87] [1, 87] [1, 87] [1, 87] [1, 87] 
regular batch size: 2*89, diving batch size 1*0
best_l after optimization: 233.80938720703125 with beta sum per layer: [0.0, 78.53284454345703, 210.4417724609375]
alpha/beta optimization time: 0.25263071060180664
This batch time : update_bounds func: 0.2888	 prepare: 0.0173	 bound: 0.2529	 transfer: 0.0081	 finalize: 0.0101
Accumulated time: update_bounds func: 0.8179	 prepare: 0.0361	 bound: 0.7481	 transfer: 0.0081	 finalize: 0.0215
batch bounding time:  0.2890644073486328
Current worst splitting domains [lb, ub] (depth):
[-4.58378,   inf] (11), [-4.50220,   inf] (11), [-4.27534,   inf] (11), [-4.24829,   inf] (11), [-4.00923,   inf] (11), [-3.89399,   inf] (11), [-3.84645,   inf] (11), [-3.80487,   inf] (11), [-3.73893,   inf] (11), [-3.72410,   inf] (11), [-3.57262,   inf] (11), [-3.53359,   inf] (11), [-3.52536,   inf] (11), [-3.51766,   inf] (11), [-3.37055,   inf] (11), [-3.36903,   inf] (11), [-3.36194,   inf] (11), [-3.30724,   inf] (11), [-3.27451,   inf] (11), [-3.24014,   inf] (11), 
length of domains: 153
Total time: 0.3531	 pickout: 0.0126	 decision: 0.0438	 get_bound: 0.2893	 add_domain: 0.0073
Current lb:-4.583775997161865
370 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.515744924545288

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([153, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([153, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 626] [1, 626] [1, 626] [1, 626] [1, 1039] [1, 1039] [1, 1067] [1, 1067] [1, 626] [1, 626] 
regular batch size: 2*153, diving batch size 1*0
best_l after optimization: 361.8701171875 with beta sum per layer: [0.0, 206.91514587402344, 360.2660827636719]
alpha/beta optimization time: 0.2878391742706299
This batch time : update_bounds func: 0.3449	 prepare: 0.0285	 bound: 0.2881	 transfer: 0.0101	 finalize: 0.0175
Accumulated time: update_bounds func: 1.1628	 prepare: 0.0646	 bound: 1.0362	 transfer: 0.0101	 finalize: 0.0390
batch bounding time:  0.3452267646789551
Current worst splitting domains [lb, ub] (depth):
[-4.43204,   inf] (13), [-4.35378,   inf] (13), [-4.13973,   inf] (13), [-4.11260,   inf] (13), [-4.06778,   inf] (13), [-4.02445,   inf] (13), [-3.83972,   inf] (13), [-3.76341,   inf] (13), [-3.75489,   inf] (13), [-3.73254,   inf] (13), [-3.55657,   inf] (13), [-3.55182,   inf] (13), [-3.48770,   inf] (13), [-3.48276,   inf] (13), [-3.46802,   inf] (13), [-3.46357,   inf] (13), [-3.41444,   inf] (13), [-3.39169,   inf] (13), [-3.35309,   inf] (13), [-3.31427,   inf] (13), 
length of domains: 253
Total time: 0.4346	 pickout: 0.0207	 decision: 0.0562	 get_bound: 0.3457	 add_domain: 0.0120
Current lb:-4.432037353515625
676 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.9524948596954346

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([253, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([253, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 1067] [1, 1067] [1, 1067] [1, 1067] [1, 1067] [1, 1067] [1, 626] [1, 626] [1, 654] [1, 1039] 
regular batch size: 2*253, diving batch size 1*0
best_l after optimization: 570.1544799804688 with beta sum per layer: [0.0, 461.1628723144531, 566.625244140625]
alpha/beta optimization time: 0.3023684024810791
This batch time : update_bounds func: 0.3925	 prepare: 0.0459	 bound: 0.3027	 transfer: 0.0140	 finalize: 0.0289
Accumulated time: update_bounds func: 1.5553	 prepare: 0.1104	 bound: 1.3389	 transfer: 0.0140	 finalize: 0.0679
batch bounding time:  0.393110990524292
Current worst splitting domains [lb, ub] (depth):
[-4.26610,   inf] (15), [-4.19825,   inf] (15), [-3.91844,   inf] (15), [-3.91245,   inf] (15), [-3.90865,   inf] (15), [-3.89543,   inf] (15), [-3.87298,   inf] (15), [-3.87104,   inf] (15), [-3.79643,   inf] (15), [-3.77337,   inf] (15), [-3.64742,   inf] (15), [-3.63703,   inf] (15), [-3.63524,   inf] (15), [-3.58419,   inf] (15), [-3.46070,   inf] (15), [-3.44591,   inf] (15), [-3.40388,   inf] (15), [-3.40276,   inf] (15), [-3.39505,   inf] (15), [-3.37813,   inf] (15), 
length of domains: 421
Total time: 0.5336	 pickout: 0.0347	 decision: 0.0829	 get_bound: 0.3939	 add_domain: 0.0221
Current lb:-4.266098499298096
1182 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.489982604980469

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([421, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([421, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 1039] [1, 1039] [1, 1039] [1, 1039] [1, 1039] [1, 1039] [1, 1039] [1, 1039] [1, 1039] [1, 1039] 
regular batch size: 2*421, diving batch size 1*0
best_l after optimization: 905.68359375 with beta sum per layer: [0.0, 973.012939453125, 890.2444458007812]
alpha/beta optimization time: 0.37734174728393555
This batch time : update_bounds func: 0.5293	 prepare: 0.0777	 bound: 0.3776	 transfer: 0.0234	 finalize: 0.0489
Accumulated time: update_bounds func: 2.0847	 prepare: 0.1881	 bound: 1.7165	 transfer: 0.0234	 finalize: 0.1167
batch bounding time:  0.5301539897918701
Current worst splitting domains [lb, ub] (depth):
[-4.17341,   inf] (17), [-4.11044,   inf] (17), [-3.83729,   inf] (17), [-3.83147,   inf] (17), [-3.81424,   inf] (17), [-3.80378,   inf] (17), [-3.78522,   inf] (17), [-3.77642,   inf] (17), [-3.77246,   inf] (17), [-3.72747,   inf] (17), [-3.71708,   inf] (17), [-3.69701,   inf] (17), [-3.57642,   inf] (17), [-3.48712,   inf] (17), [-3.48146,   inf] (17), [-3.46663,   inf] (17), [-3.43395,   inf] (17), [-3.42802,   inf] (17), [-3.42740,   inf] (17), [-3.41435,   inf] (17), 
length of domains: 715
Total time: 0.8062	 pickout: 0.0599	 decision: 0.1760	 get_bound: 0.5314	 add_domain: 0.0389
Current lb:-4.173412799835205
2024 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.303200006484985

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([715, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([715, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 654] [1, 654] [1, 654] [1, 654] [1, 654] [1, 654] [1, 654] [1, 654] [1, 654] [1, 654] 
regular batch size: 2*715, diving batch size 1*0
best_l after optimization: 1453.7216796875 with beta sum per layer: [0.0, 1950.173095703125, 1445.0458984375]
alpha/beta optimization time: 0.5260343551635742
This batch time : update_bounds func: 0.7831	 prepare: 0.1305	 bound: 0.5264	 transfer: 0.0377	 finalize: 0.0855
Accumulated time: update_bounds func: 2.8678	 prepare: 0.3186	 bound: 2.2429	 transfer: 0.0377	 finalize: 0.2023
batch bounding time:  0.7843794822692871
Current worst splitting domains [lb, ub] (depth):
[-4.08747,   inf] (19), [-4.03541,   inf] (19), [-3.76501,   inf] (19), [-3.75965,   inf] (19), [-3.75130,   inf] (19), [-3.74436,   inf] (19), [-3.71867,   inf] (19), [-3.70411,   inf] (19), [-3.67912,   inf] (19), [-3.65373,   inf] (19), [-3.64629,   inf] (19), [-3.63603,   inf] (19), [-3.63011,   inf] (19), [-3.58422,   inf] (19), [-3.53716,   inf] (19), [-3.44153,   inf] (19), [-3.43077,   inf] (19), [-3.42672,   inf] (19), [-3.42183,   inf] (19), [-3.40864,   inf] (19), 
length of domains: 1227
Total time: 1.2453	 pickout: 0.1102	 decision: 0.2770	 get_bound: 0.7866	 add_domain: 0.0716
Current lb:-4.087471008300781
3454 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.5601136684417725

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 941] [1, 941] [1, 941] [1, 941] [1, 941] [1, 941] [1, 941] [1, 941] [1, 941] [1, 941] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 2373.33154296875 with beta sum per layer: [0.41599491238594055, 3250.044921875, 1734.25927734375]
alpha/beta optimization time: 0.6890690326690674
This batch time : update_bounds func: 1.1159	 prepare: 0.1956	 bound: 0.6894	 transfer: 0.0468	 finalize: 0.1793
Accumulated time: update_bounds func: 3.9837	 prepare: 0.5142	 bound: 2.9323	 transfer: 0.0468	 finalize: 0.3816
batch bounding time:  1.117642879486084
Current worst splitting domains [lb, ub] (depth):
[-4.03789,   inf] (21), [-3.99372,   inf] (21), [-3.72078,   inf] (21), [-3.71752,   inf] (21), [-3.71692,   inf] (21), [-3.69890,   inf] (21), [-3.67820,   inf] (21), [-3.63480,   inf] (21), [-3.62749,   inf] (21), [-3.62524,   inf] (21), [-3.60430,   inf] (21), [-3.59603,   inf] (21), [-3.59519,   inf] (21), [-3.58483,   inf] (21), [-3.57266,   inf] (21), [-3.52537,   inf] (21), [-3.49001,   inf] (21), [-3.39902,   inf] (21), [-3.39745,   inf] (21), [-3.39593,   inf] (21), 
length of domains: 2163
Total time: 1.7512	 pickout: 0.1515	 decision: 0.3560	 get_bound: 1.1207	 add_domain: 0.1231
Current lb:-4.037893295288086
5502 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.328912258148193

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 556] [1, 556] [1, 556] [1, 556] [1, 647] [1, 556] [1, 556] [1, 556] [1, 556] [1, 556] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 3557.3017578125 with beta sum per layer: [0.0, 2815.674072265625, 1103.135009765625]
alpha/beta optimization time: 0.6831161975860596
This batch time : update_bounds func: 1.1131	 prepare: 0.1872	 bound: 0.6835	 transfer: 0.0526	 finalize: 0.1849
Accumulated time: update_bounds func: 5.0969	 prepare: 0.7014	 bound: 3.6158	 transfer: 0.0526	 finalize: 0.5665
batch bounding time:  1.1148896217346191
Current worst splitting domains [lb, ub] (depth):
[-3.91810,   inf] (23), [-3.86251,   inf] (23), [-3.83885,   inf] (23), [-3.78344,   inf] (23), [-3.61643,   inf] (23), [-3.59794,   inf] (23), [-3.59574,   inf] (23), [-3.57219,   inf] (23), [-3.55129,   inf] (23), [-3.52481,   inf] (23), [-3.52206,   inf] (23), [-3.51752,   inf] (23), [-3.51328,   inf] (23), [-3.51066,   inf] (23), [-3.50712,   inf] (23), [-3.49260,   inf] (23), [-3.48958,   inf] (23), [-3.48161,   inf] (23), [-3.47116,   inf] (23), [-3.45767,   inf] (23), 
length of domains: 3187
Total time: 1.7668	 pickout: 0.1547	 decision: 0.3596	 get_bound: 1.1179	 add_domain: 0.1346
Current lb:-3.9180996417999268
7550 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.11078667640686

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 648] [1, 648] [1, 648] [1, 648] [1, 648] [1, 648] [1, 648] [1, 648] [1, 648] [1, 648] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 4303.36328125 with beta sum per layer: [0.0, 2479.23828125, 548.0540771484375]
alpha/beta optimization time: 0.6829137802124023
This batch time : update_bounds func: 1.1349	 prepare: 0.1851	 bound: 0.6832	 transfer: 0.0550	 finalize: 0.2069
Accumulated time: update_bounds func: 6.2318	 prepare: 0.8865	 bound: 4.2990	 transfer: 0.0550	 finalize: 0.7734
batch bounding time:  1.1370046138763428
Current worst splitting domains [lb, ub] (depth):
[-3.87440,   inf] (25), [-3.83041,   inf] (25), [-3.80838,   inf] (25), [-3.75279,   inf] (25), [-3.60839,   inf] (25), [-3.58906,   inf] (25), [-3.58190,   inf] (25), [-3.55681,   inf] (25), [-3.55291,   inf] (25), [-3.53554,   inf] (25), [-3.52359,   inf] (25), [-3.51518,   inf] (25), [-3.49589,   inf] (25), [-3.49064,   inf] (25), [-3.48870,   inf] (25), [-3.48424,   inf] (25), [-3.48095,   inf] (25), [-3.47142,   inf] (25), [-3.45831,   inf] (25), [-3.45821,   inf] (25), 
length of domains: 4211
Total time: 1.7926	 pickout: 0.1508	 decision: 0.3638	 get_bound: 1.1403	 add_domain: 0.1377
Current lb:-3.874404191970825
9598 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.918782472610474

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 723] [1, 647] [1, 723] [1, 723] [1, 723] [1, 723] [1, 723] [1, 723] [1, 723] [1, 723] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 4547.1650390625 with beta sum per layer: [0.0, 2618.7587890625, 288.2784118652344]
alpha/beta optimization time: 0.6890227794647217
This batch time : update_bounds func: 1.0686	 prepare: 0.1914	 bound: 0.6893	 transfer: 0.0557	 finalize: 0.1271
Accumulated time: update_bounds func: 7.3003	 prepare: 1.0779	 bound: 4.9883	 transfer: 0.0557	 finalize: 0.9005
batch bounding time:  1.0704331398010254
Current worst splitting domains [lb, ub] (depth):
[-3.82307,   inf] (27), [-3.78478,   inf] (27), [-3.75964,   inf] (27), [-3.70635,   inf] (27), [-3.62265,   inf] (27), [-3.54659,   inf] (27), [-3.53379,   inf] (27), [-3.53018,   inf] (27), [-3.50089,   inf] (27), [-3.48101,   inf] (27), [-3.47135,   inf] (27), [-3.46597,   inf] (27), [-3.46488,   inf] (27), [-3.44081,   inf] (27), [-3.43583,   inf] (27), [-3.43071,   inf] (27), [-3.42886,   inf] (27), [-3.42083,   inf] (27), [-3.41979,   inf] (27), [-3.41846,   inf] (27), 
length of domains: 5235
Total time: 1.8915	 pickout: 0.1576	 decision: 0.3842	 get_bound: 1.0736	 add_domain: 0.2761
Current lb:-3.8230671882629395
11646 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.825614929199219

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 647] [1, 723] [1, 60] [1, 60] [1, 723] [1, 647] [1, 556] [1, 647] [1, 647] [1, 647] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 4757.998046875 with beta sum per layer: [0.0, 2619.804443359375, 208.60548400878906]
alpha/beta optimization time: 0.6883573532104492
This batch time : update_bounds func: 1.1711	 prepare: 0.1882	 bound: 0.6887	 transfer: 0.0537	 finalize: 0.2354
Accumulated time: update_bounds func: 8.4714	 prepare: 1.2661	 bound: 5.6770	 transfer: 0.0537	 finalize: 1.1360
batch bounding time:  1.1727852821350098
Current worst splitting domains [lb, ub] (depth):
[-3.76922,   inf] (29), [-3.73778,   inf] (29), [-3.61173,   inf] (29), [-3.61068,   inf] (29), [-3.57185,   inf] (29), [-3.56287,   inf] (29), [-3.55107,   inf] (29), [-3.50433,   inf] (29), [-3.48724,   inf] (29), [-3.48492,   inf] (29), [-3.44664,   inf] (29), [-3.42768,   inf] (29), [-3.42671,   inf] (29), [-3.42102,   inf] (29), [-3.39248,   inf] (29), [-3.38621,   inf] (29), [-3.37526,   inf] (29), [-3.36597,   inf] (29), [-3.31956,   inf] (29), [-3.31163,   inf] (29), 
length of domains: 6259
Total time: 1.7683	 pickout: 0.1517	 decision: 0.2887	 get_bound: 1.1758	 add_domain: 0.1521
Current lb:-3.769219160079956
13694 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.610466957092285

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 60] [1, 60] [1, 647] [1, 60] [1, 60] [1, 647] [1, 647] [1, 647] [1, 60] [1, 60] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 4930.138671875 with beta sum per layer: [0.0, 2363.95166015625, 201.5839385986328]
alpha/beta optimization time: 0.6873128414154053
This batch time : update_bounds func: 1.2019	 prepare: 0.1919	 bound: 0.6876	 transfer: 0.0541	 finalize: 0.2634
Accumulated time: update_bounds func: 9.6733	 prepare: 1.4580	 bound: 6.3646	 transfer: 0.0541	 finalize: 1.3993
batch bounding time:  1.2040057182312012
Current worst splitting domains [lb, ub] (depth):
[-3.62611,   inf] (31), [-3.59769,   inf] (31), [-3.54773,   inf] (31), [-3.54643,   inf] (31), [-3.51246,   inf] (31), [-3.50856,   inf] (31), [-3.46512,   inf] (31), [-3.46022,   inf] (31), [-3.45811,   inf] (31), [-3.43575,   inf] (31), [-3.43021,   inf] (31), [-3.41745,   inf] (31), [-3.38520,   inf] (31), [-3.37565,   inf] (31), [-3.34458,   inf] (31), [-3.33974,   inf] (31), [-3.33922,   inf] (31), [-3.33629,   inf] (31), [-3.31290,   inf] (31), [-3.30883,   inf] (31), 
length of domains: 7283
Total time: 1.9358	 pickout: 0.1521	 decision: 0.4193	 get_bound: 1.2073	 add_domain: 0.1571
Current lb:-3.626110076904297
15742 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.56467628479004

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 18] [1, 18] [1, 653] [1, 18] [1, 18] [1, 18] [2, 96] [1, 18] [1, 18] [1, 18] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5043.2666015625 with beta sum per layer: [0.0, 2121.070068359375, 320.0463562011719]
alpha/beta optimization time: 0.6873927116394043
This batch time : update_bounds func: 1.2105	 prepare: 0.1929	 bound: 0.6877	 transfer: 0.0541	 finalize: 0.2704
Accumulated time: update_bounds func: 10.8839	 prepare: 1.6509	 bound: 7.0523	 transfer: 0.0541	 finalize: 1.6697
batch bounding time:  1.2123932838439941
Current worst splitting domains [lb, ub] (depth):
[-3.51534,   inf] (33), [-3.50707,   inf] (33), [-3.48155,   inf] (33), [-3.46992,   inf] (33), [-3.44778,   inf] (33), [-3.43172,   inf] (33), [-3.39875,   inf] (33), [-3.39754,   inf] (33), [-3.38370,   inf] (33), [-3.38069,   inf] (33), [-3.38031,   inf] (33), [-3.37629,   inf] (33), [-3.37534,   inf] (33), [-3.37125,   inf] (33), [-3.36408,   inf] (33), [-3.36139,   inf] (33), [-3.33361,   inf] (33), [-3.31983,   inf] (33), [-3.30786,   inf] (33), [-3.29341,   inf] (33), 
length of domains: 8307
Total time: 1.8201	 pickout: 0.1527	 decision: 0.2890	 get_bound: 1.2155	 add_domain: 0.1629
Current lb:-3.5153417587280273
17790 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 19.40401840209961

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 906] [1, 906] [1, 906] [2, 96] [2, 96] [1, 906] [1, 18] [1, 906] [1, 653] [1, 653] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5187.908203125 with beta sum per layer: [0.0, 1790.900146484375, 275.1000671386719]
alpha/beta optimization time: 0.6853036880493164
This batch time : update_bounds func: 1.0636	 prepare: 0.1911	 bound: 0.6856	 transfer: 0.0547	 finalize: 0.1274
Accumulated time: update_bounds func: 11.9474	 prepare: 1.8420	 bound: 7.7380	 transfer: 0.0547	 finalize: 1.7971
batch bounding time:  1.0653014183044434
Current worst splitting domains [lb, ub] (depth):
[-3.46498,   inf] (35), [-3.46118,   inf] (35), [-3.42918,   inf] (35), [-3.37646,   inf] (35), [-3.37577,   inf] (35), [-3.35844,   inf] (35), [-3.35500,   inf] (35), [-3.35130,   inf] (35), [-3.33976,   inf] (35), [-3.31962,   inf] (35), [-3.31800,   inf] (35), [-3.31078,   inf] (35), [-3.30891,   inf] (35), [-3.30238,   inf] (35), [-3.29189,   inf] (35), [-3.28952,   inf] (35), [-3.28257,   inf] (35), [-3.27637,   inf] (35), [-3.27313,   inf] (35), [-3.26635,   inf] (35), 
length of domains: 9331
Total time: 1.8545	 pickout: 0.1528	 decision: 0.4647	 get_bound: 1.0684	 add_domain: 0.1686
Current lb:-3.464984893798828
19838 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 21.277228832244873

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 18] [1, 653] [1, 653] [1, 653] [1, 970] [1, 919] [2, 96] [1, 919] [1, 653] [1, 18] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5289.3291015625 with beta sum per layer: [0.0, 1526.20263671875, 280.2999267578125]
alpha/beta optimization time: 0.6887362003326416
This batch time : update_bounds func: 1.0696	 prepare: 0.1929	 bound: 0.6891	 transfer: 0.0544	 finalize: 0.1279
Accumulated time: update_bounds func: 13.0170	 prepare: 2.0349	 bound: 8.4270	 transfer: 0.0544	 finalize: 1.9249
batch bounding time:  1.0714244842529297
Current worst splitting domains [lb, ub] (depth):
[-3.43766,   inf] (37), [-3.40540,   inf] (37), [-3.35908,   inf] (37), [-3.34384,   inf] (37), [-3.33855,   inf] (37), [-3.31861,   inf] (37), [-3.31607,   inf] (37), [-3.31170,   inf] (37), [-3.30134,   inf] (37), [-3.30047,   inf] (37), [-3.28236,   inf] (37), [-3.28092,   inf] (37), [-3.26998,   inf] (37), [-3.26353,   inf] (37), [-3.25720,   inf] (37), [-3.24701,   inf] (37), [-3.23862,   inf] (37), [-3.23629,   inf] (37), [-3.22742,   inf] (37), [-3.22316,   inf] (37), 
length of domains: 10355
Total time: 2.0940	 pickout: 0.1528	 decision: 0.4727	 get_bound: 1.0746	 add_domain: 0.3939
Current lb:-3.4376602172851562
21886 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 23.389544010162354

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [2, 96] [2, 96] [2, 96] [2, 96] [2, 96] [1, 906] [2, 96] [2, 96] [1, 906] [1, 906] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5288.60791015625 with beta sum per layer: [0.0, 1466.901123046875, 206.38400268554688]
alpha/beta optimization time: 0.6903505325317383
This batch time : update_bounds func: 1.0680	 prepare: 0.1921	 bound: 0.6907	 transfer: 0.0548	 finalize: 0.1256
Accumulated time: update_bounds func: 14.0851	 prepare: 2.2270	 bound: 9.1177	 transfer: 0.0548	 finalize: 2.0505
batch bounding time:  1.0698256492614746
Current worst splitting domains [lb, ub] (depth):
[-3.33763,   inf] (39), [-3.30480,   inf] (39), [-3.27983,   inf] (39), [-3.26941,   inf] (39), [-3.26628,   inf] (39), [-3.26601,   inf] (39), [-3.25673,   inf] (39), [-3.24594,   inf] (39), [-3.24579,   inf] (39), [-3.24138,   inf] (39), [-3.24044,   inf] (39), [-3.23690,   inf] (39), [-3.22376,   inf] (39), [-3.21863,   inf] (39), [-3.20615,   inf] (39), [-3.20312,   inf] (39), [-3.20295,   inf] (39), [-3.19980,   inf] (39), [-3.19786,   inf] (39), [-3.19176,   inf] (39), 
length of domains: 11379
Total time: 1.9120	 pickout: 0.1541	 decision: 0.2917	 get_bound: 1.0730	 add_domain: 0.3932
Current lb:-3.337632179260254
23934 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 25.319440126419067

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 919] [1, 919] [1, 682] [1, 682] [1, 682] [1, 919] [1, 682] [1, 682] [1, 906] [1, 906] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5295.23291015625 with beta sum per layer: [0.0, 1554.15234375, 117.82482147216797]
alpha/beta optimization time: 0.6901075839996338
This batch time : update_bounds func: 1.0692	 prepare: 0.1933	 bound: 0.6904	 transfer: 0.0551	 finalize: 0.1255
Accumulated time: update_bounds func: 15.1542	 prepare: 2.4203	 bound: 9.8081	 transfer: 0.0551	 finalize: 2.1760
batch bounding time:  1.0710101127624512
Current worst splitting domains [lb, ub] (depth):
[-3.27588,   inf] (41), [-3.25738,   inf] (41), [-3.25216,   inf] (41), [-3.24304,   inf] (41), [-3.23774,   inf] (41), [-3.23317,   inf] (41), [-3.21871,   inf] (41), [-3.20682,   inf] (41), [-3.20613,   inf] (41), [-3.20342,   inf] (41), [-3.20110,   inf] (41), [-3.17924,   inf] (41), [-3.17551,   inf] (41), [-3.17550,   inf] (41), [-3.17550,   inf] (41), [-3.17371,   inf] (41), [-3.17332,   inf] (41), [-3.15670,   inf] (41), [-3.15612,   inf] (41), [-3.15329,   inf] (41), 
length of domains: 12403
Total time: 1.9392	 pickout: 0.1548	 decision: 0.2924	 get_bound: 1.0741	 add_domain: 0.4179
Current lb:-3.27587890625
25982 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 27.27714204788208

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 682] [1, 653] [1, 17] [1, 682] [1, 653] [1, 970] [1, 17] [1, 970] [1, 682] [1, 919] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5281.8642578125 with beta sum per layer: [0.0, 1711.026611328125, 108.22090148925781]
alpha/beta optimization time: 0.6903996467590332
This batch time : update_bounds func: 1.0711	 prepare: 0.1952	 bound: 0.6907	 transfer: 0.0548	 finalize: 0.1254
Accumulated time: update_bounds func: 16.2253	 prepare: 2.6155	 bound: 10.4989	 transfer: 0.0548	 finalize: 2.3014
batch bounding time:  1.0728976726531982
Current worst splitting domains [lb, ub] (depth):
[-3.25626,   inf] (43), [-3.23200,   inf] (43), [-3.22597,   inf] (43), [-3.22095,   inf] (43), [-3.21644,   inf] (43), [-3.18777,   inf] (43), [-3.17436,   inf] (43), [-3.16667,   inf] (43), [-3.15733,   inf] (43), [-3.15724,   inf] (43), [-3.15514,   inf] (43), [-3.14357,   inf] (43), [-3.13870,   inf] (43), [-3.13448,   inf] (43), [-3.13277,   inf] (43), [-3.12724,   inf] (43), [-3.12461,   inf] (43), [-3.12297,   inf] (43), [-3.12147,   inf] (43), [-3.11701,   inf] (43), 
length of domains: 13427
Total time: 1.9735	 pickout: 0.1552	 decision: 0.2951	 get_bound: 1.0760	 add_domain: 0.4471
Current lb:-3.2562551498413086
28030 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 29.26959252357483

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 422] [1, 919] [1, 422] [1, 970] [1, 970] [1, 422] [1, 422] [1, 17] [1, 422] [1, 422] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5272.8173828125 with beta sum per layer: [0.9020651578903198, 1620.162353515625, 102.95307922363281]
alpha/beta optimization time: 0.6895778179168701
This batch time : update_bounds func: 1.0764	 prepare: 0.1994	 bound: 0.6899	 transfer: 0.0545	 finalize: 0.1272
Accumulated time: update_bounds func: 17.3018	 prepare: 2.8149	 bound: 11.1888	 transfer: 0.0545	 finalize: 2.4286
batch bounding time:  1.0782248973846436
Current worst splitting domains [lb, ub] (depth):
[-3.23478,   inf] (45), [-3.20335,   inf] (45), [-3.17449,   inf] (45), [-3.16751,   inf] (45), [-3.16204,   inf] (45), [-3.15212,   inf] (45), [-3.14971,   inf] (45), [-3.13605,   inf] (45), [-3.13592,   inf] (45), [-3.11631,   inf] (45), [-3.11393,   inf] (45), [-3.10826,   inf] (45), [-3.10414,   inf] (45), [-3.10088,   inf] (45), [-3.09786,   inf] (45), [-3.09647,   inf] (45), [-3.09439,   inf] (45), [-3.09114,   inf] (45), [-3.08840,   inf] (45), [-3.08110,   inf] (45), 
length of domains: 14451
Total time: 1.7299	 pickout: 0.1554	 decision: 0.2962	 get_bound: 1.0813	 add_domain: 0.1969
Current lb:-3.2347841262817383
30078 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 31.01992154121399

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 970] [1, 17] [1, 422] [1, 970] [1, 422] [1, 422] [1, 970] [1, 970] [1, 970] [1, 422] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5237.19140625 with beta sum per layer: [1.3797708749771118, 1675.52685546875, 122.52256774902344]
alpha/beta optimization time: 0.6867899894714355
This batch time : update_bounds func: 1.0789	 prepare: 0.2027	 bound: 0.6871	 transfer: 0.0540	 finalize: 0.1297
Accumulated time: update_bounds func: 18.3807	 prepare: 3.0176	 bound: 11.8759	 transfer: 0.0540	 finalize: 2.5583
batch bounding time:  1.0808475017547607
Current worst splitting domains [lb, ub] (depth):
[-3.18193,   inf] (47), [-3.15401,   inf] (47), [-3.14616,   inf] (47), [-3.14579,   inf] (47), [-3.13316,   inf] (47), [-3.11542,   inf] (47), [-3.10178,   inf] (47), [-3.08882,   inf] (47), [-3.08843,   inf] (47), [-3.08370,   inf] (47), [-3.08315,   inf] (47), [-3.07837,   inf] (47), [-3.07803,   inf] (47), [-3.07264,   inf] (47), [-3.06313,   inf] (47), [-3.06273,   inf] (47), [-3.06115,   inf] (47), [-3.06107,   inf] (47), [-3.05629,   inf] (47), [-3.05489,   inf] (47), 
length of domains: 15475
Total time: 2.0020	 pickout: 0.1552	 decision: 0.5593	 get_bound: 1.0840	 add_domain: 0.2034
Current lb:-3.1819276809692383
32126 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 33.04312705993652

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 123] [0, 1474] [2, 96] [1, 123] [1, 17] [1, 123] [1, 17] [1, 606] [1, 606] [1, 123] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5346.0732421875 with beta sum per layer: [3.42205548286438, 1639.36083984375, 115.29399108886719]
alpha/beta optimization time: 0.6794354915618896
This batch time : update_bounds func: 1.0710	 prepare: 0.2039	 bound: 0.6798	 transfer: 0.0545	 finalize: 0.1276
Accumulated time: update_bounds func: 19.4517	 prepare: 3.2215	 bound: 12.5557	 transfer: 0.0545	 finalize: 2.6860
batch bounding time:  1.0728507041931152
Current worst splitting domains [lb, ub] (depth):
[-3.15100,   inf] (49), [-3.14558,   inf] (49), [-3.11265,   inf] (49), [-3.08896,   inf] (49), [-3.08786,   inf] (49), [-3.08695,   inf] (49), [-3.07774,   inf] (49), [-3.07590,   inf] (49), [-3.06452,   inf] (49), [-3.06086,   inf] (49), [-3.06059,   inf] (49), [-3.05894,   inf] (49), [-3.05489,   inf] (49), [-3.04714,   inf] (49), [-3.04471,   inf] (49), [-3.04439,   inf] (49), [-3.04403,   inf] (49), [-3.03688,   inf] (49), [-3.03645,   inf] (49), [-3.03440,   inf] (49), 
length of domains: 16499
Total time: 2.0368	 pickout: 0.1570	 decision: 0.5913	 get_bound: 1.0760	 add_domain: 0.2126
Current lb:-3.151003122329712
34174 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 35.10441541671753

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 606] [1, 17] [1, 606] [1, 606] [1, 606] [1, 17] [1, 17] [1, 606] [1, 919] [1, 17] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5399.234375 with beta sum per layer: [5.040071487426758, 1810.736572265625, 98.94094848632812]
alpha/beta optimization time: 0.6872372627258301
This batch time : update_bounds func: 1.0850	 prepare: 0.2072	 bound: 0.6876	 transfer: 0.0546	 finalize: 0.1303
Accumulated time: update_bounds func: 20.5367	 prepare: 3.4287	 bound: 13.2433	 transfer: 0.0546	 finalize: 2.8162
batch bounding time:  1.0868377685546875
Current worst splitting domains [lb, ub] (depth):
[-3.12343,   inf] (51), [-3.08749,   inf] (51), [-3.07849,   inf] (51), [-3.06167,   inf] (51), [-3.06054,   inf] (51), [-3.05324,   inf] (51), [-3.04515,   inf] (51), [-3.03834,   inf] (51), [-3.02846,   inf] (51), [-3.02769,   inf] (51), [-3.02733,   inf] (51), [-3.02416,   inf] (51), [-3.02362,   inf] (51), [-3.01895,   inf] (51), [-3.01806,   inf] (51), [-3.01489,   inf] (51), [-3.01071,   inf] (51), [-3.00984,   inf] (51), [-3.00934,   inf] (51), [-3.00733,   inf] (51), 
length of domains: 17523
Total time: 2.0803	 pickout: 0.1612	 decision: 0.6127	 get_bound: 1.0900	 add_domain: 0.2165
Current lb:-3.1234288215637207
36222 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 37.207069873809814

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 123] [1, 970] [1, 606] [1, 123] [1, 17] [1, 606] [1, 123] [1, 123] [1, 17] [1, 123] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5443.3515625 with beta sum per layer: [5.901960372924805, 1661.439453125, 96.03501892089844]
alpha/beta optimization time: 0.6839485168457031
This batch time : update_bounds func: 1.4333	 prepare: 0.2095	 bound: 0.6843	 transfer: 0.0547	 finalize: 0.4796
Accumulated time: update_bounds func: 21.9700	 prepare: 3.6382	 bound: 13.9275	 transfer: 0.0547	 finalize: 3.2958
batch bounding time:  1.435215950012207
Current worst splitting domains [lb, ub] (depth):
[-3.08948,   inf] (53), [-3.05293,   inf] (53), [-3.03466,   inf] (53), [-3.03426,   inf] (53), [-3.02721,   inf] (53), [-3.01813,   inf] (53), [-3.01446,   inf] (53), [-3.01035,   inf] (53), [-3.00338,   inf] (53), [-2.99647,   inf] (53), [-2.99181,   inf] (53), [-2.99065,   inf] (53), [-2.98864,   inf] (53), [-2.98728,   inf] (53), [-2.98643,   inf] (53), [-2.98473,   inf] (53), [-2.98379,   inf] (53), [-2.98171,   inf] (53), [-2.98143,   inf] (53), [-2.98017,   inf] (53), 
length of domains: 18547
Total time: 2.1185	 pickout: 0.1609	 decision: 0.2986	 get_bound: 1.4384	 add_domain: 0.2206
Current lb:-3.089479923248291
38270 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 39.347474098205566

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 17] [0, 1474] [0, 1474] [0, 1474] [0, 1474] [1, 1060] [1, 122] [1, 1060] [0, 1474] [1, 17] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5474.56787109375 with beta sum per layer: [7.656240463256836, 1422.337890625, 85.91720581054688]
alpha/beta optimization time: 0.6811277866363525
This batch time : update_bounds func: 1.0800	 prepare: 0.2075	 bound: 0.6815	 transfer: 0.0556	 finalize: 0.1301
Accumulated time: update_bounds func: 23.0500	 prepare: 3.8457	 bound: 14.6090	 transfer: 0.0556	 finalize: 3.4259
batch bounding time:  1.0819659233093262
Current worst splitting domains [lb, ub] (depth):
[-3.05176,   inf] (55), [-3.03592,   inf] (55), [-3.03417,   inf] (55), [-3.03329,   inf] (55), [-3.02577,   inf] (55), [-3.00302,   inf] (55), [-2.99440,   inf] (55), [-2.99322,   inf] (55), [-2.99037,   inf] (55), [-2.98778,   inf] (55), [-2.98425,   inf] (55), [-2.98352,   inf] (55), [-2.97900,   inf] (55), [-2.97719,   inf] (55), [-2.97543,   inf] (55), [-2.97066,   inf] (55), [-2.96969,   inf] (55), [-2.96902,   inf] (55), [-2.96657,   inf] (55), [-2.96393,   inf] (55), 
length of domains: 19571
Total time: 2.1785	 pickout: 0.1630	 decision: 0.2977	 get_bound: 1.0853	 add_domain: 0.6325
Current lb:-3.051757335662842
40318 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 41.54708933830261

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 611] [1, 1060] [1, 122] [1, 611] [1, 611] [1, 122] [1, 17] [1, 1060] [1, 606] [1, 17] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5396.2861328125 with beta sum per layer: [7.755561828613281, 1449.07666015625, 91.58078002929688]
alpha/beta optimization time: 0.685737133026123
This batch time : update_bounds func: 1.0846	 prepare: 0.2097	 bound: 0.6861	 transfer: 0.0543	 finalize: 0.1296
Accumulated time: update_bounds func: 24.1346	 prepare: 4.0554	 bound: 15.2951	 transfer: 0.0543	 finalize: 3.5555
batch bounding time:  1.0864574909210205
Current worst splitting domains [lb, ub] (depth):
[-3.04471,   inf] (57), [-3.02723,   inf] (57), [-3.01974,   inf] (57), [-3.01258,   inf] (57), [-2.98935,   inf] (57), [-2.97344,   inf] (57), [-2.97258,   inf] (57), [-2.97101,   inf] (57), [-2.96580,   inf] (57), [-2.96407,   inf] (57), [-2.96335,   inf] (57), [-2.96190,   inf] (57), [-2.95831,   inf] (57), [-2.95359,   inf] (57), [-2.95338,   inf] (57), [-2.95219,   inf] (57), [-2.95062,   inf] (57), [-2.94514,   inf] (57), [-2.94297,   inf] (57), [-2.94240,   inf] (57), 
length of domains: 20595
Total time: 1.7810	 pickout: 0.1622	 decision: 0.2969	 get_bound: 1.0897	 add_domain: 0.2323
Current lb:-3.044705390930176
42366 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 43.35033106803894

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 913] [1, 913] [1, 913] [1, 67] [1, 67] [1, 122] [1, 913] [1, 67] [1, 913] [1, 913] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5379.62744140625 with beta sum per layer: [10.596999168395996, 1449.9354248046875, 96.1451187133789]
alpha/beta optimization time: 0.6901340484619141
This batch time : update_bounds func: 1.5045	 prepare: 0.2152	 bound: 0.6905	 transfer: 0.0546	 finalize: 0.1291
Accumulated time: update_bounds func: 25.6391	 prepare: 4.2706	 bound: 15.9856	 transfer: 0.0546	 finalize: 3.6846
batch bounding time:  1.5063209533691406
Current worst splitting domains [lb, ub] (depth):
[-3.01513,   inf] (59), [-2.99676,   inf] (59), [-2.98975,   inf] (59), [-2.98795,   inf] (59), [-2.97697,   inf] (59), [-2.95245,   inf] (59), [-2.94555,   inf] (59), [-2.94352,   inf] (59), [-2.93924,   inf] (59), [-2.93829,   inf] (59), [-2.93809,   inf] (59), [-2.93673,   inf] (59), [-2.93353,   inf] (59), [-2.93290,   inf] (59), [-2.93098,   inf] (59), [-2.93097,   inf] (59), [-2.93045,   inf] (59), [-2.92976,   inf] (59), [-2.92415,   inf] (59), [-2.92299,   inf] (59), 
length of domains: 21619
Total time: 2.2047	 pickout: 0.1621	 decision: 0.2936	 get_bound: 1.5095	 add_domain: 0.2396
Current lb:-3.0151329040527344
44414 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 45.578871965408325

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 1060] [1, 1060] [1, 1060] [1, 122] [1, 1060] [1, 1060] [1, 1060] [1, 122] [1, 1060] [1, 913] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5435.6572265625 with beta sum per layer: [14.711111068725586, 1128.238525390625, 97.99336242675781]
alpha/beta optimization time: 0.6839964389801025
This batch time : update_bounds func: 1.0869	 prepare: 0.2173	 bound: 0.6843	 transfer: 0.0532	 finalize: 0.1270
Accumulated time: update_bounds func: 26.7260	 prepare: 4.4879	 bound: 16.6699	 transfer: 0.0532	 finalize: 3.8116
batch bounding time:  1.0886995792388916
Current worst splitting domains [lb, ub] (depth):
[-2.99425,   inf] (61), [-2.97620,   inf] (61), [-2.96659,   inf] (61), [-2.95304,   inf] (61), [-2.93919,   inf] (61), [-2.93050,   inf] (61), [-2.92800,   inf] (61), [-2.92273,   inf] (61), [-2.91778,   inf] (61), [-2.91503,   inf] (61), [-2.91181,   inf] (61), [-2.90920,   inf] (61), [-2.90919,   inf] (61), [-2.90766,   inf] (61), [-2.90607,   inf] (61), [-2.90594,   inf] (61), [-2.90540,   inf] (61), [-2.89959,   inf] (61), [-2.89502,   inf] (61), [-2.89465,   inf] (61), 
length of domains: 22643
Total time: 2.2373	 pickout: 0.1625	 decision: 0.2946	 get_bound: 1.0919	 add_domain: 0.6884
Current lb:-2.9942498207092285
46462 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 47.839319467544556

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 122] [1, 122] [1, 122] [1, 611] [1, 611] [1, 611] [1, 122] [1, 122] [1, 122] [1, 122] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5365.779296875 with beta sum per layer: [20.85946273803711, 1184.2003173828125, 89.47882843017578]
alpha/beta optimization time: 0.6844515800476074
This batch time : update_bounds func: 1.0928	 prepare: 0.2216	 bound: 0.6848	 transfer: 0.0546	 finalize: 0.1265
Accumulated time: update_bounds func: 27.8188	 prepare: 4.7095	 bound: 17.3547	 transfer: 0.0546	 finalize: 3.9381
batch bounding time:  1.0946002006530762
Current worst splitting domains [lb, ub] (depth):
[-2.95161,   inf] (63), [-2.94428,   inf] (63), [-2.93508,   inf] (63), [-2.92916,   inf] (63), [-2.92809,   inf] (63), [-2.92325,   inf] (63), [-2.91760,   inf] (63), [-2.91554,   inf] (63), [-2.90592,   inf] (63), [-2.90533,   inf] (63), [-2.89538,   inf] (63), [-2.89416,   inf] (63), [-2.88988,   inf] (63), [-2.88719,   inf] (63), [-2.88480,   inf] (63), [-2.88345,   inf] (63), [-2.88173,   inf] (63), [-2.88033,   inf] (63), [-2.88007,   inf] (63), [-2.87858,   inf] (63), 
length of domains: 23667
Total time: 1.8090	 pickout: 0.1636	 decision: 0.2945	 get_bound: 1.0977	 add_domain: 0.2532
Current lb:-2.951613426208496
48510 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 49.671992778778076

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 59] [1, 913] [1, 59] [1, 913] [1, 59] [1, 59] [1, 913] [1, 59] [1, 59] [1, 67] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5334.6083984375 with beta sum per layer: [22.44955825805664, 1245.02880859375, 89.43416595458984]
alpha/beta optimization time: 0.6798896789550781
This batch time : update_bounds func: 1.5640	 prepare: 0.2192	 bound: 0.6802	 transfer: 0.0545	 finalize: 0.6047
Accumulated time: update_bounds func: 29.3828	 prepare: 4.9287	 bound: 18.0349	 transfer: 0.0545	 finalize: 4.5427
batch bounding time:  1.565870761871338
Current worst splitting domains [lb, ub] (depth):
[-2.91732,   inf] (65), [-2.91474,   inf] (65), [-2.90670,   inf] (65), [-2.90068,   inf] (65), [-2.90032,   inf] (65), [-2.89321,   inf] (65), [-2.89213,   inf] (65), [-2.89005,   inf] (65), [-2.88982,   inf] (65), [-2.88829,   inf] (65), [-2.88677,   inf] (65), [-2.88581,   inf] (65), [-2.88554,   inf] (65), [-2.88193,   inf] (65), [-2.88092,   inf] (65), [-2.87410,   inf] (65), [-2.87340,   inf] (65), [-2.86995,   inf] (65), [-2.86935,   inf] (65), [-2.86580,   inf] (65), 
length of domains: 24691
Total time: 2.2875	 pickout: 0.1650	 decision: 0.2958	 get_bound: 1.5691	 add_domain: 0.2576
Current lb:-2.917318344116211
50558 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 51.98341751098633

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 550] [0, 1518] [1, 550] [1, 550] [0, 1518] [1, 611] [1, 550] [1, 550] [1, 611] [1, 550] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5358.5263671875 with beta sum per layer: [41.389122009277344, 1225.5809326171875, 59.72321319580078]
alpha/beta optimization time: 0.6836833953857422
This batch time : update_bounds func: 1.0921	 prepare: 0.2202	 bound: 0.6840	 transfer: 0.0559	 finalize: 0.1266
Accumulated time: update_bounds func: 30.4749	 prepare: 5.1489	 bound: 18.7190	 transfer: 0.0559	 finalize: 4.6694
batch bounding time:  1.0938975811004639
Current worst splitting domains [lb, ub] (depth):
[-2.91310,   inf] (67), [-2.89974,   inf] (67), [-2.89118,   inf] (67), [-2.88638,   inf] (67), [-2.88135,   inf] (67), [-2.87954,   inf] (67), [-2.87771,   inf] (67), [-2.87629,   inf] (67), [-2.86672,   inf] (67), [-2.86415,   inf] (67), [-2.86393,   inf] (67), [-2.86384,   inf] (67), [-2.86133,   inf] (67), [-2.85849,   inf] (67), [-2.85721,   inf] (67), [-2.85505,   inf] (67), [-2.85428,   inf] (67), [-2.85139,   inf] (67), [-2.85130,   inf] (67), [-2.84705,   inf] (67), 
length of domains: 25715
Total time: 1.8205	 pickout: 0.1655	 decision: 0.2947	 get_bound: 1.0971	 add_domain: 0.2631
Current lb:-2.9130964279174805
52606 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 53.82798099517822

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 550] [1, 550] [0, 1518] [1, 550] [1, 550] [0, 1518] [1, 550] [0, 1518] [1, 550] [0, 1518] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5297.3974609375 with beta sum per layer: [33.427734375, 1320.7755126953125, 55.77552032470703]
alpha/beta optimization time: 0.6809544563293457
This batch time : update_bounds func: 1.6006	 prepare: 0.2206	 bound: 0.6813	 transfer: 0.0532	 finalize: 0.1293
Accumulated time: update_bounds func: 32.0755	 prepare: 5.3696	 bound: 19.4002	 transfer: 0.0532	 finalize: 4.7987
batch bounding time:  1.6024720668792725
Current worst splitting domains [lb, ub] (depth):
[-2.89111,   inf] (69), [-2.88784,   inf] (69), [-2.87947,   inf] (69), [-2.87546,   inf] (69), [-2.87389,   inf] (69), [-2.86377,   inf] (69), [-2.86258,   inf] (69), [-2.86098,   inf] (69), [-2.86079,   inf] (69), [-2.85749,   inf] (69), [-2.85689,   inf] (69), [-2.85340,   inf] (69), [-2.85305,   inf] (69), [-2.84602,   inf] (69), [-2.84331,   inf] (69), [-2.83756,   inf] (69), [-2.83627,   inf] (69), [-2.83522,   inf] (69), [-2.83083,   inf] (69), [-2.82620,   inf] (69), 
length of domains: 26739
Total time: 2.3329	 pickout: 0.1641	 decision: 0.2961	 get_bound: 1.6057	 add_domain: 0.2670
Current lb:-2.891112804412842
54654 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 56.183614015579224

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 25] [1, 59] [1, 25] [1, 25] [1, 59] [1, 25] [1, 25] [1, 59] [1, 25] [1, 59] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5289.84033203125 with beta sum per layer: [24.074607849121094, 1191.1214599609375, 67.06226348876953]
alpha/beta optimization time: 0.6783561706542969
This batch time : update_bounds func: 1.0877	 prepare: 0.2179	 bound: 0.6787	 transfer: 0.0546	 finalize: 0.1310
Accumulated time: update_bounds func: 33.1632	 prepare: 5.5875	 bound: 20.0789	 transfer: 0.0546	 finalize: 4.9297
batch bounding time:  1.0895814895629883
Current worst splitting domains [lb, ub] (depth):
[-2.88664,   inf] (71), [-2.87547,   inf] (71), [-2.87124,   inf] (71), [-2.85969,   inf] (71), [-2.85721,   inf] (71), [-2.85571,   inf] (71), [-2.85520,   inf] (71), [-2.85154,   inf] (71), [-2.84695,   inf] (71), [-2.84116,   inf] (71), [-2.84103,   inf] (71), [-2.84045,   inf] (71), [-2.83876,   inf] (71), [-2.83243,   inf] (71), [-2.82898,   inf] (71), [-2.82778,   inf] (71), [-2.82773,   inf] (71), [-2.82706,   inf] (71), [-2.82145,   inf] (71), [-2.81567,   inf] (71), 
length of domains: 27763
Total time: 1.8291	 pickout: 0.1673	 decision: 0.2980	 get_bound: 1.0928	 add_domain: 0.2710
Current lb:-2.886640787124634
56702 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 58.035956144332886

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 940] [1, 940] [1, 940] [1, 940] [1, 940] [1, 940] [1, 1046] [1, 940] [1, 940] [1, 1046] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5182.296875 with beta sum per layer: [22.308555603027344, 1458.444091796875, 66.63603973388672]
alpha/beta optimization time: 0.6791503429412842
This batch time : update_bounds func: 1.0880	 prepare: 0.2174	 bound: 0.6795	 transfer: 0.0540	 finalize: 0.1312
Accumulated time: update_bounds func: 34.2512	 prepare: 5.8049	 bound: 20.7584	 transfer: 0.0540	 finalize: 5.0609
batch bounding time:  1.0898408889770508
Current worst splitting domains [lb, ub] (depth):
[-2.86667,   inf] (73), [-2.84977,   inf] (73), [-2.84867,   inf] (73), [-2.84441,   inf] (73), [-2.84003,   inf] (73), [-2.83767,   inf] (73), [-2.83560,   inf] (73), [-2.83280,   inf] (73), [-2.82967,   inf] (73), [-2.82760,   inf] (73), [-2.82544,   inf] (73), [-2.82227,   inf] (73), [-2.81934,   inf] (73), [-2.81912,   inf] (73), [-2.81830,   inf] (73), [-2.81614,   inf] (73), [-2.81590,   inf] (73), [-2.81589,   inf] (73), [-2.81394,   inf] (73), [-2.81364,   inf] (73), 
length of domains: 28787
Total time: 2.3927	 pickout: 0.1680	 decision: 0.8565	 get_bound: 1.0930	 add_domain: 0.2752
Current lb:-2.8666720390319824
58750 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 60.45719361305237

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 1046] [1, 1046] [1, 1046] [1, 25] [1, 1046] [1, 1046] [1, 1046] [1, 1046] [1, 25] [1, 25] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5014.71875 with beta sum per layer: [21.427600860595703, 1775.535400390625, 51.761940002441406]
alpha/beta optimization time: 0.6853692531585693
This batch time : update_bounds func: 1.0968	 prepare: 0.2209	 bound: 0.6857	 transfer: 0.0547	 finalize: 0.1300
Accumulated time: update_bounds func: 35.3480	 prepare: 6.0258	 bound: 21.4441	 transfer: 0.0547	 finalize: 5.1909
batch bounding time:  1.0986671447753906
Current worst splitting domains [lb, ub] (depth):
[-2.84263,   inf] (75), [-2.84089,   inf] (75), [-2.83491,   inf] (75), [-2.82887,   inf] (75), [-2.82629,   inf] (75), [-2.82448,   inf] (75), [-2.82015,   inf] (75), [-2.81940,   inf] (75), [-2.81382,   inf] (75), [-2.81147,   inf] (75), [-2.81103,   inf] (75), [-2.81087,   inf] (75), [-2.81049,   inf] (75), [-2.79871,   inf] (75), [-2.79738,   inf] (75), [-2.79733,   inf] (75), [-2.79688,   inf] (75), [-2.79500,   inf] (75), [-2.79495,   inf] (75), [-2.79271,   inf] (75), 
length of domains: 29811
Total time: 1.8521	 pickout: 0.1667	 decision: 0.2994	 get_bound: 1.1019	 add_domain: 0.2841
Current lb:-2.8426260948181152
60798 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 62.33479619026184

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 67] [1, 940] [1, 67] [1, 67] [1, 940] [1, 940] [1, 67] [1, 67] [1, 67] [1, 67] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5191.482421875 with beta sum per layer: [22.512008666992188, 1379.896484375, 62.11491394042969]
alpha/beta optimization time: 0.6834430694580078
This batch time : update_bounds func: 1.0988	 prepare: 0.2236	 bound: 0.6838	 transfer: 0.0546	 finalize: 0.1308
Accumulated time: update_bounds func: 36.4467	 prepare: 6.2494	 bound: 22.1280	 transfer: 0.0546	 finalize: 5.3217
batch bounding time:  1.1006903648376465
Current worst splitting domains [lb, ub] (depth):
[-2.82268,   inf] (77), [-2.82011,   inf] (77), [-2.82001,   inf] (77), [-2.81050,   inf] (77), [-2.80966,   inf] (77), [-2.80526,   inf] (77), [-2.80193,   inf] (77), [-2.80059,   inf] (77), [-2.80034,   inf] (77), [-2.79290,   inf] (77), [-2.79267,   inf] (77), [-2.79178,   inf] (77), [-2.78743,   inf] (77), [-2.78504,   inf] (77), [-2.77910,   inf] (77), [-2.77808,   inf] (77), [-2.77750,   inf] (77), [-2.77701,   inf] (77), [-2.77584,   inf] (77), [-2.77390,   inf] (77), 
length of domains: 30835
Total time: 2.4732	 pickout: 0.1701	 decision: 0.9160	 get_bound: 1.1041	 add_domain: 0.2831
Current lb:-2.8226799964904785
62846 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 64.83803796768188

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [0, 1852] [1, 724] [0, 1852] [0, 1852] [0, 1852] [1, 45] [1, 724] [0, 1852] [0, 1852] [1, 45] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5279.9912109375 with beta sum per layer: [19.147262573242188, 1261.74365234375, 64.3829345703125]
alpha/beta optimization time: 0.6763527393341064
This batch time : update_bounds func: 1.0990	 prepare: 0.2264	 bound: 0.6767	 transfer: 0.0556	 finalize: 0.1344
Accumulated time: update_bounds func: 37.5457	 prepare: 6.4758	 bound: 22.8047	 transfer: 0.0556	 finalize: 5.4561
batch bounding time:  1.1009671688079834
Current worst splitting domains [lb, ub] (depth):
[-2.82078,   inf] (79), [-2.81815,   inf] (79), [-2.80952,   inf] (79), [-2.80894,   inf] (79), [-2.79939,   inf] (79), [-2.79904,   inf] (79), [-2.79900,   inf] (79), [-2.79148,   inf] (79), [-2.78704,   inf] (79), [-2.78553,   inf] (79), [-2.78268,   inf] (79), [-2.78040,   inf] (79), [-2.77935,   inf] (79), [-2.77735,   inf] (79), [-2.77674,   inf] (79), [-2.77454,   inf] (79), [-2.77416,   inf] (79), [-2.77392,   inf] (79), [-2.77332,   inf] (79), [-2.76973,   inf] (79), 
length of domains: 31859
Total time: 1.8597	 pickout: 0.1675	 decision: 0.3002	 get_bound: 1.1041	 add_domain: 0.2878
Current lb:-2.820779323577881
64894 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 66.7273440361023

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 724] [1, 724] [1, 45] [1, 45] [1, 45] [1, 45] [1, 45] [0, 1852] [1, 724] [1, 724] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5293.33056640625 with beta sum per layer: [16.822799682617188, 1178.3427734375, 61.98666000366211]
alpha/beta optimization time: 0.6787219047546387
This batch time : update_bounds func: 1.1186	 prepare: 0.2446	 bound: 0.6791	 transfer: 0.0552	 finalize: 0.1341
Accumulated time: update_bounds func: 38.6643	 prepare: 6.7204	 bound: 23.4837	 transfer: 0.0552	 finalize: 5.5902
batch bounding time:  1.1205105781555176
Current worst splitting domains [lb, ub] (depth):
[-2.79553,   inf] (81), [-2.79533,   inf] (81), [-2.79259,   inf] (81), [-2.79087,   inf] (81), [-2.79045,   inf] (81), [-2.78544,   inf] (81), [-2.78512,   inf] (81), [-2.78261,   inf] (81), [-2.77872,   inf] (81), [-2.77352,   inf] (81), [-2.77001,   inf] (81), [-2.76912,   inf] (81), [-2.76854,   inf] (81), [-2.76556,   inf] (81), [-2.76369,   inf] (81), [-2.76324,   inf] (81), [-2.76304,   inf] (81), [-2.76232,   inf] (81), [-2.76160,   inf] (81), [-2.76092,   inf] (81), 
length of domains: 32883
Total time: 2.5581	 pickout: 0.1675	 decision: 0.9746	 get_bound: 1.1238	 add_domain: 0.2923
Current lb:-2.795530319213867
66942 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 69.31365633010864

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 724] [1, 724] [1, 45] [1, 45] [1, 724] [1, 724] [1, 724] [0, 1852] [1, 724] [1, 724] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5275.3193359375 with beta sum per layer: [15.011073112487793, 1069.360595703125, 60.20859146118164]
alpha/beta optimization time: 0.6803293228149414
This batch time : update_bounds func: 1.1078	 prepare: 0.2331	 bound: 0.6808	 transfer: 0.0546	 finalize: 0.1335
Accumulated time: update_bounds func: 39.7721	 prepare: 6.9536	 bound: 24.1645	 transfer: 0.0546	 finalize: 5.7237
batch bounding time:  1.1097393035888672
Current worst splitting domains [lb, ub] (depth):
[-2.77933,   inf] (83), [-2.77855,   inf] (83), [-2.77690,   inf] (83), [-2.77023,   inf] (83), [-2.76797,   inf] (83), [-2.76795,   inf] (83), [-2.76261,   inf] (83), [-2.75979,   inf] (83), [-2.75979,   inf] (83), [-2.75888,   inf] (83), [-2.75445,   inf] (83), [-2.75131,   inf] (83), [-2.74952,   inf] (83), [-2.74705,   inf] (83), [-2.74678,   inf] (83), [-2.74530,   inf] (83), [-2.74510,   inf] (83), [-2.74460,   inf] (83), [-2.74363,   inf] (83), [-2.74355,   inf] (83), 
length of domains: 33907
Total time: 1.8812	 pickout: 0.1692	 decision: 0.3022	 get_bound: 1.1132	 add_domain: 0.2966
Current lb:-2.779332160949707
68990 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 71.22313690185547

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [0, 453] [1, 23] [1, 23] [0, 453] [1, 23] [1, 23] [0, 453] [0, 453] [1, 23] [1, 23] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5187.92138671875 with beta sum per layer: [15.850349426269531, 930.2095336914062, 107.60289001464844]
alpha/beta optimization time: 0.6809089183807373
This batch time : update_bounds func: 1.8233	 prepare: 0.2286	 bound: 0.6813	 transfer: 0.0538	 finalize: 0.8538
Accumulated time: update_bounds func: 41.5954	 prepare: 7.1821	 bound: 24.8458	 transfer: 0.0538	 finalize: 6.5775
batch bounding time:  1.825239896774292
Current worst splitting domains [lb, ub] (depth):
[-2.76100,   inf] (85), [-2.75993,   inf] (85), [-2.75895,   inf] (85), [-2.75600,   inf] (85), [-2.75558,   inf] (85), [-2.75501,   inf] (85), [-2.75455,   inf] (85), [-2.75128,   inf] (85), [-2.75086,   inf] (85), [-2.75053,   inf] (85), [-2.74539,   inf] (85), [-2.74487,   inf] (85), [-2.74471,   inf] (85), [-2.74314,   inf] (85), [-2.74099,   inf] (85), [-2.74006,   inf] (85), [-2.73977,   inf] (85), [-2.73960,   inf] (85), [-2.73766,   inf] (85), [-2.73656,   inf] (85), 
length of domains: 34931
Total time: 2.6040	 pickout: 0.1711	 decision: 0.3030	 get_bound: 1.8287	 add_domain: 0.3012
Current lb:-2.760997772216797
71038 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 73.85496163368225

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 80] [2, 61] [1, 80] [2, 61] [1, 80] [2, 61] [1, 80] [1, 80] [1, 80] [2, 61] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 4766.158203125 with beta sum per layer: [16.82836151123047, 776.5306396484375, 286.28656005859375]
alpha/beta optimization time: 0.6831402778625488
This batch time : update_bounds func: 1.1067	 prepare: 0.2301	 bound: 0.6835	 transfer: 0.0545	 finalize: 0.1326
Accumulated time: update_bounds func: 42.7020	 prepare: 7.4123	 bound: 25.5293	 transfer: 0.0545	 finalize: 6.7101
batch bounding time:  1.1086602210998535
Current worst splitting domains [lb, ub] (depth):
[-2.74759,   inf] (87), [-2.74759,   inf] (87), [-2.74710,   inf] (87), [-2.74571,   inf] (87), [-2.74419,   inf] (87), [-2.74324,   inf] (87), [-2.74288,   inf] (87), [-2.74096,   inf] (87), [-2.73610,   inf] (87), [-2.73576,   inf] (87), [-2.73458,   inf] (87), [-2.73144,   inf] (87), [-2.73139,   inf] (87), [-2.73127,   inf] (87), [-2.73079,   inf] (87), [-2.73026,   inf] (87), [-2.72663,   inf] (87), [-2.72653,   inf] (87), [-2.72444,   inf] (87), [-2.72409,   inf] (87), 
length of domains: 35955
Total time: 1.9029	 pickout: 0.1770	 decision: 0.3029	 get_bound: 1.1121	 add_domain: 0.3110
Current lb:-2.747593641281128
73086 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 75.7864248752594

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 157] [0, 453] [1, 157] [0, 453] [0, 453] [0, 453] [1, 157] [1, 157] [2, 61] [2, 61] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 4874.58154296875 with beta sum per layer: [19.777420043945312, 927.3316040039062, 235.11544799804688]
alpha/beta optimization time: 0.6822946071624756
This batch time : update_bounds func: 1.1164	 prepare: 0.2401	 bound: 0.6826	 transfer: 0.0546	 finalize: 0.1329
Accumulated time: update_bounds func: 43.8184	 prepare: 7.6523	 bound: 26.2119	 transfer: 0.0546	 finalize: 6.8430
batch bounding time:  1.118293285369873
Current worst splitting domains [lb, ub] (depth):
[-2.72868,   inf] (89), [-2.72840,   inf] (89), [-2.72738,   inf] (89), [-2.72701,   inf] (89), [-2.72652,   inf] (89), [-2.72621,   inf] (89), [-2.72590,   inf] (89), [-2.72469,   inf] (89), [-2.72459,   inf] (89), [-2.72361,   inf] (89), [-2.72292,   inf] (89), [-2.72273,   inf] (89), [-2.72220,   inf] (89), [-2.72170,   inf] (89), [-2.72145,   inf] (89), [-2.72121,   inf] (89), [-2.71977,   inf] (89), [-2.71834,   inf] (89), [-2.71806,   inf] (89), [-2.71789,   inf] (89), 
length of domains: 36979
Total time: 2.6957	 pickout: 0.1717	 decision: 0.3024	 get_bound: 1.1216	 add_domain: 1.1001
Current lb:-2.7286839485168457
75134 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 78.50995421409607

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [2, 61] [0, 2454] [0, 453] [0, 440] [0, 453] [2, 61] [0, 453] [2, 61] [0, 440] [2, 61] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 4956.3935546875 with beta sum per layer: [22.196521759033203, 988.5452880859375, 191.13526916503906]
alpha/beta optimization time: 0.6816508769989014
This batch time : update_bounds func: 1.1021	 prepare: 0.2243	 bound: 0.6820	 transfer: 0.0546	 finalize: 0.1346
Accumulated time: update_bounds func: 44.9205	 prepare: 7.8766	 bound: 26.8939	 transfer: 0.0546	 finalize: 6.9776
batch bounding time:  1.1041152477264404
Current worst splitting domains [lb, ub] (depth):
[-2.72786,   inf] (91), [-2.72141,   inf] (91), [-2.71884,   inf] (91), [-2.71653,   inf] (91), [-2.71498,   inf] (91), [-2.71403,   inf] (91), [-2.71348,   inf] (91), [-2.71321,   inf] (91), [-2.71250,   inf] (91), [-2.71248,   inf] (91), [-2.71219,   inf] (91), [-2.71143,   inf] (91), [-2.71075,   inf] (91), [-2.71049,   inf] (91), [-2.71042,   inf] (91), [-2.70959,   inf] (91), [-2.70884,   inf] (91), [-2.70875,   inf] (91), [-2.70858,   inf] (91), [-2.70825,   inf] (91), 
length of domains: 38003
Total time: 1.9004	 pickout: 0.1711	 decision: 0.3038	 get_bound: 1.1075	 add_domain: 0.3179
Current lb:-2.727856397628784
77182 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 80.438884973526

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 23] [1, 23] [1, 23] [1, 23] [0, 440] [1, 23] [1, 1052] [0, 440] [0, 2454] [0, 2454] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5178.6884765625 with beta sum per layer: [20.682798385620117, 958.2116088867188, 102.51244354248047]
alpha/beta optimization time: 0.6820454597473145
This batch time : update_bounds func: 1.0985	 prepare: 0.2230	 bound: 0.6824	 transfer: 0.0539	 finalize: 0.1335
Accumulated time: update_bounds func: 46.0190	 prepare: 8.0996	 bound: 27.5763	 transfer: 0.0539	 finalize: 7.1111
batch bounding time:  1.1004753112792969
Current worst splitting domains [lb, ub] (depth):
[-2.71739,   inf] (93), [-2.71215,   inf] (93), [-2.71090,   inf] (93), [-2.71022,   inf] (93), [-2.71019,   inf] (93), [-2.70993,   inf] (93), [-2.70917,   inf] (93), [-2.70851,   inf] (93), [-2.70795,   inf] (93), [-2.70714,   inf] (93), [-2.70710,   inf] (93), [-2.70636,   inf] (93), [-2.70552,   inf] (93), [-2.70517,   inf] (93), [-2.70466,   inf] (93), [-2.70446,   inf] (93), [-2.70427,   inf] (93), [-2.70343,   inf] (93), [-2.70341,   inf] (93), [-2.70337,   inf] (93), 
length of domains: 39027
Total time: 1.9006	 pickout: 0.1718	 decision: 0.3034	 get_bound: 1.1039	 add_domain: 0.3215
Current lb:-2.717393398284912
79230 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 82.36792850494385

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [0, 440] [1, 408] [0, 2454] [1, 1052] [1, 408] [1, 1052] [0, 2454] [1, 1052] [1, 1052] [1, 1052] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5257.2177734375 with beta sum per layer: [23.21900177001953, 800.103759765625, 69.68096923828125]
alpha/beta optimization time: 0.6797747611999512
This batch time : update_bounds func: 1.9120	 prepare: 0.2233	 bound: 0.6801	 transfer: 0.0546	 finalize: 0.9476
Accumulated time: update_bounds func: 47.9310	 prepare: 8.3229	 bound: 28.2564	 transfer: 0.0546	 finalize: 8.0588
batch bounding time:  1.9139418601989746
Current worst splitting domains [lb, ub] (depth):
[-2.71290,   inf] (95), [-2.70975,   inf] (95), [-2.70873,   inf] (95), [-2.70724,   inf] (95), [-2.70603,   inf] (95), [-2.70373,   inf] (95), [-2.70305,   inf] (95), [-2.70282,   inf] (95), [-2.70202,   inf] (95), [-2.70133,   inf] (95), [-2.70041,   inf] (95), [-2.70023,   inf] (95), [-2.70020,   inf] (95), [-2.70000,   inf] (95), [-2.69923,   inf] (95), [-2.69921,   inf] (95), [-2.69912,   inf] (95), [-2.69856,   inf] (95), [-2.69778,   inf] (95), [-2.69771,   inf] (95), 
length of domains: 40051
Total time: 2.7207	 pickout: 0.1707	 decision: 0.3038	 get_bound: 1.9173	 add_domain: 0.3288
Current lb:-2.712897300720215
81278 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 85.11671733856201

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 408] [1, 408] [1, 718] [1, 718] [1, 408] [1, 718] [1, 408] [1, 1052] [1, 718] [1, 408] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5253.7421875 with beta sum per layer: [33.684471130371094, 792.8258666992188, 54.9354248046875]
alpha/beta optimization time: 0.6805830001831055
This batch time : update_bounds func: 1.0978	 prepare: 0.2246	 bound: 0.6809	 transfer: 0.0545	 finalize: 0.1315
Accumulated time: update_bounds func: 49.0288	 prepare: 8.5475	 bound: 28.9374	 transfer: 0.0545	 finalize: 8.1902
batch bounding time:  1.0997734069824219
Current worst splitting domains [lb, ub] (depth):
[-2.70263,   inf] (97), [-2.70129,   inf] (97), [-2.70063,   inf] (97), [-2.69992,   inf] (97), [-2.69966,   inf] (97), [-2.69809,   inf] (97), [-2.69802,   inf] (97), [-2.69802,   inf] (97), [-2.69680,   inf] (97), [-2.69599,   inf] (97), [-2.69585,   inf] (97), [-2.69554,   inf] (97), [-2.69464,   inf] (97), [-2.69443,   inf] (97), [-2.69441,   inf] (97), [-2.69409,   inf] (97), [-2.69404,   inf] (97), [-2.69336,   inf] (97), [-2.69331,   inf] (97), [-2.69286,   inf] (97), 
length of domains: 41075
Total time: 1.9188	 pickout: 0.1694	 decision: 0.3072	 get_bound: 1.1032	 add_domain: 0.3391
Current lb:-2.702631950378418
83326 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 87.06356358528137

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 1052] [0, 440] [1, 157] [1, 1052] [1, 718] [0, 2454] [1, 157] [1, 718] [1, 1052] [1, 157] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5190.849609375 with beta sum per layer: [41.769287109375, 1031.2099609375, 62.518795013427734]
alpha/beta optimization time: 0.681605339050293
This batch time : update_bounds func: 1.1006	 prepare: 0.2271	 bound: 0.6819	 transfer: 0.0541	 finalize: 0.1314
Accumulated time: update_bounds func: 50.1294	 prepare: 8.7746	 bound: 29.6193	 transfer: 0.0541	 finalize: 8.3217
batch bounding time:  1.102459192276001
Current worst splitting domains [lb, ub] (depth):
[-2.70046,   inf] (99), [-2.69778,   inf] (99), [-2.69765,   inf] (99), [-2.69580,   inf] (99), [-2.69501,   inf] (99), [-2.69484,   inf] (99), [-2.69463,   inf] (99), [-2.69358,   inf] (99), [-2.69188,   inf] (99), [-2.69055,   inf] (99), [-2.69001,   inf] (99), [-2.68995,   inf] (99), [-2.68955,   inf] (99), [-2.68866,   inf] (99), [-2.68798,   inf] (99), [-2.68790,   inf] (99), [-2.68694,   inf] (99), [-2.68625,   inf] (99), [-2.68524,   inf] (99), [-2.68519,   inf] (99), 
length of domains: 42099
Total time: 1.9313	 pickout: 0.1714	 decision: 0.3084	 get_bound: 1.1058	 add_domain: 0.3457
Current lb:-2.7004594802856445
85374 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 89.02389192581177

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 718] [1, 157] [1, 718] [0, 553] [0, 553] [1, 157] [1, 718] [1, 718] [1, 718] [1, 718] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5245.90283203125 with beta sum per layer: [47.20114517211914, 851.3819580078125, 45.19231033325195]
alpha/beta optimization time: 0.6833040714263916
This batch time : update_bounds func: 1.0990	 prepare: 0.2244	 bound: 0.6836	 transfer: 0.0545	 finalize: 0.1306
Accumulated time: update_bounds func: 51.2284	 prepare: 8.9990	 bound: 30.3030	 transfer: 0.0545	 finalize: 8.4523
batch bounding time:  1.1009080410003662
Current worst splitting domains [lb, ub] (depth):
[-2.69535,   inf] (101), [-2.69432,   inf] (101), [-2.69170,   inf] (101), [-2.68949,   inf] (101), [-2.68899,   inf] (101), [-2.68723,   inf] (101), [-2.68410,   inf] (101), [-2.68346,   inf] (101), [-2.68313,   inf] (101), [-2.68259,   inf] (101), [-2.68213,   inf] (101), [-2.68160,   inf] (101), [-2.68091,   inf] (101), [-2.68022,   inf] (101), [-2.67976,   inf] (101), [-2.67908,   inf] (101), [-2.67894,   inf] (101), [-2.67844,   inf] (101), [-2.67830,   inf] (101), [-2.67782,   inf] (101), 
length of domains: 43123
Total time: 2.7786	 pickout: 0.1703	 decision: 1.1584	 get_bound: 1.1043	 add_domain: 0.3456
Current lb:-2.6953487396240234
87422 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 91.83136200904846

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 1208] [1, 1208] [1, 1208] [1, 1208] [1, 1208] [1, 1208] [1, 1208] [1, 1208] [1, 1208] [1, 408] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5205.7373046875 with beta sum per layer: [46.15660858154297, 963.6578979492188, 42.137149810791016]
alpha/beta optimization time: 0.682722806930542
This batch time : update_bounds func: 1.1005	 prepare: 0.2246	 bound: 0.6831	 transfer: 0.0545	 finalize: 0.1325
Accumulated time: update_bounds func: 52.3288	 prepare: 9.2236	 bound: 30.9860	 transfer: 0.0545	 finalize: 8.5848
batch bounding time:  1.1024346351623535
Current worst splitting domains [lb, ub] (depth):
[-2.68798,   inf] (103), [-2.68643,   inf] (103), [-2.68215,   inf] (103), [-2.68175,   inf] (103), [-2.68127,   inf] (103), [-2.67959,   inf] (103), [-2.67680,   inf] (103), [-2.67584,   inf] (103), [-2.67557,   inf] (103), [-2.67547,   inf] (103), [-2.67453,   inf] (103), [-2.67389,   inf] (103), [-2.67203,   inf] (103), [-2.67178,   inf] (103), [-2.67121,   inf] (103), [-2.67112,   inf] (103), [-2.67098,   inf] (103), [-2.67031,   inf] (103), [-2.66984,   inf] (103), [-2.66980,   inf] (103), 
length of domains: 44147
Total time: 1.9263	 pickout: 0.1670	 decision: 0.3022	 get_bound: 1.1059	 add_domain: 0.3513
Current lb:-2.687981128692627
89470 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 93.7876353263855

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 920] [1, 920] [1, 920] [1, 920] [1, 920] [1, 920] [1, 920] [1, 920] [1, 171] [1, 920] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5018.42529296875 with beta sum per layer: [142.17877197265625, 1054.414306640625, 60.19185256958008]
alpha/beta optimization time: 0.6839003562927246
This batch time : update_bounds func: 1.1076	 prepare: 0.2264	 bound: 0.6843	 transfer: 0.0557	 finalize: 0.1349
Accumulated time: update_bounds func: 53.4364	 prepare: 9.4500	 bound: 31.6703	 transfer: 0.0557	 finalize: 8.7197
batch bounding time:  1.1097450256347656
Current worst splitting domains [lb, ub] (depth):
[-2.68500,   inf] (105), [-2.68336,   inf] (105), [-2.67914,   inf] (105), [-2.67844,   inf] (105), [-2.67755,   inf] (105), [-2.67559,   inf] (105), [-2.67379,   inf] (105), [-2.67290,   inf] (105), [-2.67289,   inf] (105), [-2.67154,   inf] (105), [-2.66970,   inf] (105), [-2.66956,   inf] (105), [-2.66893,   inf] (105), [-2.66876,   inf] (105), [-2.66816,   inf] (105), [-2.66727,   inf] (105), [-2.66684,   inf] (105), [-2.66672,   inf] (105), [-2.66642,   inf] (105), [-2.66598,   inf] (105), 
length of domains: 45171
Total time: 2.9335	 pickout: 0.1692	 decision: 0.3031	 get_bound: 1.1134	 add_domain: 1.3478
Current lb:-2.68499755859375
91518 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 96.75262761116028

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 38] [1, 38] [1, 38] [1, 38] [1, 38] [1, 38] [1, 38] [1, 38] [1, 38] [1, 38] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 4922.6083984375 with beta sum per layer: [37.46675491333008, 1111.2462158203125, 60.470375061035156]
alpha/beta optimization time: 0.6823854446411133
This batch time : update_bounds func: 1.1057	 prepare: 0.2270	 bound: 0.6828	 transfer: 0.0551	 finalize: 0.1351
Accumulated time: update_bounds func: 54.5421	 prepare: 9.6769	 bound: 32.3530	 transfer: 0.0551	 finalize: 8.8548
batch bounding time:  1.107633113861084
Current worst splitting domains [lb, ub] (depth):
[-2.68259,   inf] (107), [-2.68011,   inf] (107), [-2.67673,   inf] (107), [-2.67602,   inf] (107), [-2.67484,   inf] (107), [-2.67297,   inf] (107), [-2.67155,   inf] (107), [-2.67072,   inf] (107), [-2.67035,   inf] (107), [-2.66890,   inf] (107), [-2.66692,   inf] (107), [-2.66600,   inf] (107), [-2.66586,   inf] (107), [-2.66496,   inf] (107), [-2.66471,   inf] (107), [-2.66421,   inf] (107), [-2.66366,   inf] (107), [-2.66354,   inf] (107), [-2.66353,   inf] (107), [-2.66328,   inf] (107), 
length of domains: 46195
Total time: 1.9374	 pickout: 0.1725	 decision: 0.3038	 get_bound: 1.1111	 add_domain: 0.3501
Current lb:-2.682589054107666
93566 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 98.72104525566101

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 95] [1, 95] [1, 95] [1, 95] [1, 95] [1, 95] [1, 95] [1, 95] [1, 95] [1, 95] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5035.353515625 with beta sum per layer: [50.59626770019531, 1238.7586669921875, 68.86094665527344]
alpha/beta optimization time: 0.6806676387786865
This batch time : update_bounds func: 1.1054	 prepare: 0.2270	 bound: 0.6810	 transfer: 0.0552	 finalize: 0.1361
Accumulated time: update_bounds func: 55.6475	 prepare: 9.9039	 bound: 33.0341	 transfer: 0.0552	 finalize: 8.9909
batch bounding time:  1.1073665618896484
Current worst splitting domains [lb, ub] (depth):
[-2.67636,   inf] (109), [-2.67366,   inf] (109), [-2.67041,   inf] (109), [-2.66973,   inf] (109), [-2.66763,   inf] (109), [-2.66660,   inf] (109), [-2.66521,   inf] (109), [-2.66408,   inf] (109), [-2.66350,   inf] (109), [-2.66252,   inf] (109), [-2.66003,   inf] (109), [-2.65958,   inf] (109), [-2.65945,   inf] (109), [-2.65833,   inf] (109), [-2.65829,   inf] (109), [-2.65791,   inf] (109), [-2.65756,   inf] (109), [-2.65713,   inf] (109), [-2.65658,   inf] (109), [-2.65588,   inf] (109), 
length of domains: 47219
Total time: 1.9413	 pickout: 0.1715	 decision: 0.3093	 get_bound: 1.1107	 add_domain: 0.3497
Current lb:-2.6763601303100586
95614 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 100.69188261032104

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 416] [1, 416] [1, 416] [1, 416] [1, 416] [1, 416] [1, 416] [1, 416] [1, 416] [1, 416] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5136.8134765625 with beta sum per layer: [42.25301742553711, 1209.637451171875, 55.09162521362305]
alpha/beta optimization time: 0.681220293045044
This batch time : update_bounds func: 1.1005	 prepare: 0.2237	 bound: 0.6816	 transfer: 0.0549	 finalize: 0.1345
Accumulated time: update_bounds func: 56.7481	 prepare: 10.1276	 bound: 33.7157	 transfer: 0.0549	 finalize: 9.1254
batch bounding time:  1.1024422645568848
Current worst splitting domains [lb, ub] (depth):
[-2.67046,   inf] (111), [-2.66933,   inf] (111), [-2.66563,   inf] (111), [-2.66430,   inf] (111), [-2.66349,   inf] (111), [-2.66231,   inf] (111), [-2.65957,   inf] (111), [-2.65880,   inf] (111), [-2.65858,   inf] (111), [-2.65768,   inf] (111), [-2.65602,   inf] (111), [-2.65529,   inf] (111), [-2.65412,   inf] (111), [-2.65387,   inf] (111), [-2.65385,   inf] (111), [-2.65380,   inf] (111), [-2.65337,   inf] (111), [-2.65245,   inf] (111), [-2.65158,   inf] (111), [-2.65139,   inf] (111), 
length of domains: 48243
Total time: 1.9261	 pickout: 0.1673	 decision: 0.3042	 get_bound: 1.1058	 add_domain: 0.3488
Current lb:-2.6704626083374023
97662 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 102.64722418785095

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 144] [1, 144] [1, 144] [1, 144] [1, 144] [1, 144] [1, 144] [1, 144] [1, 144] [1, 144] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5151.107421875 with beta sum per layer: [40.73938751220703, 1239.365234375, 78.94140625]
alpha/beta optimization time: 0.6882505416870117
This batch time : update_bounds func: 1.1757	 prepare: 0.2866	 bound: 0.6887	 transfer: 0.0554	 finalize: 0.1378
Accumulated time: update_bounds func: 57.9238	 prepare: 10.4143	 bound: 34.4043	 transfer: 0.0554	 finalize: 9.2632
batch bounding time:  1.1777162551879883
Current worst splitting domains [lb, ub] (depth):
[-2.65970,   inf] (113), [-2.65897,   inf] (113), [-2.65518,   inf] (113), [-2.65369,   inf] (113), [-2.65289,   inf] (113), [-2.65112,   inf] (113), [-2.64962,   inf] (113), [-2.64894,   inf] (113), [-2.64847,   inf] (113), [-2.64826,   inf] (113), [-2.64738,   inf] (113), [-2.64732,   inf] (113), [-2.64656,   inf] (113), [-2.64542,   inf] (113), [-2.64497,   inf] (113), [-2.64466,   inf] (113), [-2.64450,   inf] (113), [-2.64359,   inf] (113), [-2.64352,   inf] (113), [-2.64342,   inf] (113), 
length of domains: 49267
Total time: 3.7068	 pickout: 0.1693	 decision: 2.0086	 get_bound: 1.1812	 add_domain: 0.3477
Current lb:-2.659700393676758
99710 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 106.3855369091034

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 1215] [1, 1215] [1, 1215] [1, 1215] [1, 1215] [1, 1215] [0, 553] [1, 1215] [0, 1337] [1, 1215] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5103.2470703125 with beta sum per layer: [52.826393127441406, 1246.412109375, 79.23056030273438]
alpha/beta optimization time: 0.6971695423126221
This batch time : update_bounds func: 1.1369	 prepare: 0.2309	 bound: 0.6976	 transfer: 0.0554	 finalize: 0.1469
Accumulated time: update_bounds func: 59.0607	 prepare: 10.6451	 bound: 35.1019	 transfer: 0.0554	 finalize: 9.4101
batch bounding time:  1.1389617919921875
Current worst splitting domains [lb, ub] (depth):
[-2.65298,   inf] (115), [-2.65233,   inf] (115), [-2.64865,   inf] (115), [-2.64696,   inf] (115), [-2.64611,   inf] (115), [-2.64464,   inf] (115), [-2.64283,   inf] (115), [-2.64204,   inf] (115), [-2.64094,   inf] (115), [-2.64069,   inf] (115), [-2.64022,   inf] (115), [-2.64008,   inf] (115), [-2.63856,   inf] (115), [-2.63837,   inf] (115), [-2.63830,   inf] (115), [-2.63719,   inf] (115), [-2.63705,   inf] (115), [-2.63690,   inf] (115), [-2.63689,   inf] (115), [-2.63672,   inf] (115), 
length of domains: 50291
Total time: 1.9898	 pickout: 0.1750	 decision: 0.3129	 get_bound: 1.1424	 add_domain: 0.3596
Current lb:-2.652977466583252
101758 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 108.42643284797668

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [0, 1296] [0, 1296] [0, 1296] [0, 1296] [0, 1296] [0, 1296] [1, 1215] [0, 1296] [1, 1215] [0, 1296] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5118.6357421875 with beta sum per layer: [45.904415130615234, 1190.4256591796875, 77.90147399902344]
alpha/beta optimization time: 0.6817598342895508
This batch time : update_bounds func: 1.1585	 prepare: 0.2710	 bound: 0.6821	 transfer: 0.0548	 finalize: 0.1429
Accumulated time: update_bounds func: 60.2192	 prepare: 10.9161	 bound: 35.7840	 transfer: 0.0548	 finalize: 9.5530
batch bounding time:  1.1604864597320557
Current worst splitting domains [lb, ub] (depth):
[-2.65294,   inf] (117), [-2.65208,   inf] (117), [-2.64861,   inf] (117), [-2.64691,   inf] (117), [-2.64604,   inf] (117), [-2.64459,   inf] (117), [-2.64201,   inf] (117), [-2.64065,   inf] (117), [-2.64017,   inf] (117), [-2.64004,   inf] (117), [-2.63852,   inf] (117), [-2.63715,   inf] (117), [-2.63705,   inf] (117), [-2.63701,   inf] (117), [-2.63685,   inf] (117), [-2.63596,   inf] (117), [-2.63571,   inf] (117), [-2.63522,   inf] (117), [-2.63518,   inf] (117), [-2.63436,   inf] (117), 
length of domains: 51315
Total time: 2.0347	 pickout: 0.1947	 decision: 0.3125	 get_bound: 1.1643	 add_domain: 0.3632
Current lb:-2.6529383659362793
103806 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 110.49686408042908

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [0, 553] [0, 553] [0, 1323] [0, 553] [0, 553] [0, 553] [0, 553] [0, 553] [0, 553] [0, 553] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5093.900390625 with beta sum per layer: [46.628746032714844, 1232.2786865234375, 83.22618103027344]
alpha/beta optimization time: 0.6838467121124268
This batch time : update_bounds func: 1.1213	 prepare: 0.2382	 bound: 0.6842	 transfer: 0.0561	 finalize: 0.1359
Accumulated time: update_bounds func: 61.3405	 prepare: 11.1544	 bound: 36.4682	 transfer: 0.0561	 finalize: 9.6889
batch bounding time:  1.1233036518096924
Current worst splitting domains [lb, ub] (depth):
[-2.64845,   inf] (119), [-2.63884,   inf] (119), [-2.63868,   inf] (119), [-2.63566,   inf] (119), [-2.63546,   inf] (119), [-2.63458,   inf] (119), [-2.63419,   inf] (119), [-2.63286,   inf] (119), [-2.63236,   inf] (119), [-2.63167,   inf] (119), [-2.63167,   inf] (119), [-2.63147,   inf] (119), [-2.63131,   inf] (119), [-2.62981,   inf] (119), [-2.62924,   inf] (119), [-2.62885,   inf] (119), [-2.62874,   inf] (119), [-2.62851,   inf] (119), [-2.62796,   inf] (119), [-2.62783,   inf] (119), 
length of domains: 52339
Total time: 3.2299	 pickout: 0.1898	 decision: 1.5670	 get_bound: 1.1267	 add_domain: 0.3463
Current lb:-2.6484460830688477
105854 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 113.76211524009705

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [0, 553] [0, 457] [0, 457] [0, 553] [0, 457] [0, 457] [0, 553] [0, 457] [0, 553] [0, 457] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5123.66064453125 with beta sum per layer: [42.84165954589844, 1224.628173828125, 73.43416595458984]
alpha/beta optimization time: 0.6842224597930908
This batch time : update_bounds func: 1.1236	 prepare: 0.2324	 bound: 0.6846	 transfer: 0.0556	 finalize: 0.1445
Accumulated time: update_bounds func: 62.4641	 prepare: 11.3868	 bound: 37.1528	 transfer: 0.0556	 finalize: 9.8334
batch bounding time:  1.125511646270752
Current worst splitting domains [lb, ub] (depth):
[-2.63502,   inf] (121), [-2.63478,   inf] (121), [-2.63405,   inf] (121), [-2.63184,   inf] (121), [-2.63103,   inf] (121), [-2.63050,   inf] (121), [-2.63040,   inf] (121), [-2.62990,   inf] (121), [-2.62846,   inf] (121), [-2.62819,   inf] (121), [-2.62698,   inf] (121), [-2.62695,   inf] (121), [-2.62646,   inf] (121), [-2.62635,   inf] (121), [-2.62556,   inf] (121), [-2.62541,   inf] (121), [-2.62481,   inf] (121), [-2.62390,   inf] (121), [-2.62377,   inf] (121), [-2.62359,   inf] (121), 
length of domains: 53363
Total time: 1.9903	 pickout: 0.1863	 decision: 0.3136	 get_bound: 1.1289	 add_domain: 0.3615
Current lb:-2.6350200176239014
107902 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 115.79368138313293

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [0, 484] [0, 484] [0, 484] [0, 484] [0, 484] [0, 484] [0, 484] [0, 484] [0, 484] [0, 484] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5093.5458984375 with beta sum per layer: [51.357730865478516, 1187.5306396484375, 83.49003601074219]
alpha/beta optimization time: 0.6825988292694092
This batch time : update_bounds func: 1.1281	 prepare: 0.2336	 bound: 0.6830	 transfer: 0.0549	 finalize: 0.1492
Accumulated time: update_bounds func: 63.5922	 prepare: 11.6204	 bound: 37.8358	 transfer: 0.0549	 finalize: 9.9826
batch bounding time:  1.1302738189697266
Current worst splitting domains [lb, ub] (depth):
[-2.63070,   inf] (123), [-2.63067,   inf] (123), [-2.62959,   inf] (123), [-2.62834,   inf] (123), [-2.62789,   inf] (123), [-2.62674,   inf] (123), [-2.62601,   inf] (123), [-2.62484,   inf] (123), [-2.62371,   inf] (123), [-2.62308,   inf] (123), [-2.62306,   inf] (123), [-2.62298,   inf] (123), [-2.62245,   inf] (123), [-2.62198,   inf] (123), [-2.62155,   inf] (123), [-2.62113,   inf] (123), [-2.62084,   inf] (123), [-2.62082,   inf] (123), [-2.61990,   inf] (123), [-2.61948,   inf] (123), 
length of domains: 54387
Total time: 2.0064	 pickout: 0.1906	 decision: 0.3172	 get_bound: 1.1341	 add_domain: 0.3646
Current lb:-2.6306967735290527
109950 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 117.83613538742065

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 171] [1, 171] [1, 171] [1, 171] [1, 171] [1, 171] [1, 171] [1, 171] [1, 171] [1, 171] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5079.10986328125 with beta sum per layer: [52.58861541748047, 1232.55615234375, 84.35802459716797]
alpha/beta optimization time: 0.6834404468536377
This batch time : update_bounds func: 2.4398	 prepare: 0.2289	 bound: 0.6838	 transfer: 0.0546	 finalize: 1.4651
Accumulated time: update_bounds func: 66.0320	 prepare: 11.8492	 bound: 38.5196	 transfer: 0.0546	 finalize: 11.4477
batch bounding time:  2.4419617652893066
Current worst splitting domains [lb, ub] (depth):
[-2.62610,   inf] (125), [-2.62375,   inf] (125), [-2.62322,   inf] (125), [-2.62291,   inf] (125), [-2.62099,   inf] (125), [-2.62049,   inf] (125), [-2.61986,   inf] (125), [-2.61983,   inf] (125), [-2.61794,   inf] (125), [-2.61782,   inf] (125), [-2.61689,   inf] (125), [-2.61680,   inf] (125), [-2.61653,   inf] (125), [-2.61643,   inf] (125), [-2.61634,   inf] (125), [-2.61591,   inf] (125), [-2.61527,   inf] (125), [-2.61523,   inf] (125), [-2.61505,   inf] (125), [-2.61498,   inf] (125), 
length of domains: 55411
Total time: 3.3095	 pickout: 0.1892	 decision: 0.3230	 get_bound: 2.4455	 add_domain: 0.3518
Current lb:-2.626100540161133
111998 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 121.17803978919983

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [0, 2053] [0, 2053] [0, 2053] [0, 2053] [0, 2053] [0, 2053] [0, 2053] [0, 2053] [0, 2053] [0, 2053] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5094.46484375 with beta sum per layer: [53.81297302246094, 1232.9635009765625, 87.38745880126953]
alpha/beta optimization time: 0.6836504936218262
This batch time : update_bounds func: 1.1107	 prepare: 0.2278	 bound: 0.6840	 transfer: 0.0551	 finalize: 0.1363
Accumulated time: update_bounds func: 67.1428	 prepare: 12.0770	 bound: 39.2037	 transfer: 0.0551	 finalize: 11.5840
batch bounding time:  1.1127159595489502
Current worst splitting domains [lb, ub] (depth):
[-2.62571,   inf] (127), [-2.62297,   inf] (127), [-2.62283,   inf] (127), [-2.62233,   inf] (127), [-2.62060,   inf] (127), [-2.62012,   inf] (127), [-2.61947,   inf] (127), [-2.61944,   inf] (127), [-2.61756,   inf] (127), [-2.61737,   inf] (127), [-2.61641,   inf] (127), [-2.61622,   inf] (127), [-2.61584,   inf] (127), [-2.61538,   inf] (127), [-2.61494,   inf] (127), [-2.61470,   inf] (127), [-2.61437,   inf] (127), [-2.61433,   inf] (127), [-2.61427,   inf] (127), [-2.61402,   inf] (127), 
length of domains: 56435
Total time: 1.9589	 pickout: 0.1806	 decision: 0.3149	 get_bound: 1.1162	 add_domain: 0.3472
Current lb:-2.6257128715515137
114046 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 123.17004561424255

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [0, 1293] [0, 1293] [0, 1293] [0, 1293] [0, 1293] [0, 1293] [0, 1293] [0, 1293] [0, 1293] [0, 1293] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5099.0400390625 with beta sum per layer: [64.18974304199219, 1266.83740234375, 89.74994659423828]
alpha/beta optimization time: 0.683577299118042
This batch time : update_bounds func: 1.1138	 prepare: 0.2273	 bound: 0.6840	 transfer: 0.0545	 finalize: 0.1401
Accumulated time: update_bounds func: 68.2566	 prepare: 12.3043	 bound: 39.8876	 transfer: 0.0545	 finalize: 11.7242
batch bounding time:  1.1158943176269531
Current worst splitting domains [lb, ub] (depth):
[-2.62564,   inf] (129), [-2.62275,   inf] (129), [-2.62232,   inf] (129), [-2.62207,   inf] (129), [-2.62052,   inf] (129), [-2.62004,   inf] (129), [-2.61939,   inf] (129), [-2.61936,   inf] (129), [-2.61748,   inf] (129), [-2.61678,   inf] (129), [-2.61633,   inf] (129), [-2.61549,   inf] (129), [-2.61529,   inf] (129), [-2.61500,   inf] (129), [-2.61429,   inf] (129), [-2.61425,   inf] (129), [-2.61394,   inf] (129), [-2.61391,   inf] (129), [-2.61385,   inf] (129), [-2.61340,   inf] (129), 
length of domains: 57459
Total time: 1.9700	 pickout: 0.1790	 decision: 0.3176	 get_bound: 1.1193	 add_domain: 0.3542
Current lb:-2.625636100769043
116094 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 125.1865406036377

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [0, 525] [0, 525] [0, 525] [0, 525] [0, 525] [0, 525] [0, 525] [0, 525] [0, 525] [0, 525] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5078.80712890625 with beta sum per layer: [54.37196350097656, 1300.9638671875, 82.7957534790039]
alpha/beta optimization time: 0.6815488338470459
This batch time : update_bounds func: 1.1182	 prepare: 0.2312	 bound: 0.6819	 transfer: 0.0548	 finalize: 0.1431
Accumulated time: update_bounds func: 69.3748	 prepare: 12.5356	 bound: 40.5695	 transfer: 0.0548	 finalize: 11.8672
batch bounding time:  1.1202218532562256
Current worst splitting domains [lb, ub] (depth):
[-2.62491,   inf] (131), [-2.62229,   inf] (131), [-2.62207,   inf] (131), [-2.62115,   inf] (131), [-2.61996,   inf] (131), [-2.61976,   inf] (131), [-2.61909,   inf] (131), [-2.61873,   inf] (131), [-2.61717,   inf] (131), [-2.61650,   inf] (131), [-2.61580,   inf] (131), [-2.61489,   inf] (131), [-2.61449,   inf] (131), [-2.61402,   inf] (131), [-2.61373,   inf] (131), [-2.61360,   inf] (131), [-2.61359,   inf] (131), [-2.61256,   inf] (131), [-2.61237,   inf] (131), [-2.61231,   inf] (131), 
length of domains: 58483
Total time: 1.9893	 pickout: 0.1873	 decision: 0.3180	 get_bound: 1.1237	 add_domain: 0.3603
Current lb:-2.624908447265625
118142 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 127.21281099319458

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 1075] [1, 1075] [1, 1075] [1, 1075] [1, 1075] [1, 1075] [1, 1075] [1, 1075] [1, 1075] [1, 1075] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5069.4111328125 with beta sum per layer: [60.81687927246094, 1279.2723388671875, 93.28355407714844]
alpha/beta optimization time: 0.6814043521881104
This batch time : update_bounds func: 1.1157	 prepare: 0.2299	 bound: 0.6818	 transfer: 0.0553	 finalize: 0.1411
Accumulated time: update_bounds func: 70.4905	 prepare: 12.7655	 bound: 41.2513	 transfer: 0.0553	 finalize: 12.0083
batch bounding time:  1.117689609527588
Current worst splitting domains [lb, ub] (depth):
[-2.62093,   inf] (133), [-2.61836,   inf] (133), [-2.61824,   inf] (133), [-2.61704,   inf] (133), [-2.61596,   inf] (133), [-2.61544,   inf] (133), [-2.61541,   inf] (133), [-2.61493,   inf] (133), [-2.61298,   inf] (133), [-2.61261,   inf] (133), [-2.61196,   inf] (133), [-2.61146,   inf] (133), [-2.61100,   inf] (133), [-2.61076,   inf] (109), [-2.61069,   inf] (131), [-2.61055,   inf] (131), [-2.61052,   inf] (109), [-2.61039,   inf] (129), [-2.61037,   inf] (129), [-2.61028,   inf] (129), 
length of domains: 59507
Total time: 3.4257	 pickout: 0.1958	 decision: 1.7471	 get_bound: 1.1212	 add_domain: 0.3616
Current lb:-2.620926856994629
120190 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 130.67054176330566

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [0, 1491] [0, 1491] [0, 1491] [0, 1491] [0, 1491] [0, 1491] [0, 1491] [0, 1491] [0, 1491] [0, 1491] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5095.7626953125 with beta sum per layer: [63.21894073486328, 1285.812744140625, 76.82303619384766]
alpha/beta optimization time: 0.6836404800415039
This batch time : update_bounds func: 1.1151	 prepare: 0.2287	 bound: 0.6840	 transfer: 0.0542	 finalize: 0.1413
Accumulated time: update_bounds func: 71.6056	 prepare: 12.9942	 bound: 41.9353	 transfer: 0.0542	 finalize: 12.1496
batch bounding time:  1.1171379089355469
Current worst splitting domains [lb, ub] (depth):
[-2.62091,   inf] (135), [-2.61835,   inf] (135), [-2.61780,   inf] (135), [-2.61701,   inf] (135), [-2.61586,   inf] (135), [-2.61542,   inf] (135), [-2.61440,   inf] (135), [-2.61394,   inf] (135), [-2.61278,   inf] (135), [-2.61206,   inf] (135), [-2.61193,   inf] (135), [-2.61058,   inf] (135), [-2.61017,   inf] (89), [-2.61004,   inf] (131), [-2.60990,   inf] (131), [-2.60987,   inf] (135), [-2.60979,   inf] (131), [-2.60968,   inf] (135), [-2.60955,   inf] (89), [-2.60955,   inf] (135), 
length of domains: 60531
Total time: 1.9843	 pickout: 0.1855	 decision: 0.3154	 get_bound: 1.1207	 add_domain: 0.3627
Current lb:-2.620907783508301
122238 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 132.68495893478394

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [0, 454] [0, 1856] [0, 454] [0, 1856] [0, 1856] [0, 1856] [0, 1856] [0, 1856] [0, 1856] [0, 454] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5104.7919921875 with beta sum per layer: [61.421722412109375, 1213.0443115234375, 74.25495910644531]
alpha/beta optimization time: 0.6818151473999023
This batch time : update_bounds func: 1.1077	 prepare: 0.2264	 bound: 0.6822	 transfer: 0.0550	 finalize: 0.1374
Accumulated time: update_bounds func: 72.7133	 prepare: 13.2206	 bound: 42.6175	 transfer: 0.0550	 finalize: 12.2870
batch bounding time:  1.1096434593200684
Current worst splitting domains [lb, ub] (depth):
[-2.61829,   inf] (137), [-2.61694,   inf] (137), [-2.61580,   inf] (137), [-2.61536,   inf] (137), [-2.61432,   inf] (137), [-2.61405,   inf] (137), [-2.61388,   inf] (137), [-2.61270,   inf] (137), [-2.61186,   inf] (137), [-2.61096,   inf] (137), [-2.60991,   inf] (137), [-2.60961,   inf] (137), [-2.60864,   inf] (127), [-2.60858,   inf] (137), [-2.60836,   inf] (131), [-2.60835,   inf] (137), [-2.60834,   inf] (129), [-2.60825,   inf] (131), [-2.60822,   inf] (137), [-2.60821,   inf] (131), 
length of domains: 61555
Total time: 1.9764	 pickout: 0.1844	 decision: 0.3146	 get_bound: 1.1131	 add_domain: 0.3644
Current lb:-2.618285655975342
124286 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 134.69355821609497

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 110] [1, 110] [1, 110] [1, 110] [1, 110] [0, 1856] [1, 110] [1, 110] [1, 110] [0, 1856] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5098.67236328125 with beta sum per layer: [71.75000762939453, 1216.7734375, 75.0145492553711]
alpha/beta optimization time: 0.6787021160125732
This batch time : update_bounds func: 1.1046	 prepare: 0.2273	 bound: 0.6791	 transfer: 0.0546	 finalize: 0.1367
Accumulated time: update_bounds func: 73.8179	 prepare: 13.4480	 bound: 43.2966	 transfer: 0.0546	 finalize: 12.4237
batch bounding time:  1.106576919555664
Current worst splitting domains [lb, ub] (depth):
[-2.61398,   inf] (139), [-2.61352,   inf] (139), [-2.61234,   inf] (139), [-2.61090,   inf] (139), [-2.61059,   inf] (139), [-2.61038,   inf] (139), [-2.60926,   inf] (139), [-2.60912,   inf] (139), [-2.60788,   inf] (131), [-2.60780,   inf] (131), [-2.60776,   inf] (129), [-2.60750,   inf] (137), [-2.60741,   inf] (131), [-2.60731,   inf] (139), [-2.60731,   inf] (129), [-2.60728,   inf] (129), [-2.60725,   inf] (137), [-2.60724,   inf] (129), [-2.60709,   inf] (127), [-2.60708,   inf] (127), 
length of domains: 62579
Total time: 1.9655	 pickout: 0.1807	 decision: 0.3142	 get_bound: 1.1101	 add_domain: 0.3605
Current lb:-2.6139817237854004
126334 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 136.6925027370453

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 110] [0, 454] [0, 454] [1, 110] [0, 454] [0, 454] [0, 454] [0, 454] [1, 1075] [1, 1075] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5069.38525390625 with beta sum per layer: [67.79188537597656, 1330.42138671875, 90.27452087402344]
alpha/beta optimization time: 0.6818761825561523
This batch time : update_bounds func: 1.1148	 prepare: 0.2326	 bound: 0.6823	 transfer: 0.0539	 finalize: 0.1388
Accumulated time: update_bounds func: 74.9328	 prepare: 13.6806	 bound: 43.9788	 transfer: 0.0539	 finalize: 12.5625
batch bounding time:  1.1168432235717773
Current worst splitting domains [lb, ub] (depth):
[-2.60944,   inf] (141), [-2.60701,   inf] (131), [-2.60691,   inf] (131), [-2.60668,   inf] (109), [-2.60666,   inf] (131), [-2.60661,   inf] (131), [-2.60658,   inf] (131), [-2.60655,   inf] (103), [-2.60651,   inf] (125), [-2.60648,   inf] (111), [-2.60644,   inf] (129), [-2.60644,   inf] (131), [-2.60640,   inf] (129), [-2.60638,   inf] (131), [-2.60634,   inf] (141), [-2.60628,   inf] (129), [-2.60622,   inf] (129), [-2.60621,   inf] (127), [-2.60621,   inf] (129), [-2.60620,   inf] (131), 
length of domains: 63603
Total time: 3.4954	 pickout: 0.1814	 decision: 1.8326	 get_bound: 1.1203	 add_domain: 0.3611
Current lb:-2.609438896179199
128382 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 140.2281937599182

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [0, 2904] [1, 1075] [1, 1075] [1, 1208] [1, 1075] [1, 1075] [1, 1075] [1, 408] [0, 525] [1, 95] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5089.8310546875 with beta sum per layer: [68.56596374511719, 1226.0849609375, 78.05055236816406]
alpha/beta optimization time: 0.6812858581542969
This batch time : update_bounds func: 1.1105	 prepare: 0.2275	 bound: 0.6816	 transfer: 0.0545	 finalize: 0.1395
Accumulated time: update_bounds func: 76.0432	 prepare: 13.9081	 bound: 44.6605	 transfer: 0.0545	 finalize: 12.7020
batch bounding time:  1.112476110458374
Current worst splitting domains [lb, ub] (depth):
[-2.60620,   inf] (127), [-2.60609,   inf] (131), [-2.60604,   inf] (133), [-2.60603,   inf] (131), [-2.60596,   inf] (131), [-2.60582,   inf] (131), [-2.60571,   inf] (131), [-2.60568,   inf] (137), [-2.60554,   inf] (137), [-2.60549,   inf] (131), [-2.60547,   inf] (131), [-2.60541,   inf] (137), [-2.60538,   inf] (125), [-2.60536,   inf] (129), [-2.60527,   inf] (107), [-2.60525,   inf] (129), [-2.60524,   inf] (137), [-2.60521,   inf] (127), [-2.60516,   inf] (119), [-2.60514,   inf] (127), 
length of domains: 64627
Total time: 1.9873	 pickout: 0.1865	 decision: 0.3199	 get_bound: 1.1160	 add_domain: 0.3650
Current lb:-2.6061978340148926
130430 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 142.2525372505188

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [0, 484] [1, 1075] [1, 1075] [1, 1075] [1, 1075] [1, 1075] [1, 1075] [1, 110] [1, 110] [1, 1075] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5093.7880859375 with beta sum per layer: [65.94226837158203, 1241.0201416015625, 80.80244445800781]
alpha/beta optimization time: 0.6812059879302979
This batch time : update_bounds func: 1.1091	 prepare: 0.2258	 bound: 0.6816	 transfer: 0.0546	 finalize: 0.1398
Accumulated time: update_bounds func: 77.1523	 prepare: 14.1339	 bound: 45.3421	 transfer: 0.0546	 finalize: 12.8418
batch bounding time:  1.111124038696289
Current worst splitting domains [lb, ub] (depth):
[-2.60523,   inf] (109), [-2.60509,   inf] (127), [-2.60496,   inf] (137), [-2.60493,   inf] (131), [-2.60491,   inf] (129), [-2.60484,   inf] (127), [-2.60469,   inf] (131), [-2.60469,   inf] (133), [-2.60459,   inf] (137), [-2.60459,   inf] (129), [-2.60458,   inf] (107), [-2.60453,   inf] (129), [-2.60450,   inf] (137), [-2.60443,   inf] (129), [-2.60443,   inf] (131), [-2.60441,   inf] (109), [-2.60439,   inf] (123), [-2.60431,   inf] (137), [-2.60430,   inf] (117), [-2.60429,   inf] (113), 
length of domains: 65651
Total time: 1.9889	 pickout: 0.1860	 decision: 0.3192	 get_bound: 1.1147	 add_domain: 0.3690
Current lb:-2.6052303314208984
132478 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 144.27593278884888

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 1208] [0, 484] [1, 110] [1, 1075] [1, 1075] [0, 484] [1, 1075] [0, 357] [0, 454] [0, 525] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5090.97412109375 with beta sum per layer: [64.88862609863281, 1300.311767578125, 68.16378021240234]
alpha/beta optimization time: 0.6798789501190186
This batch time : update_bounds func: 1.1113	 prepare: 0.2291	 bound: 0.6802	 transfer: 0.0545	 finalize: 0.1404
Accumulated time: update_bounds func: 78.2636	 prepare: 14.3631	 bound: 46.0223	 transfer: 0.0545	 finalize: 12.9822
batch bounding time:  1.1133482456207275
Current worst splitting domains [lb, ub] (depth):
[-2.60468,   inf] (135), [-2.60413,   inf] (129), [-2.60412,   inf] (133), [-2.60408,   inf] (131), [-2.60407,   inf] (131), [-2.60395,   inf] (129), [-2.60394,   inf] (87), [-2.60384,   inf] (131), [-2.60381,   inf] (131), [-2.60380,   inf] (131), [-2.60371,   inf] (131), [-2.60367,   inf] (129), [-2.60366,   inf] (131), [-2.60366,   inf] (137), [-2.60363,   inf] (135), [-2.60350,   inf] (125), [-2.60347,   inf] (129), [-2.60341,   inf] (103), [-2.60339,   inf] (135), [-2.60338,   inf] (131), 
length of domains: 66675
Total time: 1.9976	 pickout: 0.1894	 decision: 0.3217	 get_bound: 1.1170	 add_domain: 0.3695
Current lb:-2.6046810150146484
134526 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 146.30870914459229

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 1075] [1, 1075] [0, 357] [1, 1075] [1, 1075] [1, 1075] [0, 330] [1, 1075] [1, 1075] [1, 1075] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5097.79248046875 with beta sum per layer: [77.42280578613281, 1202.793701171875, 73.33274841308594]
alpha/beta optimization time: 0.6797502040863037
This batch time : update_bounds func: 1.1228	 prepare: 0.2420	 bound: 0.6801	 transfer: 0.0545	 finalize: 0.1385
Accumulated time: update_bounds func: 79.3864	 prepare: 14.6051	 bound: 46.7024	 transfer: 0.0545	 finalize: 13.1206
batch bounding time:  1.1248369216918945
Current worst splitting domains [lb, ub] (depth):
[-2.60410,   inf] (135), [-2.60386,   inf] (89), [-2.60356,   inf] (137), [-2.60341,   inf] (131), [-2.60321,   inf] (131), [-2.60317,   inf] (109), [-2.60306,   inf] (131), [-2.60302,   inf] (127), [-2.60292,   inf] (131), [-2.60291,   inf] (137), [-2.60283,   inf] (125), [-2.60280,   inf] (129), [-2.60276,   inf] (131), [-2.60274,   inf] (129), [-2.60273,   inf] (127), [-2.60272,   inf] (131), [-2.60272,   inf] (125), [-2.60270,   inf] (135), [-2.60269,   inf] (137), [-2.60267,   inf] (131), 
length of domains: 67699
Total time: 3.6644	 pickout: 0.1887	 decision: 1.9750	 get_bound: 1.1285	 add_domain: 0.3722
Current lb:-2.604104518890381
136574 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 150.00794315338135

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 1075] [2, 61] [1, 110] [1, 1075] [1, 1075] [1, 1208] [1, 1075] [0, 484] [1, 1075] [1, 110] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5074.41357421875 with beta sum per layer: [72.96742248535156, 1286.552734375, 82.77659606933594]
alpha/beta optimization time: 0.678544282913208
This batch time : update_bounds func: 1.1077	 prepare: 0.2278	 bound: 0.6789	 transfer: 0.0545	 finalize: 0.1389
Accumulated time: update_bounds func: 80.4941	 prepare: 14.8329	 bound: 47.3813	 transfer: 0.0545	 finalize: 13.2595
batch bounding time:  1.1097004413604736
Current worst splitting domains [lb, ub] (depth):
[-2.60264,   inf] (137), [-2.60256,   inf] (127), [-2.60247,   inf] (137), [-2.60245,   inf] (137), [-2.60242,   inf] (131), [-2.60237,   inf] (133), [-2.60236,   inf] (131), [-2.60236,   inf] (127), [-2.60235,   inf] (131), [-2.60224,   inf] (137), [-2.60221,   inf] (101), [-2.60214,   inf] (129), [-2.60212,   inf] (129), [-2.60210,   inf] (133), [-2.60208,   inf] (129), [-2.60207,   inf] (127), [-2.60205,   inf] (129), [-2.60203,   inf] (133), [-2.60196,   inf] (131), [-2.60196,   inf] (93), 
length of domains: 68723
Total time: 1.9835	 pickout: 0.1810	 decision: 0.3175	 get_bound: 1.1133	 add_domain: 0.3717
Current lb:-2.6026411056518555
138622 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 152.02684354782104

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 110] [0, 484] [1, 110] [1, 110] [1, 1075] [0, 357] [1, 1075] [0, 484] [0, 1491] [1, 110] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5115.44921875 with beta sum per layer: [74.79666137695312, 1246.499755859375, 70.38458251953125]
alpha/beta optimization time: 0.678537130355835
This batch time : update_bounds func: 1.1091	 prepare: 0.2284	 bound: 0.6789	 transfer: 0.0547	 finalize: 0.1396
Accumulated time: update_bounds func: 81.6032	 prepare: 15.0613	 bound: 48.0602	 transfer: 0.0547	 finalize: 13.3991
batch bounding time:  1.1111955642700195
Current worst splitting domains [lb, ub] (depth):
[-2.60235,   inf] (135), [-2.60232,   inf] (133), [-2.60202,   inf] (135), [-2.60194,   inf] (125), [-2.60181,   inf] (131), [-2.60178,   inf] (131), [-2.60174,   inf] (131), [-2.60174,   inf] (137), [-2.60168,   inf] (129), [-2.60159,   inf] (137), [-2.60152,   inf] (133), [-2.60143,   inf] (129), [-2.60142,   inf] (127), [-2.60141,   inf] (129), [-2.60131,   inf] (129), [-2.60131,   inf] (129), [-2.60128,   inf] (129), [-2.60126,   inf] (139), [-2.60114,   inf] (129), [-2.60110,   inf] (131), 
length of domains: 69747
Total time: 1.9873	 pickout: 0.1835	 decision: 0.3170	 get_bound: 1.1148	 add_domain: 0.3720
Current lb:-2.602353572845459
140670 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 154.04756903648376

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 1075] [1, 1075] [1, 1075] [1, 1208] [1, 1075] [1, 1075] [1, 1075] [1, 110] [1, 1075] [1, 110] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5102.490234375 with beta sum per layer: [69.98265075683594, 1219.032470703125, 64.78298950195312]
alpha/beta optimization time: 0.678767204284668
This batch time : update_bounds func: 1.1031	 prepare: 0.2262	 bound: 0.6791	 transfer: 0.0533	 finalize: 0.1373
Accumulated time: update_bounds func: 82.7063	 prepare: 15.2874	 bound: 48.7394	 transfer: 0.0533	 finalize: 13.5364
batch bounding time:  1.1051876544952393
Current worst splitting domains [lb, ub] (depth):
[-2.60132,   inf] (135), [-2.60108,   inf] (131), [-2.60103,   inf] (131), [-2.60095,   inf] (137), [-2.60088,   inf] (135), [-2.60088,   inf] (131), [-2.60079,   inf] (137), [-2.60078,   inf] (131), [-2.60070,   inf] (131), [-2.60066,   inf] (131), [-2.60062,   inf] (129), [-2.60053,   inf] (131), [-2.60053,   inf] (129), [-2.60050,   inf] (127), [-2.60048,   inf] (131), [-2.60047,   inf] (113), [-2.60044,   inf] (115), [-2.60044,   inf] (93), [-2.60044,   inf] (113), [-2.60042,   inf] (113), 
length of domains: 70771
Total time: 1.9844	 pickout: 0.1809	 decision: 0.3202	 get_bound: 1.1096	 add_domain: 0.3738
Current lb:-2.6013243198394775
142718 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 156.06505370140076

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 1075] [1, 1075] [1, 1075] [1, 110] [1, 1075] [1, 1075] [0, 1856] [1, 1075] [1, 1075] [1, 1075] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5102.12109375 with beta sum per layer: [76.92022705078125, 1249.82763671875, 71.27137756347656]
alpha/beta optimization time: 0.6799540519714355
This batch time : update_bounds func: 2.8349	 prepare: 0.2279	 bound: 0.6803	 transfer: 0.0545	 finalize: 1.8648
Accumulated time: update_bounds func: 85.5412	 prepare: 15.5153	 bound: 49.4197	 transfer: 0.0545	 finalize: 15.4012
batch bounding time:  2.8368422985076904
Current worst splitting domains [lb, ub] (depth):
[-2.60073,   inf] (139), [-2.60028,   inf] (137), [-2.60022,   inf] (133), [-2.60018,   inf] (131), [-2.60014,   inf] (137), [-2.60009,   inf] (119), [-2.60007,   inf] (141), [-2.60005,   inf] (119), [-2.60001,   inf] (127), [-2.59999,   inf] (131), [-2.59997,   inf] (103), [-2.59995,   inf] (129), [-2.59991,   inf] (129), [-2.59987,   inf] (131), [-2.59986,   inf] (131), [-2.59986,   inf] (131), [-2.59984,   inf] (127), [-2.59980,   inf] (125), [-2.59979,   inf] (127), [-2.59977,   inf] (117), 
length of domains: 71795
Total time: 3.7125	 pickout: 0.1803	 decision: 0.3205	 get_bound: 2.8403	 add_domain: 0.3713
Current lb:-2.6007256507873535
144766 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 159.80973196029663

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 110] [1, 110] [0, 357] [1, 1075] [0, 1856] [0, 553] [1, 110] [1, 171] [0, 484] [0, 525] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5091.7314453125 with beta sum per layer: [81.4286117553711, 1286.147216796875, 69.34857177734375]
alpha/beta optimization time: 0.6796708106994629
This batch time : update_bounds func: 1.1089	 prepare: 0.2279	 bound: 0.6801	 transfer: 0.0551	 finalize: 0.1389
Accumulated time: update_bounds func: 86.6501	 prepare: 15.7432	 bound: 50.0997	 transfer: 0.0551	 finalize: 15.5401
batch bounding time:  1.1108522415161133
Current worst splitting domains [lb, ub] (depth):
[-2.60021,   inf] (135), [-2.60007,   inf] (139), [-2.59969,   inf] (137), [-2.59966,   inf] (131), [-2.59956,   inf] (131), [-2.59952,   inf] (127), [-2.59948,   inf] (131), [-2.59934,   inf] (131), [-2.59933,   inf] (137), [-2.59933,   inf] (131), [-2.59927,   inf] (127), [-2.59925,   inf] (129), [-2.59922,   inf] (109), [-2.59922,   inf] (131), [-2.59920,   inf] (133), [-2.59920,   inf] (131), [-2.59917,   inf] (137), [-2.59915,   inf] (137), [-2.59914,   inf] (127), [-2.59914,   inf] (127), 
length of domains: 72819
Total time: 1.9803	 pickout: 0.1763	 decision: 0.3166	 get_bound: 1.1144	 add_domain: 0.3730
Current lb:-2.600212574005127
146814 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 161.82474946975708

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 1075] [1, 110] [1, 110] [1, 1075] [1, 1075] [0, 484] [1, 1075] [1, 1075] [1, 110] [0, 525] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5109.841796875 with beta sum per layer: [83.23758697509766, 1295.4271240234375, 72.48345947265625]
alpha/beta optimization time: 0.681826114654541
This batch time : update_bounds func: 1.1086	 prepare: 0.2255	 bound: 0.6822	 transfer: 0.0545	 finalize: 0.1393
Accumulated time: update_bounds func: 87.7587	 prepare: 15.9687	 bound: 50.7819	 transfer: 0.0545	 finalize: 15.6794
batch bounding time:  1.1107478141784668
Current worst splitting domains [lb, ub] (depth):
[-2.59919,   inf] (135), [-2.59911,   inf] (135), [-2.59908,   inf] (133), [-2.59895,   inf] (131), [-2.59890,   inf] (137), [-2.59882,   inf] (107), [-2.59880,   inf] (109), [-2.59872,   inf] (137), [-2.59865,   inf] (131), [-2.59864,   inf] (127), [-2.59863,   inf] (129), [-2.59861,   inf] (115), [-2.59856,   inf] (129), [-2.59852,   inf] (133), [-2.59847,   inf] (141), [-2.59843,   inf] (131), [-2.59842,   inf] (123), [-2.59841,   inf] (127), [-2.59839,   inf] (131), [-2.59838,   inf] (115), 
length of domains: 73843
Total time: 1.9944	 pickout: 0.1822	 decision: 0.3163	 get_bound: 1.1144	 add_domain: 0.3814
Current lb:-2.5991902351379395
148862 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 163.87132501602173

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 1075] [1, 1075] [0, 357] [1, 1075] [1, 110] [0, 440] [1, 1208] [0, 1856] [1, 1075] [0, 1269] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5106.814453125 with beta sum per layer: [82.46566009521484, 1284.302001953125, 70.98031616210938]
alpha/beta optimization time: 0.6798124313354492
This batch time : update_bounds func: 1.1260	 prepare: 0.2348	 bound: 0.6802	 transfer: 0.0551	 finalize: 0.1488
Accumulated time: update_bounds func: 88.8847	 prepare: 16.2035	 bound: 51.4621	 transfer: 0.0551	 finalize: 15.8282
batch bounding time:  1.1281168460845947
Current worst splitting domains [lb, ub] (depth):
[-2.59906,   inf] (135), [-2.59866,   inf] (139), [-2.59846,   inf] (129), [-2.59829,   inf] (131), [-2.59811,   inf] (131), [-2.59808,   inf] (127), [-2.59808,   inf] (131), [-2.59797,   inf] (131), [-2.59792,   inf] (131), [-2.59790,   inf] (93), [-2.59788,   inf] (109), [-2.59774,   inf] (141), [-2.59773,   inf] (115), [-2.59772,   inf] (129), [-2.59772,   inf] (127), [-2.59770,   inf] (131), [-2.59769,   inf] (131), [-2.59769,   inf] (115), [-2.59767,   inf] (113), [-2.59766,   inf] (141), 
length of domains: 74867
Total time: 2.0497	 pickout: 0.1946	 decision: 0.3252	 get_bound: 1.1318	 add_domain: 0.3980
Current lb:-2.599057674407959
150910 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 165.96724891662598

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 1075] [1, 110] [0, 1856] [1, 1075] [1, 1075] [0, 484] [1, 1075] [1, 1075] [1, 1075] [1, 23] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5093.72265625 with beta sum per layer: [74.96116638183594, 1242.5506591796875, 74.8814697265625]
alpha/beta optimization time: 0.6775319576263428
This batch time : update_bounds func: 1.1287	 prepare: 0.2419	 bound: 0.6779	 transfer: 0.0539	 finalize: 0.1470
Accumulated time: update_bounds func: 90.0134	 prepare: 16.4454	 bound: 52.1400	 transfer: 0.0539	 finalize: 15.9752
batch bounding time:  1.1308021545410156
Current worst splitting domains [lb, ub] (depth):
[-2.59839,   inf] (131), [-2.59756,   inf] (141), [-2.59755,   inf] (139), [-2.59747,   inf] (131), [-2.59744,   inf] (133), [-2.59743,   inf] (141), [-2.59733,   inf] (115), [-2.59723,   inf] (129), [-2.59721,   inf] (131), [-2.59720,   inf] (129), [-2.59716,   inf] (131), [-2.59715,   inf] (131), [-2.59715,   inf] (137), [-2.59713,   inf] (131), [-2.59712,   inf] (131), [-2.59712,   inf] (113), [-2.59711,   inf] (139), [-2.59710,   inf] (133), [-2.59710,   inf] (137), [-2.59709,   inf] (125), 
length of domains: 75891
Total time: 2.0511	 pickout: 0.2017	 decision: 0.3205	 get_bound: 1.1347	 add_domain: 0.3941
Current lb:-2.598393440246582
152958 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 168.0593318939209

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 23] [1, 110] [1, 110] [1, 1075] [1, 1075] [1, 110] [0, 2053] [0, 525] [1, 1075] [1, 1075] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5088.7919921875 with beta sum per layer: [85.93792724609375, 1307.62744140625, 77.58423614501953]
alpha/beta optimization time: 0.6875953674316406
This batch time : update_bounds func: 1.1275	 prepare: 0.2330	 bound: 0.6880	 transfer: 0.0546	 finalize: 0.1444
Accumulated time: update_bounds func: 91.1410	 prepare: 16.6784	 bound: 52.8280	 transfer: 0.0546	 finalize: 16.1196
batch bounding time:  1.1296448707580566
Current worst splitting domains [lb, ub] (depth):
[-2.59708,   inf] (139), [-2.59705,   inf] (117), [-2.59695,   inf] (137), [-2.59692,   inf] (133), [-2.59680,   inf] (127), [-2.59680,   inf] (137), [-2.59679,   inf] (137), [-2.59671,   inf] (139), [-2.59670,   inf] (141), [-2.59668,   inf] (141), [-2.59667,   inf] (125), [-2.59662,   inf] (133), [-2.59660,   inf] (135), [-2.59659,   inf] (127), [-2.59656,   inf] (101), [-2.59656,   inf] (127), [-2.59654,   inf] (127), [-2.59651,   inf] (131), [-2.59650,   inf] (131), [-2.59650,   inf] (113), 
length of domains: 76915
Total time: 3.9798	 pickout: 0.2007	 decision: 2.2676	 get_bound: 1.1331	 add_domain: 0.3785
Current lb:-2.597083568572998
155006 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Time out!!!!!!!!
Image 30 label 4 verification end, final lower bound -2.597083568572998, upper bound inf, time: 174.05639123916626
30 -2.597083568572998
Result: image 30 verification failure (with branch and bound).
Wall time: 182.95557117462158

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 0): []
verification failure idx (total 1): [30]
final verified acc: 0.0%[1]
verifier is called on 1 examples.
total verified: 0
mean time [cnt:1] (excluding attack success): 182.8630542755127
