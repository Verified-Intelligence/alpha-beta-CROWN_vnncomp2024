Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: mnist_cnn_a_adv.model
  name: mnist_cnn_4layer
data:
  start: 69
  end: 70
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: MNIST_SDP
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.3
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 1024
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 180
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Tue May  3 01:02:24 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(1, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Flatten(start_dim=1, end_dim=-1)
  (5): Linear(in_features=1568, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=10, bias=True)
)
############################
Shape: torch.Size([200, 1, 28, 28]) torch.Size([200]) torch.Size([200])
X range: tensor(1.) tensor(0.) tensor(0.1340)
############################
epsilon after preprocessing: 0.30000001192092896, data_max = tensor([[[[1.]]]]), data_min = tensor([[[[0.]]]])
Task length: 1
saving results to Verified_ret_[mnist_cnn_4layer]_start=69_end=70_iter=20_b=1024_timeout=180_branching=kfsb-max-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 69 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 7, correct label 7, image norm 141.4039306640625, logits tensor([ -3.7638,  -6.5174,  -4.7464,  -2.7490,  -0.8870,  -4.4974, -11.8775,
          5.7896,  -0.5153,   2.6719], device='cuda:0',
       grad_fn=<SelectBackward>)
##### PGD attack: True label: 7, Tested against: ['all'] ######
pgd prediction: tensor([-3.6780, -5.7255, -4.6645, -2.1563, -0.6830, -3.7120, -9.9873,  2.8896,
         0.2425,  2.2644], device='cuda:0', grad_fn=<SqueezeBackward1>)
attack margin tensor([ 6.5677,  8.6151,  7.5542,  5.0460,  3.5727,  6.6017, 12.8769,     inf,
         2.6471,  0.6252], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[ -3.7638,  -6.5174,  -4.7464,  -2.7490,  -0.8870,  -4.4974, -11.8775,
           5.7896,  -0.5153,   2.6719]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-1.2965, -1.3256, -0.5781, -1.6319, -3.2872, -2.7520, -1.4211, -4.7345,
         -3.6042]], device='cuda:0') None
best_l after optimization: -7.238161087036133 with beta sum per layer: []
alpha/beta optimization time: 7.539117813110352
initial alpha-CROWN bounds: tensor([[ 1.1500,  2.7637,  2.1775,  0.3946, -0.0442,  0.2932,  3.9428, -1.8657,
         -1.5737]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-1.8657, device='cuda:0', grad_fn=<MinBackward1>)
Sorted order for labels to verify: [9, 8, 4, 3, 0, 5, 2, 1, 6, 7]
##### [0:69] Tested against 9 ######
Model prediction is: tensor([[ -3.7638,  -6.5174,  -4.7464,  -2.7490,  -0.8870,  -4.4974, -11.8775,
           5.7896,  -0.5153,   2.6719]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 16, 14, 14]) != torch.Size([2, 9, 1, 16, 14, 14]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 7, 7]) != torch.Size([2, 9, 1, 32, 7, 7]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 14, 14])
1 /11 torch.Size([1, 32, 7, 7])
2 /14 torch.Size([1, 100])
best_l after optimization: 1.571415662765503 with beta sum per layer: []
alpha/beta optimization time: 1.75673508644104
alpha-CROWN with fixed intermediate bounds: tensor([[-1.5714]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-1.571415662765503
layer 0 size torch.Size([3136]) unstable 1172
layer 1 size torch.Size([1568]) unstable 159
layer 2 size torch.Size([100]) unstable 18
-----------------
# of unstable neurons: 1349
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 14, 14]) pre split depth:  6
batch:  torch.Size([1, 16, 14, 14]) post split depth:  6
splitting decisions: 
split level 0: [2, 5] 
split level 1: [2, 83] 
split level 2: [2, 56] 
split level 3: [2, 85] 
split level 4: [2, 96] 
split level 5: [2, 33] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: -5.701089859008789 with beta sum per layer: [0.0, 0.0, 20.372814178466797]
alpha/beta optimization time: 0.2604384422302246
This batch time : update_bounds func: 0.2723	 prepare: 0.0057	 bound: 0.2607	 transfer: 0.0015	 finalize: 0.0041
Accumulated time: update_bounds func: 0.2723	 prepare: 0.0057	 bound: 0.2607	 transfer: 0.0015	 finalize: 0.0041
batch bounding time:  0.2724792957305908
Current worst splitting domains [lb, ub] (depth):
[-0.77021,   inf] (7), [-0.72474,   inf] (7), [-0.69183,   inf] (7), [-0.64456,   inf] (7), [-0.61655,   inf] (7), [-0.40095,   inf] (7), [-0.39965,   inf] (7), [-0.36846,   inf] (7), [-0.25174,   inf] (7), [-0.19264,   inf] (7), [-0.18297,   inf] (7), [-0.15170,   inf] (7), [-0.09880,   inf] (7), [-0.04229,   inf] (7), [-0.03396,   inf] (7), [-0.02534,   inf] (7), [-0.01166,   inf] (7), 
length of domains: 17
Total time: 0.3167	 pickout: 0.0009	 decision: 0.0347	 get_bound: 0.2803	 add_domain: 0.0008
Current lb:-0.7702096104621887
64 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.9099907875061035

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([17, 16, 14, 14]) pre split depth:  2
batch:  torch.Size([17, 16, 14, 14]) post split depth:  2
splitting decisions: 
split level 0: [1, 603] [1, 16] [1, 72] [1, 72] [1, 603] [1, 603] [1, 603] [1, 16] [1, 603] [1, 72] 
split level 1: [1, 72] [1, 72] [1, 603] [1, 603] [1, 72] [1, 72] [1, 72] [1, 603] [1, 72] [1, 603] 
regular batch size: 2*34, diving batch size 1*0
best_l after optimization: 7.3943190574646 with beta sum per layer: [0.0, 1.6629831790924072, 22.586074829101562]
alpha/beta optimization time: 0.2575404644012451
This batch time : update_bounds func: 0.2712	 prepare: 0.0073	 bound: 0.2578	 transfer: 0.0015	 finalize: 0.0043
Accumulated time: update_bounds func: 0.5435	 prepare: 0.0130	 bound: 0.5186	 transfer: 0.0015	 finalize: 0.0084
batch bounding time:  0.27135300636291504
Current worst splitting domains [lb, ub] (depth):
[-0.61223,   inf] (10), [-0.58676,   inf] (10), [-0.54691,   inf] (10), [-0.52856,   inf] (10), [-0.52855,   inf] (10), [-0.51360,   inf] (10), [-0.50240,   inf] (10), [-0.49918,   inf] (10), [-0.46111,   inf] (10), [-0.44905,   inf] (10), [-0.44728,   inf] (10), [-0.44411,   inf] (10), [-0.42301,   inf] (10), [-0.42210,   inf] (10), [-0.39182,   inf] (10), [-0.37902,   inf] (10), [-0.36635,   inf] (10), [-0.34410,   inf] (10), [-0.33046,   inf] (10), [-0.32020,   inf] (10), 
length of domains: 34
Total time: 0.3041	 pickout: 0.0029	 decision: 0.0236	 get_bound: 0.2761	 add_domain: 0.0016
Current lb:-0.6122270822525024
132 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.2145936489105225

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([34, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([34, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 16] [1, 16] [1, 603] [1, 16] [1, 16] [1, 603] [1, 16] [1, 16] [1, 16] [1, 16] 
regular batch size: 2*34, diving batch size 1*0
best_l after optimization: 12.437812805175781 with beta sum per layer: [0.0, 7.271760940551758, 12.606042861938477]
alpha/beta optimization time: 0.257840633392334
This batch time : update_bounds func: 0.2722	 prepare: 0.0080	 bound: 0.2581	 transfer: 0.0016	 finalize: 0.0044
Accumulated time: update_bounds func: 0.8157	 prepare: 0.0210	 bound: 0.7767	 transfer: 0.0016	 finalize: 0.0128
batch bounding time:  0.2724027633666992
Current worst splitting domains [lb, ub] (depth):
[-0.56064,   inf] (12), [-0.53040,   inf] (12), [-0.48890,   inf] (12), [-0.47774,   inf] (12), [-0.46973,   inf] (12), [-0.45476,   inf] (12), [-0.45138,   inf] (12), [-0.43902,   inf] (12), [-0.40388,   inf] (12), [-0.39947,   inf] (12), [-0.39413,   inf] (12), [-0.39052,   inf] (12), [-0.38610,   inf] (12), [-0.38573,   inf] (12), [-0.36752,   inf] (12), [-0.36325,   inf] (12), [-0.36269,   inf] (12), [-0.35240,   inf] (12), [-0.32015,   inf] (12), [-0.30863,   inf] (12), 
length of domains: 49
Total time: 0.3069	 pickout: 0.0052	 decision: 0.0268	 get_bound: 0.2725	 add_domain: 0.0023
Current lb:-0.5606395602226257
200 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.522104501724243

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([49, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([49, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [2, 8] [2, 8] [2, 8] [2, 8] [2, 8] [2, 8] [2, 8] [2, 8] [2, 81] [2, 8] 
regular batch size: 2*49, diving batch size 1*0
best_l after optimization: 11.818946838378906 with beta sum per layer: [0.0, 13.286571502685547, 17.321260452270508]
alpha/beta optimization time: 0.2602264881134033
This batch time : update_bounds func: 0.2800	 prepare: 0.0109	 bound: 0.2605	 transfer: 0.0020	 finalize: 0.0064
Accumulated time: update_bounds func: 1.0957	 prepare: 0.0319	 bound: 1.0372	 transfer: 0.0020	 finalize: 0.0192
batch bounding time:  0.28019213676452637
Current worst splitting domains [lb, ub] (depth):
[-0.50045,   inf] (14), [-0.46982,   inf] (14), [-0.42313,   inf] (14), [-0.42211,   inf] (14), [-0.40762,   inf] (14), [-0.39592,   inf] (14), [-0.38601,   inf] (14), [-0.37769,   inf] (14), [-0.34939,   inf] (14), [-0.33191,   inf] (14), [-0.33049,   inf] (14), [-0.32932,   inf] (14), [-0.32878,   inf] (14), [-0.32701,   inf] (14), [-0.32430,   inf] (14), [-0.30654,   inf] (14), [-0.30609,   inf] (14), [-0.29837,   inf] (14), [-0.28766,   inf] (14), [-0.28192,   inf] (14), 
length of domains: 68
Total time: 0.3223	 pickout: 0.0072	 decision: 0.0312	 get_bound: 0.2803	 add_domain: 0.0036
Current lb:-0.5004532933235168
298 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.845243453979492

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([68, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([68, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 275] [1, 275] [2, 81] [2, 81] [1, 275] [2, 81] [2, 81] [1, 275] [2, 8] [2, 81] 
regular batch size: 2*68, diving batch size 1*0
best_l after optimization: 5.04988431930542 with beta sum per layer: [0.0, 17.48700523376465, 30.042280197143555]
alpha/beta optimization time: 0.24893665313720703
This batch time : update_bounds func: 0.2792	 prepare: 0.0144	 bound: 0.2492	 transfer: 0.0065	 finalize: 0.0088
Accumulated time: update_bounds func: 1.3750	 prepare: 0.0463	 bound: 1.2865	 transfer: 0.0065	 finalize: 0.0280
batch bounding time:  0.2794835567474365
Current worst splitting domains [lb, ub] (depth):
[-0.45647,   inf] (16), [-0.42657,   inf] (16), [-0.37537,   inf] (16), [-0.37062,   inf] (16), [-0.36604,   inf] (16), [-0.36204,   inf] (16), [-0.34559,   inf] (16), [-0.34309,   inf] (16), [-0.33433,   inf] (16), [-0.32890,   inf] (16), [-0.28688,   inf] (16), [-0.28151,   inf] (16), [-0.27939,   inf] (16), [-0.27408,   inf] (16), [-0.27250,   inf] (16), [-0.26609,   inf] (16), [-0.26557,   inf] (16), [-0.25649,   inf] (16), [-0.25059,   inf] (16), [-0.24978,   inf] (16), 
length of domains: 67
Total time: 0.3287	 pickout: 0.0097	 decision: 0.0356	 get_bound: 0.2797	 add_domain: 0.0037
Current lb:-0.4564675986766815
434 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.175364255905151

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([67, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([67, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [2, 81] [2, 81] [2, 81] [1, 613] [1, 613] [2, 81] [1, 613] [2, 81] [2, 81] [1, 613] 
regular batch size: 2*67, diving batch size 1*0
best_l after optimization: 7.8392791748046875 with beta sum per layer: [0.0, 15.358810424804688, 17.290494918823242]
alpha/beta optimization time: 0.24424362182617188
This batch time : update_bounds func: 0.2718	 prepare: 0.0138	 bound: 0.2445	 transfer: 0.0048	 finalize: 0.0083
Accumulated time: update_bounds func: 1.6468	 prepare: 0.0601	 bound: 1.5310	 transfer: 0.0048	 finalize: 0.0363
batch bounding time:  0.27210521697998047
Current worst splitting domains [lb, ub] (depth):
[-0.40390,   inf] (18), [-0.37257,   inf] (18), [-0.32182,   inf] (18), [-0.30998,   inf] (18), [-0.28851,   inf] (18), [-0.28475,   inf] (18), [-0.28053,   inf] (18), [-0.27964,   inf] (18), [-0.26428,   inf] (18), [-0.26281,   inf] (18), [-0.26177,   inf] (18), [-0.24655,   inf] (18), [-0.24270,   inf] (18), [-0.23661,   inf] (18), [-0.22687,   inf] (18), [-0.21866,   inf] (18), [-0.20231,   inf] (18), [-0.19653,   inf] (18), [-0.19476,   inf] (18), [-0.19423,   inf] (18), 
length of domains: 74
Total time: 0.3225	 pickout: 0.0102	 decision: 0.0358	 get_bound: 0.2723	 add_domain: 0.0042
Current lb:-0.40389931201934814
568 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.499277353286743

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([74, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([74, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 613] [1, 38] [1, 613] [1, 613] [1, 38] [1, 275] [1, 38] [1, 275] [1, 275] [1, 275] 
regular batch size: 2*74, diving batch size 1*0
best_l after optimization: 9.090660095214844 with beta sum per layer: [0.0, 14.432914733886719, 13.707489013671875]
alpha/beta optimization time: 0.25383472442626953
This batch time : update_bounds func: 0.2834	 prepare: 0.0150	 bound: 0.2541	 transfer: 0.0043	 finalize: 0.0095
Accumulated time: update_bounds func: 1.9302	 prepare: 0.0751	 bound: 1.7852	 transfer: 0.0043	 finalize: 0.0458
batch bounding time:  0.28366827964782715
Current worst splitting domains [lb, ub] (depth):
[-0.33094,   inf] (20), [-0.32576,   inf] (20), [-0.29980,   inf] (20), [-0.27286,   inf] (20), [-0.24728,   inf] (20), [-0.24370,   inf] (20), [-0.24320,   inf] (20), [-0.24074,   inf] (20), [-0.23250,   inf] (20), [-0.23171,   inf] (20), [-0.22565,   inf] (20), [-0.22427,   inf] (20), [-0.22136,   inf] (20), [-0.21841,   inf] (20), [-0.20856,   inf] (20), [-0.20813,   inf] (20), [-0.20784,   inf] (20), [-0.20617,   inf] (20), [-0.20087,   inf] (20), [-0.18161,   inf] (20), 
length of domains: 96
Total time: 0.3395	 pickout: 0.0110	 decision: 0.0383	 get_bound: 0.2839	 add_domain: 0.0063
Current lb:-0.33093953132629395
716 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.84013032913208

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([96, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([96, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 416] [1, 38] [1, 416] [1, 416] [2, 79] [1, 163] [1, 38] [1, 416] [1, 416] [1, 416] 
regular batch size: 2*96, diving batch size 1*0
best_l after optimization: 6.603437423706055 with beta sum per layer: [0.0, 20.385395050048828, 13.003585815429688]
alpha/beta optimization time: 0.250333309173584
This batch time : update_bounds func: 0.2897	 prepare: 0.0201	 bound: 0.2507	 transfer: 0.0061	 finalize: 0.0124
Accumulated time: update_bounds func: 2.2199	 prepare: 0.0952	 bound: 2.0358	 transfer: 0.0061	 finalize: 0.0582
batch bounding time:  0.29001879692077637
Current worst splitting domains [lb, ub] (depth):
[-0.30367,   inf] (22), [-0.28243,   inf] (22), [-0.26956,   inf] (22), [-0.24653,   inf] (22), [-0.22641,   inf] (22), [-0.21336,   inf] (22), [-0.21242,   inf] (22), [-0.21058,   inf] (22), [-0.20232,   inf] (22), [-0.19585,   inf] (22), [-0.19397,   inf] (22), [-0.19101,   inf] (22), [-0.18660,   inf] (22), [-0.18585,   inf] (22), [-0.18398,   inf] (22), [-0.18280,   inf] (22), [-0.18118,   inf] (22), [-0.17718,   inf] (22), [-0.17684,   inf] (22), [-0.17358,   inf] (22), 
length of domains: 102
Total time: 0.3539	 pickout: 0.0139	 decision: 0.0433	 get_bound: 0.2903	 add_domain: 0.0064
Current lb:-0.3036731481552124
908 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.195639133453369

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([102, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([102, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 269] [1, 269] [1, 38] [1, 269] [1, 269] [2, 41] [1, 163] [1, 269] [1, 269] [1, 269] 
regular batch size: 2*102, diving batch size 1*0
best_l after optimization: 4.014155864715576 with beta sum per layer: [0.0, 19.2347412109375, 12.193136215209961]
alpha/beta optimization time: 0.267822265625
This batch time : update_bounds func: 0.3078	 prepare: 0.0209	 bound: 0.2681	 transfer: 0.0055	 finalize: 0.0127
Accumulated time: update_bounds func: 2.5277	 prepare: 0.1161	 bound: 2.3040	 transfer: 0.0055	 finalize: 0.0709
batch bounding time:  0.3080873489379883
Current worst splitting domains [lb, ub] (depth):
[-0.27295,   inf] (24), [-0.24492,   inf] (24), [-0.22554,   inf] (24), [-0.21293,   inf] (24), [-0.18715,   inf] (24), [-0.18680,   inf] (24), [-0.17974,   inf] (24), [-0.17611,   inf] (24), [-0.17531,   inf] (24), [-0.16696,   inf] (24), [-0.16591,   inf] (24), [-0.16277,   inf] (24), [-0.15561,   inf] (24), [-0.15079,   inf] (24), [-0.14961,   inf] (24), [-0.14795,   inf] (24), [-0.14733,   inf] (24), [-0.14320,   inf] (24), [-0.14148,   inf] (24), [-0.14038,   inf] (24), 
length of domains: 101
Total time: 0.3762	 pickout: 0.0169	 decision: 0.0438	 get_bound: 0.3084	 add_domain: 0.0071
Current lb:-0.2729465663433075
1112 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.5736613273620605

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([101, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([101, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 613] [1, 416] [1, 269] [1, 613] [1, 38] [1, 416] [1, 613] [1, 613] [1, 613] [2, 79] 
regular batch size: 2*101, diving batch size 1*0
best_l after optimization: 0.8301906585693359 with beta sum per layer: [0.0, 16.77513313293457, 8.434769630432129]
alpha/beta optimization time: 0.26641201972961426
This batch time : update_bounds func: 0.3052	 prepare: 0.0207	 bound: 0.2667	 transfer: 0.0046	 finalize: 0.0126
Accumulated time: update_bounds func: 2.8329	 prepare: 0.1368	 bound: 2.5707	 transfer: 0.0046	 finalize: 0.0836
batch bounding time:  0.30545902252197266
Current worst splitting domains [lb, ub] (depth):
[-0.20597,   inf] (26), [-0.19192,   inf] (26), [-0.18953,   inf] (26), [-0.17946,   inf] (26), [-0.15569,   inf] (26), [-0.15209,   inf] (26), [-0.15013,   inf] (26), [-0.14786,   inf] (26), [-0.14050,   inf] (26), [-0.13004,   inf] (26), [-0.12546,   inf] (26), [-0.11773,   inf] (26), [-0.11666,   inf] (26), [-0.11288,   inf] (26), [-0.11122,   inf] (26), [-0.11104,   inf] (26), [-0.11073,   inf] (26), [-0.11039,   inf] (26), [-0.10832,   inf] (26), [-0.10397,   inf] (26), 
length of domains: 93
Total time: 0.3688	 pickout: 0.0145	 decision: 0.0423	 get_bound: 0.3058	 add_domain: 0.0062
Current lb:-0.2059740275144577
1314 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.944360971450806

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([93, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([93, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [2, 79] [2, 79] [2, 79] [2, 79] [2, 79] [2, 79] [1, 710] [1, 269] [2, 79] [1, 723] 
regular batch size: 2*93, diving batch size 1*0
best_l after optimization: -5.376438140869141 with beta sum per layer: [0.0, 13.469192504882812, 4.727519512176514]
alpha/beta optimization time: 0.25234413146972656
This batch time : update_bounds func: 0.2864	 prepare: 0.0188	 bound: 0.2526	 transfer: 0.0030	 finalize: 0.0115
Accumulated time: update_bounds func: 3.1193	 prepare: 0.1556	 bound: 2.8233	 transfer: 0.0030	 finalize: 0.0951
batch bounding time:  0.2866933345794678
Current worst splitting domains [lb, ub] (depth):
[-0.16828,   inf] (28), [-0.15518,   inf] (28), [-0.14959,   inf] (28), [-0.13647,   inf] (28), [-0.12715,   inf] (28), [-0.12234,   inf] (28), [-0.11414,   inf] (28), [-0.10724,   inf] (28), [-0.10353,   inf] (28), [-0.10241,   inf] (28), [-0.09839,   inf] (28), [-0.08599,   inf] (28), [-0.08587,   inf] (28), [-0.08192,   inf] (28), [-0.07590,   inf] (28), [-0.07555,   inf] (28), [-0.07536,   inf] (28), [-0.07482,   inf] (28), [-0.07469,   inf] (28), [-0.07096,   inf] (28), 
length of domains: 68
Total time: 0.3486	 pickout: 0.0135	 decision: 0.0430	 get_bound: 0.2870	 add_domain: 0.0052
Current lb:-0.16827929019927979
1500 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.294790506362915

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([68, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([68, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 710] [1, 710] [1, 163] [1, 163] [2, 41] [1, 710] [1, 163] [1, 38] [1, 163] [1, 710] 
regular batch size: 2*68, diving batch size 1*0
best_l after optimization: -3.2149834632873535 with beta sum per layer: [0.0, 8.374357223510742, 2.589078664779663]
alpha/beta optimization time: 0.250622034072876
This batch time : update_bounds func: 0.2778	 prepare: 0.0152	 bound: 0.2509	 transfer: 0.0025	 finalize: 0.0087
Accumulated time: update_bounds func: 3.3970	 prepare: 0.1708	 bound: 3.0743	 transfer: 0.0025	 finalize: 0.1039
batch bounding time:  0.2780036926269531
Current worst splitting domains [lb, ub] (depth):
[-0.14127,   inf] (30), [-0.13112,   inf] (30), [-0.12191,   inf] (30), [-0.11176,   inf] (30), [-0.09846,   inf] (30), [-0.08822,   inf] (30), [-0.08016,   inf] (30), [-0.07774,   inf] (30), [-0.07583,   inf] (30), [-0.07465,   inf] (30), [-0.06407,   inf] (30), [-0.05980,   inf] (30), [-0.05817,   inf] (30), [-0.05726,   inf] (30), [-0.05482,   inf] (30), [-0.05377,   inf] (30), [-0.05149,   inf] (30), [-0.04902,   inf] (30), [-0.04703,   inf] (30), [-0.04653,   inf] (30), 
length of domains: 44
Total time: 0.3764	 pickout: 0.0101	 decision: 0.0846	 get_bound: 0.2782	 add_domain: 0.0034
Current lb:-0.1412716507911682
1636 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.672588586807251

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([44, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([44, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 163] [1, 163] [1, 710] [1, 710] [2, 41] [1, 710] [1, 38] [1, 710] [1, 422] [2, 41] 
regular batch size: 2*44, diving batch size 1*0
best_l after optimization: -2.4964332580566406 with beta sum per layer: [0.0, 4.075962543487549, 1.1536390781402588]
alpha/beta optimization time: 0.27553629875183105
This batch time : update_bounds func: 0.2962	 prepare: 0.0102	 bound: 0.2759	 transfer: 0.0018	 finalize: 0.0081
Accumulated time: update_bounds func: 3.6932	 prepare: 0.1811	 bound: 3.3501	 transfer: 0.0018	 finalize: 0.1119
batch bounding time:  0.296428918838501
Current worst splitting domains [lb, ub] (depth):
[-0.11486,   inf] (32), [-0.10686,   inf] (32), [-0.09608,   inf] (32), [-0.08952,   inf] (32), [-0.06304,   inf] (32), [-0.05389,   inf] (32), [-0.05381,   inf] (32), [-0.05103,   inf] (32), [-0.04186,   inf] (32), [-0.02971,   inf] (32), [-0.02654,   inf] (32), [-0.02397,   inf] (32), [-0.02216,   inf] (32), [-0.02145,   inf] (32), [-0.02051,   inf] (32), [-0.01979,   inf] (32), [-0.01730,   inf] (32), [-0.01698,   inf] (32), [-0.01422,   inf] (32), [-0.01173,   inf] (32), 
length of domains: 31
Total time: 0.3341	 pickout: 0.0067	 decision: 0.0281	 get_bound: 0.2966	 add_domain: 0.0027
Current lb:-0.114863321185112
1724 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.007770776748657

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([31, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([31, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 723] [2, 41] [1, 723] [1, 723] [1, 723] [1, 571] [2, 41] [0, 2455] [0, 2455] [1, 710] 
regular batch size: 2*31, diving batch size 1*0
best_l after optimization: -1.7775113582611084 with beta sum per layer: [0.0, 2.476764678955078, 0.45506957173347473]
alpha/beta optimization time: 0.2860424518585205
This batch time : update_bounds func: 0.3113	 prepare: 0.0126	 bound: 0.2865	 transfer: 0.0060	 finalize: 0.0060
Accumulated time: update_bounds func: 4.0046	 prepare: 0.1937	 bound: 3.6366	 transfer: 0.0060	 finalize: 0.1179
batch bounding time:  0.31152772903442383
Current worst splitting domains [lb, ub] (depth):
[-0.08595,   inf] (34), [-0.07019,   inf] (34), [-0.06402,   inf] (34), [-0.05980,   inf] (34), [-0.04940,   inf] (34), [-0.04162,   inf] (34), [-0.03869,   inf] (34), [-0.03121,   inf] (34), [-0.02647,   inf] (34), [-0.02245,   inf] (34), [-0.02035,   inf] (34), [-0.01736,   inf] (34), [-0.01670,   inf] (34), [-0.01164,   inf] (34), [-0.01032,   inf] (34), [-0.00796,   inf] (34), [-0.00723,   inf] (34), [-0.00427,   inf] (34), [-0.00352,   inf] (34), [-0.00205,   inf] (34), 
length of domains: 20
Total time: 0.3554	 pickout: 0.0071	 decision: 0.0344	 get_bound: 0.3116	 add_domain: 0.0023
Current lb:-0.08595013618469238
1786 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.363981246948242

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([20, 16, 14, 14]) pre split depth:  2
batch:  torch.Size([20, 16, 14, 14]) post split depth:  2
splitting decisions: 
split level 0: [1, 422] [0, 2455] [0, 2455] [0, 2455] [1, 422] [1, 416] [1, 422] [0, 2455] [1, 422] [1, 422] 
split level 1: [1, 919] [1, 422] [2, 41] [1, 723] [1, 702] [1, 702] [1, 115] [2, 41] [1, 702] [1, 115] 
regular batch size: 2*40, diving batch size 1*0
best_l after optimization: -5.838045597076416 with beta sum per layer: [0.0, 0.9226828813552856, 0.6410828232765198]
alpha/beta optimization time: 0.281719446182251
This batch time : update_bounds func: 0.3086	 prepare: 0.0141	 bound: 0.2821	 transfer: 0.0048	 finalize: 0.0074
Accumulated time: update_bounds func: 4.3131	 prepare: 0.2077	 bound: 3.9187	 transfer: 0.0048	 finalize: 0.1253
batch bounding time:  0.30876684188842773
Current worst splitting domains [lb, ub] (depth):
[-0.03257,   inf] (37), [-0.01683,   inf] (37), 
length of domains: 2
Total time: 0.3549	 pickout: 0.0052	 decision: 0.0319	 get_bound: 0.3176	 add_domain: 0.0003
Current lb:-0.03256595879793167
1866 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.71971869468689

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2, 16, 14, 14]) pre split depth:  5
batch:  torch.Size([2, 16, 14, 14]) post split depth:  5
splitting decisions: 
split level 0: [1, 919] [1, 919] 
split level 1: [1, 422] [1, 422] 
split level 2: [1, 702] [1, 702] 
split level 3: [1, 116] [1, 558] 
split level 4: [1, 605] [1, 116] 
regular batch size: 2*32, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -12.661602020263672 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.010646343231201172
This batch time : update_bounds func: 0.0323	 prepare: 0.0116	 bound: 0.0110	 transfer: 0.0019	 finalize: 0.0075
Accumulated time: update_bounds func: 4.3454	 prepare: 0.2194	 bound: 3.9297	 transfer: 0.0019	 finalize: 0.1328
batch bounding time:  0.03239631652832031
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0831	 pickout: 0.0013	 decision: 0.0363	 get_bound: 0.0454	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 7.80323600769043

Image 69 label 9 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 7.861351728439331
69 1.0000000116860974e-07
##### [0:69] Tested against 8 ######
Model prediction is: tensor([[ -3.7638,  -6.5174,  -4.7464,  -2.7490,  -0.8870,  -4.4974, -11.8775,
           5.7896,  -0.5153,   2.6719]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 16, 14, 14]) != torch.Size([2, 9, 1, 16, 14, 14]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 7, 7]) != torch.Size([2, 9, 1, 32, 7, 7]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 14, 14])
1 /11 torch.Size([1, 32, 7, 7])
2 /14 torch.Size([1, 100])
best_l after optimization: 1.8633034229278564 with beta sum per layer: []
alpha/beta optimization time: 1.0792343616485596
alpha-CROWN with fixed intermediate bounds: tensor([[-1.8633]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-1.8633034229278564
layer 0 size torch.Size([3136]) unstable 1172
layer 1 size torch.Size([1568]) unstable 159
layer 2 size torch.Size([100]) unstable 18
-----------------
# of unstable neurons: 1349
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 14, 14]) pre split depth:  6
batch:  torch.Size([1, 16, 14, 14]) post split depth:  6
splitting decisions: 
split level 0: [2, 83] 
split level 1: [2, 47] 
split level 2: [2, 5] 
split level 3: [2, 81] 
split level 4: [2, 85] 
split level 5: [2, 41] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: -66.34832000732422 with beta sum per layer: [0.0, 0.0, 1.0979957580566406]
alpha/beta optimization time: 0.250812292098999
This batch time : update_bounds func: 0.2670	 prepare: 0.0085	 bound: 0.2511	 transfer: 0.0015	 finalize: 0.0041
Accumulated time: update_bounds func: 4.6124	 prepare: 0.2279	 bound: 4.1808	 transfer: 0.0015	 finalize: 0.1369
batch bounding time:  0.26714658737182617
Current worst splitting domains [lb, ub] (depth):
[-0.59968,   inf] (7), [-0.49356,   inf] (7), [-0.24240,   inf] (7), [-0.14806,   inf] (7), 
length of domains: 4
Total time: 0.3206	 pickout: 0.0010	 decision: 0.0408	 get_bound: 0.2786	 add_domain: 0.0003
Current lb:-0.5996838212013245
64 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.4193899631500244

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 16, 14, 14]) pre split depth:  4
batch:  torch.Size([4, 16, 14, 14]) post split depth:  4
splitting decisions: 
split level 0: [1, 571] [1, 571] [1, 416] [1, 927] 
split level 1: [1, 613] [1, 603] [1, 613] [1, 603] 
split level 2: [1, 603] [1, 927] [1, 927] [1, 416] 
split level 3: [1, 927] [1, 613] [1, 603] [1, 613] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: -4.580412864685059 with beta sum per layer: [0.0, 1.7908413410186768, 4.637299537658691]
alpha/beta optimization time: 0.23997235298156738
This batch time : update_bounds func: 0.2536	 prepare: 0.0068	 bound: 0.2403	 transfer: 0.0023	 finalize: 0.0041
Accumulated time: update_bounds func: 4.8660	 prepare: 0.2347	 bound: 4.4211	 transfer: 0.0023	 finalize: 0.1410
batch bounding time:  0.25382232666015625
Current worst splitting domains [lb, ub] (depth):
[-0.29970,   inf] (12), [-0.28529,   inf] (12), [-0.22947,   inf] (12), [-0.21490,   inf] (12), [-0.20361,   inf] (12), [-0.19145,   inf] (12), [-0.18582,   inf] (12), [-0.16791,   inf] (12), [-0.13424,   inf] (12), [-0.12095,   inf] (12), [-0.08420,   inf] (12), [-0.08046,   inf] (12), [-0.07542,   inf] (12), [-0.06057,   inf] (12), [-0.02572,   inf] (12), [-0.01401,   inf] (12), [-0.00617,   inf] (12), [-0.00518,   inf] (12), 
length of domains: 18
Total time: 0.2891	 pickout: 0.0012	 decision: 0.0255	 get_bound: 0.2613	 add_domain: 0.0010
Current lb:-0.2996959090232849
128 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.70882248878479

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([18, 16, 14, 14]) pre split depth:  2
batch:  torch.Size([18, 16, 14, 14]) post split depth:  2
splitting decisions: 
split level 0: [2, 79] [2, 79] [2, 79] [2, 79] [2, 79] [2, 79] [2, 79] [2, 79] [2, 79] [2, 79] 
split level 1: [1, 908] [1, 908] [1, 908] [1, 908] [1, 908] [1, 908] [1, 908] [1, 908] [1, 908] [1, 908] 
regular batch size: 2*36, diving batch size 1*0
best_l after optimization: -11.159226417541504 with beta sum per layer: [0.0, 2.772439956665039, 2.6625313758850098]
alpha/beta optimization time: 0.2405683994293213
This batch time : update_bounds func: 0.2583	 prepare: 0.0081	 bound: 0.2409	 transfer: 0.0042	 finalize: 0.0049
Accumulated time: update_bounds func: 5.1243	 prepare: 0.2428	 bound: 4.6620	 transfer: 0.0042	 finalize: 0.1459
batch bounding time:  0.25844573974609375
Current worst splitting domains [lb, ub] (depth):
[-0.17084,   inf] (15), [-0.14235,   inf] (15), [-0.09705,   inf] (15), [-0.06890,   inf] (15), [-0.05818,   inf] (15), [-0.04222,   inf] (15), [-0.02781,   inf] (15), [-0.02088,   inf] (15), 
length of domains: 8
Total time: 0.2912	 pickout: 0.0033	 decision: 0.0238	 get_bound: 0.2636	 add_domain: 0.0006
Current lb:-0.17084363102912903
200 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.0006563663482666

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 14, 14]) pre split depth:  3
batch:  torch.Size([8, 16, 14, 14]) post split depth:  3
splitting decisions: 
split level 0: [2, 92] [2, 92] [2, 92] [2, 92] [2, 92] [2, 92] [2, 92] [2, 92] 
split level 1: [1, 16] [1, 16] [1, 16] [1, 16] [1, 16] [1, 16] [1, 16] [1, 16] 
split level 2: [1, 72] [1, 72] [1, 72] [1, 72] [1, 72] [1, 72] [1, 72] [1, 72] 
regular batch size: 2*32, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -32.963783264160156 with beta sum per layer: [0.0, 0.0, 1.717888593673706]
alpha/beta optimization time: 0.008907079696655273
This batch time : update_bounds func: 0.0219	 prepare: 0.0074	 bound: 0.0092	 transfer: 0.0013	 finalize: 0.0039
Accumulated time: update_bounds func: 5.1462	 prepare: 0.2502	 bound: 4.6711	 transfer: 0.0013	 finalize: 0.1498
batch bounding time:  0.022008895874023438
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0541	 pickout: 0.0018	 decision: 0.0233	 get_bound: 0.0289	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 2.0552241802215576

Image 69 label 8 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 2.1133675575256348
69 1.0000000116860974e-07
##### [0:69] Tested against 4 ######
Model prediction is: tensor([[ -3.7638,  -6.5174,  -4.7464,  -2.7490,  -0.8870,  -4.4974, -11.8775,
           5.7896,  -0.5153,   2.6719]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 16, 14, 14]) != torch.Size([2, 9, 1, 16, 14, 14]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 7, 7]) != torch.Size([2, 9, 1, 32, 7, 7]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 14, 14])
1 /11 torch.Size([1, 32, 7, 7])
2 /14 torch.Size([1, 100])
best_l after optimization: 0.038993120193481445 with beta sum per layer: []
alpha/beta optimization time: 0.9353716373443604
alpha-CROWN with fixed intermediate bounds: tensor([[-0.0390]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.038993120193481445
layer 0 size torch.Size([3136]) unstable 1172
layer 1 size torch.Size([1568]) unstable 159
layer 2 size torch.Size([100]) unstable 18
-----------------
# of unstable neurons: 1349
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 14, 14]) pre split depth:  6
batch:  torch.Size([1, 16, 14, 14]) post split depth:  6
splitting decisions: 
split level 0: [2, 47] 
split level 1: [2, 5] 
split level 2: [2, 33] 
split level 3: [2, 56] 
split level 4: [2, 83] 
split level 5: [2, 85] 
regular batch size: 2*32, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -122.89152526855469 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.010581016540527344
This batch time : update_bounds func: 0.0249	 prepare: 0.0058	 bound: 0.0109	 transfer: 0.0037	 finalize: 0.0044
Accumulated time: update_bounds func: 5.1712	 prepare: 0.2560	 bound: 4.6820	 transfer: 0.0037	 finalize: 0.1542
batch bounding time:  0.025050878524780273
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0686	 pickout: 0.0010	 decision: 0.0344	 get_bound: 0.0332	 add_domain: 0.0001
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.0206141471862793

Image 69 label 4 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.0743317604064941
69 1.0000000116860974e-07
##### [0:69] Tested against 3 ######
Initial alpha-CROWN verified for label 3 with bound 0.39456748962402344
Image 69 label 3 verification end, final lower bound 0.39456748962402344, upper bound inf, time: 0.0003800392150878906
69 0.39456748962402344
##### [0:69] Tested against 0 ######
Initial alpha-CROWN verified for label 0 with bound 1.150029182434082
Image 69 label 0 verification end, final lower bound 1.150029182434082, upper bound inf, time: 0.00039696693420410156
69 1.150029182434082
##### [0:69] Tested against 5 ######
Initial alpha-CROWN verified for label 5 with bound 0.2932281494140625
Image 69 label 5 verification end, final lower bound 0.2932281494140625, upper bound inf, time: 0.001424551010131836
69 0.2932281494140625
##### [0:69] Tested against 2 ######
Initial alpha-CROWN verified for label 2 with bound 2.1775100231170654
Image 69 label 2 verification end, final lower bound 2.1775100231170654, upper bound inf, time: 0.0003771781921386719
69 2.1775100231170654
##### [0:69] Tested against 1 ######
Initial alpha-CROWN verified for label 1 with bound 2.7636938095092773
Image 69 label 1 verification end, final lower bound 2.7636938095092773, upper bound inf, time: 0.000377655029296875
69 2.7636938095092773
##### [0:69] Tested against 6 ######
Initial alpha-CROWN verified for label 6 with bound 3.9427547454833984
Image 69 label 6 verification end, final lower bound 3.9427547454833984, upper bound inf, time: 0.0003769397735595703
69 3.9427547454833984
##### [0:69] Tested against 7 ######
groundtruth label, skip!
Result: image 69 verification success (with branch and bound)!
Wall time: 21.46056365966797

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 1): [69]
verification failure idx (total 0): []
final verified acc: 100.0%[1]
verifier is called on 1 examples.
total verified: 1
mean time [cnt:1] (excluding attack success): 20.191497564315796
