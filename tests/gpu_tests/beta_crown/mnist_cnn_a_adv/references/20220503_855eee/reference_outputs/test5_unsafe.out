Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: mnist_cnn_a_adv.model
  name: mnist_cnn_4layer
data:
  start: 112
  end: 113
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: MNIST_SDP
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.3
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 1024
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 180
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Tue May  3 01:06:11 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(1, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Flatten(start_dim=1, end_dim=-1)
  (5): Linear(in_features=1568, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=10, bias=True)
)
############################
Shape: torch.Size([200, 1, 28, 28]) torch.Size([200]) torch.Size([200])
X range: tensor(1.) tensor(0.) tensor(0.1340)
############################
epsilon after preprocessing: 0.30000001192092896, data_max = tensor([[[[1.]]]]), data_min = tensor([[[[0.]]]])
Task length: 1
saving results to Verified_ret_[mnist_cnn_4layer]_start=112_end=113_iter=20_b=1024_timeout=180_branching=kfsb-max-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 112 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 5, correct label 5, image norm 91.76078796386719, logits tensor([-4.7719, -4.7969, -2.7344,  0.9703, -4.2306,  3.9781, -3.2837, -5.5923,
        -1.9195, -3.1023], device='cuda:0', grad_fn=<SelectBackward>)
Model prediction is: tensor([[-4.7719, -4.7969, -2.7344,  0.9703, -4.2306,  3.9781, -3.2837, -5.5923,
         -1.9195, -3.1023]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-4.0532, -6.6028, -7.3169, -5.3871, -4.1978, -3.8863, -7.0527, -4.0116,
         -4.1086]], device='cuda:0') None
best_l after optimization: 22.554550170898438 with beta sum per layer: []
alpha/beta optimization time: 7.134029865264893
initial alpha-CROWN bounds: tensor([[-1.4910, -2.8929, -4.3633, -3.4383, -1.6461, -1.4682, -3.6496, -1.8280,
         -1.7770]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-4.3633, device='cuda:0', grad_fn=<MinBackward1>)
##### [0:112] Tested against 2 ######
Model prediction is: tensor([[-4.7719, -4.7969, -2.7344,  0.9703, -4.2306,  3.9781, -3.2837, -5.5923,
         -1.9195, -3.1023]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /14
not setting layer /10 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 16, 14, 14]) != torch.Size([2, 9, 1, 16, 14, 14]))
setting alpha for layer /12 start_node /14
not setting layer /12 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 32, 7, 7]) != torch.Size([2, 9, 1, 32, 7, 7]))
not setting layer /15 start_node /16 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 14, 14])
1 /11 torch.Size([1, 32, 7, 7])
2 /14 torch.Size([1, 100])
best_l after optimization: 4.357344627380371 with beta sum per layer: []
alpha/beta optimization time: 1.7032451629638672
alpha-CROWN with fixed intermediate bounds: tensor([[-4.3573]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-4.357344627380371
layer 0 size torch.Size([3136]) unstable 1270
layer 1 size torch.Size([1568]) unstable 194
layer 2 size torch.Size([100]) unstable 22
-----------------
# of unstable neurons: 1486
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 14, 14]) pre split depth:  6
batch:  torch.Size([1, 16, 14, 14]) post split depth:  6
splitting decisions: 
split level 0: [2, 11] 
split level 1: [2, 67] 
split level 2: [2, 64] 
split level 3: [2, 46] 
split level 4: [2, 84] 
split level 5: [1, 1192] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: 2.9365954399108887 with beta sum per layer: [0.0, 3.8568665981292725, 45.33969497680664]
alpha/beta optimization time: 0.24194812774658203
This batch time : update_bounds func: 0.2536	 prepare: 0.0058	 bound: 0.2422	 transfer: 0.0015	 finalize: 0.0037
Accumulated time: update_bounds func: 0.2536	 prepare: 0.0058	 bound: 0.2422	 transfer: 0.0015	 finalize: 0.0037
batch bounding time:  0.25369715690612793
Current worst splitting domains [lb, ub] (depth):
[-3.25014,   inf] (7), [-2.98893,   inf] (7), [-2.94964,   inf] (7), [-2.69901,   inf] (7), [-2.42021,   inf] (7), [-2.18211,   inf] (7), [-1.77530,   inf] (7), [-1.62860,   inf] (7), [-0.85488,   inf] (7), [-0.84133,   inf] (7), [-0.78999,   inf] (7), [-0.78240,   inf] (7), [-0.51143,   inf] (7), [-0.49254,   inf] (7), [-0.47286,   inf] (7), [-0.42441,   inf] (7), [-0.42055,   inf] (7), [-0.36717,   inf] (7), [-0.20687,   inf] (7), [-0.17237,   inf] (7), 
length of domains: 21
Total time: 0.2978	 pickout: 0.0008	 decision: 0.0345	 get_bound: 0.2615	 add_domain: 0.0009
Current lb:-3.250143527984619
64 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.8353164196014404

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([21, 16, 14, 14]) pre split depth:  2
batch:  torch.Size([21, 16, 14, 14]) post split depth:  2
splitting decisions: 
split level 0: [2, 22] [2, 22] [2, 22] [2, 22] [2, 22] [2, 22] [2, 22] [2, 14] [2, 22] [2, 22] 
split level 1: [1, 1047] [1, 1047] [1, 1047] [1, 1047] [1, 66] [1, 1047] [1, 1053] [2, 22] [1, 1047] [1, 1047] 
regular batch size: 2*42, diving batch size 1*0
best_l after optimization: 29.986061096191406 with beta sum per layer: [0.0, 6.944433689117432, 67.15299224853516]
alpha/beta optimization time: 0.23981523513793945
This batch time : update_bounds func: 0.2564	 prepare: 0.0095	 bound: 0.2401	 transfer: 0.0018	 finalize: 0.0049
Accumulated time: update_bounds func: 0.5100	 prepare: 0.0153	 bound: 0.4823	 transfer: 0.0018	 finalize: 0.0086
batch bounding time:  0.25658702850341797
Current worst splitting domains [lb, ub] (depth):
[-3.01558,   inf] (10), [-2.75505,   inf] (10), [-2.67726,   inf] (10), [-2.61698,   inf] (10), [-2.44397,   inf] (10), [-2.40470,   inf] (10), [-2.40036,   inf] (10), [-2.18506,   inf] (10), [-2.09552,   inf] (10), [-1.83863,   inf] (10), [-1.81489,   inf] (10), [-1.58684,   inf] (10), [-1.36267,   inf] (10), [-1.24410,   inf] (10), [-0.98139,   inf] (10), [-0.84170,   inf] (10), [-0.75082,   inf] (10), [-0.69155,   inf] (10), [-0.63977,   inf] (10), [-0.61616,   inf] (10), 
length of domains: 39
Total time: 0.2927	 pickout: 0.0037	 decision: 0.0248	 get_bound: 0.2623	 add_domain: 0.0019
Current lb:-3.015575885772705
148 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.128519058227539

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([39, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([39, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 709] [1, 66] [1, 557] [1, 66] [1, 557] [1, 709] [1, 709] [1, 709] [2, 14] [2, 14] 
regular batch size: 2*39, diving batch size 1*0
best_l after optimization: 48.732383728027344 with beta sum per layer: [0.0, 13.729248046875, 65.06985473632812]
alpha/beta optimization time: 0.24500513076782227
This batch time : update_bounds func: 0.2608	 prepare: 0.0091	 bound: 0.2453	 transfer: 0.0017	 finalize: 0.0045
Accumulated time: update_bounds func: 0.7708	 prepare: 0.0244	 bound: 0.7276	 transfer: 0.0017	 finalize: 0.0131
batch bounding time:  0.2609851360321045
Current worst splitting domains [lb, ub] (depth):
[-2.81026,   inf] (12), [-2.77571,   inf] (12), [-2.67665,   inf] (12), [-2.56412,   inf] (12), [-2.49902,   inf] (12), [-2.43584,   inf] (12), [-2.33891,   inf] (12), [-2.31496,   inf] (12), [-2.24273,   inf] (12), [-2.17024,   inf] (12), [-2.15629,   inf] (12), [-2.14739,   inf] (12), [-2.10966,   inf] (12), [-2.00398,   inf] (12), [-1.97558,   inf] (12), [-1.93965,   inf] (12), [-1.91251,   inf] (12), [-1.74452,   inf] (12), [-1.70215,   inf] (12), [-1.41060,   inf] (12), 
length of domains: 46
Total time: 0.2976	 pickout: 0.0062	 decision: 0.0279	 get_bound: 0.2611	 add_domain: 0.0024
Current lb:-2.8102641105651855
226 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.4268758296966553

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([46, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([46, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 557] [1, 557] [1, 557] [1, 709] [1, 557] [1, 557] [1, 557] [1, 709] [1, 709] [1, 557] 
regular batch size: 2*46, diving batch size 1*0
best_l after optimization: 74.36910247802734 with beta sum per layer: [0.0, 22.58888053894043, 62.978729248046875]
alpha/beta optimization time: 0.23967528343200684
This batch time : update_bounds func: 0.2586	 prepare: 0.0102	 bound: 0.2400	 transfer: 0.0026	 finalize: 0.0056
Accumulated time: update_bounds func: 1.0294	 prepare: 0.0346	 bound: 0.9676	 transfer: 0.0026	 finalize: 0.0187
batch bounding time:  0.2587873935699463
Current worst splitting domains [lb, ub] (depth):
[-2.71289,   inf] (14), [-2.67752,   inf] (14), [-2.56553,   inf] (14), [-2.41777,   inf] (14), [-2.38001,   inf] (14), [-2.37625,   inf] (14), [-2.36373,   inf] (14), [-2.34395,   inf] (14), [-2.32960,   inf] (14), [-2.24359,   inf] (14), [-2.22586,   inf] (14), [-2.21844,   inf] (14), [-2.09327,   inf] (14), [-2.06977,   inf] (14), [-2.04683,   inf] (14), [-2.04285,   inf] (14), [-2.03643,   inf] (14), [-2.02765,   inf] (14), [-1.99924,   inf] (14), [-1.97965,   inf] (14), 
length of domains: 53
Total time: 0.2977	 pickout: 0.0072	 decision: 0.0288	 get_bound: 0.2589	 add_domain: 0.0026
Current lb:-2.712887763977051
318 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.7252376079559326

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([53, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([53, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 66] [1, 66] [1, 709] [1, 66] [1, 66] [1, 709] [1, 660] [1, 709] [1, 667] [1, 709] 
regular batch size: 2*53, diving batch size 1*0
best_l after optimization: 135.95550537109375 with beta sum per layer: [0.0, 41.13093185424805, 50.83148956298828]
alpha/beta optimization time: 0.24091815948486328
This batch time : update_bounds func: 0.2623	 prepare: 0.0115	 bound: 0.2412	 transfer: 0.0033	 finalize: 0.0060
Accumulated time: update_bounds func: 1.2917	 prepare: 0.0462	 bound: 1.2088	 transfer: 0.0033	 finalize: 0.0246
batch bounding time:  0.2624378204345703
Current worst splitting domains [lb, ub] (depth):
[-2.64711,   inf] (16), [-2.60805,   inf] (16), [-2.46858,   inf] (16), [-2.46440,   inf] (16), [-2.35447,   inf] (16), [-2.30648,   inf] (16), [-2.29922,   inf] (16), [-2.28668,   inf] (16), [-2.23964,   inf] (16), [-2.23406,   inf] (16), [-2.15977,   inf] (16), [-2.15156,   inf] (16), [-2.13053,   inf] (16), [-2.11498,   inf] (16), [-2.11331,   inf] (16), [-2.05075,   inf] (16), [-2.02073,   inf] (16), [-1.99325,   inf] (16), [-1.98436,   inf] (16), [-1.98000,   inf] (16), 
length of domains: 85
Total time: 0.3070	 pickout: 0.0081	 decision: 0.0317	 get_bound: 0.2626	 add_domain: 0.0046
Current lb:-2.647113084793091
424 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.033070802688599

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([85, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([85, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [2, 14] [2, 14] [2, 33] [2, 14] [2, 14] [2, 14] [1, 667] [1, 660] [1, 660] [1, 660] 
regular batch size: 2*85, diving batch size 1*0
best_l after optimization: 213.17782592773438 with beta sum per layer: [0.0, 116.1365966796875, 59.33639144897461]
alpha/beta optimization time: 0.2482006549835205
This batch time : update_bounds func: 0.2826	 prepare: 0.0175	 bound: 0.2485	 transfer: 0.0063	 finalize: 0.0099
Accumulated time: update_bounds func: 1.5743	 prepare: 0.0637	 bound: 1.4573	 transfer: 0.0063	 finalize: 0.0346
batch bounding time:  0.2828407287597656
Current worst splitting domains [lb, ub] (depth):
[-2.56363,   inf] (18), [-2.52345,   inf] (18), [-2.38452,   inf] (18), [-2.31163,   inf] (18), [-2.26674,   inf] (18), [-2.26140,   inf] (18), [-2.22172,   inf] (18), [-2.21058,   inf] (18), [-2.20676,   inf] (18), [-2.15543,   inf] (18), [-2.14063,   inf] (18), [-2.06083,   inf] (18), [-2.03476,   inf] (18), [-1.95563,   inf] (18), [-1.95514,   inf] (18), [-1.93683,   inf] (18), [-1.92018,   inf] (18), [-1.91911,   inf] (18), [-1.90844,   inf] (18), [-1.90783,   inf] (18), 
length of domains: 168
Total time: 0.3455	 pickout: 0.0127	 decision: 0.0401	 get_bound: 0.2831	 add_domain: 0.0096
Current lb:-2.5636332035064697
594 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.379940748214722

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([168, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([168, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 660] [1, 660] [2, 33] [2, 14] [1, 660] [1, 660] [1, 660] [2, 33] [2, 33] [2, 33] 
regular batch size: 2*168, diving batch size 1*0
best_l after optimization: 281.70794677734375 with beta sum per layer: [0.0, 290.0694580078125, 152.5862579345703]
alpha/beta optimization time: 0.2884187698364258
This batch time : update_bounds func: 0.3601	 prepare: 0.0333	 bound: 0.2887	 transfer: 0.0172	 finalize: 0.0201
Accumulated time: update_bounds func: 1.9343	 prepare: 0.0969	 bound: 1.7460	 transfer: 0.0172	 finalize: 0.0547
batch bounding time:  0.3604397773742676
Current worst splitting domains [lb, ub] (depth):
[-2.53582,   inf] (20), [-2.48644,   inf] (20), [-2.25023,   inf] (20), [-2.22862,   inf] (20), [-2.22832,   inf] (20), [-2.19913,   inf] (20), [-2.19667,   inf] (20), [-2.17768,   inf] (20), [-2.16660,   inf] (20), [-2.10255,   inf] (20), [-2.06737,   inf] (20), [-2.04087,   inf] (20), [-2.03750,   inf] (20), [-2.01725,   inf] (20), [-1.99114,   inf] (20), [-1.97987,   inf] (20), [-1.97958,   inf] (20), [-1.97799,   inf] (20), [-1.95867,   inf] (20), [-1.93548,   inf] (20), 
length of domains: 277
Total time: 0.4643	 pickout: 0.0242	 decision: 0.0618	 get_bound: 0.3609	 add_domain: 0.0173
Current lb:-2.5358238220214844
930 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.847024440765381

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([277, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([277, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [2, 33] [2, 33] [2, 33] [1, 660] [1, 666] [2, 33] [2, 33] [1, 660] [2, 33] [1, 666] 
regular batch size: 2*277, diving batch size 1*0
best_l after optimization: 369.322998046875 with beta sum per layer: [0.0, 571.9432373046875, 259.6400146484375]
alpha/beta optimization time: 0.3106083869934082
This batch time : update_bounds func: 0.4661	 prepare: 0.0534	 bound: 0.3109	 transfer: 0.0167	 finalize: 0.0837
Accumulated time: update_bounds func: 2.4004	 prepare: 0.1503	 bound: 2.0570	 transfer: 0.0167	 finalize: 0.1384
batch bounding time:  0.4666604995727539
Current worst splitting domains [lb, ub] (depth):
[-2.38180,   inf] (22), [-2.33923,   inf] (22), [-2.33043,   inf] (22), [-2.28724,   inf] (22), [-2.10337,   inf] (22), [-2.09005,   inf] (22), [-2.04400,   inf] (22), [-2.03772,   inf] (22), [-2.03250,   inf] (22), [-2.03126,   inf] (22), [-2.03014,   inf] (22), [-2.02253,   inf] (22), [-2.01936,   inf] (22), [-2.01274,   inf] (22), [-1.99352,   inf] (22), [-1.96853,   inf] (22), [-1.96603,   inf] (22), [-1.95160,   inf] (22), [-1.94488,   inf] (22), [-1.89456,   inf] (22), 
length of domains: 422
Total time: 0.6263	 pickout: 0.0429	 decision: 0.0890	 get_bound: 0.4675	 add_domain: 0.0269
Current lb:-2.3817977905273438
1484 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.477606534957886

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([422, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([422, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 1053] [1, 666] [1, 1053] [1, 666] [1, 1053] [1, 1053] [1, 1053] [1, 666] [1, 1053] [1, 666] 
regular batch size: 2*422, diving batch size 1*0
best_l after optimization: 509.5675354003906 with beta sum per layer: [0.0, 957.7369995117188, 381.4252624511719]
alpha/beta optimization time: 0.376514196395874
This batch time : update_bounds func: 0.5285	 prepare: 0.0798	 bound: 0.3768	 transfer: 0.0213	 finalize: 0.0488
Accumulated time: update_bounds func: 2.9289	 prepare: 0.2301	 bound: 2.4338	 transfer: 0.0213	 finalize: 0.1872
batch bounding time:  0.5292963981628418
Current worst splitting domains [lb, ub] (depth):
[-2.30555,   inf] (24), [-2.25401,   inf] (24), [-2.13015,   inf] (24), [-2.12065,   inf] (24), [-2.07525,   inf] (24), [-2.07230,   inf] (24), [-2.01312,   inf] (24), [-2.00632,   inf] (24), [-1.97017,   inf] (24), [-1.94266,   inf] (24), [-1.93899,   inf] (24), [-1.93360,   inf] (24), [-1.92348,   inf] (24), [-1.92321,   inf] (24), [-1.83793,   inf] (24), [-1.81438,   inf] (24), [-1.81352,   inf] (24), [-1.79954,   inf] (24), [-1.79229,   inf] (24), [-1.78885,   inf] (24), 
length of domains: 665
Total time: 0.7588	 pickout: 0.0620	 decision: 0.1229	 get_bound: 0.5305	 add_domain: 0.0434
Current lb:-2.3055474758148193
2328 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.245016098022461

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([665, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([665, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 666] [1, 666] [1, 1058] [1, 1058] [1, 1058] [1, 1058] [1, 666] [1, 666] [1, 666] [1, 660] 
regular batch size: 2*665, diving batch size 1*0
best_l after optimization: 731.2164306640625 with beta sum per layer: [0.0, 1618.327392578125, 568.09619140625]
alpha/beta optimization time: 0.5002374649047852
This batch time : update_bounds func: 0.7329	 prepare: 0.1257	 bound: 0.5006	 transfer: 0.0275	 finalize: 0.0760
Accumulated time: update_bounds func: 3.6618	 prepare: 0.3559	 bound: 2.9344	 transfer: 0.0275	 finalize: 0.2632
batch bounding time:  0.733971357345581
Current worst splitting domains [lb, ub] (depth):
[-2.11143,   inf] (26), [-2.11056,   inf] (26), [-2.06378,   inf] (26), [-2.05731,   inf] (26), [-2.00730,   inf] (26), [-1.97626,   inf] (26), [-1.95808,   inf] (26), [-1.92999,   inf] (26), [-1.88380,   inf] (26), [-1.84100,   inf] (26), [-1.83221,   inf] (26), [-1.81381,   inf] (26), [-1.81345,   inf] (26), [-1.80880,   inf] (26), [-1.80709,   inf] (26), [-1.80321,   inf] (26), [-1.79200,   inf] (26), [-1.77749,   inf] (26), [-1.77473,   inf] (26), [-1.76962,   inf] (26), 
length of domains: 1110
Total time: 1.1390	 pickout: 0.0942	 decision: 0.2308	 get_bound: 0.7359	 add_domain: 0.0782
Current lb:-2.1114306449890137
3658 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.395016193389893

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 667] [1, 667] [1, 667] [1, 667] [1, 667] [1, 667] [1, 906] [1, 906] [1, 667] [1, 906] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1035.469482421875 with beta sum per layer: [0.0, 2631.662353515625, 766.2841186523438]
alpha/beta optimization time: 0.6828513145446777
This batch time : update_bounds func: 1.1179	 prepare: 0.1951	 bound: 0.6832	 transfer: 0.0485	 finalize: 0.1863
Accumulated time: update_bounds func: 4.7797	 prepare: 0.5510	 bound: 3.6176	 transfer: 0.0485	 finalize: 0.4494
batch bounding time:  1.119584560394287
Current worst splitting domains [lb, ub] (depth):
[-2.04834,   inf] (28), [-2.04756,   inf] (28), [-1.99941,   inf] (28), [-1.99527,   inf] (28), [-1.92244,   inf] (28), [-1.91674,   inf] (28), [-1.90461,   inf] (28), [-1.88653,   inf] (28), [-1.86971,   inf] (28), [-1.83111,   inf] (28), [-1.80570,   inf] (28), [-1.76624,   inf] (28), [-1.76485,   inf] (28), [-1.76269,   inf] (28), [-1.76100,   inf] (28), [-1.74907,   inf] (28), [-1.74723,   inf] (28), [-1.74378,   inf] (28), [-1.74194,   inf] (28), [-1.73853,   inf] (28), 
length of domains: 1812
Total time: 1.7288	 pickout: 0.1500	 decision: 0.3306	 get_bound: 1.1225	 add_domain: 0.1257
Current lb:-2.048344612121582
5706 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.140954494476318

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 906] [1, 906] [1, 906] [1, 906] [1, 906] [1, 906] [1, 906] [1, 906] [1, 906] [1, 906] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1324.592041015625 with beta sum per layer: [0.0, 2309.015625, 709.5643920898438]
alpha/beta optimization time: 0.6843318939208984
This batch time : update_bounds func: 1.1157	 prepare: 0.1940	 bound: 0.6847	 transfer: 0.0528	 finalize: 0.1791
Accumulated time: update_bounds func: 5.8954	 prepare: 0.7451	 bound: 4.3023	 transfer: 0.0528	 finalize: 0.6286
batch bounding time:  1.1173617839813232
Current worst splitting domains [lb, ub] (depth):
[-1.91078,   inf] (30), [-1.90497,   inf] (30), [-1.90472,   inf] (30), [-1.89976,   inf] (30), [-1.86635,   inf] (30), [-1.85662,   inf] (30), [-1.85430,   inf] (30), [-1.84282,   inf] (30), [-1.77038,   inf] (30), [-1.76768,   inf] (30), [-1.74627,   inf] (30), [-1.74223,   inf] (30), [-1.73558,   inf] (30), [-1.73534,   inf] (30), [-1.73455,   inf] (30), [-1.73098,   inf] (30), [-1.72677,   inf] (30), [-1.71886,   inf] (30), [-1.71052,   inf] (30), [-1.70358,   inf] (30), 
length of domains: 2675
Total time: 1.7599	 pickout: 0.1542	 decision: 0.3406	 get_bound: 1.1203	 add_domain: 0.1448
Current lb:-1.9107780456542969
7754 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.917458772659302

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 415] [1, 415] [1, 415] [1, 415] [1, 415] [1, 415] [1, 415] [1, 415] [1, 415] [1, 415] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1522.1392822265625 with beta sum per layer: [0.0, 2229.00048828125, 545.79833984375]
alpha/beta optimization time: 0.6814279556274414
This batch time : update_bounds func: 1.0568	 prepare: 0.1912	 bound: 0.6818	 transfer: 0.0549	 finalize: 0.1237
Accumulated time: update_bounds func: 6.9522	 prepare: 0.9363	 bound: 4.9840	 transfer: 0.0549	 finalize: 0.7522
batch bounding time:  1.0585529804229736
Current worst splitting domains [lb, ub] (depth):
[-1.84768,   inf] (32), [-1.84131,   inf] (32), [-1.83854,   inf] (32), [-1.83065,   inf] (32), [-1.80197,   inf] (32), [-1.79324,   inf] (32), [-1.78885,   inf] (32), [-1.77845,   inf] (32), [-1.70205,   inf] (32), [-1.69943,   inf] (32), [-1.68236,   inf] (32), [-1.67487,   inf] (32), [-1.67026,   inf] (32), [-1.66481,   inf] (32), [-1.66402,   inf] (32), [-1.65933,   inf] (32), [-1.65439,   inf] (32), [-1.64990,   inf] (32), [-1.63396,   inf] (32), [-1.62905,   inf] (32), 
length of domains: 3551
Total time: 1.7919	 pickout: 0.1540	 decision: 0.3487	 get_bound: 1.0615	 add_domain: 0.2277
Current lb:-1.8476786613464355
9802 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.726573944091797

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 1058] [1, 1058] [1, 1058] [1, 1058] [1, 1058] [1, 1058] [1, 1058] [1, 1058] [1, 1058] [1, 1058] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1735.356201171875 with beta sum per layer: [0.0, 2176.42236328125, 392.59490966796875]
alpha/beta optimization time: 0.6821248531341553
This batch time : update_bounds func: 1.0589	 prepare: 0.1968	 bound: 0.6825	 transfer: 0.0545	 finalize: 0.1202
Accumulated time: update_bounds func: 8.0111	 prepare: 1.1330	 bound: 5.6665	 transfer: 0.0545	 finalize: 0.8724
batch bounding time:  1.0606005191802979
Current worst splitting domains [lb, ub] (depth):
[-1.77891,   inf] (34), [-1.77363,   inf] (34), [-1.76645,   inf] (34), [-1.76104,   inf] (34), [-1.73038,   inf] (34), [-1.72182,   inf] (34), [-1.71992,   inf] (34), [-1.71270,   inf] (34), [-1.68894,   inf] (34), [-1.68850,   inf] (34), [-1.66303,   inf] (34), [-1.66033,   inf] (34), [-1.65109,   inf] (34), [-1.65057,   inf] (34), [-1.64120,   inf] (34), [-1.64053,   inf] (34), [-1.63835,   inf] (34), [-1.63348,   inf] (34), [-1.62905,   inf] (34), [-1.62800,   inf] (34), 
length of domains: 4534
Total time: 1.8857	 pickout: 0.1646	 decision: 0.3809	 get_bound: 1.0636	 add_domain: 0.2766
Current lb:-1.7789068222045898
11850 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.628865957260132

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 942] [1, 942] [1, 969] [1, 942] [1, 969] [1, 969] [1, 942] [1, 969] [1, 969] [1, 969] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1773.3131103515625 with beta sum per layer: [0.0, 2040.8299560546875, 307.92205810546875]
alpha/beta optimization time: 0.6788318157196045
This batch time : update_bounds func: 1.1669	 prepare: 0.1987	 bound: 0.6792	 transfer: 0.0545	 finalize: 0.2294
Accumulated time: update_bounds func: 9.1781	 prepare: 1.3317	 bound: 6.3457	 transfer: 0.0545	 finalize: 1.1017
batch bounding time:  1.1686971187591553
Current worst splitting domains [lb, ub] (depth):
[-1.75503,   inf] (36), [-1.71632,   inf] (36), [-1.70913,   inf] (36), [-1.70427,   inf] (36), [-1.70127,   inf] (36), [-1.69897,   inf] (36), [-1.68633,   inf] (36), [-1.67375,   inf] (36), [-1.67342,   inf] (36), [-1.64505,   inf] (36), [-1.62608,   inf] (36), [-1.62371,   inf] (36), [-1.61479,   inf] (36), [-1.61038,   inf] (36), [-1.58148,   inf] (36), [-1.57672,   inf] (36), [-1.57236,   inf] (36), [-1.56668,   inf] (36), [-1.56319,   inf] (36), [-1.56172,   inf] (36), 
length of domains: 5529
Total time: 1.7839	 pickout: 0.1549	 decision: 0.2847	 get_bound: 1.1718	 add_domain: 0.1726
Current lb:-1.7550325393676758
13898 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.429908275604248

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 942] [1, 942] [1, 942] [1, 969] [1, 942] [1, 969] [1, 969] [1, 942] [1, 942] [1, 969] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1643.64501953125 with beta sum per layer: [0.0, 1937.538330078125, 299.9276428222656]
alpha/beta optimization time: 0.684314489364624
This batch time : update_bounds func: 1.2016	 prepare: 0.1970	 bound: 0.6847	 transfer: 0.0544	 finalize: 0.2606
Accumulated time: update_bounds func: 10.3796	 prepare: 1.5287	 bound: 7.0303	 transfer: 0.0544	 finalize: 1.3623
batch bounding time:  1.2036309242248535
Current worst splitting domains [lb, ub] (depth):
[-1.69145,   inf] (38), [-1.68682,   inf] (38), [-1.68131,   inf] (38), [-1.67667,   inf] (38), [-1.64017,   inf] (38), [-1.63425,   inf] (38), [-1.63422,   inf] (38), [-1.62702,   inf] (38), [-1.59805,   inf] (38), [-1.59692,   inf] (38), [-1.55177,   inf] (38), [-1.54890,   inf] (38), [-1.54835,   inf] (38), [-1.54668,   inf] (38), [-1.53804,   inf] (38), [-1.53260,   inf] (38), [-1.50954,   inf] (38), [-1.50069,   inf] (38), [-1.49790,   inf] (38), [-1.49315,   inf] (38), 
length of domains: 6493
Total time: 1.9433	 pickout: 0.1559	 decision: 0.4056	 get_bound: 1.2070	 add_domain: 0.1748
Current lb:-1.6914536952972412
15946 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.391560316085815

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 613] [1, 613] [1, 613] [1, 613] [1, 613] [1, 613] [1, 613] [1, 613] [1, 613] [1, 613] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1728.7008056640625 with beta sum per layer: [0.0, 1654.70703125, 262.320556640625]
alpha/beta optimization time: 0.6855719089508057
This batch time : update_bounds func: 1.2060	 prepare: 0.1992	 bound: 0.6859	 transfer: 0.0537	 finalize: 0.1266
Accumulated time: update_bounds func: 11.5856	 prepare: 1.7279	 bound: 7.7162	 transfer: 0.0537	 finalize: 1.4889
batch bounding time:  1.2078008651733398
Current worst splitting domains [lb, ub] (depth):
[-1.56908,   inf] (40), [-1.56018,   inf] (40), [-1.55955,   inf] (40), [-1.55071,   inf] (40), [-1.54912,   inf] (40), [-1.54443,   inf] (40), [-1.53912,   inf] (40), [-1.53432,   inf] (40), [-1.51731,   inf] (40), [-1.51276,   inf] (40), [-1.51131,   inf] (40), [-1.50745,   inf] (40), [-1.49549,   inf] (40), [-1.49042,   inf] (40), [-1.48697,   inf] (40), [-1.48188,   inf] (40), [-1.47509,   inf] (40), [-1.46174,   inf] (40), [-1.45935,   inf] (40), [-1.45800,   inf] (40), 
length of domains: 7450
Total time: 1.8362	 pickout: 0.1586	 decision: 0.2861	 get_bound: 1.2109	 add_domain: 0.1806
Current lb:-1.5690793991088867
17994 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 20.24782681465149

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 123] [1, 123] [1, 123] [1, 123] [1, 1054] [1, 1054] [1, 1054] [1, 1054] [1, 123] [1, 123] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1842.810546875 with beta sum per layer: [0.0, 1485.943115234375, 186.54917907714844]
alpha/beta optimization time: 0.6994450092315674
This batch time : update_bounds func: 1.1373	 prepare: 0.1963	 bound: 0.6998	 transfer: 0.0551	 finalize: 0.1809
Accumulated time: update_bounds func: 12.7229	 prepare: 1.9242	 bound: 8.4160	 transfer: 0.0551	 finalize: 1.6698
batch bounding time:  1.1393201351165771
Current worst splitting domains [lb, ub] (depth):
[-1.47413,   inf] (42), [-1.47354,   inf] (42), [-1.47342,   inf] (42), [-1.46623,   inf] (42), [-1.46245,   inf] (42), [-1.46108,   inf] (42), [-1.45869,   inf] (42), [-1.45443,   inf] (42), [-1.44397,   inf] (42), [-1.44197,   inf] (42), [-1.43494,   inf] (42), [-1.42966,   inf] (42), [-1.42478,   inf] (42), [-1.42195,   inf] (42), [-1.42073,   inf] (42), [-1.41671,   inf] (42), [-1.41487,   inf] (42), [-1.41366,   inf] (42), [-1.40571,   inf] (42), [-1.39769,   inf] (42), 
length of domains: 8467
Total time: 2.1279	 pickout: 0.1574	 decision: 0.4363	 get_bound: 1.1425	 add_domain: 0.3917
Current lb:-1.4741277694702148
20042 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 22.394142866134644

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 68] [1, 68] [1, 68] [1, 68] [1, 662] [1, 68] [1, 68] [1, 68] [1, 68] [1, 68] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1773.9853515625 with beta sum per layer: [0.0, 1609.4532470703125, 185.56924438476562]
alpha/beta optimization time: 0.7036392688751221
This batch time : update_bounds func: 1.4185	 prepare: 0.2944	 bound: 0.7040	 transfer: 0.0539	 finalize: 0.3609
Accumulated time: update_bounds func: 14.1415	 prepare: 2.2185	 bound: 9.1201	 transfer: 0.0539	 finalize: 2.0307
batch bounding time:  1.4205718040466309
Current worst splitting domains [lb, ub] (depth):
[-1.41999,   inf] (44), [-1.41812,   inf] (44), [-1.41789,   inf] (44), [-1.41181,   inf] (44), [-1.40614,   inf] (44), [-1.40119,   inf] (44), [-1.40001,   inf] (44), [-1.39890,   inf] (44), [-1.38900,   inf] (44), [-1.38593,   inf] (44), [-1.37822,   inf] (44), [-1.37463,   inf] (44), [-1.37126,   inf] (44), [-1.36690,   inf] (44), [-1.36623,   inf] (44), [-1.36177,   inf] (44), [-1.35844,   inf] (44), [-1.35296,   inf] (44), [-1.33805,   inf] (44), [-1.33756,   inf] (44), 
length of domains: 9488
Total time: 2.1995	 pickout: 0.2131	 decision: 0.3563	 get_bound: 1.4240	 add_domain: 0.2062
Current lb:-1.4199886322021484
22090 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 24.612531900405884

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 408] [1, 662] [1, 123] [1, 408] [1, 408] [1, 123] [1, 68] [1, 612] [1, 1054] [1, 1054] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1726.083251953125 with beta sum per layer: [0.0, 1696.058837890625, 152.37510681152344]
alpha/beta optimization time: 0.7035894393920898
This batch time : update_bounds func: 1.4301	 prepare: 0.2955	 bound: 0.7040	 transfer: 0.0547	 finalize: 0.3707
Accumulated time: update_bounds func: 15.5716	 prepare: 2.5141	 bound: 9.8240	 transfer: 0.0547	 finalize: 2.4014
batch bounding time:  1.4320311546325684
Current worst splitting domains [lb, ub] (depth):
[-1.36606,   inf] (46), [-1.35831,   inf] (46), [-1.35442,   inf] (46), [-1.35099,   inf] (46), [-1.33957,   inf] (46), [-1.32670,   inf] (46), [-1.32647,   inf] (46), [-1.31559,   inf] (46), [-1.31286,   inf] (46), [-1.30961,   inf] (46), [-1.30701,   inf] (46), [-1.30396,   inf] (46), [-1.30377,   inf] (46), [-1.30321,   inf] (46), [-1.29436,   inf] (46), [-1.29304,   inf] (46), [-1.29282,   inf] (46), [-1.29233,   inf] (46), [-1.28998,   inf] (46), [-1.28795,   inf] (46), 
length of domains: 10511
Total time: 2.2237	 pickout: 0.2133	 decision: 0.3585	 get_bound: 1.4353	 add_domain: 0.2166
Current lb:-1.3660621643066406
24138 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 26.856248378753662

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [2, 56] [2, 56] [1, 123] [1, 612] [1, 123] [1, 1054] [2, 56] [2, 56] [2, 56] [2, 56] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1486.247802734375 with beta sum per layer: [0.0, 1706.3138427734375, 157.686767578125]
alpha/beta optimization time: 0.7057609558105469
This batch time : update_bounds func: 1.2537	 prepare: 0.3032	 bound: 0.7062	 transfer: 0.0547	 finalize: 0.1844
Accumulated time: update_bounds func: 16.8253	 prepare: 2.8173	 bound: 10.5302	 transfer: 0.0547	 finalize: 2.5859
batch bounding time:  1.2556357383728027
Current worst splitting domains [lb, ub] (depth):
[-1.32749,   inf] (48), [-1.31877,   inf] (48), [-1.28218,   inf] (48), [-1.27984,   inf] (48), [-1.27733,   inf] (48), [-1.27207,   inf] (48), [-1.26841,   inf] (48), [-1.26732,   inf] (48), [-1.25729,   inf] (48), [-1.25594,   inf] (48), [-1.24385,   inf] (48), [-1.24157,   inf] (48), [-1.23749,   inf] (48), [-1.23643,   inf] (48), [-1.23582,   inf] (48), [-1.23405,   inf] (48), [-1.23338,   inf] (48), [-1.23297,   inf] (48), [-1.23011,   inf] (48), [-1.22713,   inf] (48), 
length of domains: 11386
Total time: 2.2450	 pickout: 0.2128	 decision: 0.5680	 get_bound: 1.2588	 add_domain: 0.2055
Current lb:-1.3274879455566406
26186 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 29.125375747680664

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 1054] [1, 612] [1, 662] [2, 56] [1, 612] [1, 612] [2, 56] [1, 662] [1, 408] [2, 56] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1079.156982421875 with beta sum per layer: [0.0, 1653.5328369140625, 206.37648010253906]
alpha/beta optimization time: 0.7045533657073975
This batch time : update_bounds func: 1.2553	 prepare: 0.3058	 bound: 0.7050	 transfer: 0.0551	 finalize: 0.1843
Accumulated time: update_bounds func: 18.0806	 prepare: 3.1230	 bound: 11.2352	 transfer: 0.0551	 finalize: 2.7702
batch bounding time:  1.257300615310669
Current worst splitting domains [lb, ub] (depth):
[-1.25767,   inf] (50), [-1.24379,   inf] (50), [-1.23841,   inf] (50), [-1.22402,   inf] (50), [-1.22175,   inf] (50), [-1.21442,   inf] (50), [-1.21035,   inf] (50), [-1.20956,   inf] (50), [-1.20825,   inf] (50), [-1.20365,   inf] (50), [-1.19847,   inf] (50), [-1.19609,   inf] (50), [-1.19561,   inf] (50), [-1.19544,   inf] (50), [-1.19241,   inf] (50), [-1.19176,   inf] (50), [-1.18715,   inf] (50), [-1.18621,   inf] (50), [-1.18479,   inf] (50), [-1.18451,   inf] (50), 
length of domains: 11935
Total time: 2.2418	 pickout: 0.2160	 decision: 0.5888	 get_bound: 1.2606	 add_domain: 0.1764
Current lb:-1.257669448852539
28234 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 31.39568257331848

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 1054] [1, 612] [1, 1054] [1, 1208] [1, 408] [1, 1054] [1, 1054] [1, 1208] [1, 1208] [1, 612] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1288.2930908203125 with beta sum per layer: [6.2675275802612305, 1669.6221923828125, 172.22103881835938]
alpha/beta optimization time: 0.6828763484954834
This batch time : update_bounds func: 1.1885	 prepare: 0.3108	 bound: 0.6833	 transfer: 0.0546	 finalize: 0.1339
Accumulated time: update_bounds func: 19.2690	 prepare: 3.4338	 bound: 11.9184	 transfer: 0.0546	 finalize: 2.9041
batch bounding time:  1.1902711391448975
Current worst splitting domains [lb, ub] (depth):
[-1.17671,   inf] (52), [-1.17544,   inf] (52), [-1.17316,   inf] (52), [-1.16288,   inf] (52), [-1.16222,   inf] (52), [-1.16026,   inf] (52), [-1.15995,   inf] (52), [-1.15818,   inf] (52), [-1.15414,   inf] (52), [-1.14414,   inf] (52), [-1.13445,   inf] (52), [-1.13443,   inf] (52), [-1.13235,   inf] (52), [-1.12593,   inf] (52), [-1.12358,   inf] (52), [-1.12093,   inf] (52), [-1.12051,   inf] (52), [-1.12009,   inf] (52), [-1.11445,   inf] (52), [-1.11143,   inf] (52), 
length of domains: 12676
Total time: 2.2199	 pickout: 0.2225	 decision: 0.6150	 get_bound: 1.1934	 add_domain: 0.1889
Current lb:-1.176708459854126
30282 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 33.64056992530823

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 408] [1, 1208] [1, 1208] [1, 612] [1, 408] [1, 408] [1, 1208] [1, 116] [1, 1208] [1, 1208] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1376.4766845703125 with beta sum per layer: [7.722773551940918, 1747.109130859375, 137.60043334960938]
alpha/beta optimization time: 0.682694673538208
This batch time : update_bounds func: 1.0806	 prepare: 0.2062	 bound: 0.6830	 transfer: 0.0550	 finalize: 0.1301
Accumulated time: update_bounds func: 20.3496	 prepare: 3.6400	 bound: 12.6015	 transfer: 0.0550	 finalize: 3.0342
batch bounding time:  1.0824251174926758
Current worst splitting domains [lb, ub] (depth):
[-1.13551,   inf] (54), [-1.13250,   inf] (54), [-1.12444,   inf] (54), [-1.12149,   inf] (54), [-1.12047,   inf] (54), [-1.11597,   inf] (54), [-1.10984,   inf] (54), [-1.10880,   inf] (54), [-1.10582,   inf] (54), [-1.09899,   inf] (54), [-1.08584,   inf] (54), [-1.08087,   inf] (54), [-1.07987,   inf] (54), [-1.07926,   inf] (54), [-1.07921,   inf] (54), [-1.07822,   inf] (54), [-1.07752,   inf] (54), [-1.07523,   inf] (54), [-1.06470,   inf] (54), [-1.06424,   inf] (54), 
length of domains: 13558
Total time: 2.0279	 pickout: 0.1625	 decision: 0.5756	 get_bound: 1.0856	 add_domain: 0.2043
Current lb:-1.1355149745941162
32330 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 35.6923291683197

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 116] [1, 116] [1, 576] [1, 1208] [1, 116] [1, 408] [1, 612] [1, 116] [1, 116] [1, 612] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1274.186279296875 with beta sum per layer: [18.835996627807617, 1812.2952880859375, 114.57096862792969]
alpha/beta optimization time: 0.6842281818389893
This batch time : update_bounds func: 1.3778	 prepare: 0.2068	 bound: 0.6846	 transfer: 0.0544	 finalize: 0.4266
Accumulated time: update_bounds func: 21.7275	 prepare: 3.8468	 bound: 13.2860	 transfer: 0.0544	 finalize: 3.4608
batch bounding time:  1.3796799182891846
Current worst splitting domains [lb, ub] (depth):
[-1.09609,   inf] (56), [-1.09352,   inf] (56), [-1.09010,   inf] (56), [-1.08141,   inf] (56), [-1.07843,   inf] (56), [-1.07736,   inf] (56), [-1.06384,   inf] (56), [-1.05196,   inf] (56), [-1.04615,   inf] (56), [-1.04473,   inf] (56), [-1.04141,   inf] (56), [-1.03972,   inf] (56), [-1.03492,   inf] (56), [-1.03102,   inf] (56), [-1.02491,   inf] (56), [-1.02439,   inf] (56), [-1.02334,   inf] (56), [-1.02083,   inf] (56), [-1.01667,   inf] (56), [-1.01490,   inf] (56), 
length of domains: 14446
Total time: 2.0496	 pickout: 0.1622	 decision: 0.2951	 get_bound: 1.3828	 add_domain: 0.2094
Current lb:-1.0960946083068848
34378 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 37.765777587890625

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [0, 2038] [0, 2038] [1, 612] [1, 551] [1, 612] [1, 612] [1, 551] [1, 116] [1, 116] [0, 2038] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1308.15966796875 with beta sum per layer: [19.90407943725586, 1781.185546875, 137.3380126953125]
alpha/beta optimization time: 0.6886701583862305
This batch time : update_bounds func: 1.5157	 prepare: 0.3113	 bound: 0.6891	 transfer: 0.0545	 finalize: 0.4547
Accumulated time: update_bounds func: 23.2432	 prepare: 4.1581	 bound: 13.9751	 transfer: 0.0545	 finalize: 3.9156
batch bounding time:  1.5175824165344238
Current worst splitting domains [lb, ub] (depth):
[-1.09390,   inf] (58), [-1.08253,   inf] (58), [-1.03499,   inf] (58), [-1.02822,   inf] (58), [-1.02476,   inf] (58), [-1.01605,   inf] (58), [-1.00623,   inf] (58), [-1.00234,   inf] (58), [-1.00092,   inf] (58), [-0.99559,   inf] (58), [-0.99493,   inf] (58), [-0.98813,   inf] (58), [-0.98777,   inf] (58), [-0.97037,   inf] (58), [-0.97031,   inf] (58), [-0.96716,   inf] (58), [-0.96335,   inf] (58), [-0.95792,   inf] (58), [-0.95663,   inf] (58), [-0.95633,   inf] (58), 
length of domains: 15340
Total time: 2.2386	 pickout: 0.1656	 decision: 0.3418	 get_bound: 1.5208	 add_domain: 0.2105
Current lb:-1.0938998460769653
36426 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 40.028911113739014

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 551] [1, 551] [1, 551] [1, 551] [1, 551] [1, 551] [1, 576] [1, 662] [1, 551] [1, 551] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1279.53466796875 with beta sum per layer: [16.099281311035156, 1788.8193359375, 139.75303649902344]
alpha/beta optimization time: 0.683854341506958
This batch time : update_bounds func: 1.0906	 prepare: 0.2113	 bound: 0.6842	 transfer: 0.0542	 finalize: 0.1340
Accumulated time: update_bounds func: 24.3339	 prepare: 4.3694	 bound: 14.6593	 transfer: 0.0542	 finalize: 4.0496
batch bounding time:  1.0925674438476562
Current worst splitting domains [lb, ub] (depth):
[-1.01617,   inf] (60), [-1.00300,   inf] (60), [-0.95831,   inf] (60), [-0.95294,   inf] (60), [-0.95174,   inf] (60), [-0.94257,   inf] (60), [-0.93697,   inf] (60), [-0.93082,   inf] (60), [-0.92809,   inf] (60), [-0.92398,   inf] (60), [-0.92347,   inf] (60), [-0.92264,   inf] (60), [-0.91957,   inf] (60), [-0.91813,   inf] (60), [-0.91625,   inf] (60), [-0.91294,   inf] (60), [-0.90833,   inf] (60), [-0.90779,   inf] (60), [-0.90453,   inf] (60), [-0.90300,   inf] (60), 
length of domains: 16231
Total time: 2.1338	 pickout: 0.1647	 decision: 0.3003	 get_bound: 1.0959	 add_domain: 0.5728
Current lb:-1.0161736011505127
38474 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 42.18794298171997

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 576] [1, 576] [1, 617] [1, 576] [1, 617] [1, 617] [1, 551] [1, 576] [1, 551] [1, 576] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1215.5997314453125 with beta sum per layer: [23.132593154907227, 1860.9569091796875, 157.6024169921875]
alpha/beta optimization time: 0.6842255592346191
This batch time : update_bounds func: 1.0898	 prepare: 0.2114	 bound: 0.6846	 transfer: 0.0545	 finalize: 0.1326
Accumulated time: update_bounds func: 25.4237	 prepare: 4.5808	 bound: 15.3439	 transfer: 0.0545	 finalize: 4.1821
batch bounding time:  1.0916824340820312
Current worst splitting domains [lb, ub] (depth):
[-0.94687,   inf] (62), [-0.93486,   inf] (62), [-0.91601,   inf] (62), [-0.90209,   inf] (62), [-0.90111,   inf] (62), [-0.89801,   inf] (62), [-0.89441,   inf] (62), [-0.89210,   inf] (62), [-0.89087,   inf] (62), [-0.88503,   inf] (62), [-0.87797,   inf] (62), [-0.87547,   inf] (62), [-0.87192,   inf] (62), [-0.87142,   inf] (62), [-0.86610,   inf] (62), [-0.86385,   inf] (62), [-0.86267,   inf] (62), [-0.86139,   inf] (62), [-0.85805,   inf] (62), [-0.85459,   inf] (62), 
length of domains: 17104
Total time: 1.7640	 pickout: 0.1648	 decision: 0.2959	 get_bound: 1.0949	 add_domain: 0.2084
Current lb:-0.9468704462051392
40522 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 43.977797746658325

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [0, 2443] [0, 2443] [1, 662] [0, 2443] [0, 2443] [0, 1856] [1, 576] [1, 617] [0, 2443] [0, 2443] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1136.934326171875 with beta sum per layer: [26.267215728759766, 1882.920166015625, 198.54977416992188]
alpha/beta optimization time: 0.6868653297424316
This batch time : update_bounds func: 1.0993	 prepare: 0.2150	 bound: 0.6873	 transfer: 0.0549	 finalize: 0.1366
Accumulated time: update_bounds func: 26.5230	 prepare: 4.7958	 bound: 16.0312	 transfer: 0.0549	 finalize: 4.3187
batch bounding time:  1.101170301437378
Current worst splitting domains [lb, ub] (depth):
[-0.94450,   inf] (64), [-0.93269,   inf] (64), [-0.90073,   inf] (64), [-0.89384,   inf] (64), [-0.88283,   inf] (64), [-0.87461,   inf] (64), [-0.86839,   inf] (64), [-0.86745,   inf] (64), [-0.86300,   inf] (64), [-0.86178,   inf] (64), [-0.86075,   inf] (64), [-0.85657,   inf] (64), [-0.84284,   inf] (64), [-0.84066,   inf] (64), [-0.83778,   inf] (64), [-0.83756,   inf] (64), [-0.83685,   inf] (64), [-0.82750,   inf] (64), [-0.81814,   inf] (64), [-0.81476,   inf] (64), 
length of domains: 17942
Total time: 2.1445	 pickout: 0.1647	 decision: 0.6727	 get_bound: 1.1044	 add_domain: 0.2028
Current lb:-0.9444982409477234
42570 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 46.147483825683594

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 617] [1, 617] [1, 576] [0, 2443] [1, 617] [1, 617] [1, 576] [0, 2443] [1, 617] [0, 2443] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1093.2271728515625 with beta sum per layer: [21.72194480895996, 1945.940185546875, 208.27041625976562]
alpha/beta optimization time: 0.6841356754302979
This batch time : update_bounds func: 1.5024	 prepare: 0.2174	 bound: 0.6845	 transfer: 0.0554	 finalize: 0.1482
Accumulated time: update_bounds func: 28.0253	 prepare: 5.0132	 bound: 16.7157	 transfer: 0.0554	 finalize: 4.4669
batch bounding time:  1.5044565200805664
Current worst splitting domains [lb, ub] (depth):
[-0.89279,   inf] (66), [-0.88973,   inf] (66), [-0.86664,   inf] (66), [-0.86377,   inf] (66), [-0.86111,   inf] (66), [-0.85711,   inf] (66), [-0.85268,   inf] (66), [-0.83737,   inf] (66), [-0.83373,   inf] (66), [-0.81796,   inf] (66), [-0.81301,   inf] (66), [-0.81240,   inf] (66), [-0.81026,   inf] (66), [-0.80781,   inf] (66), [-0.80731,   inf] (66), [-0.80525,   inf] (66), [-0.80478,   inf] (66), [-0.80351,   inf] (66), [-0.80151,   inf] (66), [-0.79908,   inf] (66), 
length of domains: 18753
Total time: 2.1920	 pickout: 0.1664	 decision: 0.3036	 get_bound: 1.5080	 add_domain: 0.2141
Current lb:-0.8927874565124512
44618 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 48.37723088264465

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 1208] [2, 75] [1, 1208] [2, 75] [1, 1208] [2, 75] [2, 75] [1, 1208] [2, 75] [1, 1208] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1080.4609375 with beta sum per layer: [21.119762420654297, 1894.368408203125, 215.46697998046875]
alpha/beta optimization time: 0.684532880783081
This batch time : update_bounds func: 1.0956	 prepare: 0.2124	 bound: 0.6849	 transfer: 0.0543	 finalize: 0.1370
Accumulated time: update_bounds func: 29.1210	 prepare: 5.2256	 bound: 17.4006	 transfer: 0.0543	 finalize: 4.6039
batch bounding time:  1.0974762439727783
Current worst splitting domains [lb, ub] (depth):
[-0.84809,   inf] (68), [-0.84632,   inf] (68), [-0.82136,   inf] (68), [-0.81969,   inf] (68), [-0.81540,   inf] (68), [-0.81476,   inf] (68), [-0.80814,   inf] (68), [-0.80539,   inf] (68), [-0.79660,   inf] (68), [-0.79085,   inf] (68), [-0.78913,   inf] (68), [-0.77599,   inf] (68), [-0.77152,   inf] (68), [-0.77056,   inf] (68), [-0.76879,   inf] (68), [-0.76664,   inf] (68), [-0.76608,   inf] (68), [-0.76380,   inf] (68), [-0.76190,   inf] (68), [-0.76166,   inf] (68), 
length of domains: 19575
Total time: 2.2610	 pickout: 0.1827	 decision: 0.3079	 get_bound: 1.1009	 add_domain: 0.6695
Current lb:-0.8480939865112305
46666 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 50.67354130744934

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [0, 1856] [2, 75] [0, 1856] [2, 75] [2, 75] [0, 1856] [0, 1856] [2, 75] [2, 75] [2, 75] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1056.6639404296875 with beta sum per layer: [23.771638870239258, 1950.30517578125, 214.23992919921875]
alpha/beta optimization time: 0.682227611541748
This batch time : update_bounds func: 1.0981	 prepare: 0.2147	 bound: 0.6826	 transfer: 0.0534	 finalize: 0.1404
Accumulated time: update_bounds func: 30.2191	 prepare: 5.4403	 bound: 18.0832	 transfer: 0.0534	 finalize: 4.7443
batch bounding time:  1.1000208854675293
Current worst splitting domains [lb, ub] (depth):
[-0.84685,   inf] (70), [-0.82073,   inf] (70), [-0.81369,   inf] (70), [-0.80736,   inf] (70), [-0.80256,   inf] (70), [-0.78847,   inf] (70), [-0.77696,   inf] (70), [-0.77175,   inf] (70), [-0.76932,   inf] (70), [-0.76223,   inf] (70), [-0.76147,   inf] (70), [-0.75380,   inf] (70), [-0.75289,   inf] (70), [-0.75208,   inf] (66), [-0.75040,   inf] (64), [-0.74829,   inf] (64), [-0.74825,   inf] (70), [-0.74749,   inf] (66), [-0.74706,   inf] (62), [-0.74700,   inf] (70), 
length of domains: 20379
Total time: 1.7929	 pickout: 0.1804	 decision: 0.3041	 get_bound: 1.1033	 add_domain: 0.2051
Current lb:-0.8468542098999023
48714 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 52.49548697471619

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 368] [1, 368] [1, 368] [1, 368] [2, 41] [1, 368] [2, 41] [2, 41] [1, 368] [1, 368] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1041.09716796875 with beta sum per layer: [25.89151382446289, 1991.197021484375, 217.83782958984375]
alpha/beta optimization time: 0.6825869083404541
This batch time : update_bounds func: 1.0970	 prepare: 0.2099	 bound: 0.6830	 transfer: 0.0544	 finalize: 0.1427
Accumulated time: update_bounds func: 31.3160	 prepare: 5.6502	 bound: 18.7662	 transfer: 0.0544	 finalize: 4.8870
batch bounding time:  1.0990238189697266
Current worst splitting domains [lb, ub] (depth):
[-0.80725,   inf] (72), [-0.78197,   inf] (72), [-0.77410,   inf] (72), [-0.76794,   inf] (72), [-0.76733,   inf] (72), [-0.74840,   inf] (72), [-0.74237,   inf] (72), [-0.74022,   inf] (66), [-0.73982,   inf] (54), [-0.73959,   inf] (58), [-0.73945,   inf] (60), [-0.73858,   inf] (62), [-0.73847,   inf] (52), [-0.73752,   inf] (54), [-0.73711,   inf] (72), [-0.73710,   inf] (62), [-0.73691,   inf] (66), [-0.73667,   inf] (64), [-0.73575,   inf] (60), [-0.73567,   inf] (64), 
length of domains: 21197
Total time: 2.2575	 pickout: 0.1746	 decision: 0.7695	 get_bound: 1.1027	 add_domain: 0.2107
Current lb:-0.8072529435157776
50762 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 54.78125047683716

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 277] [1, 277] [1, 277] [1, 550] [1, 277] [1, 277] [1, 550] [1, 1208] [1, 551] [1, 662] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1015.58837890625 with beta sum per layer: [14.667129516601562, 1985.632080078125, 204.13958740234375]
alpha/beta optimization time: 0.68361496925354
This batch time : update_bounds func: 1.0982	 prepare: 0.2149	 bound: 0.6840	 transfer: 0.0544	 finalize: 0.1383
Accumulated time: update_bounds func: 32.4143	 prepare: 5.8651	 bound: 19.4502	 transfer: 0.0544	 finalize: 5.0253
batch bounding time:  1.1001482009887695
Current worst splitting domains [lb, ub] (depth):
[-0.79274,   inf] (74), [-0.76621,   inf] (74), [-0.75860,   inf] (74), [-0.75304,   inf] (74), [-0.73450,   inf] (74), [-0.72938,   inf] (62), [-0.72903,   inf] (62), [-0.72899,   inf] (70), [-0.72888,   inf] (64), [-0.72887,   inf] (66), [-0.72753,   inf] (70), [-0.72676,   inf] (56), [-0.72670,   inf] (56), [-0.72569,   inf] (64), [-0.72567,   inf] (50), [-0.72484,   inf] (62), [-0.72472,   inf] (64), [-0.72418,   inf] (64), [-0.72405,   inf] (56), [-0.72383,   inf] (64), 
length of domains: 21990
Total time: 2.3324	 pickout: 0.1754	 decision: 0.3057	 get_bound: 1.1035	 add_domain: 0.7477
Current lb:-0.7927427291870117
52810 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 57.1474723815918

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 550] [1, 550] [1, 550] [1, 550] [1, 550] [1, 617] [1, 617] [1, 368] [1, 662] [2, 75] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 999.6982421875 with beta sum per layer: [19.17191505432129, 2055.583984375, 221.82086181640625]
alpha/beta optimization time: 0.6855292320251465
This batch time : update_bounds func: 1.1065	 prepare: 0.2157	 bound: 0.6859	 transfer: 0.0544	 finalize: 0.1440
Accumulated time: update_bounds func: 33.5207	 prepare: 6.0808	 bound: 20.1361	 transfer: 0.0544	 finalize: 5.1693
batch bounding time:  1.1085069179534912
Current worst splitting domains [lb, ub] (depth):
[-0.74228,   inf] (76), [-0.72398,   inf] (66), [-0.72348,   inf] (66), [-0.72253,   inf] (66), [-0.72187,   inf] (62), [-0.71996,   inf] (68), [-0.71971,   inf] (56), [-0.71900,   inf] (64), [-0.71849,   inf] (68), [-0.71742,   inf] (62), [-0.71738,   inf] (66), [-0.71711,   inf] (60), [-0.71687,   inf] (50), [-0.71631,   inf] (70), [-0.71565,   inf] (76), [-0.71551,   inf] (66), [-0.71539,   inf] (52), [-0.71537,   inf] (50), [-0.71536,   inf] (50), [-0.71536,   inf] (40), 
length of domains: 22781
Total time: 1.7943	 pickout: 0.1722	 decision: 0.3031	 get_bound: 1.1119	 add_domain: 0.2070
Current lb:-0.7422816753387451
54858 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 58.97773599624634

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [2, 41] [1, 1208] [1, 1208] [1, 1208] [1, 576] [2, 75] [1, 551] [1, 617] [1, 550] [1, 116] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 972.06689453125 with beta sum per layer: [18.296138763427734, 2116.853759765625, 211.3959197998047]
alpha/beta optimization time: 0.6823663711547852
This batch time : update_bounds func: 1.6454	 prepare: 0.2144	 bound: 0.6827	 transfer: 0.0544	 finalize: 0.6871
Accumulated time: update_bounds func: 35.1661	 prepare: 6.2952	 bound: 20.8188	 transfer: 0.0544	 finalize: 5.8564
batch bounding time:  1.647308588027954
Current worst splitting domains [lb, ub] (depth):
[-0.71409,   inf] (64), [-0.71380,   inf] (66), [-0.71355,   inf] (58), [-0.71330,   inf] (72), [-0.71174,   inf] (58), [-0.71144,   inf] (52), [-0.71081,   inf] (64), [-0.71075,   inf] (56), [-0.71073,   inf] (56), [-0.71042,   inf] (64), [-0.70977,   inf] (64), [-0.70956,   inf] (66), [-0.70940,   inf] (56), [-0.70903,   inf] (60), [-0.70861,   inf] (62), [-0.70854,   inf] (78), [-0.70808,   inf] (62), [-0.70807,   inf] (48), [-0.70777,   inf] (64), [-0.70735,   inf] (32), 
length of domains: 23561
Total time: 2.3391	 pickout: 0.1786	 decision: 0.3079	 get_bound: 1.6506	 add_domain: 0.2020
Current lb:-0.7140879034996033
56906 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 61.34510946273804

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [0, 2443] [2, 41] [1, 551] [1, 277] [1, 551] [2, 56] [0, 2443] [1, 576] [1, 551] [1, 617] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 941.1778564453125 with beta sum per layer: [23.91619110107422, 2122.666015625, 219.04840087890625]
alpha/beta optimization time: 0.6826314926147461
This batch time : update_bounds func: 1.1013	 prepare: 0.2145	 bound: 0.6830	 transfer: 0.0546	 finalize: 0.1422
Accumulated time: update_bounds func: 36.2675	 prepare: 6.5097	 bound: 21.5018	 transfer: 0.0546	 finalize: 5.9987
batch bounding time:  1.103386402130127
Current worst splitting domains [lb, ub] (depth):
[-0.71131,   inf] (66), [-0.70986,   inf] (66), [-0.70389,   inf] (70), [-0.70359,   inf] (58), [-0.70342,   inf] (66), [-0.70244,   inf] (54), [-0.70231,   inf] (52), [-0.70220,   inf] (64), [-0.70184,   inf] (56), [-0.70177,   inf] (62), [-0.70177,   inf] (72), [-0.70173,   inf] (56), [-0.70171,   inf] (66), [-0.70152,   inf] (62), [-0.70073,   inf] (62), [-0.70042,   inf] (74), [-0.70034,   inf] (58), [-0.70014,   inf] (64), [-0.69974,   inf] (66), [-0.69962,   inf] (54), 
length of domains: 24319
Total time: 1.7899	 pickout: 0.1715	 decision: 0.3067	 get_bound: 1.1070	 add_domain: 0.2047
Current lb:-0.7113056182861328
58954 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 63.168140172958374

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 576] [1, 576] [1, 368] [1, 612] [1, 1208] [1, 408] [2, 56] [2, 75] [1, 1208] [1, 617] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 939.2316284179688 with beta sum per layer: [20.580856323242188, 2100.562744140625, 200.7041015625]
alpha/beta optimization time: 0.6870424747467041
This batch time : update_bounds func: 1.1021	 prepare: 0.2156	 bound: 0.6874	 transfer: 0.0543	 finalize: 0.1380
Accumulated time: update_bounds func: 37.3696	 prepare: 6.7253	 bound: 22.1892	 transfer: 0.0543	 finalize: 6.1367
batch bounding time:  1.1053211688995361
Current worst splitting domains [lb, ub] (depth):
[-0.69782,   inf] (70), [-0.69714,   inf] (66), [-0.69702,   inf] (66), [-0.69660,   inf] (68), [-0.69629,   inf] (66), [-0.69522,   inf] (54), [-0.69505,   inf] (72), [-0.69496,   inf] (66), [-0.69492,   inf] (70), [-0.69489,   inf] (60), [-0.69484,   inf] (68), [-0.69453,   inf] (64), [-0.69443,   inf] (58), [-0.69374,   inf] (70), [-0.69371,   inf] (68), [-0.69369,   inf] (66), [-0.69303,   inf] (62), [-0.69300,   inf] (68), [-0.69300,   inf] (66), [-0.69284,   inf] (62), 
length of domains: 25096
Total time: 2.3570	 pickout: 0.1770	 decision: 0.8673	 get_bound: 1.1087	 add_domain: 0.2041
Current lb:-0.6978225708007812
61002 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 65.55379033088684

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 368] [1, 368] [1, 1208] [1, 277] [1, 1208] [2, 56] [1, 24] [1, 1208] [1, 368] [1, 576] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 940.4039306640625 with beta sum per layer: [19.292949676513672, 2075.570556640625, 213.02601623535156]
alpha/beta optimization time: 0.6855099201202393
This batch time : update_bounds func: 1.0951	 prepare: 0.2115	 bound: 0.6859	 transfer: 0.0543	 finalize: 0.1374
Accumulated time: update_bounds func: 38.4647	 prepare: 6.9369	 bound: 22.8751	 transfer: 0.0543	 finalize: 6.2740
batch bounding time:  1.0970818996429443
Current worst splitting domains [lb, ub] (depth):
[-0.69304,   inf] (70), [-0.69166,   inf] (64), [-0.69101,   inf] (70), [-0.69043,   inf] (68), [-0.68997,   inf] (56), [-0.68891,   inf] (56), [-0.68837,   inf] (70), [-0.68828,   inf] (64), [-0.68821,   inf] (58), [-0.68727,   inf] (66), [-0.68703,   inf] (56), [-0.68692,   inf] (68), [-0.68680,   inf] (66), [-0.68652,   inf] (60), [-0.68618,   inf] (66), [-0.68569,   inf] (64), [-0.68566,   inf] (70), [-0.68550,   inf] (58), [-0.68549,   inf] (70), [-0.68547,   inf] (64), 
length of domains: 25872
Total time: 1.7857	 pickout: 0.1741	 decision: 0.3039	 get_bound: 1.1006	 add_domain: 0.2070
Current lb:-0.6930415630340576
63050 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 67.36846947669983

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 368] [1, 576] [1, 550] [1, 368] [1, 576] [1, 551] [1, 368] [1, 617] [1, 551] [1, 1208] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 910.162353515625 with beta sum per layer: [28.699153900146484, 2078.787353515625, 214.0691375732422]
alpha/beta optimization time: 0.6891798973083496
This batch time : update_bounds func: 1.1096	 prepare: 0.2164	 bound: 0.6896	 transfer: 0.0543	 finalize: 0.1424
Accumulated time: update_bounds func: 39.5743	 prepare: 7.1533	 bound: 23.5647	 transfer: 0.0543	 finalize: 6.4164
batch bounding time:  1.111609935760498
Current worst splitting domains [lb, ub] (depth):
[-0.68506,   inf] (72), [-0.68394,   inf] (66), [-0.68377,   inf] (62), [-0.68361,   inf] (64), [-0.68240,   inf] (54), [-0.68168,   inf] (56), [-0.68093,   inf] (66), [-0.68048,   inf] (60), [-0.68035,   inf] (56), [-0.68016,   inf] (62), [-0.68010,   inf] (68), [-0.67972,   inf] (72), [-0.67964,   inf] (54), [-0.67909,   inf] (56), [-0.67894,   inf] (70), [-0.67889,   inf] (58), [-0.67883,   inf] (56), [-0.67863,   inf] (66), [-0.67854,   inf] (56), [-0.67852,   inf] (62), 
length of domains: 26647
Total time: 2.4135	 pickout: 0.1703	 decision: 0.9206	 get_bound: 1.1150	 add_domain: 0.2077
Current lb:-0.6850571632385254
65098 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 69.81713247299194

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 277] [1, 1208] [1, 617] [1, 617] [1, 408] [1, 551] [1, 1208] [1, 617] [1, 551] [1, 576] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 901.4675903320312 with beta sum per layer: [26.470823287963867, 2211.4326171875, 207.38143920898438]
alpha/beta optimization time: 0.6868093013763428
This batch time : update_bounds func: 1.1068	 prepare: 0.2144	 bound: 0.6872	 transfer: 0.0546	 finalize: 0.1436
Accumulated time: update_bounds func: 40.6811	 prepare: 7.3676	 bound: 24.2518	 transfer: 0.0546	 finalize: 6.5601
batch bounding time:  1.1087007522583008
Current worst splitting domains [lb, ub] (depth):
[-0.67833,   inf] (72), [-0.67694,   inf] (70), [-0.67659,   inf] (60), [-0.67637,   inf] (68), [-0.67628,   inf] (56), [-0.67603,   inf] (56), [-0.67570,   inf] (56), [-0.67544,   inf] (70), [-0.67533,   inf] (56), [-0.67514,   inf] (74), [-0.67498,   inf] (62), [-0.67485,   inf] (56), [-0.67474,   inf] (62), [-0.67462,   inf] (62), [-0.67440,   inf] (54), [-0.67412,   inf] (66), [-0.67391,   inf] (56), [-0.67370,   inf] (56), [-0.67368,   inf] (70), [-0.67365,   inf] (70), 
length of domains: 27411
Total time: 1.8059	 pickout: 0.1762	 decision: 0.3090	 get_bound: 1.1120	 add_domain: 0.2086
Current lb:-0.6783342361450195
67146 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 71.6541051864624

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 277] [1, 550] [1, 576] [0, 1856] [1, 123] [1, 551] [1, 551] [1, 277] [1, 551] [1, 617] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 863.1229248046875 with beta sum per layer: [28.38779067993164, 2114.47412109375, 251.70401000976562]
alpha/beta optimization time: 0.683706521987915
This batch time : update_bounds func: 1.0998	 prepare: 0.2135	 bound: 0.6841	 transfer: 0.0546	 finalize: 0.1409
Accumulated time: update_bounds func: 41.7809	 prepare: 7.5811	 bound: 24.9359	 transfer: 0.0546	 finalize: 6.7010
batch bounding time:  1.1018645763397217
Current worst splitting domains [lb, ub] (depth):
[-0.67574,   inf] (70), [-0.67361,   inf] (68), [-0.67305,   inf] (72), [-0.67156,   inf] (62), [-0.67096,   inf] (70), [-0.67087,   inf] (68), [-0.67024,   inf] (62), [-0.67022,   inf] (72), [-0.66992,   inf] (70), [-0.66957,   inf] (66), [-0.66953,   inf] (74), [-0.66944,   inf] (66), [-0.66919,   inf] (64), [-0.66916,   inf] (70), [-0.66883,   inf] (56), [-0.66847,   inf] (64), [-0.66811,   inf] (66), [-0.66776,   inf] (64), [-0.66721,   inf] (60), [-0.66706,   inf] (66), 
length of domains: 28152
Total time: 2.4648	 pickout: 0.1787	 decision: 0.9740	 get_bound: 1.1055	 add_domain: 0.2067
Current lb:-0.6757431030273438
69194 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 74.14968848228455

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 368] [2, 75] [1, 277] [1, 116] [1, 368] [1, 116] [1, 1208] [2, 41] [0, 1856] [1, 1208] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 865.8104248046875 with beta sum per layer: [19.096965789794922, 2101.97607421875, 232.60357666015625]
alpha/beta optimization time: 0.6813826560974121
This batch time : update_bounds func: 1.0992	 prepare: 0.2142	 bound: 0.6817	 transfer: 0.0530	 finalize: 0.1438
Accumulated time: update_bounds func: 42.8801	 prepare: 7.7953	 bound: 25.6176	 transfer: 0.0530	 finalize: 6.8448
batch bounding time:  1.1012468338012695
Current worst splitting domains [lb, ub] (depth):
[-0.66930,   inf] (72), [-0.66476,   inf] (54), [-0.66368,   inf] (64), [-0.66361,   inf] (66), [-0.66361,   inf] (62), [-0.66320,   inf] (66), [-0.66176,   inf] (56), [-0.66110,   inf] (64), [-0.66056,   inf] (68), [-0.66030,   inf] (64), [-0.66028,   inf] (64), [-0.66020,   inf] (42), [-0.66020,   inf] (52), [-0.66019,   inf] (50), [-0.66019,   inf] (48), [-0.66019,   inf] (44), [-0.66019,   inf] (64), [-0.66018,   inf] (40), [-0.66018,   inf] (44), [-0.66017,   inf] (38), 
length of domains: 28902
Total time: 1.7951	 pickout: 0.1774	 decision: 0.3064	 get_bound: 1.1048	 add_domain: 0.2065
Current lb:-0.6692955493927002
71242 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 75.97594141960144

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 277] [2, 56] [1, 617] [2, 75] [1, 617] [2, 41] [1, 551] [0, 2443] [1, 277] [1, 576] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 852.5625 with beta sum per layer: [22.683156967163086, 2084.010498046875, 213.04534912109375]
alpha/beta optimization time: 0.6838099956512451
This batch time : update_bounds func: 1.0971	 prepare: 0.2132	 bound: 0.6842	 transfer: 0.0542	 finalize: 0.1385
Accumulated time: update_bounds func: 43.9772	 prepare: 8.0085	 bound: 26.3018	 transfer: 0.0542	 finalize: 6.9832
batch bounding time:  1.0991864204406738
Current worst splitting domains [lb, ub] (depth):
[-0.66091,   inf] (66), [-0.65723,   inf] (62), [-0.65688,   inf] (66), [-0.65685,   inf] (66), [-0.65679,   inf] (66), [-0.65650,   inf] (58), [-0.65624,   inf] (62), [-0.65615,   inf] (52), [-0.65589,   inf] (56), [-0.65571,   inf] (66), [-0.65556,   inf] (74), [-0.65528,   inf] (68), [-0.65527,   inf] (66), [-0.65520,   inf] (68), [-0.65471,   inf] (70), [-0.65462,   inf] (58), [-0.65457,   inf] (58), [-0.65455,   inf] (70), [-0.65450,   inf] (64), [-0.65442,   inf] (60), 
length of domains: 29645
Total time: 2.4930	 pickout: 0.1753	 decision: 1.0122	 get_bound: 1.1026	 add_domain: 0.2028
Current lb:-0.6609106063842773
73290 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 78.49848985671997

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 1208] [1, 576] [1, 1208] [1, 1208] [1, 1208] [1, 1208] [1, 617] [2, 56] [1, 612] [2, 75] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 843.5625 with beta sum per layer: [26.45502471923828, 2147.126708984375, 227.77227783203125]
alpha/beta optimization time: 0.6833176612854004
This batch time : update_bounds func: 1.0934	 prepare: 0.2118	 bound: 0.6837	 transfer: 0.0536	 finalize: 0.1379
Accumulated time: update_bounds func: 45.0706	 prepare: 8.2203	 bound: 26.9855	 transfer: 0.0536	 finalize: 7.1211
batch bounding time:  1.0952844619750977
Current worst splitting domains [lb, ub] (depth):
[-0.65326,   inf] (62), [-0.65317,   inf] (66), [-0.65244,   inf] (58), [-0.65180,   inf] (66), [-0.65172,   inf] (64), [-0.65152,   inf] (64), [-0.65142,   inf] (70), [-0.65131,   inf] (66), [-0.65087,   inf] (70), [-0.65055,   inf] (76), [-0.65049,   inf] (64), [-0.65035,   inf] (66), [-0.65019,   inf] (62), [-0.65010,   inf] (56), [-0.65006,   inf] (64), [-0.64989,   inf] (72), [-0.64988,   inf] (50), [-0.64972,   inf] (62), [-0.64965,   inf] (62), [-0.64954,   inf] (64), 
length of domains: 30401
Total time: 1.7873	 pickout: 0.1724	 decision: 0.3097	 get_bound: 1.0987	 add_domain: 0.2064
Current lb:-0.6532611846923828
75338 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 80.3155927658081

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 617] [2, 75] [1, 617] [1, 576] [0, 2443] [1, 576] [1, 368] [1, 576] [1, 368] [1, 262] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 828.213134765625 with beta sum per layer: [31.633716583251953, 2115.5244140625, 222.88116455078125]
alpha/beta optimization time: 0.6904370784759521
This batch time : update_bounds func: 1.1160	 prepare: 0.2248	 bound: 0.6908	 transfer: 0.0542	 finalize: 0.1397
Accumulated time: update_bounds func: 46.1866	 prepare: 8.4451	 bound: 27.6763	 transfer: 0.0542	 finalize: 7.2608
batch bounding time:  1.1179640293121338
Current worst splitting domains [lb, ub] (depth):
[-0.65031,   inf] (66), [-0.64831,   inf] (66), [-0.64750,   inf] (66), [-0.64743,   inf] (56), [-0.64694,   inf] (66), [-0.64642,   inf] (62), [-0.64593,   inf] (56), [-0.64571,   inf] (70), [-0.64555,   inf] (66), [-0.64547,   inf] (58), [-0.64545,   inf] (70), [-0.64542,   inf] (54), [-0.64535,   inf] (66), [-0.64534,   inf] (66), [-0.64528,   inf] (62), [-0.64522,   inf] (78), [-0.64511,   inf] (70), [-0.64470,   inf] (68), [-0.64470,   inf] (56), [-0.64451,   inf] (70), 
length of domains: 31132
Total time: 2.5468	 pickout: 0.1733	 decision: 1.0452	 get_bound: 1.1214	 add_domain: 0.2070
Current lb:-0.6503067016601562
77386 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 82.90927910804749

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 576] [1, 576] [1, 1208] [1, 551] [1, 576] [1, 617] [1, 551] [2, 41] [1, 1208] [1, 1208] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 805.466552734375 with beta sum per layer: [20.73651885986328, 2183.022216796875, 220.55831909179688]
alpha/beta optimization time: 0.682337760925293
This batch time : update_bounds func: 1.1036	 prepare: 0.2157	 bound: 0.6827	 transfer: 0.0542	 finalize: 0.1445
Accumulated time: update_bounds func: 47.2902	 prepare: 8.6608	 bound: 28.3590	 transfer: 0.0542	 finalize: 7.4052
batch bounding time:  1.1055326461791992
Current worst splitting domains [lb, ub] (depth):
[-0.64336,   inf] (70), [-0.64281,   inf] (72), [-0.64188,   inf] (68), [-0.64159,   inf] (64), [-0.64078,   inf] (70), [-0.64039,   inf] (68), [-0.63974,   inf] (66), [-0.63917,   inf] (56), [-0.63906,   inf] (62), [-0.63903,   inf] (66), [-0.63879,   inf] (58), [-0.63815,   inf] (66), [-0.63801,   inf] (64), [-0.63801,   inf] (54), [-0.63796,   inf] (48), [-0.63796,   inf] (46), [-0.63796,   inf] (60), [-0.63796,   inf] (60), [-0.63795,   inf] (64), [-0.63795,   inf] (52), 
length of domains: 31860
Total time: 1.8153	 pickout: 0.1833	 decision: 0.3151	 get_bound: 1.1091	 add_domain: 0.2078
Current lb:-0.6433615684509277
79434 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 84.75738906860352

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [2, 41] [1, 277] [1, 116] [1, 576] [2, 41] [1, 277] [2, 41] [1, 551] [1, 576] [2, 75] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 794.094970703125 with beta sum per layer: [24.90473175048828, 2194.6689453125, 214.173095703125]
alpha/beta optimization time: 0.6826543807983398
This batch time : update_bounds func: 1.1134	 prepare: 0.2183	 bound: 0.6830	 transfer: 0.0540	 finalize: 0.1509
Accumulated time: update_bounds func: 48.4036	 prepare: 8.8790	 bound: 29.0420	 transfer: 0.0540	 finalize: 7.5562
batch bounding time:  1.1156394481658936
Current worst splitting domains [lb, ub] (depth):
[-0.63709,   inf] (70), [-0.63632,   inf] (70), [-0.63609,   inf] (66), [-0.63588,   inf] (62), [-0.63585,   inf] (54), [-0.63585,   inf] (62), [-0.63583,   inf] (72), [-0.63552,   inf] (70), [-0.63493,   inf] (74), [-0.63477,   inf] (66), [-0.63472,   inf] (72), [-0.63450,   inf] (54), [-0.63424,   inf] (64), [-0.63413,   inf] (58), [-0.63402,   inf] (56), [-0.63345,   inf] (68), [-0.63299,   inf] (68), [-0.63293,   inf] (64), [-0.63287,   inf] (60), [-0.63287,   inf] (46), 
length of domains: 32574
Total time: 2.6032	 pickout: 0.1790	 decision: 1.0896	 get_bound: 1.1197	 add_domain: 0.2149
Current lb:-0.6370944976806641
81482 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 87.39529585838318

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 368] [1, 550] [2, 41] [1, 576] [1, 1208] [1, 576] [1, 277] [1, 368] [1, 625] [1, 368] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 795.0184326171875 with beta sum per layer: [28.679275512695312, 2142.130859375, 235.591552734375]
alpha/beta optimization time: 0.6849675178527832
This batch time : update_bounds func: 1.1035	 prepare: 0.2154	 bound: 0.6854	 transfer: 0.0542	 finalize: 0.1414
Accumulated time: update_bounds func: 49.5071	 prepare: 9.0944	 bound: 29.7274	 transfer: 0.0542	 finalize: 7.6976
batch bounding time:  1.1055271625518799
Current worst splitting domains [lb, ub] (depth):
[-0.63262,   inf] (68), [-0.63169,   inf] (64), [-0.63150,   inf] (62), [-0.63115,   inf] (64), [-0.63055,   inf] (72), [-0.63012,   inf] (56), [-0.62998,   inf] (54), [-0.62989,   inf] (64), [-0.62974,   inf] (64), [-0.62937,   inf] (72), [-0.62935,   inf] (66), [-0.62918,   inf] (68), [-0.62916,   inf] (74), [-0.62899,   inf] (74), [-0.62887,   inf] (62), [-0.62808,   inf] (70), [-0.62807,   inf] (50), [-0.62807,   inf] (42), [-0.62807,   inf] (38), [-0.62806,   inf] (46), 
length of domains: 33313
Total time: 1.8070	 pickout: 0.1785	 decision: 0.3126	 get_bound: 1.1091	 add_domain: 0.2068
Current lb:-0.6326217651367188
83530 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 89.24993586540222

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 368] [1, 617] [2, 75] [1, 576] [1, 277] [1, 662] [2, 56] [1, 617] [1, 617] [1, 277] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 777.8104248046875 with beta sum per layer: [26.880451202392578, 2228.0654296875, 224.25405883789062]
alpha/beta optimization time: 0.6838886737823486
This batch time : update_bounds func: 1.9518	 prepare: 0.2158	 bound: 0.6842	 transfer: 0.0540	 finalize: 0.9907
Accumulated time: update_bounds func: 51.4588	 prepare: 9.3102	 bound: 30.4116	 transfer: 0.0540	 finalize: 8.6882
batch bounding time:  1.9538633823394775
Current worst splitting domains [lb, ub] (depth):
[-0.62672,   inf] (64), [-0.62627,   inf] (62), [-0.62595,   inf] (74), [-0.62551,   inf] (54), [-0.62549,   inf] (64), [-0.62542,   inf] (66), [-0.62541,   inf] (68), [-0.62538,   inf] (58), [-0.62537,   inf] (56), [-0.62491,   inf] (66), [-0.62467,   inf] (74), [-0.62454,   inf] (56), [-0.62445,   inf] (80), [-0.62440,   inf] (70), [-0.62426,   inf] (58), [-0.62388,   inf] (54), [-0.62379,   inf] (64), [-0.62362,   inf] (72), [-0.62336,   inf] (62), [-0.62316,   inf] (62), 
length of domains: 34039
Total time: 2.6660	 pickout: 0.1841	 decision: 0.3143	 get_bound: 1.9578	 add_domain: 0.2098
Current lb:-0.6267166137695312
85578 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 91.94978976249695

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 617] [2, 75] [1, 1208] [1, 551] [1, 617] [1, 1208] [1, 277] [1, 551] [1, 551] [2, 41] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 768.8778686523438 with beta sum per layer: [27.486223220825195, 2174.8603515625, 225.62353515625]
alpha/beta optimization time: 0.685462236404419
This batch time : update_bounds func: 1.1148	 prepare: 0.2213	 bound: 0.6858	 transfer: 0.0544	 finalize: 0.1462
Accumulated time: update_bounds func: 52.5737	 prepare: 9.5315	 bound: 31.0975	 transfer: 0.0544	 finalize: 8.8345
batch bounding time:  1.1169514656066895
Current worst splitting domains [lb, ub] (depth):
[-0.62275,   inf] (66), [-0.62201,   inf] (62), [-0.62183,   inf] (58), [-0.62181,   inf] (56), [-0.62121,   inf] (70), [-0.62099,   inf] (56), [-0.62087,   inf] (62), [-0.62067,   inf] (66), [-0.62057,   inf] (64), [-0.62057,   inf] (66), [-0.62051,   inf] (70), [-0.62041,   inf] (64), [-0.61996,   inf] (68), [-0.61988,   inf] (66), [-0.61983,   inf] (68), [-0.61982,   inf] (66), [-0.61964,   inf] (66), [-0.61960,   inf] (70), [-0.61953,   inf] (62), [-0.61945,   inf] (54), 
length of domains: 34766
Total time: 1.8281	 pickout: 0.1818	 decision: 0.3134	 get_bound: 1.1206	 add_domain: 0.2123
Current lb:-0.6227531433105469
87626 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 93.81093239784241

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [2, 75] [1, 1208] [1, 1208] [1, 576] [1, 368] [1, 551] [1, 116] [1, 1208] [1, 617] [1, 617] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 755.29052734375 with beta sum per layer: [24.720890045166016, 2144.669921875, 224.34640502929688]
alpha/beta optimization time: 0.6840581893920898
This batch time : update_bounds func: 1.1019	 prepare: 0.2161	 bound: 0.6844	 transfer: 0.0543	 finalize: 0.1395
Accumulated time: update_bounds func: 53.6756	 prepare: 9.7476	 bound: 31.7819	 transfer: 0.0543	 finalize: 8.9739
batch bounding time:  1.1038246154785156
Current worst splitting domains [lb, ub] (depth):
[-0.61952,   inf] (70), [-0.61761,   inf] (66), [-0.61685,   inf] (70), [-0.61593,   inf] (58), [-0.61472,   inf] (62), [-0.61437,   inf] (64), [-0.61424,   inf] (64), [-0.61395,   inf] (70), [-0.61391,   inf] (56), [-0.61390,   inf] (52), [-0.61390,   inf] (46), [-0.61390,   inf] (50), [-0.61389,   inf] (42), [-0.61388,   inf] (54), [-0.61388,   inf] (34), [-0.61388,   inf] (60), [-0.61387,   inf] (58), [-0.61387,   inf] (48), [-0.61387,   inf] (66), [-0.61386,   inf] (36), 
length of domains: 35486
Total time: 2.6954	 pickout: 0.1771	 decision: 0.3089	 get_bound: 1.1072	 add_domain: 1.1022
Current lb:-0.6195201873779297
89674 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 96.54762601852417

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 550] [1, 576] [1, 24] [2, 75] [1, 576] [1, 576] [1, 576] [2, 41] [1, 551] [1, 612] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 758.4754638671875 with beta sum per layer: [24.236120223999023, 2250.79248046875, 217.44677734375]
alpha/beta optimization time: 0.6881363391876221
This batch time : update_bounds func: 1.1122	 prepare: 0.2158	 bound: 0.6885	 transfer: 0.0550	 finalize: 0.1462
Accumulated time: update_bounds func: 54.7878	 prepare: 9.9634	 bound: 32.4704	 transfer: 0.0550	 finalize: 9.1202
batch bounding time:  1.114443063735962
Current worst splitting domains [lb, ub] (depth):
[-0.61309,   inf] (78), [-0.61301,   inf] (68), [-0.61271,   inf] (64), [-0.61218,   inf] (66), [-0.61182,   inf] (62), [-0.61176,   inf] (68), [-0.61156,   inf] (66), [-0.61108,   inf] (64), [-0.61097,   inf] (70), [-0.61096,   inf] (58), [-0.61087,   inf] (66), [-0.61061,   inf] (64), [-0.61050,   inf] (64), [-0.61044,   inf] (64), [-0.61025,   inf] (66), [-0.61019,   inf] (64), [-0.60996,   inf] (66), [-0.60995,   inf] (52), [-0.60954,   inf] (64), [-0.60937,   inf] (54), 
length of domains: 36203
Total time: 1.8162	 pickout: 0.1766	 decision: 0.3097	 get_bound: 1.1181	 add_domain: 0.2117
Current lb:-0.6130948066711426
91722 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 98.40032172203064

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [0, 1856] [1, 550] [2, 75] [2, 41] [1, 617] [1, 368] [1, 368] [1, 576] [1, 368] [1, 612] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 748.8279418945312 with beta sum per layer: [26.85101318359375, 2291.00341796875, 246.80084228515625]
alpha/beta optimization time: 0.6890113353729248
This batch time : update_bounds func: 1.1272	 prepare: 0.2346	 bound: 0.6894	 transfer: 0.0541	 finalize: 0.1412
Accumulated time: update_bounds func: 55.9150	 prepare: 10.1980	 bound: 33.1598	 transfer: 0.0541	 finalize: 9.2614
batch bounding time:  1.1293036937713623
Current worst splitting domains [lb, ub] (depth):
[-0.61180,   inf] (80), [-0.60900,   inf] (66), [-0.60855,   inf] (66), [-0.60820,   inf] (66), [-0.60813,   inf] (72), [-0.60789,   inf] (58), [-0.60781,   inf] (62), [-0.60756,   inf] (70), [-0.60725,   inf] (66), [-0.60710,   inf] (62), [-0.60697,   inf] (66), [-0.60641,   inf] (56), [-0.60624,   inf] (68), [-0.60623,   inf] (64), [-0.60614,   inf] (66), [-0.60556,   inf] (70), [-0.60536,   inf] (66), [-0.60531,   inf] (52), [-0.60523,   inf] (46), [-0.60521,   inf] (38), 
length of domains: 36929
Total time: 1.8708	 pickout: 0.1919	 decision: 0.3313	 get_bound: 1.1329	 add_domain: 0.2148
Current lb:-0.6117968559265137
93770 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 100.30595874786377

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 262] [1, 1208] [1, 1208] [1, 1208] [1, 262] [1, 617] [1, 662] [2, 41] [1, 1208] [1, 576] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 729.532470703125 with beta sum per layer: [26.29958724975586, 2224.128173828125, 238.141357421875]
alpha/beta optimization time: 0.6850965023040771
This batch time : update_bounds func: 2.0514	 prepare: 0.2173	 bound: 0.6855	 transfer: 0.0540	 finalize: 0.1448
Accumulated time: update_bounds func: 57.9664	 prepare: 10.4153	 bound: 33.8453	 transfer: 0.0540	 finalize: 9.4061
batch bounding time:  2.0534937381744385
Current worst splitting domains [lb, ub] (depth):
[-0.60321,   inf] (62), [-0.60286,   inf] (74), [-0.60273,   inf] (64), [-0.60269,   inf] (68), [-0.60257,   inf] (70), [-0.60221,   inf] (58), [-0.60218,   inf] (66), [-0.60206,   inf] (78), [-0.60195,   inf] (60), [-0.60161,   inf] (66), [-0.60159,   inf] (60), [-0.60145,   inf] (72), [-0.60143,   inf] (66), [-0.60128,   inf] (66), [-0.60120,   inf] (62), [-0.60103,   inf] (52), [-0.60102,   inf] (46), [-0.60102,   inf] (42), [-0.60102,   inf] (56), [-0.60101,   inf] (50), 
length of domains: 37642
Total time: 2.7590	 pickout: 0.1814	 decision: 0.3117	 get_bound: 2.0574	 add_domain: 0.2085
Current lb:-0.6032125949859619
95818 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 103.09881520271301

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 576] [1, 625] [0, 2443] [1, 262] [2, 41] [1, 662] [1, 576] [0, 1856] [1, 1208] [2, 75] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 719.0706176757812 with beta sum per layer: [27.077709197998047, 2191.927734375, 223.564453125]
alpha/beta optimization time: 0.6876358985900879
This batch time : update_bounds func: 1.1069	 prepare: 0.2165	 bound: 0.6880	 transfer: 0.0556	 finalize: 0.1395
Accumulated time: update_bounds func: 59.0733	 prepare: 10.6318	 bound: 34.5334	 transfer: 0.0556	 finalize: 9.5457
batch bounding time:  1.1090030670166016
Current worst splitting domains [lb, ub] (depth):
[-0.60257,   inf] (66), [-0.59977,   inf] (68), [-0.59962,   inf] (70), [-0.59948,   inf] (56), [-0.59932,   inf] (70), [-0.59930,   inf] (68), [-0.59916,   inf] (80), [-0.59913,   inf] (62), [-0.59905,   inf] (60), [-0.59902,   inf] (76), [-0.59897,   inf] (70), [-0.59882,   inf] (66), [-0.59873,   inf] (56), [-0.59869,   inf] (60), [-0.59847,   inf] (66), [-0.59845,   inf] (68), [-0.59762,   inf] (66), [-0.59718,   inf] (70), [-0.59715,   inf] (70), [-0.59708,   inf] (56), 
length of domains: 38347
Total time: 1.8098	 pickout: 0.1767	 decision: 0.3140	 get_bound: 1.1125	 add_domain: 0.2065
Current lb:-0.6025686264038086
97866 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 104.94110488891602

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 576] [1, 550] [2, 41] [1, 551] [2, 41] [1, 368] [1, 262] [1, 617] [1, 617] [1, 277] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 710.2252197265625 with beta sum per layer: [28.504959106445312, 2278.73779296875, 228.89169311523438]
alpha/beta optimization time: 0.6835191249847412
This batch time : update_bounds func: 1.1024	 prepare: 0.2149	 bound: 0.6839	 transfer: 0.0546	 finalize: 0.1419
Accumulated time: update_bounds func: 60.1756	 prepare: 10.8467	 bound: 35.2172	 transfer: 0.0546	 finalize: 9.6875
batch bounding time:  1.1043310165405273
Current worst splitting domains [lb, ub] (depth):
[-0.59588,   inf] (78), [-0.59554,   inf] (56), [-0.59512,   inf] (60), [-0.59497,   inf] (62), [-0.59493,   inf] (68), [-0.59442,   inf] (54), [-0.59429,   inf] (56), [-0.59413,   inf] (66), [-0.59407,   inf] (66), [-0.59395,   inf] (70), [-0.59392,   inf] (68), [-0.59379,   inf] (56), [-0.59366,   inf] (66), [-0.59324,   inf] (72), [-0.59312,   inf] (54), [-0.59310,   inf] (70), [-0.59308,   inf] (64), [-0.59305,   inf] (66), [-0.59304,   inf] (54), [-0.59303,   inf] (66), 
length of domains: 39035
Total time: 1.8015	 pickout: 0.1772	 decision: 0.3139	 get_bound: 1.1078	 add_domain: 0.2025
Current lb:-0.5958805084228516
99914 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 106.77479815483093

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [0, 1856] [1, 551] [1, 551] [1, 576] [1, 262] [2, 56] [1, 612] [2, 41] [2, 41] [1, 1208] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 692.1279296875 with beta sum per layer: [21.489124298095703, 2280.43115234375, 239.69189453125]
alpha/beta optimization time: 0.6851077079772949
This batch time : update_bounds func: 1.1103	 prepare: 0.2177	 bound: 0.6855	 transfer: 0.0546	 finalize: 0.1458
Accumulated time: update_bounds func: 61.2859	 prepare: 11.0643	 bound: 35.9027	 transfer: 0.0546	 finalize: 9.8333
batch bounding time:  1.1124043464660645
Current worst splitting domains [lb, ub] (depth):
[-0.59509,   inf] (80), [-0.59104,   inf] (64), [-0.59095,   inf] (66), [-0.59094,   inf] (70), [-0.59039,   inf] (70), [-0.59008,   inf] (62), [-0.58968,   inf] (62), [-0.58944,   inf] (64), [-0.58943,   inf] (64), [-0.58943,   inf] (64), [-0.58909,   inf] (66), [-0.58907,   inf] (80), [-0.58890,   inf] (72), [-0.58884,   inf] (66), [-0.58884,   inf] (48), [-0.58884,   inf] (60), [-0.58884,   inf] (56), [-0.58883,   inf] (42), [-0.58882,   inf] (60), [-0.58882,   inf] (50), 
length of domains: 39713
Total time: 2.7885	 pickout: 0.1748	 decision: 1.2960	 get_bound: 1.1160	 add_domain: 0.2017
Current lb:-0.5950899124145508
101962 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 109.60086178779602

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 262] [1, 617] [1, 617] [1, 368] [0, 1856] [1, 576] [1, 576] [0, 2443] [1, 617] [1, 576] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 704.18896484375 with beta sum per layer: [32.016048431396484, 2193.454833984375, 227.30712890625]
alpha/beta optimization time: 0.6837081909179688
This batch time : update_bounds func: 1.1063	 prepare: 0.2177	 bound: 0.6841	 transfer: 0.0536	 finalize: 0.1433
Accumulated time: update_bounds func: 62.3922	 prepare: 11.2820	 bound: 36.5868	 transfer: 0.0536	 finalize: 9.9766
batch bounding time:  1.1082358360290527
Current worst splitting domains [lb, ub] (depth):
[-0.58978,   inf] (72), [-0.58881,   inf] (66), [-0.58852,   inf] (66), [-0.58847,   inf] (82), [-0.58844,   inf] (74), [-0.58811,   inf] (72), [-0.58790,   inf] (66), [-0.58777,   inf] (56), [-0.58735,   inf] (76), [-0.58720,   inf] (66), [-0.58714,   inf] (66), [-0.58690,   inf] (64), [-0.58688,   inf] (56), [-0.58686,   inf] (78), [-0.58644,   inf] (70), [-0.58573,   inf] (70), [-0.58549,   inf] (50), [-0.58547,   inf] (66), [-0.58502,   inf] (70), [-0.58495,   inf] (68), 
length of domains: 40419
Total time: 1.8228	 pickout: 0.1832	 decision: 0.3157	 get_bound: 1.1118	 add_domain: 0.2122
Current lb:-0.589777946472168
104010 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 111.45733165740967

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 277] [1, 1208] [1, 617] [1, 617] [1, 625] [1, 277] [1, 662] [1, 123] [1, 262] [1, 368] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 684.741943359375 with beta sum per layer: [29.757741928100586, 2227.510986328125, 233.54791259765625]
alpha/beta optimization time: 0.6828417778015137
This batch time : update_bounds func: 2.1230	 prepare: 0.2148	 bound: 0.6832	 transfer: 0.0549	 finalize: 1.1629
Accumulated time: update_bounds func: 64.5152	 prepare: 11.4968	 bound: 37.2700	 transfer: 0.0549	 finalize: 11.1395
batch bounding time:  2.1253244876861572
Current worst splitting domains [lb, ub] (depth):
[-0.58477,   inf] (70), [-0.58395,   inf] (62), [-0.58377,   inf] (76), [-0.58375,   inf] (62), [-0.58336,   inf] (72), [-0.58326,   inf] (64), [-0.58310,   inf] (56), [-0.58302,   inf] (62), [-0.58281,   inf] (68), [-0.58280,   inf] (80), [-0.58263,   inf] (62), [-0.58248,   inf] (62), [-0.58200,   inf] (62), [-0.58198,   inf] (54), [-0.58114,   inf] (58), [-0.58114,   inf] (52), [-0.58114,   inf] (50), [-0.58113,   inf] (54), [-0.58113,   inf] (56), [-0.58113,   inf] (48), 
length of domains: 41122
Total time: 2.8332	 pickout: 0.1828	 decision: 0.3135	 get_bound: 2.1291	 add_domain: 0.2078
Current lb:-0.5847733020782471
106058 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 114.32326745986938

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [2, 41] [1, 576] [1, 24] [1, 576] [1, 277] [1, 617] [1, 551] [2, 75] [1, 368] [1, 262] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 685.54443359375 with beta sum per layer: [33.39856719970703, 2281.833740234375, 231.29771423339844]
alpha/beta optimization time: 0.6836481094360352
This batch time : update_bounds func: 1.1052	 prepare: 0.2180	 bound: 0.6840	 transfer: 0.0542	 finalize: 0.1415
Accumulated time: update_bounds func: 65.6204	 prepare: 11.7147	 bound: 37.9540	 transfer: 0.0542	 finalize: 11.2810
batch bounding time:  1.1072416305541992
Current worst splitting domains [lb, ub] (depth):
[-0.58019,   inf] (56), [-0.58012,   inf] (60), [-0.58000,   inf] (70), [-0.57999,   inf] (62), [-0.57992,   inf] (76), [-0.57965,   inf] (72), [-0.57964,   inf] (74), [-0.57947,   inf] (62), [-0.57898,   inf] (70), [-0.57886,   inf] (66), [-0.57852,   inf] (62), [-0.57832,   inf] (72), [-0.57826,   inf] (68), [-0.57820,   inf] (56), [-0.57814,   inf] (66), [-0.57797,   inf] (62), [-0.57786,   inf] (68), [-0.57782,   inf] (52), [-0.57772,   inf] (60), [-0.57761,   inf] (56), 
length of domains: 41813
Total time: 1.8179	 pickout: 0.1776	 decision: 0.3173	 get_bound: 1.1110	 add_domain: 0.2120
Current lb:-0.5801854133605957
108106 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 116.17641258239746

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 551] [1, 576] [1, 368] [1, 1208] [0, 1856] [2, 41] [1, 550] [1, 617] [1, 368] [1, 576] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 668.428955078125 with beta sum per layer: [24.452056884765625, 2306.7353515625, 243.98878479003906]
alpha/beta optimization time: 0.682671308517456
This batch time : update_bounds func: 1.1038	 prepare: 0.2177	 bound: 0.6830	 transfer: 0.0542	 finalize: 0.1420
Accumulated time: update_bounds func: 66.7242	 prepare: 11.9325	 bound: 38.6370	 transfer: 0.0542	 finalize: 11.4230
batch bounding time:  1.1060190200805664
Current worst splitting domains [lb, ub] (depth):
[-0.57785,   inf] (78), [-0.57673,   inf] (58), [-0.57653,   inf] (66), [-0.57472,   inf] (62), [-0.57471,   inf] (64), [-0.57469,   inf] (64), [-0.57457,   inf] (68), [-0.57456,   inf] (70), [-0.57445,   inf] (66), [-0.57431,   inf] (68), [-0.57387,   inf] (62), [-0.57387,   inf] (44), [-0.57386,   inf] (44), [-0.57386,   inf] (68), [-0.57386,   inf] (48), [-0.57385,   inf] (48), [-0.57385,   inf] (48), [-0.57385,   inf] (48), [-0.57385,   inf] (58), [-0.57385,   inf] (70), 
length of domains: 42503
Total time: 1.8133	 pickout: 0.1801	 decision: 0.3135	 get_bound: 1.1099	 add_domain: 0.2098
Current lb:-0.5778495073318481
110154 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 118.02431726455688

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 24] [1, 1208] [1, 368] [1, 617] [1, 576] [0, 2443] [1, 550] [1, 368] [2, 41] [1, 277] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 692.8836669921875 with beta sum per layer: [30.402469635009766, 2395.890625, 230.24217224121094]
alpha/beta optimization time: 0.6845941543579102
This batch time : update_bounds func: 2.1894	 prepare: 0.2190	 bound: 0.6850	 transfer: 0.0545	 finalize: 1.2231
Accumulated time: update_bounds func: 68.9136	 prepare: 12.1515	 bound: 39.3220	 transfer: 0.0545	 finalize: 12.6461
batch bounding time:  2.1913909912109375
Current worst splitting domains [lb, ub] (depth):
[-0.57448,   inf] (66), [-0.57261,   inf] (68), [-0.57238,   inf] (70), [-0.57221,   inf] (50), [-0.57188,   inf] (62), [-0.57138,   inf] (62), [-0.57125,   inf] (50), [-0.57112,   inf] (68), [-0.57106,   inf] (64), [-0.57089,   inf] (68), [-0.57087,   inf] (62), [-0.57048,   inf] (64), [-0.57045,   inf] (44), [-0.57045,   inf] (68), [-0.57045,   inf] (50), [-0.57045,   inf] (42), [-0.57044,   inf] (64), [-0.57044,   inf] (52), [-0.57044,   inf] (58), [-0.57044,   inf] (48), 
length of domains: 43221
Total time: 2.8980	 pickout: 0.1783	 decision: 0.3159	 get_bound: 2.1950	 add_domain: 0.2088
Current lb:-0.5744812488555908
112202 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 120.95387887954712

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 576] [1, 368] [2, 41] [2, 56] [1, 116] [1, 408] [1, 123] [2, 75] [1, 576] [1, 550] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 659.7322387695312 with beta sum per layer: [27.831418991088867, 2326.52197265625, 216.91932678222656]
alpha/beta optimization time: 0.6838846206665039
This batch time : update_bounds func: 1.1031	 prepare: 0.2178	 bound: 0.6843	 transfer: 0.0542	 finalize: 0.1399
Accumulated time: update_bounds func: 70.0167	 prepare: 12.3693	 bound: 40.0063	 transfer: 0.0542	 finalize: 12.7860
batch bounding time:  1.1051521301269531
Current worst splitting domains [lb, ub] (depth):
[-0.56942,   inf] (76), [-0.56909,   inf] (72), [-0.56893,   inf] (64), [-0.56890,   inf] (66), [-0.56889,   inf] (70), [-0.56848,   inf] (66), [-0.56829,   inf] (72), [-0.56827,   inf] (70), [-0.56794,   inf] (70), [-0.56788,   inf] (74), [-0.56780,   inf] (64), [-0.56780,   inf] (70), [-0.56777,   inf] (62), [-0.56750,   inf] (62), [-0.56747,   inf] (64), [-0.56746,   inf] (56), [-0.56735,   inf] (68), [-0.56733,   inf] (70), [-0.56733,   inf] (66), [-0.56726,   inf] (56), 
length of domains: 43897
Total time: 1.8065	 pickout: 0.1758	 decision: 0.3152	 get_bound: 1.1086	 add_domain: 0.2068
Current lb:-0.5694208145141602
114250 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 122.79336380958557

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 24] [1, 262] [1, 617] [2, 41] [1, 368] [1, 550] [1, 277] [1, 24] [1, 368] [1, 277] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 676.405029296875 with beta sum per layer: [28.559377670288086, 2286.572265625, 225.7545166015625]
alpha/beta optimization time: 0.6830852031707764
This batch time : update_bounds func: 1.1056	 prepare: 0.2195	 bound: 0.6834	 transfer: 0.0554	 finalize: 0.1399
Accumulated time: update_bounds func: 71.1223	 prepare: 12.5888	 bound: 40.6897	 transfer: 0.0554	 finalize: 12.9259
batch bounding time:  1.107541561126709
Current worst splitting domains [lb, ub] (depth):
[-0.56685,   inf] (62), [-0.56628,   inf] (72), [-0.56549,   inf] (74), [-0.56520,   inf] (70), [-0.56520,   inf] (62), [-0.56492,   inf] (60), [-0.56426,   inf] (70), [-0.56426,   inf] (68), [-0.56425,   inf] (72), [-0.56420,   inf] (66), [-0.56404,   inf] (70), [-0.56385,   inf] (72), [-0.56380,   inf] (64), [-0.56373,   inf] (54), [-0.56373,   inf] (52), [-0.56373,   inf] (60), [-0.56373,   inf] (44), [-0.56373,   inf] (78), [-0.56373,   inf] (56), [-0.56372,   inf] (60), 
length of domains: 44616
Total time: 1.8148	 pickout: 0.1759	 decision: 0.3180	 get_bound: 1.1111	 add_domain: 0.2098
Current lb:-0.5668463706970215
116298 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 124.64105677604675

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 576] [1, 262] [1, 24] [1, 368] [1, 576] [1, 617] [1, 368] [1, 368] [1, 24] [2, 41] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 641.963134765625 with beta sum per layer: [24.7482852935791, 2327.400634765625, 233.32888793945312]
alpha/beta optimization time: 0.684398889541626
This batch time : update_bounds func: 2.2463	 prepare: 0.2141	 bound: 0.6848	 transfer: 0.0541	 finalize: 1.2861
Accumulated time: update_bounds func: 73.3686	 prepare: 12.8029	 bound: 41.3745	 transfer: 0.0541	 finalize: 14.2120
batch bounding time:  2.248379707336426
Current worst splitting domains [lb, ub] (depth):
[-0.56352,   inf] (78), [-0.56292,   inf] (68), [-0.56265,   inf] (68), [-0.56261,   inf] (82), [-0.56256,   inf] (70), [-0.56232,   inf] (76), [-0.56227,   inf] (62), [-0.56207,   inf] (62), [-0.56207,   inf] (58), [-0.56198,   inf] (64), [-0.56123,   inf] (66), [-0.56114,   inf] (70), [-0.56103,   inf] (64), [-0.56093,   inf] (66), [-0.56075,   inf] (68), [-0.56061,   inf] (68), [-0.56059,   inf] (68), [-0.56047,   inf] (58), [-0.56047,   inf] (64), [-0.56046,   inf] (46), 
length of domains: 45294
Total time: 2.9505	 pickout: 0.1751	 decision: 0.3171	 get_bound: 2.2520	 add_domain: 0.2064
Current lb:-0.5635209083557129
118346 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 127.62727046012878

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 262] [1, 368] [1, 550] [1, 32] [1, 368] [1, 262] [1, 617] [1, 576] [1, 662] [2, 75] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 634.3765258789062 with beta sum per layer: [31.2752742767334, 2301.120361328125, 220.0203857421875]
alpha/beta optimization time: 0.6848838329315186
This batch time : update_bounds func: 1.1051	 prepare: 0.2174	 bound: 0.6853	 transfer: 0.0535	 finalize: 0.1418
Accumulated time: update_bounds func: 74.4736	 prepare: 13.0203	 bound: 42.0597	 transfer: 0.0535	 finalize: 14.3538
batch bounding time:  1.107161283493042
Current worst splitting domains [lb, ub] (depth):
[-0.56033,   inf] (66), [-0.56011,   inf] (70), [-0.55946,   inf] (78), [-0.55924,   inf] (70), [-0.55924,   inf] (64), [-0.55922,   inf] (56), [-0.55872,   inf] (66), [-0.55854,   inf] (72), [-0.55845,   inf] (66), [-0.55843,   inf] (72), [-0.55843,   inf] (70), [-0.55821,   inf] (66), [-0.55811,   inf] (64), [-0.55780,   inf] (62), [-0.55778,   inf] (70), [-0.55775,   inf] (74), [-0.55764,   inf] (58), [-0.55751,   inf] (72), [-0.55749,   inf] (64), [-0.55749,   inf] (64), 
length of domains: 45962
Total time: 1.8132	 pickout: 0.1768	 decision: 0.3193	 get_bound: 1.1108	 add_domain: 0.2063
Current lb:-0.560330867767334
120394 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 129.48041486740112

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 1208] [1, 1208] [1, 262] [1, 368] [1, 617] [1, 612] [1, 576] [1, 262] [1, 368] [1, 262] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 642.7799682617188 with beta sum per layer: [30.181835174560547, 2276.547119140625, 238.81320190429688]
alpha/beta optimization time: 0.6830117702484131
This batch time : update_bounds func: 1.1126	 prepare: 0.2236	 bound: 0.6834	 transfer: 0.0543	 finalize: 0.1438
Accumulated time: update_bounds func: 75.5862	 prepare: 13.2439	 bound: 42.7431	 transfer: 0.0543	 finalize: 14.4976
batch bounding time:  1.1146368980407715
Current worst splitting domains [lb, ub] (depth):
[-0.55764,   inf] (72), [-0.55633,   inf] (66), [-0.55622,   inf] (66), [-0.55598,   inf] (56), [-0.55588,   inf] (66), [-0.55557,   inf] (66), [-0.55549,   inf] (62), [-0.55540,   inf] (70), [-0.55527,   inf] (70), [-0.55510,   inf] (64), [-0.55463,   inf] (74), [-0.55461,   inf] (60), [-0.55461,   inf] (70), [-0.55447,   inf] (70), [-0.55446,   inf] (60), [-0.55433,   inf] (74), [-0.55413,   inf] (78), [-0.55413,   inf] (72), [-0.55411,   inf] (62), [-0.55411,   inf] (70), 
length of domains: 46650
Total time: 1.8230	 pickout: 0.1795	 decision: 0.3161	 get_bound: 1.1182	 add_domain: 0.2093
Current lb:-0.5576438903808594
122442 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 131.33833622932434

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 277] [2, 75] [1, 368] [1, 551] [1, 1208] [2, 75] [1, 576] [0, 1856] [0, 1856] [2, 75] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 653.427490234375 with beta sum per layer: [25.258909225463867, 2298.484375, 236.89862060546875]
alpha/beta optimization time: 0.6838703155517578
This batch time : update_bounds func: 2.2895	 prepare: 0.2144	 bound: 0.6842	 transfer: 0.0542	 finalize: 1.3296
Accumulated time: update_bounds func: 77.8758	 prepare: 13.4583	 bound: 43.4274	 transfer: 0.0542	 finalize: 15.8273
batch bounding time:  2.2915375232696533
Current worst splitting domains [lb, ub] (depth):
[-0.55464,   inf] (72), [-0.55331,   inf] (70), [-0.55292,   inf] (62), [-0.55291,   inf] (72), [-0.55280,   inf] (72), [-0.55275,   inf] (56), [-0.55269,   inf] (72), [-0.55242,   inf] (78), [-0.55231,   inf] (54), [-0.55202,   inf] (70), [-0.55199,   inf] (58), [-0.55186,   inf] (74), [-0.55167,   inf] (68), [-0.55161,   inf] (72), [-0.55156,   inf] (74), [-0.55156,   inf] (70), [-0.55134,   inf] (62), [-0.55118,   inf] (78), [-0.55111,   inf] (64), [-0.55095,   inf] (58), 
length of domains: 47367
Total time: 3.0029	 pickout: 0.1796	 decision: 0.3180	 get_bound: 2.2951	 add_domain: 0.2102
Current lb:-0.5546393394470215
124490 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 134.37407422065735

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 277] [1, 368] [1, 576] [0, 2443] [1, 277] [1, 551] [1, 277] [1, 262] [1, 612] [1, 368] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 633.1883544921875 with beta sum per layer: [31.031070709228516, 2323.95166015625, 227.0157470703125]
alpha/beta optimization time: 0.6837170124053955
This batch time : update_bounds func: 1.1013	 prepare: 0.2147	 bound: 0.6841	 transfer: 0.0542	 finalize: 0.1407
Accumulated time: update_bounds func: 78.9770	 prepare: 13.6730	 bound: 44.1114	 transfer: 0.0542	 finalize: 15.9680
batch bounding time:  1.1032519340515137
Current worst splitting domains [lb, ub] (depth):
[-0.55278,   inf] (74), [-0.55024,   inf] (68), [-0.55001,   inf] (70), [-0.54998,   inf] (68), [-0.54985,   inf] (56), [-0.54972,   inf] (66), [-0.54929,   inf] (64), [-0.54925,   inf] (72), [-0.54921,   inf] (74), [-0.54896,   inf] (64), [-0.54873,   inf] (70), [-0.54859,   inf] (52), [-0.54844,   inf] (58), [-0.54835,   inf] (56), [-0.54832,   inf] (66), [-0.54822,   inf] (52), [-0.54804,   inf] (64), [-0.54803,   inf] (64), [-0.54800,   inf] (62), [-0.54792,   inf] (50), 
length of domains: 48055
Total time: 1.8178	 pickout: 0.1801	 decision: 0.3187	 get_bound: 1.1069	 add_domain: 0.2121
Current lb:-0.5527815818786621
126538 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 136.2252960205078

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 550] [1, 550] [1, 262] [1, 277] [1, 551] [1, 576] [0, 1856] [1, 550] [1, 277] [2, 75] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 626.305419921875 with beta sum per layer: [29.111175537109375, 2267.6162109375, 245.3543701171875]
alpha/beta optimization time: 0.6826944351196289
This batch time : update_bounds func: 1.1035	 prepare: 0.2176	 bound: 0.6831	 transfer: 0.0542	 finalize: 0.1419
Accumulated time: update_bounds func: 80.0806	 prepare: 13.8905	 bound: 44.7945	 transfer: 0.0542	 finalize: 16.1099
batch bounding time:  1.1054866313934326
Current worst splitting domains [lb, ub] (depth):
[-0.54732,   inf] (66), [-0.54726,   inf] (68), [-0.54696,   inf] (62), [-0.54652,   inf] (56), [-0.54646,   inf] (60), [-0.54645,   inf] (72), [-0.54643,   inf] (66), [-0.54641,   inf] (74), [-0.54620,   inf] (72), [-0.54613,   inf] (70), [-0.54599,   inf] (70), [-0.54583,   inf] (74), [-0.54581,   inf] (64), [-0.54579,   inf] (66), [-0.54577,   inf] (76), [-0.54570,   inf] (72), [-0.54555,   inf] (56), [-0.54550,   inf] (62), [-0.54532,   inf] (64), [-0.54521,   inf] (66), 
length of domains: 48736
Total time: 1.8099	 pickout: 0.1786	 decision: 0.3138	 get_bound: 1.1089	 add_domain: 0.2086
Current lb:-0.5473153591156006
128586 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 138.0676884651184

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 1208] [1, 123] [1, 576] [1, 551] [1, 576] [1, 277] [1, 576] [1, 550] [1, 262] [1, 550] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 619.1070556640625 with beta sum per layer: [25.194442749023438, 2313.50927734375, 238.73779296875]
alpha/beta optimization time: 0.683422327041626
This batch time : update_bounds func: 1.1040	 prepare: 0.2160	 bound: 0.6838	 transfer: 0.0553	 finalize: 0.1413
Accumulated time: update_bounds func: 81.1846	 prepare: 14.1065	 bound: 45.4783	 transfer: 0.0553	 finalize: 16.2512
batch bounding time:  1.106013536453247
Current worst splitting domains [lb, ub] (depth):
[-0.54414,   inf] (66), [-0.54365,   inf] (64), [-0.54346,   inf] (70), [-0.54309,   inf] (68), [-0.54299,   inf] (64), [-0.54289,   inf] (74), [-0.54281,   inf] (82), [-0.54277,   inf] (64), [-0.54275,   inf] (66), [-0.54273,   inf] (60), [-0.54257,   inf] (62), [-0.54252,   inf] (64), [-0.54216,   inf] (70), [-0.54187,   inf] (42), [-0.54187,   inf] (30), [-0.54187,   inf] (74), [-0.54187,   inf] (50), [-0.54187,   inf] (50), [-0.54186,   inf] (42), [-0.54186,   inf] (64), 
length of domains: 49437
Total time: 3.1306	 pickout: 0.1778	 decision: 0.3200	 get_bound: 1.1096	 add_domain: 1.5232
Current lb:-0.544135570526123
130634 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 141.2311544418335

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 368] [1, 617] [0, 1856] [1, 116] [1, 576] [1, 24] [1, 32] [1, 617] [1, 1208] [1, 1208] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 620.505859375 with beta sum per layer: [21.875593185424805, 2273.868896484375, 226.8792724609375]
alpha/beta optimization time: 0.6831765174865723
This batch time : update_bounds func: 1.1015	 prepare: 0.2165	 bound: 0.6835	 transfer: 0.0543	 finalize: 0.1398
Accumulated time: update_bounds func: 82.2861	 prepare: 14.3230	 bound: 46.1618	 transfer: 0.0543	 finalize: 16.3909
batch bounding time:  1.1035170555114746
Current worst splitting domains [lb, ub] (depth):
[-0.54275,   inf] (72), [-0.54163,   inf] (70), [-0.54156,   inf] (72), [-0.54120,   inf] (60), [-0.54103,   inf] (74), [-0.54095,   inf] (76), [-0.54089,   inf] (66), [-0.54066,   inf] (70), [-0.54049,   inf] (54), [-0.54032,   inf] (72), [-0.54031,   inf] (66), [-0.54004,   inf] (66), [-0.53977,   inf] (64), [-0.53969,   inf] (76), [-0.53951,   inf] (66), [-0.53929,   inf] (78), [-0.53912,   inf] (74), [-0.53903,   inf] (48), [-0.53903,   inf] (40), [-0.53903,   inf] (36), 
length of domains: 50138
Total time: 1.8152	 pickout: 0.1765	 decision: 0.3195	 get_bound: 1.1071	 add_domain: 0.2121
Current lb:-0.5427517890930176
132682 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 143.07978010177612

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 277] [2, 41] [1, 277] [1, 617] [1, 625] [1, 368] [2, 41] [1, 277] [1, 408] [1, 277] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 604.4552001953125 with beta sum per layer: [35.666969299316406, 2324.1123046875, 224.73828125]
alpha/beta optimization time: 0.6859745979309082
This batch time : update_bounds func: 1.1118	 prepare: 0.2190	 bound: 0.6864	 transfer: 0.0552	 finalize: 0.1434
Accumulated time: update_bounds func: 83.3978	 prepare: 14.5420	 bound: 46.8482	 transfer: 0.0552	 finalize: 16.5344
batch bounding time:  1.1137504577636719
Current worst splitting domains [lb, ub] (depth):
[-0.53821,   inf] (70), [-0.53806,   inf] (60), [-0.53800,   inf] (70), [-0.53758,   inf] (64), [-0.53755,   inf] (60), [-0.53735,   inf] (78), [-0.53722,   inf] (62), [-0.53713,   inf] (72), [-0.53705,   inf] (54), [-0.53697,   inf] (62), [-0.53693,   inf] (68), [-0.53679,   inf] (72), [-0.53647,   inf] (74), [-0.53639,   inf] (64), [-0.53615,   inf] (56), [-0.53615,   inf] (52), [-0.53615,   inf] (58), [-0.53615,   inf] (40), [-0.53615,   inf] (36), [-0.53615,   inf] (72), 
length of domains: 50811
Total time: 1.8237	 pickout: 0.1777	 decision: 0.3189	 get_bound: 1.1173	 add_domain: 0.2097
Current lb:-0.5382092595100403
134730 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 144.9377956390381

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 368] [1, 662] [1, 368] [1, 123] [1, 617] [1, 262] [1, 116] [1, 550] [2, 56] [2, 75] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 624.899169921875 with beta sum per layer: [20.048982620239258, 2375.64306640625, 215.04124450683594]
alpha/beta optimization time: 0.6826229095458984
This batch time : update_bounds func: 1.1086	 prepare: 0.2196	 bound: 0.6830	 transfer: 0.0543	 finalize: 0.1435
Accumulated time: update_bounds func: 84.5064	 prepare: 14.7616	 bound: 47.5312	 transfer: 0.0543	 finalize: 16.6779
batch bounding time:  1.110703468322754
Current worst splitting domains [lb, ub] (depth):
[-0.53536,   inf] (56), [-0.53528,   inf] (74), [-0.53521,   inf] (68), [-0.53521,   inf] (60), [-0.53521,   inf] (54), [-0.53508,   inf] (72), [-0.53499,   inf] (80), [-0.53484,   inf] (52), [-0.53472,   inf] (70), [-0.53441,   inf] (54), [-0.53421,   inf] (78), [-0.53401,   inf] (74), [-0.53390,   inf] (64), [-0.53389,   inf] (68), [-0.53374,   inf] (64), [-0.53352,   inf] (58), [-0.53340,   inf] (50), [-0.53340,   inf] (46), [-0.53340,   inf] (42), [-0.53340,   inf] (52), 
length of domains: 51525
Total time: 1.8319	 pickout: 0.1800	 decision: 0.3220	 get_bound: 1.1143	 add_domain: 0.2156
Current lb:-0.535362958908081
136778 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 146.80298614501953

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 551] [0, 2443] [1, 116] [1, 576] [1, 612] [2, 41] [1, 262] [2, 56] [2, 41] [1, 612] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 578.818359375 with beta sum per layer: [35.20240783691406, 2265.72900390625, 245.17132568359375]
alpha/beta optimization time: 0.682697057723999
This batch time : update_bounds func: 1.1032	 prepare: 0.2180	 bound: 0.6831	 transfer: 0.0532	 finalize: 0.1419
Accumulated time: update_bounds func: 85.6097	 prepare: 14.9796	 bound: 48.2143	 transfer: 0.0532	 finalize: 16.8198
batch bounding time:  1.1052019596099854
Current worst splitting domains [lb, ub] (depth):
[-0.53515,   inf] (76), [-0.53284,   inf] (70), [-0.53268,   inf] (70), [-0.53267,   inf] (64), [-0.53241,   inf] (66), [-0.53211,   inf] (58), [-0.53208,   inf] (68), [-0.53127,   inf] (72), [-0.53116,   inf] (74), [-0.53115,   inf] (76), [-0.53109,   inf] (68), [-0.53101,   inf] (62), [-0.53088,   inf] (62), [-0.53076,   inf] (76), [-0.53070,   inf] (50), [-0.53070,   inf] (58), [-0.53070,   inf] (62), [-0.53070,   inf] (54), [-0.53070,   inf] (42), [-0.53069,   inf] (58), 
length of domains: 52187
Total time: 3.1229	 pickout: 0.1806	 decision: 1.6229	 get_bound: 1.1087	 add_domain: 0.2107
Current lb:-0.5351529121398926
138826 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 149.96110343933105

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 262] [2, 41] [2, 41] [1, 576] [1, 617] [1, 116] [1, 123] [1, 262] [1, 550] [0, 1856] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 597.82568359375 with beta sum per layer: [25.996368408203125, 2317.451171875, 227.398193359375]
alpha/beta optimization time: 0.6830239295959473
This batch time : update_bounds func: 1.1041	 prepare: 0.2168	 bound: 0.6834	 transfer: 0.0545	 finalize: 0.1420
Accumulated time: update_bounds func: 86.7138	 prepare: 15.1964	 bound: 48.8977	 transfer: 0.0545	 finalize: 16.9619
batch bounding time:  1.1061882972717285
Current worst splitting domains [lb, ub] (depth):
[-0.53036,   inf] (78), [-0.52988,   inf] (62), [-0.52969,   inf] (70), [-0.52964,   inf] (70), [-0.52952,   inf] (72), [-0.52927,   inf] (74), [-0.52926,   inf] (76), [-0.52916,   inf] (62), [-0.52903,   inf] (78), [-0.52899,   inf] (56), [-0.52848,   inf] (66), [-0.52845,   inf] (70), [-0.52837,   inf] (54), [-0.52828,   inf] (70), [-0.52809,   inf] (66), [-0.52804,   inf] (76), [-0.52793,   inf] (76), [-0.52792,   inf] (66), [-0.52792,   inf] (62), [-0.52792,   inf] (72), 
length of domains: 52878
Total time: 1.8152	 pickout: 0.1774	 decision: 0.3166	 get_bound: 1.1098	 add_domain: 0.2113
Current lb:-0.5303635597229004
140874 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 151.81028628349304

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 24] [1, 617] [1, 625] [1, 550] [1, 277] [2, 41] [1, 262] [1, 576] [1, 262] [1, 551] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 593.0177001953125 with beta sum per layer: [31.792402267456055, 2413.15234375, 204.0548095703125]
alpha/beta optimization time: 0.6833696365356445
This batch time : update_bounds func: 1.1076	 prepare: 0.2191	 bound: 0.6837	 transfer: 0.0548	 finalize: 0.1424
Accumulated time: update_bounds func: 87.8214	 prepare: 15.4155	 bound: 49.5814	 transfer: 0.0548	 finalize: 17.1042
batch bounding time:  1.109713077545166
Current worst splitting domains [lb, ub] (depth):
[-0.52767,   inf] (72), [-0.52727,   inf] (66), [-0.52708,   inf] (72), [-0.52691,   inf] (78), [-0.52671,   inf] (68), [-0.52667,   inf] (68), [-0.52656,   inf] (68), [-0.52644,   inf] (66), [-0.52630,   inf] (62), [-0.52621,   inf] (62), [-0.52619,   inf] (62), [-0.52592,   inf] (70), [-0.52588,   inf] (64), [-0.52580,   inf] (62), [-0.52547,   inf] (66), [-0.52538,   inf] (68), [-0.52525,   inf] (60), [-0.52525,   inf] (40), [-0.52525,   inf] (56), [-0.52524,   inf] (44), 
length of domains: 53554
Total time: 1.8226	 pickout: 0.1769	 decision: 0.3193	 get_bound: 1.1134	 add_domain: 0.2130
Current lb:-0.5276708602905273
142922 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 153.66602230072021

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 277] [1, 576] [1, 277] [1, 262] [1, 262] [2, 75] [0, 2443] [2, 41] [1, 662] [1, 617] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 585.5230712890625 with beta sum per layer: [35.61174392700195, 2336.6640625, 221.39955139160156]
alpha/beta optimization time: 0.6833024024963379
This batch time : update_bounds func: 1.1082	 prepare: 0.2177	 bound: 0.6837	 transfer: 0.0560	 finalize: 0.1437
Accumulated time: update_bounds func: 88.9296	 prepare: 15.6332	 bound: 50.2651	 transfer: 0.0560	 finalize: 17.2479
batch bounding time:  1.1102039813995361
Current worst splitting domains [lb, ub] (depth):
[-0.52638,   inf] (70), [-0.52568,   inf] (66), [-0.52460,   inf] (66), [-0.52437,   inf] (56), [-0.52436,   inf] (72), [-0.52432,   inf] (70), [-0.52415,   inf] (82), [-0.52410,   inf] (66), [-0.52408,   inf] (66), [-0.52405,   inf] (74), [-0.52405,   inf] (56), [-0.52401,   inf] (66), [-0.52399,   inf] (54), [-0.52398,   inf] (66), [-0.52395,   inf] (58), [-0.52388,   inf] (66), [-0.52385,   inf] (58), [-0.52378,   inf] (66), [-0.52366,   inf] (76), [-0.52356,   inf] (64), 
length of domains: 54228
Total time: 3.1997	 pickout: 0.1820	 decision: 0.3172	 get_bound: 1.1139	 add_domain: 1.5866
Current lb:-0.5263767242431641
144970 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 156.8995804786682

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [2, 41] [1, 576] [1, 617] [1, 551] [1, 277] [1, 368] [1, 1208] [1, 277] [2, 41] [1, 24] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 585.768310546875 with beta sum per layer: [29.496768951416016, 2278.278564453125, 228.4224853515625]
alpha/beta optimization time: 0.6839718818664551
This batch time : update_bounds func: 1.1099	 prepare: 0.2204	 bound: 0.6844	 transfer: 0.0543	 finalize: 0.1426
Accumulated time: update_bounds func: 90.0395	 prepare: 15.8536	 bound: 50.9494	 transfer: 0.0543	 finalize: 17.3906
batch bounding time:  1.11199951171875
Current worst splitting domains [lb, ub] (depth):
[-0.52179,   inf] (70), [-0.52173,   inf] (70), [-0.52153,   inf] (62), [-0.52088,   inf] (68), [-0.52058,   inf] (56), [-0.52057,   inf] (56), [-0.52053,   inf] (50), [-0.52051,   inf] (62), [-0.52041,   inf] (72), [-0.52030,   inf] (58), [-0.52019,   inf] (72), [-0.52019,   inf] (66), [-0.52003,   inf] (68), [-0.52001,   inf] (64), [-0.51995,   inf] (56), [-0.51984,   inf] (78), [-0.51983,   inf] (62), [-0.51982,   inf] (56), [-0.51982,   inf] (48), [-0.51981,   inf] (48), 
length of domains: 54907
Total time: 1.8301	 pickout: 0.1795	 decision: 0.3213	 get_bound: 1.1156	 add_domain: 0.2137
Current lb:-0.5217936038970947
147018 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 158.76392221450806

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 368] [1, 550] [1, 576] [1, 550] [1, 551] [1, 551] [1, 123] [1, 576] [1, 262] [1, 116] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 578.1484375 with beta sum per layer: [25.704553604125977, 2338.470703125, 231.92132568359375]
alpha/beta optimization time: 0.683495044708252
This batch time : update_bounds func: 1.1110	 prepare: 0.2205	 bound: 0.6839	 transfer: 0.0550	 finalize: 0.1438
Accumulated time: update_bounds func: 91.1505	 prepare: 16.0741	 bound: 51.6333	 transfer: 0.0550	 finalize: 17.5344
batch bounding time:  1.1131675243377686
Current worst splitting domains [lb, ub] (depth):
[-0.51943,   inf] (72), [-0.51886,   inf] (70), [-0.51847,   inf] (68), [-0.51846,   inf] (70), [-0.51845,   inf] (56), [-0.51841,   inf] (66), [-0.51829,   inf] (68), [-0.51825,   inf] (70), [-0.51817,   inf] (62), [-0.51816,   inf] (70), [-0.51814,   inf] (56), [-0.51814,   inf] (76), [-0.51812,   inf] (58), [-0.51807,   inf] (76), [-0.51791,   inf] (62), [-0.51787,   inf] (70), [-0.51778,   inf] (68), [-0.51759,   inf] (72), [-0.51758,   inf] (82), [-0.51751,   inf] (62), 
length of domains: 55601
Total time: 1.8288	 pickout: 0.1762	 decision: 0.3203	 get_bound: 1.1168	 add_domain: 0.2155
Current lb:-0.5194287300109863
149066 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 160.62353420257568

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 262] [1, 368] [2, 41] [1, 368] [1, 576] [1, 576] [1, 368] [1, 368] [1, 662] [1, 368] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 566.7531127929688 with beta sum per layer: [24.280364990234375, 2362.863037109375, 231.52584838867188]
alpha/beta optimization time: 0.6845362186431885
This batch time : update_bounds func: 1.1030	 prepare: 0.2165	 bound: 0.6849	 transfer: 0.0540	 finalize: 0.1401
Accumulated time: update_bounds func: 92.2535	 prepare: 16.2906	 bound: 52.3182	 transfer: 0.0540	 finalize: 17.6745
batch bounding time:  1.1051082611083984
Current worst splitting domains [lb, ub] (depth):
[-0.51759,   inf] (70), [-0.51724,   inf] (72), [-0.51675,   inf] (78), [-0.51618,   inf] (56), [-0.51610,   inf] (72), [-0.51607,   inf] (68), [-0.51592,   inf] (64), [-0.51570,   inf] (72), [-0.51531,   inf] (74), [-0.51531,   inf] (68), [-0.51523,   inf] (66), [-0.51508,   inf] (72), [-0.51505,   inf] (66), [-0.51468,   inf] (70), [-0.51467,   inf] (52), [-0.51463,   inf] (70), [-0.51457,   inf] (76), [-0.51457,   inf] (74), [-0.51457,   inf] (48), [-0.51457,   inf] (44), 
length of domains: 56272
Total time: 1.8171	 pickout: 0.1794	 decision: 0.3185	 get_bound: 1.1088	 add_domain: 0.2104
Current lb:-0.5175943374633789
151114 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 162.47405457496643

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 368] [1, 277] [1, 262] [1, 551] [1, 277] [1, 277] [1, 617] [1, 277] [1, 24] [1, 368] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 565.8343505859375 with beta sum per layer: [27.191402435302734, 2306.90478515625, 235.56068420410156]
alpha/beta optimization time: 0.6851086616516113
This batch time : update_bounds func: 2.5590	 prepare: 0.2225	 bound: 0.6855	 transfer: 0.0545	 finalize: 1.5890
Accumulated time: update_bounds func: 94.8125	 prepare: 16.5131	 bound: 53.0037	 transfer: 0.0545	 finalize: 19.2636
batch bounding time:  2.5611352920532227
Current worst splitting domains [lb, ub] (depth):
[-0.51384,   inf] (68), [-0.51369,   inf] (62), [-0.51327,   inf] (62), [-0.51318,   inf] (70), [-0.51317,   inf] (66), [-0.51309,   inf] (80), [-0.51303,   inf] (70), [-0.51302,   inf] (70), [-0.51279,   inf] (66), [-0.51259,   inf] (58), [-0.51255,   inf] (64), [-0.51250,   inf] (64), [-0.51243,   inf] (70), [-0.51229,   inf] (62), [-0.51221,   inf] (64), [-0.51218,   inf] (60), [-0.51208,   inf] (52), [-0.51208,   inf] (48), [-0.51207,   inf] (56), [-0.51207,   inf] (44), 
length of domains: 56949
Total time: 3.2731	 pickout: 0.1748	 decision: 0.3231	 get_bound: 2.5647	 add_domain: 0.2105
Current lb:-0.5138392448425293
153162 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 165.78223085403442

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 368] [1, 576] [1, 576] [0, 1856] [1, 368] [1, 262] [1, 368] [2, 41] [1, 368] [1, 551] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 571.0423583984375 with beta sum per layer: [28.78412437438965, 2395.453125, 222.15045166015625]
alpha/beta optimization time: 0.6840429306030273
This batch time : update_bounds func: 1.1071	 prepare: 0.2198	 bound: 0.6844	 transfer: 0.0545	 finalize: 0.1413
Accumulated time: update_bounds func: 95.9196	 prepare: 16.7330	 bound: 53.6881	 transfer: 0.0545	 finalize: 19.4049
batch bounding time:  1.1090960502624512
Current worst splitting domains [lb, ub] (depth):
[-0.51256,   inf] (72), [-0.51164,   inf] (74), [-0.51121,   inf] (70), [-0.51114,   inf] (66), [-0.51104,   inf] (72), [-0.51091,   inf] (56), [-0.51081,   inf] (56), [-0.51079,   inf] (84), [-0.51064,   inf] (76), [-0.51059,   inf] (82), [-0.51052,   inf] (70), [-0.51048,   inf] (66), [-0.51041,   inf] (64), [-0.51028,   inf] (62), [-0.51024,   inf] (66), [-0.51012,   inf] (68), [-0.51010,   inf] (84), [-0.51003,   inf] (70), [-0.50973,   inf] (56), [-0.50962,   inf] (62), 
length of domains: 57640
Total time: 1.8265	 pickout: 0.1772	 decision: 0.3219	 get_bound: 1.1126	 add_domain: 0.2148
Current lb:-0.5125637054443359
155210 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 167.64354538917542

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 277] [1, 625] [1, 368] [2, 41] [1, 277] [1, 551] [1, 662] [1, 425] [1, 277] [1, 32] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 561.404052734375 with beta sum per layer: [28.50127410888672, 2430.03564453125, 220.267333984375]
alpha/beta optimization time: 0.6852941513061523
This batch time : update_bounds func: 1.1075	 prepare: 0.2163	 bound: 0.6857	 transfer: 0.0547	 finalize: 0.1434
Accumulated time: update_bounds func: 97.0271	 prepare: 16.9493	 bound: 54.3738	 transfer: 0.0547	 finalize: 19.5483
batch bounding time:  1.1094794273376465
Current worst splitting domains [lb, ub] (depth):
[-0.51020,   inf] (66), [-0.50993,   inf] (70), [-0.50902,   inf] (66), [-0.50864,   inf] (70), [-0.50858,   inf] (70), [-0.50854,   inf] (64), [-0.50839,   inf] (70), [-0.50828,   inf] (78), [-0.50827,   inf] (70), [-0.50816,   inf] (74), [-0.50814,   inf] (70), [-0.50801,   inf] (74), [-0.50792,   inf] (56), [-0.50779,   inf] (86), [-0.50763,   inf] (78), [-0.50760,   inf] (64), [-0.50751,   inf] (56), [-0.50747,   inf] (66), [-0.50741,   inf] (64), [-0.50715,   inf] (54), 
length of domains: 58311
Total time: 1.8278	 pickout: 0.1857	 decision: 0.3172	 get_bound: 1.1130	 add_domain: 0.2120
Current lb:-0.5102009773254395
157258 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 169.50886940956116

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 16, 14, 14]) pre split depth:  1
batch:  torch.Size([1024, 16, 14, 14]) post split depth:  1
splitting decisions: 
split level 0: [1, 662] [2, 41] [1, 576] [1, 368] [1, 625] [1, 262] [1, 368] [1, 262] [0, 1856] [1, 576] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 558.493408203125 with beta sum per layer: [26.972047805786133, 2405.439453125, 225.55044555664062]
alpha/beta optimization time: 0.6828279495239258
This batch time : update_bounds func: 1.1100	 prepare: 0.2221	 bound: 0.6832	 transfer: 0.0542	 finalize: 0.1429
Accumulated time: update_bounds func: 98.1371	 prepare: 17.1713	 bound: 55.0570	 transfer: 0.0542	 finalize: 19.6912
batch bounding time:  1.111997365951538
Current worst splitting domains [lb, ub] (depth):
[-0.50753,   inf] (72), [-0.50674,   inf] (72), [-0.50635,   inf] (80), [-0.50627,   inf] (66), [-0.50621,   inf] (68), [-0.50593,   inf] (64), [-0.50589,   inf] (64), [-0.50575,   inf] (56), [-0.50547,   inf] (70), [-0.50543,   inf] (66), [-0.50540,   inf] (76), [-0.50525,   inf] (62), [-0.50510,   inf] (74), [-0.50508,   inf] (66), [-0.50507,   inf] (80), [-0.50499,   inf] (54), [-0.50496,   inf] (62), [-0.50496,   inf] (84), [-0.50491,   inf] (64), [-0.50490,   inf] (62), 
length of domains: 59000
Total time: 1.8327	 pickout: 0.1838	 decision: 0.3196	 get_bound: 1.1156	 add_domain: 0.2138
Current lb:-0.5075316429138184
159306 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Time out!!!!!!!!
Image 112 label 2 verification end, final lower bound -0.5075316429138184, upper bound inf, time: 172.77753353118896
112 -0.5075316429138184
Result: image 112 verification failure (with branch and bound).
Wall time: 181.59524703025818

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 0): []
verification failure idx (total 1): [112]
final verified acc: 0.0%[1]
verifier is called on 1 examples.
total verified: 0
mean time [cnt:1] (excluding attack success): 181.52576875686646
