/home/shiqi/miniconda3/envs/py37/lib/python3.7/site-packages/onnx/mapping.py:27: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. 
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  int(TensorProto.STRING): np.dtype(np.object)
Experiments at Mon Nov  1 22:23:58 2021 on huan-Super-Server
Namespace(batch_size=500, beta_warmup=True, branching_candidates=3, branching_method='kfsb', branching_reduceop='min', complete_verifier='bab-refine', conv_mode='patches', crown=False, data='MNIST_ERAN_UN', decision_thresh=0, deterministic=False, device='cuda', double_fp=False, end=15, epsilon=0.026, incomplete=True, init_iteration=100, intermediate_refinement_layers=[-1], iteration=50, load='eran_models/mnist_6_100_nat_old.pth', loss_reduction_func='sum', lp_test=None, lr_alpha=0.01, lr_beta=0.05, lr_decay=0.98, lr_init_alpha=0.1, lr_intermediate_beta=0.05, max_refinement_domains=1000, max_subproblems_list=200000, mip_multi_proc=16, mip_perneuron_refine_timeout=15, mip_refine_timeout=0.8, mip_threads=1, mode='verified-acc', model='mnist_6_100', no_beta=False, no_joint_opt=False, no_warm=False, norm=inf, opt_bias=False, opt_coeffs=False, opt_intermediate_beta=False, optimizer='adam', pgd_order='before', record_lb=False, refinement_batch_size=-1, seed=100, share_slopes=False, solve_slope=True, start=14, timeout=300.0)
Sequential(
  (0): Flatten()
  (1): Linear(in_features=784, out_features=100, bias=True)
  (2): ReLU()
  (3): Linear(in_features=100, out_features=100, bias=True)
  (4): ReLU()
  (5): Linear(in_features=100, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=100, bias=True)
  (8): ReLU()
  (9): Linear(in_features=100, out_features=100, bias=True)
  (10): ReLU()
  (11): Linear(in_features=100, out_features=10, bias=True)
)
complete verification for verified accuracy, set decision_thresh to be 0
/home/shiqi/CROWN-GENERAL-old/examples/vision/plnn/utils.py:1288: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  labels = torch.from_numpy(labels.astype(np.int))
/home/shiqi/CROWN-GENERAL-old/examples/vision/plnn/utils.py:1292: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(eps_temp).reshape(1,-1,1,1)
############################
Sampled data loaded. No normalization used!
Shape: torch.Size([1000, 1, 28, 28]) torch.Size([1000]) torch.Size([1000])
X range: tensor(1.) tensor(0.) tensor(0.1223)
Note runnerup label is empty here!
############################
epsilon after preprocession: tensor([[[[0.0260]]]]), data_max = tensor([[[[1.]]]]), data_min = tensor([[[[0.]]]])
saving results to Verified_ret_[mnist_6_100]_start=14_end=15_iter=50_b=500_int-beta=False_timeout=300.0_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 14 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label  1  correct label  1 logits tensor([-5.0631, 13.1667,  0.7939, -2.8103,  0.4855, -3.1720, -2.6758,  0.8242,
         1.9934, -2.4615], grad_fn=<SelectBackward0>)
##### PGD attack: True label: 1, Tested against: all others ######
pgd prediction: tensor([-3.7035,  9.4645,  0.4729, -1.4021,  0.3693, -2.2787, -2.4558,  0.7047,
         1.8104, -1.4819], device='cuda:0', grad_fn=<SqueezeBackward1>)
attack margin tensor([13.1680,     inf,  8.9916, 10.8666,  9.0952, 11.7432, 11.9203,  8.7598,
         7.6541, 10.9464], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[-5.0631, 13.1667,  0.7939, -2.8103,  0.4855, -3.1720, -2.6758,  0.8242,
          1.9934, -2.4615]], device='cuda:0', grad_fn=<AddBackward0>)
alpha-CROWN optimizable variables initialized.
best_l after optimization: 39.037353515625 with beta sum per layer: []
optimal alpha/beta time: 5.622649669647217
initial alpha-CROWN bounds: tensor([[-0.9929, -5.8539, -6.8840, -4.6689, -3.6314, -0.9617, -4.7828, -5.2511,
         -6.0107]], device='cuda:0', grad_fn=<AsStridedBackward0>) None
Start solving intermediate bounds with MIP...
alpha-CROWN optimizable variables initialized.
The program tries to detect if we are inside a docker. Hiding ourselves!!
Academic license - for non-commercial use only - expires 2022-07-16
Using license file /home/shiqi/gurobi.lic
mip_multi_proc: 16, mip_threads: 1,total threads used: 16, mip_perneuron_refine_timeout: 15
[total time budget for MIP: 240.0]

Linear(in_features=784, out_features=100, bias=True) 0 2 torch.Size([100])
Linear(in_features=100, out_features=100, bias=True) 1 4 torch.Size([100])
sorted candidates ['lay4_32', 'lay4_54', 'lay4_84', 'lay4_56', 'lay4_8', 'lay4_74', 'lay4_64', 'lay4_45', 'lay4_63', 'lay4_40', 'lay4_95', 'lay4_33', 'lay4_26', 'lay4_55', 'lay4_51', 'lay4_75', 'lay4_85', 'lay4_76', 'lay4_7', 'lay4_37', 'lay4_81', 'lay4_89', 'lay4_20', 'lay4_49', 'lay4_9', 'lay4_77', 'lay4_80', 'lay4_38', 'lay4_52', 'lay4_15', 'lay4_12', 'lay4_30', 'lay4_61', 'lay4_58', 'lay4_41', 'lay4_28', 'lay4_23', 'lay4_3', 'lay4_1', 'lay4_2', 'lay4_14', 'lay4_68', 'lay4_19', 'lay4_99', 'lay4_70', 'lay4_67', 'lay4_79'] filter: 1.0
Solving MIP for lay4_64, [-1.497612476348877,0.01712280511856079]=>[-1.497612476348877,-1e-05] (-1,-1; 15,-1), time: 0.2950s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_54, [-0.01834091544151306,1.2850501537322998]=>[1e-05,1.2850501537322998] (15,-1; -1,-1), time: 0.3662s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_51, [-1.4776906967163086,0.03983333706855774]=>[-1.4776906967163086,-1e-05] (-1,-1; 15,-1), time: 0.3876s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_33, [-1.683072566986084,0.009962677955627441]=>[-1.683072566986084,-1e-05] (-1,-1; 15,-1), time: 0.4003s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_74, [-0.1911602020263672,1.3487837314605713]=>[1e-05,1.3487837314605713] (15,-1; -1,-1), time: 0.4121s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_26, [-1.6078472137451172,0.005015730857849121]=>[-1.6078472137451172,-1e-05] (-1,-1; 15,-1), time: 0.4304s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_84, [-0.010902255773544312,1.7072384357452393]=>[1e-05,1.7072384357452393] (15,-1; -1,-1), time: 0.4562s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_63, [-0.16945472359657288,1.1107604503631592]=>[1e-05,1.1107604503631592] (15,-1; -1,-1), time: 0.5233s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_37, [-1.2499444484710693,0.10903739929199219]=>[-1.2499444484710693,-1e-05] (-1,-1; 15,-1), time: 0.3046s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_89, [-1.4536194801330566,0.010329186916351318]=>[-1.4536194801330566,-1e-05] (-1,-1; 15,-1), time: 0.3712s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_49, [-1.207350254058838,0.11945635080337524]=>[-1.207350254058838,-1e-05] (-1,-1; 15,-1), time: 0.3649s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_77, [-2.1876120567321777,0.0690661072731018]=>[-2.1876120567321777,-1e-05] (-1,-1; 15,-1), time: 0.2533s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_8, [-0.38378745317459106,0.9766632318496704]=>[-0.13664066375716277,0.7736032778231898] (2,-1; 2,-1), time: 1.4581s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_40, [-1.0231976509094238,0.5034101605415344]=>[-0.7593097293446562,0.2737686892878608] (2,-1; 2,-1), time: 1.5295s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_38, [-1.2290538549423218,0.12821346521377563]=>[-1.2290538549423218,-1e-05] (-1,-1; 15,-1), time: 0.4759s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_45, [-1.0524766445159912,0.24835175275802612]=>[-0.8182330979627898,0.010577208082282569] (2,-1; 2,-1), time: 2.2462s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_9, [-0.9883859157562256,0.21763166785240173]=>[-0.7552098898820003,0.020298848716648943] (2,-1; 2,-1), time: 1.8487s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_7, [-1.0597503185272217,0.4395363926887512]=>[-0.7954559752958197,0.23869736714847498] (2,-1; 2,-1), time: 2.2793s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_85, [-0.9221146106719971,0.5979132056236267]=>[-0.6099962189911872,0.38914131155152626] (2,-1; 2,-1), time: 2.4246s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_55, [-1.011295199394226,0.5880860090255737]=>[-0.7335457025119019,0.325443950957339] (2,-1; 2,-1), time: 2.7731s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_75, [-1.148986577987671,0.3770851492881775]=>[-0.8945081115664041,0.08236483089657012] (2,-1; 2,-1), time: 2.8075s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_32, [-0.9906705617904663,0.7563964128494263]=>[-0.7357074943142481,0.40404354452783875] (2,-1; 2,-1), time: 2.8200s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_81, [-1.4902675151824951,0.8378798365592957]=>[-1.241761985410237,0.3128195788344205] (2,-1; 2,-1), time: 2.4731s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_95, [-0.8708832263946533,1.0613462924957275]=>[-0.5895344329847193,0.7129916386526074] (2,-1; 2,-1), time: 3.0380s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_3, [-1.8068757057189941,0.09576132893562317]=>[-1.8068757057189941,-1e-05] (-1,-1; 15,-1), time: 0.3402s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_1, [-0.1180594265460968,1.2218588590621948]=>[1e-05,1.2218588590621948] (15,-1; -1,-1), time: 0.3621s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_52, [-0.458500474691391,1.1994194984436035]=>[-0.16473849598261137,0.9835448266571333] (2,-1; 2,-1), time: 2.2739s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_12, [-1.088196039199829,0.3690631687641144]=>[-0.8306906020381503,0.19587402567526407] (2,-1; 2,-1), time: 2.3069s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_76, [-1.088693618774414,0.31042176485061646]=>[-0.6939950101836149,0.17720651072055296] (2,-1; 2,-1), time: 3.5748s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_15, [-1.109146237373352,0.7243717908859253]=>[-0.8078734095705756,0.3294377799188823] (2,-1; 2,-1), time: 2.6292s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_61, [-2.0317001342773438,0.1721440851688385]=>[-1.5160774244466475,0.03945884167165354] (2,-1; 2,-1), time: 1.6479s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_56, [-0.810437798500061,0.32693639397621155]=>[-0.49037886579078105,0.122193711103399] (2,-1; 2,-1), time: 4.3049s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_20, [-1.0926311016082764,0.3391845226287842]=>[-0.6872992828218935,0.18079173195436193] (2,-1; 2,-1), time: 4.0882s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_80, [-0.37784916162490845,0.945014238357544]=>[-0.18581143206490686,0.5968087055679039] (2,-1; 2,-1), time: 3.8004s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_2, [-0.7321099042892456,1.0053895711898804]=>[-0.47264962073553535,0.6392490408368986] (2,-1; 2,-1), time: 2.0936s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_68, [-1.255540132522583,0.43152958154678345]=>[-1.0738685346366956,0.06452908277801318] (2,-1; 2,-1), time: 2.2925s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_28, [-0.5995407104492188,1.052431583404541]=>[-0.29477137551552635,0.7904143290672516] (2,-1; 2,-1), time: 2.9389s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_23, [-0.8232841491699219,0.6922702789306641]=>[-0.4135302447653451,0.544590717034783] (2,-1; 2,-1), time: 2.9181s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_41, [-0.9617838859558105,0.4175558090209961]=>[-0.7627376052596286,0.08535142836052582] (2,-1; 2,-1), time: 3.2200s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_19, [-0.6356183290481567,1.125065565109253]=>[-0.3372995218946211,0.8740292900636827] (2,-1; 2,-1), time: 2.2076s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_70, [-1.5059516429901123,0.3301336169242859]=>[-1.1956637762705395,0.055590238750676785] (2,-1; 2,-1), time: 2.0989s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_14, [-1.1731374263763428,0.3338202238082886]=>[-0.8195187697875165,0.19984271423794667] (2,-1; 2,-1), time: 2.9024s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_30, [-1.2851285934448242,0.24987083673477173]=>[-0.8759640720849414,0.03838864073157908] (2,-1; 2,-1), time: 4.0011s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_99, [-0.5681153535842896,1.1526577472686768]=>[-0.20493789649568891,0.859146201194683] (2,-1; 2,-1), time: 2.9234s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_58, [-0.37928658723831177,1.0271822214126587]=>[-0.13360202267655621,0.6938697217728714] (2,-1; 2,-1), time: 4.1567s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_79, [-0.9856913089752197,0.8501263856887817]=>[-0.5646463350097409,0.6106915792001872] (2,-1; 2,-1), time: 2.8607s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_67, [-0.44358471035957336,1.0241247415542603]=>[-0.22579391817286065,0.668383058192259] (2,-1; 2,-1), time: 3.1196s, #vars: 1057, #constrs: 308, improved: True
MIP improved 47 nodes out of 47 unstable nodes, lb improved 10.03395938873291, ub improved 8.993770599365234, time 7.7197
maximum relu layer improved by MIP so far 1 last_relu_layer_refined: True
Linear(in_features=100, out_features=100, bias=True) 2 6 torch.Size([100])
sorted candidates ['lay6_64', 'lay6_28', 'lay6_4', 'lay6_57', 'lay6_6', 'lay6_84', 'lay6_43', 'lay6_56', 'lay6_48', 'lay6_36', 'lay6_24', 'lay6_46', 'lay6_65', 'lay6_32', 'lay6_85', 'lay6_17', 'lay6_27', 'lay6_83', 'lay6_99', 'lay6_18', 'lay6_61', 'lay6_0', 'lay6_35', 'lay6_29', 'lay6_25', 'lay6_92', 'lay6_62', 'lay6_52', 'lay6_14', 'lay6_71', 'lay6_88', 'lay6_12', 'lay6_13', 'lay6_81', 'lay6_53', 'lay6_67', 'lay6_42', 'lay6_40', 'lay6_30', 'lay6_21', 'lay6_8', 'lay6_59', 'lay6_37', 'lay6_90', 'lay6_23', 'lay6_22', 'lay6_72', 'lay6_16', 'lay6_45', 'lay6_91', 'lay6_2', 'lay6_44', 'lay6_31', 'lay6_97', 'lay6_80', 'lay6_96', 'lay6_89', 'lay6_69', 'lay6_73', 'lay6_75', 'lay6_34', 'lay6_3', 'lay6_54', 'lay6_98', 'lay6_51', 'lay6_79'] filter: 1.0
Run alpha-CROWN after refining layer 4 and relu idx 1
0 /21 torch.Size([1, 100])
1 /23 torch.Size([1, 100])
Solving MIP for lay6_43, [-0.16266527771949768,1.3549267053604126]=>[1e-05,1.3549267053604126] (15,-1; -1,-1), time: 0.1760s, #vars: 1221, #constrs: 504, improved: True
Solving MIP for lay6_84, [-0.10784578323364258,1.5361840724945068]=>[1e-05,1.5361840724945068] (15,-1; -1,-1), time: 0.1782s, #vars: 1221, #constrs: 504, improved: True
Solving MIP for lay6_65, [-0.30228954553604126,1.3557178974151611]=>[1e-05,1.3557178974151611] (15,-1; -1,-1), time: 0.1821s, #vars: 1221, #constrs: 504, improved: True
Solving MIP for lay6_56, [-0.06347519159317017,1.6354615688323975]=>[1e-05,1.6354615688323975] (15,-1; -1,-1), time: 0.1872s, #vars: 1221, #constrs: 504, improved: True
Solving MIP for lay6_28, [-0.03404116630554199,1.978156328201294]=>[1e-05,1.978156328201294] (15,-1; -1,-1), time: 0.2484s, #vars: 1221, #constrs: 504, improved: True

all verified at 4th iter
best_l after optimization: -19.301979064941406 with beta sum per layer: []
optimal alpha/beta time: 0.28400707244873047
alpha-CROWN with intermediate bounds by MIP: tensor([[5.4269, 0.3847, 0.1890, 1.5091, 3.3639, 5.1928, 1.0638, 0.5077, 1.6641]],
       device='cuda:0', grad_fn=<AsStridedBackward0>) None
min of alpha-CROWN bounds 0.18895530700683594>=0, verified!
MIP finished with 9.65005087852478s
Run final alpha-CROWN after MIP solving on layer 5 and relu idx 2
0 /21 torch.Size([1, 100])
1 /23 torch.Size([1, 100])

all verified at 0th iter
best_l after optimization: -19.301979064941406 with beta sum per layer: []
optimal alpha/beta time: 0.027304887771606445
alpha-CROWN with intermediate bounds improved by MIP: tensor([[5.4269, 0.3847, 0.1890, 1.5091, 3.3639, 5.1928, 1.0638, 0.5077, 1.6641]],
       device='cuda:0', grad_fn=<AsStridedBackward0>) None
refined global lb: tensor([[5.4269, 0.0000, 0.3847, 0.1890, 1.5091, 3.3639, 5.1928, 1.0638, 0.5077,
         1.6641]], device='cuda:0') min: tensor(0., device='cuda:0')
Verified safe using alpha-CROWN with MIP improved bounds!
time threshold left for bab: 284.388712644577
bab-refine verified success!
[[14.          0.          0.          5.88054967  0.         -1.        ]
 [14.          0.          0.          9.73074341  0.         -2.        ]]
final verified acc: 100.0%[1]
Total verification count: 1 total verified: 1
mean time [total:1]: 15.611293077468872
mean time [cnt:1]: 15.611293077468872
