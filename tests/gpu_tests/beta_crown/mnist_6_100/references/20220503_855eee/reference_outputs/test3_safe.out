Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab-refine
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: mnist_6_100_nat.pth
  name: mnist_6_100
data:
  start: 14
  end: 15
  num_outputs: 10
  mean: [0.0]
  std: [1.0]
  pkl_path: null
  dataset: MNIST_ERAN_UN
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.026
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 1024
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: 16
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 900
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: after
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:58:20 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Flatten()
  (1): Linear(in_features=784, out_features=100, bias=True)
  (2): ReLU()
  (3): Linear(in_features=100, out_features=100, bias=True)
  (4): ReLU()
  (5): Linear(in_features=100, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=100, bias=True)
  (8): ReLU()
  (9): Linear(in_features=100, out_features=100, bias=True)
  (10): ReLU()
  (11): Linear(in_features=100, out_features=10, bias=True)
)
############################
Sampled data loaded. No normalization used!
Shape: torch.Size([1000, 1, 28, 28]) torch.Size([1000]) torch.Size([1000])
X range: tensor(1.) tensor(0.) tensor(0.1223)
Note runnerup label is empty here!
############################
epsilon after preprocessing: tensor([[[[0.0260]]]]), data_max = tensor([[[[1.]]]]), data_min = tensor([[[[0.]]]])
Task length: 1
saving results to Verified_ret_[mnist_6_100]_start=14_end=15_iter=20_b=1024_timeout=900_branching=kfsb-max-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=after.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 14 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 1, correct label 1, image norm 63.525489807128906, logits tensor([-5.0631, 13.1667,  0.7939, -2.8103,  0.4855, -3.1720, -2.6758,  0.8242,
         1.9934, -2.4615], device='cuda:0', grad_fn=<SelectBackward>)
Model prediction is: tensor([[-5.0631, 13.1667,  0.7939, -2.8103,  0.4855, -3.1720, -2.6758,  0.8242,
          1.9934, -2.4615]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ -4.6808, -10.2404, -11.7597,  -8.3149,  -7.6906,  -3.7429,  -8.0721,
          -8.8788, -10.2175]], device='cuda:0') None
best_l after optimization: 39.037384033203125 with beta sum per layer: []
alpha/beta optimization time: 8.211575508117676
initial alpha-CROWN bounds: tensor([[-0.9930, -5.8539, -6.8840, -4.6689, -3.6314, -0.9617, -4.7828, -5.2511,
         -6.0107]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-6.8840, device='cuda:0', grad_fn=<MinBackward1>)
##### PGD attack: True label: 1, Tested against: ['all'] ######
pgd prediction: tensor([-3.7037,  9.4653,  0.4722, -1.4019,  0.3691, -2.2786, -2.4558,  0.7045,
         1.8111, -1.4817], device='cuda:0', grad_fn=<SqueezeBackward1>)
attack margin tensor([13.1690,     inf,  8.9930, 10.8672,  9.0962, 11.7439, 11.9211,  8.7608,
         7.6542, 10.9470], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Sorted order for labels to verify: [8, 7, 2, 4, 3, 9, 5, 6, 0, 1]
Start solving intermediate bounds with MIP...
alpha-CROWN optimizable variables initialized.
Academic license - for non-commercial use only - expires 2023-03-23
Using license file /home/zhouxingshi/gurobi.lic
mip_multi_proc: 16, mip_threads: 1,total threads used: 16, mip_perneuron_refine_timeout: 15
[total time budget for MIP: 712.8135616302491]

Linear(in_features=784, out_features=100, bias=True) 0 2 torch.Size([100])
Linear(in_features=100, out_features=100, bias=True) 1 4 torch.Size([100])
sorted candidates ['lay4_79', 'lay4_67', 'lay4_70', 'lay4_99', 'lay4_19', 'lay4_68', 'lay4_14', 'lay4_2', 'lay4_1', 'lay4_3', 'lay4_23', 'lay4_28', 'lay4_41', 'lay4_58', 'lay4_61', 'lay4_30', 'lay4_12', 'lay4_15', 'lay4_52', 'lay4_38', 'lay4_80', 'lay4_77', 'lay4_9', 'lay4_49', 'lay4_20', 'lay4_89', 'lay4_81', 'lay4_37', 'lay4_7', 'lay4_76', 'lay4_85', 'lay4_75', 'lay4_51', 'lay4_55', 'lay4_26', 'lay4_33', 'lay4_95', 'lay4_40', 'lay4_63', 'lay4_45', 'lay4_64', 'lay4_74', 'lay4_8', 'lay4_56', 'lay4_84', 'lay4_54', 'lay4_32'] filter: 1.0
/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:579: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(eps_temp).reshape(1, -1, 1, 1)
Solving MIP for lay4_3, [-1.8068758249282837,0.0957612693309784]=>[-1.8068758249282837,-1e-05] (-1,-1; 15,-1), time: 0.4655s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_1, [-0.11805934458971024,1.2218587398529053]=>[1e-05,1.2218587398529053] (15,-1; -1,-1), time: 0.5216s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_61, [-2.0317001342773438,0.17214404046535492]=>[-1.521718771349273,0.03945884167165358] (2,-1; 2,-1), time: 1.6320s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_70, [-1.5059515237808228,0.3301336169242859]=>[-1.1961506043709982,0.05910587769584938] (2,-1; 2,-1), time: 1.9424s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_19, [-0.6356183290481567,1.1250656843185425]=>[-0.337453780813731,0.8762898875678236] (2,-1; 2,-1), time: 2.0460s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_38, [-1.2290538549423218,0.12821346521377563]=>[-1.2290538549423218,-1e-05] (-1,-1; 15,-1), time: 0.5088s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_77, [-2.1876120567321777,0.06906615197658539]=>[-2.1876120567321777,-1e-05] (-1,-1; 15,-1), time: 0.2914s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_12, [-1.088196039199829,0.36906319856643677]=>[-0.8284110581252891,0.19718549927473636] (2,-1; 2,-1), time: 2.5007s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_68, [-1.255540132522583,0.43152952194213867]=>[-1.0713779235917849,0.0650144445420899] (2,-1; 2,-1), time: 2.9848s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_23, [-0.8232841491699219,0.6922702789306641]=>[-0.4122817267995714,0.5437833320368665] (2,-1; 2,-1), time: 3.0196s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_99, [-0.5681152939796448,1.1526577472686768]=>[-0.1995393174028343,0.8631213679730645] (2,-1; 2,-1), time: 3.1130s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_89, [-1.4536192417144775,0.01032915711402893]=>[-1.4536192417144775,-1e-05] (-1,-1; 15,-1), time: 0.3471s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_41, [-0.9617838859558105,0.41755589842796326]=>[-0.7680999435271262,0.08163038651589971] (2,-1; 2,-1), time: 3.4108s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_49, [-1.207350254058838,0.11945632100105286]=>[-1.207350254058838,-1e-05] (-1,-1; 15,-1), time: 0.4442s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_2, [-0.7321099042892456,1.0053895711898804]=>[-0.4728601998614898,0.6336920291368007] (2,-1; 2,-1), time: 3.4743s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_79, [-0.9856913089752197,0.8501263856887817]=>[-0.5659537273112737,0.6025736799798271] (2,-1; 2,-1), time: 3.4945s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_14, [-1.1731374263763428,0.3338202238082886]=>[-0.8200762100535591,0.1999935662749016] (2,-1; 2,-1), time: 3.5462s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_37, [-1.2499444484710693,0.10903742909431458]=>[-1.2499444484710693,-1e-05] (-1,-1; 15,-1), time: 0.2969s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_28, [-0.599540650844574,1.052431583404541]=>[-0.29366149959986126,0.7934389941286886] (2,-1; 2,-1), time: 3.7081s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_58, [-0.3792865574359894,1.0271822214126587]=>[-0.13466068489691366,0.6927060945286815] (2,-1; 2,-1), time: 3.8408s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_51, [-1.4776908159255981,0.03983333706855774]=>[-1.4776908159255981,-1e-05] (-1,-1; 15,-1), time: 0.4040s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_26, [-1.6078472137451172,0.005015730857849121]=>[-1.6078472137451172,-1e-05] (-1,-1; 15,-1), time: 0.4120s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_67, [-0.4435846507549286,1.0241247415542603]=>[-0.22189217781252765,0.6654701161154141] (2,-1; 2,-1), time: 4.1420s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_33, [-1.683072566986084,0.009962677955627441]=>[-1.683072566986084,-1e-05] (-1,-1; 15,-1), time: 0.3373s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_15, [-1.1091463565826416,0.7243717908859253]=>[-0.8034201681281129,0.32761433178998145] (2,-1; 2,-1), time: 3.7603s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_52, [-0.4585004448890686,1.1994194984436035]=>[-0.15910709240724966,0.9858330877508286] (2,-1; 2,-1), time: 2.6711s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_64, [-1.497612476348877,0.01712281070649624]=>[-1.497612476348877,-1e-05] (-1,-1; 15,-1), time: 0.3409s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_63, [-0.16945481300354004,1.1107604503631592]=>[1e-05,1.1107604503631592] (15,-1; -1,-1), time: 0.5340s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_74, [-0.1911601424217224,1.3487837314605713]=>[1e-05,1.3487837314605713] (15,-1; -1,-1), time: 0.4256s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_9, [-0.9883859157562256,0.21763163805007935]=>[-0.7578175308368091,0.015004887764121311] (2,-1; 2,-1), time: 2.3786s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_84, [-0.010902196168899536,1.7072384357452393]=>[1e-05,1.7072384357452393] (15,-1; -1,-1), time: 0.4250s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_30, [-1.2851285934448242,0.24987077713012695]=>[-0.8779948592623771,0.037862770803431964] (2,-1; 2,-1), time: 5.2936s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_81, [-1.4902673959732056,0.8378798365592957]=>[-1.2412049429395924,0.312931535500124] (2,-1; 2,-1), time: 2.3809s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_54, [-0.01834094524383545,1.2850501537322998]=>[1e-05,1.2850501537322998] (15,-1; -1,-1), time: 0.4090s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_75, [-1.1489863395690918,0.3770851492881775]=>[-0.8947108144950039,0.08210467296647178] (2,-1; 2,-1), time: 2.1698s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_40, [-1.0231975317001343,0.5034101009368896]=>[-0.7593097284250115,0.27323162458467976] (2,-1; 2,-1), time: 1.6746s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_55, [-1.011295199394226,0.5880858898162842]=>[-0.7306720245463689,0.3271111589015893] (2,-1; 2,-1), time: 2.2113s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_45, [-1.0524765253067017,0.24835169315338135]=>[-0.8253902308238235,0.011756342073399428] (2,-1; 2,-1), time: 1.7190s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_80, [-0.37784919142723083,0.945014238357544]=>[-0.18574130407356823,0.5979298112924736] (2,-1; 2,-1), time: 3.8657s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_7, [-1.0597503185272217,0.4395364224910736]=>[-0.798963403344609,0.23927826609403835] (2,-1; 2,-1), time: 2.6353s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_85, [-0.9221145510673523,0.5979132652282715]=>[-0.6108967690048702,0.38368109136609496] (2,-1; 2,-1), time: 2.6438s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_95, [-0.8708832859992981,1.0613462924957275]=>[-0.5875512026404217,0.7103463539182601] (2,-1; 2,-1), time: 2.8694s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_8, [-0.3837873935699463,0.9766632318496704]=>[-0.12925645172928044,0.7708877010121951] (2,-1; 2,-1), time: 2.2920s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_76, [-1.088693618774414,0.31042176485061646]=>[-0.6984405529923938,0.17737171548831798] (2,-1; 2,-1), time: 4.0822s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_32, [-0.9906705617904663,0.7563963532447815]=>[-0.7309847289137922,0.39711360540069257] (2,-1; 2,-1), time: 2.4444s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_20, [-1.0926311016082764,0.3391844630241394]=>[-0.6875446118104122,0.17767102336202734] (2,-1; 2,-1), time: 4.6211s, #vars: 1057, #constrs: 308, improved: True
Solving MIP for lay4_56, [-0.8104377388954163,0.32693642377853394]=>[-0.4910279200223789,0.12219371094939024] (2,-1; 2,-1), time: 3.8280s, #vars: 1057, #constrs: 308, improved: True
MIP improved 47 nodes out of 47 unstable nodes, lb improved 10.041534423828125, ub improved 9.02352237701416, time 9.1039
maximum relu layer improved by MIP so far 1 last_relu_layer_refined: True
Linear(in_features=100, out_features=100, bias=True) 2 6 torch.Size([100])
sorted candidates ['lay6_79', 'lay6_51', 'lay6_98', 'lay6_54', 'lay6_3', 'lay6_34', 'lay6_75', 'lay6_73', 'lay6_69', 'lay6_89', 'lay6_96', 'lay6_80', 'lay6_97', 'lay6_31', 'lay6_44', 'lay6_2', 'lay6_91', 'lay6_45', 'lay6_16', 'lay6_72', 'lay6_22', 'lay6_23', 'lay6_90', 'lay6_37', 'lay6_59', 'lay6_8', 'lay6_21', 'lay6_30', 'lay6_40', 'lay6_42', 'lay6_67', 'lay6_53', 'lay6_81', 'lay6_13', 'lay6_12', 'lay6_88', 'lay6_71', 'lay6_14', 'lay6_52', 'lay6_62', 'lay6_92', 'lay6_25', 'lay6_29', 'lay6_35', 'lay6_0', 'lay6_61', 'lay6_18', 'lay6_99', 'lay6_83', 'lay6_27', 'lay6_17', 'lay6_85', 'lay6_32', 'lay6_65', 'lay6_46', 'lay6_24', 'lay6_36', 'lay6_48', 'lay6_56', 'lay6_43', 'lay6_84', 'lay6_6', 'lay6_57', 'lay6_4', 'lay6_28', 'lay6_64'] filter: 1.0
Run alpha-CROWN after refining layer 4 and relu idx 1
0 /21 torch.Size([1, 100])
1 /23 torch.Size([1, 100])

all verified at 3th iter
best_l after optimization: -18.00567626953125 with beta sum per layer: []
alpha/beta optimization time: 0.29593873023986816
alpha-CROWN with intermediate bounds by MIP: tensor([[5.3066e+00, 2.2678e-01, 4.9887e-03, 1.3701e+00, 3.2117e+00, 5.0730e+00,
         9.3352e-01, 3.7613e-01, 1.5030e+00]], device='cuda:0',
       grad_fn=<AsStridedBackward>) None
min of alpha-CROWN bounds 0.004988670349121094>=0, verified!
MIP finished with 11.362895250320435s
Run final alpha-CROWN after MIP solving on layer 5 and relu idx 2
0 /21 torch.Size([1, 100])
1 /23 torch.Size([1, 100])

all verified at 0th iter
best_l after optimization: -18.00567626953125 with beta sum per layer: []
alpha/beta optimization time: 0.0363614559173584
alpha-CROWN with intermediate bounds improved by MIP: tensor([[5.3066e+00, 2.2678e-01, 4.9887e-03, 1.3701e+00, 3.2117e+00, 5.0730e+00,
         9.3352e-01, 3.7613e-01, 1.5030e+00]], device='cuda:0',
       grad_fn=<AsStridedBackward>) None
refined global lb: tensor([[5.3066e+00, 0.0000e+00, 2.2678e-01, 4.9887e-03, 1.3701e+00, 3.2117e+00,
         5.0730e+00, 9.3352e-01, 3.7613e-01, 1.5030e+00]], device='cuda:0') min: tensor(0., device='cuda:0')
Verified safe using alpha-CROWN with MIP improved bounds!
time threshold left for bab: 879.5833878517151
Result: image 14 verification success (with mip refine)!
Wall time: 21.087066888809204

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 1): [14]
verification failure idx (total 0): []
final verified acc: 100.0%[1]
verifier is called on 1 examples.
total verified: 1
mean time [cnt:1] (excluding attack success): 20.416616201400757
