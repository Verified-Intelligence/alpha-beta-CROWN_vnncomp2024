Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab-refine
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: mnist_6_100_nat.pth
  name: mnist_6_100
data:
  start: 20
  end: 21
  num_outputs: 10
  mean: [0.0]
  std: [1.0]
  pkl_path: null
  dataset: MNIST_ERAN_UN
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.026
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 1024
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: 16
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 900
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:58:47 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Flatten()
  (1): Linear(in_features=784, out_features=100, bias=True)
  (2): ReLU()
  (3): Linear(in_features=100, out_features=100, bias=True)
  (4): ReLU()
  (5): Linear(in_features=100, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=100, bias=True)
  (8): ReLU()
  (9): Linear(in_features=100, out_features=100, bias=True)
  (10): ReLU()
  (11): Linear(in_features=100, out_features=10, bias=True)
)
############################
Sampled data loaded. No normalization used!
Shape: torch.Size([1000, 1, 28, 28]) torch.Size([1000]) torch.Size([1000])
X range: tensor(1.) tensor(0.) tensor(0.1223)
Note runnerup label is empty here!
############################
epsilon after preprocessing: tensor([[[[0.0260]]]]), data_max = tensor([[[[1.]]]]), data_min = tensor([[[[0.]]]])
Task length: 1
saving results to Verified_ret_[mnist_6_100]_start=20_end=21_iter=20_b=1024_timeout=900_branching=kfsb-max-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 20 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 9, correct label 9, image norm 108.07843017578125, logits tensor([-1.3886, -0.7100, -2.2255, -0.0764,  1.1890, -0.3403, -4.0691,  2.6444,
        -0.5482,  6.5574], device='cuda:0', grad_fn=<SelectBackward>)
Model prediction is: tensor([[-1.3886, -0.7100, -2.2255, -0.0764,  1.1890, -0.3403, -4.0691,  2.6444,
         -0.5482,  6.5574]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-29.2376, -28.0748, -31.4882, -28.3599, -20.1338, -27.8897, -28.6254,
         -28.3173, -26.2863]], device='cuda:0') None
best_l after optimization: 118.8796157836914 with beta sum per layer: []
alpha/beta optimization time: 7.741761684417725
initial alpha-CROWN bounds: tensor([[-13.5007, -13.5761, -15.3914, -14.1209,  -9.6594, -13.8576, -12.5532,
         -13.0459, -13.1745]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-15.3914, device='cuda:0', grad_fn=<MinBackward1>)
Start solving intermediate bounds with MIP...
alpha-CROWN optimizable variables initialized.
Academic license - for non-commercial use only - expires 2023-03-23
Using license file /home/zhouxingshi/gurobi.lic
mip_multi_proc: 16, mip_threads: 1,total threads used: 16, mip_perneuron_refine_timeout: 15
[total time budget for MIP: 713.1999961853028]

Linear(in_features=784, out_features=100, bias=True) 0 2 torch.Size([100])
Linear(in_features=100, out_features=100, bias=True) 1 4 torch.Size([100])
sorted candidates ['lay4_14', 'lay4_15', 'lay4_16', 'lay4_18', 'lay4_54', 'lay4_80', 'lay4_60', 'lay4_79', 'lay4_26', 'lay4_42', 'lay4_59', 'lay4_9', 'lay4_66', 'lay4_63', 'lay4_50', 'lay4_49', 'lay4_68', 'lay4_30', 'lay4_52', 'lay4_64', 'lay4_62', 'lay4_7', 'lay4_22', 'lay4_69', 'lay4_24', 'lay4_36', 'lay4_55', 'lay4_35', 'lay4_17', 'lay4_93', 'lay4_5', 'lay4_75', 'lay4_53', 'lay4_95', 'lay4_34', 'lay4_94', 'lay4_48', 'lay4_86', 'lay4_33', 'lay4_2', 'lay4_29', 'lay4_25', 'lay4_70', 'lay4_56', 'lay4_71', 'lay4_81', 'lay4_0', 'lay4_51', 'lay4_28', 'lay4_98', 'lay4_12', 'lay4_57', 'lay4_43', 'lay4_83'] filter: 1.0
/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:579: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(eps_temp).reshape(1, -1, 1, 1)
Solving MIP for lay4_50, [-1.6092109680175781,0.11213117837905884]=>[-1.6092109680175781,-1e-05] (-1,-1; 15,-1), time: 0.2109s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_9, [-1.0645846128463745,0.10176470875740051]=>[-1.0645846128463745,-1e-05] (-1,-1; 15,-1), time: 0.2202s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_59, [-1.5643541812896729,0.1303337663412094]=>[-1.5643541812896729,-1e-05] (-1,-1; 15,-1), time: 0.2389s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_18, [-1.2776954174041748,0.15768921375274658]=>[-1.2776954174041748,-1e-05] (-1,-1; 15,-1), time: 0.3053s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_66, [-1.3235785961151123,0.10866168141365051]=>[-1.3235785961151123,-1e-05] (-1,-1; 15,-1), time: 0.3456s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_62, [-1.2734403610229492,0.06848803162574768]=>[-1.2734403610229492,-1e-05] (-1,-1; 15,-1), time: 0.2373s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_64, [-1.0472947359085083,0.14740055799484253]=>[-1.0472947359085083,-1e-05] (-1,-1; 15,-1), time: 0.3038s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_22, [-1.3863441944122314,0.10048112273216248]=>[-1.3863441944122314,-1e-05] (-1,-1; 15,-1), time: 0.2472s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_26, [-1.1031877994537354,0.7722219228744507]=>[-0.7696241474101474,0.5303496318453211] (2,-1; 2,-1), time: 1.4656s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_30, [-0.944024384021759,0.4456638991832733]=>[-0.7585649909794696,0.13799872404737312] (2,-1; 2,-1), time: 1.7816s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_54, [-0.7970568537712097,0.5278089046478271]=>[-0.4778543051910265,0.3361875025122932] (2,-1; 2,-1), time: 2.0435s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_16, [-0.8452985286712646,0.47220951318740845]=>[-0.575878138990139,0.2681945035552952] (2,-1; 2,-1), time: 2.0965s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_55, [-1.544124722480774,0.03432360291481018]=>[-1.544124722480774,-1e-05] (-1,-1; 15,-1), time: 0.1849s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_15, [-0.9920099973678589,1.2529966831207275]=>[-0.5889267344809795,0.8337104756832368] (2,-1; 2,-1), time: 2.2847s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_14, [-1.156355381011963,0.37445852160453796]=>[-0.9095327520011239,0.11915132759154651] (2,-1; 2,-1), time: 2.3519s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_52, [-0.7920871376991272,0.26067185401916504]=>[-0.5964429726963272,0.08690561389764445] (2,-1; 2,-1), time: 2.2985s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_68, [-1.0690224170684814,0.4109511077404022]=>[-0.7939250666898471,0.17538310878839927] (2,-1; 2,-1), time: 2.3806s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_53, [-0.07320677489042282,1.4670588970184326]=>[1e-05,1.4670588970184326] (15,-1; -1,-1), time: 0.2988s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_80, [-0.6018922328948975,0.5441042184829712]=>[-0.2792963553751446,0.448275797355728] (2,-1; 2,-1), time: 3.0474s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_63, [-0.6167105436325073,0.7303063869476318]=>[-0.3391977313979052,0.4851070291344351] (2,-1; 2,-1), time: 3.1352s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_69, [-0.7140456438064575,0.807601273059845]=>[-0.5395725700521565,0.4537474868645147] (2,-1; 2,-1), time: 2.2742s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_49, [-0.6870503425598145,0.785720944404602]=>[-0.36173855674397254,0.5196015000536284] (2,-1; 2,-1), time: 3.1738s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_48, [-0.1413612961769104,1.6460789442062378]=>[1e-05,1.6460789442062378] (15,-1; -1,-1), time: 0.2146s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_34, [-0.1725013554096222,1.3360915184020996]=>[1e-05,1.3360915184020996] (15,-1; -1,-1), time: 0.3713s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_42, [-1.013458490371704,0.2359849214553833]=>[-0.6743913484526861,0.09348347099967892] (2,-1; 2,-1), time: 3.4670s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_79, [-1.0849652290344238,0.5434386730194092]=>[-0.7534719434406781,0.2571393766962508] (2,-1; 2,-1), time: 3.5134s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_60, [-0.9640235304832458,0.21469174325466156]=>[-0.6261957532689637,0.053415206825060575] (2,-1; 2,-1), time: 3.6908s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_25, [-1.3733474016189575,0.05430161952972412]=>[-1.3733474016189575,-1e-05] (-1,-1; 15,-1), time: 0.2594s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_17, [-1.1613965034484863,0.47287675738334656]=>[-0.9103225295433012,0.20323870313885914] (2,-1; 2,-1), time: 1.6397s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_56, [-0.13027605414390564,1.096127986907959]=>[1e-05,1.096127986907959] (15,-1; -1,-1), time: 0.2348s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_36, [-0.7696734666824341,1.0295743942260742]=>[-0.47044245514784205,0.7017727131960779] (2,-1; 2,-1), time: 2.0232s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_5, [-0.525271475315094,1.8416904211044312]=>[-0.057112375731236814,1.5291466280785928] (2,-1; 2,-1), time: 1.6796s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_75, [-0.3881886601448059,1.1661344766616821]=>[-0.10025338964684395,0.8929877190478757] (2,-1; 2,-1), time: 1.7121s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_0, [-1.3655152320861816,0.0940815806388855]=>[-1.3655152320861816,-1e-05] (-1,-1; 15,-1), time: 0.2551s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_24, [-0.7291580438613892,0.4432515501976013]=>[-0.5101162316069727,0.1883881140651479] (2,-1; 2,-1), time: 3.0548s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_28, [-0.09669560194015503,1.663663387298584]=>[1e-05,1.663663387298584] (15,-1; -1,-1), time: 0.2644s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_2, [-0.7149951457977295,0.7050505876541138]=>[-0.43217667081831534,0.5137133156087257] (2,-1; 2,-1), time: 1.2774s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_57, [-1.631080150604248,0.14694565534591675]=>[-1.631080150604248,-1e-05] (-1,-1; 15,-1), time: 0.2215s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_7, [-0.3380987048149109,0.5067189335823059]=>[-0.07793420400210514,0.39509860648666095] (2,-1; 2,-1), time: 4.1744s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_12, [-0.022828876972198486,1.1324342489242554]=>[1e-05,1.1324342489242554] (15,-1; -1,-1), time: 0.2430s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_95, [-1.0849233865737915,0.7154898643493652]=>[-0.7786717792815598,0.36735704403558994] (2,-1; 2,-1), time: 1.8756s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_35, [-0.38219237327575684,1.494396448135376]=>[-0.061497853726256935,1.1832219028769584] (2,-1; 2,-1), time: 2.8614s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_33, [-0.406345933675766,1.4576785564422607]=>[0.021302716847535062,1.4576785564422607] (2,-1; -1,-1), time: 1.9600s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_93, [-0.9447112083435059,0.66164231300354]=>[-0.6657958334917552,0.26294704052975837] (2,-1; 2,-1), time: 3.4129s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_94, [-0.4882250726222992,0.8564285635948181]=>[-0.18770251831618004,0.6440886107916025] (2,-1; 2,-1), time: 2.5824s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_86, [-0.37698787450790405,0.6419070959091187]=>[-0.19707165056158493,0.40755900537495054] (2,-1; 2,-1), time: 2.6455s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_98, [-1.0352284908294678,0.23868747055530548]=>[-1.0352284908294678,-1e-05] (-1,-1; 15,-1), time: 1.5582s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_29, [-0.9653702974319458,0.5792795419692993]=>[-0.5921181706621177,0.3964053890468654] (2,-1; 2,-1), time: 2.4113s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_83, [-0.9242798089981079,0.9834696650505066]=>[-0.7193715679734815,0.6049664459792065] (2,-1; 2,-1), time: 1.3058s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_70, [-0.8920994997024536,0.5380619764328003]=>[-0.6459961138117836,0.25909403377576407] (2,-1; 2,-1), time: 2.8569s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_43, [-0.8951679468154907,1.2331902980804443]=>[-0.5446957984566582,0.8435650451211364] (2,-1; 2,-1), time: 1.9454s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_71, [-0.7590311169624329,0.4315871298313141]=>[-0.4145709951404497,0.2607860532956813] (2,-1; 2,-1), time: 2.8242s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_51, [-0.5063337683677673,0.8887364864349365]=>[-0.28500074686819155,0.5816687546800304] (2,-1; 2,-1), time: 2.8474s, #vars: 1045, #constrs: 290, improved: True
Solving MIP for lay4_81, [-1.4761614799499512,0.8499495387077332]=>[-0.7988107493326486,0.453235046622746] (2,-1; 2,-1), time: 3.8041s, #vars: 1045, #constrs: 290, improved: True
MIP improved 54 nodes out of 54 unstable nodes, lb improved 11.273759841918945, ub improved 10.42579460144043, time 8.5076
maximum relu layer improved by MIP so far 1 last_relu_layer_refined: True
Linear(in_features=100, out_features=100, bias=True) 2 6 torch.Size([100])
sorted candidates ['lay6_7', 'lay6_99', 'lay6_2', 'lay6_22', 'lay6_73', 'lay6_79', 'lay6_10', 'lay6_59', 'lay6_47', 'lay6_26', 'lay6_93', 'lay6_60', 'lay6_35', 'lay6_72', 'lay6_53', 'lay6_86', 'lay6_54', 'lay6_69', 'lay6_0', 'lay6_68', 'lay6_98', 'lay6_76', 'lay6_3', 'lay6_33', 'lay6_29', 'lay6_23', 'lay6_39', 'lay6_71', 'lay6_6', 'lay6_52', 'lay6_9', 'lay6_83', 'lay6_77', 'lay6_40', 'lay6_5', 'lay6_18', 'lay6_38', 'lay6_75', 'lay6_84', 'lay6_81', 'lay6_17', 'lay6_1', 'lay6_20', 'lay6_49', 'lay6_13', 'lay6_51', 'lay6_88', 'lay6_15', 'lay6_50', 'lay6_44', 'lay6_28', 'lay6_89', 'lay6_65', 'lay6_37', 'lay6_24', 'lay6_74', 'lay6_56', 'lay6_48', 'lay6_91', 'lay6_62', 'lay6_43', 'lay6_36', 'lay6_82', 'lay6_92', 'lay6_42', 'lay6_97', 'lay6_66', 'lay6_25', 'lay6_27', 'lay6_32', 'lay6_11', 'lay6_16', 'lay6_78', 'lay6_95', 'lay6_46', 'lay6_58', 'lay6_85', 'lay6_41', 'lay6_94', 'lay6_61', 'lay6_70', 'lay6_31', 'lay6_67', 'lay6_4', 'lay6_45', 'lay6_12', 'lay6_63', 'lay6_21', 'lay6_57', 'lay6_64', 'lay6_96'] filter: 1.0
Solving MIP for lay6_72, [-1.5138529539108276,0.12492743134498596]=>[-1.5138529539108276,-1e-05] (-1,-1; 15,-1), time: 0.2848s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_35, [-1.2880955934524536,0.275343120098114]=>[-1.2880955934524536,-1e-05] (-1,-1; 15,-1), time: 0.3873s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_73, [-1.6734538078308105,0.2427573800086975]=>[-1.6734538078308105,-1e-05] (-1,-1; 15,-1), time: 0.4838s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_0, [-1.790563941001892,0.1612418293952942]=>[-1.790563941001892,-1e-05] (-1,-1; 15,-1), time: 0.1683s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_54, [-1.7492351531982422,0.3863849639892578]=>[-1.7492351531982422,-1e-05] (-1,-1; 15,-1), time: 0.5058s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_68, [-1.1629811525344849,0.18679919838905334]=>[-1.1629811525344849,-1e-05] (-1,-1; 15,-1), time: 0.1927s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_86, [-1.1473698616027832,0.23514893651008606]=>[-1.1473698616027832,-1e-05] (-1,-1; 15,-1), time: 2.2676s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_3, [-1.635454535484314,0.1281864047050476]=>[-1.635454535484314,-1e-05] (-1,-1; 15,-1), time: 0.1774s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_33, [-1.7044007778167725,0.16367661952972412]=>[-1.7044007778167725,-1e-05] (-1,-1; 15,-1), time: 0.1885s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_98, [-0.9132826924324036,1.162217378616333]=>[-0.3599475680963019,0.5380010938835922] (2,-1; 2,-1), time: 8.0500s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_23, [-1.4772230386734009,0.06869196891784668]=>[-1.4772230386734009,-1e-05] (-1,-1; 15,-1), time: 0.1536s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_53, [-0.8357540369033813,1.7766282558441162]=>[-0.18220140154937953,1.108673552892766] (2,-1; 2,-1), time: 9.6747s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_71, [-1.4400712251663208,0.3082190752029419]=>[-1.4400712251663208,-1e-05] (-1,-1; 15,-1), time: 0.8731s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_39, [-1.3122029304504395,0.581993579864502]=>[-1.3122029304504395,-1e-05] (-1,-1; 15,-1), time: 3.0861s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_76, [-1.0800575017929077,0.8717957735061646]=>[-0.5396516525135573,0.29718308579458796] (2,-1; 2,-1), time: 12.6651s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_6, [-1.0091370344161987,0.33955198526382446]=>[-1.0091370344161987,-1e-05] (-1,-1; 15,-1), time: 3.6975s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_22, [-1.1541619300842285,0.4683016836643219]=>[-0.5460310043192316,0.10936672257649359] (2,-1; 2,-1), time: 14.3946s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_77, [-1.6786079406738281,0.057878732681274414]=>[-1.6786079406738281,-1e-05] (-1,-1; 15,-1), time: 0.1476s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_10, [-0.8037761449813843,0.8394697308540344]=>[-0.30520845854481166,0.27878085501455047] (2,-1; 2,-1), time: 14.8941s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_79, [-1.6542842388153076,0.6354953050613403]=>[-0.9450388874173302,0.06250769821332099] (9,-1; 2,-1), time: 17.5515s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_26, [-0.7686712741851807,0.7882727384567261]=>[-0.2125927535254517,0.4278820060562338] (9,-1; 2,-1), time: 17.8779s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_38, [-1.2644290924072266,0.15039333701133728]=>[-1.2644290924072266,-1e-05] (-1,-1; 15,-1), time: 0.2115s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_69, [-1.4764827489852905,0.4540993869304657]=>[-0.8119293895359918,0.062227132285813745] (9,-1; 2,-1), time: 18.2065s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_60, [-1.0657116174697876,0.7877715229988098]=>[-0.41486980884500096,0.38815938387031396] (9,-1; 2,-1), time: 18.9829s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_84, [-1.474034309387207,0.2164413332939148]=>[-1.474034309387207,-1e-05] (-1,-1; 15,-1), time: 0.3803s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_2, [-1.5126694440841675,0.4856128990650177]=>[-0.811642374886115,0.016672924583783052] (9,-1; 2,-1), time: 20.3948s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_99, [-0.8118368983268738,0.8423510789871216]=>[-0.22321868238664175,0.37409040219714723] (9,-1; 2,-1), time: 20.6711s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_1, [-1.3346264362335205,0.23331701755523682]=>[-1.3346264362335205,-1e-05] (-1,-1; 15,-1), time: 0.5282s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_47, [-1.3165805339813232,0.4760769009590149]=>[-0.6577533348269835,0.043854044277440926] (9,-1; 2,-1), time: 20.9950s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_49, [-1.2934086322784424,0.34607207775115967]=>[-1.2934086322784424,-1e-05] (-1,-1; 15,-1), time: 0.4417s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_93, [-1.3070493936538696,0.9786747694015503]=>[-0.6192355138812053,0.2251268896422491] (2,-1; 2,-1), time: 21.4429s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_88, [-1.684316873550415,0.12181681394577026]=>[-1.684316873550415,-1e-05] (-1,-1; 15,-1), time: 0.1576s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_52, [-1.2712628841400146,0.39551690220832825]=>[-0.6561524575552531,0.003543141361910521] (2,-1; 2,-1), time: 9.6389s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_50, [-1.7945126295089722,0.4044479727745056]=>[-1.7945126295089722,-1e-05] (-1,-1; 15,-1), time: 0.4294s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_15, [-1.3436484336853027,0.3105418384075165]=>[-1.3436484336853027,-1e-05] (-1,-1; 15,-1), time: 0.6669s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_28, [-2.180086135864258,0.033434391021728516]=>[-2.180086135864258,-1e-05] (-1,-1; 15,-1), time: 0.1555s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_9, [-1.2227492332458496,0.40263015031814575]=>[-0.6531057904072609,0.030297451241203532] (2,-1; 2,-1), time: 10.1629s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_13, [-0.6146488189697266,2.1804018020629883]=>[1e-05,2.1804018020629883] (15,-1; -1,-1), time: 2.9124s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_65, [-1.4237735271453857,0.17503753304481506]=>[-1.4237735271453857,-1e-05] (-1,-1; 15,-1), time: 0.2303s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_24, [-1.1064659357070923,0.07104960083961487]=>[-1.1064659357070923,-1e-05] (-1,-1; 15,-1), time: 0.1867s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_74, [-1.4069108963012695,0.19710299372673035]=>[-1.4069108963012695,-1e-05] (-1,-1; 15,-1), time: 0.2062s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_59, [-1.3292701244354248,0.7156057357788086]=>[-0.7037177965506412,0.11540968729917567] (9,-1; 2,-1), time: 24.8610s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_48, [-1.4305258989334106,0.08901816606521606]=>[-1.4305258989334106,-1e-05] (-1,-1; 15,-1), time: 0.1462s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_20, [-1.3649725914001465,0.4548494219779968]=>[-1.3649725914001465,-1e-05] (-1,-1; 15,-1), time: 4.8707s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_17, [-1.0964035987854004,0.7235122919082642]=>[-0.5691867381359818,0.2501811045448215] (2,-1; 2,-1), time: 6.7491s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_37, [-0.46616002917289734,2.1201274394989014]=>[1e-05,2.1201274394989014] (15,-1; -1,-1), time: 3.3735s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_29, [-0.8805429339408875,0.5005209445953369]=>[-0.45867867041941074,0.07213924728065875] (2,-1; 9,-1), time: 26.8254s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_75, [-0.6586583852767944,1.980340838432312]=>[-0.15569055912047525,1.153147625571638] (2,-1; 2,-1), time: 11.5328s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_7, [-1.1018083095550537,0.7369137406349182]=>[-0.3726195614284277,0.270655582993655] (9,-1; 2,-1), time: 29.9422s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_42, [-1.619404911994934,0.06083416938781738]=>[-1.619404911994934,-1e-05] (-1,-1; 15,-1), time: 0.2031s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_97, [-0.18127793073654175,1.392589807510376]=>[1e-05,1.392589807510376] (15,-1; -1,-1), time: 0.1705s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_92, [-0.35170257091522217,1.2121702432632446]=>[1e-05,1.2121702432632446] (15,-1; -1,-1), time: 1.0151s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_18, [-0.8034161329269409,0.8046584129333496]=>[-0.2574135739854209,0.33872895654011703] (2,-1; 2,-1), time: 13.4081s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_25, [-0.38530898094177246,2.5814504623413086]=>[1e-05,2.5814504623413086] (15,-1; -1,-1), time: 0.4172s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_32, [-1.6758456230163574,0.16673585772514343]=>[-1.6758456230163574,-1e-05] (-1,-1; 15,-1), time: 0.1780s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_11, [-0.176652193069458,2.1125032901763916]=>[1e-05,2.1125032901763916] (15,-1; -1,-1), time: 0.1764s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_36, [-0.8483940362930298,0.44555848836898804]=>[-0.8483940362930298,-1e-05] (-1,-1; 15,-1), time: 4.1753s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_62, [-1.025866985321045,0.4123663008213043]=>[-1.025866985321045,-1e-05] (-1,-1; 15,-1), time: 6.0172s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_95, [-1.1798901557922363,0.08365410566329956]=>[-1.1798901557922363,-1e-05] (-1,-1; 15,-1), time: 0.2031s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_78, [-0.22530296444892883,1.1229615211486816]=>[1e-05,1.1229615211486816] (15,-1; -1,-1), time: 0.5187s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_58, [-0.3749374449253082,2.124420166015625]=>[1e-05,2.124420166015625] (15,-1; -1,-1), time: 0.3451s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_85, [-1.397426724433899,0.18545854091644287]=>[-1.397426724433899,-1e-05] (-1,-1; 15,-1), time: 0.3761s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_41, [-1.2765780687332153,0.1271803379058838]=>[-1.2765780687332153,-1e-05] (-1,-1; 15,-1), time: 0.1838s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_81, [-0.7692168354988098,1.343259572982788]=>[-0.2881824819821876,0.602443842685381] (2,-1; 2,-1), time: 14.0147s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_94, [-1.844138741493225,0.26251065731048584]=>[-1.844138741493225,-1e-05] (-1,-1; 15,-1), time: 0.1865s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_89, [-0.7691656947135925,1.1302213668823242]=>[-0.24805304266184128,0.49226934616226165] (2,-1; 2,-1), time: 10.9802s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_31, [-1.4134609699249268,0.04946151375770569]=>[-1.4134609699249268,-1e-05] (-1,-1; 15,-1), time: 0.1463s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_67, [-0.02914905548095703,1.61728835105896]=>[1e-05,1.61728835105896] (15,-1; -1,-1), time: 0.1508s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_40, [-0.8822040557861328,0.47044724225997925]=>[-0.3829074313609545,0.1241880876608164] (2,-1; 9,-1), time: 19.1945s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_4, [-0.0271378755569458,1.920274257659912]=>[1e-05,1.920274257659912] (15,-1; -1,-1), time: 0.1472s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_12, [-0.009997546672821045,2.3653743267059326]=>[1e-05,2.3653743267059326] (15,-1; -1,-1), time: 0.1434s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_16, [-0.42790961265563965,1.1826668977737427]=>[1e-05,1.1826668977737427] (15,-1; -1,-1), time: 3.9257s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_21, [-1.088670253753662,0.2446793019771576]=>[-1.088670253753662,-1e-05] (-1,-1; 15,-1), time: 0.3472s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_83, [-1.1175763607025146,0.4239124059677124]=>[-0.6571051838137395,0.008107507439643839] (2,-1; 9,-1), time: 21.6670s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_46, [-1.2733334302902222,0.4866006374359131]=>[-1.2733334302902222,-1e-05] (-1,-1; 15,-1), time: 4.6571s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_5, [-0.7987400889396667,0.44140952825546265]=>[-0.4047109315830266,0.03126897864060756] (2,-1; 9,-1), time: 23.1435s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_56, [-0.7529220581054688,1.183800458908081]=>[-0.21300657090170666,0.5626070295532681] (2,-1; 2,-1), time: 13.8174s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_43, [-0.8554026484489441,1.1327816247940063]=>[-0.3063559120592655,0.5556780068219831] (2,-1; 2,-1), time: 13.1057s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_91, [-0.7145180702209473,1.0571088790893555]=>[-0.09178337806145086,0.6789642322822146] (9,-1; 2,-1), time: 17.3974s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_51, [-1.1665701866149902,0.8571695685386658]=>[-0.6272134615254404,0.28090762374400485] (2,-1; 9,-1), time: 21.2930s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_44, [-0.6542540788650513,1.1860653162002563]=>[-0.16480286495994956,0.5225600096055067] (9,-1; 2,-1), time: 20.6390s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_70, [-0.7375583648681641,1.3216333389282227]=>[-0.20085124388812578,0.6772233738559122] (2,-1; 2,-1), time: 9.7365s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_61, [-1.0335428714752197,0.8469216823577881]=>[-0.4910992963559454,0.26986586015923264] (2,-1; 2,-1), time: 10.7552s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_64, [-0.9099005460739136,0.9773980975151062]=>[-0.40425855874906647,0.4321360960770616] (2,-1; 2,-1), time: 8.2371s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_96, [-0.6773463487625122,0.5691611170768738]=>[-0.2780574496189579,0.2501443420125636] (2,-1; 2,-1), time: 8.1425s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_45, [-1.0632083415985107,0.6319614052772522]=>[-0.45303654958517914,0.21916843635967637] (2,-1; 2,-1), time: 12.0017s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_63, [-1.5066616535186768,0.8026230335235596]=>[-0.8114595638690298,0.0935591572946439] (2,-1; 2,-1), time: 13.4889s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_66, [-0.708358883857727,0.8312099575996399]=>[-0.3141826276577079,0.36477966100284415] (9,-1; 2,-1), time: 17.2269s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_27, [-1.341468095779419,0.7810291051864624]=>[-0.7133105204449627,0.2996864894474322] (9,-1; 2,-1), time: 17.8410s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_82, [-0.7719338536262512,1.0966627597808838]=>[-0.16796434462315157,0.5078006346009477] (2,-1; 9,-1), time: 24.3460s, #vars: 1213, #constrs: 492, improved: True
Solving MIP for lay6_57, [-0.780515730381012,1.1328315734863281]=>[-0.30771475810199317,0.44080799181030056] (2,-1; 9,-1), time: 26.6685s, #vars: 1213, #constrs: 492, improved: True
Run alpha-CROWN after refining layer 4 and relu idx 1
0 /21 torch.Size([1, 100])
1 /23 torch.Size([1, 100])
best_l after optimization: 43.39383316040039 with beta sum per layer: []
alpha/beta optimization time: 7.190861463546753
alpha-CROWN with intermediate bounds by MIP: tensor([[-5.0959, -4.5818, -4.9810, -5.7925, -2.7946, -5.5102, -2.8157, -7.0142,
         -4.8079]], device='cuda:0', grad_fn=<AsStridedBackward>) None
MIP improved 91 nodes out of 91 unstable nodes, lb improved 26.363853454589844, ub improved 30.053020477294922, time 63.0756
maximum relu layer improved by MIP so far 2
Linear(in_features=100, out_features=100, bias=True) 3 8 torch.Size([100])
sorted candidates ['lay8_12', 'lay8_92', 'lay8_76', 'lay8_60', 'lay8_85', 'lay8_21', 'lay8_0', 'lay8_6', 'lay8_56', 'lay8_47', 'lay8_5', 'lay8_66', 'lay8_39', 'lay8_31', 'lay8_94', 'lay8_62', 'lay8_81', 'lay8_7', 'lay8_24', 'lay8_45', 'lay8_91', 'lay8_15', 'lay8_61', 'lay8_58', 'lay8_64', 'lay8_20', 'lay8_9', 'lay8_17', 'lay8_18', 'lay8_78', 'lay8_40', 'lay8_87', 'lay8_82', 'lay8_53', 'lay8_65', 'lay8_36', 'lay8_49', 'lay8_72', 'lay8_93', 'lay8_77', 'lay8_90', 'lay8_41', 'lay8_54', 'lay8_71', 'lay8_8', 'lay8_46', 'lay8_30', 'lay8_33', 'lay8_75', 'lay8_48', 'lay8_74', 'lay8_84', 'lay8_37', 'lay8_52', 'lay8_3', 'lay8_32', 'lay8_23', 'lay8_69', 'lay8_35', 'lay8_79', 'lay8_68', 'lay8_25', 'lay8_29', 'lay8_34', 'lay8_83', 'lay8_63', 'lay8_38', 'lay8_98', 'lay8_70', 'lay8_88', 'lay8_16', 'lay8_59', 'lay8_27', 'lay8_97', 'lay8_51', 'lay8_96', 'lay8_11', 'lay8_13', 'lay8_95', 'lay8_1', 'lay8_28', 'lay8_42', 'lay8_50', 'lay8_22', 'lay8_43', 'lay8_80', 'lay8_99', 'lay8_67', 'lay8_89', 'lay8_2', 'lay8_57', 'lay8_4', 'lay8_26', 'lay8_19', 'lay8_86', 'lay8_73', 'lay8_14', 'lay8_55', 'lay8_10'] filter: 1.0
Solving MIP for lay8_66, [-1.9906314611434937,0.7204841375350952]=>[-1.9906314611434937,-1e-05] (-1,-1; 15,-1), time: 0.1856s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_31, [-1.8136022090911865,0.7657687664031982]=>[-1.8136022090911865,-1e-05] (-1,-1; 15,-1), time: 0.1922s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_94, [-1.866899013519287,0.638457179069519]=>[-1.866899013519287,-1e-05] (-1,-1; 15,-1), time: 0.2350s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_92, [-2.0244483947753906,0.5754601955413818]=>[-2.0244483947753906,-1e-05] (-1,-1; 15,-1), time: 0.2529s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_7, [-2.367074728012085,0.4875583052635193]=>[-2.367074728012085,-1e-05] (-1,-1; 15,-1), time: 0.1770s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_60, [-1.898160696029663,0.776728630065918]=>[-1.898160696029663,-1e-05] (-1,-1; 15,-1), time: 0.4523s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_91, [-2.116284132003784,0.7311992645263672]=>[-2.116284132003784,-1e-05] (-1,-1; 15,-1), time: 0.1827s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_81, [-2.1709868907928467,1.1956218481063843]=>[-2.1709868907928467,-1e-05] (-1,-1; 15,-1), time: 0.5613s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_61, [-1.6967592239379883,0.5160283446311951]=>[-1.6967592239379883,-1e-05] (-1,-1; 15,-1), time: 0.1877s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_58, [-2.1749606132507324,0.7343665957450867]=>[-2.1749606132507324,-1e-05] (-1,-1; 15,-1), time: 0.1733s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_15, [-1.6003516912460327,0.8134385347366333]=>[-1.6003516912460327,-1e-05] (-1,-1; 15,-1), time: 1.6286s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_5, [-1.5172498226165771,0.8942636847496033]=>[-1.5172498226165771,-1e-05] (-1,-1; 15,-1), time: 6.5184s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_85, [-1.6118205785751343,0.9491019248962402]=>[-1.6118205785751343,-1e-05] (-1,-1; 15,-1), time: 10.0494s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_18, [-2.148690700531006,0.5312541723251343]=>[-2.148690700531006,-1e-05] (-1,-1; 15,-1), time: 0.2169s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_64, [-1.5454187393188477,2.2951862812042236]=>[-0.5511920371424636,1.2105882191980744] (2,-1; 9,-1), time: 21.7429s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_40, [-1.474880337715149,0.5534783601760864]=>[-1.474880337715149,-1e-05] (-1,-1; 15,-1), time: 0.3485s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_45, [-1.2454819679260254,1.6389007568359375]=>[-0.05594558678115475,0.8910122960946019] (9,-1; 2,-1), time: 26.7200s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_47, [-1.5961121320724487,1.2636609077453613]=>[-0.6769112309539805,0.12223265156124576] (9,-1; 9,-1), time: 30.0072s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_6, [-1.6567583084106445,1.0185630321502686]=>[-0.7455867074256051,0.03218229122572678] (9,-1; 9,-1), time: 30.0100s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_12, [-2.447455883026123,1.4638564586639404]=>[-1.2889869106481522,0.06254389102187738] (9,-1; 9,-1), time: 30.0112s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_39, [-1.1880048513412476,1.0541640520095825]=>[-0.2910987544982808,0.29598497329253237] (9,-1; 9,-1), time: 30.0118s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_21, [-1.6799037456512451,1.2155464887619019]=>[-0.740762319955879,0.28411598453141407] (9,-1; 9,-1), time: 30.0139s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_62, [-1.4377505779266357,1.400672197341919]=>[-0.37918083832506777,0.40315974046934233] (9,-1; 9,-1), time: 30.0114s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_0, [-1.3154376745224,1.0356554985046387]=>[-0.4794832145093559,0.24870732134128662] (9,-1; 9,-1), time: 30.0250s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_76, [-1.283835530281067,1.478603482246399]=>[-0.437223975186615,0.2951011056959281] (9,-1; 9,-1), time: 30.0282s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_56, [-1.1696467399597168,1.204514980316162]=>[-0.23241179631567385,0.3678160248313637] (9,-1; 9,-1), time: 30.0311s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_72, [-0.7317626476287842,3.849093437194824]=>[1e-05,3.849093437194824] (15,-1; -1,-1), time: 0.1990s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_93, [-2.045105218887329,0.31319332122802734]=>[-2.045105218887329,-1e-05] (-1,-1; 15,-1), time: 0.2179s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_77, [-2.091336488723755,0.413468599319458]=>[-2.091336488723755,-1e-05] (-1,-1; 15,-1), time: 0.2092s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_24, [-1.3689987659454346,0.8371137380599976]=>[-0.4427058578751228,0.0936734541579152] (9,-1; 9,-1), time: 30.0291s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_54, [-0.9035447835922241,2.505941390991211]=>[1e-05,2.505941390991211] (15,-1; -1,-1), time: 0.1932s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_71, [-1.7069529294967651,0.6117386817932129]=>[-1.7069529294967651,-1e-05] (-1,-1; 15,-1), time: 0.2311s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_53, [-1.5328221321105957,0.7214782238006592]=>[-1.5328221321105957,-1e-05] (-1,-1; 15,-1), time: 0.5798s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_30, [-0.6944258213043213,2.405012845993042]=>[1e-05,2.405012845993042] (15,-1; -1,-1), time: 0.1847s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_8, [-1.994478702545166,0.8345795273780823]=>[-1.994478702545166,-1e-05] (-1,-1; 15,-1), time: 0.4141s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_46, [-0.814544677734375,1.6251757144927979]=>[1e-05,1.6251757144927979] (15,-1; -1,-1), time: 0.4010s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_48, [-0.5091111660003662,1.8846244812011719]=>[1e-05,1.8846244812011719] (15,-1; -1,-1), time: 0.1918s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_74, [-0.44215211272239685,3.1667113304138184]=>[1e-05,3.1667113304138184] (15,-1; -1,-1), time: 0.1982s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_20, [-1.0544323921203613,1.326688528060913]=>[-0.08645452597949925,0.6391360552652712] (9,-1; 9,-1), time: 30.0168s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_3, [-0.7205051183700562,1.7737609148025513]=>[1e-05,1.7737609148025513] (15,-1; -1,-1), time: 0.4220s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_32, [-1.5903583765029907,0.5567941665649414]=>[-1.5903583765029907,-1e-05] (-1,-1; 15,-1), time: 0.2461s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_23, [-0.542112410068512,2.78774094581604]=>[1e-05,2.78774094581604] (15,-1; -1,-1), time: 0.2046s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_69, [-0.7908291816711426,1.5985896587371826]=>[1e-05,1.5985896587371826] (15,-1; -1,-1), time: 0.2206s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_9, [-1.5436149835586548,0.7119791507720947]=>[-0.5451389856242562,0.0479363588023425] (9,-1; 9,-1), time: 30.0469s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_79, [-0.8434644341468811,2.0459702014923096]=>[1e-05,2.0459702014923096] (15,-1; -1,-1), time: 0.2200s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_68, [-0.3603103756904602,2.295527696609497]=>[1e-05,2.295527696609497] (15,-1; -1,-1), time: 0.2309s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_33, [-1.5419384241104126,0.9401904940605164]=>[-1.5419384241104126,-1e-05] (-1,-1; 15,-1), time: 4.0760s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_17, [-1.0942103862762451,1.4015971422195435]=>[-0.37069143749925476,0.37354878281449555] (9,-1; 9,-1), time: 30.0137s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_34, [-0.6153316497802734,1.95148766040802]=>[1e-05,1.95148766040802] (15,-1; -1,-1), time: 0.1901s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_83, [-2.006927967071533,0.3866819739341736]=>[-2.006927967071533,-1e-05] (-1,-1; 15,-1), time: 0.2168s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_52, [-1.165962815284729,1.6881253719329834]=>[1e-05,1.6881253719329834] (15,-1; -1,-1), time: 7.2839s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_78, [-1.136460304260254,1.5795552730560303]=>[-0.12458082134320037,0.7395926650797814] (9,-1; 9,-1), time: 30.0184s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_29, [-0.898029088973999,1.8892152309417725]=>[1e-05,1.8892152309417725] (15,-1; -1,-1), time: 6.7413s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_70, [-1.775930404663086,0.7168640494346619]=>[-1.775930404663086,-1e-05] (-1,-1; 15,-1), time: 0.5647s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_88, [-0.40985584259033203,2.734795093536377]=>[1e-05,2.734795093536377] (15,-1; -1,-1), time: 0.1874s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_16, [-1.8318156003952026,0.7116577625274658]=>[-1.8318156003952026,-1e-05] (-1,-1; 15,-1), time: 0.1884s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_63, [-1.3880819082260132,3.0928902626037598]=>[1e-05,3.0928902626037598] (15,-1; -1,-1), time: 5.4642s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_59, [-0.9914175271987915,2.0339388847351074]=>[1e-05,2.0339388847351074] (15,-1; -1,-1), time: 5.4597s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_87, [-1.558561086654663,1.558969497680664]=>[-0.6003845790821641,0.37072274365734975] (9,-1; 9,-1), time: 30.0064s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_82, [-1.5888113975524902,1.1698288917541504]=>[-0.6456248988784973,0.1562247630301552] (9,-1; 9,-1), time: 30.0095s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_65, [-1.4684216976165771,0.7603844404220581]=>[-0.5638298455642802,0.009335785801228015] (9,-1; 9,-1), time: 30.0088s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_36, [-1.3136259317398071,0.8598562479019165]=>[-0.36170786893815676,0.15234646004817448] (9,-1; 9,-1), time: 30.0065s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_49, [-1.420277714729309,1.564856767654419]=>[-0.3508337308593187,0.5815163896869793] (9,-1; 9,-1), time: 30.0264s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_41, [-1.2878254652023315,0.8126286268234253]=>[-0.24766459046352365,0.23316505872810475] (9,-1; 9,-1), time: 30.0186s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_90, [-1.6748467683792114,1.9107308387756348]=>[-0.46580129485718774,0.8373761048152041] (9,-1; 9,-1), time: 30.0209s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_95, [-2.288980007171631,0.6455792784690857]=>[-2.288980007171631,-1e-05] (-1,-1; 15,-1), time: 0.1951s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_13, [-0.7554123401641846,1.4740232229232788]=>[1e-05,1.4740232229232788] (15,-1; -1,-1), time: 0.4334s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_42, [-1.7388544082641602,0.7394378185272217]=>[-1.7388544082641602,-1e-05] (-1,-1; 15,-1), time: 0.2572s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_75, [-1.0111180543899536,1.6365110874176025]=>[-0.19424829975512986,0.5492327445666476] (9,-1; 9,-1), time: 30.0063s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_84, [-1.3427257537841797,0.9867967963218689]=>[-0.4611858921069041,0.20297463108430047] (9,-1; 9,-1), time: 30.0055s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_50, [-0.48430126905441284,2.596872568130493]=>[1e-05,2.596872568130493] (15,-1; -1,-1), time: 0.2484s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_11, [-0.9799448251724243,1.7881615161895752]=>[1e-05,1.7881615161895752] (15,-1; -1,-1), time: 0.6988s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_37, [-0.9004353284835815,1.9659225940704346]=>[-0.09463072363391534,0.9259674145893037] (9,-1; 9,-1), time: 30.0100s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_80, [-0.17465555667877197,2.9687986373901367]=>[1e-05,2.9687986373901367] (15,-1; -1,-1), time: 0.1793s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_99, [-1.8578264713287354,0.42688339948654175]=>[-1.8578264713287354,-1e-05] (-1,-1; 15,-1), time: 0.2297s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_35, [-1.6956660747528076,1.5637168884277344]=>[-0.6972161734811279,0.47670444396104056] (9,-1; 9,-1), time: 30.0076s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_25, [-1.7191323041915894,0.9248859882354736]=>[-0.5888011687732801,0.15680322094822505] (9,-1; 9,-1), time: 30.0049s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_96, [-1.6528552770614624,0.8952326774597168]=>[-1.6528552770614624,-1e-05] (-1,-1; 15,-1), time: 5.9617s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_26, [-2.378445625305176,1.0253249406814575]=>[-2.378445625305176,-1e-05] (-1,-1; 15,-1), time: 1.2468s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_89, [-1.5210247039794922,0.7888086438179016]=>[-1.5210247039794922,-1e-05] (-1,-1; 15,-1), time: 3.9539s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_57, [-2.712310552597046,1.3519445657730103]=>[-2.712310552597046,-1e-05] (-1,-1; 15,-1), time: 6.8664s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_38, [-1.3540335893630981,1.1810617446899414]=>[-0.41864893145694343,0.2016733282829367] (9,-1; 9,-1), time: 30.0052s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_98, [-1.2203965187072754,1.4405956268310547]=>[-0.3817253422930194,0.39807918958716887] (9,-1; 9,-1), time: 30.0074s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_27, [-1.4596643447875977,0.78907310962677]=>[-0.5008178808086644,0.22465113199252493] (9,-1; 9,-1), time: 30.0130s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_97, [-1.3073689937591553,0.7305400371551514]=>[-0.3566540754596601,0.14331391668530807] (9,-1; 9,-1), time: 30.0058s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_51, [-2.2136547565460205,1.7289581298828125]=>[-1.043383968384661,0.5854122080043933] (9,-1; 9,-1), time: 30.0050s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_1, [-1.3371071815490723,1.2117185592651367]=>[-0.5501010871660528,0.24984489848994829] (2,-1; 9,-1), time: 24.8837s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_28, [-1.333556890487671,1.0587421655654907]=>[-0.48790943698064765,0.1618399421781222] (9,-1; 9,-1), time: 30.0069s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_22, [-1.2416306734085083,1.9130648374557495]=>[-0.2452753992844512,0.9561319916594603] (9,-1; 9,-1), time: 30.0096s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_43, [-1.4250476360321045,2.3152682781219482]=>[-0.4781735051022764,1.0058438031071062] (9,-1; 9,-1), time: 30.0104s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_67, [-1.6525723934173584,1.6301683187484741]=>[-0.646017187171759,0.4952196051990746] (9,-1; 9,-1), time: 30.0062s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_2, [-1.0142889022827148,1.1714155673980713]=>[-0.16777324607505242,0.3894243570343365] (9,-1; 9,-1), time: 30.0048s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_4, [-1.3264961242675781,1.1657642126083374]=>[-0.3041471160719265,0.4949511527280473] (9,-1; 9,-1), time: 30.0052s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_19, [-1.563920021057129,1.1820532083511353]=>[-0.4039565050102334,0.364108018392372] (9,-1; 9,-1), time: 30.0098s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_86, [-2.0515689849853516,1.4857940673828125]=>[-1.0788273182886106,0.2675695272665041] (9,-1; 9,-1), time: 30.0069s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_73, [-1.3650376796722412,1.0658280849456787]=>[-0.5419131474767449,0.08360914502826867] (9,-1; 9,-1), time: 30.0091s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_14, [-1.1169466972351074,2.6867012977600098]=>[-0.1623318421697029,1.39467817335996] (9,-1; 9,-1), time: 30.0135s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_55, [-1.618753433227539,1.6631333827972412]=>[-0.5482456036247166,0.6908168706972981] (9,-1; 9,-1), time: 30.0103s, #vars: 1395, #constrs: 715, improved: True
Solving MIP for lay8_10, [-1.1755428314208984,1.4750535488128662]=>[-0.19478961997469615,0.6209521097557035] (9,-1; 9,-1), time: 30.0049s, #vars: 1395, #constrs: 715, improved: True
Run alpha-CROWN after refining layer 6 and relu idx 2
0 /21 torch.Size([1, 100])
1 /23 torch.Size([1, 100])
2 /25 torch.Size([1, 100])
best_l after optimization: -0.6066726446151733 with beta sum per layer: []
alpha/beta optimization time: 7.086520195007324
alpha-CROWN with intermediate bounds by MIP: tensor([[ 0.1648,  0.6567,  1.1018, -1.0930,  1.1714, -0.8974,  2.8294, -3.5779,
          0.2508]], device='cuda:0', grad_fn=<AsStridedBackward>) None
MIP improved 99 nodes out of 99 unstable nodes, lb improved 59.507545471191406, ub improved 66.01184844970703, time 101.0578
maximum relu layer improved by MIP so far 3
Linear(in_features=100, out_features=100, bias=True) 4 10 torch.Size([100])
sorted candidates ['lay10_2', 'lay10_34', 'lay10_72', 'lay10_3', 'lay10_45', 'lay10_81', 'lay10_36', 'lay10_92', 'lay10_86', 'lay10_49', 'lay10_11', 'lay10_99', 'lay10_23', 'lay10_57', 'lay10_50', 'lay10_37', 'lay10_14', 'lay10_84', 'lay10_79', 'lay10_26', 'lay10_43', 'lay10_0', 'lay10_21', 'lay10_70', 'lay10_52', 'lay10_67', 'lay10_51', 'lay10_7', 'lay10_96', 'lay10_5', 'lay10_1', 'lay10_13', 'lay10_28', 'lay10_41', 'lay10_69', 'lay10_54', 'lay10_8', 'lay10_22', 'lay10_97', 'lay10_89', 'lay10_48', 'lay10_33', 'lay10_32', 'lay10_42', 'lay10_94', 'lay10_17', 'lay10_15', 'lay10_55', 'lay10_61', 'lay10_47', 'lay10_66', 'lay10_95', 'lay10_87', 'lay10_4', 'lay10_38', 'lay10_91', 'lay10_60', 'lay10_58', 'lay10_24', 'lay10_90', 'lay10_85', 'lay10_46', 'lay10_19', 'lay10_44', 'lay10_64', 'lay10_88', 'lay10_39', 'lay10_10', 'lay10_71', 'lay10_74', 'lay10_9', 'lay10_93', 'lay10_78', 'lay10_65', 'lay10_12', 'lay10_40', 'lay10_20', 'lay10_63', 'lay10_25', 'lay10_27', 'lay10_62', 'lay10_68', 'lay10_31', 'lay10_73', 'lay10_30', 'lay10_80', 'lay10_82', 'lay10_59', 'lay10_76', 'lay10_75', 'lay10_18', 'lay10_83', 'lay10_16', 'lay10_56', 'lay10_6', 'lay10_77', 'lay10_35', 'lay10_98', 'lay10_53', 'lay10_29'] filter: 1.0
Solving MIP for lay10_49, [-3.8369100093841553,2.305034875869751]=>[-3.8369100093841553,-1e-05] (-1,-1; 15,-1), time: 0.3362s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_37, [-3.075815200805664,1.8604220151901245]=>[-3.075815200805664,-1e-05] (-1,-1; 15,-1), time: 0.3358s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_86, [-3.8946595191955566,1.593031406402588]=>[-3.8946595191955566,-1e-05] (-1,-1; 15,-1), time: 0.3490s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_72, [-3.148935556411743,2.468386650085449]=>[-3.148935556411743,-1e-05] (-1,-1; 15,-1), time: 0.3644s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_79, [-3.455205202102661,2.4140803813934326]=>[-3.455205202102661,-1e-05] (-1,-1; 15,-1), time: 0.2969s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_26, [-3.228652238845825,2.2354001998901367]=>[-3.228652238845825,-1e-05] (-1,-1; 15,-1), time: 0.7053s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_3, [-4.06215763092041,2.487144708633423]=>[-4.06215763092041,-1e-05] (-1,-1; 15,-1), time: 2.0039s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_84, [-2.8973140716552734,2.39782977104187]=>[-2.8973140716552734,-1e-05] (-1,-1; 15,-1), time: 13.3283s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_70, [-2.7982821464538574,1.170924425125122]=>[-2.7982821464538574,-1e-05] (-1,-1; 15,-1), time: 0.2908s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_50, [-2.6144943237304688,2.4117655754089355]=>[-0.4802610320218816,0.31350901115671587] (9,-1; 9,-1), time: 30.0078s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_92, [-2.9812841415405273,2.370241641998291]=>[-0.7750596090104046,0.1663196076228096] (9,-1; 9,-1), time: 30.0071s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_57, [-2.5612845420837402,2.4747507572174072]=>[-0.5928899723631349,0.19194136293204775] (9,-1; 9,-1), time: 30.0115s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_45, [-2.7489099502563477,2.8954010009765625]=>[-0.4082875961010919,0.6717351815269498] (9,-1; 9,-1), time: 30.0164s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_23, [-2.6027956008911133,2.308505058288574]=>[-0.8776961805322268,0.0057299316905525454] (9,-1; 9,-1), time: 30.0223s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_36, [-2.3084516525268555,2.6537892818450928]=>[-0.2570781895818271,0.6038379390372813] (9,-1; 9,-1), time: 30.0475s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_99, [-3.538792610168457,2.729351043701172]=>[-1.4640367546371247,0.48585332077151616] (9,-1; 9,-1), time: 30.0545s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_81, [-2.9832980632781982,2.8060176372528076]=>[-1.140697932340515,0.49730994205766776] (9,-1; 9,-1), time: 30.0692s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_11, [-3.1103250980377197,2.4424309730529785]=>[-0.717007971522509,0.20690115017483177] (9,-1; 9,-1), time: 30.0730s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_2, [-3.310134172439575,3.8239779472351074]=>[-0.9843832659607719,0.283714195923765] (9,-1; 9,-1), time: 30.0827s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_34, [-2.7690000534057617,2.8912577629089355]=>[-0.5971675307730729,0.4850861506818301] (9,-1; 9,-1), time: 30.1159s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_1, [-3.4603612422943115,2.2496767044067383]=>[-3.4603612422943115,-1e-05] (-1,-1; 15,-1), time: 0.3270s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_14, [-2.996753692626953,2.2128045558929443]=>[-0.8494953749950894,0.07233798427207916] (9,-1; 9,-1), time: 30.0661s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_54, [-3.1008567810058594,1.8563185930252075]=>[-3.1008567810058594,-1e-05] (-1,-1; 15,-1), time: 0.3128s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_43, [-2.3862721920013428,3.5981686115264893]=>[-0.4745259616726638,1.2077199983518683] (9,-1; 9,-1), time: 30.1305s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_96, [-2.833224058151245,1.9147117137908936]=>[-2.833224058151245,-1e-05] (-1,-1; 15,-1), time: 0.8391s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_0, [-2.5636560916900635,2.0059151649475098]=>[-0.3553359653195581,0.4186771399610394] (9,-1; 9,-1), time: 30.0080s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_48, [-2.8998899459838867,1.6714832782745361]=>[-2.8998899459838867,-1e-05] (-1,-1; 15,-1), time: 0.3151s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_21, [-2.874622344970703,3.1677393913269043]=>[-0.8002689383383539,0.20542919893288472] (9,-1; 9,-1), time: 30.0299s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_52, [-2.391765594482422,2.5943987369537354]=>[-0.7979156435049897,0.0429583497303889] (9,-1; 9,-1), time: 30.0050s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_22, [-2.7413876056671143,2.0808117389678955]=>[-2.7413876056671143,-1e-05] (-1,-1; 15,-1), time: 14.4014s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_8, [-2.661262273788452,2.6853415966033936]=>[-0.9362572752408378,-1e-05] (9,-1; 15,-1), time: 26.5962s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_67, [-2.7692179679870605,2.310030937194824]=>[-1.1371169556422989,0.1685229405647013] (9,-1; 9,-1), time: 30.0237s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_5, [-2.6455461978912354,2.44014048576355]=>[-0.592963216247725,0.22489804741870356] (9,-1; 9,-1), time: 30.0144s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_28, [-2.5948538780212402,2.402808666229248]=>[-0.6418213903877136,0.20374938236048912] (9,-1; 9,-1), time: 30.0052s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_41, [-3.1283552646636963,2.0746073722839355]=>[-0.8964233816705723,0.19338288430615538] (9,-1; 9,-1), time: 30.0094s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_69, [-3.2346725463867188,2.3942391872406006]=>[-1.002977936887826,0.0413346786537558] (9,-1; 9,-1), time: 30.0209s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_7, [-3.0240747928619385,2.523237943649292]=>[-0.6236515514816922,0.4140288966258792] (9,-1; 9,-1), time: 30.1530s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_13, [-2.8155839443206787,3.3940787315368652]=>[-0.2299913733915203,1.241127185969916] (9,-1; 9,-1), time: 30.1103s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_51, [-3.0627970695495605,1.5480529069900513]=>[-0.7951601901715378,0.11596964840856452] (9,-1; 9,-1), time: 30.1691s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_66, [-2.325157880783081,5.120223045349121]=>[1e-05,5.120223045349121] (15,-1; -1,-1), time: 0.2610s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_38, [-2.20515513420105,4.306428909301758]=>[1e-05,4.306428909301758] (15,-1; -1,-1), time: 0.3180s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_97, [-2.794729471206665,2.170037031173706]=>[-0.6256103187240385,0.2076542750001293] (9,-1; 9,-1), time: 30.0946s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_89, [-2.9611988067626953,2.658371686935425]=>[-0.9294082468974045,0.23680982520461563] (9,-1; 9,-1), time: 30.0601s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_91, [-2.8547465801239014,4.469984531402588]=>[1e-05,4.469984531402588] (15,-1; -1,-1), time: 0.6166s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_24, [-2.8837027549743652,5.162811756134033]=>[1e-05,5.162811756134033] (15,-1; -1,-1), time: 0.2988s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_32, [-2.904271125793457,1.888195514678955]=>[-0.6905876931449884,0.12091609610423425] (9,-1; 9,-1), time: 30.0052s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_33, [-2.992952346801758,3.710547924041748]=>[-0.3120019332091993,1.5632743175859294] (9,-1; 9,-1), time: 30.1132s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_46, [-2.1481313705444336,3.9774303436279297]=>[1e-05,3.9774303436279297] (15,-1; -1,-1), time: 0.2744s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_42, [-2.864223003387451,2.3431332111358643]=>[-0.7001038590464694,0.3675324546643432] (9,-1; 9,-1), time: 30.0290s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_60, [-3.1238515377044678,1.5056185722351074]=>[-3.1238515377044678,-1e-05] (-1,-1; 15,-1), time: 5.6902s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_88, [-2.3744640350341797,3.5988986492156982]=>[1e-05,3.5988986492156982] (15,-1; -1,-1), time: 0.2201s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_4, [-3.3097825050354004,2.0194361209869385]=>[-3.3097825050354004,-1e-05] (-1,-1; 15,-1), time: 7.1372s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_94, [-2.4076900482177734,2.1886484622955322]=>[-0.557148605101928,0.08376697951300703] (9,-1; 9,-1), time: 30.0276s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_17, [-2.4081084728240967,3.283224105834961]=>[-0.19161192141230954,1.2144601395767531] (9,-1; 9,-1), time: 30.0465s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_15, [-2.6573338508605957,1.9765006303787231]=>[-0.6959855749930075,0.1582875061621258] (9,-1; 9,-1), time: 30.1076s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_47, [-2.1421446800231934,3.241940498352051]=>[-0.06645308786371917,1.2807280200841453] (9,-1; 9,-1), time: 30.0314s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_55, [-2.2558083534240723,2.472072124481201]=>[-0.16553420986634396,0.6701524626239695] (9,-1; 9,-1), time: 30.1088s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_95, [-2.9336369037628174,2.8248205184936523]=>[-0.5707438096895495,0.5686818477411822] (9,-1; 9,-1), time: 30.0403s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_61, [-2.7381350994110107,3.204012393951416]=>[-0.28293847744667344,1.0202990448476028] (9,-1; 9,-1), time: 30.1321s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_87, [-2.7908453941345215,2.481426477432251]=>[-0.4237413465164562,0.803508899150545] (9,-1; 9,-1), time: 30.0260s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_93, [-1.7577950954437256,2.8336374759674072]=>[1e-05,2.8336374759674072] (15,-1; -1,-1), time: 0.2998s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_78, [-1.6694567203521729,4.223186016082764]=>[1e-05,4.223186016082764] (15,-1; -1,-1), time: 0.2918s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_12, [-1.8993977308273315,4.301590919494629]=>[1e-05,4.301590919494629] (15,-1; -1,-1), time: 0.3091s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_58, [-2.755446434020996,2.8689160346984863]=>[-0.1690231749827603,0.838417293973181] (9,-1; 9,-1), time: 30.0579s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_90, [-3.813631772994995,4.0207295417785645]=>[-0.7069775905397423,1.0567452916540359] (9,-1; 9,-1), time: 30.0872s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_85, [-2.874422311782837,1.7859182357788086]=>[-0.6040419011113746,0.09216130206150908] (9,-1; 9,-1), time: 30.0067s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_19, [-2.15826153755188,2.5849790573120117]=>[-0.19210260068952686,0.6289353345477361] (9,-1; 9,-1), time: 30.0441s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_44, [-3.9898014068603516,2.9015262126922607]=>[-0.8281845519748525,0.9632188683616713] (9,-1; 9,-1), time: 30.0804s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_31, [-1.608405351638794,4.662815570831299]=>[1e-05,4.662815570831299] (15,-1; -1,-1), time: 0.3068s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_62, [-2.189697742462158,2.9302690029144287]=>[1e-05,2.9302690029144287] (15,-1; -1,-1), time: 0.6693s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_64, [-2.458578586578369,2.6028034687042236]=>[-0.2824477069896912,0.7122943652812213] (9,-1; 9,-1), time: 30.1047s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_39, [-2.8280909061431885,1.9644815921783447]=>[-0.6729032911578908,0.21140557188916503] (9,-1; 9,-1), time: 30.0123s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_10, [-2.8675894737243652,3.0258047580718994]=>[-0.6633779872115229,0.42235900374122703] (9,-1; 9,-1), time: 30.0194s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_76, [-2.017362117767334,3.864846706390381]=>[1e-05,3.864846706390381] (15,-1; -1,-1), time: 0.2513s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_40, [-2.3385801315307617,3.5799784660339355]=>[1e-05,3.5799784660339355] (15,-1; -1,-1), time: 11.3888s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_59, [-2.8959391117095947,1.4866480827331543]=>[-2.8959391117095947,-1e-05] (-1,-1; 15,-1), time: 6.7859s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_83, [-2.361319065093994,3.451042652130127]=>[1e-05,3.451042652130127] (15,-1; -1,-1), time: 0.3054s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_71, [-2.7798566818237305,3.395200490951538]=>[-0.15693825152800872,1.2120938540931114] (9,-1; 9,-1), time: 30.0670s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_74, [-3.084315776824951,2.3760178089141846]=>[-0.8246118824815328,0.4302855163929681] (9,-1; 9,-1), time: 30.0191s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_75, [-2.207242727279663,3.0813639163970947]=>[1e-05,3.0813639163970947] (15,-1; -1,-1), time: 11.5341s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_9, [-2.2367610931396484,1.7866759300231934]=>[-0.49754410958839435,0.1135214066706486] (9,-1; 9,-1), time: 30.0998s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_65, [-2.881392240524292,2.2831203937530518]=>[-0.7440543690403919,0.33872014636594144] (9,-1; 9,-1), time: 30.0131s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_20, [-2.896904945373535,2.064275026321411]=>[-0.4019321655551663,0.45842395060273916] (9,-1; 9,-1), time: 30.0123s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_25, [-2.362240791320801,2.5698864459991455]=>[-0.2409203632893445,0.6737801425281665] (9,-1; 9,-1), time: 30.0661s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_27, [-2.3602311611175537,2.6863763332366943]=>[-0.19406894283671774,0.8134724097985716] (9,-1; 9,-1), time: 30.0054s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_63, [-2.175410509109497,2.45044207572937]=>[-0.43500171074577443,0.258682433716911] (9,-1; 9,-1), time: 30.1975s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_68, [-2.099982976913452,3.2239577770233154]=>[-0.1242395665622998,1.1914381714476812] (9,-1; 9,-1), time: 30.0179s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_73, [-2.3310093879699707,2.011723756790161]=>[-0.5083043403619952,0.4856181097840263] (9,-1; 9,-1), time: 30.0101s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_30, [-2.7181999683380127,2.849780321121216]=>[-0.32345877404605755,1.0762378461712314] (9,-1; 9,-1), time: 30.0404s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_80, [-3.027186632156372,2.4882819652557373]=>[-1.0306948101504572,0.1598078907695874] (9,-1; 9,-1), time: 30.0144s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_82, [-2.4678986072540283,3.0088343620300293]=>[-0.07282673966800887,1.1890485054056283] (9,-1; 9,-1), time: 30.0970s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_18, [-2.3435304164886475,2.9647789001464844]=>[-0.3613154871208687,0.5894898478729266] (9,-1; 9,-1), time: 30.0060s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_16, [-2.331136465072632,1.8312404155731201]=>[-0.33511112165132223,0.23356244538204893] (9,-1; 9,-1), time: 30.0057s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_56, [-2.44732928276062,2.5870184898376465]=>[-0.44118411338108326,0.29224580000765993] (9,-1; 9,-1), time: 30.0083s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_6, [-2.402702808380127,3.31901216506958]=>[-0.4476603945753674,0.641068704823076] (9,-1; 9,-1), time: 30.0235s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_29, [-2.2952675819396973,2.764833688735962]=>[2.192351885119386e-06,2.764833688735962] (9,-1; -1,-1), time: 15.0049s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_77, [-2.536499500274658,2.137470245361328]=>[-0.24109144130407653,0.41909274993573103] (9,-1; 9,-1), time: 30.0186s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_35, [-2.6296637058258057,1.951498031616211]=>[-1.0006231404217254,0.052400991869628766] (9,-1; 9,-1), time: 30.0277s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_98, [-3.021066427230835,1.8598814010620117]=>[-0.4248311522331182,0.32487936280245305] (9,-1; 9,-1), time: 30.0330s, #vars: 1587, #constrs: 953, improved: True
Solving MIP for lay10_53, [-2.6364169120788574,3.4018449783325195]=>[-0.4251177922055809,0.7589239664652008] (9,-1; 9,-1), time: 30.0310s, #vars: 1587, #constrs: 953, improved: True
Run alpha-CROWN after refining layer 8 and relu idx 3
0 /21 torch.Size([1, 100])
1 /23 torch.Size([1, 100])
2 /25 torch.Size([1, 100])
3 /27 torch.Size([1, 100])
best_l after optimization: -12.577597618103027 with beta sum per layer: []
alpha/beta optimization time: 6.061340570449829
alpha-CROWN with intermediate bounds by MIP: tensor([[ 1.5767,  2.0316,  2.7448,  0.2641,  2.2640,  0.3431,  4.2624, -2.4721,
          1.5630]], device='cuda:0', grad_fn=<AsStridedBackward>) None
MIP improved 100 nodes out of 100 unstable nodes, lb improved 180.1899871826172, ub improved 174.92510986328125, time 151.2298
maximum relu layer improved by MIP so far 4
Linear(in_features=100, out_features=10, bias=True) 5 12 torch.Size([10])
MIP finished with 325.5715882778168s
Run final alpha-CROWN after MIP solving on layer 12 and relu idx 5
0 /21 torch.Size([1, 100])
1 /23 torch.Size([1, 100])
2 /25 torch.Size([1, 100])
3 /27 torch.Size([1, 100])
4 /29 torch.Size([1, 100])
best_l after optimization: -17.25272560119629 with beta sum per layer: []
alpha/beta optimization time: 5.560925722122192
alpha-CROWN with intermediate bounds improved by MIP: tensor([[ 2.1093,  2.5468,  3.3068,  0.8485,  2.6903,  0.8843,  4.7424, -2.0109,
          2.1352]], device='cuda:0', grad_fn=<AsStridedBackward>) None
refined global lb: tensor([[ 2.1093,  2.5468,  3.3068,  0.8485,  2.6903,  0.8843,  4.7424, -2.0109,
          2.1352,  0.0000]], device='cuda:0') min: tensor(-2.0109, device='cuda:0')
time threshold left for bab: 560.3318204879761
##### [0:20] Tested against 2 ######
Initial alpha-CROWN verified for label 2 with bound 3.3068277835845947
Image 20 label 2 verification end, final lower bound 3.3068277835845947, upper bound inf, time: 0.00039076805114746094
20 3.3068277835845947
##### [0:20] Tested against 3 ######
Initial alpha-CROWN verified for label 3 with bound 0.8484606742858887
Image 20 label 3 verification end, final lower bound 0.8484606742858887, upper bound inf, time: 0.0005521774291992188
20 0.8484606742858887
##### [0:20] Tested against 5 ######
Initial alpha-CROWN verified for label 5 with bound 0.8842880725860596
Image 20 label 5 verification end, final lower bound 0.8842880725860596, upper bound inf, time: 0.00039076805114746094
20 0.8842880725860596
##### [0:20] Tested against 1 ######
Initial alpha-CROWN verified for label 1 with bound 2.546813726425171
Image 20 label 1 verification end, final lower bound 2.546813726425171, upper bound inf, time: 0.00039124488830566406
20 2.546813726425171
##### [0:20] Tested against 0 ######
Initial alpha-CROWN verified for label 0 with bound 2.109276056289673
Image 20 label 0 verification end, final lower bound 2.109276056289673, upper bound inf, time: 0.00037670135498046875
20 2.109276056289673
##### [0:20] Tested against 8 ######
Initial alpha-CROWN verified for label 8 with bound 2.135211944580078
Image 20 label 8 verification end, final lower bound 2.135211944580078, upper bound inf, time: 0.0003771781921386719
20 2.135211944580078
##### [0:20] Tested against 7 ######
Model prediction is: tensor([[-1.3886, -0.7100, -2.2255, -0.0764,  1.1890, -0.3403, -4.0691,  2.6444,
         -0.5482,  6.5574]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /22 start_node /23
setting alpha for layer /22 start_node /25
setting alpha for layer /22 start_node /27
setting alpha for layer /22 start_node /29
not setting layer /22 start_node /31 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
setting alpha for layer /24 start_node /25
setting alpha for layer /24 start_node /27
setting alpha for layer /24 start_node /29
not setting layer /24 start_node /31 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
setting alpha for layer /26 start_node /27
setting alpha for layer /26 start_node /29
not setting layer /26 start_node /31 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
setting alpha for layer /28 start_node /29
not setting layer /28 start_node /31 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
not setting layer /30 start_node /31 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /21 torch.Size([1, 100])
1 /23 torch.Size([1, 100])
2 /25 torch.Size([1, 100])
3 /27 torch.Size([1, 100])
4 /29 torch.Size([1, 100])
best_l after optimization: 2.011631965637207 with beta sum per layer: []
alpha/beta optimization time: 2.0119102001190186
alpha-CROWN with fixed intermediate bounds: tensor([[-2.0116]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-2.011631965637207
layer 0 size torch.Size([100]) unstable 30
layer 1 size torch.Size([100]) unstable 34
layer 2 size torch.Size([100]) unstable 41
layer 3 size torch.Size([100]) unstable 46
layer 4 size torch.Size([100]) unstable 66
-----------------
# of unstable neurons: 217
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 100]) pre split depth:  6
batch:  torch.Size([1, 100]) post split depth:  6
splitting decisions: 
split level 0: [3, 64] 
split level 1: [0, 99] 
split level 2: [4, 81] 
split level 3: [0, 28] 
split level 4: [0, 95] 
split level 5: [4, 99] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: 39.1715202331543 with beta sum per layer: [3.382923126220703, 0.0, 0.0, 24.71575164794922, 33.0347900390625]
alpha/beta optimization time: 0.34981513023376465
This batch time : update_bounds func: 0.3654	 prepare: 0.0078	 bound: 0.3502	 transfer: 0.0008	 finalize: 0.0063
Accumulated time: update_bounds func: 0.3654	 prepare: 0.0078	 bound: 0.3502	 transfer: 0.0008	 finalize: 0.0063
batch bounding time:  0.36556529998779297
Current worst splitting domains [lb, ub] (depth):
[-1.71622,   inf] (7), [-1.65343,   inf] (7), [-1.63044,   inf] (7), [-1.57544,   inf] (7), [-1.41940,   inf] (7), [-1.40935,   inf] (7), [-1.38803,   inf] (7), [-1.35730,   inf] (7), [-1.35663,   inf] (7), [-1.34443,   inf] (7), [-1.33539,   inf] (7), [-1.28509,   inf] (7), [-1.20687,   inf] (7), [-1.19142,   inf] (7), [-1.16783,   inf] (7), [-1.15891,   inf] (7), [-1.15820,   inf] (7), [-1.15070,   inf] (7), [-1.12598,   inf] (7), [-1.11407,   inf] (7), 
length of domains: 53
Total time: 0.4287	 pickout: 0.0012	 decision: 0.0487	 get_bound: 0.3761	 add_domain: 0.0028
Current lb:-1.7162221670150757
64 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.9032881259918213

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([53, 100]) pre split depth:  1
batch:  torch.Size([53, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 43] [3, 43] [3, 43] [3, 43] [3, 43] [3, 43] [3, 43] [3, 43] [3, 43] [3, 43] 
regular batch size: 2*53, diving batch size 1*0
best_l after optimization: 42.77996826171875 with beta sum per layer: [7.157567501068115, 0.0, 0.0, 51.33311462402344, 82.02893829345703]
alpha/beta optimization time: 0.3544032573699951
This batch time : update_bounds func: 0.3810	 prepare: 0.0152	 bound: 0.3548	 transfer: 0.0008	 finalize: 0.0099
Accumulated time: update_bounds func: 0.7464	 prepare: 0.0230	 bound: 0.7050	 transfer: 0.0008	 finalize: 0.0162
batch bounding time:  0.38128662109375
Current worst splitting domains [lb, ub] (depth):
[-1.70449,   inf] (9), [-1.64764,   inf] (9), [-1.61037,   inf] (9), [-1.56127,   inf] (9), [-1.37676,   inf] (9), [-1.35836,   inf] (9), [-1.35288,   inf] (9), [-1.31842,   inf] (9), [-1.30064,   inf] (9), [-1.28482,   inf] (9), [-1.28378,   inf] (9), [-1.21960,   inf] (9), [-1.12843,   inf] (9), [-1.09895,   inf] (9), [-1.08271,   inf] (9), [-1.04954,   inf] (9), [-1.04176,   inf] (9), [-1.02150,   inf] (9), [-1.00470,   inf] (9), [-0.98555,   inf] (9), 
length of domains: 64
Total time: 0.4302	 pickout: 0.0096	 decision: 0.0355	 get_bound: 0.3815	 add_domain: 0.0035
Current lb:-1.7044892311096191
170 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.3351802825927734

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 100]) pre split depth:  1
batch:  torch.Size([64, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 83] [1, 83] [0, 53] [1, 83] [4, 6] [4, 6] [0, 53] [4, 6] [4, 6] [0, 53] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 59.26654052734375 with beta sum per layer: [17.838531494140625, 2.269218921661377, 0.0, 50.58759307861328, 203.33558654785156]
alpha/beta optimization time: 0.3589918613433838
This batch time : update_bounds func: 0.3915	 prepare: 0.0189	 bound: 0.3594	 transfer: 0.0009	 finalize: 0.0120
Accumulated time: update_bounds func: 1.1379	 prepare: 0.0420	 bound: 1.0644	 transfer: 0.0009	 finalize: 0.0282
batch bounding time:  0.39184021949768066
Current worst splitting domains [lb, ub] (depth):
[-1.68141,   inf] (11), [-1.61955,   inf] (11), [-1.53564,   inf] (11), [-1.52615,   inf] (11), [-1.32211,   inf] (11), [-1.30715,   inf] (11), [-1.26443,   inf] (11), [-1.26399,   inf] (11), [-1.26041,   inf] (11), [-1.25039,   inf] (11), [-1.24822,   inf] (11), [-1.23630,   inf] (11), [-1.18721,   inf] (11), [-1.17712,   inf] (11), [-1.16585,   inf] (11), [-1.11063,   inf] (11), [-1.05497,   inf] (11), [-1.03089,   inf] (11), [-0.99291,   inf] (11), [-0.97704,   inf] (11), 
length of domains: 102
Total time: 0.4481	 pickout: 0.0116	 decision: 0.0383	 get_bound: 0.3920	 add_domain: 0.0063
Current lb:-1.681412935256958
298 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.7850794792175293

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([102, 100]) pre split depth:  1
batch:  torch.Size([102, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 53] [0, 53] [1, 83] [0, 53] [4, 53] [4, 53] [4, 6] [0, 53] [4, 53] [1, 83] 
regular batch size: 2*102, diving batch size 1*0
best_l after optimization: 73.81669616699219 with beta sum per layer: [33.32171630859375, 6.9608001708984375, 0.0, 96.71829223632812, 346.7120666503906]
alpha/beta optimization time: 0.36419677734375
This batch time : update_bounds func: 0.4152	 prepare: 0.0295	 bound: 0.3646	 transfer: 0.0010	 finalize: 0.0194
Accumulated time: update_bounds func: 1.5531	 prepare: 0.0715	 bound: 1.4291	 transfer: 0.0010	 finalize: 0.0476
batch bounding time:  0.4155588150024414
Current worst splitting domains [lb, ub] (depth):
[-1.60158,   inf] (13), [-1.55467,   inf] (13), [-1.49048,   inf] (13), [-1.45074,   inf] (13), [-1.31407,   inf] (13), [-1.31283,   inf] (13), [-1.27019,   inf] (13), [-1.25883,   inf] (13), [-1.20591,   inf] (13), [-1.19970,   inf] (13), [-1.19962,   inf] (13), [-1.16857,   inf] (13), [-1.15398,   inf] (13), [-1.14431,   inf] (13), [-1.14250,   inf] (13), [-1.12108,   inf] (13), [-1.09438,   inf] (13), [-1.09375,   inf] (13), [-1.06810,   inf] (13), [-1.01883,   inf] (13), 
length of domains: 151
Total time: 0.4883	 pickout: 0.0178	 decision: 0.0453	 get_bound: 0.4159	 add_domain: 0.0094
Current lb:-1.60158371925354
502 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.276170015335083

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([151, 100]) pre split depth:  1
batch:  torch.Size([151, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 6] [4, 6] [4, 6] [4, 6] [4, 6] [4, 6] [3, 51] [3, 51] [3, 51] [3, 51] 
regular batch size: 2*151, diving batch size 1*0
best_l after optimization: 88.99333190917969 with beta sum per layer: [53.52365493774414, 19.204763412475586, 0.0, 122.8643569946289, 604.1929321289062]
alpha/beta optimization time: 0.3692965507507324
This batch time : update_bounds func: 0.4425	 prepare: 0.0424	 bound: 0.3697	 transfer: 0.0011	 finalize: 0.0284
Accumulated time: update_bounds func: 1.9956	 prepare: 0.1139	 bound: 1.7988	 transfer: 0.0011	 finalize: 0.0759
batch bounding time:  0.4429740905761719
Current worst splitting domains [lb, ub] (depth):
[-1.57152,   inf] (15), [-1.52728,   inf] (15), [-1.45271,   inf] (15), [-1.41532,   inf] (15), [-1.24967,   inf] (15), [-1.24867,   inf] (15), [-1.24677,   inf] (15), [-1.23874,   inf] (15), [-1.19340,   inf] (15), [-1.18019,   inf] (15), [-1.17630,   inf] (15), [-1.14968,   inf] (15), [-1.14516,   inf] (15), [-1.10874,   inf] (15), [-1.09604,   inf] (15), [-1.08725,   inf] (15), [-1.07663,   inf] (15), [-1.06545,   inf] (15), [-1.05036,   inf] (15), [-1.04103,   inf] (15), 
length of domains: 218
Total time: 0.5386	 pickout: 0.0261	 decision: 0.0550	 get_bound: 0.4434	 add_domain: 0.0141
Current lb:-1.5715172290802002
804 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.8193583488464355

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([218, 100]) pre split depth:  1
batch:  torch.Size([218, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 51] [4, 53] [3, 51] [3, 51] [1, 81] [3, 51] [3, 51] [1, 81] [3, 51] [1, 81] 
regular batch size: 2*218, diving batch size 1*0
best_l after optimization: 105.08634948730469 with beta sum per layer: [103.11341094970703, 47.7683219909668, 0.3296889662742615, 204.4084014892578, 844.5146484375]
alpha/beta optimization time: 0.3685176372528076
This batch time : update_bounds func: 0.5559	 prepare: 0.0618	 bound: 0.3690	 transfer: 0.0022	 finalize: 0.1219
Accumulated time: update_bounds func: 2.5515	 prepare: 0.1757	 bound: 2.1678	 transfer: 0.0022	 finalize: 0.1979
batch bounding time:  0.5565900802612305
Current worst splitting domains [lb, ub] (depth):
[-1.57058,   inf] (17), [-1.48833,   inf] (17), [-1.43996,   inf] (17), [-1.40447,   inf] (17), [-1.21232,   inf] (17), [-1.20854,   inf] (17), [-1.18763,   inf] (17), [-1.16616,   inf] (17), [-1.15835,   inf] (17), [-1.10702,   inf] (17), [-1.09363,   inf] (17), [-1.08605,   inf] (17), [-1.08424,   inf] (17), [-1.08302,   inf] (17), [-1.05916,   inf] (17), [-1.04740,   inf] (17), [-1.04027,   inf] (17), [-1.00159,   inf] (17), [-0.99229,   inf] (17), [-0.98815,   inf] (17), 
length of domains: 281
Total time: 0.6851	 pickout: 0.0408	 decision: 0.0689	 get_bound: 0.5573	 add_domain: 0.0181
Current lb:-1.5705832242965698
1240 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.511462688446045

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([281, 100]) pre split depth:  1
batch:  torch.Size([281, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 53] [3, 51] [1, 81] [1, 81] [1, 81] [1, 81] [3, 51] [0, 53] [0, 53] [4, 21] 
regular batch size: 2*281, diving batch size 1*0
best_l after optimization: 130.20216369628906 with beta sum per layer: [163.9501495361328, 98.15141296386719, 0.5625649690628052, 311.509765625, 925.807373046875]
alpha/beta optimization time: 0.37152791023254395
This batch time : update_bounds func: 0.5133	 prepare: 0.0834	 bound: 0.3720	 transfer: 0.0027	 finalize: 0.0538
Accumulated time: update_bounds func: 3.0648	 prepare: 0.2591	 bound: 2.5398	 transfer: 0.0027	 finalize: 0.2517
batch bounding time:  0.5140383243560791
Current worst splitting domains [lb, ub] (depth):
[-1.53542,   inf] (19), [-1.48833,   inf] (19), [-1.38240,   inf] (19), [-1.33949,   inf] (19), [-1.27326,   inf] (19), [-1.25177,   inf] (19), [-1.24218,   inf] (19), [-1.14477,   inf] (19), [-1.12176,   inf] (19), [-1.09501,   inf] (19), [-1.09182,   inf] (19), [-1.07777,   inf] (19), [-1.02344,   inf] (19), [-1.02284,   inf] (19), [-1.01911,   inf] (19), [-1.01850,   inf] (19), [-1.01669,   inf] (19), [-1.01598,   inf] (19), [-0.99968,   inf] (19), [-0.97530,   inf] (19), 
length of domains: 376
Total time: 0.6726	 pickout: 0.0513	 decision: 0.0800	 get_bound: 0.5149	 add_domain: 0.0265
Current lb:-1.5354223251342773
1802 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.1930670738220215

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([376, 100]) pre split depth:  1
batch:  torch.Size([376, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 81] [1, 81] [4, 53] [4, 53] [4, 53] [4, 53] [4, 21] [4, 53] [4, 53] [4, 21] 
regular batch size: 2*376, diving batch size 1*0
best_l after optimization: 153.4110870361328 with beta sum per layer: [238.39443969726562, 174.71536254882812, 9.4208345413208, 392.05426025390625, 1290.0794677734375]
alpha/beta optimization time: 0.37971067428588867
This batch time : update_bounds func: 0.5681	 prepare: 0.1100	 bound: 0.3803	 transfer: 0.0039	 finalize: 0.0719
Accumulated time: update_bounds func: 3.6329	 prepare: 0.3692	 bound: 2.9201	 transfer: 0.0039	 finalize: 0.3236
batch bounding time:  0.5690751075744629
Current worst splitting domains [lb, ub] (depth):
[-1.47318,   inf] (21), [-1.42467,   inf] (21), [-1.38427,   inf] (21), [-1.35457,   inf] (21), [-1.34389,   inf] (21), [-1.30244,   inf] (21), [-1.23055,   inf] (21), [-1.21164,   inf] (21), [-1.12014,   inf] (21), [-1.09723,   inf] (21), [-1.09625,   inf] (21), [-1.06342,   inf] (21), [-1.06261,   inf] (21), [-1.03217,   inf] (21), [-1.03049,   inf] (21), [-0.99898,   inf] (21), [-0.99596,   inf] (21), [-0.99381,   inf] (21), [-0.99380,   inf] (21), [-0.98676,   inf] (21), 
length of domains: 524
Total time: 0.8640	 pickout: 0.0696	 decision: 0.1854	 get_bound: 0.5703	 add_domain: 0.0387
Current lb:-1.473182201385498
2554 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.068942546844482

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([524, 100]) pre split depth:  1
batch:  torch.Size([524, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 72] [0, 72] [0, 98] [0, 98] [0, 72] [0, 72] [0, 98] [4, 21] [2, 64] [2, 64] 
regular batch size: 2*524, diving batch size 1*0
best_l after optimization: 184.9236297607422 with beta sum per layer: [346.0507507324219, 283.30328369140625, 58.51355743408203, 480.66900634765625, 1956.560791015625]
alpha/beta optimization time: 0.37285828590393066
This batch time : update_bounds func: 0.7066	 prepare: 0.1558	 bound: 0.3734	 transfer: 0.0051	 finalize: 0.1696
Accumulated time: update_bounds func: 4.3395	 prepare: 0.5249	 bound: 3.2934	 transfer: 0.0051	 finalize: 0.4932
batch bounding time:  0.7076601982116699
Current worst splitting domains [lb, ub] (depth):
[-1.38195,   inf] (23), [-1.33507,   inf] (23), [-1.32828,   inf] (23), [-1.32772,   inf] (23), [-1.29735,   inf] (23), [-1.26921,   inf] (23), [-1.24620,   inf] (23), [-1.20699,   inf] (23), [-1.17800,   inf] (23), [-1.17010,   inf] (23), [-1.14559,   inf] (23), [-1.12914,   inf] (23), [-1.12264,   inf] (23), [-1.11049,   inf] (23), [-1.05067,   inf] (23), [-1.02858,   inf] (23), [-1.02727,   inf] (23), [-1.01367,   inf] (23), [-1.00048,   inf] (23), [-0.99009,   inf] (23), 
length of domains: 685
Total time: 0.9869	 pickout: 0.0986	 decision: 0.1259	 get_bound: 0.7093	 add_domain: 0.0531
Current lb:-1.3819489479064941
3602 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.074671745300293

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([685, 100]) pre split depth:  1
batch:  torch.Size([685, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 21] [4, 21] [4, 21] [4, 21] [4, 21] [4, 21] [0, 21] [0, 21] [0, 21] [4, 21] 
regular batch size: 2*685, diving batch size 1*0
best_l after optimization: 210.9855194091797 with beta sum per layer: [516.0631103515625, 441.27313232421875, 160.16488647460938, 551.4254150390625, 2579.059326171875]
alpha/beta optimization time: 0.37137508392333984
This batch time : update_bounds func: 0.7315	 prepare: 0.2095	 bound: 0.3719	 transfer: 0.0083	 finalize: 0.1381
Accumulated time: update_bounds func: 5.0709	 prepare: 0.7344	 bound: 3.6653	 transfer: 0.0083	 finalize: 0.6313
batch bounding time:  0.7330517768859863
Current worst splitting domains [lb, ub] (depth):
[-1.32481,   inf] (25), [-1.27697,   inf] (25), [-1.26847,   inf] (25), [-1.26354,   inf] (25), [-1.23265,   inf] (25), [-1.21053,   inf] (25), [-1.20711,   inf] (25), [-1.20478,   inf] (25), [-1.16615,   inf] (25), [-1.16032,   inf] (25), [-1.15507,   inf] (25), [-1.14434,   inf] (25), [-1.13416,   inf] (25), [-1.11468,   inf] (25), [-1.10369,   inf] (25), [-1.08820,   inf] (25), [-1.08592,   inf] (25), [-1.07670,   inf] (25), [-1.05274,   inf] (25), [-1.03628,   inf] (25), 
length of domains: 829
Total time: 1.2304	 pickout: 0.1539	 decision: 0.2739	 get_bound: 0.7353	 add_domain: 0.0672
Current lb:-1.3248125314712524
4972 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.331470251083374

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([829, 100]) pre split depth:  1
batch:  torch.Size([829, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 21] [0, 98] [0, 21] [2, 64] [2, 64] [0, 21] [0, 21] [4, 21] [4, 21] [0, 21] 
regular batch size: 2*829, diving batch size 1*0
best_l after optimization: 235.702392578125 with beta sum per layer: [750.6813354492188, 676.4339599609375, 283.2278137207031, 535.662841796875, 3182.19970703125]
alpha/beta optimization time: 0.3972742557525635
This batch time : update_bounds func: 0.8864	 prepare: 0.2515	 bound: 0.3978	 transfer: 0.0077	 finalize: 0.2245
Accumulated time: update_bounds func: 5.9574	 prepare: 0.9859	 bound: 4.0631	 transfer: 0.0077	 finalize: 0.8558
batch bounding time:  0.888068675994873
Current worst splitting domains [lb, ub] (depth):
[-1.28593,   inf] (27), [-1.26147,   inf] (27), [-1.23265,   inf] (27), [-1.22718,   inf] (27), [-1.22512,   inf] (27), [-1.16648,   inf] (27), [-1.14792,   inf] (27), [-1.13271,   inf] (27), [-1.11848,   inf] (27), [-1.11044,   inf] (27), [-1.10098,   inf] (27), [-1.08878,   inf] (27), [-1.08592,   inf] (27), [-1.08189,   inf] (27), [-1.07673,   inf] (27), [-1.07223,   inf] (27), [-1.05846,   inf] (27), [-1.04150,   inf] (27), [-1.02828,   inf] (27), [-1.02048,   inf] (27), 
length of domains: 970
Total time: 1.4127	 pickout: 0.1613	 decision: 0.2744	 get_bound: 0.8907	 add_domain: 0.0863
Current lb:-1.2859258651733398
6630 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.788043737411499

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([970, 100]) pre split depth:  1
batch:  torch.Size([970, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 98] [1, 15] [1, 15] [0, 98] [0, 21] [0, 98] [0, 98] [3, 22] [3, 22] [0, 98] 
regular batch size: 2*970, diving batch size 1*0
best_l after optimization: 252.72402954101562 with beta sum per layer: [933.7764892578125, 891.6549682617188, 398.6723327636719, 632.2322387695312, 3935.56787109375]
alpha/beta optimization time: 0.3800802230834961
This batch time : update_bounds func: 0.9823	 prepare: 0.3082	 bound: 0.3806	 transfer: 0.0107	 finalize: 0.2774
Accumulated time: update_bounds func: 6.9396	 prepare: 1.2941	 bound: 4.4437	 transfer: 0.0107	 finalize: 1.1332
batch bounding time:  0.9847760200500488
Current worst splitting domains [lb, ub] (depth):
[-1.23486,   inf] (29), [-1.22979,   inf] (29), [-1.20416,   inf] (29), [-1.18703,   inf] (29), [-1.17771,   inf] (29), [-1.11404,   inf] (29), [-1.10411,   inf] (29), [-1.09886,   inf] (29), [-1.09322,   inf] (29), [-1.06744,   inf] (29), [-1.06396,   inf] (29), [-1.05931,   inf] (29), [-1.05842,   inf] (29), [-1.05510,   inf] (29), [-1.04963,   inf] (29), [-1.04323,   inf] (29), [-1.02796,   inf] (29), [-1.02601,   inf] (29), [-1.01108,   inf] (29), [-1.00332,   inf] (29), 
length of domains: 1138
Total time: 1.6064	 pickout: 0.1934	 decision: 0.3247	 get_bound: 0.9885	 add_domain: 0.0999
Current lb:-1.2348601818084717
8570 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.436994075775146

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 64] [3, 14] [3, 14] [2, 64] [2, 64] [2, 64] [1, 29] [2, 64] [1, 29] [3, 14] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 297.2020568847656 with beta sum per layer: [1073.1328125, 1085.9129638671875, 476.16668701171875, 670.365234375, 4229.32861328125]
alpha/beta optimization time: 0.3991410732269287
This batch time : update_bounds func: 1.0425	 prepare: 0.3171	 bound: 0.3996	 transfer: 0.0095	 finalize: 0.3106
Accumulated time: update_bounds func: 7.9822	 prepare: 1.6112	 bound: 4.8433	 transfer: 0.0095	 finalize: 1.4438
batch bounding time:  1.0447125434875488
Current worst splitting domains [lb, ub] (depth):
[-1.23486,   inf] (31), [-1.22581,   inf] (31), [-1.20229,   inf] (31), [-1.18703,   inf] (31), [-1.17771,   inf] (31), [-1.11404,   inf] (31), [-1.09886,   inf] (31), [-1.06406,   inf] (31), [-1.05931,   inf] (31), [-1.05439,   inf] (31), [-1.03976,   inf] (31), [-1.02796,   inf] (31), [-1.01108,   inf] (31), [-1.00551,   inf] (31), [-0.99546,   inf] (31), [-0.99255,   inf] (31), [-0.98869,   inf] (31), [-0.97655,   inf] (31), [-0.97446,   inf] (31), [-0.97065,   inf] (31), 
length of domains: 1488
Total time: 1.6978	 pickout: 0.2319	 decision: 0.2943	 get_bound: 1.0480	 add_domain: 0.1236
Current lb:-1.2348601818084717
10618 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.170265674591064

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 15] [1, 29] [1, 29] [1, 15] [1, 15] [1, 15] [1, 15] [2, 75] [1, 15] [2, 75] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 312.7950134277344 with beta sum per layer: [1161.1497802734375, 1156.27978515625, 471.24530029296875, 572.6778564453125, 4341.6708984375]
alpha/beta optimization time: 0.3858776092529297
This batch time : update_bounds func: 1.0073	 prepare: 0.3152	 bound: 0.3864	 transfer: 0.0120	 finalize: 0.2882
Accumulated time: update_bounds func: 8.9895	 prepare: 1.9264	 bound: 5.2297	 transfer: 0.0120	 finalize: 1.7320
batch bounding time:  1.00960111618042
Current worst splitting domains [lb, ub] (depth):
[-1.22536,   inf] (33), [-1.18219,   inf] (33), [-1.16363,   inf] (33), [-1.12706,   inf] (33), [-1.11010,   inf] (33), [-1.10734,   inf] (33), [-1.10512,   inf] (33), [-1.08884,   inf] (33), [-1.07979,   inf] (33), [-1.06166,   inf] (33), [-1.05228,   inf] (33), [-1.05154,   inf] (33), [-1.01827,   inf] (33), [-1.01461,   inf] (33), [-1.01212,   inf] (33), [-0.99478,   inf] (33), [-0.99443,   inf] (33), [-0.99190,   inf] (33), [-0.98947,   inf] (33), [-0.96076,   inf] (33), 
length of domains: 1971
Total time: 1.6673	 pickout: 0.2063	 decision: 0.3080	 get_bound: 1.0132	 add_domain: 0.1398
Current lb:-1.22536039352417
12666 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.871091365814209

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 14] [3, 14] [3, 14] [2, 75] [2, 75] [2, 75] [3, 14] [3, 14] [2, 75] [1, 29] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 295.92889404296875 with beta sum per layer: [1122.9296875, 1231.2537841796875, 484.5731506347656, 736.9215087890625, 4253.146484375]
alpha/beta optimization time: 0.4115164279937744
This batch time : update_bounds func: 1.0405	 prepare: 0.3196	 bound: 0.4120	 transfer: 0.0119	 finalize: 0.2914
Accumulated time: update_bounds func: 10.0300	 prepare: 2.2460	 bound: 5.6416	 transfer: 0.0119	 finalize: 2.0234
batch bounding time:  1.0427112579345703
Current worst splitting domains [lb, ub] (depth):
[-1.22510,   inf] (35), [-1.18198,   inf] (35), [-1.16229,   inf] (35), [-1.12566,   inf] (35), [-1.10531,   inf] (35), [-1.10511,   inf] (35), [-1.10362,   inf] (35), [-1.08725,   inf] (35), [-1.07570,   inf] (35), [-1.04990,   inf] (35), [-1.01507,   inf] (35), [-1.01229,   inf] (35), [-0.99236,   inf] (35), [-0.98545,   inf] (35), [-0.95823,   inf] (35), [-0.95781,   inf] (35), [-0.95033,   inf] (35), [-0.94960,   inf] (35), [-0.93720,   inf] (35), [-0.92708,   inf] (35), 
length of domains: 2407
Total time: 1.7184	 pickout: 0.2039	 decision: 0.3192	 get_bound: 1.0460	 add_domain: 0.1493
Current lb:-1.2251043319702148
14714 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.641693830490112

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 29] [1, 29] [1, 29] [4, 7] [4, 7] [4, 7] [1, 29] [1, 29] [4, 7] [1, 29] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 349.5477294921875 with beta sum per layer: [1198.569091796875, 1265.2581787109375, 482.16876220703125, 889.7174072265625, 4167.7578125]
alpha/beta optimization time: 0.3791186809539795
This batch time : update_bounds func: 1.0164	 prepare: 0.3197	 bound: 0.3796	 transfer: 0.0125	 finalize: 0.2987
Accumulated time: update_bounds func: 11.0464	 prepare: 2.5656	 bound: 6.0212	 transfer: 0.0125	 finalize: 2.3221
batch bounding time:  1.018716812133789
Current worst splitting domains [lb, ub] (depth):
[-1.12541,   inf] (37), [-1.11319,   inf] (37), [-1.11162,   inf] (37), [-1.09316,   inf] (37), [-1.09283,   inf] (37), [-1.08610,   inf] (37), [-1.06407,   inf] (37), [-1.06168,   inf] (37), [-1.05988,   inf] (37), [-1.04824,   inf] (37), [-1.00633,   inf] (37), [-0.98296,   inf] (37), [-0.97792,   inf] (37), [-0.97635,   inf] (37), [-0.94800,   inf] (37), [-0.94456,   inf] (37), [-0.93693,   inf] (37), [-0.93607,   inf] (37), [-0.93289,   inf] (37), [-0.92116,   inf] (37), 
length of domains: 2894
Total time: 1.7208	 pickout: 0.2109	 decision: 0.3375	 get_bound: 1.0223	 add_domain: 0.1502
Current lb:-1.1254104375839233
16762 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 19.398464679718018

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 75] [1, 36] [2, 75] [1, 36] [1, 36] [2, 75] [2, 75] [2, 75] [0, 21] [2, 75] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 388.2333679199219 with beta sum per layer: [1283.5491943359375, 1364.89404296875, 437.08721923828125, 1029.367431640625, 3870.597900390625]
alpha/beta optimization time: 0.3799097537994385
This batch time : update_bounds func: 1.0416	 prepare: 0.3236	 bound: 0.3804	 transfer: 0.0125	 finalize: 0.3190
Accumulated time: update_bounds func: 12.0880	 prepare: 2.8893	 bound: 6.4016	 transfer: 0.0125	 finalize: 2.6411
batch bounding time:  1.0437097549438477
Current worst splitting domains [lb, ub] (depth):
[-1.12541,   inf] (39), [-1.11162,   inf] (39), [-1.09669,   inf] (39), [-1.08610,   inf] (39), [-1.07707,   inf] (39), [-1.07608,   inf] (39), [-1.06407,   inf] (39), [-1.06168,   inf] (39), [-1.04824,   inf] (39), [-1.02260,   inf] (39), [-1.00633,   inf] (39), [-0.98296,   inf] (39), [-0.97792,   inf] (39), [-0.97635,   inf] (39), [-0.94800,   inf] (39), [-0.93289,   inf] (39), [-0.92547,   inf] (39), [-0.91820,   inf] (39), [-0.91646,   inf] (39), [-0.90849,   inf] (39), 
length of domains: 3435
Total time: 1.7617	 pickout: 0.2050	 decision: 0.3465	 get_bound: 1.0471	 add_domain: 0.1631
Current lb:-1.1254104375839233
18810 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 21.195824146270752

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 7] [4, 7] [1, 69] [4, 7] [2, 43] [1, 69] [1, 36] [4, 7] [4, 7] [1, 36] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 463.8560485839844 with beta sum per layer: [1293.4725341796875, 1443.3790283203125, 352.03070068359375, 1222.0433349609375, 3985.68798828125]
alpha/beta optimization time: 0.3817775249481201
This batch time : update_bounds func: 1.0564	 prepare: 0.3229	 bound: 0.3822	 transfer: 0.0119	 finalize: 0.3334
Accumulated time: update_bounds func: 13.1445	 prepare: 3.2122	 bound: 6.7839	 transfer: 0.0119	 finalize: 2.9746
batch bounding time:  1.058610200881958
Current worst splitting domains [lb, ub] (depth):
[-1.11229,   inf] (41), [-1.09748,   inf] (41), [-1.07343,   inf] (41), [-1.07150,   inf] (41), [-1.05749,   inf] (41), [-1.04623,   inf] (41), [-1.04598,   inf] (41), [-1.03892,   inf] (41), [-1.03350,   inf] (41), [-1.00475,   inf] (41), [-0.98683,   inf] (41), [-0.95922,   inf] (41), [-0.95242,   inf] (41), [-0.94160,   inf] (41), [-0.94157,   inf] (41), [-0.93277,   inf] (41), [-0.92858,   inf] (41), [-0.89823,   inf] (41), [-0.89162,   inf] (41), [-0.88575,   inf] (41), 
length of domains: 4110
Total time: 1.7941	 pickout: 0.2051	 decision: 0.3507	 get_bound: 1.0622	 add_domain: 0.1762
Current lb:-1.112287163734436
20858 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 23.025453567504883

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 43] [1, 36] [4, 43] [2, 43] [2, 43] [4, 7] [2, 43] [2, 43] [2, 43] [2, 43] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 505.47235107421875 with beta sum per layer: [1148.1571044921875, 1390.5919189453125, 420.5948486328125, 1262.10009765625, 4239.5234375]
alpha/beta optimization time: 0.3777194023132324
This batch time : update_bounds func: 1.1039	 prepare: 0.3315	 bound: 0.3782	 transfer: 0.0122	 finalize: 0.3757
Accumulated time: update_bounds func: 14.2483	 prepare: 3.5436	 bound: 7.1621	 transfer: 0.0122	 finalize: 3.3503
batch bounding time:  1.1061725616455078
Current worst splitting domains [lb, ub] (depth):
[-1.10504,   inf] (43), [-1.07569,   inf] (43), [-1.06248,   inf] (43), [-1.06211,   inf] (43), [-1.05395,   inf] (43), [-1.03724,   inf] (43), [-1.03443,   inf] (43), [-1.02784,   inf] (43), [-1.02318,   inf] (43), [-0.99870,   inf] (43), [-0.96685,   inf] (43), [-0.93980,   inf] (43), [-0.91803,   inf] (43), [-0.91803,   inf] (43), [-0.90904,   inf] (43), [-0.89323,   inf] (43), [-0.87880,   inf] (43), [-0.87699,   inf] (43), [-0.87594,   inf] (43), [-0.87285,   inf] (43), 
length of domains: 4871
Total time: 1.9104	 pickout: 0.2353	 decision: 0.3737	 get_bound: 1.1098	 add_domain: 0.1917
Current lb:-1.105044960975647
22906 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 24.971354246139526

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 36] [2, 43] [1, 69] [1, 36] [4, 43] [1, 36] [4, 43] [2, 43] [1, 36] [4, 43] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 516.0455322265625 with beta sum per layer: [1103.637451171875, 1331.6092529296875, 550.138916015625, 1209.38818359375, 4077.363037109375]
alpha/beta optimization time: 0.3753669261932373
This batch time : update_bounds func: 0.9278	 prepare: 0.3270	 bound: 0.3758	 transfer: 0.0122	 finalize: 0.2065
Accumulated time: update_bounds func: 15.1761	 prepare: 3.8706	 bound: 7.5379	 transfer: 0.0122	 finalize: 3.5568
batch bounding time:  0.9296557903289795
Current worst splitting domains [lb, ub] (depth):
[-1.08477,   inf] (45), [-1.06874,   inf] (45), [-1.04171,   inf] (45), [-1.03916,   inf] (45), [-1.02233,   inf] (45), [-1.02231,   inf] (45), [-1.01560,   inf] (45), [-1.01332,   inf] (45), [-1.00073,   inf] (45), [-0.98717,   inf] (45), [-0.95390,   inf] (45), [-0.92801,   inf] (45), [-0.91693,   inf] (45), [-0.90390,   inf] (45), [-0.90295,   inf] (45), [-0.89631,   inf] (45), [-0.86355,   inf] (45), [-0.85718,   inf] (45), [-0.85287,   inf] (45), [-0.84658,   inf] (45), 
length of domains: 5637
Total time: 1.9174	 pickout: 0.2060	 decision: 0.3949	 get_bound: 0.9329	 add_domain: 0.3837
Current lb:-1.0847700834274292
24954 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 26.924280166625977

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 69] [1, 69] [4, 34] [1, 69] [4, 34] [4, 34] [1, 69] [1, 69] [1, 69] [1, 69] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 534.905517578125 with beta sum per layer: [1099.161376953125, 1343.210693359375, 584.5806884765625, 950.7943115234375, 3884.94677734375]
alpha/beta optimization time: 0.3963901996612549
This batch time : update_bounds func: 1.1529	 prepare: 0.3447	 bound: 0.3968	 transfer: 0.0125	 finalize: 0.3920
Accumulated time: update_bounds func: 16.3289	 prepare: 4.2153	 bound: 7.9348	 transfer: 0.0125	 finalize: 3.9488
batch bounding time:  1.155048131942749
Current worst splitting domains [lb, ub] (depth):
[-1.05718,   inf] (47), [-1.03906,   inf] (47), [-1.01371,   inf] (47), [-1.01100,   inf] (47), [-0.99491,   inf] (47), [-0.99301,   inf] (47), [-0.98586,   inf] (47), [-0.98311,   inf] (47), [-0.97138,   inf] (47), [-0.94849,   inf] (47), [-0.92779,   inf] (47), [-0.89946,   inf] (47), [-0.89207,   inf] (47), [-0.89159,   inf] (47), [-0.86983,   inf] (47), [-0.86748,   inf] (47), [-0.86105,   inf] (47), [-0.85710,   inf] (47), [-0.85393,   inf] (47), [-0.84733,   inf] (47), 
length of domains: 6436
Total time: 1.8072	 pickout: 0.2058	 decision: 0.2327	 get_bound: 1.1594	 add_domain: 0.2093
Current lb:-1.0571845769882202
27002 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 28.765641927719116

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 43] [0, 36] [2, 99] [4, 43] [2, 99] [0, 25] [4, 43] [0, 36] [0, 36] [4, 34] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 545.9160766601562 with beta sum per layer: [1027.9375, 1225.41162109375, 693.8006591796875, 746.5367431640625, 3837.654296875]
alpha/beta optimization time: 0.3789253234863281
This batch time : update_bounds func: 0.9496	 prepare: 0.3337	 bound: 0.3794	 transfer: 0.0120	 finalize: 0.2186
Accumulated time: update_bounds func: 17.2785	 prepare: 4.5490	 bound: 8.3142	 transfer: 0.0120	 finalize: 4.1675
batch bounding time:  0.9517180919647217
Current worst splitting domains [lb, ub] (depth):
[-1.04886,   inf] (49), [-1.00222,   inf] (49), [-1.00017,   inf] (49), [-0.97706,   inf] (49), [-0.97644,   inf] (49), [-0.95652,   inf] (49), [-0.95594,   inf] (49), [-0.94689,   inf] (49), [-0.93848,   inf] (49), [-0.93465,   inf] (49), [-0.93182,   inf] (49), [-0.91870,   inf] (49), [-0.91869,   inf] (49), [-0.89012,   inf] (49), [-0.85868,   inf] (49), [-0.85830,   inf] (49), [-0.85799,   inf] (49), [-0.83956,   inf] (49), [-0.83827,   inf] (49), [-0.82759,   inf] (49), 
length of domains: 7236
Total time: 2.0667	 pickout: 0.2100	 decision: 0.4354	 get_bound: 0.9551	 add_domain: 0.4662
Current lb:-1.048864483833313
29050 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 30.86727499961853

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 4] [0, 4] [4, 34] [0, 4] [0, 4] [4, 45] [0, 4] [4, 43] [4, 45] [0, 4] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 547.3578491210938 with beta sum per layer: [935.1246337890625, 1204.87841796875, 710.70654296875, 618.0556640625, 3746.822265625]
alpha/beta optimization time: 0.3788433074951172
This batch time : update_bounds func: 1.2466	 prepare: 0.3870	 bound: 0.3793	 transfer: 0.0119	 finalize: 0.4620
Accumulated time: update_bounds func: 18.5252	 prepare: 4.9360	 bound: 8.6935	 transfer: 0.0119	 finalize: 4.6295
batch bounding time:  1.2489745616912842
Current worst splitting domains [lb, ub] (depth):
[-1.03039,   inf] (51), [-0.98432,   inf] (51), [-0.97238,   inf] (51), [-0.95870,   inf] (51), [-0.95856,   inf] (51), [-0.93839,   inf] (51), [-0.93537,   inf] (51), [-0.93152,   inf] (51), [-0.91630,   inf] (51), [-0.91180,   inf] (51), [-0.90390,   inf] (51), [-0.90098,   inf] (51), [-0.90004,   inf] (51), [-0.87073,   inf] (51), [-0.84722,   inf] (51), [-0.84661,   inf] (51), [-0.83825,   inf] (51), [-0.81714,   inf] (51), [-0.80677,   inf] (51), [-0.80530,   inf] (51), 
length of domains: 8013
Total time: 1.9099	 pickout: 0.2089	 decision: 0.2324	 get_bound: 1.2524	 add_domain: 0.2163
Current lb:-1.0303928852081299
31098 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 32.81262230873108

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 34] [4, 34] [4, 43] [4, 34] [4, 45] [4, 45] [4, 34] [0, 4] [4, 45] [0, 4] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 564.0195922851562 with beta sum per layer: [889.695068359375, 1117.867919921875, 661.5628662109375, 674.98681640625, 3625.867431640625]
alpha/beta optimization time: 0.3732280731201172
This batch time : update_bounds func: 1.2191	 prepare: 0.3364	 bound: 0.3737	 transfer: 0.0120	 finalize: 0.4907
Accumulated time: update_bounds func: 19.7442	 prepare: 5.2724	 bound: 9.0672	 transfer: 0.0120	 finalize: 5.1202
batch bounding time:  1.2211830615997314
Current worst splitting domains [lb, ub] (depth):
[-1.00504,   inf] (53), [-0.96065,   inf] (53), [-0.95862,   inf] (53), [-0.93267,   inf] (53), [-0.93249,   inf] (53), [-0.91449,   inf] (53), [-0.91307,   inf] (53), [-0.90708,   inf] (53), [-0.89479,   inf] (53), [-0.89196,   inf] (53), [-0.88947,   inf] (53), [-0.87661,   inf] (53), [-0.87336,   inf] (53), [-0.84421,   inf] (53), [-0.81986,   inf] (53), [-0.81878,   inf] (53), [-0.81073,   inf] (53), [-0.80825,   inf] (53), [-0.78612,   inf] (53), [-0.77796,   inf] (53), 
length of domains: 8797
Total time: 1.9215	 pickout: 0.2310	 decision: 0.2412	 get_bound: 1.2246	 add_domain: 0.2247
Current lb:-1.005041480064392
33146 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 34.7690315246582

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 45] [0, 4] [4, 45] [0, 25] [4, 45] [0, 72] [3, 21] [0, 4] [3, 21] [0, 4] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 590.216552734375 with beta sum per layer: [814.0985107421875, 1137.08984375, 596.2651977539062, 698.45166015625, 3411.117431640625]
alpha/beta optimization time: 0.36957406997680664
This batch time : update_bounds func: 1.1903	 prepare: 0.3281	 bound: 0.3700	 transfer: 0.0117	 finalize: 0.2077
Accumulated time: update_bounds func: 20.9345	 prepare: 5.6005	 bound: 9.4372	 transfer: 0.0117	 finalize: 5.3279
batch bounding time:  1.192596435546875
Current worst splitting domains [lb, ub] (depth):
[-0.98345,   inf] (55), [-0.94279,   inf] (55), [-0.93724,   inf] (55), [-0.91132,   inf] (55), [-0.90608,   inf] (55), [-0.88891,   inf] (55), [-0.88874,   inf] (55), [-0.87598,   inf] (55), [-0.87404,   inf] (55), [-0.87179,   inf] (55), [-0.86810,   inf] (55), [-0.86581,   inf] (55), [-0.85231,   inf] (55), [-0.82257,   inf] (55), [-0.80290,   inf] (55), [-0.79984,   inf] (55), [-0.79941,   inf] (55), [-0.78861,   inf] (55), [-0.77346,   inf] (55), [-0.76916,   inf] (55), 
length of domains: 9611
Total time: 1.8746	 pickout: 0.2095	 decision: 0.2371	 get_bound: 1.1962	 add_domain: 0.2318
Current lb:-0.9834467172622681
35194 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 36.679441690444946

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 21] [0, 30] [3, 21] [3, 21] [3, 86] [1, 80] [3, 21] [2, 99] [0, 30] [0, 25] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 608.057373046875 with beta sum per layer: [781.846435546875, 1145.5714111328125, 620.0963745117188, 757.192626953125, 3156.1015625]
alpha/beta optimization time: 0.37563419342041016
This batch time : update_bounds func: 0.9377	 prepare: 0.3348	 bound: 0.3761	 transfer: 0.0128	 finalize: 0.2076
Accumulated time: update_bounds func: 21.8722	 prepare: 5.9353	 bound: 9.8133	 transfer: 0.0128	 finalize: 5.5355
batch bounding time:  0.9400570392608643
Current worst splitting domains [lb, ub] (depth):
[-0.97672,   inf] (57), [-0.93032,   inf] (57), [-0.90273,   inf] (57), [-0.90111,   inf] (57), [-0.88376,   inf] (57), [-0.87958,   inf] (57), [-0.86610,   inf] (57), [-0.85837,   inf] (57), [-0.84256,   inf] (57), [-0.83316,   inf] (57), [-0.83242,   inf] (57), [-0.82814,   inf] (57), [-0.82666,   inf] (57), [-0.82180,   inf] (57), [-0.81486,   inf] (57), [-0.81288,   inf] (57), [-0.81213,   inf] (57), [-0.81062,   inf] (57), [-0.77847,   inf] (57), [-0.75824,   inf] (57), 
length of domains: 10452
Total time: 1.9330	 pickout: 0.2082	 decision: 0.5404	 get_bound: 0.9437	 add_domain: 0.2407
Current lb:-0.9767229557037354
37242 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 38.64932823181152

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 36] [2, 99] [0, 36] [4, 45] [2, 66] [4, 45] [0, 21] [1, 80] [0, 36] [1, 80] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 596.6402587890625 with beta sum per layer: [758.775634765625, 1202.864013671875, 629.9102783203125, 793.30419921875, 2956.680908203125]
alpha/beta optimization time: 0.409137487411499
This batch time : update_bounds func: 1.1661	 prepare: 0.4935	 bound: 0.4097	 transfer: 0.0123	 finalize: 0.2442
Accumulated time: update_bounds func: 23.0383	 prepare: 6.4288	 bound: 10.2230	 transfer: 0.0123	 finalize: 5.7796
batch bounding time:  1.1681842803955078
Current worst splitting domains [lb, ub] (depth):
[-0.94691,   inf] (59), [-0.89911,   inf] (59), [-0.87541,   inf] (59), [-0.87335,   inf] (59), [-0.86702,   inf] (59), [-0.85656,   inf] (59), [-0.85608,   inf] (59), [-0.83898,   inf] (59), [-0.83682,   inf] (59), [-0.82047,   inf] (59), [-0.81449,   inf] (59), [-0.81432,   inf] (59), [-0.81219,   inf] (59), [-0.80720,   inf] (59), [-0.80500,   inf] (59), [-0.80377,   inf] (59), [-0.79161,   inf] (59), [-0.78797,   inf] (59), [-0.78484,   inf] (59), [-0.78199,   inf] (59), 
length of domains: 11290
Total time: 2.2745	 pickout: 0.2105	 decision: 0.6456	 get_bound: 1.1716	 add_domain: 0.2467
Current lb:-0.9469081163406372
39290 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 40.960580348968506

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 99] [1, 80] [3, 21] [2, 99] [1, 80] [2, 57] [0, 30] [3, 22] [3, 22] [1, 80] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 573.9183349609375 with beta sum per layer: [796.236572265625, 1400.919921875, 617.0149536132812, 837.2828369140625, 2654.5712890625]
alpha/beta optimization time: 0.37232089042663574
This batch time : update_bounds func: 0.9360	 prepare: 0.3345	 bound: 0.3728	 transfer: 0.0123	 finalize: 0.2099
Accumulated time: update_bounds func: 23.9743	 prepare: 6.7632	 bound: 10.5958	 transfer: 0.0123	 finalize: 5.9896
batch bounding time:  0.9381475448608398
Current worst splitting domains [lb, ub] (depth):
[-0.92009,   inf] (61), [-0.87630,   inf] (61), [-0.87032,   inf] (61), [-0.86420,   inf] (61), [-0.84914,   inf] (61), [-0.84318,   inf] (61), [-0.84164,   inf] (61), [-0.83250,   inf] (61), [-0.82874,   inf] (61), [-0.81017,   inf] (61), [-0.80406,   inf] (61), [-0.80012,   inf] (61), [-0.79791,   inf] (61), [-0.79695,   inf] (61), [-0.79443,   inf] (61), [-0.79075,   inf] (61), [-0.78514,   inf] (61), [-0.78094,   inf] (61), [-0.77810,   inf] (61), [-0.76641,   inf] (61), 
length of domains: 12105
Total time: 1.9812	 pickout: 0.2134	 decision: 0.5742	 get_bound: 0.9416	 add_domain: 0.2520
Current lb:-0.9200884103775024
41338 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 42.97905993461609

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 68] [0, 25] [1, 80] [2, 99] [3, 22] [1, 68] [0, 36] [0, 25] [3, 86] [2, 99] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 571.3573608398438 with beta sum per layer: [766.445068359375, 1578.912353515625, 639.0068969726562, 724.529052734375, 2571.41064453125]
alpha/beta optimization time: 0.37397170066833496
This batch time : update_bounds func: 0.9432	 prepare: 0.3335	 bound: 0.3744	 transfer: 0.0118	 finalize: 0.2169
Accumulated time: update_bounds func: 24.9175	 prepare: 7.0967	 bound: 10.9702	 transfer: 0.0118	 finalize: 6.2065
batch bounding time:  0.9458727836608887
Current worst splitting domains [lb, ub] (depth):
[-0.87819,   inf] (63), [-0.86098,   inf] (63), [-0.84338,   inf] (63), [-0.84163,   inf] (63), [-0.84142,   inf] (63), [-0.83551,   inf] (63), [-0.81173,   inf] (63), [-0.80572,   inf] (63), [-0.80186,   inf] (63), [-0.79660,   inf] (63), [-0.79322,   inf] (63), [-0.79205,   inf] (63), [-0.78986,   inf] (63), [-0.78599,   inf] (63), [-0.78421,   inf] (63), [-0.78195,   inf] (63), [-0.77538,   inf] (63), [-0.77210,   inf] (63), [-0.77205,   inf] (63), [-0.77027,   inf] (63), 
length of domains: 12940
Total time: 2.0555	 pickout: 0.2452	 decision: 0.6010	 get_bound: 0.9494	 add_domain: 0.2598
Current lb:-0.8781867027282715
43386 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 45.085142374038696

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 80] [0, 30] [0, 25] [3, 22] [0, 88] [1, 80] [0, 88] [2, 57] [1, 80] [2, 66] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 542.5382080078125 with beta sum per layer: [868.646728515625, 1731.243408203125, 659.2114868164062, 603.7677001953125, 2365.343505859375]
alpha/beta optimization time: 0.38279032707214355
This batch time : update_bounds func: 0.9634	 prepare: 0.3453	 bound: 0.3833	 transfer: 0.0121	 finalize: 0.2162
Accumulated time: update_bounds func: 25.8810	 prepare: 7.4420	 bound: 11.3535	 transfer: 0.0121	 finalize: 6.4227
batch bounding time:  0.9656388759613037
Current worst splitting domains [lb, ub] (depth):
[-0.85469,   inf] (65), [-0.83769,   inf] (65), [-0.82929,   inf] (65), [-0.81398,   inf] (65), [-0.80286,   inf] (65), [-0.80029,   inf] (65), [-0.79944,   inf] (65), [-0.78763,   inf] (65), [-0.78287,   inf] (65), [-0.77998,   inf] (65), [-0.77727,   inf] (65), [-0.77485,   inf] (65), [-0.77065,   inf] (65), [-0.76967,   inf] (65), [-0.76480,   inf] (65), [-0.76169,   inf] (65), [-0.75925,   inf] (65), [-0.75776,   inf] (65), [-0.75472,   inf] (65), [-0.74282,   inf] (65), 
length of domains: 13754
Total time: 2.0722	 pickout: 0.2151	 decision: 0.6265	 get_bound: 0.9690	 add_domain: 0.2616
Current lb:-0.8546906113624573
45434 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 47.200483560562134

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 25] [0, 88] [3, 22] [3, 22] [0, 88] [3, 22] [2, 66] [0, 25] [1, 80] [4, 18] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 500.5184631347656 with beta sum per layer: [917.328857421875, 1761.786865234375, 759.745849609375, 598.67041015625, 2140.95703125]
alpha/beta optimization time: 0.37621569633483887
This batch time : update_bounds func: 1.4127	 prepare: 0.3343	 bound: 0.3767	 transfer: 0.0125	 finalize: 0.2111
Accumulated time: update_bounds func: 27.2936	 prepare: 7.7763	 bound: 11.7302	 transfer: 0.0125	 finalize: 6.6338
batch bounding time:  1.4148337841033936
Current worst splitting domains [lb, ub] (depth):
[-0.82657,   inf] (67), [-0.82371,   inf] (67), [-0.82031,   inf] (67), [-0.80786,   inf] (67), [-0.79482,   inf] (67), [-0.78922,   inf] (67), [-0.77372,   inf] (67), [-0.76518,   inf] (67), [-0.76185,   inf] (67), [-0.75867,   inf] (67), [-0.75441,   inf] (67), [-0.75312,   inf] (67), [-0.75062,   inf] (67), [-0.74972,   inf] (67), [-0.74717,   inf] (67), [-0.74678,   inf] (67), [-0.74183,   inf] (67), [-0.73628,   inf] (67), [-0.72955,   inf] (67), [-0.72779,   inf] (67), 
length of domains: 14500
Total time: 2.1352	 pickout: 0.2183	 decision: 0.2432	 get_bound: 1.4183	 add_domain: 0.2555
Current lb:-0.8265673518180847
47482 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 49.37644934654236

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 66] [4, 18] [0, 88] [1, 68] [3, 86] [1, 80] [0, 88] [0, 88] [2, 70] [2, 66] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 508.05010986328125 with beta sum per layer: [982.7454833984375, 1873.9686279296875, 950.4639892578125, 605.51708984375, 1874.054443359375]
alpha/beta optimization time: 0.3837707042694092
This batch time : update_bounds func: 1.4339	 prepare: 0.3345	 bound: 0.3842	 transfer: 0.0122	 finalize: 0.6964
Accumulated time: update_bounds func: 28.7275	 prepare: 8.1109	 bound: 12.1145	 transfer: 0.0122	 finalize: 7.3303
batch bounding time:  1.4362711906433105
Current worst splitting domains [lb, ub] (depth):
[-0.81000,   inf] (69), [-0.80885,   inf] (69), [-0.80556,   inf] (69), [-0.77429,   inf] (69), [-0.77185,   inf] (69), [-0.77064,   inf] (69), [-0.76157,   inf] (69), [-0.76129,   inf] (69), [-0.75345,   inf] (69), [-0.73658,   inf] (69), [-0.73463,   inf] (69), [-0.73431,   inf] (69), [-0.73257,   inf] (69), [-0.72946,   inf] (69), [-0.72890,   inf] (69), [-0.72621,   inf] (69), [-0.72167,   inf] (69), [-0.71647,   inf] (69), [-0.70941,   inf] (69), [-0.70206,   inf] (69), 
length of domains: 15282
Total time: 2.1741	 pickout: 0.2230	 decision: 0.2463	 get_bound: 1.4399	 add_domain: 0.2648
Current lb:-0.8099974393844604
49530 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 51.59353947639465

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 56] [3, 22] [2, 66] [2, 57] [2, 76] [3, 22] [2, 70] [1, 80] [2, 66] [2, 57] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 498.8882141113281 with beta sum per layer: [997.1016845703125, 1872.7255859375, 1146.698974609375, 569.636962890625, 1715.468994140625]
alpha/beta optimization time: 0.37805724143981934
This batch time : update_bounds func: 0.9472	 prepare: 0.3386	 bound: 0.3785	 transfer: 0.0120	 finalize: 0.2116
Accumulated time: update_bounds func: 29.6747	 prepare: 8.4495	 bound: 12.4930	 transfer: 0.0120	 finalize: 7.5419
batch bounding time:  0.9493248462677002
Current worst splitting domains [lb, ub] (depth):
[-0.80432,   inf] (71), [-0.79237,   inf] (71), [-0.78146,   inf] (71), [-0.76770,   inf] (71), [-0.76557,   inf] (71), [-0.76083,   inf] (71), [-0.75171,   inf] (71), [-0.73657,   inf] (71), [-0.73055,   inf] (71), [-0.72799,   inf] (71), [-0.72621,   inf] (71), [-0.72488,   inf] (71), [-0.72360,   inf] (71), [-0.72102,   inf] (71), [-0.71710,   inf] (71), [-0.71571,   inf] (71), [-0.71490,   inf] (71), [-0.71321,   inf] (71), [-0.69539,   inf] (71), [-0.68556,   inf] (71), 
length of domains: 16047
Total time: 1.6760	 pickout: 0.2170	 decision: 0.2413	 get_bound: 0.9528	 add_domain: 0.2650
Current lb:-0.8043174147605896
51578 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 53.31288719177246

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 86] [0, 30] [4, 18] [2, 66] [0, 25] [4, 18] [2, 66] [4, 0] [2, 70] [2, 66] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 495.4298095703125 with beta sum per layer: [1043.4324951171875, 2002.98046875, 1381.925537109375, 628.808349609375, 1443.4937744140625]
alpha/beta optimization time: 0.3809337615966797
This batch time : update_bounds func: 0.9519	 prepare: 0.3390	 bound: 0.3814	 transfer: 0.0124	 finalize: 0.2124
Accumulated time: update_bounds func: 30.6265	 prepare: 8.7884	 bound: 12.8744	 transfer: 0.0124	 finalize: 7.7543
batch bounding time:  0.9540650844573975
Current worst splitting domains [lb, ub] (depth):
[-0.78489,   inf] (73), [-0.76224,   inf] (73), [-0.75888,   inf] (73), [-0.75430,   inf] (73), [-0.74180,   inf] (73), [-0.72924,   inf] (73), [-0.72833,   inf] (73), [-0.72235,   inf] (73), [-0.70981,   inf] (73), [-0.70859,   inf] (73), [-0.70733,   inf] (73), [-0.70538,   inf] (73), [-0.70477,   inf] (73), [-0.70208,   inf] (73), [-0.69312,   inf] (73), [-0.68881,   inf] (73), [-0.68199,   inf] (73), [-0.68033,   inf] (73), [-0.67711,   inf] (73), [-0.66598,   inf] (73), 
length of domains: 16797
Total time: 2.1838	 pickout: 0.2169	 decision: 0.7410	 get_bound: 0.9575	 add_domain: 0.2683
Current lb:-0.7848889827728271
53626 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 55.538949966430664

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 57] [2, 76] [0, 25] [0, 30] [4, 0] [4, 18] [4, 18] [4, 56] [0, 25] [0, 30] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 512.015869140625 with beta sum per layer: [1095.734619140625, 1997.658447265625, 1414.605712890625, 703.4012451171875, 1344.9552001953125]
alpha/beta optimization time: 0.3736104965209961
This batch time : update_bounds func: 1.4520	 prepare: 0.3333	 bound: 0.3741	 transfer: 0.0118	 finalize: 0.7262
Accumulated time: update_bounds func: 32.0785	 prepare: 9.1217	 bound: 13.2485	 transfer: 0.0118	 finalize: 8.4806
batch bounding time:  1.4544422626495361
Current worst splitting domains [lb, ub] (depth):
[-0.77668,   inf] (75), [-0.75591,   inf] (75), [-0.72704,   inf] (75), [-0.72551,   inf] (75), [-0.71312,   inf] (75), [-0.71306,   inf] (75), [-0.70983,   inf] (75), [-0.70254,   inf] (75), [-0.69295,   inf] (75), [-0.69160,   inf] (75), [-0.68578,   inf] (75), [-0.68328,   inf] (75), [-0.67513,   inf] (75), [-0.67495,   inf] (75), [-0.67494,   inf] (75), [-0.67421,   inf] (75), [-0.66944,   inf] (75), [-0.66250,   inf] (75), [-0.65675,   inf] (75), [-0.65100,   inf] (75), 
length of domains: 17569
Total time: 2.1966	 pickout: 0.2168	 decision: 0.2430	 get_bound: 1.4582	 add_domain: 0.2786
Current lb:-0.776677131652832
55674 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 57.777138233184814

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 66] [0, 36] [4, 56] [2, 76] [2, 57] [2, 70] [4, 0] [4, 0] [2, 57] [2, 76] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 522.644775390625 with beta sum per layer: [1037.771240234375, 2000.559326171875, 1468.9815673828125, 665.8564453125, 1367.540283203125]
alpha/beta optimization time: 0.375516414642334
This batch time : update_bounds func: 0.9438	 prepare: 0.3357	 bound: 0.3760	 transfer: 0.0119	 finalize: 0.2135
Accumulated time: update_bounds func: 33.0224	 prepare: 9.4574	 bound: 13.6244	 transfer: 0.0119	 finalize: 8.6941
batch bounding time:  0.9461324214935303
Current worst splitting domains [lb, ub] (depth):
[-0.76000,   inf] (77), [-0.72561,   inf] (77), [-0.71554,   inf] (77), [-0.70649,   inf] (77), [-0.70642,   inf] (77), [-0.69663,   inf] (77), [-0.69616,   inf] (77), [-0.68824,   inf] (77), [-0.68576,   inf] (77), [-0.68326,   inf] (77), [-0.67217,   inf] (77), [-0.66430,   inf] (77), [-0.66283,   inf] (77), [-0.66015,   inf] (77), [-0.65818,   inf] (77), [-0.65651,   inf] (77), [-0.65539,   inf] (77), [-0.64452,   inf] (77), [-0.64073,   inf] (77), [-0.63747,   inf] (77), 
length of domains: 18359
Total time: 2.2580	 pickout: 0.2172	 decision: 0.2445	 get_bound: 0.9497	 add_domain: 0.8467
Current lb:-0.7599971294403076
57722 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 60.07896304130554

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 30] [1, 68] [2, 57] [0, 25] [0, 88] [2, 76] [4, 56] [0, 72] [4, 0] [1, 68] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 514.6968994140625 with beta sum per layer: [1054.341552734375, 1955.957763671875, 1411.96044921875, 716.2293701171875, 1506.5469970703125]
alpha/beta optimization time: 0.3748810291290283
This batch time : update_bounds func: 0.9433	 prepare: 0.3369	 bound: 0.3753	 transfer: 0.0124	 finalize: 0.2122
Accumulated time: update_bounds func: 33.9657	 prepare: 9.7943	 bound: 13.9998	 transfer: 0.0124	 finalize: 8.9062
batch bounding time:  0.945544958114624
Current worst splitting domains [lb, ub] (depth):
[-0.72188,   inf] (79), [-0.70857,   inf] (79), [-0.69547,   inf] (79), [-0.68948,   inf] (79), [-0.68249,   inf] (79), [-0.67297,   inf] (79), [-0.67250,   inf] (79), [-0.66492,   inf] (79), [-0.65808,   inf] (79), [-0.65801,   inf] (79), [-0.65564,   inf] (79), [-0.65333,   inf] (79), [-0.65111,   inf] (79), [-0.64755,   inf] (79), [-0.64601,   inf] (79), [-0.64002,   inf] (79), [-0.63636,   inf] (79), [-0.63376,   inf] (79), [-0.63375,   inf] (79), [-0.62714,   inf] (79), 
length of domains: 19173
Total time: 1.7097	 pickout: 0.2174	 decision: 0.2450	 get_bound: 0.9494	 add_domain: 0.2979
Current lb:-0.7218819260597229
59770 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 61.83071565628052

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 70] [4, 0] [4, 0] [2, 53] [2, 57] [4, 0] [2, 70] [1, 68] [4, 56] [2, 57] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 515.56494140625 with beta sum per layer: [960.07666015625, 1818.153076171875, 1320.82958984375, 846.9698486328125, 1709.193603515625]
alpha/beta optimization time: 0.378939151763916
This batch time : update_bounds func: 1.5198	 prepare: 0.3363	 bound: 0.3794	 transfer: 0.0121	 finalize: 0.7855
Accumulated time: update_bounds func: 35.4854	 prepare: 10.1306	 bound: 14.3792	 transfer: 0.0121	 finalize: 9.6917
batch bounding time:  1.5220723152160645
Current worst splitting domains [lb, ub] (depth):
[-0.72188,   inf] (81), [-0.69518,   inf] (81), [-0.68368,   inf] (81), [-0.68306,   inf] (81), [-0.67498,   inf] (81), [-0.66716,   inf] (81), [-0.65525,   inf] (81), [-0.65075,   inf] (81), [-0.64724,   inf] (81), [-0.64644,   inf] (81), [-0.64265,   inf] (81), [-0.63732,   inf] (81), [-0.63207,   inf] (81), [-0.62834,   inf] (81), [-0.62793,   inf] (81), [-0.62570,   inf] (81), [-0.62073,   inf] (81), [-0.62010,   inf] (81), [-0.61549,   inf] (81), [-0.61524,   inf] (81), 
length of domains: 20014
Total time: 2.2953	 pickout: 0.2189	 decision: 0.2467	 get_bound: 1.5257	 add_domain: 0.3039
Current lb:-0.7218819260597229
61818 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 64.16900897026062

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 0] [3, 86] [2, 60] [4, 56] [4, 0] [3, 86] [4, 18] [0, 30] [4, 0] [1, 63] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 482.26727294921875 with beta sum per layer: [937.3424682617188, 1756.6361083984375, 1259.4910888671875, 915.8675537109375, 1656.3603515625]
alpha/beta optimization time: 0.3720076084136963
This batch time : update_bounds func: 0.9373	 prepare: 0.3345	 bound: 0.3725	 transfer: 0.0122	 finalize: 0.2113
Accumulated time: update_bounds func: 36.4227	 prepare: 10.4651	 bound: 14.7517	 transfer: 0.0122	 finalize: 9.9030
batch bounding time:  0.9397833347320557
Current worst splitting domains [lb, ub] (depth):
[-0.70863,   inf] (83), [-0.67122,   inf] (83), [-0.66460,   inf] (83), [-0.66257,   inf] (83), [-0.65386,   inf] (83), [-0.63434,   inf] (83), [-0.63404,   inf] (83), [-0.63090,   inf] (83), [-0.63040,   inf] (83), [-0.62773,   inf] (83), [-0.62073,   inf] (83), [-0.61993,   inf] (83), [-0.61861,   inf] (83), [-0.61426,   inf] (83), [-0.61227,   inf] (83), [-0.60994,   inf] (83), [-0.60269,   inf] (83), [-0.60109,   inf] (83), [-0.59284,   inf] (83), [-0.59157,   inf] (83), 
length of domains: 20820
Total time: 1.7192	 pickout: 0.2191	 decision: 0.2508	 get_bound: 0.9436	 add_domain: 0.3057
Current lb:-0.708631694316864
63866 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 65.93179273605347

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 18] [1, 68] [2, 70] [0, 30] [3, 86] [3, 86] [2, 76] [4, 56] [1, 43] [1, 68] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 486.082763671875 with beta sum per layer: [887.4063110351562, 1675.9254150390625, 1224.5452880859375, 887.9642333984375, 1808.377685546875]
alpha/beta optimization time: 0.3735675811767578
This batch time : update_bounds func: 0.9356	 prepare: 0.3325	 bound: 0.3740	 transfer: 0.0120	 finalize: 0.2106
Accumulated time: update_bounds func: 37.3583	 prepare: 10.7976	 bound: 15.1257	 transfer: 0.0120	 finalize: 10.1137
batch bounding time:  0.937847375869751
Current worst splitting domains [lb, ub] (depth):
[-0.69111,   inf] (85), [-0.65855,   inf] (85), [-0.63266,   inf] (85), [-0.62456,   inf] (85), [-0.62361,   inf] (85), [-0.62013,   inf] (85), [-0.61802,   inf] (85), [-0.60692,   inf] (85), [-0.60500,   inf] (85), [-0.60437,   inf] (85), [-0.60255,   inf] (85), [-0.59356,   inf] (85), [-0.59193,   inf] (85), [-0.59114,   inf] (85), [-0.58719,   inf] (85), [-0.58703,   inf] (85), [-0.58571,   inf] (85), [-0.58487,   inf] (85), [-0.58447,   inf] (85), [-0.58090,   inf] (85), 
length of domains: 21651
Total time: 2.3293	 pickout: 0.2186	 decision: 0.8532	 get_bound: 0.9414	 add_domain: 0.3161
Current lb:-0.6911141872406006
65914 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 68.31570267677307

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 56] [4, 56] [2, 63] [2, 53] [3, 86] [1, 68] [2, 63] [1, 93] [2, 70] [0, 36] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 464.9869079589844 with beta sum per layer: [918.7658081054688, 1611.910888671875, 1287.111328125, 843.1890258789062, 1715.0380859375]
alpha/beta optimization time: 0.3741292953491211
This batch time : update_bounds func: 1.6051	 prepare: 0.3352	 bound: 0.3746	 transfer: 0.0121	 finalize: 0.8768
Accumulated time: update_bounds func: 38.9634	 prepare: 11.1328	 bound: 15.5003	 transfer: 0.0121	 finalize: 10.9905
batch bounding time:  1.6077635288238525
Current worst splitting domains [lb, ub] (depth):
[-0.66003,   inf] (87), [-0.62933,   inf] (87), [-0.61921,   inf] (87), [-0.60395,   inf] (87), [-0.60374,   inf] (87), [-0.60331,   inf] (87), [-0.60008,   inf] (87), [-0.59622,   inf] (87), [-0.59508,   inf] (87), [-0.59041,   inf] (87), [-0.59040,   inf] (87), [-0.58987,   inf] (87), [-0.58955,   inf] (87), [-0.58792,   inf] (87), [-0.58242,   inf] (87), [-0.58242,   inf] (87), [-0.57953,   inf] (87), [-0.57717,   inf] (87), [-0.57501,   inf] (87), [-0.56764,   inf] (87), 
length of domains: 22443
Total time: 2.3845	 pickout: 0.2168	 decision: 0.2457	 get_bound: 1.6117	 add_domain: 0.3103
Current lb:-0.6600320339202881
67962 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 70.75552368164062

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 93] [2, 53] [2, 70] [1, 43] [4, 50] [1, 43] [2, 76] [2, 63] [2, 70] [4, 56] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 472.3993225097656 with beta sum per layer: [822.2177734375, 1672.841552734375, 1269.215576171875, 950.8026123046875, 1712.55078125]
alpha/beta optimization time: 0.37711334228515625
This batch time : update_bounds func: 0.9415	 prepare: 0.3316	 bound: 0.3776	 transfer: 0.0123	 finalize: 0.2139
Accumulated time: update_bounds func: 39.9050	 prepare: 11.4644	 bound: 15.8779	 transfer: 0.0123	 finalize: 11.2044
batch bounding time:  0.9437763690948486
Current worst splitting domains [lb, ub] (depth):
[-0.63796,   inf] (89), [-0.62250,   inf] (89), [-0.61921,   inf] (89), [-0.59425,   inf] (89), [-0.58490,   inf] (89), [-0.58242,   inf] (89), [-0.58013,   inf] (89), [-0.57860,   inf] (89), [-0.57723,   inf] (89), [-0.57336,   inf] (89), [-0.56970,   inf] (89), [-0.56874,   inf] (89), [-0.56213,   inf] (89), [-0.56211,   inf] (89), [-0.55949,   inf] (89), [-0.55881,   inf] (89), [-0.55586,   inf] (89), [-0.55430,   inf] (89), [-0.55300,   inf] (89), [-0.55208,   inf] (89), 
length of domains: 23262
Total time: 1.7370	 pickout: 0.2263	 decision: 0.2444	 get_bound: 0.9473	 add_domain: 0.3189
Current lb:-0.6379609704017639
70010 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 72.53568840026855

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 53] [4, 50] [1, 43] [1, 43] [1, 93] [4, 56] [4, 50] [1, 43] [1, 93] [1, 43] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 458.8153076171875 with beta sum per layer: [808.9412231445312, 1555.69775390625, 1284.5755615234375, 1096.2264404296875, 1773.38671875]
alpha/beta optimization time: 0.38367629051208496
This batch time : update_bounds func: 1.7254	 prepare: 0.3317	 bound: 0.3842	 transfer: 0.0120	 finalize: 0.9915
Accumulated time: update_bounds func: 41.6304	 prepare: 11.7961	 bound: 16.2621	 transfer: 0.0120	 finalize: 12.1959
batch bounding time:  1.727663516998291
Current worst splitting domains [lb, ub] (depth):
[-0.63204,   inf] (91), [-0.60094,   inf] (91), [-0.59605,   inf] (91), [-0.57606,   inf] (91), [-0.57605,   inf] (91), [-0.56342,   inf] (91), [-0.56206,   inf] (91), [-0.55723,   inf] (91), [-0.55482,   inf] (91), [-0.55336,   inf] (91), [-0.55271,   inf] (91), [-0.55208,   inf] (91), [-0.54375,   inf] (91), [-0.54184,   inf] (91), [-0.54098,   inf] (91), [-0.53645,   inf] (91), [-0.53325,   inf] (91), [-0.53262,   inf] (91), [-0.53192,   inf] (91), [-0.53087,   inf] (91), 
length of domains: 24089
Total time: 2.5155	 pickout: 0.2204	 decision: 0.2392	 get_bound: 1.7312	 add_domain: 0.3248
Current lb:-0.6320364475250244
72058 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 75.09165287017822

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 43] [2, 63] [2, 63] [2, 53] [1, 68] [0, 25] [2, 53] [2, 93] [4, 56] [1, 93] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 464.406005859375 with beta sum per layer: [813.1956787109375, 1551.275390625, 1302.41259765625, 1146.13671875, 1576.17041015625]
alpha/beta optimization time: 0.38162755966186523
This batch time : update_bounds func: 0.9692	 prepare: 0.3361	 bound: 0.3821	 transfer: 0.0127	 finalize: 0.2314
Accumulated time: update_bounds func: 42.5995	 prepare: 12.1322	 bound: 16.6442	 transfer: 0.0127	 finalize: 12.4272
batch bounding time:  0.971930742263794
Current worst splitting domains [lb, ub] (depth):
[-0.61487,   inf] (93), [-0.57261,   inf] (93), [-0.56895,   inf] (93), [-0.56603,   inf] (93), [-0.55472,   inf] (93), [-0.54969,   inf] (93), [-0.54841,   inf] (93), [-0.53535,   inf] (93), [-0.53477,   inf] (93), [-0.53255,   inf] (93), [-0.52583,   inf] (93), [-0.52546,   inf] (93), [-0.52543,   inf] (93), [-0.52327,   inf] (93), [-0.52273,   inf] (93), [-0.52112,   inf] (93), [-0.52013,   inf] (93), [-0.51677,   inf] (93), [-0.51273,   inf] (93), [-0.51219,   inf] (93), 
length of domains: 24935
Total time: 1.7946	 pickout: 0.2259	 decision: 0.2489	 get_bound: 0.9765	 add_domain: 0.3433
Current lb:-0.6148664355278015
74106 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 76.93327903747559

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 76] [4, 50] [2, 63] [2, 93] [4, 56] [1, 63] [2, 60] [2, 63] [1, 7] [1, 63] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 448.8676452636719 with beta sum per layer: [832.9093627929688, 1578.739013671875, 1389.821044921875, 1163.419189453125, 1436.5257568359375]
alpha/beta optimization time: 0.3887026309967041
This batch time : update_bounds func: 1.7897	 prepare: 0.3413	 bound: 0.3892	 transfer: 0.0121	 finalize: 1.0404
Accumulated time: update_bounds func: 44.3892	 prepare: 12.4735	 bound: 17.0334	 transfer: 0.0121	 finalize: 13.4676
batch bounding time:  1.7921955585479736
Current worst splitting domains [lb, ub] (depth):
[-0.60621,   inf] (95), [-0.54447,   inf] (95), [-0.53917,   inf] (95), [-0.53689,   inf] (95), [-0.53423,   inf] (95), [-0.53304,   inf] (95), [-0.52809,   inf] (95), [-0.52668,   inf] (95), [-0.52341,   inf] (95), [-0.52312,   inf] (95), [-0.51323,   inf] (95), [-0.51281,   inf] (95), [-0.51133,   inf] (95), [-0.50770,   inf] (95), [-0.50680,   inf] (95), [-0.50621,   inf] (95), [-0.50058,   inf] (95), [-0.49917,   inf] (95), [-0.49734,   inf] (95), [-0.49502,   inf] (95), 
length of domains: 25755
Total time: 2.6092	 pickout: 0.2303	 decision: 0.2504	 get_bound: 1.7961	 add_domain: 0.3325
Current lb:-0.6062139868736267
76154 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 79.58573317527771

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 63] [2, 60] [1, 93] [1, 63] [2, 93] [1, 68] [2, 60] [1, 63] [2, 63] [4, 50] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 451.6706848144531 with beta sum per layer: [793.0131225585938, 1664.0908203125, 1391.85986328125, 1115.744873046875, 1345.6231689453125]
alpha/beta optimization time: 0.39292311668395996
This batch time : update_bounds func: 0.9695	 prepare: 0.3431	 bound: 0.3934	 transfer: 0.0122	 finalize: 0.2140
Accumulated time: update_bounds func: 45.3587	 prepare: 12.8166	 bound: 17.4268	 transfer: 0.0122	 finalize: 13.6816
batch bounding time:  0.9720017910003662
Current worst splitting domains [lb, ub] (depth):
[-0.57608,   inf] (97), [-0.56385,   inf] (97), [-0.53109,   inf] (97), [-0.51731,   inf] (97), [-0.51466,   inf] (97), [-0.51217,   inf] (97), [-0.50568,   inf] (97), [-0.50439,   inf] (97), [-0.50310,   inf] (97), [-0.50194,   inf] (97), [-0.49995,   inf] (97), [-0.49819,   inf] (97), [-0.49465,   inf] (97), [-0.49330,   inf] (97), [-0.49329,   inf] (97), [-0.49315,   inf] (97), [-0.48792,   inf] (97), [-0.48299,   inf] (97), [-0.48081,   inf] (97), [-0.48011,   inf] (97), 
length of domains: 26589
Total time: 1.7915	 pickout: 0.2257	 decision: 0.2489	 get_bound: 0.9758	 add_domain: 0.3411
Current lb:-0.576078474521637
78202 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 81.42302656173706

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 50] [1, 63] [2, 56] [4, 50] [1, 49] [2, 60] [2, 63] [2, 60] [1, 93] [1, 49] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 436.05596923828125 with beta sum per layer: [757.8349609375, 1628.344482421875, 1355.5047607421875, 1158.0872802734375, 1429.7611083984375]
alpha/beta optimization time: 0.3780193328857422
This batch time : update_bounds func: 1.8184	 prepare: 0.3392	 bound: 0.3785	 transfer: 0.0120	 finalize: 1.0816
Accumulated time: update_bounds func: 47.1771	 prepare: 13.1559	 bound: 17.8053	 transfer: 0.0120	 finalize: 14.7632
batch bounding time:  1.8209407329559326
Current worst splitting domains [lb, ub] (depth):
[-0.54961,   inf] (99), [-0.54139,   inf] (99), [-0.53098,   inf] (99), [-0.51907,   inf] (99), [-0.49932,   inf] (99), [-0.49364,   inf] (99), [-0.49023,   inf] (99), [-0.48911,   inf] (99), [-0.48231,   inf] (99), [-0.47971,   inf] (99), [-0.47899,   inf] (99), [-0.47450,   inf] (99), [-0.47300,   inf] (99), [-0.47289,   inf] (99), [-0.47081,   inf] (99), [-0.46693,   inf] (99), [-0.46659,   inf] (99), [-0.46644,   inf] (99), [-0.46521,   inf] (99), [-0.46469,   inf] (99), 
length of domains: 27408
Total time: 2.6441	 pickout: 0.2277	 decision: 0.2535	 get_bound: 1.8249	 add_domain: 0.3380
Current lb:-0.549610435962677
80250 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 84.11154174804688

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 60] [2, 93] [2, 60] [1, 93] [2, 56] [0, 25] [2, 56] [2, 60] [1, 52] [2, 60] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 422.64422607421875 with beta sum per layer: [708.1251220703125, 1728.940673828125, 1464.123046875, 1123.48095703125, 1264.4306640625]
alpha/beta optimization time: 0.384690523147583
This batch time : update_bounds func: 0.9620	 prepare: 0.3433	 bound: 0.3852	 transfer: 0.0122	 finalize: 0.2148
Accumulated time: update_bounds func: 48.1391	 prepare: 13.4991	 bound: 18.1904	 transfer: 0.0122	 finalize: 14.9780
batch bounding time:  0.9644162654876709
Current worst splitting domains [lb, ub] (depth):
[-0.53673,   inf] (101), [-0.51766,   inf] (101), [-0.51157,   inf] (101), [-0.50304,   inf] (101), [-0.49717,   inf] (101), [-0.48581,   inf] (101), [-0.47882,   inf] (101), [-0.47689,   inf] (101), [-0.47562,   inf] (101), [-0.47387,   inf] (101), [-0.46996,   inf] (101), [-0.46926,   inf] (101), [-0.46534,   inf] (101), [-0.45890,   inf] (101), [-0.45774,   inf] (101), [-0.45664,   inf] (101), [-0.45277,   inf] (101), [-0.45023,   inf] (101), [-0.44700,   inf] (101), [-0.44648,   inf] (101), 
length of domains: 28209
Total time: 1.7757	 pickout: 0.2240	 decision: 0.2469	 get_bound: 0.9683	 add_domain: 0.3365
Current lb:-0.536730170249939
82298 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 85.93358397483826

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 56] [2, 93] [2, 60] [2, 60] [2, 93] [2, 7] [4, 68] [0, 25] [2, 56] [2, 79] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 423.0440979003906 with beta sum per layer: [662.6180419921875, 1937.9715576171875, 1555.95703125, 931.1481323242188, 1152.968505859375]
alpha/beta optimization time: 0.39214324951171875
This batch time : update_bounds func: 0.9698	 prepare: 0.3410	 bound: 0.3926	 transfer: 0.0123	 finalize: 0.2171
Accumulated time: update_bounds func: 49.1089	 prepare: 13.8401	 bound: 18.5831	 transfer: 0.0123	 finalize: 15.1951
batch bounding time:  0.9720840454101562
Current worst splitting domains [lb, ub] (depth):
[-0.52599,   inf] (103), [-0.49862,   inf] (103), [-0.48948,   inf] (103), [-0.48924,   inf] (103), [-0.48641,   inf] (103), [-0.47386,   inf] (103), [-0.46988,   inf] (103), [-0.46485,   inf] (103), [-0.46367,   inf] (103), [-0.46156,   inf] (103), [-0.46062,   inf] (103), [-0.45420,   inf] (103), [-0.45313,   inf] (103), [-0.45222,   inf] (103), [-0.44862,   inf] (103), [-0.44339,   inf] (103), [-0.43747,   inf] (103), [-0.43669,   inf] (103), [-0.43644,   inf] (103), [-0.43132,   inf] (103), 
length of domains: 29032
Total time: 2.7401	 pickout: 0.2263	 decision: 0.2506	 get_bound: 0.9758	 add_domain: 1.2874
Current lb:-0.5259859561920166
84346 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 88.71988272666931

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 68] [1, 52] [4, 68] [4, 68] [4, 68] [1, 63] [4, 68] [1, 93] [4, 68] [1, 52] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 394.7733154296875 with beta sum per layer: [563.76220703125, 1887.23876953125, 1626.6346435546875, 975.4964599609375, 1221.2265625]
alpha/beta optimization time: 0.38603854179382324
This batch time : update_bounds func: 0.9656	 prepare: 0.3436	 bound: 0.3865	 transfer: 0.0123	 finalize: 0.2164
Accumulated time: update_bounds func: 50.0745	 prepare: 14.1837	 bound: 18.9696	 transfer: 0.0123	 finalize: 15.4115
batch bounding time:  0.9679882526397705
Current worst splitting domains [lb, ub] (depth):
[-0.52142,   inf] (105), [-0.48485,   inf] (105), [-0.48349,   inf] (105), [-0.48120,   inf] (105), [-0.47296,   inf] (105), [-0.46496,   inf] (105), [-0.45854,   inf] (105), [-0.45552,   inf] (105), [-0.44604,   inf] (105), [-0.44474,   inf] (105), [-0.43816,   inf] (105), [-0.43318,   inf] (105), [-0.43158,   inf] (105), [-0.42137,   inf] (105), [-0.41933,   inf] (105), [-0.41733,   inf] (105), [-0.41617,   inf] (105), [-0.41318,   inf] (105), [-0.41091,   inf] (105), [-0.41063,   inf] (105), 
length of domains: 29804
Total time: 1.7819	 pickout: 0.2216	 decision: 0.2486	 get_bound: 0.9718	 add_domain: 0.3399
Current lb:-0.5214173793792725
86394 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 90.54944133758545

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 93] [2, 56] [2, 79] [2, 79] [4, 50] [1, 49] [2, 93] [1, 63] [2, 79] [1, 7] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 389.7872314453125 with beta sum per layer: [565.9727172851562, 1905.6539306640625, 1631.287353515625, 852.609130859375, 1339.392822265625]
alpha/beta optimization time: 0.38004255294799805
This batch time : update_bounds func: 0.9648	 prepare: 0.3466	 bound: 0.3805	 transfer: 0.0120	 finalize: 0.2183
Accumulated time: update_bounds func: 51.0393	 prepare: 14.5303	 bound: 19.3501	 transfer: 0.0120	 finalize: 15.6298
batch bounding time:  0.967266321182251
Current worst splitting domains [lb, ub] (depth):
[-0.49262,   inf] (107), [-0.48702,   inf] (107), [-0.47367,   inf] (107), [-0.45966,   inf] (107), [-0.45836,   inf] (107), [-0.44363,   inf] (107), [-0.44362,   inf] (107), [-0.43316,   inf] (107), [-0.43160,   inf] (107), [-0.43146,   inf] (107), [-0.42575,   inf] (107), [-0.42358,   inf] (107), [-0.41588,   inf] (107), [-0.41306,   inf] (107), [-0.40942,   inf] (107), [-0.40940,   inf] (107), [-0.40859,   inf] (107), [-0.40329,   inf] (107), [-0.40253,   inf] (107), [-0.40246,   inf] (107), 
length of domains: 30586
Total time: 1.7904	 pickout: 0.2247	 decision: 0.2530	 get_bound: 0.9711	 add_domain: 0.3416
Current lb:-0.49262261390686035
88442 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 92.38372778892517

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 49] [1, 63] [4, 50] [1, 49] [1, 49] [4, 68] [0, 25] [2, 7] [4, 68] [2, 7] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 373.0107421875 with beta sum per layer: [548.1041870117188, 1714.47509765625, 1752.548583984375, 773.2000732421875, 1376.2066650390625]
alpha/beta optimization time: 0.3946495056152344
This batch time : update_bounds func: 1.9276	 prepare: 0.3453	 bound: 0.3952	 transfer: 0.0121	 finalize: 0.2176
Accumulated time: update_bounds func: 52.9669	 prepare: 14.8756	 bound: 19.7453	 transfer: 0.0121	 finalize: 15.8475
batch bounding time:  1.9299840927124023
Current worst splitting domains [lb, ub] (depth):
[-0.47062,   inf] (109), [-0.46279,   inf] (109), [-0.44346,   inf] (109), [-0.43898,   inf] (109), [-0.43602,   inf] (109), [-0.43370,   inf] (109), [-0.43365,   inf] (109), [-0.42599,   inf] (109), [-0.41911,   inf] (109), [-0.41288,   inf] (109), [-0.40988,   inf] (109), [-0.40410,   inf] (109), [-0.39914,   inf] (109), [-0.39893,   inf] (109), [-0.39861,   inf] (109), [-0.39396,   inf] (109), [-0.39363,   inf] (109), [-0.39157,   inf] (109), [-0.39004,   inf] (109), [-0.38930,   inf] (109), 
length of domains: 31349
Total time: 2.7685	 pickout: 0.2299	 decision: 0.2598	 get_bound: 1.9339	 add_domain: 0.3450
Current lb:-0.47061991691589355
90490 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 95.20113611221313

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 67] [2, 7] [2, 7] [2, 7] [4, 67] [2, 79] [2, 7] [2, 79] [1, 63] [4, 67] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 359.09637451171875 with beta sum per layer: [581.463134765625, 1837.819580078125, 1662.9683837890625, 805.0542602539062, 1519.1654052734375]
alpha/beta optimization time: 0.39032840728759766
This batch time : update_bounds func: 0.9772	 prepare: 0.3484	 bound: 0.3908	 transfer: 0.0121	 finalize: 0.2188
Accumulated time: update_bounds func: 53.9441	 prepare: 15.2241	 bound: 20.1361	 transfer: 0.0121	 finalize: 16.0663
batch bounding time:  0.9795804023742676
Current worst splitting domains [lb, ub] (depth):
[-0.44375,   inf] (111), [-0.43989,   inf] (111), [-0.43732,   inf] (111), [-0.42433,   inf] (111), [-0.42075,   inf] (111), [-0.41671,   inf] (111), [-0.41558,   inf] (111), [-0.41246,   inf] (111), [-0.40583,   inf] (111), [-0.40467,   inf] (111), [-0.40320,   inf] (111), [-0.40166,   inf] (111), [-0.39853,   inf] (111), [-0.38654,   inf] (111), [-0.38351,   inf] (111), [-0.38153,   inf] (111), [-0.38146,   inf] (111), [-0.38088,   inf] (111), [-0.37673,   inf] (111), [-0.37647,   inf] (111), 
length of domains: 32116
Total time: 1.8065	 pickout: 0.2239	 decision: 0.2546	 get_bound: 0.9834	 add_domain: 0.3445
Current lb:-0.4437505006790161
92538 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 97.0519802570343

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 79] [2, 79] [4, 67] [1, 49] [4, 67] [0, 29] [3, 0] [4, 67] [4, 71] [2, 7] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 351.288330078125 with beta sum per layer: [553.8997802734375, 1773.236572265625, 1694.40771484375, 776.4170532226562, 1617.7548828125]
alpha/beta optimization time: 0.39144277572631836
This batch time : update_bounds func: 0.9834	 prepare: 0.3527	 bound: 0.3919	 transfer: 0.0123	 finalize: 0.2192
Accumulated time: update_bounds func: 54.9275	 prepare: 15.5768	 bound: 20.5280	 transfer: 0.0123	 finalize: 16.2855
batch bounding time:  0.986203670501709
Current worst splitting domains [lb, ub] (depth):
[-0.42109,   inf] (113), [-0.41912,   inf] (113), [-0.40814,   inf] (113), [-0.40554,   inf] (113), [-0.39849,   inf] (113), [-0.39508,   inf] (113), [-0.39491,   inf] (113), [-0.39439,   inf] (113), [-0.39162,   inf] (113), [-0.38650,   inf] (113), [-0.38423,   inf] (113), [-0.38286,   inf] (113), [-0.38270,   inf] (113), [-0.37846,   inf] (113), [-0.37791,   inf] (113), [-0.36571,   inf] (113), [-0.36443,   inf] (113), [-0.36390,   inf] (113), [-0.36284,   inf] (113), [-0.35793,   inf] (113), 
length of domains: 32893
Total time: 2.8621	 pickout: 0.2291	 decision: 0.2555	 get_bound: 0.9903	 add_domain: 1.3871
Current lb:-0.4210916757583618
94586 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 99.96261596679688

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 63] [1, 63] [2, 79] [2, 79] [4, 71] [1, 63] [4, 67] [4, 67] [2, 79] [2, 79] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 325.52850341796875 with beta sum per layer: [620.26513671875, 1753.5283203125, 1566.051025390625, 847.340087890625, 1840.114990234375]
alpha/beta optimization time: 0.3773369789123535
This batch time : update_bounds func: 0.9652	 prepare: 0.3396	 bound: 0.3778	 transfer: 0.0121	 finalize: 0.2285
Accumulated time: update_bounds func: 55.8927	 prepare: 15.9164	 bound: 20.9058	 transfer: 0.0121	 finalize: 16.5140
batch bounding time:  0.967972993850708
Current worst splitting domains [lb, ub] (depth):
[-0.40286,   inf] (115), [-0.40167,   inf] (115), [-0.38790,   inf] (115), [-0.38732,   inf] (115), [-0.38227,   inf] (115), [-0.37761,   inf] (115), [-0.37268,   inf] (115), [-0.37163,   inf] (115), [-0.36444,   inf] (115), [-0.36341,   inf] (115), [-0.36210,   inf] (115), [-0.36159,   inf] (115), [-0.35955,   inf] (115), [-0.35718,   inf] (115), [-0.35587,   inf] (115), [-0.35466,   inf] (115), [-0.35257,   inf] (115), [-0.35000,   inf] (115), [-0.34646,   inf] (115), [-0.34557,   inf] (115), 
length of domains: 33650
Total time: 1.7938	 pickout: 0.2306	 decision: 0.2520	 get_bound: 0.9721	 add_domain: 0.3391
Current lb:-0.40286388993263245
96634 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 101.79968905448914

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 7] [1, 52] [1, 52] [4, 71] [3, 38] [3, 0] [1, 52] [1, 7] [3, 38] [1, 7] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 312.8114013671875 with beta sum per layer: [691.5218505859375, 1814.240234375, 1526.80810546875, 921.009521484375, 1840.31201171875]
alpha/beta optimization time: 0.381361722946167
This batch time : update_bounds func: 0.9867	 prepare: 0.3655	 bound: 0.3818	 transfer: 0.0124	 finalize: 0.2194
Accumulated time: update_bounds func: 56.8794	 prepare: 16.2819	 bound: 21.2877	 transfer: 0.0124	 finalize: 16.7333
batch bounding time:  0.9889030456542969
Current worst splitting domains [lb, ub] (depth):
[-0.38096,   inf] (117), [-0.37924,   inf] (117), [-0.37675,   inf] (117), [-0.36767,   inf] (117), [-0.36149,   inf] (117), [-0.35481,   inf] (117), [-0.35326,   inf] (117), [-0.35180,   inf] (117), [-0.35100,   inf] (117), [-0.34574,   inf] (117), [-0.34328,   inf] (117), [-0.33964,   inf] (117), [-0.33750,   inf] (117), [-0.33393,   inf] (117), [-0.33207,   inf] (117), [-0.33024,   inf] (117), [-0.33016,   inf] (117), [-0.32947,   inf] (117), [-0.32940,   inf] (117), [-0.32910,   inf] (117), 
length of domains: 34376
Total time: 1.7962	 pickout: 0.2255	 decision: 0.2516	 get_bound: 0.9926	 add_domain: 0.3265
Current lb:-0.38096240162849426
98682 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 103.6398286819458

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 52] [2, 7] [1, 7] [0, 89] [4, 28] [2, 82] [4, 71] [2, 7] [2, 7] [2, 56] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 296.4779968261719 with beta sum per layer: [694.6014404296875, 1806.580322265625, 1506.1553955078125, 950.0555419921875, 2028.2685546875]
alpha/beta optimization time: 0.38517165184020996
This batch time : update_bounds func: 2.0555	 prepare: 0.3436	 bound: 0.3857	 transfer: 0.0123	 finalize: 1.3066
Accumulated time: update_bounds func: 58.9349	 prepare: 16.6255	 bound: 21.6733	 transfer: 0.0123	 finalize: 18.0400
batch bounding time:  2.0577361583709717
Current worst splitting domains [lb, ub] (depth):
[-0.36070,   inf] (119), [-0.36000,   inf] (119), [-0.35659,   inf] (119), [-0.35500,   inf] (119), [-0.35035,   inf] (119), [-0.34298,   inf] (119), [-0.33365,   inf] (119), [-0.33152,   inf] (119), [-0.33098,   inf] (119), [-0.32724,   inf] (119), [-0.32062,   inf] (119), [-0.31921,   inf] (119), [-0.31897,   inf] (119), [-0.31464,   inf] (119), [-0.31177,   inf] (119), [-0.31150,   inf] (119), [-0.31103,   inf] (119), [-0.30754,   inf] (119), [-0.30627,   inf] (119), [-0.30461,   inf] (119), 
length of domains: 35105
Total time: 2.8670	 pickout: 0.2261	 decision: 0.2523	 get_bound: 2.0615	 add_domain: 0.3271
Current lb:-0.36069607734680176
100730 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 106.55066204071045

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 82] [4, 71] [2, 40] [0, 89] [2, 40] [1, 52] [2, 79] [1, 49] [4, 28] [2, 40] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 289.8544921875 with beta sum per layer: [718.4251708984375, 1830.96484375, 1585.5068359375, 1018.6722412109375, 2109.966064453125]
alpha/beta optimization time: 0.38114500045776367
This batch time : update_bounds func: 0.9638	 prepare: 0.3436	 bound: 0.3816	 transfer: 0.0122	 finalize: 0.2189
Accumulated time: update_bounds func: 59.8986	 prepare: 16.9691	 bound: 22.0550	 transfer: 0.0122	 finalize: 18.2589
batch bounding time:  0.9659616947174072
Current worst splitting domains [lb, ub] (depth):
[-0.34948,   inf] (121), [-0.34613,   inf] (121), [-0.34417,   inf] (121), [-0.33905,   inf] (121), [-0.33800,   inf] (121), [-0.32210,   inf] (121), [-0.31920,   inf] (121), [-0.31314,   inf] (121), [-0.31209,   inf] (121), [-0.30779,   inf] (121), [-0.30039,   inf] (121), [-0.29881,   inf] (121), [-0.29875,   inf] (121), [-0.29844,   inf] (121), [-0.29643,   inf] (121), [-0.29307,   inf] (121), [-0.29270,   inf] (121), [-0.29163,   inf] (121), [-0.28878,   inf] (121), [-0.28627,   inf] (121), 
length of domains: 35848
Total time: 1.7715	 pickout: 0.2263	 decision: 0.2531	 get_bound: 0.9696	 add_domain: 0.3224
Current lb:-0.349484920501709
102778 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 108.36644673347473

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 89] [1, 49] [4, 28] [1, 52] [2, 82] [4, 28] [1, 7] [1, 7] [2, 82] [3, 0] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 274.37945556640625 with beta sum per layer: [849.2393798828125, 1828.5765380859375, 1516.9368896484375, 976.1210327148438, 2153.39599609375]
alpha/beta optimization time: 0.37955713272094727
This batch time : update_bounds func: 0.9606	 prepare: 0.3415	 bound: 0.3800	 transfer: 0.0124	 finalize: 0.2188
Accumulated time: update_bounds func: 60.8592	 prepare: 17.3105	 bound: 22.4350	 transfer: 0.0124	 finalize: 18.4778
batch bounding time:  0.9629294872283936
Current worst splitting domains [lb, ub] (depth):
[-0.33701,   inf] (123), [-0.33268,   inf] (123), [-0.32878,   inf] (123), [-0.32026,   inf] (123), [-0.31475,   inf] (123), [-0.31103,   inf] (123), [-0.30240,   inf] (123), [-0.29589,   inf] (123), [-0.29510,   inf] (123), [-0.28928,   inf] (123), [-0.28864,   inf] (123), [-0.27997,   inf] (123), [-0.27961,   inf] (123), [-0.27867,   inf] (123), [-0.27574,   inf] (123), [-0.27558,   inf] (123), [-0.27241,   inf] (123), [-0.27203,   inf] (123), [-0.27117,   inf] (123), [-0.27095,   inf] (123), 
length of domains: 36555
Total time: 1.7700	 pickout: 0.2261	 decision: 0.2574	 get_bound: 0.9668	 add_domain: 0.3197
Current lb:-0.33700892329216003
104826 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 110.19495368003845

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 28] [4, 67] [4, 28] [2, 7] [0, 29] [2, 82] [3, 0] [4, 71] [2, 56] [1, 7] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 260.58099365234375 with beta sum per layer: [725.2718505859375, 1830.99267578125, 1493.5892333984375, 1138.614501953125, 2336.6337890625]
alpha/beta optimization time: 0.3828587532043457
This batch time : update_bounds func: 0.9777	 prepare: 0.3503	 bound: 0.3833	 transfer: 0.0122	 finalize: 0.2240
Accumulated time: update_bounds func: 61.8369	 prepare: 17.6608	 bound: 22.8184	 transfer: 0.0122	 finalize: 18.7018
batch bounding time:  0.9801020622253418
Current worst splitting domains [lb, ub] (depth):
[-0.32495,   inf] (125), [-0.31608,   inf] (125), [-0.30494,   inf] (125), [-0.30114,   inf] (125), [-0.29659,   inf] (125), [-0.29099,   inf] (125), [-0.28838,   inf] (125), [-0.28692,   inf] (125), [-0.28607,   inf] (125), [-0.28490,   inf] (125), [-0.28028,   inf] (125), [-0.26905,   inf] (125), [-0.26821,   inf] (125), [-0.26728,   inf] (125), [-0.26550,   inf] (125), [-0.26377,   inf] (125), [-0.26110,   inf] (125), [-0.25950,   inf] (125), [-0.25620,   inf] (125), [-0.25403,   inf] (125), 
length of domains: 37236
Total time: 3.0176	 pickout: 0.2223	 decision: 1.5009	 get_bound: 0.9840	 add_domain: 0.3104
Current lb:-0.32494989037513733
106874 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 113.26431941986084

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 82] [1, 52] [0, 29] [4, 20] [2, 59] [3, 38] [2, 40] [2, 82] [4, 98] [2, 82] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 261.121337890625 with beta sum per layer: [784.0775146484375, 1771.843017578125, 1621.45751953125, 1155.493896484375, 2249.05029296875]
alpha/beta optimization time: 0.4003915786743164
This batch time : update_bounds func: 1.0048	 prepare: 0.3575	 bound: 0.4009	 transfer: 0.0122	 finalize: 0.2261
Accumulated time: update_bounds func: 62.8417	 prepare: 18.0183	 bound: 23.2193	 transfer: 0.0122	 finalize: 18.9279
batch bounding time:  1.0072133541107178
Current worst splitting domains [lb, ub] (depth):
[-0.30868,   inf] (127), [-0.29530,   inf] (127), [-0.29191,   inf] (127), [-0.29107,   inf] (127), [-0.28339,   inf] (127), [-0.27815,   inf] (127), [-0.26817,   inf] (127), [-0.26704,   inf] (127), [-0.26375,   inf] (127), [-0.26234,   inf] (127), [-0.26086,   inf] (127), [-0.25418,   inf] (127), [-0.25312,   inf] (127), [-0.25004,   inf] (127), [-0.24910,   inf] (127), [-0.24877,   inf] (67), [-0.24826,   inf] (65), [-0.24820,   inf] (65), [-0.24795,   inf] (127), [-0.24714,   inf] (127), 
length of domains: 37923
Total time: 1.8230	 pickout: 0.2315	 decision: 0.2682	 get_bound: 1.0111	 add_domain: 0.3123
Current lb:-0.3086772561073303
108922 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 115.13587808609009

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 29] [2, 59] [1, 7] [1, 70] [3, 38] [4, 20] [2, 59] [0, 29] [4, 20] [4, 28] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 250.45010375976562 with beta sum per layer: [796.4906005859375, 1928.8193359375, 1586.889892578125, 1117.974365234375, 2243.218994140625]
alpha/beta optimization time: 0.3889946937561035
This batch time : update_bounds func: 0.9868	 prepare: 0.3540	 bound: 0.3895	 transfer: 0.0124	 finalize: 0.2235
Accumulated time: update_bounds func: 63.8285	 prepare: 18.3723	 bound: 23.6087	 transfer: 0.0124	 finalize: 19.1514
batch bounding time:  0.9894223213195801
Current worst splitting domains [lb, ub] (depth):
[-0.29234,   inf] (129), [-0.28264,   inf] (129), [-0.27967,   inf] (129), [-0.27468,   inf] (129), [-0.26828,   inf] (129), [-0.25881,   inf] (129), [-0.25256,   inf] (129), [-0.25155,   inf] (129), [-0.25083,   inf] (129), [-0.24986,   inf] (129), [-0.24690,   inf] (129), [-0.24647,   inf] (129), [-0.24455,   inf] (71), [-0.24454,   inf] (67), [-0.24374,   inf] (61), [-0.24374,   inf] (67), [-0.24374,   inf] (77), [-0.24374,   inf] (109), [-0.24373,   inf] (101), [-0.24373,   inf] (107), 
length of domains: 38602
Total time: 1.8042	 pickout: 0.2351	 decision: 0.2634	 get_bound: 0.9933	 add_domain: 0.3125
Current lb:-0.29233670234680176
110970 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 116.98581218719482

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 38] [3, 38] [2, 82] [4, 98] [4, 98] [2, 40] [4, 28] [1, 7] [2, 82] [1, 7] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 250.94921875 with beta sum per layer: [805.4468994140625, 2001.6822509765625, 1733.474853515625, 1132.039794921875, 2126.18994140625]
alpha/beta optimization time: 0.38223981857299805
This batch time : update_bounds func: 0.9825	 prepare: 0.3565	 bound: 0.3827	 transfer: 0.0123	 finalize: 0.2230
Accumulated time: update_bounds func: 64.8109	 prepare: 18.7289	 bound: 23.9915	 transfer: 0.0123	 finalize: 19.3744
batch bounding time:  0.9849686622619629
Current worst splitting domains [lb, ub] (depth):
[-0.27314,   inf] (131), [-0.26584,   inf] (131), [-0.25673,   inf] (131), [-0.24943,   inf] (131), [-0.24892,   inf] (131), [-0.24601,   inf] (131), [-0.24490,   inf] (131), [-0.24312,   inf] (63), [-0.24281,   inf] (131), [-0.24255,   inf] (63), [-0.24245,   inf] (65), [-0.24145,   inf] (131), [-0.24142,   inf] (71), [-0.24135,   inf] (131), [-0.24118,   inf] (61), [-0.24116,   inf] (97), [-0.24115,   inf] (107), [-0.24115,   inf] (103), [-0.24115,   inf] (117), [-0.24115,   inf] (105), 
length of domains: 39271
Total time: 3.0744	 pickout: 0.2309	 decision: 1.5450	 get_bound: 0.9889	 add_domain: 0.3097
Current lb:-0.2731375992298126
113018 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 120.10783195495605

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 54] [0, 89] [0, 89] [2, 22] [2, 22] [4, 20] [3, 84] [0, 72] [2, 82] [3, 17] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 245.87368774414062 with beta sum per layer: [796.621337890625, 1847.610595703125, 1515.5379638671875, 1252.9603271484375, 2280.708984375]
alpha/beta optimization time: 0.3996303081512451
This batch time : update_bounds func: 1.0113	 prepare: 0.3621	 bound: 0.4001	 transfer: 0.0122	 finalize: 0.2288
Accumulated time: update_bounds func: 65.8223	 prepare: 19.0910	 bound: 24.3916	 transfer: 0.0122	 finalize: 19.6032
batch bounding time:  1.0137097835540771
Current worst splitting domains [lb, ub] (depth):
[-0.25521,   inf] (133), [-0.25510,   inf] (133), [-0.24385,   inf] (133), [-0.24104,   inf] (63), [-0.24059,   inf] (67), [-0.23963,   inf] (71), [-0.23959,   inf] (73), [-0.23947,   inf] (61), [-0.23894,   inf] (71), [-0.23882,   inf] (63), [-0.23864,   inf] (105), [-0.23864,   inf] (77), [-0.23864,   inf] (93), [-0.23864,   inf] (83), [-0.23863,   inf] (107), [-0.23863,   inf] (83), [-0.23863,   inf] (107), [-0.23863,   inf] (67), [-0.23863,   inf] (69), [-0.23863,   inf] (59), 
length of domains: 39931
Total time: 1.8261	 pickout: 0.2356	 decision: 0.2668	 get_bound: 1.0175	 add_domain: 0.3063
Current lb:-0.2552090287208557
115066 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 121.98591041564941

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 70] [4, 98] [2, 40] [4, 56] [3, 17] [1, 29] [0, 13] [0, 72] [3, 55] [3, 17] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 227.9902801513672 with beta sum per layer: [834.1474609375, 1851.2349853515625, 1538.331298828125, 1119.821044921875, 2312.7666015625]
alpha/beta optimization time: 0.3893406391143799
This batch time : update_bounds func: 0.9982	 prepare: 0.3642	 bound: 0.3899	 transfer: 0.0124	 finalize: 0.2242
Accumulated time: update_bounds func: 66.8205	 prepare: 19.4551	 bound: 24.7815	 transfer: 0.0124	 finalize: 19.8274
batch bounding time:  1.0006790161132812
Current worst splitting domains [lb, ub] (depth):
[-0.23764,   inf] (135), [-0.23703,   inf] (73), [-0.23624,   inf] (117), [-0.23623,   inf] (95), [-0.23623,   inf] (65), [-0.23623,   inf] (69), [-0.23623,   inf] (85), [-0.23622,   inf] (87), [-0.23622,   inf] (69), [-0.23622,   inf] (85), [-0.23622,   inf] (81), [-0.23622,   inf] (99), [-0.23621,   inf] (83), [-0.23621,   inf] (79), [-0.23621,   inf] (81), [-0.23621,   inf] (75), [-0.23620,   inf] (75), [-0.23619,   inf] (77), [-0.23619,   inf] (73), [-0.23619,   inf] (65), 
length of domains: 40579
Total time: 1.8181	 pickout: 0.2438	 decision: 0.2650	 get_bound: 1.0045	 add_domain: 0.3047
Current lb:-0.23763611912727356
117114 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 123.85016751289368

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 7] [0, 13] [1, 7] [1, 93] [0, 2] [1, 80] [3, 35] [0, 88] [2, 60] [1, 93] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 229.8273468017578 with beta sum per layer: [768.2313232421875, 1979.6240234375, 1659.719482421875, 1227.165283203125, 2237.603515625]
alpha/beta optimization time: 0.38344454765319824
This batch time : update_bounds func: 0.9846	 prepare: 0.3571	 bound: 0.3839	 transfer: 0.0122	 finalize: 0.2233
Accumulated time: update_bounds func: 67.8051	 prepare: 19.8122	 bound: 25.1654	 transfer: 0.0122	 finalize: 20.0506
batch bounding time:  0.9869797229766846
Current worst splitting domains [lb, ub] (depth):
[-0.23616,   inf] (67), [-0.23607,   inf] (73), [-0.23550,   inf] (65), [-0.23534,   inf] (73), [-0.23506,   inf] (71), [-0.23386,   inf] (69), [-0.23385,   inf] (77), [-0.23384,   inf] (85), [-0.23384,   inf] (77), [-0.23383,   inf] (109), [-0.23383,   inf] (67), [-0.23383,   inf] (111), [-0.23383,   inf] (85), [-0.23383,   inf] (65), [-0.23382,   inf] (55), [-0.23382,   inf] (79), [-0.23382,   inf] (67), [-0.23381,   inf] (61), [-0.23381,   inf] (79), [-0.23381,   inf] (69), 
length of domains: 41210
Total time: 3.1963	 pickout: 0.2369	 decision: 1.6643	 get_bound: 0.9908	 add_domain: 0.3043
Current lb:-0.2361612468957901
119162 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 127.09303689002991

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 61] [1, 70] [1, 29] [2, 7] [1, 70] [2, 44] [0, 72] [2, 60] [0, 21] [2, 63] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 230.59275817871094 with beta sum per layer: [815.7025146484375, 1932.530517578125, 1650.68359375, 1128.4599609375, 2240.865966796875]
alpha/beta optimization time: 0.40564751625061035
This batch time : update_bounds func: 0.9987	 prepare: 0.3508	 bound: 0.4061	 transfer: 0.0121	 finalize: 0.2221
Accumulated time: update_bounds func: 68.8038	 prepare: 20.1630	 bound: 25.5715	 transfer: 0.0121	 finalize: 20.2727
batch bounding time:  1.0009980201721191
Current worst splitting domains [lb, ub] (depth):
[-0.23259,   inf] (67), [-0.23207,   inf] (67), [-0.23153,   inf] (111), [-0.23153,   inf] (115), [-0.23153,   inf] (93), [-0.23153,   inf] (55), [-0.23153,   inf] (83), [-0.23153,   inf] (107), [-0.23152,   inf] (109), [-0.23152,   inf] (67), [-0.23152,   inf] (115), [-0.23152,   inf] (67), [-0.23152,   inf] (105), [-0.23151,   inf] (93), [-0.23151,   inf] (57), [-0.23151,   inf] (77), [-0.23150,   inf] (89), [-0.23150,   inf] (73), [-0.23150,   inf] (99), [-0.23150,   inf] (59), 
length of domains: 41858
Total time: 1.8276	 pickout: 0.2468	 decision: 0.2637	 get_bound: 1.0048	 add_domain: 0.3123
Current lb:-0.23259060084819794
121210 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 128.97219920158386

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 2] [1, 29] [0, 72] [4, 28] [0, 36] [2, 57] [2, 63] [4, 68] [4, 71] [3, 4] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 228.38681030273438 with beta sum per layer: [780.333251953125, 1962.4554443359375, 1663.649169921875, 1224.552001953125, 2346.1923828125]
alpha/beta optimization time: 0.3892500400543213
This batch time : update_bounds func: 0.9949	 prepare: 0.3630	 bound: 0.3898	 transfer: 0.0122	 finalize: 0.2214
Accumulated time: update_bounds func: 69.7987	 prepare: 20.5260	 bound: 25.9613	 transfer: 0.0122	 finalize: 20.4941
batch bounding time:  0.997265100479126
Current worst splitting domains [lb, ub] (depth):
[-0.23063,   inf] (69), [-0.22964,   inf] (69), [-0.22961,   inf] (67), [-0.22932,   inf] (65), [-0.22915,   inf] (117), [-0.22915,   inf] (109), [-0.22914,   inf] (81), [-0.22914,   inf] (99), [-0.22914,   inf] (51), [-0.22914,   inf] (101), [-0.22914,   inf] (99), [-0.22914,   inf] (75), [-0.22914,   inf] (93), [-0.22914,   inf] (53), [-0.22913,   inf] (113), [-0.22913,   inf] (69), [-0.22913,   inf] (65), [-0.22912,   inf] (93), [-0.22912,   inf] (93), [-0.22912,   inf] (125), 
length of domains: 42521
Total time: 1.8266	 pickout: 0.2508	 decision: 0.2661	 get_bound: 1.0009	 add_domain: 0.3088
Current lb:-0.230626180768013
123258 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 130.84533095359802

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 61] [1, 70] [1, 29] [3, 35] [0, 25] [2, 82] [3, 90] [4, 98] [2, 57] [1, 54] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 219.5235137939453 with beta sum per layer: [848.5220947265625, 1957.7864990234375, 1650.3681640625, 1183.8648681640625, 2180.19140625]
alpha/beta optimization time: 0.387559175491333
This batch time : update_bounds func: 2.4852	 prepare: 0.3618	 bound: 0.3880	 transfer: 0.0125	 finalize: 1.7152
Accumulated time: update_bounds func: 72.2839	 prepare: 20.8878	 bound: 26.3493	 transfer: 0.0125	 finalize: 22.2093
batch bounding time:  2.4876885414123535
Current worst splitting domains [lb, ub] (depth):
[-0.22875,   inf] (65), [-0.22821,   inf] (67), [-0.22686,   inf] (63), [-0.22686,   inf] (113), [-0.22686,   inf] (93), [-0.22685,   inf] (61), [-0.22685,   inf] (95), [-0.22685,   inf] (95), [-0.22685,   inf] (105), [-0.22684,   inf] (111), [-0.22684,   inf] (123), [-0.22684,   inf] (77), [-0.22684,   inf] (69), [-0.22684,   inf] (61), [-0.22683,   inf] (65), [-0.22683,   inf] (125), [-0.22683,   inf] (59), [-0.22682,   inf] (87), [-0.22682,   inf] (99), [-0.22682,   inf] (91), 
length of domains: 43142
Total time: 3.3147	 pickout: 0.2445	 decision: 0.2706	 get_bound: 2.4915	 add_domain: 0.3081
Current lb:-0.2287532389163971
125306 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 134.2084677219391

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 29] [3, 2] [3, 90] [4, 20] [3, 38] [2, 53] [3, 27] [2, 93] [3, 0] [1, 93] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 210.346923828125 with beta sum per layer: [830.0018920898438, 1942.93017578125, 1531.132568359375, 1311.10791015625, 2354.637939453125]
alpha/beta optimization time: 0.38448452949523926
This batch time : update_bounds func: 0.9868	 prepare: 0.3562	 bound: 0.3850	 transfer: 0.0122	 finalize: 0.2252
Accumulated time: update_bounds func: 73.2707	 prepare: 21.2440	 bound: 26.7343	 transfer: 0.0122	 finalize: 22.4345
batch bounding time:  0.9893527030944824
Current worst splitting domains [lb, ub] (depth):
[-0.22664,   inf] (57), [-0.22619,   inf] (63), [-0.22460,   inf] (111), [-0.22459,   inf] (75), [-0.22458,   inf] (63), [-0.22458,   inf] (47), [-0.22458,   inf] (103), [-0.22458,   inf] (69), [-0.22458,   inf] (105), [-0.22457,   inf] (81), [-0.22457,   inf] (87), [-0.22457,   inf] (59), [-0.22457,   inf] (73), [-0.22457,   inf] (93), [-0.22457,   inf] (123), [-0.22456,   inf] (111), [-0.22456,   inf] (81), [-0.22456,   inf] (85), [-0.22456,   inf] (59), [-0.22456,   inf] (119), 
length of domains: 43759
Total time: 1.8007	 pickout: 0.2403	 decision: 0.2661	 get_bound: 0.9933	 add_domain: 0.3010
Current lb:-0.22663916647434235
127354 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 136.066397190094

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 0] [2, 7] [4, 98] [3, 17] [1, 49] [1, 80] [1, 51] [4, 18] [1, 7] [1, 49] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 214.07391357421875 with beta sum per layer: [823.927490234375, 1949.453125, 1660.40576171875, 1221.324462890625, 2278.21826171875]
alpha/beta optimization time: 0.381176233291626
This batch time : update_bounds func: 0.9896	 prepare: 0.3637	 bound: 0.3817	 transfer: 0.0122	 finalize: 0.2242
Accumulated time: update_bounds func: 74.2602	 prepare: 21.6077	 bound: 27.1160	 transfer: 0.0122	 finalize: 22.6588
batch bounding time:  0.991804838180542
Current worst splitting domains [lb, ub] (depth):
[-0.22437,   inf] (77), [-0.22376,   inf] (75), [-0.22276,   inf] (67), [-0.22235,   inf] (85), [-0.22235,   inf] (97), [-0.22235,   inf] (93), [-0.22235,   inf] (103), [-0.22234,   inf] (83), [-0.22234,   inf] (67), [-0.22234,   inf] (49), [-0.22233,   inf] (125), [-0.22233,   inf] (107), [-0.22233,   inf] (83), [-0.22233,   inf] (95), [-0.22233,   inf] (69), [-0.22233,   inf] (69), [-0.22232,   inf] (87), [-0.22232,   inf] (65), [-0.22232,   inf] (91), [-0.22232,   inf] (115), 
length of domains: 44369
Total time: 1.8146	 pickout: 0.2494	 decision: 0.2699	 get_bound: 0.9956	 add_domain: 0.2996
Current lb:-0.22436589002609253
129402 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 137.93453359603882

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 27] [3, 2] [3, 17] [0, 13] [2, 82] [2, 96] [1, 14] [1, 63] [2, 59] [3, 38] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 199.16043090820312 with beta sum per layer: [794.3336181640625, 1973.013671875, 1677.265625, 1265.76220703125, 2312.1435546875]
alpha/beta optimization time: 0.37938785552978516
This batch time : update_bounds func: 0.9844	 prepare: 0.3633	 bound: 0.3799	 transfer: 0.0128	 finalize: 0.2206
Accumulated time: update_bounds func: 75.2446	 prepare: 21.9710	 bound: 27.4958	 transfer: 0.0128	 finalize: 22.8793
batch bounding time:  0.9867615699768066
Current worst splitting domains [lb, ub] (depth):
[-0.22084,   inf] (69), [-0.22012,   inf] (93), [-0.22012,   inf] (91), [-0.22012,   inf] (61), [-0.22012,   inf] (97), [-0.22011,   inf] (79), [-0.22011,   inf] (73), [-0.22010,   inf] (103), [-0.22010,   inf] (89), [-0.22010,   inf] (101), [-0.22010,   inf] (75), [-0.22009,   inf] (53), [-0.22009,   inf] (79), [-0.22009,   inf] (101), [-0.22009,   inf] (87), [-0.22009,   inf] (67), [-0.22009,   inf] (85), [-0.22008,   inf] (117), [-0.22008,   inf] (113), [-0.22008,   inf] (63), 
length of domains: 44983
Total time: 3.3725	 pickout: 0.2392	 decision: 0.2832	 get_bound: 0.9907	 add_domain: 1.8593
Current lb:-0.2208404839038849
131450 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 141.35464930534363

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 80] [2, 22] [3, 35] [1, 49] [2, 63] [3, 87] [0, 21] [4, 67] [4, 18] [2, 96] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 198.91091918945312 with beta sum per layer: [858.5843505859375, 2060.53515625, 1667.189453125, 1344.5689697265625, 2160.517333984375]
alpha/beta optimization time: 0.3885786533355713
This batch time : update_bounds func: 0.9876	 prepare: 0.3537	 bound: 0.3891	 transfer: 0.0124	 finalize: 0.2247
Accumulated time: update_bounds func: 76.2322	 prepare: 22.3247	 bound: 27.8849	 transfer: 0.0124	 finalize: 23.1040
batch bounding time:  0.9901959896087646
Current worst splitting domains [lb, ub] (depth):
[-0.21969,   inf] (69), [-0.21933,   inf] (69), [-0.21808,   inf] (79), [-0.21808,   inf] (117), [-0.21808,   inf] (97), [-0.21808,   inf] (111), [-0.21808,   inf] (85), [-0.21808,   inf] (69), [-0.21808,   inf] (93), [-0.21807,   inf] (93), [-0.21807,   inf] (121), [-0.21807,   inf] (77), [-0.21807,   inf] (101), [-0.21807,   inf] (51), [-0.21806,   inf] (105), [-0.21806,   inf] (111), [-0.21806,   inf] (79), [-0.21806,   inf] (83), [-0.21806,   inf] (109), [-0.21806,   inf] (109), 
length of domains: 45561
Total time: 1.7864	 pickout: 0.2317	 decision: 0.2652	 get_bound: 0.9944	 add_domain: 0.2950
Current lb:-0.21968775987625122
133498 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 143.19462776184082

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 29] [1, 29] [2, 63] [1, 7] [2, 79] [4, 71] [2, 96] [3, 98] [2, 63] [2, 7] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 204.20767211914062 with beta sum per layer: [860.248779296875, 2020.438720703125, 1667.6661376953125, 1223.6243896484375, 2320.813720703125]
alpha/beta optimization time: 0.39067864418029785
This batch time : update_bounds func: 0.9926	 prepare: 0.3547	 bound: 0.3912	 transfer: 0.0122	 finalize: 0.2267
Accumulated time: update_bounds func: 77.2248	 prepare: 22.6794	 bound: 28.2761	 transfer: 0.0122	 finalize: 23.3307
batch bounding time:  0.9952938556671143
Current worst splitting domains [lb, ub] (depth):
[-0.21660,   inf] (69), [-0.21620,   inf] (73), [-0.21617,   inf] (69), [-0.21614,   inf] (73), [-0.21614,   inf] (101), [-0.21614,   inf] (57), [-0.21613,   inf] (87), [-0.21613,   inf] (109), [-0.21613,   inf] (121), [-0.21613,   inf] (63), [-0.21613,   inf] (53), [-0.21612,   inf] (71), [-0.21612,   inf] (97), [-0.21612,   inf] (109), [-0.21612,   inf] (119), [-0.21612,   inf] (67), [-0.21612,   inf] (53), [-0.21611,   inf] (71), [-0.21611,   inf] (109), [-0.21610,   inf] (71), 
length of domains: 46195
Total time: 1.7919	 pickout: 0.2262	 decision: 0.2607	 get_bound: 0.9994	 add_domain: 0.3056
Current lb:-0.21660487353801727
135546 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 145.0349564552307

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 29] [3, 2] [1, 29] [3, 62] [0, 36] [3, 73] [3, 86] [2, 56] [0, 29] [3, 86] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 205.57229614257812 with beta sum per layer: [883.4617919921875, 2072.287109375, 1623.8741455078125, 1260.5042724609375, 2271.81396484375]
alpha/beta optimization time: 0.3770284652709961
This batch time : update_bounds func: 0.9838	 prepare: 0.3632	 bound: 0.3775	 transfer: 0.0123	 finalize: 0.2227
Accumulated time: update_bounds func: 78.2086	 prepare: 23.0426	 bound: 28.6536	 transfer: 0.0123	 finalize: 23.5534
batch bounding time:  0.9859938621520996
Current worst splitting domains [lb, ub] (depth):
[-0.21433,   inf] (73), [-0.21404,   inf] (49), [-0.21404,   inf] (123), [-0.21403,   inf] (55), [-0.21403,   inf] (79), [-0.21403,   inf] (65), [-0.21403,   inf] (87), [-0.21403,   inf] (63), [-0.21402,   inf] (81), [-0.21402,   inf] (101), [-0.21402,   inf] (49), [-0.21402,   inf] (101), [-0.21402,   inf] (61), [-0.21402,   inf] (63), [-0.21402,   inf] (67), [-0.21402,   inf] (65), [-0.21402,   inf] (55), [-0.21402,   inf] (91), [-0.21402,   inf] (71), [-0.21401,   inf] (81), 
length of domains: 46811
Total time: 1.7925	 pickout: 0.2314	 decision: 0.2689	 get_bound: 0.9898	 add_domain: 0.3023
Current lb:-0.21432797610759735
137594 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 146.87582802772522

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 13] [2, 64] [2, 96] [3, 90] [2, 63] [0, 98] [1, 7] [3, 14] [1, 70] [1, 52] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 188.13331604003906 with beta sum per layer: [871.552978515625, 1847.25, 1708.973388671875, 1288.1265869140625, 2292.52685546875]
alpha/beta optimization time: 0.4302670955657959
This batch time : update_bounds func: 2.7034	 prepare: 0.3759	 bound: 0.4310	 transfer: 0.0153	 finalize: 1.8733
Accumulated time: update_bounds func: 80.9119	 prepare: 23.4185	 bound: 29.0845	 transfer: 0.0153	 finalize: 25.4267
batch bounding time:  2.7058093547821045
Current worst splitting domains [lb, ub] (depth):
[-0.21373,   inf] (71), [-0.21216,   inf] (67), [-0.21213,   inf] (63), [-0.21209,   inf] (69), [-0.21206,   inf] (73), [-0.21206,   inf] (59), [-0.21206,   inf] (71), [-0.21205,   inf] (99), [-0.21205,   inf] (111), [-0.21205,   inf] (87), [-0.21205,   inf] (69), [-0.21204,   inf] (81), [-0.21204,   inf] (49), [-0.21204,   inf] (73), [-0.21204,   inf] (113), [-0.21203,   inf] (117), [-0.21203,   inf] (111), [-0.21203,   inf] (93), [-0.21203,   inf] (43), [-0.21203,   inf] (103), 
length of domains: 47390
Total time: 3.5026	 pickout: 0.2304	 decision: 0.2657	 get_bound: 2.7097	 add_domain: 0.2968
Current lb:-0.21372677385807037
139642 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 150.4337649345398

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 61] [3, 2] [4, 56] [1, 29] [1, 80] [3, 17] [2, 63] [4, 67] [2, 79] [4, 0] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 194.83578491210938 with beta sum per layer: [814.1077880859375, 1986.083984375, 1647.0655517578125, 1226.2540283203125, 2372.65625]
alpha/beta optimization time: 0.3898501396179199
This batch time : update_bounds func: 1.0127	 prepare: 0.3763	 bound: 0.3903	 transfer: 0.0122	 finalize: 0.2256
Accumulated time: update_bounds func: 81.9246	 prepare: 23.7948	 bound: 29.4749	 transfer: 0.0122	 finalize: 25.6523
batch bounding time:  1.0153262615203857
Current worst splitting domains [lb, ub] (depth):
[-0.21176,   inf] (77), [-0.21121,   inf] (77), [-0.21012,   inf] (43), [-0.21012,   inf] (67), [-0.21011,   inf] (107), [-0.21011,   inf] (107), [-0.21011,   inf] (53), [-0.21011,   inf] (93), [-0.21011,   inf] (101), [-0.21011,   inf] (93), [-0.21011,   inf] (53), [-0.21011,   inf] (113), [-0.21011,   inf] (65), [-0.21010,   inf] (111), [-0.21010,   inf] (53), [-0.21010,   inf] (53), [-0.21010,   inf] (73), [-0.21009,   inf] (83), [-0.21009,   inf] (53), [-0.21009,   inf] (107), 
length of domains: 48024
Total time: 1.8248	 pickout: 0.2282	 decision: 0.2691	 get_bound: 1.0193	 add_domain: 0.3082
Current lb:-0.2117641568183899
141690 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 152.30799674987793

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 2] [3, 2] [2, 57] [1, 36] [2, 79] [3, 38] [3, 75] [0, 13] [1, 52] [0, 72] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 188.45021057128906 with beta sum per layer: [836.5033569335938, 1930.537841796875, 1669.501708984375, 1211.422607421875, 2506.54296875]
alpha/beta optimization time: 0.3888370990753174
This batch time : update_bounds func: 1.0264	 prepare: 0.3860	 bound: 0.3894	 transfer: 0.0124	 finalize: 0.2296
Accumulated time: update_bounds func: 82.9510	 prepare: 24.1808	 bound: 29.8643	 transfer: 0.0124	 finalize: 25.8819
batch bounding time:  1.0289742946624756
Current worst splitting domains [lb, ub] (depth):
[-0.20994,   inf] (71), [-0.20930,   inf] (73), [-0.20916,   inf] (63), [-0.20899,   inf] (71), [-0.20880,   inf] (71), [-0.20862,   inf] (67), [-0.20823,   inf] (119), [-0.20822,   inf] (107), [-0.20822,   inf] (61), [-0.20822,   inf] (117), [-0.20821,   inf] (75), [-0.20821,   inf] (113), [-0.20821,   inf] (133), [-0.20821,   inf] (47), [-0.20820,   inf] (105), [-0.20820,   inf] (125), [-0.20820,   inf] (91), [-0.20820,   inf] (49), [-0.20820,   inf] (103), [-0.20820,   inf] (115), 
length of domains: 48592
Total time: 1.9877	 pickout: 0.3306	 decision: 0.3295	 get_bound: 1.0329	 add_domain: 0.2947
Current lb:-0.20993727445602417
143738 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 154.34700441360474

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 29] [0, 13] [3, 73] [0, 13] [1, 29] [3, 2] [1, 70] [0, 21] [2, 82] [4, 28] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 189.49298095703125 with beta sum per layer: [834.133056640625, 1911.75390625, 1707.653564453125, 1305.9970703125, 2444.373779296875]
alpha/beta optimization time: 0.3882749080657959
This batch time : update_bounds func: 1.0125	 prepare: 0.3742	 bound: 0.3888	 transfer: 0.0126	 finalize: 0.2289
Accumulated time: update_bounds func: 83.9635	 prepare: 24.5550	 bound: 30.2530	 transfer: 0.0126	 finalize: 26.1108
batch bounding time:  1.0153300762176514
Current worst splitting domains [lb, ub] (depth):
[-0.20650,   inf] (63), [-0.20636,   inf] (103), [-0.20636,   inf] (91), [-0.20636,   inf] (109), [-0.20636,   inf] (67), [-0.20635,   inf] (105), [-0.20635,   inf] (83), [-0.20635,   inf] (47), [-0.20635,   inf] (61), [-0.20635,   inf] (107), [-0.20635,   inf] (81), [-0.20635,   inf] (45), [-0.20634,   inf] (93), [-0.20634,   inf] (83), [-0.20634,   inf] (111), [-0.20634,   inf] (89), [-0.20633,   inf] (103), [-0.20633,   inf] (103), [-0.20633,   inf] (63), [-0.20633,   inf] (63), 
length of domains: 49172
Total time: 1.8200	 pickout: 0.2346	 decision: 0.2648	 get_bound: 1.0196	 add_domain: 0.3010
Current lb:-0.20649580657482147
145786 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 156.21684861183167

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 73] [1, 7] [2, 60] [2, 82] [0, 2] [0, 21] [3, 86] [2, 59] [2, 57] [2, 79] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 188.18972778320312 with beta sum per layer: [851.9444580078125, 2032.619873046875, 1802.775146484375, 1250.85791015625, 2284.995849609375]
alpha/beta optimization time: 0.3915681838989258
This batch time : update_bounds func: 1.0410	 prepare: 0.4009	 bound: 0.3922	 transfer: 0.0121	 finalize: 0.2274
Accumulated time: update_bounds func: 85.0045	 prepare: 24.9559	 bound: 30.6452	 transfer: 0.0121	 finalize: 26.3382
batch bounding time:  1.0433590412139893
Current worst splitting domains [lb, ub] (depth):
[-0.20456,   inf] (95), [-0.20456,   inf] (83), [-0.20456,   inf] (59), [-0.20455,   inf] (125), [-0.20455,   inf] (103), [-0.20455,   inf] (121), [-0.20455,   inf] (107), [-0.20455,   inf] (119), [-0.20455,   inf] (103), [-0.20454,   inf] (91), [-0.20454,   inf] (75), [-0.20454,   inf] (67), [-0.20454,   inf] (107), [-0.20454,   inf] (115), [-0.20454,   inf] (119), [-0.20453,   inf] (99), [-0.20453,   inf] (99), [-0.20453,   inf] (57), [-0.20453,   inf] (51), [-0.20453,   inf] (81), 
length of domains: 49763
Total time: 3.5769	 pickout: 0.2321	 decision: 1.9936	 get_bound: 1.0473	 add_domain: 0.3040
Current lb:-0.2045602798461914
147834 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 159.84498167037964

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 7] [3, 38] [3, 38] [2, 59] [1, 7] [2, 59] [0, 36] [3, 38] [1, 52] [2, 7] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 179.61318969726562 with beta sum per layer: [879.78759765625, 2088.24365234375, 1587.218505859375, 1241.4627685546875, 2367.90771484375]
alpha/beta optimization time: 0.3863198757171631
This batch time : update_bounds func: 1.0219	 prepare: 0.3867	 bound: 0.3869	 transfer: 0.0123	 finalize: 0.2280
Accumulated time: update_bounds func: 86.0264	 prepare: 25.3426	 bound: 31.0321	 transfer: 0.0123	 finalize: 26.5662
batch bounding time:  1.024146318435669
Current worst splitting domains [lb, ub] (depth):
[-0.20414,   inf] (77), [-0.20280,   inf] (109), [-0.20279,   inf] (117), [-0.20279,   inf] (113), [-0.20279,   inf] (79), [-0.20279,   inf] (43), [-0.20279,   inf] (75), [-0.20279,   inf] (117), [-0.20279,   inf] (105), [-0.20279,   inf] (89), [-0.20279,   inf] (107), [-0.20278,   inf] (119), [-0.20278,   inf] (69), [-0.20278,   inf] (71), [-0.20278,   inf] (95), [-0.20278,   inf] (105), [-0.20278,   inf] (57), [-0.20278,   inf] (53), [-0.20277,   inf] (91), [-0.20277,   inf] (79), 
length of domains: 50349
Total time: 1.8387	 pickout: 0.2368	 decision: 0.2743	 get_bound: 1.0281	 add_domain: 0.2995
Current lb:-0.20413967967033386
149882 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 161.73373746871948

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 13] [0, 72] [4, 71] [2, 82] [2, 57] [0, 21] [3, 19] [2, 93] [2, 79] [4, 18] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 180.97398376464844 with beta sum per layer: [883.9088745117188, 2050.01318359375, 1715.126220703125, 1306.9561767578125, 2347.178955078125]
alpha/beta optimization time: 0.38465380668640137
This batch time : update_bounds func: 1.0305	 prepare: 0.3946	 bound: 0.3851	 transfer: 0.0122	 finalize: 0.2301
Accumulated time: update_bounds func: 87.0569	 prepare: 25.7372	 bound: 31.4172	 transfer: 0.0122	 finalize: 26.7963
batch bounding time:  1.0331168174743652
Current worst splitting domains [lb, ub] (depth):
[-0.20094,   inf] (75), [-0.20094,   inf] (69), [-0.20094,   inf] (87), [-0.20094,   inf] (89), [-0.20094,   inf] (49), [-0.20094,   inf] (107), [-0.20093,   inf] (45), [-0.20093,   inf] (59), [-0.20093,   inf] (91), [-0.20093,   inf] (73), [-0.20092,   inf] (117), [-0.20092,   inf] (113), [-0.20091,   inf] (99), [-0.20090,   inf] (95), [-0.20090,   inf] (73), [-0.20090,   inf] (107), [-0.20089,   inf] (105), [-0.20089,   inf] (75), [-0.20089,   inf] (75), [-0.20088,   inf] (83), 
length of domains: 50916
Total time: 1.8439	 pickout: 0.2342	 decision: 0.2751	 get_bound: 1.0372	 add_domain: 0.2973
Current lb:-0.2009400725364685
151930 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 163.6278257369995

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 68] [1, 52] [3, 38] [3, 27] [4, 34] [3, 38] [2, 75] [4, 43] [2, 59] [3, 90] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 170.00045776367188 with beta sum per layer: [773.6973876953125, 2056.09521484375, 1711.7532958984375, 1336.1185302734375, 2360.494140625]
alpha/beta optimization time: 0.3870275020599365
This batch time : update_bounds func: 1.0104	 prepare: 0.3747	 bound: 0.3875	 transfer: 0.0122	 finalize: 0.2280
Accumulated time: update_bounds func: 88.0673	 prepare: 26.1120	 bound: 31.8047	 transfer: 0.0122	 finalize: 27.0243
batch bounding time:  1.0129783153533936
Current worst splitting domains [lb, ub] (depth):
[-0.19925,   inf] (75), [-0.19919,   inf] (127), [-0.19919,   inf] (69), [-0.19919,   inf] (109), [-0.19919,   inf] (115), [-0.19919,   inf] (127), [-0.19918,   inf] (93), [-0.19918,   inf] (95), [-0.19918,   inf] (53), [-0.19918,   inf] (69), [-0.19918,   inf] (91), [-0.19917,   inf] (119), [-0.19917,   inf] (119), [-0.19917,   inf] (109), [-0.19917,   inf] (67), [-0.19917,   inf] (75), [-0.19917,   inf] (65), [-0.19917,   inf] (57), [-0.19916,   inf] (71), [-0.19916,   inf] (117), 
length of domains: 51461
Total time: 1.8129	 pickout: 0.2303	 decision: 0.2697	 get_bound: 1.0171	 add_domain: 0.2959
Current lb:-0.19924920797348022
153978 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 165.49523830413818

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 15] [2, 82] [3, 98] [0, 32] [2, 82] [2, 56] [1, 68] [3, 38] [0, 98] [2, 57] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 161.22349548339844 with beta sum per layer: [829.145751953125, 2097.91259765625, 1780.2957763671875, 1433.5018310546875, 2313.18115234375]
alpha/beta optimization time: 0.3873434066772461
This batch time : update_bounds func: 1.0218	 prepare: 0.3777	 bound: 0.3879	 transfer: 0.0120	 finalize: 0.2356
Accumulated time: update_bounds func: 89.0891	 prepare: 26.4896	 bound: 32.1926	 transfer: 0.0120	 finalize: 27.2599
batch bounding time:  1.024348497390747
Current worst splitting domains [lb, ub] (depth):
[-0.19875,   inf] (61), [-0.19756,   inf] (63), [-0.19756,   inf] (117), [-0.19756,   inf] (87), [-0.19756,   inf] (85), [-0.19756,   inf] (73), [-0.19756,   inf] (101), [-0.19756,   inf] (43), [-0.19756,   inf] (107), [-0.19756,   inf] (47), [-0.19756,   inf] (85), [-0.19755,   inf] (105), [-0.19755,   inf] (119), [-0.19755,   inf] (75), [-0.19755,   inf] (67), [-0.19755,   inf] (97), [-0.19755,   inf] (53), [-0.19755,   inf] (49), [-0.19755,   inf] (45), [-0.19755,   inf] (59), 
length of domains: 52024
Total time: 3.6388	 pickout: 0.2316	 decision: 2.0769	 get_bound: 1.0283	 add_domain: 0.3020
Current lb:-0.1987500786781311
156026 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 169.19144129753113

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 44] [3, 17] [2, 56] [1, 68] [2, 53] [2, 44] [1, 54] [4, 43] [4, 68] [0, 98] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 169.54754638671875 with beta sum per layer: [812.1409912109375, 2062.212890625, 1662.794921875, 1316.7169189453125, 2482.403564453125]
alpha/beta optimization time: 0.3908259868621826
This batch time : update_bounds func: 1.0249	 prepare: 0.3839	 bound: 0.3913	 transfer: 0.0122	 finalize: 0.2297
Accumulated time: update_bounds func: 90.1140	 prepare: 26.8735	 bound: 32.5839	 transfer: 0.0122	 finalize: 27.4896
batch bounding time:  1.0275115966796875
Current worst splitting domains [lb, ub] (depth):
[-0.19648,   inf] (77), [-0.19598,   inf] (95), [-0.19598,   inf] (61), [-0.19598,   inf] (57), [-0.19598,   inf] (117), [-0.19597,   inf] (69), [-0.19597,   inf] (67), [-0.19597,   inf] (97), [-0.19597,   inf] (109), [-0.19597,   inf] (69), [-0.19597,   inf] (119), [-0.19597,   inf] (63), [-0.19597,   inf] (117), [-0.19597,   inf] (113), [-0.19596,   inf] (101), [-0.19596,   inf] (95), [-0.19596,   inf] (113), [-0.19596,   inf] (111), [-0.19596,   inf] (109), [-0.19596,   inf] (55), 
length of domains: 52596
Total time: 1.8405	 pickout: 0.2372	 decision: 0.2714	 get_bound: 1.0315	 add_domain: 0.3004
Current lb:-0.1964750587940216
158074 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 171.0848662853241

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 13] [2, 79] [0, 21] [3, 98] [2, 82] [2, 40] [2, 44] [2, 93] [4, 67] [0, 2] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 161.18246459960938 with beta sum per layer: [893.0067749023438, 2014.2838134765625, 1766.4066162109375, 1429.142333984375, 2217.7958984375]
alpha/beta optimization time: 0.4035830497741699
This batch time : update_bounds func: 1.0495	 prepare: 0.3953	 bound: 0.4041	 transfer: 0.0120	 finalize: 0.2299
Accumulated time: update_bounds func: 91.1635	 prepare: 27.2688	 bound: 32.9880	 transfer: 0.0120	 finalize: 27.7195
batch bounding time:  1.0518791675567627
Current worst splitting domains [lb, ub] (depth):
[-0.19560,   inf] (67), [-0.19429,   inf] (109), [-0.19429,   inf] (99), [-0.19429,   inf] (63), [-0.19429,   inf] (97), [-0.19429,   inf] (67), [-0.19429,   inf] (95), [-0.19428,   inf] (121), [-0.19428,   inf] (85), [-0.19428,   inf] (59), [-0.19428,   inf] (89), [-0.19427,   inf] (63), [-0.19427,   inf] (103), [-0.19427,   inf] (111), [-0.19427,   inf] (67), [-0.19427,   inf] (73), [-0.19427,   inf] (109), [-0.19427,   inf] (55), [-0.19427,   inf] (111), [-0.19427,   inf] (131), 
length of domains: 53127
Total time: 1.8607	 pickout: 0.2336	 decision: 0.2735	 get_bound: 1.0557	 add_domain: 0.2979
Current lb:-0.19560468196868896
160122 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 173.00268244743347

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 29] [4, 67] [3, 38] [3, 38] [3, 0] [3, 98] [2, 60] [2, 40] [2, 7] [2, 64] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 163.71121215820312 with beta sum per layer: [853.7338256835938, 1976.823486328125, 1797.833984375, 1363.434814453125, 2270.9052734375]
alpha/beta optimization time: 0.38344359397888184
This batch time : update_bounds func: 1.0188	 prepare: 0.3874	 bound: 0.3839	 transfer: 0.0123	 finalize: 0.2273
Accumulated time: update_bounds func: 92.1823	 prepare: 27.6562	 bound: 33.3720	 transfer: 0.0123	 finalize: 27.9468
batch bounding time:  1.021615982055664
Current worst splitting domains [lb, ub] (depth):
[-0.19410,   inf] (67), [-0.19337,   inf] (65), [-0.19336,   inf] (77), [-0.19330,   inf] (77), [-0.19277,   inf] (67), [-0.19264,   inf] (63), [-0.19264,   inf] (107), [-0.19263,   inf] (91), [-0.19263,   inf] (111), [-0.19263,   inf] (97), [-0.19263,   inf] (63), [-0.19263,   inf] (81), [-0.19263,   inf] (101), [-0.19262,   inf] (69), [-0.19262,   inf] (59), [-0.19262,   inf] (97), [-0.19262,   inf] (81), [-0.19262,   inf] (117), [-0.19261,   inf] (67), [-0.19261,   inf] (119), 
length of domains: 53670
Total time: 1.8336	 pickout: 0.2388	 decision: 0.2733	 get_bound: 1.0259	 add_domain: 0.2956
Current lb:-0.19410130381584167
162170 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 174.88800883293152

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 73] [1, 29] [2, 7] [0, 13] [3, 86] [4, 45] [2, 56] [0, 72] [2, 22] [1, 7] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 157.0499725341797 with beta sum per layer: [806.9610595703125, 2183.9560546875, 1667.400146484375, 1418.86865234375, 2376.710693359375]
alpha/beta optimization time: 0.38556718826293945
This batch time : update_bounds func: 1.0096	 prepare: 0.3676	 bound: 0.3860	 transfer: 0.0128	 finalize: 0.2355
Accumulated time: update_bounds func: 93.1919	 prepare: 28.0238	 bound: 33.7580	 transfer: 0.0128	 finalize: 28.1822
batch bounding time:  1.011986255645752
Current worst splitting domains [lb, ub] (depth):
[-0.19144,   inf] (45), [-0.19142,   inf] (65), [-0.19101,   inf] (71), [-0.19101,   inf] (87), [-0.19101,   inf] (73), [-0.19101,   inf] (85), [-0.19101,   inf] (123), [-0.19101,   inf] (75), [-0.19101,   inf] (83), [-0.19100,   inf] (115), [-0.19100,   inf] (53), [-0.19100,   inf] (61), [-0.19100,   inf] (91), [-0.19100,   inf] (117), [-0.19100,   inf] (109), [-0.19100,   inf] (57), [-0.19100,   inf] (95), [-0.19100,   inf] (105), [-0.19100,   inf] (115), [-0.19099,   inf] (73), 
length of domains: 54211
Total time: 3.7609	 pickout: 0.2608	 decision: 2.1879	 get_bound: 1.0157	 add_domain: 0.2964
Current lb:-0.19143860042095184
164218 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 178.7096083164215

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 36] [1, 29] [1, 70] [1, 70] [2, 53] [1, 43] [4, 98] [3, 86] [1, 54] [3, 38] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 148.94732666015625 with beta sum per layer: [831.2219848632812, 2058.34912109375, 1637.1953125, 1392.972900390625, 2344.543701171875]
alpha/beta optimization time: 0.3879671096801758
This batch time : update_bounds func: 1.0131	 prepare: 0.3755	 bound: 0.3885	 transfer: 0.0127	 finalize: 0.2284
Accumulated time: update_bounds func: 94.2050	 prepare: 28.3993	 bound: 34.1465	 transfer: 0.0127	 finalize: 28.4106
batch bounding time:  1.0154972076416016
Current worst splitting domains [lb, ub] (depth):
[-0.19144,   inf] (47), [-0.19097,   inf] (45), [-0.18946,   inf] (65), [-0.18940,   inf] (65), [-0.18940,   inf] (91), [-0.18940,   inf] (105), [-0.18940,   inf] (83), [-0.18940,   inf] (143), [-0.18940,   inf] (105), [-0.18939,   inf] (127), [-0.18939,   inf] (57), [-0.18939,   inf] (71), [-0.18939,   inf] (89), [-0.18939,   inf] (77), [-0.18938,   inf] (127), [-0.18938,   inf] (115), [-0.18938,   inf] (107), [-0.18938,   inf] (43), [-0.18937,   inf] (101), [-0.18937,   inf] (79), 
length of domains: 54696
Total time: 1.8137	 pickout: 0.2405	 decision: 0.2665	 get_bound: 1.0195	 add_domain: 0.2871
Current lb:-0.19143860042095184
166266 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 180.58145022392273

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 83] [1, 36] [4, 56] [0, 13] [2, 56] [0, 36] [1, 49] [1, 14] [2, 44] [1, 7] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 154.63943481445312 with beta sum per layer: [865.256103515625, 2189.557373046875, 1856.848388671875, 1307.700927734375, 2154.9384765625]
alpha/beta optimization time: 0.3903200626373291
This batch time : update_bounds func: 1.0314	 prepare: 0.3911	 bound: 0.3908	 transfer: 0.0126	 finalize: 0.2285
Accumulated time: update_bounds func: 95.2364	 prepare: 28.7904	 bound: 34.5373	 transfer: 0.0126	 finalize: 28.6391
batch bounding time:  1.0338444709777832
Current worst splitting domains [lb, ub] (depth):
[-0.19097,   inf] (47), [-0.18834,   inf] (75), [-0.18773,   inf] (113), [-0.18773,   inf] (103), [-0.18773,   inf] (69), [-0.18773,   inf] (67), [-0.18772,   inf] (91), [-0.18772,   inf] (95), [-0.18772,   inf] (91), [-0.18772,   inf] (77), [-0.18772,   inf] (89), [-0.18772,   inf] (83), [-0.18772,   inf] (115), [-0.18772,   inf] (89), [-0.18772,   inf] (73), [-0.18772,   inf] (61), [-0.18772,   inf] (65), [-0.18772,   inf] (87), [-0.18771,   inf] (89), [-0.18771,   inf] (93), 
length of domains: 55221
Total time: 1.8295	 pickout: 0.2315	 decision: 0.2640	 get_bound: 1.0378	 add_domain: 0.2961
Current lb:-0.19096513092517853
168314 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 182.47346091270447

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 83] [2, 7] [1, 63] [4, 71] [0, 98] [2, 59] [3, 17] [2, 60] [3, 35] [4, 0] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 152.87973022460938 with beta sum per layer: [881.5936279296875, 2125.429443359375, 1675.4462890625, 1402.889892578125, 2333.263671875]
alpha/beta optimization time: 0.38965725898742676
This batch time : update_bounds func: 1.0340	 prepare: 0.3978	 bound: 0.3903	 transfer: 0.0126	 finalize: 0.2254
Accumulated time: update_bounds func: 96.2704	 prepare: 29.1882	 bound: 34.9276	 transfer: 0.0126	 finalize: 28.8645
batch bounding time:  1.0363638401031494
Current worst splitting domains [lb, ub] (depth):
[-0.18656,   inf] (61), [-0.18621,   inf] (101), [-0.18621,   inf] (93), [-0.18621,   inf] (123), [-0.18621,   inf] (87), [-0.18621,   inf] (127), [-0.18621,   inf] (99), [-0.18621,   inf] (73), [-0.18621,   inf] (73), [-0.18621,   inf] (93), [-0.18621,   inf] (105), [-0.18620,   inf] (59), [-0.18620,   inf] (97), [-0.18620,   inf] (79), [-0.18620,   inf] (127), [-0.18620,   inf] (67), [-0.18620,   inf] (43), [-0.18620,   inf] (111), [-0.18620,   inf] (123), [-0.18619,   inf] (119), 
length of domains: 55743
Total time: 1.8560	 pickout: 0.2393	 decision: 0.2847	 get_bound: 1.0403	 add_domain: 0.2917
Current lb:-0.18655970692634583
170362 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 184.3866138458252

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 29] [2, 82] [3, 87] [1, 54] [2, 40] [4, 20] [1, 52] [2, 61] [0, 98] [4, 18] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 149.69827270507812 with beta sum per layer: [833.20751953125, 2031.2557373046875, 1785.6884765625, 1466.5869140625, 2214.9814453125]
alpha/beta optimization time: 0.3899974822998047
This batch time : update_bounds func: 3.1039	 prepare: 0.4128	 bound: 0.3905	 transfer: 0.0127	 finalize: 2.2797
Accumulated time: update_bounds func: 99.3743	 prepare: 29.6010	 bound: 35.3181	 transfer: 0.0127	 finalize: 31.1442
batch bounding time:  3.106508731842041
Current worst splitting domains [lb, ub] (depth):
[-0.18588,   inf] (65), [-0.18468,   inf] (105), [-0.18468,   inf] (91), [-0.18468,   inf] (63), [-0.18468,   inf] (59), [-0.18468,   inf] (57), [-0.18468,   inf] (75), [-0.18468,   inf] (99), [-0.18467,   inf] (111), [-0.18467,   inf] (99), [-0.18467,   inf] (89), [-0.18467,   inf] (45), [-0.18467,   inf] (109), [-0.18467,   inf] (49), [-0.18467,   inf] (119), [-0.18467,   inf] (107), [-0.18466,   inf] (105), [-0.18466,   inf] (113), [-0.18466,   inf] (71), [-0.18466,   inf] (67), 
length of domains: 56237
Total time: 3.9433	 pickout: 0.2456	 decision: 0.2951	 get_bound: 3.1105	 add_domain: 0.2920
Current lb:-0.18587525188922882
172410 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 188.38690304756165

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 29] [1, 52] [0, 72] [1, 36] [3, 22] [1, 49] [2, 93] [2, 82] [2, 22] [0, 25] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 139.7686767578125 with beta sum per layer: [846.4942016601562, 2220.942626953125, 1786.1015625, 1283.749755859375, 2329.849365234375]
alpha/beta optimization time: 0.3949768543243408
This batch time : update_bounds func: 1.0364	 prepare: 0.3906	 bound: 0.3956	 transfer: 0.0124	 finalize: 0.2297
Accumulated time: update_bounds func: 100.4107	 prepare: 29.9917	 bound: 35.7137	 transfer: 0.0124	 finalize: 31.3739
batch bounding time:  1.038785696029663
Current worst splitting domains [lb, ub] (depth):
[-0.18453,   inf] (69), [-0.18313,   inf] (97), [-0.18313,   inf] (79), [-0.18313,   inf] (95), [-0.18313,   inf] (123), [-0.18313,   inf] (81), [-0.18313,   inf] (67), [-0.18313,   inf] (69), [-0.18313,   inf] (109), [-0.18312,   inf] (79), [-0.18312,   inf] (133), [-0.18312,   inf] (111), [-0.18312,   inf] (85), [-0.18312,   inf] (117), [-0.18312,   inf] (89), [-0.18312,   inf] (115), [-0.18312,   inf] (117), [-0.18312,   inf] (99), [-0.18312,   inf] (73), [-0.18312,   inf] (75), 
length of domains: 56746
Total time: 1.8663	 pickout: 0.2577	 decision: 0.2763	 get_bound: 1.0428	 add_domain: 0.2894
Current lb:-0.1845315396785736
174458 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 190.30831694602966

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 17] [2, 79] [3, 98] [2, 93] [2, 59] [1, 54] [1, 93] [2, 7] [0, 21] [1, 93] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 141.72073364257812 with beta sum per layer: [875.407470703125, 2123.23388671875, 1769.6298828125, 1505.2308349609375, 2215.375]
alpha/beta optimization time: 0.3901801109313965
This batch time : update_bounds func: 1.0280	 prepare: 0.3867	 bound: 0.3907	 transfer: 0.0121	 finalize: 0.2302
Accumulated time: update_bounds func: 101.4387	 prepare: 30.3784	 bound: 36.1044	 transfer: 0.0121	 finalize: 31.6041
batch bounding time:  1.030771255493164
Current worst splitting domains [lb, ub] (depth):
[-0.18312,   inf] (81), [-0.18247,   inf] (81), [-0.18212,   inf] (79), [-0.18163,   inf] (125), [-0.18163,   inf] (107), [-0.18162,   inf] (87), [-0.18162,   inf] (105), [-0.18162,   inf] (137), [-0.18162,   inf] (73), [-0.18162,   inf] (99), [-0.18162,   inf] (69), [-0.18162,   inf] (91), [-0.18162,   inf] (101), [-0.18162,   inf] (43), [-0.18162,   inf] (71), [-0.18162,   inf] (71), [-0.18162,   inf] (75), [-0.18162,   inf] (47), [-0.18161,   inf] (79), [-0.18161,   inf] (95), 
length of domains: 57229
Total time: 1.8481	 pickout: 0.2493	 decision: 0.2764	 get_bound: 1.0349	 add_domain: 0.2875
Current lb:-0.18311667442321777
176506 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 192.2108714580536

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 27] [2, 27] [1, 15] [4, 28] [3, 0] [3, 86] [0, 29] [4, 98] [2, 27] [2, 22] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 138.44866943359375 with beta sum per layer: [832.7823486328125, 1947.697509765625, 1839.59765625, 1381.9263916015625, 2420.79736328125]
alpha/beta optimization time: 0.3900785446166992
This batch time : update_bounds func: 1.0302	 prepare: 0.3877	 bound: 0.3906	 transfer: 0.0124	 finalize: 0.2312
Accumulated time: update_bounds func: 102.4690	 prepare: 30.7661	 bound: 36.4950	 transfer: 0.0124	 finalize: 31.8353
batch bounding time:  1.03277587890625
Current worst splitting domains [lb, ub] (depth):
[-0.18021,   inf] (51), [-0.18021,   inf] (57), [-0.18021,   inf] (131), [-0.18021,   inf] (111), [-0.18021,   inf] (67), [-0.18021,   inf] (117), [-0.18021,   inf] (101), [-0.18020,   inf] (65), [-0.18020,   inf] (89), [-0.18020,   inf] (111), [-0.18020,   inf] (97), [-0.18020,   inf] (119), [-0.18020,   inf] (59), [-0.18020,   inf] (87), [-0.18020,   inf] (59), [-0.18020,   inf] (101), [-0.18020,   inf] (83), [-0.18019,   inf] (101), [-0.18019,   inf] (65), [-0.18019,   inf] (79), 
length of domains: 57694
Total time: 1.8687	 pickout: 0.2572	 decision: 0.2788	 get_bound: 1.0368	 add_domain: 0.2958
Current lb:-0.1802116483449936
178554 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 194.14284086227417

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 66] [3, 86] [4, 92] [1, 63] [3, 17] [2, 82] [3, 0] [2, 59] [3, 35] [2, 82] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 132.4936065673828 with beta sum per layer: [838.57763671875, 2008.1142578125, 1798.454833984375, 1505.318603515625, 2398.83251953125]
alpha/beta optimization time: 0.3929581642150879
This batch time : update_bounds func: 1.0654	 prepare: 0.3923	 bound: 0.3935	 transfer: 0.0126	 finalize: 0.2588
Accumulated time: update_bounds func: 103.5344	 prepare: 31.1584	 bound: 36.8885	 transfer: 0.0126	 finalize: 32.0941
batch bounding time:  1.0682053565979004
Current worst splitting domains [lb, ub] (depth):
[-0.18009,   inf] (75), [-0.18006,   inf] (67), [-0.17872,   inf] (99), [-0.17872,   inf] (125), [-0.17872,   inf] (89), [-0.17871,   inf] (107), [-0.17871,   inf] (113), [-0.17871,   inf] (73), [-0.17871,   inf] (103), [-0.17871,   inf] (119), [-0.17871,   inf] (43), [-0.17871,   inf] (111), [-0.17871,   inf] (61), [-0.17871,   inf] (133), [-0.17870,   inf] (119), [-0.17870,   inf] (87), [-0.17870,   inf] (129), [-0.17870,   inf] (85), [-0.17870,   inf] (85), [-0.17870,   inf] (93), 
length of domains: 58137
Total time: 4.1151	 pickout: 0.2562	 decision: 0.2740	 get_bound: 1.0725	 add_domain: 2.5124
Current lb:-0.18009310960769653
180602 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 198.31210565567017

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 59] [3, 73] [1, 63] [0, 25] [4, 50] [2, 56] [1, 63] [3, 98] [0, 13] [4, 20] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 125.9813003540039 with beta sum per layer: [884.281982421875, 2063.2421875, 1809.368408203125, 1445.182861328125, 2336.765625]
alpha/beta optimization time: 0.3930037021636963
This batch time : update_bounds func: 1.0326	 prepare: 0.3858	 bound: 0.3935	 transfer: 0.0127	 finalize: 0.2322
Accumulated time: update_bounds func: 104.5670	 prepare: 31.5442	 bound: 37.2820	 transfer: 0.0127	 finalize: 32.3263
batch bounding time:  1.0352489948272705
Current worst splitting domains [lb, ub] (depth):
[-0.17796,   inf] (67), [-0.17733,   inf] (85), [-0.17733,   inf] (103), [-0.17733,   inf] (65), [-0.17733,   inf] (73), [-0.17733,   inf] (59), [-0.17733,   inf] (73), [-0.17733,   inf] (91), [-0.17733,   inf] (131), [-0.17732,   inf] (79), [-0.17732,   inf] (109), [-0.17732,   inf] (85), [-0.17732,   inf] (75), [-0.17732,   inf] (81), [-0.17732,   inf] (83), [-0.17731,   inf] (107), [-0.17731,   inf] (115), [-0.17731,   inf] (57), [-0.17731,   inf] (101), [-0.17731,   inf] (97), 
length of domains: 58592
Total time: 1.8432	 pickout: 0.2473	 decision: 0.2727	 get_bound: 1.0396	 add_domain: 0.2836
Current lb:-0.1779552847146988
182650 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 200.2098457813263

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 29] [1, 63] [4, 50] [2, 59] [1, 7] [4, 45] [1, 70] [3, 38] [4, 92] [3, 86] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 141.75924682617188 with beta sum per layer: [862.832763671875, 2176.91259765625, 1777.25, 1474.94970703125, 2237.941162109375]
alpha/beta optimization time: 0.39797353744506836
This batch time : update_bounds func: 1.0482	 prepare: 0.3893	 bound: 0.3985	 transfer: 0.0127	 finalize: 0.2397
Accumulated time: update_bounds func: 105.6152	 prepare: 31.9335	 bound: 37.6805	 transfer: 0.0127	 finalize: 32.5661
batch bounding time:  1.0511186122894287
Current worst splitting domains [lb, ub] (depth):
[-0.17596,   inf] (121), [-0.17596,   inf] (65), [-0.17596,   inf] (91), [-0.17596,   inf] (51), [-0.17596,   inf] (117), [-0.17596,   inf] (71), [-0.17596,   inf] (87), [-0.17595,   inf] (127), [-0.17595,   inf] (109), [-0.17595,   inf] (95), [-0.17595,   inf] (111), [-0.17595,   inf] (117), [-0.17594,   inf] (87), [-0.17594,   inf] (81), [-0.17594,   inf] (83), [-0.17594,   inf] (123), [-0.17594,   inf] (69), [-0.17594,   inf] (97), [-0.17593,   inf] (107), [-0.17593,   inf] (113), 
length of domains: 59078
Total time: 1.8921	 pickout: 0.2627	 decision: 0.2765	 get_bound: 1.0554	 add_domain: 0.2975
Current lb:-0.1759626269340515
184698 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 202.15729069709778

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 22] [3, 75] [4, 18] [2, 57] [2, 69] [2, 53] [4, 0] [4, 98] [1, 52] [2, 63] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 131.74288940429688 with beta sum per layer: [868.5050659179688, 2062.23583984375, 1846.42138671875, 1476.794189453125, 2254.8515625]
alpha/beta optimization time: 0.39296507835388184
This batch time : update_bounds func: 1.0304	 prepare: 0.3848	 bound: 0.3936	 transfer: 0.0120	 finalize: 0.2320
Accumulated time: update_bounds func: 106.6456	 prepare: 32.3183	 bound: 38.0741	 transfer: 0.0120	 finalize: 32.7981
batch bounding time:  1.0327436923980713
Current worst splitting domains [lb, ub] (depth):
[-0.17518,   inf] (79), [-0.17459,   inf] (91), [-0.17459,   inf] (89), [-0.17459,   inf] (71), [-0.17459,   inf] (41), [-0.17458,   inf] (105), [-0.17458,   inf] (119), [-0.17458,   inf] (73), [-0.17458,   inf] (67), [-0.17457,   inf] (97), [-0.17457,   inf] (61), [-0.17457,   inf] (69), [-0.17457,   inf] (131), [-0.17457,   inf] (113), [-0.17457,   inf] (123), [-0.17456,   inf] (111), [-0.17456,   inf] (103), [-0.17456,   inf] (121), [-0.17456,   inf] (59), [-0.17456,   inf] (69), 
length of domains: 59543
Total time: 1.8489	 pickout: 0.2480	 decision: 0.2728	 get_bound: 1.0367	 add_domain: 0.2913
Current lb:-0.17517946660518646
186746 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 204.06719183921814

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 17] [1, 7] [0, 25] [2, 76] [2, 66] [2, 82] [1, 7] [0, 2] [3, 98] [1, 49] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 134.37832641601562 with beta sum per layer: [864.004150390625, 2097.85888671875, 1845.848876953125, 1447.8994140625, 2260.845458984375]
alpha/beta optimization time: 0.3888213634490967
This batch time : update_bounds func: 1.0256	 prepare: 0.3814	 bound: 0.3893	 transfer: 0.0127	 finalize: 0.2344
Accumulated time: update_bounds func: 107.6712	 prepare: 32.6997	 bound: 38.4634	 transfer: 0.0127	 finalize: 33.0324
batch bounding time:  1.0281624794006348
Current worst splitting domains [lb, ub] (depth):
[-0.17312,   inf] (109), [-0.17312,   inf] (83), [-0.17311,   inf] (113), [-0.17311,   inf] (121), [-0.17311,   inf] (131), [-0.17311,   inf] (121), [-0.17311,   inf] (43), [-0.17311,   inf] (47), [-0.17311,   inf] (103), [-0.17310,   inf] (99), [-0.17310,   inf] (89), [-0.17310,   inf] (77), [-0.17310,   inf] (93), [-0.17310,   inf] (113), [-0.17310,   inf] (103), [-0.17310,   inf] (95), [-0.17309,   inf] (83), [-0.17309,   inf] (61), [-0.17309,   inf] (95), [-0.17309,   inf] (115), 
length of domains: 60011
Total time: 1.8450	 pickout: 0.2483	 decision: 0.2748	 get_bound: 1.0323	 add_domain: 0.2897
Current lb:-0.1731167733669281
188794 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 205.96772503852844

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 21] [1, 52] [3, 38] [1, 49] [3, 19] [1, 54] [4, 7] [3, 73] [4, 50] [2, 79] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 126.71640014648438 with beta sum per layer: [853.2421875, 2129.382080078125, 1727.8673095703125, 1412.738525390625, 2392.525634765625]
alpha/beta optimization time: 0.397885799407959
This batch time : update_bounds func: 3.2574	 prepare: 0.3965	 bound: 0.3984	 transfer: 0.0129	 finalize: 2.4411
Accumulated time: update_bounds func: 110.9286	 prepare: 33.0961	 bound: 38.8618	 transfer: 0.0129	 finalize: 35.4735
batch bounding time:  3.2599406242370605
Current worst splitting domains [lb, ub] (depth):
[-0.17200,   inf] (71), [-0.17171,   inf] (111), [-0.17171,   inf] (77), [-0.17171,   inf] (69), [-0.17171,   inf] (129), [-0.17171,   inf] (103), [-0.17170,   inf] (71), [-0.17170,   inf] (85), [-0.17170,   inf] (75), [-0.17170,   inf] (57), [-0.17170,   inf] (87), [-0.17170,   inf] (101), [-0.17170,   inf] (89), [-0.17169,   inf] (113), [-0.17169,   inf] (119), [-0.17169,   inf] (65), [-0.17169,   inf] (89), [-0.17169,   inf] (103), [-0.17169,   inf] (117), [-0.17169,   inf] (121), 
length of domains: 60457
Total time: 4.0773	 pickout: 0.2493	 decision: 0.2758	 get_bound: 3.2639	 add_domain: 0.2883
Current lb:-0.1720028966665268
190842 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 210.10078024864197

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 29] [2, 63] [0, 2] [2, 44] [2, 59] [2, 7] [1, 69] [3, 86] [2, 70] [3, 22] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 117.80378723144531 with beta sum per layer: [880.5557861328125, 2108.211669921875, 1793.46728515625, 1442.0142822265625, 2263.744873046875]
alpha/beta optimization time: 0.38726091384887695
This batch time : update_bounds func: 1.0233	 prepare: 0.3863	 bound: 0.3878	 transfer: 0.0123	 finalize: 0.2284
Accumulated time: update_bounds func: 111.9520	 prepare: 33.4824	 bound: 39.2496	 transfer: 0.0123	 finalize: 35.7019
batch bounding time:  1.0257554054260254
Current worst splitting domains [lb, ub] (depth):
[-0.17157,   inf] (67), [-0.17064,   inf] (79), [-0.17035,   inf] (47), [-0.17035,   inf] (73), [-0.17035,   inf] (71), [-0.17035,   inf] (57), [-0.17035,   inf] (101), [-0.17035,   inf] (99), [-0.17035,   inf] (95), [-0.17035,   inf] (117), [-0.17034,   inf] (99), [-0.17034,   inf] (109), [-0.17034,   inf] (105), [-0.17034,   inf] (123), [-0.17034,   inf] (71), [-0.17034,   inf] (91), [-0.17034,   inf] (97), [-0.17034,   inf] (85), [-0.17033,   inf] (71), [-0.17033,   inf] (103), 
length of domains: 60892
Total time: 1.8302	 pickout: 0.2418	 decision: 0.2778	 get_bound: 1.0298	 add_domain: 0.2808
Current lb:-0.17157118022441864
192890 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 211.99594163894653

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 2] [1, 80] [0, 2] [1, 15] [0, 21] [2, 76] [0, 89] [4, 18] [2, 79] [4, 98] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 116.6846923828125 with beta sum per layer: [835.2801513671875, 2345.73486328125, 1959.93798828125, 1499.5810546875, 2237.060546875]
alpha/beta optimization time: 0.38849830627441406
This batch time : update_bounds func: 1.0225	 prepare: 0.3810	 bound: 0.3890	 transfer: 0.0126	 finalize: 0.2316
Accumulated time: update_bounds func: 112.9744	 prepare: 33.8634	 bound: 39.6386	 transfer: 0.0126	 finalize: 35.9335
batch bounding time:  1.024756908416748
Current worst splitting domains [lb, ub] (depth):
[-0.16908,   inf] (131), [-0.16908,   inf] (75), [-0.16908,   inf] (109), [-0.16908,   inf] (69), [-0.16908,   inf] (71), [-0.16908,   inf] (69), [-0.16908,   inf] (119), [-0.16907,   inf] (85), [-0.16907,   inf] (77), [-0.16907,   inf] (101), [-0.16907,   inf] (47), [-0.16907,   inf] (109), [-0.16907,   inf] (115), [-0.16907,   inf] (125), [-0.16907,   inf] (117), [-0.16907,   inf] (87), [-0.16907,   inf] (87), [-0.16907,   inf] (59), [-0.16906,   inf] (87), [-0.16906,   inf] (85), 
length of domains: 61323
Total time: 1.8392	 pickout: 0.2530	 decision: 0.2763	 get_bound: 1.0289	 add_domain: 0.2810
Current lb:-0.16908037662506104
194938 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 213.8952763080597

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 59] [2, 66] [2, 82] [3, 90] [2, 7] [2, 60] [2, 82] [4, 50] [0, 13] [1, 14] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 119.48008728027344 with beta sum per layer: [793.0614013671875, 2200.959228515625, 1881.63134765625, 1480.1923828125, 2279.543212890625]
alpha/beta optimization time: 0.3915679454803467
This batch time : update_bounds func: 1.0230	 prepare: 0.3774	 bound: 0.3921	 transfer: 0.0127	 finalize: 0.2324
Accumulated time: update_bounds func: 113.9975	 prepare: 34.2409	 bound: 40.0306	 transfer: 0.0127	 finalize: 36.1659
batch bounding time:  1.0258088111877441
Current worst splitting domains [lb, ub] (depth):
[-0.16881,   inf] (77), [-0.16846,   inf] (75), [-0.16773,   inf] (69), [-0.16773,   inf] (73), [-0.16773,   inf] (63), [-0.16773,   inf] (103), [-0.16773,   inf] (53), [-0.16773,   inf] (55), [-0.16773,   inf] (107), [-0.16773,   inf] (123), [-0.16773,   inf] (97), [-0.16773,   inf] (101), [-0.16773,   inf] (115), [-0.16773,   inf] (115), [-0.16772,   inf] (101), [-0.16772,   inf] (115), [-0.16772,   inf] (115), [-0.16772,   inf] (89), [-0.16772,   inf] (99), [-0.16772,   inf] (93), 
length of domains: 61753
Total time: 1.8160	 pickout: 0.2307	 decision: 0.2738	 get_bound: 1.0300	 add_domain: 0.2814
Current lb:-0.1688087284564972
196986 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 215.76576399803162

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 29] [2, 59] [3, 4] [1, 52] [2, 57] [2, 56] [3, 84] [3, 75] [1, 93] [4, 71] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 117.615478515625 with beta sum per layer: [895.0416259765625, 2176.93896484375, 1679.67578125, 1454.560302734375, 2296.681884765625]
alpha/beta optimization time: 0.3903191089630127
This batch time : update_bounds func: 1.0251	 prepare: 0.3822	 bound: 0.3908	 transfer: 0.0122	 finalize: 0.2318
Accumulated time: update_bounds func: 115.0226	 prepare: 34.6231	 bound: 40.4214	 transfer: 0.0122	 finalize: 36.3977
batch bounding time:  1.0272951126098633
Current worst splitting domains [lb, ub] (depth):
[-0.16741,   inf] (83), [-0.16695,   inf] (67), [-0.16641,   inf] (79), [-0.16641,   inf] (73), [-0.16641,   inf] (87), [-0.16641,   inf] (87), [-0.16640,   inf] (71), [-0.16640,   inf] (115), [-0.16640,   inf] (69), [-0.16640,   inf] (95), [-0.16640,   inf] (93), [-0.16639,   inf] (103), [-0.16639,   inf] (75), [-0.16639,   inf] (101), [-0.16639,   inf] (109), [-0.16639,   inf] (125), [-0.16639,   inf] (115), [-0.16639,   inf] (73), [-0.16639,   inf] (63), [-0.16639,   inf] (63), 
length of domains: 62212
Total time: 1.8284	 pickout: 0.2351	 decision: 0.2716	 get_bound: 1.0312	 add_domain: 0.2905
Current lb:-0.16741225123405457
199034 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 217.6567714214325

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 2] [1, 29] [3, 17] [2, 66] [0, 88] [1, 54] [2, 7] [2, 56] [0, 2] [2, 79] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 113.86936950683594 with beta sum per layer: [837.45361328125, 2153.48779296875, 1866.2138671875, 1486.893310546875, 2322.006591796875]
alpha/beta optimization time: 0.4328634738922119
This batch time : update_bounds func: 1.1631	 prepare: 0.3732	 bound: 0.4334	 transfer: 0.0131	 finalize: 0.3357
Accumulated time: update_bounds func: 116.1857	 prepare: 34.9963	 bound: 40.8548	 transfer: 0.0131	 finalize: 36.7334
batch bounding time:  1.16603684425354
Current worst splitting domains [lb, ub] (depth):
[-0.16519,   inf] (105), [-0.16518,   inf] (65), [-0.16518,   inf] (87), [-0.16518,   inf] (107), [-0.16518,   inf] (93), [-0.16517,   inf] (111), [-0.16517,   inf] (55), [-0.16517,   inf] (111), [-0.16517,   inf] (69), [-0.16517,   inf] (115), [-0.16517,   inf] (53), [-0.16517,   inf] (71), [-0.16517,   inf] (101), [-0.16517,   inf] (49), [-0.16517,   inf] (97), [-0.16516,   inf] (93), [-0.16516,   inf] (91), [-0.16516,   inf] (83), [-0.16516,   inf] (91), [-0.16516,   inf] (63), 
length of domains: 62653
Total time: 4.1981	 pickout: 0.2306	 decision: 2.4979	 get_bound: 1.1704	 add_domain: 0.2992
Current lb:-0.16518574953079224
201082 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 221.91466879844666

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 82] [1, 69] [2, 53] [4, 67] [2, 40] [0, 72] [2, 57] [2, 82] [0, 2] [0, 30] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 110.86532592773438 with beta sum per layer: [917.5128173828125, 2200.72119140625, 1759.502197265625, 1462.33837890625, 2248.21044921875]
alpha/beta optimization time: 0.41832590103149414
This batch time : update_bounds func: 1.2251	 prepare: 0.5505	 bound: 0.4189	 transfer: 0.0127	 finalize: 0.2348
Accumulated time: update_bounds func: 117.4108	 prepare: 35.5468	 bound: 41.2737	 transfer: 0.0127	 finalize: 36.9682
batch bounding time:  1.2276701927185059
Current worst splitting domains [lb, ub] (depth):
[-0.16391,   inf] (109), [-0.16391,   inf] (59), [-0.16391,   inf] (119), [-0.16391,   inf] (65), [-0.16391,   inf] (45), [-0.16390,   inf] (137), [-0.16390,   inf] (99), [-0.16390,   inf] (117), [-0.16390,   inf] (91), [-0.16390,   inf] (67), [-0.16390,   inf] (91), [-0.16390,   inf] (67), [-0.16389,   inf] (71), [-0.16389,   inf] (125), [-0.16389,   inf] (113), [-0.16389,   inf] (89), [-0.16389,   inf] (67), [-0.16389,   inf] (111), [-0.16389,   inf] (91), [-0.16389,   inf] (111), 
length of domains: 63065
Total time: 2.1827	 pickout: 0.3319	 decision: 0.3375	 get_bound: 1.2318	 add_domain: 0.2815
Current lb:-0.16390888392925262
203130 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 224.1589479446411

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 68] [3, 75] [4, 14] [2, 66] [0, 89] [4, 14] [2, 63] [1, 7] [2, 22] [2, 59] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 113.0449447631836 with beta sum per layer: [859.1448974609375, 2142.8818359375, 1819.50244140625, 1528.67236328125, 2412.176025390625]
alpha/beta optimization time: 0.39314889907836914
This batch time : update_bounds func: 1.0233	 prepare: 0.3771	 bound: 0.3938	 transfer: 0.0121	 finalize: 0.2320
Accumulated time: update_bounds func: 118.4341	 prepare: 35.9239	 bound: 41.6675	 transfer: 0.0121	 finalize: 37.2001
batch bounding time:  1.0256433486938477
Current worst splitting domains [lb, ub] (depth):
[-0.16287,   inf] (77), [-0.16265,   inf] (83), [-0.16265,   inf] (97), [-0.16265,   inf] (75), [-0.16265,   inf] (103), [-0.16265,   inf] (119), [-0.16264,   inf] (105), [-0.16264,   inf] (77), [-0.16264,   inf] (69), [-0.16264,   inf] (85), [-0.16264,   inf] (97), [-0.16264,   inf] (65), [-0.16264,   inf] (63), [-0.16264,   inf] (117), [-0.16264,   inf] (111), [-0.16264,   inf] (125), [-0.16264,   inf] (109), [-0.16263,   inf] (111), [-0.16263,   inf] (77), [-0.16263,   inf] (89), 
length of domains: 63498
Total time: 1.8278	 pickout: 0.2351	 decision: 0.2769	 get_bound: 1.0296	 add_domain: 0.2861
Current lb:-0.16286887228488922
205178 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 226.04283356666565

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 2] [2, 93] [2, 53] [0, 72] [3, 4] [2, 22] [1, 52] [2, 44] [2, 96] [2, 93] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 110.08141326904297 with beta sum per layer: [951.3291015625, 2178.99267578125, 1836.191650390625, 1371.796630859375, 2469.92431640625]
alpha/beta optimization time: 0.3926692008972168
This batch time : update_bounds func: 1.0318	 prepare: 0.3860	 bound: 0.3932	 transfer: 0.0128	 finalize: 0.2315
Accumulated time: update_bounds func: 119.4659	 prepare: 36.3099	 bound: 42.0607	 transfer: 0.0128	 finalize: 37.4316
batch bounding time:  1.0346078872680664
Current worst splitting domains [lb, ub] (depth):
[-0.16140,   inf] (109), [-0.16140,   inf] (89), [-0.16140,   inf] (65), [-0.16140,   inf] (91), [-0.16140,   inf] (63), [-0.16140,   inf] (111), [-0.16140,   inf] (81), [-0.16139,   inf] (81), [-0.16139,   inf] (89), [-0.16139,   inf] (107), [-0.16139,   inf] (107), [-0.16139,   inf] (121), [-0.16139,   inf] (105), [-0.16139,   inf] (97), [-0.16139,   inf] (55), [-0.16138,   inf] (65), [-0.16138,   inf] (87), [-0.16138,   inf] (133), [-0.16138,   inf] (87), [-0.16138,   inf] (103), 
length of domains: 63920
Total time: 1.8332	 pickout: 0.2385	 decision: 0.2723	 get_bound: 1.0390	 add_domain: 0.2833
Current lb:-0.1614014357328415
207226 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 227.9318299293518

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 53] [3, 4] [1, 29] [2, 96] [4, 43] [2, 82] [4, 56] [2, 93] [1, 14] [2, 82] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 106.05509185791016 with beta sum per layer: [862.10791015625, 2164.293701171875, 1848.3720703125, 1535.89111328125, 2206.41650390625]
alpha/beta optimization time: 0.3915550708770752
This batch time : update_bounds func: 1.0305	 prepare: 0.3863	 bound: 0.3921	 transfer: 0.0128	 finalize: 0.2314
Accumulated time: update_bounds func: 120.4964	 prepare: 36.6962	 bound: 42.4528	 transfer: 0.0128	 finalize: 37.6630
batch bounding time:  1.0328996181488037
Current worst splitting domains [lb, ub] (depth):
[-0.16022,   inf] (113), [-0.16022,   inf] (55), [-0.16021,   inf] (89), [-0.16021,   inf] (103), [-0.16021,   inf] (53), [-0.16021,   inf] (113), [-0.16021,   inf] (113), [-0.16021,   inf] (123), [-0.16021,   inf] (75), [-0.16021,   inf] (117), [-0.16021,   inf] (87), [-0.16020,   inf] (83), [-0.16020,   inf] (57), [-0.16020,   inf] (63), [-0.16020,   inf] (53), [-0.16020,   inf] (67), [-0.16020,   inf] (57), [-0.16019,   inf] (93), [-0.16019,   inf] (109), [-0.16019,   inf] (117), 
length of domains: 64345
Total time: 1.8333	 pickout: 0.2350	 decision: 0.2776	 get_bound: 1.0369	 add_domain: 0.2838
Current lb:-0.1602177768945694
209274 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 229.82191348075867

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 93] [2, 63] [2, 63] [4, 67] [2, 57] [0, 13] [2, 44] [3, 38] [2, 82] [2, 63] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 110.42720031738281 with beta sum per layer: [853.7954711914062, 2031.6951904296875, 1843.8583984375, 1519.2022705078125, 2316.458740234375]
alpha/beta optimization time: 0.39183974266052246
This batch time : update_bounds func: 1.0361	 prepare: 0.3874	 bound: 0.3923	 transfer: 0.0127	 finalize: 0.2356
Accumulated time: update_bounds func: 121.5325	 prepare: 37.0836	 bound: 42.8451	 transfer: 0.0127	 finalize: 37.8986
batch bounding time:  1.0385398864746094
Current worst splitting domains [lb, ub] (depth):
[-0.16000,   inf] (67), [-0.15925,   inf] (75), [-0.15905,   inf] (83), [-0.15905,   inf] (69), [-0.15905,   inf] (49), [-0.15905,   inf] (105), [-0.15905,   inf] (111), [-0.15905,   inf] (57), [-0.15905,   inf] (115), [-0.15905,   inf] (87), [-0.15905,   inf] (135), [-0.15905,   inf] (119), [-0.15904,   inf] (99), [-0.15904,   inf] (99), [-0.15904,   inf] (49), [-0.15904,   inf] (97), [-0.15904,   inf] (113), [-0.15904,   inf] (117), [-0.15904,   inf] (59), [-0.15904,   inf] (67), 
length of domains: 64753
Total time: 4.3072	 pickout: 0.2363	 decision: 2.7480	 get_bound: 1.0426	 add_domain: 0.2803
Current lb:-0.15999631583690643
211322 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 234.1847915649414

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 13] [1, 29] [0, 36] [1, 29] [0, 72] [1, 70] [4, 98] [4, 43] [3, 0] [4, 50] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 109.55926513671875 with beta sum per layer: [884.7146606445312, 2139.87451171875, 1918.4691162109375, 1495.664794921875, 2190.44287109375]
alpha/beta optimization time: 0.3999314308166504
This batch time : update_bounds func: 1.0394	 prepare: 0.3883	 bound: 0.4004	 transfer: 0.0127	 finalize: 0.2299
Accumulated time: update_bounds func: 122.5719	 prepare: 37.4719	 bound: 43.2456	 transfer: 0.0127	 finalize: 38.1285
batch bounding time:  1.0419588088989258
Current worst splitting domains [lb, ub] (depth):
[-0.15788,   inf] (71), [-0.15788,   inf] (77), [-0.15788,   inf] (119), [-0.15787,   inf] (99), [-0.15787,   inf] (69), [-0.15787,   inf] (91), [-0.15787,   inf] (111), [-0.15787,   inf] (75), [-0.15787,   inf] (103), [-0.15787,   inf] (109), [-0.15787,   inf] (121), [-0.15787,   inf] (97), [-0.15786,   inf] (43), [-0.15786,   inf] (61), [-0.15786,   inf] (75), [-0.15786,   inf] (75), [-0.15786,   inf] (73), [-0.15786,   inf] (83), [-0.15786,   inf] (89), [-0.15786,   inf] (109), 
length of domains: 65183
Total time: 1.8680	 pickout: 0.2516	 decision: 0.2806	 get_bound: 1.0461	 add_domain: 0.2897
Current lb:-0.15787939727306366
213370 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 236.11546874046326

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 14] [1, 15] [2, 79] [1, 68] [1, 63] [2, 59] [2, 82] [2, 57] [2, 79] [2, 56] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 105.81965637207031 with beta sum per layer: [836.7412109375, 2275.3203125, 1842.01171875, 1515.9456787109375, 2142.82958984375]
alpha/beta optimization time: 0.4043233394622803
This batch time : update_bounds func: 1.0638	 prepare: 0.3992	 bound: 0.4048	 transfer: 0.0126	 finalize: 0.2389
Accumulated time: update_bounds func: 123.6357	 prepare: 37.8711	 bound: 43.6504	 transfer: 0.0126	 finalize: 38.3675
batch bounding time:  1.0663173198699951
Current worst splitting domains [lb, ub] (depth):
[-0.15680,   inf] (49), [-0.15671,   inf] (111), [-0.15671,   inf] (55), [-0.15671,   inf] (103), [-0.15671,   inf] (95), [-0.15671,   inf] (115), [-0.15670,   inf] (57), [-0.15670,   inf] (97), [-0.15670,   inf] (109), [-0.15670,   inf] (79), [-0.15670,   inf] (97), [-0.15670,   inf] (97), [-0.15670,   inf] (73), [-0.15670,   inf] (123), [-0.15670,   inf] (111), [-0.15670,   inf] (111), [-0.15670,   inf] (89), [-0.15669,   inf] (69), [-0.15669,   inf] (119), [-0.15669,   inf] (119), 
length of domains: 65596
Total time: 1.8640	 pickout: 0.2335	 decision: 0.2739	 get_bound: 1.0704	 add_domain: 0.2862
Current lb:-0.15679633617401123
215418 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 238.05167388916016

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 53] [2, 82] [0, 29] [0, 89] [1, 52] [1, 68] [3, 22] [3, 17] [1, 54] [0, 25] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 98.26028442382812 with beta sum per layer: [824.8565673828125, 2193.896240234375, 1836.521728515625, 1529.757568359375, 2314.0439453125]
alpha/beta optimization time: 0.3976726531982422
This batch time : update_bounds func: 1.0404	 prepare: 0.3897	 bound: 0.3982	 transfer: 0.0122	 finalize: 0.2322
Accumulated time: update_bounds func: 124.6761	 prepare: 38.2608	 bound: 44.0486	 transfer: 0.0122	 finalize: 38.5996
batch bounding time:  1.042982578277588
Current worst splitting domains [lb, ub] (depth):
[-0.15546,   inf] (107), [-0.15546,   inf] (97), [-0.15546,   inf] (113), [-0.15546,   inf] (93), [-0.15546,   inf] (111), [-0.15546,   inf] (103), [-0.15546,   inf] (65), [-0.15545,   inf] (87), [-0.15545,   inf] (103), [-0.15545,   inf] (111), [-0.15545,   inf] (129), [-0.15544,   inf] (55), [-0.15544,   inf] (107), [-0.15544,   inf] (107), [-0.15544,   inf] (95), [-0.15544,   inf] (97), [-0.15544,   inf] (79), [-0.15544,   inf] (63), [-0.15544,   inf] (55), [-0.15544,   inf] (69), 
length of domains: 65980
Total time: 1.8431	 pickout: 0.2369	 decision: 0.2759	 get_bound: 1.0470	 add_domain: 0.2834
Current lb:-0.15546445548534393
217466 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 239.96362113952637

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 36] [0, 88] [0, 29] [1, 52] [4, 68] [4, 67] [3, 62] [1, 52] [0, 25] [2, 82] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 99.07157897949219 with beta sum per layer: [814.1846923828125, 2160.313720703125, 1745.947509765625, 1478.1995849609375, 2263.765869140625]
alpha/beta optimization time: 0.39292335510253906
This batch time : update_bounds func: 1.0431	 prepare: 0.3935	 bound: 0.3935	 transfer: 0.0127	 finalize: 0.2353
Accumulated time: update_bounds func: 125.7192	 prepare: 38.6543	 bound: 44.4421	 transfer: 0.0127	 finalize: 38.8350
batch bounding time:  1.045471429824829
Current worst splitting domains [lb, ub] (depth):
[-0.15430,   inf] (93), [-0.15430,   inf] (113), [-0.15430,   inf] (117), [-0.15430,   inf] (65), [-0.15429,   inf] (89), [-0.15429,   inf] (77), [-0.15429,   inf] (63), [-0.15429,   inf] (135), [-0.15429,   inf] (81), [-0.15429,   inf] (109), [-0.15429,   inf] (97), [-0.15429,   inf] (81), [-0.15429,   inf] (81), [-0.15428,   inf] (103), [-0.15428,   inf] (75), [-0.15428,   inf] (127), [-0.15428,   inf] (79), [-0.15428,   inf] (91), [-0.15428,   inf] (43), [-0.15428,   inf] (95), 
length of domains: 66375
Total time: 1.8551	 pickout: 0.2473	 decision: 0.2736	 get_bound: 1.0494	 add_domain: 0.2848
Current lb:-0.15430164337158203
219514 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 241.8767831325531

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 50] [1, 54] [3, 0] [3, 10] [4, 0] [1, 7] [3, 35] [3, 84] [3, 86] [1, 52] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 91.58424377441406 with beta sum per layer: [915.183349609375, 2348.76416015625, 1819.1258544921875, 1529.552490234375, 2138.5791015625]
alpha/beta optimization time: 0.4281139373779297
This batch time : update_bounds func: 1.2583	 prepare: 0.5728	 bound: 0.4287	 transfer: 0.0122	 finalize: 0.2364
Accumulated time: update_bounds func: 126.9775	 prepare: 39.2272	 bound: 44.8708	 transfer: 0.0122	 finalize: 39.0714
batch bounding time:  1.2608325481414795
Current worst splitting domains [lb, ub] (depth):
[-0.15321,   inf] (101), [-0.15321,   inf] (61), [-0.15321,   inf] (119), [-0.15321,   inf] (125), [-0.15320,   inf] (69), [-0.15320,   inf] (67), [-0.15320,   inf] (81), [-0.15320,   inf] (75), [-0.15320,   inf] (51), [-0.15320,   inf] (117), [-0.15319,   inf] (117), [-0.15319,   inf] (123), [-0.15319,   inf] (105), [-0.15319,   inf] (105), [-0.15319,   inf] (87), [-0.15319,   inf] (69), [-0.15319,   inf] (81), [-0.15319,   inf] (95), [-0.15319,   inf] (119), [-0.15318,   inf] (65), 
length of domains: 66742
Total time: 4.7011	 pickout: 0.3407	 decision: 2.8180	 get_bound: 1.2649	 add_domain: 0.2774
Current lb:-0.15320749580860138
221562 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 246.63839197158813

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 7] [3, 17] [2, 7] [3, 38] [0, 21] [1, 54] [3, 35] [2, 53] [3, 84] [2, 82] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 96.49490356445312 with beta sum per layer: [909.6358032226562, 2122.81298828125, 1903.57568359375, 1515.456787109375, 2277.771484375]
alpha/beta optimization time: 0.3862757682800293
This batch time : update_bounds func: 1.0341	 prepare: 0.3917	 bound: 0.3868	 transfer: 0.0122	 finalize: 0.2351
Accumulated time: update_bounds func: 128.0116	 prepare: 39.6188	 bound: 45.2576	 transfer: 0.0122	 finalize: 39.3065
batch bounding time:  1.0366334915161133
Current worst splitting domains [lb, ub] (depth):
[-0.15225,   inf] (81), [-0.15212,   inf] (109), [-0.15211,   inf] (99), [-0.15211,   inf] (107), [-0.15211,   inf] (85), [-0.15211,   inf] (107), [-0.15211,   inf] (107), [-0.15211,   inf] (79), [-0.15211,   inf] (77), [-0.15211,   inf] (61), [-0.15211,   inf] (79), [-0.15211,   inf] (103), [-0.15211,   inf] (119), [-0.15210,   inf] (113), [-0.15210,   inf] (113), [-0.15210,   inf] (87), [-0.15209,   inf] (95), [-0.15209,   inf] (105), [-0.15209,   inf] (81), [-0.15209,   inf] (103), 
length of domains: 67136
Total time: 1.8417	 pickout: 0.2431	 decision: 0.2729	 get_bound: 1.0408	 add_domain: 0.2849
Current lb:-0.15225467085838318
223610 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 248.54164695739746

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 17] [4, 98] [1, 49] [4, 68] [1, 63] [4, 50] [4, 50] [3, 62] [2, 93] [2, 57] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 95.92550659179688 with beta sum per layer: [854.3250732421875, 2274.9677734375, 1833.237548828125, 1533.39990234375, 2277.87158203125]
alpha/beta optimization time: 0.4040184020996094
This batch time : update_bounds func: 1.1343	 prepare: 0.3820	 bound: 0.4045	 transfer: 0.0127	 finalize: 0.3267
Accumulated time: update_bounds func: 129.1459	 prepare: 40.0009	 bound: 45.6621	 transfer: 0.0127	 finalize: 39.6332
batch bounding time:  1.1371452808380127
Current worst splitting domains [lb, ub] (depth):
[-0.15096,   inf] (73), [-0.15096,   inf] (77), [-0.15096,   inf] (109), [-0.15096,   inf] (95), [-0.15096,   inf] (121), [-0.15096,   inf] (83), [-0.15096,   inf] (105), [-0.15095,   inf] (39), [-0.15095,   inf] (57), [-0.15095,   inf] (101), [-0.15095,   inf] (97), [-0.15095,   inf] (63), [-0.15095,   inf] (39), [-0.15095,   inf] (71), [-0.15095,   inf] (103), [-0.15094,   inf] (117), [-0.15094,   inf] (63), [-0.15094,   inf] (93), [-0.15094,   inf] (129), [-0.15094,   inf] (97), 
length of domains: 67507
Total time: 1.9824	 pickout: 0.2485	 decision: 0.2842	 get_bound: 1.1414	 add_domain: 0.3084
Current lb:-0.15096047520637512
225658 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 250.5878734588623

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 68] [2, 82] [4, 68] [2, 27] [3, 78] [1, 52] [2, 63] [2, 56] [0, 4] [0, 32] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 92.90904998779297 with beta sum per layer: [880.191162109375, 2104.82666015625, 1850.8267822265625, 1559.056640625, 2327.216064453125]
alpha/beta optimization time: 0.38382673263549805
This batch time : update_bounds func: 1.0294	 prepare: 0.3895	 bound: 0.3843	 transfer: 0.0122	 finalize: 0.2352
Accumulated time: update_bounds func: 130.1753	 prepare: 40.3904	 bound: 46.0465	 transfer: 0.0122	 finalize: 39.8684
batch bounding time:  1.0320029258728027
Current worst splitting domains [lb, ub] (depth):
[-0.14997,   inf] (81), [-0.14986,   inf] (53), [-0.14986,   inf] (101), [-0.14986,   inf] (93), [-0.14985,   inf] (65), [-0.14985,   inf] (91), [-0.14985,   inf] (133), [-0.14985,   inf] (87), [-0.14985,   inf] (101), [-0.14985,   inf] (53), [-0.14984,   inf] (73), [-0.14984,   inf] (91), [-0.14984,   inf] (71), [-0.14984,   inf] (121), [-0.14984,   inf] (73), [-0.14984,   inf] (105), [-0.14983,   inf] (81), [-0.14983,   inf] (133), [-0.14983,   inf] (97), [-0.14983,   inf] (125), 
length of domains: 67887
Total time: 1.8354	 pickout: 0.2472	 decision: 0.2739	 get_bound: 1.0362	 add_domain: 0.2781
Current lb:-0.1499735713005066
227706 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 252.48216915130615

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 17] [2, 99] [1, 52] [1, 7] [1, 49] [2, 40] [1, 49] [0, 72] [1, 52] [1, 29] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 83.9243392944336 with beta sum per layer: [888.7925415039062, 2174.534912109375, 1820.93408203125, 1563.9228515625, 2191.9833984375]
alpha/beta optimization time: 0.3871173858642578
This batch time : update_bounds func: 1.0243	 prepare: 0.3815	 bound: 0.3876	 transfer: 0.0123	 finalize: 0.2348
Accumulated time: update_bounds func: 131.1997	 prepare: 40.7719	 bound: 46.4341	 transfer: 0.0123	 finalize: 40.1032
batch bounding time:  1.0269215106964111
Current worst splitting domains [lb, ub] (depth):
[-0.14967,   inf] (65), [-0.14896,   inf] (51), [-0.14875,   inf] (67), [-0.14874,   inf] (99), [-0.14874,   inf] (121), [-0.14874,   inf] (93), [-0.14874,   inf] (131), [-0.14874,   inf] (63), [-0.14874,   inf] (109), [-0.14874,   inf] (103), [-0.14874,   inf] (123), [-0.14874,   inf] (45), [-0.14874,   inf] (123), [-0.14874,   inf] (95), [-0.14874,   inf] (97), [-0.14874,   inf] (127), [-0.14873,   inf] (107), [-0.14873,   inf] (95), [-0.14873,   inf] (99), [-0.14873,   inf] (71), 
length of domains: 68214
Total time: 1.8239	 pickout: 0.2522	 decision: 0.2713	 get_bound: 1.0311	 add_domain: 0.2693
Current lb:-0.14966511726379395
229754 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 254.36603450775146

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 17] [0, 53] [3, 90] [2, 79] [2, 44] [3, 86] [1, 54] [3, 73] [4, 68] [2, 82] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 88.9996337890625 with beta sum per layer: [855.2882080078125, 2090.918212890625, 1951.098876953125, 1538.3421630859375, 2237.984619140625]
alpha/beta optimization time: 0.38208603858947754
This batch time : update_bounds func: 3.6560	 prepare: 0.3883	 bound: 0.3827	 transfer: 0.0123	 finalize: 2.8643
Accumulated time: update_bounds func: 134.8556	 prepare: 41.1601	 bound: 46.8168	 transfer: 0.0123	 finalize: 42.9675
batch bounding time:  3.659048080444336
Current worst splitting domains [lb, ub] (depth):
[-0.14786,   inf] (77), [-0.14786,   inf] (61), [-0.14773,   inf] (77), [-0.14773,   inf] (101), [-0.14773,   inf] (91), [-0.14772,   inf] (107), [-0.14772,   inf] (75), [-0.14772,   inf] (65), [-0.14772,   inf] (93), [-0.14772,   inf] (57), [-0.14772,   inf] (79), [-0.14772,   inf] (129), [-0.14772,   inf] (101), [-0.14772,   inf] (67), [-0.14772,   inf] (83), [-0.14771,   inf] (69), [-0.14771,   inf] (111), [-0.14771,   inf] (101), [-0.14771,   inf] (99), [-0.14771,   inf] (117), 
length of domains: 68589
Total time: 4.4854	 pickout: 0.2544	 decision: 0.2752	 get_bound: 3.6638	 add_domain: 0.2920
Current lb:-0.14786271750926971
231802 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 258.9198021888733

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 98] [1, 95] [3, 73] [1, 63] [3, 38] [3, 38] [1, 80] [2, 63] [1, 49] [2, 66] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 88.44381713867188 with beta sum per layer: [773.0352172851562, 2163.17431640625, 1956.437255859375, 1639.1578369140625, 2194.69384765625]
alpha/beta optimization time: 0.4001286029815674
This batch time : update_bounds func: 1.0477	 prepare: 0.3887	 bound: 0.4006	 transfer: 0.0122	 finalize: 0.2380
Accumulated time: update_bounds func: 135.9033	 prepare: 41.5489	 bound: 47.2174	 transfer: 0.0122	 finalize: 43.2055
batch bounding time:  1.050276756286621
Current worst splitting domains [lb, ub] (depth):
[-0.14663,   inf] (99), [-0.14663,   inf] (55), [-0.14663,   inf] (71), [-0.14663,   inf] (79), [-0.14663,   inf] (71), [-0.14663,   inf] (111), [-0.14663,   inf] (89), [-0.14663,   inf] (67), [-0.14663,   inf] (57), [-0.14663,   inf] (73), [-0.14662,   inf] (75), [-0.14662,   inf] (73), [-0.14662,   inf] (121), [-0.14662,   inf] (89), [-0.14662,   inf] (97), [-0.14662,   inf] (65), [-0.14662,   inf] (87), [-0.14662,   inf] (69), [-0.14662,   inf] (75), [-0.14662,   inf] (83), 
length of domains: 68961
Total time: 1.9188	 pickout: 0.2706	 decision: 0.3068	 get_bound: 1.0544	 add_domain: 0.2870
Current lb:-0.14663055539131165
233850 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 260.8971061706543

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 14] [3, 86] [3, 98] [1, 52] [3, 98] [4, 67] [1, 68] [1, 80] [3, 22] [3, 98] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 79.15270233154297 with beta sum per layer: [794.72314453125, 2114.955322265625, 1957.8330078125, 1579.077392578125, 2352.697265625]
alpha/beta optimization time: 0.38214802742004395
This batch time : update_bounds func: 1.0574	 prepare: 0.4041	 bound: 0.3827	 transfer: 0.0121	 finalize: 0.2504
Accumulated time: update_bounds func: 136.9608	 prepare: 41.9530	 bound: 47.6001	 transfer: 0.0121	 finalize: 43.4559
batch bounding time:  1.059910774230957
Current worst splitting domains [lb, ub] (depth):
[-0.14586,   inf] (77), [-0.14557,   inf] (73), [-0.14557,   inf] (97), [-0.14557,   inf] (79), [-0.14557,   inf] (69), [-0.14557,   inf] (111), [-0.14557,   inf] (83), [-0.14557,   inf] (99), [-0.14557,   inf] (113), [-0.14557,   inf] (75), [-0.14556,   inf] (133), [-0.14556,   inf] (69), [-0.14556,   inf] (91), [-0.14556,   inf] (97), [-0.14556,   inf] (75), [-0.14556,   inf] (59), [-0.14556,   inf] (93), [-0.14556,   inf] (111), [-0.14556,   inf] (123), [-0.14556,   inf] (129), 
length of domains: 69332
Total time: 1.8960	 pickout: 0.2606	 decision: 0.2761	 get_bound: 1.0645	 add_domain: 0.2947
Current lb:-0.14585517346858978
235898 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 262.85636925697327

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 69] [0, 30] [4, 0] [0, 29] [0, 13] [4, 68] [4, 18] [4, 56] [3, 38] [0, 88] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 86.74008178710938 with beta sum per layer: [869.1002197265625, 2113.63916015625, 1867.1767578125, 1502.570556640625, 2259.91845703125]
alpha/beta optimization time: 0.38253331184387207
This batch time : update_bounds func: 1.0338	 prepare: 0.3946	 bound: 0.3830	 transfer: 0.0121	 finalize: 0.2358
Accumulated time: update_bounds func: 137.9945	 prepare: 42.3476	 bound: 47.9831	 transfer: 0.0121	 finalize: 43.6917
batch bounding time:  1.0364127159118652
Current worst splitting domains [lb, ub] (depth):
[-0.14556,   inf] (77), [-0.14486,   inf] (77), [-0.14455,   inf] (121), [-0.14455,   inf] (83), [-0.14455,   inf] (71), [-0.14455,   inf] (79), [-0.14455,   inf] (45), [-0.14454,   inf] (55), [-0.14454,   inf] (107), [-0.14454,   inf] (79), [-0.14454,   inf] (61), [-0.14453,   inf] (89), [-0.14453,   inf] (77), [-0.14453,   inf] (69), [-0.14453,   inf] (101), [-0.14453,   inf] (57), [-0.14452,   inf] (99), [-0.14452,   inf] (73), [-0.14452,   inf] (75), [-0.14452,   inf] (67), 
length of domains: 69691
Total time: 1.8765	 pickout: 0.2634	 decision: 0.2712	 get_bound: 1.0412	 add_domain: 0.3007
Current lb:-0.1455613672733307
237946 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 264.81545186042786

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 29] [1, 29] [3, 38] [1, 54] [2, 53] [2, 76] [2, 66] [0, 25] [4, 28] [2, 75] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 80.70578002929688 with beta sum per layer: [826.9769897460938, 2253.64013671875, 1868.6513671875, 1517.4354248046875, 2234.4609375]
alpha/beta optimization time: 0.3825500011444092
This batch time : update_bounds func: 1.0319	 prepare: 0.3958	 bound: 0.3830	 transfer: 0.0126	 finalize: 0.2324
Accumulated time: update_bounds func: 139.0264	 prepare: 42.7434	 bound: 48.3661	 transfer: 0.0126	 finalize: 43.9241
batch bounding time:  1.034360647201538
Current worst splitting domains [lb, ub] (depth):
[-0.14348,   inf] (117), [-0.14348,   inf] (101), [-0.14348,   inf] (75), [-0.14348,   inf] (109), [-0.14348,   inf] (107), [-0.14348,   inf] (51), [-0.14348,   inf] (105), [-0.14348,   inf] (75), [-0.14348,   inf] (107), [-0.14347,   inf] (79), [-0.14347,   inf] (93), [-0.14347,   inf] (115), [-0.14347,   inf] (103), [-0.14347,   inf] (117), [-0.14347,   inf] (93), [-0.14347,   inf] (89), [-0.14347,   inf] (121), [-0.14347,   inf] (137), [-0.14347,   inf] (135), [-0.14347,   inf] (103), 
length of domains: 70018
Total time: 1.8590	 pickout: 0.2706	 decision: 0.2736	 get_bound: 1.0385	 add_domain: 0.2762
Current lb:-0.1434849202632904
239994 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 266.7347893714905

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 25] [3, 87] [1, 93] [0, 36] [2, 79] [4, 43] [4, 28] [1, 70] [1, 63] [2, 63] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 74.58045959472656 with beta sum per layer: [830.8487548828125, 2257.6552734375, 1931.626708984375, 1544.751708984375, 2272.49755859375]
alpha/beta optimization time: 0.3858821392059326
This batch time : update_bounds func: 1.0482	 prepare: 0.4018	 bound: 0.3864	 transfer: 0.0125	 finalize: 0.2395
Accumulated time: update_bounds func: 140.0746	 prepare: 43.1451	 bound: 48.7526	 transfer: 0.0125	 finalize: 44.1637
batch bounding time:  1.0509233474731445
Current worst splitting domains [lb, ub] (depth):
[-0.14297,   inf] (65), [-0.14237,   inf] (87), [-0.14236,   inf] (63), [-0.14236,   inf] (101), [-0.14236,   inf] (77), [-0.14236,   inf] (85), [-0.14236,   inf] (91), [-0.14236,   inf] (93), [-0.14236,   inf] (129), [-0.14236,   inf] (123), [-0.14235,   inf] (85), [-0.14235,   inf] (53), [-0.14235,   inf] (103), [-0.14235,   inf] (103), [-0.14235,   inf] (85), [-0.14235,   inf] (115), [-0.14235,   inf] (101), [-0.14235,   inf] (97), [-0.14235,   inf] (61), [-0.14235,   inf] (105), 
length of domains: 70334
Total time: 1.8617	 pickout: 0.2610	 decision: 0.2744	 get_bound: 1.0551	 add_domain: 0.2711
Current lb:-0.1429743766784668
242042 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 268.6581916809082

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 17] [4, 56] [0, 21] [3, 76] [2, 7] [1, 49] [4, 50] [2, 60] [4, 14] [2, 59] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 76.47390747070312 with beta sum per layer: [869.170654296875, 2098.978759765625, 1954.708251953125, 1528.48974609375, 2245.03125]
alpha/beta optimization time: 0.38393425941467285
This batch time : update_bounds func: 1.0305	 prepare: 0.3897	 bound: 0.3844	 transfer: 0.0122	 finalize: 0.2358
Accumulated time: update_bounds func: 141.1052	 prepare: 43.5349	 bound: 49.1370	 transfer: 0.0122	 finalize: 44.3995
batch bounding time:  1.0334742069244385
Current worst splitting domains [lb, ub] (depth):
[-0.14133,   inf] (93), [-0.14133,   inf] (55), [-0.14133,   inf] (111), [-0.14133,   inf] (47), [-0.14133,   inf] (71), [-0.14133,   inf] (75), [-0.14133,   inf] (77), [-0.14133,   inf] (109), [-0.14132,   inf] (113), [-0.14132,   inf] (117), [-0.14132,   inf] (111), [-0.14132,   inf] (117), [-0.14132,   inf] (137), [-0.14132,   inf] (107), [-0.14132,   inf] (49), [-0.14132,   inf] (101), [-0.14132,   inf] (127), [-0.14132,   inf] (79), [-0.14132,   inf] (113), [-0.14131,   inf] (93), 
length of domains: 70650
Total time: 4.6022	 pickout: 0.2583	 decision: 3.0341	 get_bound: 1.0380	 add_domain: 0.2717
Current lb:-0.1413307785987854
244090 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 273.32106494903564

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 90] [0, 21] [1, 7] [3, 90] [0, 13] [3, 90] [3, 2] [3, 0] [2, 82] [1, 7] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 73.20298767089844 with beta sum per layer: [816.692138671875, 2259.2021484375, 1956.545166015625, 1569.1673583984375, 2229.08447265625]
alpha/beta optimization time: 0.395113468170166
This batch time : update_bounds func: 1.0403	 prepare: 0.3896	 bound: 0.3956	 transfer: 0.0124	 finalize: 0.2340
Accumulated time: update_bounds func: 142.1455	 prepare: 43.9245	 bound: 49.5326	 transfer: 0.0124	 finalize: 44.6335
batch bounding time:  1.0431275367736816
Current worst splitting domains [lb, ub] (depth):
[-0.14087,   inf] (67), [-0.14060,   inf] (81), [-0.14030,   inf] (97), [-0.14030,   inf] (91), [-0.14030,   inf] (79), [-0.14030,   inf] (57), [-0.14030,   inf] (115), [-0.14030,   inf] (137), [-0.14030,   inf] (99), [-0.14030,   inf] (87), [-0.14030,   inf] (65), [-0.14029,   inf] (51), [-0.14029,   inf] (115), [-0.14029,   inf] (121), [-0.14029,   inf] (95), [-0.14029,   inf] (125), [-0.14029,   inf] (83), [-0.14029,   inf] (101), [-0.14029,   inf] (93), [-0.14028,   inf] (117), 
length of domains: 70967
Total time: 1.8416	 pickout: 0.2473	 decision: 0.2745	 get_bound: 1.0473	 add_domain: 0.2726
Current lb:-0.14086878299713135
246138 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 275.2221510410309

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 29] [1, 63] [2, 79] [3, 38] [2, 7] [2, 57] [4, 67] [4, 14] [2, 7] [2, 70] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 76.18174743652344 with beta sum per layer: [906.236328125, 2269.056396484375, 1864.80322265625, 1613.513671875, 2175.3623046875]
alpha/beta optimization time: 0.3926980495452881
This batch time : update_bounds func: 1.0393	 prepare: 0.3911	 bound: 0.3932	 transfer: 0.0120	 finalize: 0.2352
Accumulated time: update_bounds func: 143.1848	 prepare: 44.3156	 bound: 49.9258	 transfer: 0.0120	 finalize: 44.8687
batch bounding time:  1.04172682762146
Current worst splitting domains [lb, ub] (depth):
[-0.14006,   inf] (77), [-0.13931,   inf] (63), [-0.13930,   inf] (121), [-0.13930,   inf] (103), [-0.13930,   inf] (83), [-0.13930,   inf] (129), [-0.13930,   inf] (79), [-0.13930,   inf] (73), [-0.13930,   inf] (75), [-0.13930,   inf] (99), [-0.13929,   inf] (45), [-0.13929,   inf] (129), [-0.13929,   inf] (127), [-0.13929,   inf] (87), [-0.13929,   inf] (115), [-0.13929,   inf] (125), [-0.13929,   inf] (107), [-0.13929,   inf] (109), [-0.13929,   inf] (113), [-0.13929,   inf] (71), 
length of domains: 71301
Total time: 1.8357	 pickout: 0.2437	 decision: 0.2732	 get_bound: 1.0455	 add_domain: 0.2733
Current lb:-0.14006000757217407
248186 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 277.11824011802673

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 69] [1, 93] [2, 82] [1, 52] [2, 44] [1, 70] [2, 57] [3, 2] [1, 43] [2, 70] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 74.68573760986328 with beta sum per layer: [787.856689453125, 2306.351806640625, 1947.1263427734375, 1638.942138671875, 2168.924072265625]
alpha/beta optimization time: 0.38401150703430176
This batch time : update_bounds func: 1.0312	 prepare: 0.3894	 bound: 0.3846	 transfer: 0.0123	 finalize: 0.2369
Accumulated time: update_bounds func: 144.2160	 prepare: 44.7050	 bound: 50.3104	 transfer: 0.0123	 finalize: 45.1056
batch bounding time:  1.034078598022461
Current worst splitting domains [lb, ub] (depth):
[-0.13827,   inf] (109), [-0.13827,   inf] (135), [-0.13827,   inf] (133), [-0.13827,   inf] (123), [-0.13827,   inf] (109), [-0.13827,   inf] (107), [-0.13827,   inf] (131), [-0.13827,   inf] (101), [-0.13827,   inf] (47), [-0.13827,   inf] (53), [-0.13826,   inf] (61), [-0.13826,   inf] (125), [-0.13826,   inf] (53), [-0.13826,   inf] (111), [-0.13826,   inf] (51), [-0.13826,   inf] (99), [-0.13826,   inf] (101), [-0.13826,   inf] (73), [-0.13826,   inf] (99), [-0.13826,   inf] (105), 
length of domains: 71606
Total time: 1.8342	 pickout: 0.2462	 decision: 0.2771	 get_bound: 1.0384	 add_domain: 0.2725
Current lb:-0.13827277719974518
250234 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 279.01951479911804

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 21] [0, 21] [2, 22] [2, 22] [2, 82] [1, 70] [3, 38] [4, 71] [3, 17] [0, 2] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 70.73268127441406 with beta sum per layer: [866.489013671875, 2151.926513671875, 1926.669189453125, 1548.24462890625, 2312.5537109375]
alpha/beta optimization time: 0.3879053592681885
This batch time : update_bounds func: 1.0491	 prepare: 0.4012	 bound: 0.3884	 transfer: 0.0122	 finalize: 0.2388
Accumulated time: update_bounds func: 145.2651	 prepare: 45.1062	 bound: 50.6988	 transfer: 0.0122	 finalize: 45.3444
batch bounding time:  1.0518362522125244
Current worst splitting domains [lb, ub] (depth):
[-0.13730,   inf] (111), [-0.13730,   inf] (53), [-0.13729,   inf] (105), [-0.13729,   inf] (89), [-0.13729,   inf] (99), [-0.13729,   inf] (103), [-0.13729,   inf] (95), [-0.13729,   inf] (105), [-0.13729,   inf] (131), [-0.13729,   inf] (95), [-0.13729,   inf] (135), [-0.13728,   inf] (85), [-0.13728,   inf] (121), [-0.13728,   inf] (75), [-0.13728,   inf] (121), [-0.13728,   inf] (91), [-0.13728,   inf] (73), [-0.13728,   inf] (69), [-0.13727,   inf] (49), [-0.13727,   inf] (97), 
length of domains: 71937
Total time: 1.8539	 pickout: 0.2417	 decision: 0.2803	 get_bound: 1.0562	 add_domain: 0.2757
Current lb:-0.1373002827167511
252282 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 280.93492603302

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 82] [2, 57] [2, 82] [0, 88] [3, 49] [2, 93] [1, 49] [2, 60] [1, 7] [1, 49] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 72.29178619384766 with beta sum per layer: [843.2539672851562, 2228.377685546875, 1877.70166015625, 1516.6533203125, 2428.044189453125]
alpha/beta optimization time: 0.3863046169281006
This batch time : update_bounds func: 3.8409	 prepare: 0.3933	 bound: 0.3869	 transfer: 0.0121	 finalize: 3.0403
Accumulated time: update_bounds func: 149.1060	 prepare: 45.4995	 bound: 51.0857	 transfer: 0.0121	 finalize: 48.3847
batch bounding time:  3.843304395675659
Current worst splitting domains [lb, ub] (depth):
[-0.13628,   inf] (91), [-0.13628,   inf] (117), [-0.13627,   inf] (111), [-0.13627,   inf] (87), [-0.13627,   inf] (85), [-0.13627,   inf] (75), [-0.13627,   inf] (95), [-0.13627,   inf] (105), [-0.13627,   inf] (75), [-0.13627,   inf] (65), [-0.13627,   inf] (133), [-0.13627,   inf] (129), [-0.13627,   inf] (117), [-0.13627,   inf] (67), [-0.13627,   inf] (75), [-0.13627,   inf] (67), [-0.13627,   inf] (41), [-0.13626,   inf] (129), [-0.13626,   inf] (67), [-0.13626,   inf] (101), 
length of domains: 72235
Total time: 4.6371	 pickout: 0.2463	 decision: 0.2779	 get_bound: 3.8473	 add_domain: 0.2657
Current lb:-0.13627581298351288
254330 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 285.6336588859558

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 38] [3, 38] [2, 82] [2, 76] [2, 82] [1, 7] [2, 79] [3, 0] [2, 82] [0, 13] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 69.83220672607422 with beta sum per layer: [837.0765380859375, 2240.030029296875, 2033.7093505859375, 1528.359375, 2122.204833984375]
alpha/beta optimization time: 0.38341784477233887
This batch time : update_bounds func: 1.0281	 prepare: 0.3867	 bound: 0.3839	 transfer: 0.0127	 finalize: 0.2361
Accumulated time: update_bounds func: 150.1341	 prepare: 45.8862	 bound: 51.4696	 transfer: 0.0127	 finalize: 48.6208
batch bounding time:  1.0305280685424805
Current worst splitting domains [lb, ub] (depth):
[-0.13569,   inf] (69), [-0.13560,   inf] (51), [-0.13524,   inf] (109), [-0.13524,   inf] (99), [-0.13524,   inf] (45), [-0.13524,   inf] (141), [-0.13524,   inf] (101), [-0.13524,   inf] (67), [-0.13524,   inf] (85), [-0.13524,   inf] (119), [-0.13524,   inf] (59), [-0.13524,   inf] (53), [-0.13524,   inf] (105), [-0.13524,   inf] (83), [-0.13524,   inf] (111), [-0.13524,   inf] (105), [-0.13524,   inf] (131), [-0.13524,   inf] (103), [-0.13524,   inf] (69), [-0.13524,   inf] (97), 
length of domains: 72538
Total time: 1.8274	 pickout: 0.2473	 decision: 0.2748	 get_bound: 1.0345	 add_domain: 0.2707
Current lb:-0.13569259643554688
256378 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 287.5261836051941

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 44] [3, 62] [2, 79] [3, 49] [2, 96] [4, 82] [3, 87] [4, 18] [0, 2] [2, 22] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 67.0098648071289 with beta sum per layer: [885.5556640625, 2167.578369140625, 1957.731689453125, 1662.8226318359375, 2256.68212890625]
alpha/beta optimization time: 0.38202834129333496
This batch time : update_bounds func: 1.0215	 prepare: 0.3782	 bound: 0.3825	 transfer: 0.0121	 finalize: 0.2405
Accumulated time: update_bounds func: 151.1556	 prepare: 46.2644	 bound: 51.8521	 transfer: 0.0121	 finalize: 48.8613
batch bounding time:  1.0239403247833252
Current worst splitting domains [lb, ub] (depth):
[-0.13468,   inf] (65), [-0.13430,   inf] (79), [-0.13427,   inf] (77), [-0.13427,   inf] (131), [-0.13427,   inf] (91), [-0.13427,   inf] (69), [-0.13427,   inf] (67), [-0.13427,   inf] (97), [-0.13427,   inf] (61), [-0.13427,   inf] (91), [-0.13427,   inf] (147), [-0.13427,   inf] (137), [-0.13427,   inf] (123), [-0.13427,   inf] (95), [-0.13427,   inf] (113), [-0.13426,   inf] (95), [-0.13426,   inf] (95), [-0.13426,   inf] (135), [-0.13426,   inf] (85), [-0.13426,   inf] (85), 
length of domains: 72838
Total time: 1.8054	 pickout: 0.2352	 decision: 0.2706	 get_bound: 1.0280	 add_domain: 0.2715
Current lb:-0.13467572629451752
258426 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 289.3930103778839

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 80] [2, 82] [2, 61] [4, 92] [3, 38] [0, 21] [3, 10] [2, 7] [0, 72] [3, 35] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 64.78881072998047 with beta sum per layer: [855.697998046875, 2279.707275390625, 1973.763916015625, 1522.062744140625, 2347.416259765625]
alpha/beta optimization time: 0.3828704357147217
This batch time : update_bounds func: 1.0243	 prepare: 0.3825	 bound: 0.3834	 transfer: 0.0121	 finalize: 0.2382
Accumulated time: update_bounds func: 152.1799	 prepare: 46.6469	 bound: 52.2355	 transfer: 0.0121	 finalize: 49.0995
batch bounding time:  1.026686191558838
Current worst splitting domains [lb, ub] (depth):
[-0.13331,   inf] (85), [-0.13331,   inf] (113), [-0.13331,   inf] (119), [-0.13331,   inf] (99), [-0.13331,   inf] (109), [-0.13330,   inf] (109), [-0.13330,   inf] (125), [-0.13330,   inf] (87), [-0.13330,   inf] (105), [-0.13330,   inf] (111), [-0.13330,   inf] (109), [-0.13330,   inf] (127), [-0.13330,   inf] (127), [-0.13330,   inf] (75), [-0.13330,   inf] (117), [-0.13329,   inf] (97), [-0.13329,   inf] (67), [-0.13329,   inf] (103), [-0.13329,   inf] (81), [-0.13329,   inf] (85), 
length of domains: 73139
Total time: 1.8085	 pickout: 0.2394	 decision: 0.2697	 get_bound: 1.0307	 add_domain: 0.2687
Current lb:-0.13331098854541779
260474 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 291.2622950077057

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 52] [3, 38] [3, 38] [0, 29] [2, 82] [3, 38] [3, 78] [1, 52] [2, 7] [2, 79] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 58.82151794433594 with beta sum per layer: [823.029296875, 2314.12890625, 1860.8858642578125, 1660.333984375, 2174.54248046875]
alpha/beta optimization time: 0.38825464248657227
This batch time : update_bounds func: 1.0424	 prepare: 0.3858	 bound: 0.3888	 transfer: 0.0121	 finalize: 0.2474
Accumulated time: update_bounds func: 153.2223	 prepare: 47.0327	 bound: 52.6243	 transfer: 0.0121	 finalize: 49.3469
batch bounding time:  1.045095682144165
Current worst splitting domains [lb, ub] (depth):
[-0.13285,   inf] (45), [-0.13235,   inf] (141), [-0.13235,   inf] (81), [-0.13235,   inf] (89), [-0.13235,   inf] (77), [-0.13235,   inf] (85), [-0.13235,   inf] (71), [-0.13235,   inf] (113), [-0.13235,   inf] (115), [-0.13234,   inf] (91), [-0.13234,   inf] (59), [-0.13234,   inf] (81), [-0.13234,   inf] (59), [-0.13234,   inf] (91), [-0.13234,   inf] (81), [-0.13234,   inf] (119), [-0.13234,   inf] (105), [-0.13234,   inf] (123), [-0.13234,   inf] (113), [-0.13234,   inf] (95), 
length of domains: 73441
Total time: 1.8369	 pickout: 0.2406	 decision: 0.2743	 get_bound: 1.0494	 add_domain: 0.2725
Current lb:-0.13285484910011292
262522 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 293.1682333946228

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 36] [1, 7] [1, 49] [1, 7] [0, 88] [4, 50] [2, 76] [2, 82] [4, 20] [2, 40] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 63.90436935424805 with beta sum per layer: [875.1705932617188, 2205.7685546875, 1872.1932373046875, 1697.773193359375, 2313.875]
alpha/beta optimization time: 0.37766432762145996
This batch time : update_bounds func: 1.0144	 prepare: 0.3814	 bound: 0.3782	 transfer: 0.0121	 finalize: 0.2340
Accumulated time: update_bounds func: 154.2367	 prepare: 47.4141	 bound: 53.0024	 transfer: 0.0121	 finalize: 49.5809
batch bounding time:  1.017411231994629
Current worst splitting domains [lb, ub] (depth):
[-0.13142,   inf] (71), [-0.13142,   inf] (109), [-0.13142,   inf] (101), [-0.13142,   inf] (95), [-0.13142,   inf] (117), [-0.13142,   inf] (95), [-0.13142,   inf] (123), [-0.13142,   inf] (119), [-0.13142,   inf] (85), [-0.13142,   inf] (133), [-0.13141,   inf] (113), [-0.13141,   inf] (103), [-0.13141,   inf] (137), [-0.13141,   inf] (97), [-0.13141,   inf] (77), [-0.13141,   inf] (67), [-0.13141,   inf] (87), [-0.13141,   inf] (61), [-0.13141,   inf] (83), [-0.13141,   inf] (67), 
length of domains: 73733
Total time: 1.8015	 pickout: 0.2415	 decision: 0.2721	 get_bound: 1.0216	 add_domain: 0.2662
Current lb:-0.131417915225029
264570 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 295.0406050682068

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 57] [4, 67] [1, 52] [1, 70] [2, 82] [2, 79] [4, 28] [0, 29] [1, 43] [2, 7] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 62.51693344116211 with beta sum per layer: [850.6590576171875, 2422.301513671875, 1830.642822265625, 1582.8372802734375, 2131.85205078125]
alpha/beta optimization time: 0.39319610595703125
This batch time : update_bounds func: 1.0460	 prepare: 0.3896	 bound: 0.3937	 transfer: 0.0125	 finalize: 0.2421
Accumulated time: update_bounds func: 155.2827	 prepare: 47.8037	 bound: 53.3961	 transfer: 0.0125	 finalize: 49.8231
batch bounding time:  1.0486578941345215
Current worst splitting domains [lb, ub] (depth):
[-0.13048,   inf] (121), [-0.13048,   inf] (121), [-0.13048,   inf] (89), [-0.13048,   inf] (113), [-0.13048,   inf] (73), [-0.13048,   inf] (121), [-0.13048,   inf] (111), [-0.13048,   inf] (97), [-0.13048,   inf] (85), [-0.13048,   inf] (99), [-0.13048,   inf] (43), [-0.13048,   inf] (123), [-0.13047,   inf] (103), [-0.13047,   inf] (57), [-0.13047,   inf] (71), [-0.13047,   inf] (65), [-0.13047,   inf] (113), [-0.13047,   inf] (93), [-0.13047,   inf] (115), [-0.13047,   inf] (57), 
length of domains: 74037
Total time: 4.7639	 pickout: 0.2517	 decision: 3.1873	 get_bound: 1.0528	 add_domain: 0.2720
Current lb:-0.13048481941223145
266618 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 299.8748023509979

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 7] [1, 52] [0, 21] [2, 82] [1, 70] [2, 44] [2, 79] [2, 56] [2, 44] [0, 36] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 56.265037536621094 with beta sum per layer: [891.5689086914062, 2117.50830078125, 1943.2108154296875, 1622.7998046875, 2373.63623046875]
alpha/beta optimization time: 0.399463415145874
This batch time : update_bounds func: 1.0759	 prepare: 0.4178	 bound: 0.4000	 transfer: 0.0120	 finalize: 0.2377
Accumulated time: update_bounds func: 156.3586	 prepare: 48.2215	 bound: 53.7961	 transfer: 0.0120	 finalize: 50.0608
batch bounding time:  1.0784761905670166
Current worst splitting domains [lb, ub] (depth):
[-0.12953,   inf] (79), [-0.12953,   inf] (95), [-0.12953,   inf] (79), [-0.12953,   inf] (49), [-0.12953,   inf] (75), [-0.12953,   inf] (93), [-0.12953,   inf] (103), [-0.12953,   inf] (101), [-0.12952,   inf] (69), [-0.12952,   inf] (105), [-0.12952,   inf] (113), [-0.12952,   inf] (71), [-0.12952,   inf] (107), [-0.12952,   inf] (107), [-0.12952,   inf] (119), [-0.12952,   inf] (109), [-0.12952,   inf] (51), [-0.12952,   inf] (127), [-0.12952,   inf] (105), [-0.12952,   inf] (125), 
length of domains: 74301
Total time: 1.8691	 pickout: 0.2475	 decision: 0.2758	 get_bound: 1.0827	 add_domain: 0.2631
Current lb:-0.1295318454504013
268666 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 301.81206917762756

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 13] [3, 49] [2, 63] [3, 84] [2, 93] [0, 13] [2, 56] [3, 76] [2, 59] [3, 0] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 61.57188034057617 with beta sum per layer: [824.8372802734375, 2164.33642578125, 1914.69384765625, 1657.8427734375, 2243.222900390625]
alpha/beta optimization time: 0.39266228675842285
This batch time : update_bounds func: 1.0748	 prepare: 0.3982	 bound: 0.3932	 transfer: 0.0125	 finalize: 0.2622
Accumulated time: update_bounds func: 157.4334	 prepare: 48.6197	 bound: 54.1893	 transfer: 0.0125	 finalize: 50.3229
batch bounding time:  1.0772361755371094
Current worst splitting domains [lb, ub] (depth):
[-0.12933,   inf] (53), [-0.12863,   inf] (113), [-0.12863,   inf] (119), [-0.12863,   inf] (91), [-0.12862,   inf] (53), [-0.12862,   inf] (109), [-0.12862,   inf] (79), [-0.12862,   inf] (107), [-0.12862,   inf] (111), [-0.12862,   inf] (89), [-0.12862,   inf] (61), [-0.12862,   inf] (103), [-0.12862,   inf] (97), [-0.12862,   inf] (71), [-0.12862,   inf] (67), [-0.12862,   inf] (43), [-0.12862,   inf] (87), [-0.12862,   inf] (51), [-0.12862,   inf] (127), [-0.12862,   inf] (85), 
length of domains: 74557
Total time: 1.8748	 pickout: 0.2467	 decision: 0.2829	 get_bound: 1.0814	 add_domain: 0.2638
Current lb:-0.1293310821056366
270714 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 303.7499957084656

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 53] [3, 38] [2, 59] [4, 50] [3, 19] [1, 54] [2, 44] [2, 22] [2, 44] [2, 22] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 58.03776550292969 with beta sum per layer: [937.553955078125, 2276.046875, 1826.423828125, 1667.672607421875, 2269.59912109375]
alpha/beta optimization time: 0.3982815742492676
This batch time : update_bounds func: 1.0656	 prepare: 0.4044	 bound: 0.3988	 transfer: 0.0123	 finalize: 0.2419
Accumulated time: update_bounds func: 158.4990	 prepare: 49.0241	 bound: 54.5881	 transfer: 0.0123	 finalize: 50.5648
batch bounding time:  1.0684497356414795
Current worst splitting domains [lb, ub] (depth):
[-0.12816,   inf] (53), [-0.12773,   inf] (77), [-0.12773,   inf] (109), [-0.12773,   inf] (97), [-0.12773,   inf] (93), [-0.12773,   inf] (99), [-0.12773,   inf] (59), [-0.12773,   inf] (101), [-0.12773,   inf] (63), [-0.12773,   inf] (45), [-0.12772,   inf] (133), [-0.12772,   inf] (65), [-0.12772,   inf] (65), [-0.12772,   inf] (83), [-0.12772,   inf] (119), [-0.12772,   inf] (147), [-0.12772,   inf] (43), [-0.12772,   inf] (113), [-0.12771,   inf] (69), [-0.12771,   inf] (117), 
length of domains: 74828
Total time: 1.8571	 pickout: 0.2455	 decision: 0.2749	 get_bound: 1.0727	 add_domain: 0.2641
Current lb:-0.1281614750623703
272762 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 305.67868185043335

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 53] [1, 63] [2, 59] [1, 14] [0, 88] [1, 70] [2, 64] [4, 67] [3, 14] [2, 99] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 54.88292694091797 with beta sum per layer: [857.9097290039062, 2204.796630859375, 1892.4912109375, 1660.8583984375, 2285.3984375]
alpha/beta optimization time: 0.38915395736694336
This batch time : update_bounds func: 1.0419	 prepare: 0.3885	 bound: 0.3897	 transfer: 0.0123	 finalize: 0.2433
Accumulated time: update_bounds func: 159.5409	 prepare: 49.4126	 bound: 54.9777	 transfer: 0.0123	 finalize: 50.8081
batch bounding time:  1.0448660850524902
Current worst splitting domains [lb, ub] (depth):
[-0.12680,   inf] (57), [-0.12680,   inf] (97), [-0.12680,   inf] (117), [-0.12679,   inf] (117), [-0.12679,   inf] (73), [-0.12679,   inf] (121), [-0.12679,   inf] (101), [-0.12679,   inf] (77), [-0.12679,   inf] (75), [-0.12679,   inf] (57), [-0.12679,   inf] (113), [-0.12678,   inf] (123), [-0.12678,   inf] (69), [-0.12678,   inf] (109), [-0.12678,   inf] (127), [-0.12678,   inf] (123), [-0.12678,   inf] (89), [-0.12678,   inf] (123), [-0.12678,   inf] (61), [-0.12678,   inf] (95), 
length of domains: 75121
Total time: 1.8357	 pickout: 0.2415	 decision: 0.2736	 get_bound: 1.0494	 add_domain: 0.2712
Current lb:-0.12679626047611237
274810 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 307.58056116104126

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 73] [1, 49] [2, 82] [2, 79] [2, 57] [2, 40] [1, 24] [0, 2] [2, 61] [3, 17] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 62.70185089111328 with beta sum per layer: [831.379638671875, 2302.78271484375, 1941.785888671875, 1576.643310546875, 2145.13671875]
alpha/beta optimization time: 0.3847332000732422
This batch time : update_bounds func: 1.0402	 prepare: 0.3937	 bound: 0.3852	 transfer: 0.0122	 finalize: 0.2404
Accumulated time: update_bounds func: 160.5811	 prepare: 49.8062	 bound: 55.3630	 transfer: 0.0122	 finalize: 51.0485
batch bounding time:  1.0427284240722656
Current worst splitting domains [lb, ub] (depth):
[-0.12594,   inf] (119), [-0.12594,   inf] (57), [-0.12594,   inf] (115), [-0.12594,   inf] (115), [-0.12594,   inf] (111), [-0.12594,   inf] (79), [-0.12594,   inf] (99), [-0.12594,   inf] (83), [-0.12594,   inf] (43), [-0.12594,   inf] (99), [-0.12594,   inf] (113), [-0.12594,   inf] (119), [-0.12594,   inf] (117), [-0.12593,   inf] (97), [-0.12593,   inf] (61), [-0.12593,   inf] (125), [-0.12593,   inf] (69), [-0.12593,   inf] (107), [-0.12593,   inf] (115), [-0.12592,   inf] (101), 
length of domains: 75408
Total time: 1.8519	 pickout: 0.2525	 decision: 0.2779	 get_bound: 1.0469	 add_domain: 0.2745
Current lb:-0.1259445995092392
276858 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 309.50031900405884

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 98] [3, 21] [2, 22] [2, 56] [1, 7] [3, 86] [3, 98] [2, 63] [2, 66] [2, 27] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 54.702964782714844 with beta sum per layer: [837.4722900390625, 2161.391357421875, 2002.7333984375, 1694.95361328125, 2219.415283203125]
alpha/beta optimization time: 0.3853261470794678
This batch time : update_bounds func: 1.0400	 prepare: 0.3949	 bound: 0.3858	 transfer: 0.0126	 finalize: 0.2384
Accumulated time: update_bounds func: 161.6211	 prepare: 50.2012	 bound: 55.7488	 transfer: 0.0126	 finalize: 51.2869
batch bounding time:  1.0427656173706055
Current worst splitting domains [lb, ub] (depth):
[-0.12521,   inf] (73), [-0.12509,   inf] (109), [-0.12509,   inf] (91), [-0.12509,   inf] (141), [-0.12509,   inf] (125), [-0.12509,   inf] (111), [-0.12509,   inf] (53), [-0.12509,   inf] (119), [-0.12509,   inf] (57), [-0.12509,   inf] (69), [-0.12509,   inf] (85), [-0.12509,   inf] (103), [-0.12508,   inf] (109), [-0.12508,   inf] (115), [-0.12508,   inf] (83), [-0.12508,   inf] (81), [-0.12508,   inf] (105), [-0.12508,   inf] (67), [-0.12508,   inf] (87), [-0.12508,   inf] (95), 
length of domains: 75660
Total time: 4.7795	 pickout: 0.2521	 decision: 3.2102	 get_bound: 1.0472	 add_domain: 0.2700
Current lb:-0.1252073496580124
278906 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 314.3542466163635

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 29] [2, 79] [2, 56] [1, 7] [3, 62] [1, 63] [0, 21] [4, 28] [3, 84] [1, 80] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 56.88902282714844 with beta sum per layer: [857.2615356445312, 2240.22314453125, 1936.7269287109375, 1613.65625, 2251.935546875]
alpha/beta optimization time: 0.38262200355529785
This batch time : update_bounds func: 1.0349	 prepare: 0.3925	 bound: 0.3831	 transfer: 0.0121	 finalize: 0.2390
Accumulated time: update_bounds func: 162.6560	 prepare: 50.5937	 bound: 56.1319	 transfer: 0.0121	 finalize: 51.5259
batch bounding time:  1.0374255180358887
Current worst splitting domains [lb, ub] (depth):
[-0.12500,   inf] (77), [-0.12422,   inf] (125), [-0.12422,   inf] (141), [-0.12422,   inf] (81), [-0.12422,   inf] (95), [-0.12422,   inf] (119), [-0.12422,   inf] (127), [-0.12422,   inf] (75), [-0.12421,   inf] (127), [-0.12421,   inf] (67), [-0.12421,   inf] (113), [-0.12421,   inf] (81), [-0.12421,   inf] (101), [-0.12421,   inf] (115), [-0.12421,   inf] (57), [-0.12421,   inf] (117), [-0.12421,   inf] (85), [-0.12421,   inf] (49), [-0.12421,   inf] (77), [-0.12421,   inf] (65), 
length of domains: 75929
Total time: 1.8596	 pickout: 0.2618	 decision: 0.2878	 get_bound: 1.0416	 add_domain: 0.2684
Current lb:-0.12499949336051941
280954 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 316.27754497528076

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 63] [2, 40] [0, 25] [1, 95] [1, 93] [4, 71] [4, 28] [3, 17] [2, 60] [2, 59] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 50.09674072265625 with beta sum per layer: [823.29150390625, 2359.865234375, 1948.833984375, 1597.03125, 2288.341064453125]
alpha/beta optimization time: 0.3840336799621582
This batch time : update_bounds func: 1.0387	 prepare: 0.3938	 bound: 0.3845	 transfer: 0.0120	 finalize: 0.2397
Accumulated time: update_bounds func: 163.6946	 prepare: 50.9875	 bound: 56.5164	 transfer: 0.0120	 finalize: 51.7656
batch bounding time:  1.0411098003387451
Current worst splitting domains [lb, ub] (depth):
[-0.12335,   inf] (91), [-0.12335,   inf] (133), [-0.12335,   inf] (75), [-0.12335,   inf] (115), [-0.12335,   inf] (77), [-0.12335,   inf] (103), [-0.12335,   inf] (73), [-0.12335,   inf] (73), [-0.12335,   inf] (67), [-0.12335,   inf] (113), [-0.12335,   inf] (85), [-0.12335,   inf] (63), [-0.12335,   inf] (77), [-0.12335,   inf] (95), [-0.12335,   inf] (81), [-0.12334,   inf] (115), [-0.12334,   inf] (113), [-0.12334,   inf] (53), [-0.12334,   inf] (119), [-0.12334,   inf] (75), 
length of domains: 76201
Total time: 1.8521	 pickout: 0.2579	 decision: 0.2790	 get_bound: 1.0453	 add_domain: 0.2700
Current lb:-0.12335491180419922
283002 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 318.1921594142914

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 82] [4, 82] [0, 4] [2, 82] [3, 73] [1, 70] [1, 69] [0, 88] [3, 98] [1, 17] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 42.139732360839844 with beta sum per layer: [956.0079345703125, 2294.1796875, 1974.41259765625, 1664.6181640625, 2145.422119140625]
alpha/beta optimization time: 0.3826887607574463
This batch time : update_bounds func: 1.0402	 prepare: 0.3962	 bound: 0.3832	 transfer: 0.0119	 finalize: 0.2402
Accumulated time: update_bounds func: 164.7348	 prepare: 51.3837	 bound: 56.8996	 transfer: 0.0119	 finalize: 52.0058
batch bounding time:  1.0427162647247314
Current worst splitting domains [lb, ub] (depth):
[-0.12246,   inf] (83), [-0.12246,   inf] (47), [-0.12245,   inf] (95), [-0.12245,   inf] (91), [-0.12245,   inf] (131), [-0.12245,   inf] (105), [-0.12245,   inf] (133), [-0.12245,   inf] (101), [-0.12245,   inf] (121), [-0.12245,   inf] (79), [-0.12245,   inf] (77), [-0.12245,   inf] (137), [-0.12245,   inf] (71), [-0.12245,   inf] (91), [-0.12245,   inf] (123), [-0.12245,   inf] (95), [-0.12245,   inf] (119), [-0.12245,   inf] (125), [-0.12245,   inf] (81), [-0.12245,   inf] (93), 
length of domains: 76447
Total time: 1.8509	 pickout: 0.2615	 decision: 0.2789	 get_bound: 1.0470	 add_domain: 0.2635
Current lb:-0.12245580554008484
285050 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 320.1121995449066

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 60] [4, 34] [1, 54] [4, 56] [2, 44] [2, 22] [3, 38] [2, 57] [2, 59] [1, 49] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 49.82910919189453 with beta sum per layer: [835.4906005859375, 2303.784912109375, 1886.3927001953125, 1669.3896484375, 2225.301025390625]
alpha/beta optimization time: 0.38511013984680176
This batch time : update_bounds func: 1.0385	 prepare: 0.3916	 bound: 0.3856	 transfer: 0.0133	 finalize: 0.2397
Accumulated time: update_bounds func: 165.7733	 prepare: 51.7753	 bound: 57.2852	 transfer: 0.0133	 finalize: 52.2455
batch bounding time:  1.0407774448394775
Current worst splitting domains [lb, ub] (depth):
[-0.12214,   inf] (83), [-0.12158,   inf] (135), [-0.12158,   inf] (73), [-0.12158,   inf] (99), [-0.12157,   inf] (69), [-0.12157,   inf] (93), [-0.12157,   inf] (121), [-0.12157,   inf] (115), [-0.12157,   inf] (79), [-0.12157,   inf] (67), [-0.12157,   inf] (101), [-0.12157,   inf] (115), [-0.12156,   inf] (103), [-0.12156,   inf] (117), [-0.12156,   inf] (91), [-0.12156,   inf] (103), [-0.12156,   inf] (121), [-0.12156,   inf] (73), [-0.12156,   inf] (67), [-0.12156,   inf] (97), 
length of domains: 76714
Total time: 1.8514	 pickout: 0.2595	 decision: 0.2768	 get_bound: 1.0449	 add_domain: 0.2702
Current lb:-0.12214411795139313
287098 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 322.02603244781494

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 2] [1, 7] [3, 75] [1, 63] [2, 7] [0, 89] [1, 7] [1, 93] [3, 35] [2, 60] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 42.72749328613281 with beta sum per layer: [864.4025268554688, 2135.703125, 2011.010986328125, 1526.069580078125, 2265.26904296875]
alpha/beta optimization time: 0.38291454315185547
This batch time : update_bounds func: 1.0534	 prepare: 0.4105	 bound: 0.3834	 transfer: 0.0126	 finalize: 0.2383
Accumulated time: update_bounds func: 166.8266	 prepare: 52.1858	 bound: 57.6686	 transfer: 0.0126	 finalize: 52.4838
batch bounding time:  1.0558457374572754
Current worst splitting domains [lb, ub] (depth):
[-0.12149,   inf] (41), [-0.12070,   inf] (87), [-0.12070,   inf] (65), [-0.12070,   inf] (63), [-0.12070,   inf] (119), [-0.12070,   inf] (67), [-0.12069,   inf] (125), [-0.12069,   inf] (61), [-0.12069,   inf] (105), [-0.12069,   inf] (81), [-0.12069,   inf] (103), [-0.12069,   inf] (123), [-0.12069,   inf] (89), [-0.12069,   inf] (111), [-0.12069,   inf] (89), [-0.12069,   inf] (83), [-0.12069,   inf] (65), [-0.12068,   inf] (67), [-0.12068,   inf] (101), [-0.12068,   inf] (89), 
length of domains: 76971
Total time: 1.8661	 pickout: 0.2611	 decision: 0.2727	 get_bound: 1.0599	 add_domain: 0.2724
Current lb:-0.12149020284414291
289146 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 323.97628903388977

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 87] [2, 22] [2, 60] [1, 49] [4, 92] [3, 10] [3, 0] [1, 49] [3, 4] [3, 87] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 50.45643615722656 with beta sum per layer: [926.2730712890625, 2254.671875, 1975.068359375, 1681.35546875, 2055.7763671875]
alpha/beta optimization time: 0.38787364959716797
This batch time : update_bounds func: 1.0282	 prepare: 0.3834	 bound: 0.3884	 transfer: 0.0124	 finalize: 0.2355
Accumulated time: update_bounds func: 167.8549	 prepare: 52.5692	 bound: 58.0570	 transfer: 0.0124	 finalize: 52.7194
batch bounding time:  1.030846357345581
Current worst splitting domains [lb, ub] (depth):
[-0.11985,   inf] (95), [-0.11984,   inf] (79), [-0.11984,   inf] (111), [-0.11984,   inf] (45), [-0.11984,   inf] (99), [-0.11984,   inf] (139), [-0.11984,   inf] (73), [-0.11984,   inf] (97), [-0.11984,   inf] (119), [-0.11984,   inf] (113), [-0.11984,   inf] (103), [-0.11984,   inf] (107), [-0.11984,   inf] (87), [-0.11984,   inf] (99), [-0.11984,   inf] (113), [-0.11984,   inf] (111), [-0.11984,   inf] (113), [-0.11984,   inf] (105), [-0.11984,   inf] (67), [-0.11983,   inf] (99), 
length of domains: 77222
Total time: 4.9546	 pickout: 0.2681	 decision: 3.3690	 get_bound: 1.0350	 add_domain: 0.2825
Current lb:-0.11984507739543915
291194 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 329.00542426109314

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 86] [3, 2] [1, 7] [2, 57] [2, 79] [4, 14] [3, 35] [0, 72] [4, 71] [1, 43] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 37.60326385498047 with beta sum per layer: [852.6040649414062, 2427.511474609375, 1957.6427001953125, 1671.018798828125, 2163.465576171875]
alpha/beta optimization time: 0.38068485260009766
This batch time : update_bounds func: 1.0321	 prepare: 0.3932	 bound: 0.3812	 transfer: 0.0120	 finalize: 0.2373
Accumulated time: update_bounds func: 168.8869	 prepare: 52.9624	 bound: 58.4382	 transfer: 0.0120	 finalize: 52.9567
batch bounding time:  1.0345666408538818
Current worst splitting domains [lb, ub] (depth):
[-0.11904,   inf] (101), [-0.11903,   inf] (113), [-0.11903,   inf] (59), [-0.11903,   inf] (51), [-0.11903,   inf] (69), [-0.11903,   inf] (75), [-0.11903,   inf] (77), [-0.11903,   inf] (99), [-0.11903,   inf] (71), [-0.11903,   inf] (77), [-0.11903,   inf] (101), [-0.11903,   inf] (73), [-0.11903,   inf] (77), [-0.11903,   inf] (131), [-0.11902,   inf] (93), [-0.11902,   inf] (97), [-0.11902,   inf] (123), [-0.11902,   inf] (127), [-0.11902,   inf] (77), [-0.11902,   inf] (93), 
length of domains: 77459
Total time: 1.8303	 pickout: 0.2615	 decision: 0.2716	 get_bound: 1.0386	 add_domain: 0.2586
Current lb:-0.11903530359268188
293242 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 330.8984217643738

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 67] [0, 21] [1, 49] [2, 60] [2, 59] [3, 90] [4, 18] [3, 38] [1, 93] [2, 7] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 42.251014709472656 with beta sum per layer: [824.7572021484375, 2342.64208984375, 1861.764404296875, 1674.1719970703125, 2204.165771484375]
alpha/beta optimization time: 0.3876962661743164
This batch time : update_bounds func: 1.0523	 prepare: 0.3861	 bound: 0.3882	 transfer: 0.0135	 finalize: 0.2560
Accumulated time: update_bounds func: 169.9392	 prepare: 53.3485	 bound: 58.8264	 transfer: 0.0135	 finalize: 53.2127
batch bounding time:  1.0555696487426758
Current worst splitting domains [lb, ub] (depth):
[-0.11841,   inf] (73), [-0.11826,   inf] (55), [-0.11826,   inf] (97), [-0.11826,   inf] (93), [-0.11825,   inf] (65), [-0.11825,   inf] (143), [-0.11825,   inf] (115), [-0.11825,   inf] (129), [-0.11825,   inf] (47), [-0.11825,   inf] (89), [-0.11825,   inf] (71), [-0.11825,   inf] (105), [-0.11825,   inf] (97), [-0.11824,   inf] (69), [-0.11824,   inf] (87), [-0.11824,   inf] (93), [-0.11824,   inf] (123), [-0.11824,   inf] (81), [-0.11824,   inf] (113), [-0.11824,   inf] (95), 
length of domains: 77685
Total time: 1.8574	 pickout: 0.2555	 decision: 0.2738	 get_bound: 1.0609	 add_domain: 0.2672
Current lb:-0.11840532720088959
295290 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 332.82046389579773

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 29] [4, 43] [1, 70] [2, 60] [1, 93] [0, 25] [3, 38] [4, 82] [3, 21] [2, 70] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 44.85283660888672 with beta sum per layer: [901.0040893554688, 2193.5673828125, 1952.785888671875, 1681.7340087890625, 2199.65185546875]
alpha/beta optimization time: 0.3840944766998291
This batch time : update_bounds func: 1.0445	 prepare: 0.3992	 bound: 0.3847	 transfer: 0.0125	 finalize: 0.2393
Accumulated time: update_bounds func: 170.9837	 prepare: 53.7477	 bound: 59.2111	 transfer: 0.0125	 finalize: 53.4520
batch bounding time:  1.047151803970337
Current worst splitting domains [lb, ub] (depth):
[-0.11789,   inf] (85), [-0.11742,   inf] (71), [-0.11742,   inf] (119), [-0.11742,   inf] (95), [-0.11742,   inf] (123), [-0.11742,   inf] (101), [-0.11742,   inf] (115), [-0.11742,   inf] (75), [-0.11742,   inf] (115), [-0.11742,   inf] (117), [-0.11742,   inf] (121), [-0.11742,   inf] (57), [-0.11742,   inf] (85), [-0.11742,   inf] (83), [-0.11742,   inf] (79), [-0.11741,   inf] (113), [-0.11741,   inf] (73), [-0.11741,   inf] (97), [-0.11741,   inf] (73), [-0.11741,   inf] (79), 
length of domains: 77941
Total time: 1.8580	 pickout: 0.2561	 decision: 0.2828	 get_bound: 1.0513	 add_domain: 0.2678
Current lb:-0.11789345741271973
297338 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 334.7473590373993

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 75] [0, 25] [3, 78] [2, 79] [4, 92] [4, 98] [1, 49] [1, 68] [1, 70] [4, 71] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 44.91117858886719 with beta sum per layer: [867.100830078125, 2293.21337890625, 1960.392578125, 1632.18896484375, 2130.79052734375]
alpha/beta optimization time: 0.38544225692749023
This batch time : update_bounds func: 1.0509	 prepare: 0.4004	 bound: 0.3860	 transfer: 0.0125	 finalize: 0.2435
Accumulated time: update_bounds func: 172.0346	 prepare: 54.1481	 bound: 59.5970	 transfer: 0.0125	 finalize: 53.6955
batch bounding time:  1.053609848022461
Current worst splitting domains [lb, ub] (depth):
[-0.11663,   inf] (81), [-0.11663,   inf] (113), [-0.11663,   inf] (115), [-0.11662,   inf] (97), [-0.11662,   inf] (87), [-0.11662,   inf] (111), [-0.11662,   inf] (105), [-0.11662,   inf] (111), [-0.11662,   inf] (123), [-0.11662,   inf] (59), [-0.11662,   inf] (127), [-0.11662,   inf] (79), [-0.11662,   inf] (59), [-0.11662,   inf] (91), [-0.11662,   inf] (113), [-0.11662,   inf] (81), [-0.11662,   inf] (115), [-0.11662,   inf] (39), [-0.11662,   inf] (113), [-0.11662,   inf] (109), 
length of domains: 78150
Total time: 1.8493	 pickout: 0.2516	 decision: 0.2812	 get_bound: 1.0579	 add_domain: 0.2586
Current lb:-0.1166258305311203
299386 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 336.6608831882477

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 93] [4, 71] [2, 79] [1, 70] [0, 21] [2, 82] [4, 67] [2, 82] [0, 89] [3, 73] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 43.95250701904297 with beta sum per layer: [791.4668579101562, 2240.59521484375, 1939.5269775390625, 1701.0712890625, 2077.703125]
alpha/beta optimization time: 0.38375329971313477
This batch time : update_bounds func: 1.0427	 prepare: 0.3962	 bound: 0.3843	 transfer: 0.0125	 finalize: 0.2413
Accumulated time: update_bounds func: 173.0773	 prepare: 54.5444	 bound: 59.9813	 transfer: 0.0125	 finalize: 53.9368
batch bounding time:  1.045335054397583
Current worst splitting domains [lb, ub] (depth):
[-0.11584,   inf] (121), [-0.11584,   inf] (95), [-0.11584,   inf] (105), [-0.11584,   inf] (109), [-0.11584,   inf] (103), [-0.11584,   inf] (105), [-0.11584,   inf] (99), [-0.11584,   inf] (125), [-0.11584,   inf] (95), [-0.11584,   inf] (79), [-0.11584,   inf] (125), [-0.11584,   inf] (115), [-0.11584,   inf] (55), [-0.11583,   inf] (81), [-0.11583,   inf] (95), [-0.11583,   inf] (127), [-0.11583,   inf] (115), [-0.11583,   inf] (117), [-0.11583,   inf] (103), [-0.11583,   inf] (81), 
length of domains: 78392
Total time: 1.8469	 pickout: 0.2539	 decision: 0.2774	 get_bound: 1.0496	 add_domain: 0.2660
Current lb:-0.11584460735321045
301434 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 338.5726742744446

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 0] [4, 67] [1, 52] [1, 68] [3, 4] [3, 0] [4, 68] [4, 28] [1, 54] [1, 63] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 50.893707275390625 with beta sum per layer: [892.0322265625, 2152.48876953125, 2011.205078125, 1697.8775634765625, 2386.85107421875]
alpha/beta optimization time: 0.38630056381225586
This batch time : update_bounds func: 4.2593	 prepare: 0.4198	 bound: 0.3868	 transfer: 0.0124	 finalize: 0.2392
Accumulated time: update_bounds func: 177.3366	 prepare: 54.9642	 bound: 60.3681	 transfer: 0.0124	 finalize: 54.1760
batch bounding time:  4.261856555938721
Current worst splitting domains [lb, ub] (depth):
[-0.11500,   inf] (87), [-0.11500,   inf] (65), [-0.11500,   inf] (121), [-0.11500,   inf] (77), [-0.11500,   inf] (123), [-0.11500,   inf] (115), [-0.11500,   inf] (113), [-0.11500,   inf] (81), [-0.11500,   inf] (93), [-0.11500,   inf] (123), [-0.11500,   inf] (91), [-0.11499,   inf] (101), [-0.11499,   inf] (83), [-0.11499,   inf] (119), [-0.11499,   inf] (71), [-0.11499,   inf] (71), [-0.11499,   inf] (67), [-0.11499,   inf] (113), [-0.11499,   inf] (125), [-0.11499,   inf] (125), 
length of domains: 78617
Total time: 5.0502	 pickout: 0.2501	 decision: 0.2773	 get_bound: 4.2661	 add_domain: 0.2567
Current lb:-0.1150003969669342
303482 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 343.686429977417

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 60] [2, 64] [2, 56] [1, 49] [2, 53] [2, 22] [4, 67] [2, 60] [1, 52] [1, 7] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 38.963836669921875 with beta sum per layer: [887.5303344726562, 2370.4169921875, 1924.96875, 1675.8603515625, 2160.515869140625]
alpha/beta optimization time: 0.3924136161804199
This batch time : update_bounds func: 1.0558	 prepare: 0.3984	 bound: 0.3929	 transfer: 0.0130	 finalize: 0.2430
Accumulated time: update_bounds func: 178.3924	 prepare: 55.3626	 bound: 60.7611	 transfer: 0.0130	 finalize: 54.4190
batch bounding time:  1.0584959983825684
Current worst splitting domains [lb, ub] (depth):
[-0.11459,   inf] (43), [-0.11418,   inf] (111), [-0.11418,   inf] (97), [-0.11418,   inf] (71), [-0.11418,   inf] (97), [-0.11418,   inf] (105), [-0.11418,   inf] (109), [-0.11418,   inf] (89), [-0.11418,   inf] (99), [-0.11418,   inf] (111), [-0.11418,   inf] (99), [-0.11418,   inf] (67), [-0.11418,   inf] (75), [-0.11418,   inf] (93), [-0.11417,   inf] (115), [-0.11417,   inf] (139), [-0.11417,   inf] (111), [-0.11417,   inf] (79), [-0.11417,   inf] (91), [-0.11417,   inf] (109), 
length of domains: 78838
Total time: 1.8430	 pickout: 0.2469	 decision: 0.2733	 get_bound: 1.0629	 add_domain: 0.2599
Current lb:-0.11459008604288101
305530 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 345.59995913505554

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 15] [2, 53] [3, 35] [1, 68] [3, 38] [4, 68] [1, 7] [1, 63] [2, 7] [4, 67] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 41.035606384277344 with beta sum per layer: [914.552978515625, 2280.504638671875, 2042.9818115234375, 1571.6669921875, 2236.91748046875]
alpha/beta optimization time: 0.387117862701416
This batch time : update_bounds func: 1.0493	 prepare: 0.3948	 bound: 0.3876	 transfer: 0.0121	 finalize: 0.2460
Accumulated time: update_bounds func: 179.4417	 prepare: 55.7574	 bound: 61.1487	 transfer: 0.0121	 finalize: 54.6650
batch bounding time:  1.0518791675567627
Current worst splitting domains [lb, ub] (depth):
[-0.11340,   inf] (93), [-0.11340,   inf] (75), [-0.11340,   inf] (99), [-0.11340,   inf] (127), [-0.11340,   inf] (83), [-0.11340,   inf] (83), [-0.11340,   inf] (125), [-0.11340,   inf] (63), [-0.11340,   inf] (125), [-0.11340,   inf] (117), [-0.11340,   inf] (91), [-0.11340,   inf] (111), [-0.11340,   inf] (81), [-0.11339,   inf] (97), [-0.11339,   inf] (41), [-0.11339,   inf] (149), [-0.11339,   inf] (69), [-0.11339,   inf] (73), [-0.11339,   inf] (49), [-0.11339,   inf] (97), 
length of domains: 79063
Total time: 1.8402	 pickout: 0.2441	 decision: 0.2745	 get_bound: 1.0561	 add_domain: 0.2655
Current lb:-0.11340286582708359
307578 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 347.51063895225525

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 63] [2, 60] [1, 93] [2, 82] [2, 70] [2, 57] [2, 82] [0, 21] [2, 22] [1, 54] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 37.402793884277344 with beta sum per layer: [846.4803466796875, 2198.259521484375, 1954.650634765625, 1666.036865234375, 2200.747802734375]
alpha/beta optimization time: 0.39548182487487793
This batch time : update_bounds func: 1.0886	 prepare: 0.3888	 bound: 0.3960	 transfer: 0.0128	 finalize: 0.2825
Accumulated time: update_bounds func: 180.5303	 prepare: 56.1462	 bound: 61.5447	 transfer: 0.0128	 finalize: 54.9475
batch bounding time:  1.0912461280822754
Current worst splitting domains [lb, ub] (depth):
[-0.11339,   inf] (43), [-0.11260,   inf] (97), [-0.11260,   inf] (93), [-0.11260,   inf] (67), [-0.11260,   inf] (77), [-0.11260,   inf] (61), [-0.11260,   inf] (87), [-0.11260,   inf] (93), [-0.11260,   inf] (89), [-0.11260,   inf] (61), [-0.11260,   inf] (61), [-0.11260,   inf] (97), [-0.11260,   inf] (125), [-0.11260,   inf] (77), [-0.11260,   inf] (49), [-0.11259,   inf] (127), [-0.11259,   inf] (97), [-0.11259,   inf] (115), [-0.11259,   inf] (103), [-0.11259,   inf] (105), 
length of domains: 79267
Total time: 1.8757	 pickout: 0.2415	 decision: 0.2771	 get_bound: 1.0956	 add_domain: 0.2616
Current lb:-0.11339298635721207
309626 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 349.4502320289612

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 15] [0, 29] [1, 70] [1, 93] [0, 88] [4, 45] [4, 18] [1, 52] [1, 54] [0, 21] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 36.975181579589844 with beta sum per layer: [846.962890625, 2328.17041015625, 1985.2080078125, 1655.18798828125, 2072.1201171875]
alpha/beta optimization time: 0.425884485244751
This batch time : update_bounds func: 1.2465	 prepare: 0.5586	 bound: 0.4265	 transfer: 0.0126	 finalize: 0.2401
Accumulated time: update_bounds func: 181.7768	 prepare: 56.7049	 bound: 61.9712	 transfer: 0.0126	 finalize: 55.1876
batch bounding time:  1.2489917278289795
Current worst splitting domains [lb, ub] (depth):
[-0.11186,   inf] (65), [-0.11186,   inf] (77), [-0.11186,   inf] (91), [-0.11186,   inf] (93), [-0.11186,   inf] (131), [-0.11186,   inf] (135), [-0.11186,   inf] (115), [-0.11186,   inf] (99), [-0.11186,   inf] (99), [-0.11186,   inf] (61), [-0.11186,   inf] (115), [-0.11186,   inf] (85), [-0.11185,   inf] (45), [-0.11185,   inf] (109), [-0.11185,   inf] (87), [-0.11185,   inf] (73), [-0.11185,   inf] (125), [-0.11185,   inf] (125), [-0.11185,   inf] (109), [-0.11185,   inf] (131), 
length of domains: 79483
Total time: 2.2071	 pickout: 0.3467	 decision: 0.3433	 get_bound: 1.2533	 add_domain: 0.2639
Current lb:-0.11186175793409348
311674 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 351.7216432094574

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 57] [3, 4] [2, 63] [2, 59] [4, 28] [0, 36] [3, 38] [3, 0] [0, 88] [3, 38] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 32.965721130371094 with beta sum per layer: [887.135498046875, 2243.34130859375, 1889.8253173828125, 1725.86181640625, 2219.519775390625]
alpha/beta optimization time: 0.3885171413421631
This batch time : update_bounds func: 1.0649	 prepare: 0.4118	 bound: 0.3890	 transfer: 0.0126	 finalize: 0.2432
Accumulated time: update_bounds func: 182.8418	 prepare: 57.1166	 bound: 62.3602	 transfer: 0.0126	 finalize: 55.4309
batch bounding time:  1.0677721500396729
Current worst splitting domains [lb, ub] (depth):
[-0.11108,   inf] (91), [-0.11108,   inf] (129), [-0.11108,   inf] (81), [-0.11108,   inf] (73), [-0.11108,   inf] (77), [-0.11108,   inf] (101), [-0.11108,   inf] (115), [-0.11108,   inf] (69), [-0.11108,   inf] (121), [-0.11108,   inf] (53), [-0.11108,   inf] (133), [-0.11108,   inf] (139), [-0.11108,   inf] (121), [-0.11107,   inf] (73), [-0.11107,   inf] (119), [-0.11107,   inf] (101), [-0.11107,   inf] (117), [-0.11107,   inf] (73), [-0.11107,   inf] (53), [-0.11107,   inf] (65), 
length of domains: 79682
Total time: 1.8562	 pickout: 0.2489	 decision: 0.2770	 get_bound: 1.0723	 add_domain: 0.2580
Current lb:-0.11108481884002686
313722 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 353.6444878578186

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 2] [1, 54] [0, 2] [3, 90] [2, 44] [1, 7] [1, 93] [2, 70] [2, 7] [1, 49] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 31.853099822998047 with beta sum per layer: [881.0597534179688, 2432.271484375, 1912.025390625, 1643.58251953125, 2180.263671875]
alpha/beta optimization time: 0.4060690402984619
This batch time : update_bounds func: 4.3806	 prepare: 0.4003	 bound: 0.4067	 transfer: 0.0124	 finalize: 3.5524
Accumulated time: update_bounds func: 187.2223	 prepare: 57.5170	 bound: 62.7669	 transfer: 0.0124	 finalize: 58.9832
batch bounding time:  4.383037567138672
Current worst splitting domains [lb, ub] (depth):
[-0.11031,   inf] (109), [-0.11031,   inf] (89), [-0.11031,   inf] (125), [-0.11031,   inf] (119), [-0.11031,   inf] (135), [-0.11031,   inf] (57), [-0.11031,   inf] (93), [-0.11030,   inf] (95), [-0.11030,   inf] (105), [-0.11030,   inf] (73), [-0.11030,   inf] (57), [-0.11030,   inf] (77), [-0.11030,   inf] (125), [-0.11030,   inf] (111), [-0.11030,   inf] (143), [-0.11030,   inf] (47), [-0.11030,   inf] (85), [-0.11030,   inf] (75), [-0.11030,   inf] (111), [-0.11030,   inf] (105), 
length of domains: 79873
Total time: 5.1794	 pickout: 0.2460	 decision: 0.2907	 get_bound: 4.3871	 add_domain: 0.2556
Current lb:-0.11030711978673935
315770 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 358.8979012966156

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 38] [0, 36] [2, 82] [2, 22] [0, 21] [2, 57] [0, 72] [1, 68] [0, 29] [2, 53] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 33.566627502441406 with beta sum per layer: [934.8125, 2292.8623046875, 1886.65966796875, 1651.24072265625, 2152.3349609375]
alpha/beta optimization time: 0.3815491199493408
This batch time : update_bounds func: 1.0519	 prepare: 0.4075	 bound: 0.3821	 transfer: 0.0124	 finalize: 0.2414
Accumulated time: update_bounds func: 188.2742	 prepare: 57.9244	 bound: 63.1490	 transfer: 0.0124	 finalize: 59.2247
batch bounding time:  1.0543861389160156
Current worst splitting domains [lb, ub] (depth):
[-0.10958,   inf] (65), [-0.10958,   inf] (111), [-0.10958,   inf] (117), [-0.10958,   inf] (111), [-0.10958,   inf] (117), [-0.10958,   inf] (113), [-0.10958,   inf] (95), [-0.10958,   inf] (75), [-0.10958,   inf] (63), [-0.10958,   inf] (133), [-0.10957,   inf] (79), [-0.10957,   inf] (113), [-0.10957,   inf] (95), [-0.10957,   inf] (67), [-0.10957,   inf] (117), [-0.10957,   inf] (123), [-0.10957,   inf] (99), [-0.10957,   inf] (127), [-0.10957,   inf] (67), [-0.10957,   inf] (137), 
length of domains: 80068
Total time: 1.8342	 pickout: 0.2460	 decision: 0.2736	 get_bound: 1.0583	 add_domain: 0.2563
Current lb:-0.10958169400691986
317818 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 360.8034749031067

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 27] [4, 28] [3, 38] [0, 72] [4, 98] [2, 56] [1, 54] [2, 82] [2, 82] [0, 89] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 33.62992858886719 with beta sum per layer: [886.56494140625, 2235.3583984375, 1950.8857421875, 1609.64306640625, 2095.408203125]
alpha/beta optimization time: 0.38226866722106934
This batch time : update_bounds func: 1.0329	 prepare: 0.3846	 bound: 0.3828	 transfer: 0.0122	 finalize: 0.2451
Accumulated time: update_bounds func: 189.3071	 prepare: 58.3091	 bound: 63.5317	 transfer: 0.0122	 finalize: 59.4697
batch bounding time:  1.0357441902160645
Current worst splitting domains [lb, ub] (depth):
[-0.10904,   inf] (79), [-0.10882,   inf] (135), [-0.10882,   inf] (97), [-0.10882,   inf] (111), [-0.10882,   inf] (99), [-0.10882,   inf] (95), [-0.10882,   inf] (91), [-0.10882,   inf] (143), [-0.10882,   inf] (129), [-0.10882,   inf] (111), [-0.10882,   inf] (125), [-0.10882,   inf] (121), [-0.10882,   inf] (107), [-0.10881,   inf] (87), [-0.10881,   inf] (77), [-0.10881,   inf] (85), [-0.10881,   inf] (113), [-0.10881,   inf] (119), [-0.10881,   inf] (131), [-0.10881,   inf] (115), 
length of domains: 80248
Total time: 1.8247	 pickout: 0.2588	 decision: 0.2699	 get_bound: 1.0403	 add_domain: 0.2557
Current lb:-0.1090441569685936
319866 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 362.69287371635437

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 69] [3, 0] [1, 14] [1, 70] [2, 57] [1, 49] [1, 43] [0, 72] [2, 59] [2, 82] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 33.87367630004883 with beta sum per layer: [834.9454345703125, 2372.677001953125, 2017.8502197265625, 1645.75048828125, 2154.7998046875]
alpha/beta optimization time: 0.3834846019744873
This batch time : update_bounds func: 1.0447	 prepare: 0.3972	 bound: 0.3840	 transfer: 0.0125	 finalize: 0.2429
Accumulated time: update_bounds func: 190.3518	 prepare: 58.7062	 bound: 63.9157	 transfer: 0.0125	 finalize: 59.7126
batch bounding time:  1.047123908996582
Current worst splitting domains [lb, ub] (depth):
[-0.10808,   inf] (117), [-0.10808,   inf] (109), [-0.10808,   inf] (61), [-0.10808,   inf] (81), [-0.10808,   inf] (115), [-0.10808,   inf] (113), [-0.10807,   inf] (95), [-0.10807,   inf] (113), [-0.10807,   inf] (101), [-0.10807,   inf] (69), [-0.10807,   inf] (117), [-0.10807,   inf] (91), [-0.10807,   inf] (81), [-0.10807,   inf] (93), [-0.10807,   inf] (105), [-0.10807,   inf] (105), [-0.10807,   inf] (119), [-0.10806,   inf] (85), [-0.10806,   inf] (67), [-0.10806,   inf] (75), 
length of domains: 80434
Total time: 1.8369	 pickout: 0.2471	 decision: 0.2830	 get_bound: 1.0513	 add_domain: 0.2556
Current lb:-0.10808141529560089
321914 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 364.59680247306824

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 7] [2, 56] [2, 76] [4, 18] [0, 89] [2, 59] [0, 29] [2, 82] [2, 56] [2, 60] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 34.87398910522461 with beta sum per layer: [872.7636108398438, 2213.65625, 1964.882568359375, 1660.3458251953125, 2097.8798828125]
alpha/beta optimization time: 0.3849008083343506
This batch time : update_bounds func: 1.0491	 prepare: 0.4032	 bound: 0.3854	 transfer: 0.0125	 finalize: 0.2397
Accumulated time: update_bounds func: 191.4009	 prepare: 59.1094	 bound: 64.3011	 transfer: 0.0125	 finalize: 59.9523
batch bounding time:  1.0515966415405273
Current worst splitting domains [lb, ub] (depth):
[-0.10799,   inf] (75), [-0.10733,   inf] (79), [-0.10733,   inf] (57), [-0.10733,   inf] (67), [-0.10733,   inf] (93), [-0.10732,   inf] (109), [-0.10732,   inf] (123), [-0.10732,   inf] (95), [-0.10732,   inf] (113), [-0.10732,   inf] (123), [-0.10732,   inf] (65), [-0.10732,   inf] (73), [-0.10732,   inf] (81), [-0.10732,   inf] (91), [-0.10732,   inf] (121), [-0.10732,   inf] (147), [-0.10732,   inf] (139), [-0.10732,   inf] (145), [-0.10732,   inf] (91), [-0.10731,   inf] (103), 
length of domains: 80637
Total time: 1.8373	 pickout: 0.2471	 decision: 0.2719	 get_bound: 1.0557	 add_domain: 0.2626
Current lb:-0.10799157619476318
323962 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 366.5016539096832

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 82] [0, 25] [2, 60] [2, 53] [1, 70] [2, 69] [1, 49] [1, 52] [2, 79] [1, 7] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 28.99835205078125 with beta sum per layer: [869.747314453125, 2291.615234375, 1962.1484375, 1671.6085205078125, 2001.389404296875]
alpha/beta optimization time: 0.3856353759765625
This batch time : update_bounds func: 1.0386	 prepare: 0.3907	 bound: 0.3861	 transfer: 0.0121	 finalize: 0.2411
Accumulated time: update_bounds func: 192.4396	 prepare: 59.5002	 bound: 64.6873	 transfer: 0.0121	 finalize: 60.1934
batch bounding time:  1.0412566661834717
Current worst splitting domains [lb, ub] (depth):
[-0.10690,   inf] (79), [-0.10657,   inf] (99), [-0.10657,   inf] (81), [-0.10657,   inf] (47), [-0.10657,   inf] (39), [-0.10657,   inf] (115), [-0.10657,   inf] (87), [-0.10657,   inf] (95), [-0.10656,   inf] (77), [-0.10656,   inf] (93), [-0.10656,   inf] (125), [-0.10656,   inf] (81), [-0.10656,   inf] (59), [-0.10656,   inf] (103), [-0.10656,   inf] (61), [-0.10656,   inf] (105), [-0.10656,   inf] (73), [-0.10656,   inf] (87), [-0.10656,   inf] (47), [-0.10656,   inf] (95), 
length of domains: 80829
Total time: 1.8283	 pickout: 0.2495	 decision: 0.2756	 get_bound: 1.0453	 add_domain: 0.2579
Current lb:-0.10690271854400635
326010 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 368.3995187282562

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 69] [1, 63] [2, 93] [2, 27] [0, 89] [1, 7] [0, 21] [0, 13] [1, 68] [0, 36] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 26.404781341552734 with beta sum per layer: [857.7229614257812, 2338.72216796875, 1911.866943359375, 1698.96337890625, 2205.181640625]
alpha/beta optimization time: 0.4045372009277344
This batch time : update_bounds func: 1.0816	 prepare: 0.4114	 bound: 0.4050	 transfer: 0.0121	 finalize: 0.2445
Accumulated time: update_bounds func: 193.5212	 prepare: 59.9116	 bound: 65.0923	 transfer: 0.0121	 finalize: 60.4378
batch bounding time:  1.0840892791748047
Current worst splitting domains [lb, ub] (depth):
[-0.10631,   inf] (67), [-0.10587,   inf] (111), [-0.10587,   inf] (109), [-0.10586,   inf] (89), [-0.10586,   inf] (119), [-0.10586,   inf] (89), [-0.10586,   inf] (61), [-0.10586,   inf] (73), [-0.10586,   inf] (111), [-0.10586,   inf] (65), [-0.10586,   inf] (121), [-0.10586,   inf] (95), [-0.10586,   inf] (87), [-0.10586,   inf] (71), [-0.10586,   inf] (79), [-0.10585,   inf] (57), [-0.10585,   inf] (125), [-0.10585,   inf] (111), [-0.10585,   inf] (67), [-0.10585,   inf] (121), 
length of domains: 81016
Total time: 1.8709	 pickout: 0.2503	 decision: 0.2771	 get_bound: 1.0883	 add_domain: 0.2552
Current lb:-0.10631345957517624
328058 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 370.34073209762573

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 2] [2, 79] [4, 71] [2, 27] [0, 36] [2, 82] [1, 69] [2, 70] [2, 60] [1, 43] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 30.437345504760742 with beta sum per layer: [854.2598876953125, 2384.40673828125, 1956.878662109375, 1636.2882080078125, 2171.74853515625]
alpha/beta optimization time: 0.38822007179260254
This batch time : update_bounds func: 1.0533	 prepare: 0.4013	 bound: 0.3887	 transfer: 0.0121	 finalize: 0.2425
Accumulated time: update_bounds func: 194.5745	 prepare: 60.3129	 bound: 65.4810	 transfer: 0.0121	 finalize: 60.6803
batch bounding time:  1.0557165145874023
Current worst splitting domains [lb, ub] (depth):
[-0.10515,   inf] (77), [-0.10513,   inf] (59), [-0.10513,   inf] (95), [-0.10513,   inf] (65), [-0.10513,   inf] (113), [-0.10513,   inf] (93), [-0.10513,   inf] (117), [-0.10513,   inf] (127), [-0.10513,   inf] (93), [-0.10513,   inf] (89), [-0.10513,   inf] (43), [-0.10513,   inf] (77), [-0.10513,   inf] (59), [-0.10513,   inf] (117), [-0.10513,   inf] (119), [-0.10512,   inf] (65), [-0.10512,   inf] (117), [-0.10512,   inf] (85), [-0.10512,   inf] (117), [-0.10512,   inf] (105), 
length of domains: 81219
Total time: 5.2155	 pickout: 0.2551	 decision: 3.6383	 get_bound: 1.0600	 add_domain: 0.2622
Current lb:-0.10514859855175018
330106 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 375.6233539581299

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 62] [0, 21] [0, 89] [1, 63] [1, 7] [3, 0] [2, 44] [2, 59] [1, 93] [0, 13] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 26.48381805419922 with beta sum per layer: [884.478515625, 2176.823974609375, 1974.68603515625, 1649.469482421875, 2214.641845703125]
alpha/beta optimization time: 0.38854122161865234
This batch time : update_bounds func: 1.0709	 prepare: 0.4139	 bound: 0.3891	 transfer: 0.0126	 finalize: 0.2470
Accumulated time: update_bounds func: 195.6454	 prepare: 60.7268	 bound: 65.8701	 transfer: 0.0126	 finalize: 60.9273
batch bounding time:  1.0736098289489746
Current worst splitting domains [lb, ub] (depth):
[-0.10444,   inf] (99), [-0.10444,   inf] (109), [-0.10444,   inf] (139), [-0.10444,   inf] (71), [-0.10444,   inf] (131), [-0.10444,   inf] (79), [-0.10444,   inf] (103), [-0.10444,   inf] (79), [-0.10444,   inf] (115), [-0.10444,   inf] (107), [-0.10443,   inf] (113), [-0.10443,   inf] (53), [-0.10443,   inf] (93), [-0.10443,   inf] (101), [-0.10443,   inf] (103), [-0.10443,   inf] (71), [-0.10443,   inf] (79), [-0.10443,   inf] (109), [-0.10443,   inf] (73), [-0.10443,   inf] (113), 
length of domains: 81344
Total time: 1.8572	 pickout: 0.2519	 decision: 0.2786	 get_bound: 1.0781	 add_domain: 0.2486
Current lb:-0.1044439747929573
332154 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 377.5495238304138

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 79] [2, 44] [2, 59] [0, 13] [4, 14] [2, 93] [2, 27] [1, 68] [4, 98] [2, 22] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 29.347721099853516 with beta sum per layer: [817.3746337890625, 2228.79443359375, 1942.8878173828125, 1724.317626953125, 2231.43212890625]
alpha/beta optimization time: 0.39209723472595215
This batch time : update_bounds func: 1.0563	 prepare: 0.3957	 bound: 0.3926	 transfer: 0.0124	 finalize: 0.2466
Accumulated time: update_bounds func: 196.7016	 prepare: 61.1225	 bound: 66.2627	 transfer: 0.0124	 finalize: 61.1739
batch bounding time:  1.0593199729919434
Current worst splitting domains [lb, ub] (depth):
[-0.10437,   inf] (67), [-0.10408,   inf] (75), [-0.10372,   inf] (91), [-0.10372,   inf] (71), [-0.10371,   inf] (73), [-0.10371,   inf] (79), [-0.10371,   inf] (115), [-0.10371,   inf] (93), [-0.10371,   inf] (83), [-0.10371,   inf] (71), [-0.10371,   inf] (107), [-0.10371,   inf] (67), [-0.10371,   inf] (109), [-0.10371,   inf] (61), [-0.10371,   inf] (107), [-0.10371,   inf] (115), [-0.10371,   inf] (109), [-0.10371,   inf] (117), [-0.10371,   inf] (139), [-0.10371,   inf] (113), 
length of domains: 81489
Total time: 1.8546	 pickout: 0.2554	 decision: 0.2801	 get_bound: 1.0641	 add_domain: 0.2550
Current lb:-0.10437051206827164
334202 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 379.4728729724884

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 70] [3, 41] [2, 53] [2, 60] [4, 18] [1, 63] [2, 59] [0, 72] [3, 78] [0, 4] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 25.17386817932129 with beta sum per layer: [808.0569458007812, 2318.234375, 1933.827392578125, 1761.360107421875, 2160.632080078125]
alpha/beta optimization time: 0.38344454765319824
This batch time : update_bounds func: 1.0498	 prepare: 0.3967	 bound: 0.3839	 transfer: 0.0119	 finalize: 0.2487
Accumulated time: update_bounds func: 197.7514	 prepare: 61.5192	 bound: 66.6466	 transfer: 0.0119	 finalize: 61.4226
batch bounding time:  1.052553653717041
Current worst splitting domains [lb, ub] (depth):
[-0.10343,   inf] (39), [-0.10298,   inf] (137), [-0.10298,   inf] (115), [-0.10298,   inf] (79), [-0.10298,   inf] (123), [-0.10298,   inf] (101), [-0.10298,   inf] (77), [-0.10298,   inf] (101), [-0.10298,   inf] (83), [-0.10297,   inf] (125), [-0.10297,   inf] (79), [-0.10297,   inf] (95), [-0.10297,   inf] (133), [-0.10297,   inf] (113), [-0.10297,   inf] (89), [-0.10297,   inf] (115), [-0.10297,   inf] (95), [-0.10297,   inf] (111), [-0.10297,   inf] (119), [-0.10297,   inf] (83), 
length of domains: 81655
Total time: 1.8509	 pickout: 0.2592	 decision: 0.2790	 get_bound: 1.0570	 add_domain: 0.2557
Current lb:-0.10342716425657272
336250 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 381.39295625686646

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 83] [3, 37] [2, 79] [0, 2] [4, 20] [4, 67] [0, 4] [2, 22] [0, 25] [2, 59] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 20.505168914794922 with beta sum per layer: [792.9913330078125, 2304.24462890625, 2056.21044921875, 1619.583984375, 2155.722412109375]
alpha/beta optimization time: 0.3841722011566162
This batch time : update_bounds func: 1.0502	 prepare: 0.3999	 bound: 0.3847	 transfer: 0.0120	 finalize: 0.2454
Accumulated time: update_bounds func: 198.8016	 prepare: 61.9191	 bound: 67.0313	 transfer: 0.0120	 finalize: 61.6680
batch bounding time:  1.0530529022216797
Current worst splitting domains [lb, ub] (depth):
[-0.10224,   inf] (113), [-0.10224,   inf] (61), [-0.10224,   inf] (69), [-0.10224,   inf] (65), [-0.10224,   inf] (67), [-0.10224,   inf] (77), [-0.10224,   inf] (39), [-0.10223,   inf] (47), [-0.10223,   inf] (131), [-0.10223,   inf] (117), [-0.10223,   inf] (117), [-0.10223,   inf] (107), [-0.10223,   inf] (97), [-0.10223,   inf] (99), [-0.10223,   inf] (81), [-0.10223,   inf] (73), [-0.10223,   inf] (123), [-0.10222,   inf] (67), [-0.10222,   inf] (115), [-0.10222,   inf] (127), 
length of domains: 81810
Total time: 1.8527	 pickout: 0.2643	 decision: 0.2794	 get_bound: 1.0576	 add_domain: 0.2513
Current lb:-0.10223948955535889
338298 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 383.3121671676636

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 98] [1, 69] [2, 61] [1, 68] [2, 53] [0, 4] [0, 21] [2, 76] [4, 14] [2, 22] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 23.801712036132812 with beta sum per layer: [906.6861572265625, 2374.201171875, 1867.5015869140625, 1716.65380859375, 2198.86865234375]
alpha/beta optimization time: 0.3905606269836426
This batch time : update_bounds func: 1.0630	 prepare: 0.4032	 bound: 0.3911	 transfer: 0.0121	 finalize: 0.2480
Accumulated time: update_bounds func: 199.8647	 prepare: 62.3224	 bound: 67.4224	 transfer: 0.0121	 finalize: 61.9160
batch bounding time:  1.0655057430267334
Current worst splitting domains [lb, ub] (depth):
[-0.10207,   inf] (75), [-0.10152,   inf] (133), [-0.10152,   inf] (87), [-0.10152,   inf] (113), [-0.10152,   inf] (103), [-0.10152,   inf] (69), [-0.10152,   inf] (97), [-0.10152,   inf] (47), [-0.10152,   inf] (127), [-0.10152,   inf] (77), [-0.10152,   inf] (99), [-0.10152,   inf] (77), [-0.10151,   inf] (117), [-0.10151,   inf] (75), [-0.10151,   inf] (125), [-0.10151,   inf] (89), [-0.10151,   inf] (79), [-0.10151,   inf] (115), [-0.10151,   inf] (125), [-0.10151,   inf] (101), 
length of domains: 81954
Total time: 1.8598	 pickout: 0.2621	 decision: 0.2783	 get_bound: 1.0697	 add_domain: 0.2496
Current lb:-0.10206758230924606
340346 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 385.2442560195923

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 82] [2, 44] [0, 88] [1, 49] [2, 22] [3, 98] [2, 79] [2, 76] [2, 63] [3, 75] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 24.590118408203125 with beta sum per layer: [814.5784912109375, 2318.61328125, 2034.345947265625, 1640.0595703125, 2223.656494140625]
alpha/beta optimization time: 0.38832902908325195
This batch time : update_bounds func: 4.5032	 prepare: 0.3952	 bound: 0.3889	 transfer: 0.0122	 finalize: 3.6981
Accumulated time: update_bounds func: 204.3678	 prepare: 62.7176	 bound: 67.8112	 transfer: 0.0122	 finalize: 65.6141
batch bounding time:  4.505904674530029
Current worst splitting domains [lb, ub] (depth):
[-0.10117,   inf] (39), [-0.10094,   inf] (39), [-0.10085,   inf] (85), [-0.10083,   inf] (131), [-0.10083,   inf] (123), [-0.10083,   inf] (115), [-0.10083,   inf] (81), [-0.10083,   inf] (103), [-0.10083,   inf] (107), [-0.10083,   inf] (49), [-0.10082,   inf] (103), [-0.10082,   inf] (87), [-0.10082,   inf] (115), [-0.10082,   inf] (101), [-0.10082,   inf] (49), [-0.10082,   inf] (89), [-0.10082,   inf] (87), [-0.10082,   inf] (71), [-0.10082,   inf] (61), [-0.10082,   inf] (107), 
length of domains: 82083
Total time: 5.3195	 pickout: 0.2636	 decision: 0.2777	 get_bound: 4.5113	 add_domain: 0.2669
Current lb:-0.10117334872484207
342394 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 390.64179396629333

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 15] [1, 15] [2, 7] [2, 60] [1, 7] [1, 7] [0, 88] [1, 93] [4, 50] [3, 90] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 16.119598388671875 with beta sum per layer: [868.5550537109375, 2344.1806640625, 1896.11328125, 1601.8023681640625, 2189.78271484375]
alpha/beta optimization time: 0.38619017601013184
This batch time : update_bounds func: 1.0555	 prepare: 0.4035	 bound: 0.3867	 transfer: 0.0122	 finalize: 0.2443
Accumulated time: update_bounds func: 205.4233	 prepare: 63.1211	 bound: 68.1979	 transfer: 0.0122	 finalize: 65.8584
batch bounding time:  1.0582773685455322
Current worst splitting domains [lb, ub] (depth):
[-0.10013,   inf] (109), [-0.10013,   inf] (131), [-0.10013,   inf] (123), [-0.10013,   inf] (91), [-0.10013,   inf] (75), [-0.10013,   inf] (69), [-0.10013,   inf] (95), [-0.10013,   inf] (99), [-0.10013,   inf] (71), [-0.10013,   inf] (65), [-0.10013,   inf] (75), [-0.10013,   inf] (107), [-0.10013,   inf] (117), [-0.10013,   inf] (91), [-0.10013,   inf] (109), [-0.10013,   inf] (89), [-0.10013,   inf] (97), [-0.10013,   inf] (111), [-0.10013,   inf] (109), [-0.10013,   inf] (111), 
length of domains: 82226
Total time: 1.8831	 pickout: 0.2728	 decision: 0.2818	 get_bound: 1.0626	 add_domain: 0.2658
Current lb:-0.10013449192047119
344442 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 392.61221742630005

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 53] [2, 40] [2, 7] [2, 96] [0, 21] [3, 2] [3, 38] [4, 0] [2, 59] [2, 64] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 26.322383880615234 with beta sum per layer: [869.5175170898438, 2397.18359375, 1936.5, 1697.9810791015625, 2142.2861328125]
alpha/beta optimization time: 0.38300395011901855
This batch time : update_bounds func: 1.0780	 prepare: 0.4302	 bound: 0.3835	 transfer: 0.0122	 finalize: 0.2436
Accumulated time: update_bounds func: 206.5013	 prepare: 63.5513	 bound: 68.5814	 transfer: 0.0122	 finalize: 66.1020
batch bounding time:  1.081026554107666
Current worst splitting domains [lb, ub] (depth):
[-0.09997,   inf] (81), [-0.09947,   inf] (109), [-0.09946,   inf] (75), [-0.09946,   inf] (123), [-0.09946,   inf] (115), [-0.09946,   inf] (93), [-0.09946,   inf] (103), [-0.09946,   inf] (55), [-0.09946,   inf] (95), [-0.09946,   inf] (133), [-0.09946,   inf] (97), [-0.09946,   inf] (119), [-0.09946,   inf] (127), [-0.09945,   inf] (97), [-0.09945,   inf] (111), [-0.09945,   inf] (77), [-0.09945,   inf] (105), [-0.09945,   inf] (129), [-0.09945,   inf] (77), [-0.09945,   inf] (83), 
length of domains: 82378
Total time: 1.8960	 pickout: 0.2743	 decision: 0.2800	 get_bound: 1.0857	 add_domain: 0.2559
Current lb:-0.09997142851352692
346490 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 394.5761260986328

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 2] [4, 28] [2, 60] [1, 7] [4, 28] [0, 36] [4, 68] [4, 43] [2, 93] [3, 37] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 23.8402042388916 with beta sum per layer: [920.8667602539062, 2356.995849609375, 1903.906982421875, 1702.593017578125, 2186.834228515625]
alpha/beta optimization time: 0.3822312355041504
This batch time : update_bounds func: 1.0451	 prepare: 0.4001	 bound: 0.3828	 transfer: 0.0123	 finalize: 0.2412
Accumulated time: update_bounds func: 207.5464	 prepare: 63.9514	 bound: 68.9642	 transfer: 0.0123	 finalize: 66.3432
batch bounding time:  1.047572374343872
Current worst splitting domains [lb, ub] (depth):
[-0.09909,   inf] (75), [-0.09878,   inf] (123), [-0.09878,   inf] (79), [-0.09878,   inf] (113), [-0.09878,   inf] (77), [-0.09878,   inf] (93), [-0.09878,   inf] (89), [-0.09878,   inf] (147), [-0.09877,   inf] (115), [-0.09877,   inf] (71), [-0.09877,   inf] (79), [-0.09877,   inf] (91), [-0.09877,   inf] (73), [-0.09877,   inf] (149), [-0.09877,   inf] (119), [-0.09877,   inf] (87), [-0.09877,   inf] (105), [-0.09877,   inf] (137), [-0.09877,   inf] (131), [-0.09877,   inf] (103), 
length of domains: 82532
Total time: 1.8683	 pickout: 0.2732	 decision: 0.2795	 get_bound: 1.0517	 add_domain: 0.2638
Current lb:-0.09908785670995712
348538 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 396.51765489578247

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 82] [0, 30] [4, 0] [2, 79] [4, 56] [2, 96] [3, 35] [1, 63] [2, 82] [2, 76] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 17.397769927978516 with beta sum per layer: [817.5812377929688, 2367.015625, 1982.65234375, 1768.281005859375, 1991.14794921875]
alpha/beta optimization time: 0.3984038829803467
This batch time : update_bounds func: 1.0576	 prepare: 0.3934	 bound: 0.3989	 transfer: 0.0125	 finalize: 0.2446
Accumulated time: update_bounds func: 208.6040	 prepare: 64.3447	 bound: 69.3631	 transfer: 0.0125	 finalize: 66.5878
batch bounding time:  1.0602214336395264
Current worst splitting domains [lb, ub] (depth):
[-0.09824,   inf] (77), [-0.09813,   inf] (119), [-0.09813,   inf] (133), [-0.09813,   inf] (61), [-0.09813,   inf] (103), [-0.09813,   inf] (107), [-0.09813,   inf] (101), [-0.09813,   inf] (53), [-0.09813,   inf] (107), [-0.09813,   inf] (69), [-0.09813,   inf] (101), [-0.09813,   inf] (111), [-0.09813,   inf] (115), [-0.09813,   inf] (37), [-0.09813,   inf] (123), [-0.09813,   inf] (101), [-0.09813,   inf] (87), [-0.09813,   inf] (109), [-0.09813,   inf] (89), [-0.09813,   inf] (127), 
length of domains: 82659
Total time: 1.8608	 pickout: 0.2655	 decision: 0.2813	 get_bound: 1.0645	 add_domain: 0.2495
Current lb:-0.09824103116989136
350586 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 398.44605350494385

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 2] [2, 22] [3, 78] [2, 27] [2, 7] [2, 82] [0, 29] [3, 37] [2, 82] [2, 57] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 20.93896484375 with beta sum per layer: [946.1318359375, 2309.44091796875, 2065.240234375, 1665.4755859375, 2225.543212890625]
alpha/beta optimization time: 0.39446377754211426
This batch time : update_bounds func: 1.0703	 prepare: 0.3928	 bound: 0.3950	 transfer: 0.0128	 finalize: 0.2587
Accumulated time: update_bounds func: 209.6743	 prepare: 64.7375	 bound: 69.7581	 transfer: 0.0128	 finalize: 66.8465
batch bounding time:  1.073209285736084
Current worst splitting domains [lb, ub] (depth):
[-0.09745,   inf] (119), [-0.09745,   inf] (63), [-0.09745,   inf] (71), [-0.09745,   inf] (93), [-0.09745,   inf] (81), [-0.09745,   inf] (133), [-0.09745,   inf] (145), [-0.09745,   inf] (131), [-0.09745,   inf] (141), [-0.09745,   inf] (47), [-0.09744,   inf] (107), [-0.09744,   inf] (121), [-0.09744,   inf] (81), [-0.09744,   inf] (119), [-0.09744,   inf] (117), [-0.09744,   inf] (111), [-0.09744,   inf] (63), [-0.09744,   inf] (85), [-0.09744,   inf] (133), [-0.09744,   inf] (105), 
length of domains: 82820
Total time: 1.8782	 pickout: 0.2596	 decision: 0.2781	 get_bound: 1.0778	 add_domain: 0.2626
Current lb:-0.097449891269207
352634 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 400.401255607605

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 20] [3, 75] [1, 93] [3, 38] [2, 53] [4, 98] [3, 37] [4, 20] [1, 54] [2, 99] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 19.457168579101562 with beta sum per layer: [829.8121948242188, 2276.037841796875, 1939.41455078125, 1718.0238037109375, 2128.90673828125]
alpha/beta optimization time: 0.39629173278808594
This batch time : update_bounds func: 1.0799	 prepare: 0.4185	 bound: 0.3968	 transfer: 0.0119	 finalize: 0.2444
Accumulated time: update_bounds func: 210.7541	 prepare: 65.1560	 bound: 70.1549	 transfer: 0.0119	 finalize: 67.0909
batch bounding time:  1.0822875499725342
Current worst splitting domains [lb, ub] (depth):
[-0.09735,   inf] (87), [-0.09678,   inf] (121), [-0.09678,   inf] (71), [-0.09678,   inf] (115), [-0.09678,   inf] (89), [-0.09678,   inf] (35), [-0.09678,   inf] (73), [-0.09678,   inf] (69), [-0.09678,   inf] (135), [-0.09678,   inf] (41), [-0.09678,   inf] (111), [-0.09678,   inf] (47), [-0.09678,   inf] (117), [-0.09678,   inf] (83), [-0.09677,   inf] (143), [-0.09677,   inf] (113), [-0.09677,   inf] (107), [-0.09677,   inf] (125), [-0.09677,   inf] (39), [-0.09677,   inf] (57), 
length of domains: 82961
Total time: 1.8711	 pickout: 0.2583	 decision: 0.2751	 get_bound: 1.0863	 add_domain: 0.2513
Current lb:-0.09734798967838287
354682 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 402.3407053947449

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 2] [2, 7] [2, 93] [3, 84] [3, 38] [3, 21] [2, 53] [3, 17] [2, 69] [3, 75] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 16.557796478271484 with beta sum per layer: [808.9718017578125, 2328.179443359375, 2013.51123046875, 1698.0654296875, 2055.000732421875]
alpha/beta optimization time: 0.38578033447265625
This batch time : update_bounds func: 1.0683	 prepare: 0.4045	 bound: 0.3863	 transfer: 0.0122	 finalize: 0.2565
Accumulated time: update_bounds func: 211.8224	 prepare: 65.5605	 bound: 70.5412	 transfer: 0.0122	 finalize: 67.3474
batch bounding time:  1.071000099182129
Current worst splitting domains [lb, ub] (depth):
[-0.09612,   inf] (37), [-0.09611,   inf] (69), [-0.09611,   inf] (147), [-0.09611,   inf] (93), [-0.09611,   inf] (65), [-0.09611,   inf] (121), [-0.09611,   inf] (105), [-0.09611,   inf] (101), [-0.09611,   inf] (97), [-0.09611,   inf] (129), [-0.09611,   inf] (87), [-0.09611,   inf] (63), [-0.09610,   inf] (91), [-0.09610,   inf] (111), [-0.09610,   inf] (67), [-0.09610,   inf] (93), [-0.09610,   inf] (81), [-0.09610,   inf] (115), [-0.09610,   inf] (75), [-0.09610,   inf] (79), 
length of domains: 83090
Total time: 5.2423	 pickout: 0.2554	 decision: 3.6576	 get_bound: 1.0754	 add_domain: 0.2539
Current lb:-0.09611513465642929
356730 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 407.6666114330292

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 72] [3, 10] [0, 89] [3, 35] [3, 73] [2, 59] [2, 82] [0, 72] [1, 54] [2, 44] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 19.28399085998535 with beta sum per layer: [819.10693359375, 2342.27734375, 1975.02001953125, 1661.01953125, 2211.667724609375]
alpha/beta optimization time: 0.3856062889099121
This batch time : update_bounds func: 1.0537	 prepare: 0.3989	 bound: 0.3861	 transfer: 0.0123	 finalize: 0.2475
Accumulated time: update_bounds func: 212.8761	 prepare: 65.9595	 bound: 70.9273	 transfer: 0.0123	 finalize: 67.5949
batch bounding time:  1.0564696788787842
Current worst splitting domains [lb, ub] (depth):
[-0.09544,   inf] (97), [-0.09543,   inf] (101), [-0.09543,   inf] (111), [-0.09543,   inf] (127), [-0.09543,   inf] (111), [-0.09543,   inf] (97), [-0.09543,   inf] (69), [-0.09543,   inf] (135), [-0.09543,   inf] (137), [-0.09543,   inf] (93), [-0.09543,   inf] (109), [-0.09543,   inf] (63), [-0.09543,   inf] (81), [-0.09543,   inf] (137), [-0.09543,   inf] (135), [-0.09543,   inf] (75), [-0.09543,   inf] (99), [-0.09543,   inf] (103), [-0.09543,   inf] (99), [-0.09543,   inf] (59), 
length of domains: 83220
Total time: 1.8484	 pickout: 0.2553	 decision: 0.2799	 get_bound: 1.0609	 add_domain: 0.2523
Current lb:-0.09543585777282715
358778 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 409.5935037136078

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 52] [0, 88] [4, 68] [2, 82] [2, 57] [1, 63] [2, 44] [2, 69] [3, 78] [2, 60] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 15.192599296569824 with beta sum per layer: [896.272216796875, 2222.650390625, 1984.9278564453125, 1798.25341796875, 2081.94384765625]
alpha/beta optimization time: 0.38603830337524414
This batch time : update_bounds func: 1.0581	 prepare: 0.4033	 bound: 0.3865	 transfer: 0.0124	 finalize: 0.2472
Accumulated time: update_bounds func: 213.9342	 prepare: 66.3628	 bound: 71.3138	 transfer: 0.0124	 finalize: 67.8422
batch bounding time:  1.0606348514556885
Current worst splitting domains [lb, ub] (depth):
[-0.09515,   inf] (49), [-0.09480,   inf] (93), [-0.09480,   inf] (119), [-0.09480,   inf] (103), [-0.09480,   inf] (103), [-0.09480,   inf] (59), [-0.09480,   inf] (111), [-0.09479,   inf] (105), [-0.09479,   inf] (109), [-0.09479,   inf] (121), [-0.09479,   inf] (95), [-0.09479,   inf] (119), [-0.09479,   inf] (61), [-0.09479,   inf] (121), [-0.09479,   inf] (103), [-0.09479,   inf] (93), [-0.09478,   inf] (111), [-0.09478,   inf] (51), [-0.09478,   inf] (123), [-0.09478,   inf] (71), 
length of domains: 83361
Total time: 1.8559	 pickout: 0.2597	 decision: 0.2804	 get_bound: 1.0649	 add_domain: 0.2509
Current lb:-0.09514755755662918
360826 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 411.5170409679413

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 36] [1, 52] [0, 89] [2, 56] [2, 7] [4, 45] [4, 67] [3, 38] [0, 32] [1, 7] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 10.179076194763184 with beta sum per layer: [871.2701416015625, 2270.199462890625, 1997.459228515625, 1818.739990234375, 2095.6845703125]
alpha/beta optimization time: 0.39296913146972656
This batch time : update_bounds func: 1.0551	 prepare: 0.3969	 bound: 0.3935	 transfer: 0.0123	 finalize: 0.2436
Accumulated time: update_bounds func: 214.9893	 prepare: 66.7597	 bound: 71.7073	 transfer: 0.0123	 finalize: 68.0858
batch bounding time:  1.0577399730682373
Current worst splitting domains [lb, ub] (depth):
[-0.09416,   inf] (127), [-0.09416,   inf] (95), [-0.09416,   inf] (95), [-0.09416,   inf] (111), [-0.09416,   inf] (111), [-0.09415,   inf] (73), [-0.09415,   inf] (117), [-0.09415,   inf] (61), [-0.09415,   inf] (81), [-0.09415,   inf] (83), [-0.09415,   inf] (71), [-0.09415,   inf] (111), [-0.09415,   inf] (71), [-0.09415,   inf] (133), [-0.09415,   inf] (135), [-0.09415,   inf] (137), [-0.09415,   inf] (113), [-0.09415,   inf] (109), [-0.09415,   inf] (99), [-0.09415,   inf] (73), 
length of domains: 83468
Total time: 1.8496	 pickout: 0.2601	 decision: 0.2830	 get_bound: 1.0621	 add_domain: 0.2444
Current lb:-0.09415757656097412
362874 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 413.442263841629

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 38] [3, 38] [2, 53] [1, 52] [4, 67] [3, 73] [1, 63] [2, 57] [4, 50] [4, 18] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 9.503000259399414 with beta sum per layer: [843.3302001953125, 2305.785888671875, 1939.923095703125, 1719.50146484375, 2147.0625]
alpha/beta optimization time: 0.3877270221710205
This batch time : update_bounds func: 1.0594	 prepare: 0.4048	 bound: 0.3882	 transfer: 0.0121	 finalize: 0.2454
Accumulated time: update_bounds func: 216.0488	 prepare: 67.1645	 bound: 72.0955	 transfer: 0.0121	 finalize: 68.3312
batch bounding time:  1.0620274543762207
Current worst splitting domains [lb, ub] (depth):
[-0.09411,   inf] (77), [-0.09354,   inf] (93), [-0.09354,   inf] (55), [-0.09354,   inf] (105), [-0.09354,   inf] (111), [-0.09354,   inf] (85), [-0.09354,   inf] (51), [-0.09354,   inf] (51), [-0.09354,   inf] (67), [-0.09354,   inf] (107), [-0.09353,   inf] (125), [-0.09353,   inf] (81), [-0.09353,   inf] (95), [-0.09353,   inf] (73), [-0.09353,   inf] (37), [-0.09353,   inf] (73), [-0.09353,   inf] (103), [-0.09353,   inf] (107), [-0.09353,   inf] (105), [-0.09353,   inf] (111), 
length of domains: 83579
Total time: 1.8561	 pickout: 0.2549	 decision: 0.2874	 get_bound: 1.0663	 add_domain: 0.2475
Current lb:-0.09410817176103592
364922 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 415.36848425865173

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 56] [2, 93] [2, 99] [3, 38] [1, 68] [0, 88] [3, 17] [2, 75] [3, 75] [1, 93] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 9.01392936706543 with beta sum per layer: [884.392333984375, 2326.54150390625, 2044.621337890625, 1694.3720703125, 2129.9638671875]
alpha/beta optimization time: 0.38782191276550293
This batch time : update_bounds func: 1.0660	 prepare: 0.4083	 bound: 0.3883	 transfer: 0.0125	 finalize: 0.2483
Accumulated time: update_bounds func: 217.1148	 prepare: 67.5728	 bound: 72.4838	 transfer: 0.0125	 finalize: 68.5796
batch bounding time:  1.06862211227417
Current worst splitting domains [lb, ub] (depth):
[-0.09289,   inf] (89), [-0.09289,   inf] (77), [-0.09289,   inf] (103), [-0.09289,   inf] (133), [-0.09289,   inf] (41), [-0.09289,   inf] (125), [-0.09289,   inf] (83), [-0.09289,   inf] (111), [-0.09289,   inf] (107), [-0.09289,   inf] (109), [-0.09288,   inf] (81), [-0.09288,   inf] (127), [-0.09288,   inf] (73), [-0.09288,   inf] (135), [-0.09288,   inf] (85), [-0.09288,   inf] (113), [-0.09288,   inf] (53), [-0.09288,   inf] (99), [-0.09288,   inf] (127), [-0.09288,   inf] (107), 
length of domains: 83684
Total time: 1.8528	 pickout: 0.2564	 decision: 0.2790	 get_bound: 1.0728	 add_domain: 0.2445
Current lb:-0.09289415925741196
366970 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 417.2932689189911

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 19] [2, 57] [2, 10] [4, 92] [1, 83] [4, 14] [2, 40] [2, 79] [4, 71] [0, 29] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 15.085782051086426 with beta sum per layer: [826.081787109375, 2237.616455078125, 1947.789306640625, 1781.86376953125, 2088.17578125]
alpha/beta optimization time: 0.3903207778930664
This batch time : update_bounds func: 1.0703	 prepare: 0.4123	 bound: 0.3908	 transfer: 0.0124	 finalize: 0.2459
Accumulated time: update_bounds func: 218.1851	 prepare: 67.9851	 bound: 72.8747	 transfer: 0.0124	 finalize: 68.8255
batch bounding time:  1.0729129314422607
Current worst splitting domains [lb, ub] (depth):
[-0.09232,   inf] (85), [-0.09229,   inf] (93), [-0.09229,   inf] (83), [-0.09228,   inf] (97), [-0.09228,   inf] (109), [-0.09228,   inf] (121), [-0.09228,   inf] (111), [-0.09228,   inf] (67), [-0.09228,   inf] (117), [-0.09228,   inf] (107), [-0.09228,   inf] (73), [-0.09228,   inf] (91), [-0.09228,   inf] (113), [-0.09228,   inf] (75), [-0.09228,   inf] (75), [-0.09227,   inf] (123), [-0.09227,   inf] (91), [-0.09227,   inf] (119), [-0.09227,   inf] (63), [-0.09227,   inf] (119), 
length of domains: 83814
Total time: 5.4916	 pickout: 0.2570	 decision: 0.2805	 get_bound: 1.0772	 add_domain: 3.8770
Current lb:-0.09232412278652191
369018 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 422.86912512779236

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 2] [2, 76] [0, 4] [1, 52] [2, 79] [3, 84] [1, 68] [2, 70] [2, 69] [4, 67] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 3.130488872528076 with beta sum per layer: [842.8916015625, 2264.095703125, 1922.04736328125, 1690.578125, 2220.629150390625]
alpha/beta optimization time: 0.38610291481018066
This batch time : update_bounds func: 1.0574	 prepare: 0.3973	 bound: 0.3866	 transfer: 0.0123	 finalize: 0.2529
Accumulated time: update_bounds func: 219.2426	 prepare: 68.3823	 bound: 73.2613	 transfer: 0.0123	 finalize: 69.0784
batch bounding time:  1.0604579448699951
Current worst splitting domains [lb, ub] (depth):
[-0.09162,   inf] (143), [-0.09162,   inf] (89), [-0.09162,   inf] (109), [-0.09162,   inf] (101), [-0.09162,   inf] (85), [-0.09162,   inf] (141), [-0.09162,   inf] (47), [-0.09162,   inf] (115), [-0.09162,   inf] (103), [-0.09162,   inf] (103), [-0.09161,   inf] (125), [-0.09161,   inf] (79), [-0.09161,   inf] (117), [-0.09161,   inf] (97), [-0.09161,   inf] (111), [-0.09161,   inf] (93), [-0.09161,   inf] (115), [-0.09161,   inf] (43), [-0.09161,   inf] (59), [-0.09161,   inf] (95), 
length of domains: 83908
Total time: 1.8395	 pickout: 0.2525	 decision: 0.2780	 get_bound: 1.0650	 add_domain: 0.2440
Current lb:-0.0916208028793335
371066 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 424.7810797691345

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 25] [1, 49] [3, 56] [2, 82] [2, 7] [4, 14] [2, 57] [1, 52] [3, 38] [3, 75] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 10.812472343444824 with beta sum per layer: [845.9229736328125, 2395.55126953125, 1917.3912353515625, 1771.318115234375, 2273.0556640625]
alpha/beta optimization time: 0.39018750190734863
This batch time : update_bounds func: 1.0591	 prepare: 0.4019	 bound: 0.3907	 transfer: 0.0123	 finalize: 0.2456
Accumulated time: update_bounds func: 220.3016	 prepare: 68.7842	 bound: 73.6520	 transfer: 0.0123	 finalize: 69.3240
batch bounding time:  1.061629295349121
Current worst splitting domains [lb, ub] (depth):
[-0.09150,   inf] (49), [-0.09099,   inf] (87), [-0.09099,   inf] (99), [-0.09099,   inf] (73), [-0.09099,   inf] (103), [-0.09099,   inf] (109), [-0.09099,   inf] (97), [-0.09099,   inf] (127), [-0.09098,   inf] (43), [-0.09098,   inf] (93), [-0.09098,   inf] (117), [-0.09098,   inf] (117), [-0.09098,   inf] (105), [-0.09098,   inf] (129), [-0.09098,   inf] (97), [-0.09098,   inf] (117), [-0.09098,   inf] (45), [-0.09098,   inf] (139), [-0.09098,   inf] (99), [-0.09098,   inf] (109), 
length of domains: 83998
Total time: 1.8482	 pickout: 0.2585	 decision: 0.2812	 get_bound: 1.0659	 add_domain: 0.2426
Current lb:-0.09149540960788727
373114 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 426.7046740055084

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 36] [0, 21] [1, 7] [0, 13] [1, 7] [0, 13] [4, 18] [4, 20] [1, 69] [2, 63] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 12.143281936645508 with beta sum per layer: [887.322265625, 2394.85302734375, 1989.6600341796875, 1760.81884765625, 2180.79296875]
alpha/beta optimization time: 0.3850283622741699
This batch time : update_bounds func: 1.0495	 prepare: 0.3968	 bound: 0.3856	 transfer: 0.0126	 finalize: 0.2457
Accumulated time: update_bounds func: 221.3512	 prepare: 69.1810	 bound: 74.0376	 transfer: 0.0126	 finalize: 69.5697
batch bounding time:  1.0522613525390625
Current worst splitting domains [lb, ub] (depth):
[-0.09037,   inf] (53), [-0.09037,   inf] (113), [-0.09037,   inf] (127), [-0.09037,   inf] (111), [-0.09037,   inf] (111), [-0.09037,   inf] (103), [-0.09037,   inf] (113), [-0.09037,   inf] (97), [-0.09037,   inf] (105), [-0.09037,   inf] (67), [-0.09036,   inf] (117), [-0.09036,   inf] (93), [-0.09036,   inf] (71), [-0.09036,   inf] (83), [-0.09036,   inf] (75), [-0.09036,   inf] (135), [-0.09036,   inf] (77), [-0.09036,   inf] (107), [-0.09036,   inf] (111), [-0.09036,   inf] (97), 
length of domains: 84115
Total time: 1.8437	 pickout: 0.2581	 decision: 0.2807	 get_bound: 1.0566	 add_domain: 0.2482
Current lb:-0.09037098288536072
375162 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 428.62224793434143

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 66] [1, 63] [3, 78] [4, 68] [3, 25] [3, 87] [1, 49] [0, 30] [2, 7] [0, 13] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 12.314873695373535 with beta sum per layer: [798.0081176757812, 2374.96728515625, 1992.075927734375, 1744.992919921875, 2081.662841796875]
alpha/beta optimization time: 0.38437414169311523
This batch time : update_bounds func: 1.0530	 prepare: 0.3989	 bound: 0.3849	 transfer: 0.0121	 finalize: 0.2488
Accumulated time: update_bounds func: 222.4041	 prepare: 69.5799	 bound: 74.4224	 transfer: 0.0121	 finalize: 69.8184
batch bounding time:  1.0558826923370361
Current worst splitting domains [lb, ub] (depth):
[-0.08973,   inf] (87), [-0.08973,   inf] (41), [-0.08973,   inf] (101), [-0.08973,   inf] (121), [-0.08973,   inf] (99), [-0.08973,   inf] (51), [-0.08973,   inf] (117), [-0.08973,   inf] (139), [-0.08973,   inf] (111), [-0.08972,   inf] (131), [-0.08972,   inf] (135), [-0.08972,   inf] (127), [-0.08972,   inf] (139), [-0.08972,   inf] (119), [-0.08972,   inf] (65), [-0.08972,   inf] (79), [-0.08972,   inf] (61), [-0.08972,   inf] (107), [-0.08972,   inf] (107), [-0.08972,   inf] (127), 
length of domains: 84215
Total time: 1.8478	 pickout: 0.2593	 decision: 0.2796	 get_bound: 1.0605	 add_domain: 0.2484
Current lb:-0.08973181247711182
377210 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 430.5390770435333

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 93] [1, 15] [2, 22] [4, 20] [4, 71] [1, 49] [2, 59] [4, 92] [2, 82] [4, 14] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 10.976761817932129 with beta sum per layer: [954.490234375, 2326.871826171875, 1971.2401123046875, 1756.7789306640625, 1965.15771484375]
alpha/beta optimization time: 0.3833909034729004
This batch time : update_bounds func: 1.0443	 prepare: 0.3951	 bound: 0.3839	 transfer: 0.0119	 finalize: 0.2450
Accumulated time: update_bounds func: 223.4485	 prepare: 69.9749	 bound: 74.8063	 transfer: 0.0119	 finalize: 70.0634
batch bounding time:  1.0469608306884766
Current worst splitting domains [lb, ub] (depth):
[-0.08909,   inf] (103), [-0.08909,   inf] (63), [-0.08909,   inf] (95), [-0.08909,   inf] (81), [-0.08909,   inf] (67), [-0.08908,   inf] (101), [-0.08908,   inf] (89), [-0.08908,   inf] (65), [-0.08908,   inf] (75), [-0.08908,   inf] (99), [-0.08908,   inf] (61), [-0.08908,   inf] (73), [-0.08908,   inf] (117), [-0.08908,   inf] (89), [-0.08908,   inf] (125), [-0.08908,   inf] (147), [-0.08908,   inf] (123), [-0.08908,   inf] (101), [-0.08908,   inf] (115), [-0.08908,   inf] (119), 
length of domains: 84338
Total time: 1.8385	 pickout: 0.2583	 decision: 0.2805	 get_bound: 1.0513	 add_domain: 0.2485
Current lb:-0.0890909731388092
379258 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 432.44780468940735

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 56] [1, 80] [0, 36] [0, 25] [2, 53] [4, 50] [0, 21] [2, 57] [2, 82] [4, 67] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 9.75516128540039 with beta sum per layer: [836.4796752929688, 2285.2958984375, 2034.4305419921875, 1677.104248046875, 2140.780029296875]
alpha/beta optimization time: 0.3842427730560303
This batch time : update_bounds func: 1.0637	 prepare: 0.4107	 bound: 0.3847	 transfer: 0.0121	 finalize: 0.2473
Accumulated time: update_bounds func: 224.5121	 prepare: 70.3857	 bound: 75.1910	 transfer: 0.0121	 finalize: 70.3106
batch bounding time:  1.0661275386810303
Current worst splitting domains [lb, ub] (depth):
[-0.08848,   inf] (109), [-0.08848,   inf] (107), [-0.08848,   inf] (129), [-0.08848,   inf] (113), [-0.08847,   inf] (129), [-0.08847,   inf] (55), [-0.08847,   inf] (83), [-0.08847,   inf] (99), [-0.08847,   inf] (69), [-0.08847,   inf] (101), [-0.08847,   inf] (97), [-0.08847,   inf] (109), [-0.08847,   inf] (101), [-0.08847,   inf] (105), [-0.08847,   inf] (113), [-0.08847,   inf] (95), [-0.08847,   inf] (99), [-0.08847,   inf] (159), [-0.08847,   inf] (93), [-0.08847,   inf] (115), 
length of domains: 84402
Total time: 1.8467	 pickout: 0.2533	 decision: 0.2828	 get_bound: 1.0703	 add_domain: 0.2403
Current lb:-0.08847768604755402
381306 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 434.37202858924866

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 49] [0, 89] [3, 25] [4, 71] [1, 70] [2, 60] [2, 7] [2, 59] [2, 82] [1, 54] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 6.067182540893555 with beta sum per layer: [822.81005859375, 2371.847412109375, 2039.999267578125, 1635.444091796875, 2204.71826171875]
alpha/beta optimization time: 0.3992171287536621
This batch time : update_bounds func: 4.6387	 prepare: 0.3965	 bound: 0.3997	 transfer: 0.0120	 finalize: 3.8209
Accumulated time: update_bounds func: 229.1508	 prepare: 70.7822	 bound: 75.5908	 transfer: 0.0120	 finalize: 74.1315
batch bounding time:  4.641693115234375
Current worst splitting domains [lb, ub] (depth):
[-0.08787,   inf] (131), [-0.08787,   inf] (111), [-0.08787,   inf] (121), [-0.08787,   inf] (67), [-0.08787,   inf] (123), [-0.08787,   inf] (71), [-0.08787,   inf] (101), [-0.08787,   inf] (117), [-0.08787,   inf] (95), [-0.08787,   inf] (73), [-0.08786,   inf] (69), [-0.08786,   inf] (53), [-0.08786,   inf] (69), [-0.08786,   inf] (127), [-0.08786,   inf] (75), [-0.08786,   inf] (77), [-0.08786,   inf] (119), [-0.08786,   inf] (103), [-0.08786,   inf] (117), [-0.08786,   inf] (85), 
length of domains: 84469
Total time: 5.4213	 pickout: 0.2580	 decision: 0.2745	 get_bound: 4.6469	 add_domain: 0.2419
Current lb:-0.0878685712814331
383354 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 439.86397433280945

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 14] [2, 57] [4, 28] [0, 72] [2, 22] [3, 73] [3, 38] [2, 7] [3, 75] [0, 2] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 0.608850359916687 with beta sum per layer: [894.49755859375, 2335.170654296875, 2002.8050537109375, 1709.858154296875, 2194.338623046875]
alpha/beta optimization time: 0.3957085609436035
This batch time : update_bounds func: 1.0680	 prepare: 0.3904	 bound: 0.3962	 transfer: 0.0138	 finalize: 0.2593
Accumulated time: update_bounds func: 230.2188	 prepare: 71.1725	 bound: 75.9870	 transfer: 0.0138	 finalize: 74.3908
batch bounding time:  1.0704495906829834
Current worst splitting domains [lb, ub] (depth):
[-0.08728,   inf] (95), [-0.08728,   inf] (129), [-0.08728,   inf] (135), [-0.08728,   inf] (99), [-0.08728,   inf] (83), [-0.08728,   inf] (101), [-0.08728,   inf] (117), [-0.08728,   inf] (123), [-0.08728,   inf] (121), [-0.08728,   inf] (125), [-0.08728,   inf] (71), [-0.08728,   inf] (97), [-0.08728,   inf] (49), [-0.08728,   inf] (89), [-0.08728,   inf] (109), [-0.08728,   inf] (113), [-0.08728,   inf] (139), [-0.08727,   inf] (101), [-0.08727,   inf] (137), [-0.08727,   inf] (89), 
length of domains: 84526
Total time: 1.8711	 pickout: 0.2722	 decision: 0.2772	 get_bound: 1.0749	 add_domain: 0.2468
Current lb:-0.08728450536727905
385402 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 441.8092737197876

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 27] [2, 22] [4, 98] [3, 0] [1, 43] [2, 53] [0, 89] [4, 71] [4, 20] [4, 28] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 3.3308792114257812 with beta sum per layer: [846.6325073242188, 2351.275390625, 2013.370849609375, 1684.7880859375, 2199.9892578125]
alpha/beta optimization time: 0.4022023677825928
This batch time : update_bounds func: 1.0846	 prepare: 0.4039	 bound: 0.4028	 transfer: 0.0126	 finalize: 0.2566
Accumulated time: update_bounds func: 231.3034	 prepare: 71.5764	 bound: 76.3897	 transfer: 0.0126	 finalize: 74.6474
batch bounding time:  1.087198257446289
Current worst splitting domains [lb, ub] (depth):
[-0.08691,   inf] (39), [-0.08667,   inf] (47), [-0.08667,   inf] (117), [-0.08667,   inf] (117), [-0.08667,   inf] (117), [-0.08667,   inf] (99), [-0.08666,   inf] (145), [-0.08666,   inf] (97), [-0.08666,   inf] (111), [-0.08666,   inf] (69), [-0.08666,   inf] (111), [-0.08666,   inf] (153), [-0.08666,   inf] (91), [-0.08666,   inf] (121), [-0.08666,   inf] (109), [-0.08666,   inf] (123), [-0.08666,   inf] (85), [-0.08666,   inf] (71), [-0.08666,   inf] (71), [-0.08666,   inf] (97), 
length of domains: 84593
Total time: 1.9009	 pickout: 0.2706	 decision: 0.2732	 get_bound: 1.0924	 add_domain: 0.2647
Current lb:-0.0869106873869896
387450 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 443.80032300949097

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 83] [4, 34] [1, 49] [2, 53] [2, 40] [0, 88] [3, 37] [3, 87] [2, 79] [1, 52] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5.807716369628906 with beta sum per layer: [822.0889892578125, 2391.132080078125, 2014.988037109375, 1716.531005859375, 2145.62109375]
alpha/beta optimization time: 0.3839747905731201
This batch time : update_bounds func: 1.0582	 prepare: 0.4037	 bound: 0.3845	 transfer: 0.0122	 finalize: 0.2488
Accumulated time: update_bounds func: 232.3616	 prepare: 71.9801	 bound: 76.7742	 transfer: 0.0122	 finalize: 74.8962
batch bounding time:  1.0606937408447266
Current worst splitting domains [lb, ub] (depth):
[-0.08607,   inf] (87), [-0.08607,   inf] (101), [-0.08607,   inf] (131), [-0.08607,   inf] (131), [-0.08607,   inf] (101), [-0.08607,   inf] (129), [-0.08607,   inf] (79), [-0.08607,   inf] (133), [-0.08607,   inf] (107), [-0.08607,   inf] (103), [-0.08607,   inf] (119), [-0.08607,   inf] (115), [-0.08607,   inf] (81), [-0.08607,   inf] (93), [-0.08607,   inf] (95), [-0.08607,   inf] (99), [-0.08606,   inf] (91), [-0.08606,   inf] (63), [-0.08606,   inf] (85), [-0.08606,   inf] (131), 
length of domains: 84680
Total time: 1.8952	 pickout: 0.2731	 decision: 0.2834	 get_bound: 1.0648	 add_domain: 0.2739
Current lb:-0.08607204258441925
389498 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 445.78917384147644

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 35] [2, 56] [1, 63] [2, 59] [2, 93] [3, 78] [3, 2] [1, 14] [4, 28] [1, 54] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 10.414042472839355 with beta sum per layer: [918.9736328125, 2349.95458984375, 2008.339111328125, 1744.525390625, 2073.7705078125]
alpha/beta optimization time: 0.38370680809020996
This batch time : update_bounds func: 1.0587	 prepare: 0.4044	 bound: 0.3842	 transfer: 0.0121	 finalize: 0.2494
Accumulated time: update_bounds func: 233.4203	 prepare: 72.3845	 bound: 77.1584	 transfer: 0.0121	 finalize: 75.1456
batch bounding time:  1.061389446258545
Current worst splitting domains [lb, ub] (depth):
[-0.08545,   inf] (97), [-0.08545,   inf] (125), [-0.08545,   inf] (71), [-0.08545,   inf] (127), [-0.08545,   inf] (69), [-0.08545,   inf] (105), [-0.08545,   inf] (113), [-0.08545,   inf] (91), [-0.08545,   inf] (91), [-0.08545,   inf] (115), [-0.08545,   inf] (127), [-0.08544,   inf] (43), [-0.08544,   inf] (115), [-0.08544,   inf] (107), [-0.08544,   inf] (97), [-0.08544,   inf] (81), [-0.08544,   inf] (119), [-0.08544,   inf] (71), [-0.08544,   inf] (119), [-0.08544,   inf] (105), 
length of domains: 84749
Total time: 1.8730	 pickout: 0.2743	 decision: 0.2808	 get_bound: 1.0658	 add_domain: 0.2520
Current lb:-0.08544915169477463
391546 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 447.7488052845001

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 93] [2, 22] [2, 66] [2, 40] [2, 70] [2, 63] [3, 38] [3, 38] [3, 35] [1, 7] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 10.438385009765625 with beta sum per layer: [826.6627197265625, 2339.76220703125, 1991.15283203125, 1711.15234375, 2160.0498046875]
alpha/beta optimization time: 0.38404321670532227
This batch time : update_bounds func: 1.0604	 prepare: 0.4080	 bound: 0.3845	 transfer: 0.0126	 finalize: 0.2469
Accumulated time: update_bounds func: 234.4807	 prepare: 72.7925	 bound: 77.5430	 transfer: 0.0126	 finalize: 75.3926
batch bounding time:  1.062849998474121
Current worst splitting domains [lb, ub] (depth):
[-0.08528,   inf] (81), [-0.08481,   inf] (97), [-0.08481,   inf] (103), [-0.08481,   inf] (135), [-0.08481,   inf] (79), [-0.08481,   inf] (119), [-0.08481,   inf] (75), [-0.08481,   inf] (75), [-0.08481,   inf] (105), [-0.08481,   inf] (111), [-0.08481,   inf] (127), [-0.08481,   inf] (103), [-0.08481,   inf] (127), [-0.08481,   inf] (71), [-0.08481,   inf] (135), [-0.08481,   inf] (67), [-0.08481,   inf] (111), [-0.08481,   inf] (137), [-0.08481,   inf] (111), [-0.08481,   inf] (131), 
length of domains: 84842
Total time: 1.8640	 pickout: 0.2687	 decision: 0.2823	 get_bound: 1.0670	 add_domain: 0.2460
Current lb:-0.08527974039316177
393594 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 449.68413066864014

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 82] [4, 50] [4, 68] [2, 40] [1, 14] [3, 38] [0, 72] [2, 44] [2, 82] [4, 20] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5.037090301513672 with beta sum per layer: [834.1419067382812, 2263.288330078125, 1992.330322265625, 1716.3818359375, 2104.096435546875]
alpha/beta optimization time: 0.38477420806884766
This batch time : update_bounds func: 1.0564	 prepare: 0.4019	 bound: 0.3853	 transfer: 0.0126	 finalize: 0.2478
Accumulated time: update_bounds func: 235.5371	 prepare: 73.1944	 bound: 77.9283	 transfer: 0.0126	 finalize: 75.6404
batch bounding time:  1.0593130588531494
Current worst splitting domains [lb, ub] (depth):
[-0.08421,   inf] (103), [-0.08421,   inf] (113), [-0.08421,   inf] (45), [-0.08421,   inf] (103), [-0.08421,   inf] (109), [-0.08421,   inf] (87), [-0.08421,   inf] (59), [-0.08421,   inf] (115), [-0.08421,   inf] (105), [-0.08421,   inf] (117), [-0.08421,   inf] (73), [-0.08421,   inf] (127), [-0.08421,   inf] (123), [-0.08421,   inf] (87), [-0.08420,   inf] (57), [-0.08420,   inf] (107), [-0.08420,   inf] (109), [-0.08420,   inf] (123), [-0.08420,   inf] (71), [-0.08420,   inf] (139), 
length of domains: 84905
Total time: 1.8608	 pickout: 0.2734	 decision: 0.2801	 get_bound: 1.0638	 add_domain: 0.2435
Current lb:-0.08421392738819122
395642 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 451.6154034137726

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 7] [1, 93] [4, 7] [2, 27] [2, 82] [2, 63] [1, 49] [4, 68] [1, 93] [2, 59] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -0.08541834354400635 with beta sum per layer: [876.39306640625, 2346.39453125, 1925.086181640625, 1718.813720703125, 2059.515625]
alpha/beta optimization time: 0.38501667976379395
This batch time : update_bounds func: 4.7231	 prepare: 0.3967	 bound: 0.3855	 transfer: 0.0126	 finalize: 3.9196
Accumulated time: update_bounds func: 240.2602	 prepare: 73.5911	 bound: 78.3138	 transfer: 0.0126	 finalize: 79.5600
batch bounding time:  4.726133346557617
Current worst splitting domains [lb, ub] (depth):
[-0.08360,   inf] (107), [-0.08360,   inf] (51), [-0.08360,   inf] (71), [-0.08359,   inf] (99), [-0.08359,   inf] (107), [-0.08359,   inf] (75), [-0.08359,   inf] (93), [-0.08359,   inf] (119), [-0.08359,   inf] (141), [-0.08359,   inf] (101), [-0.08359,   inf] (55), [-0.08359,   inf] (139), [-0.08359,   inf] (109), [-0.08359,   inf] (107), [-0.08359,   inf] (127), [-0.08359,   inf] (141), [-0.08359,   inf] (77), [-0.08359,   inf] (83), [-0.08359,   inf] (121), [-0.08358,   inf] (91), 
length of domains: 84973
Total time: 5.5209	 pickout: 0.2656	 decision: 0.2802	 get_bound: 4.7308	 add_domain: 0.2443
Current lb:-0.08359585702419281
397690 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 457.2077956199646

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 53] [3, 84] [1, 49] [1, 63] [2, 56] [2, 63] [2, 79] [2, 53] [0, 21] [2, 96] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 7.172399997711182 with beta sum per layer: [784.5501708984375, 2386.25146484375, 2026.241943359375, 1678.873291015625, 2146.171875]
alpha/beta optimization time: 0.38281941413879395
This batch time : update_bounds func: 1.0522	 prepare: 0.3973	 bound: 0.3835	 transfer: 0.0126	 finalize: 0.2500
Accumulated time: update_bounds func: 241.3124	 prepare: 73.9884	 bound: 78.6972	 transfer: 0.0126	 finalize: 79.8100
batch bounding time:  1.0548007488250732
Current worst splitting domains [lb, ub] (depth):
[-0.08300,   inf] (83), [-0.08300,   inf] (97), [-0.08300,   inf] (103), [-0.08300,   inf] (125), [-0.08299,   inf] (137), [-0.08299,   inf] (71), [-0.08299,   inf] (39), [-0.08299,   inf] (129), [-0.08299,   inf] (67), [-0.08299,   inf] (95), [-0.08299,   inf] (75), [-0.08299,   inf] (43), [-0.08299,   inf] (137), [-0.08299,   inf] (157), [-0.08299,   inf] (107), [-0.08299,   inf] (147), [-0.08299,   inf] (71), [-0.08299,   inf] (85), [-0.08299,   inf] (109), [-0.08299,   inf] (119), 
length of domains: 85063
Total time: 1.8466	 pickout: 0.2598	 decision: 0.2787	 get_bound: 1.0592	 add_domain: 0.2489
Current lb:-0.08299762010574341
399738 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 459.12993574142456

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 18] [3, 38] [2, 56] [0, 21] [4, 20] [1, 52] [0, 72] [2, 22] [1, 54] [2, 63] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -6.265494346618652 with beta sum per layer: [880.8873291015625, 2378.08740234375, 1896.1866455078125, 1902.818603515625, 1955.816650390625]
alpha/beta optimization time: 0.38663744926452637
This batch time : update_bounds func: 1.0647	 prepare: 0.4049	 bound: 0.3872	 transfer: 0.0126	 finalize: 0.2508
Accumulated time: update_bounds func: 242.3771	 prepare: 74.3933	 bound: 79.0844	 transfer: 0.0126	 finalize: 80.0609
batch bounding time:  1.0673389434814453
Current worst splitting domains [lb, ub] (depth):
[-0.08235,   inf] (77), [-0.08235,   inf] (75), [-0.08235,   inf] (95), [-0.08235,   inf] (73), [-0.08235,   inf] (77), [-0.08235,   inf] (105), [-0.08235,   inf] (101), [-0.08235,   inf] (111), [-0.08235,   inf] (97), [-0.08235,   inf] (113), [-0.08235,   inf] (113), [-0.08235,   inf] (81), [-0.08235,   inf] (135), [-0.08235,   inf] (99), [-0.08235,   inf] (103), [-0.08235,   inf] (77), [-0.08234,   inf] (95), [-0.08234,   inf] (75), [-0.08234,   inf] (53), [-0.08234,   inf] (139), 
length of domains: 85140
Total time: 1.8486	 pickout: 0.2530	 decision: 0.2801	 get_bound: 1.0716	 add_domain: 0.2440
Current lb:-0.08235175907611847
401786 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 461.0481517314911

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 60] [3, 90] [2, 7] [3, 4] [3, 62] [3, 38] [3, 38] [1, 7] [3, 98] [2, 82] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 4.820216178894043 with beta sum per layer: [875.0748901367188, 2339.7197265625, 1995.15625, 1697.64111328125, 2016.794921875]
alpha/beta optimization time: 0.38536572456359863
This batch time : update_bounds func: 1.0554	 prepare: 0.3986	 bound: 0.3859	 transfer: 0.0126	 finalize: 0.2495
Accumulated time: update_bounds func: 243.4325	 prepare: 74.7919	 bound: 79.4702	 transfer: 0.0126	 finalize: 80.3103
batch bounding time:  1.058326244354248
Current worst splitting domains [lb, ub] (depth):
[-0.08219,   inf] (85), [-0.08178,   inf] (99), [-0.08178,   inf] (109), [-0.08177,   inf] (77), [-0.08177,   inf] (125), [-0.08177,   inf] (105), [-0.08177,   inf] (53), [-0.08177,   inf] (131), [-0.08177,   inf] (123), [-0.08177,   inf] (117), [-0.08177,   inf] (125), [-0.08177,   inf] (99), [-0.08177,   inf] (125), [-0.08177,   inf] (89), [-0.08177,   inf] (101), [-0.08177,   inf] (139), [-0.08177,   inf] (71), [-0.08177,   inf] (47), [-0.08177,   inf] (33), [-0.08177,   inf] (111), 
length of domains: 85208
Total time: 1.8463	 pickout: 0.2559	 decision: 0.2789	 get_bound: 1.0628	 add_domain: 0.2486
Current lb:-0.08218904584646225
403834 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 462.96513295173645

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 13] [2, 63] [2, 82] [1, 93] [4, 14] [3, 35] [3, 14] [0, 36] [4, 71] [2, 22] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1.6331334114074707 with beta sum per layer: [775.3048706054688, 2163.5244140625, 1958.85400390625, 1832.453125, 2334.599365234375]
alpha/beta optimization time: 0.3858451843261719
This batch time : update_bounds func: 1.0553	 prepare: 0.4001	 bound: 0.3864	 transfer: 0.0125	 finalize: 0.2479
Accumulated time: update_bounds func: 244.4878	 prepare: 75.1920	 bound: 79.8566	 transfer: 0.0125	 finalize: 80.5583
batch bounding time:  1.0579273700714111
Current worst splitting domains [lb, ub] (depth):
[-0.08120,   inf] (113), [-0.08120,   inf] (115), [-0.08120,   inf] (143), [-0.08120,   inf] (69), [-0.08120,   inf] (97), [-0.08120,   inf] (125), [-0.08120,   inf] (93), [-0.08120,   inf] (107), [-0.08120,   inf] (125), [-0.08120,   inf] (79), [-0.08120,   inf] (93), [-0.08120,   inf] (137), [-0.08119,   inf] (113), [-0.08119,   inf] (127), [-0.08119,   inf] (135), [-0.08119,   inf] (145), [-0.08119,   inf] (109), [-0.08119,   inf] (99), [-0.08119,   inf] (97), [-0.08119,   inf] (113), 
length of domains: 85252
Total time: 1.8313	 pickout: 0.2541	 decision: 0.2769	 get_bound: 1.0622	 add_domain: 0.2381
Current lb:-0.08120143413543701
405882 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 464.8684067726135

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 71] [2, 66] [4, 14] [2, 76] [0, 36] [2, 59] [4, 67] [4, 68] [3, 25] [2, 70] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -1.7415776252746582 with beta sum per layer: [806.436279296875, 2491.08203125, 1938.733642578125, 1836.15771484375, 1950.6680908203125]
alpha/beta optimization time: 0.38581275939941406
This batch time : update_bounds func: 1.0566	 prepare: 0.4002	 bound: 0.3863	 transfer: 0.0120	 finalize: 0.2495
Accumulated time: update_bounds func: 245.5444	 prepare: 75.5922	 bound: 80.2429	 transfer: 0.0120	 finalize: 80.8078
batch bounding time:  1.0592880249023438
Current worst splitting domains [lb, ub] (depth):
[-0.08062,   inf] (119), [-0.08062,   inf] (95), [-0.08062,   inf] (99), [-0.08062,   inf] (65), [-0.08062,   inf] (59), [-0.08062,   inf] (75), [-0.08062,   inf] (81), [-0.08062,   inf] (99), [-0.08062,   inf] (85), [-0.08062,   inf] (79), [-0.08062,   inf] (89), [-0.08062,   inf] (105), [-0.08062,   inf] (81), [-0.08062,   inf] (115), [-0.08062,   inf] (125), [-0.08062,   inf] (69), [-0.08062,   inf] (115), [-0.08061,   inf] (119), [-0.08061,   inf] (107), [-0.08061,   inf] (135), 
length of domains: 85314
Total time: 1.8405	 pickout: 0.2561	 decision: 0.2802	 get_bound: 1.0639	 add_domain: 0.2403
Current lb:-0.08062223345041275
407930 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 466.77887535095215

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 59] [0, 29] [2, 7] [3, 28] [3, 90] [3, 98] [2, 40] [1, 68] [4, 56] [3, 28] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -2.8310608863830566 with beta sum per layer: [844.796142578125, 2232.411865234375, 2033.64990234375, 1727.9906005859375, 2163.845947265625]
alpha/beta optimization time: 0.3894538879394531
This batch time : update_bounds func: 1.0712	 prepare: 0.4059	 bound: 0.3900	 transfer: 0.0125	 finalize: 0.2535
Accumulated time: update_bounds func: 246.6156	 prepare: 75.9981	 bound: 80.6329	 transfer: 0.0125	 finalize: 81.0613
batch bounding time:  1.0739498138427734
Current worst splitting domains [lb, ub] (depth):
[-0.08004,   inf] (79), [-0.08004,   inf] (77), [-0.08004,   inf] (79), [-0.08004,   inf] (61), [-0.08004,   inf] (61), [-0.08004,   inf] (95), [-0.08004,   inf] (87), [-0.08004,   inf] (71), [-0.08004,   inf] (107), [-0.08004,   inf] (99), [-0.08004,   inf] (119), [-0.08004,   inf] (91), [-0.08004,   inf] (95), [-0.08003,   inf] (103), [-0.08003,   inf] (113), [-0.08003,   inf] (137), [-0.08003,   inf] (63), [-0.08003,   inf] (117), [-0.08003,   inf] (87), [-0.08003,   inf] (95), 
length of domains: 85366
Total time: 1.8534	 pickout: 0.2508	 decision: 0.2823	 get_bound: 1.0783	 add_domain: 0.2420
Current lb:-0.08003883063793182
409978 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 468.70574498176575

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 18] [1, 69] [0, 13] [2, 59] [1, 80] [2, 44] [2, 70] [1, 70] [2, 82] [3, 0] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -1.2723591327667236 with beta sum per layer: [856.9962158203125, 2351.135009765625, 1855.8753662109375, 1703.37060546875, 2258.413818359375]
alpha/beta optimization time: 0.391190767288208
This batch time : update_bounds func: 4.6812	 prepare: 0.3993	 bound: 0.3917	 transfer: 0.0125	 finalize: 3.8691
Accumulated time: update_bounds func: 251.2968	 prepare: 76.3974	 bound: 81.0246	 transfer: 0.0125	 finalize: 84.9304
batch bounding time:  4.683877468109131
Current worst splitting domains [lb, ub] (depth):
[-0.07948,   inf] (75), [-0.07948,   inf] (101), [-0.07948,   inf] (101), [-0.07948,   inf] (109), [-0.07948,   inf] (131), [-0.07948,   inf] (87), [-0.07948,   inf] (129), [-0.07947,   inf] (31), [-0.07947,   inf] (117), [-0.07947,   inf] (89), [-0.07947,   inf] (39), [-0.07947,   inf] (75), [-0.07947,   inf] (75), [-0.07947,   inf] (131), [-0.07947,   inf] (121), [-0.07947,   inf] (91), [-0.07947,   inf] (103), [-0.07947,   inf] (105), [-0.07947,   inf] (107), [-0.07947,   inf] (57), 
length of domains: 85414
Total time: 5.4655	 pickout: 0.2536	 decision: 0.2806	 get_bound: 4.6883	 add_domain: 0.2430
Current lb:-0.07947899401187897
412026 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 474.25151681900024

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 17] [4, 50] [1, 63] [1, 7] [2, 44] [1, 52] [3, 38] [2, 93] [1, 7] [2, 63] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -3.3408641815185547 with beta sum per layer: [832.0438232421875, 2417.38134765625, 1984.394775390625, 1786.107666015625, 2054.740966796875]
alpha/beta optimization time: 0.3874967098236084
This batch time : update_bounds func: 1.0710	 prepare: 0.3988	 bound: 0.3880	 transfer: 0.0126	 finalize: 0.2631
Accumulated time: update_bounds func: 252.3677	 prepare: 76.7962	 bound: 81.4126	 transfer: 0.0126	 finalize: 85.1935
batch bounding time:  1.0734009742736816
Current worst splitting domains [lb, ub] (depth):
[-0.07891,   inf] (85), [-0.07891,   inf] (99), [-0.07891,   inf] (105), [-0.07891,   inf] (121), [-0.07891,   inf] (73), [-0.07891,   inf] (65), [-0.07891,   inf] (107), [-0.07891,   inf] (97), [-0.07891,   inf] (83), [-0.07891,   inf] (83), [-0.07891,   inf] (135), [-0.07891,   inf] (113), [-0.07891,   inf] (79), [-0.07890,   inf] (121), [-0.07890,   inf] (125), [-0.07890,   inf] (99), [-0.07890,   inf] (95), [-0.07890,   inf] (43), [-0.07890,   inf] (103), [-0.07890,   inf] (109), 
length of domains: 85442
Total time: 1.8467	 pickout: 0.2557	 decision: 0.2792	 get_bound: 1.0774	 add_domain: 0.2345
Current lb:-0.07891194522380829
414074 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 476.17494344711304

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 49] [2, 27] [0, 29] [2, 44] [2, 76] [2, 60] [4, 67] [3, 38] [4, 18] [4, 50] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -10.844717025756836 with beta sum per layer: [883.0615234375, 2427.67236328125, 1952.4932861328125, 1796.0390625, 2118.11181640625]
alpha/beta optimization time: 0.39613890647888184
This batch time : update_bounds func: 1.0697	 prepare: 0.3944	 bound: 0.3966	 transfer: 0.0138	 finalize: 0.2561
Accumulated time: update_bounds func: 253.4374	 prepare: 77.1906	 bound: 81.8092	 transfer: 0.0138	 finalize: 85.4496
batch bounding time:  1.0722720623016357
Current worst splitting domains [lb, ub] (depth):
[-0.07834,   inf] (81), [-0.07834,   inf] (155), [-0.07834,   inf] (87), [-0.07834,   inf] (147), [-0.07834,   inf] (133), [-0.07833,   inf] (77), [-0.07833,   inf] (133), [-0.07833,   inf] (141), [-0.07833,   inf] (91), [-0.07833,   inf] (85), [-0.07833,   inf] (103), [-0.07833,   inf] (121), [-0.07833,   inf] (77), [-0.07833,   inf] (51), [-0.07833,   inf] (109), [-0.07833,   inf] (115), [-0.07833,   inf] (75), [-0.07833,   inf] (117), [-0.07833,   inf] (111), [-0.07833,   inf] (83), 
length of domains: 85499
Total time: 1.8485	 pickout: 0.2588	 decision: 0.2747	 get_bound: 1.0765	 add_domain: 0.2385
Current lb:-0.07833808660507202
416122 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 478.0997667312622

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 90] [3, 73] [3, 28] [4, 82] [4, 20] [2, 57] [1, 54] [1, 54] [1, 52] [1, 70] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 0.6777276992797852 with beta sum per layer: [765.3236694335938, 2284.368408203125, 2021.9932861328125, 1736.972900390625, 2034.1680908203125]
alpha/beta optimization time: 0.4052305221557617
This batch time : update_bounds func: 1.0793	 prepare: 0.3979	 bound: 0.4058	 transfer: 0.0125	 finalize: 0.2547
Accumulated time: update_bounds func: 254.5167	 prepare: 77.5886	 bound: 82.2150	 transfer: 0.0125	 finalize: 85.7043
batch bounding time:  1.0824072360992432
Current worst splitting domains [lb, ub] (depth):
[-0.07778,   inf] (103), [-0.07778,   inf] (109), [-0.07778,   inf] (61), [-0.07778,   inf] (113), [-0.07778,   inf] (139), [-0.07778,   inf] (73), [-0.07778,   inf] (51), [-0.07778,   inf] (129), [-0.07778,   inf] (93), [-0.07778,   inf] (133), [-0.07777,   inf] (109), [-0.07777,   inf] (119), [-0.07777,   inf] (121), [-0.07777,   inf] (101), [-0.07777,   inf] (97), [-0.07777,   inf] (105), [-0.07777,   inf] (117), [-0.07777,   inf] (47), [-0.07777,   inf] (71), [-0.07777,   inf] (91), 
length of domains: 85544
Total time: 1.8666	 pickout: 0.2516	 decision: 0.2749	 get_bound: 1.0883	 add_domain: 0.2518
Current lb:-0.07778048515319824
418170 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 480.0496175289154

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 88] [0, 2] [0, 98] [3, 38] [3, 0] [2, 57] [2, 57] [2, 82] [1, 52] [0, 89] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -3.4710845947265625 with beta sum per layer: [856.3735961914062, 2393.91796875, 2018.802734375, 1706.24267578125, 2008.0831298828125]
alpha/beta optimization time: 0.3938596248626709
This batch time : update_bounds func: 1.1012	 prepare: 0.3976	 bound: 0.3944	 transfer: 0.0133	 finalize: 0.2865
Accumulated time: update_bounds func: 255.6179	 prepare: 77.9862	 bound: 82.6094	 transfer: 0.0133	 finalize: 85.9908
batch bounding time:  1.1040613651275635
Current worst splitting domains [lb, ub] (depth):
[-0.07722,   inf] (117), [-0.07722,   inf] (65), [-0.07722,   inf] (127), [-0.07722,   inf] (87), [-0.07722,   inf] (133), [-0.07722,   inf] (149), [-0.07722,   inf] (141), [-0.07721,   inf] (129), [-0.07721,   inf] (151), [-0.07721,   inf] (103), [-0.07721,   inf] (105), [-0.07721,   inf] (127), [-0.07721,   inf] (81), [-0.07721,   inf] (113), [-0.07721,   inf] (75), [-0.07721,   inf] (33), [-0.07721,   inf] (75), [-0.07721,   inf] (141), [-0.07721,   inf] (91), [-0.07721,   inf] (93), 
length of domains: 85596
Total time: 1.8954	 pickout: 0.2648	 decision: 0.2785	 get_bound: 1.1085	 add_domain: 0.2435
Current lb:-0.07721809297800064
420218 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 482.02279233932495

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 71] [3, 90] [3, 37] [1, 54] [2, 44] [4, 82] [1, 14] [2, 18] [4, 82] [3, 38] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1.8298383951187134 with beta sum per layer: [840.9144897460938, 2324.2392578125, 2037.3739013671875, 1711.9097900390625, 2093.73779296875]
alpha/beta optimization time: 0.38519287109375
This batch time : update_bounds func: 1.0582	 prepare: 0.3994	 bound: 0.3857	 transfer: 0.0125	 finalize: 0.2517
Accumulated time: update_bounds func: 256.6761	 prepare: 78.3856	 bound: 82.9951	 transfer: 0.0125	 finalize: 86.2425
batch bounding time:  1.0608844757080078
Current worst splitting domains [lb, ub] (depth):
[-0.07690,   inf] (79), [-0.07667,   inf] (131), [-0.07667,   inf] (119), [-0.07667,   inf] (109), [-0.07667,   inf] (59), [-0.07667,   inf] (77), [-0.07667,   inf] (77), [-0.07667,   inf] (91), [-0.07667,   inf] (55), [-0.07667,   inf] (125), [-0.07666,   inf] (63), [-0.07666,   inf] (137), [-0.07666,   inf] (109), [-0.07666,   inf] (55), [-0.07666,   inf] (157), [-0.07666,   inf] (115), [-0.07666,   inf] (101), [-0.07666,   inf] (101), [-0.07666,   inf] (135), [-0.07666,   inf] (95), 
length of domains: 85629
Total time: 1.8480	 pickout: 0.2607	 decision: 0.2814	 get_bound: 1.0653	 add_domain: 0.2406
Current lb:-0.07689890265464783
422266 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 483.94850993156433

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 82] [0, 72] [2, 82] [2, 63] [2, 27] [3, 2] [4, 0] [2, 93] [0, 98] [3, 0] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -6.034154415130615 with beta sum per layer: [811.793212890625, 2228.11962890625, 2053.519775390625, 1824.8719482421875, 2063.0087890625]
alpha/beta optimization time: 0.3847811222076416
This batch time : update_bounds func: 1.0659	 prepare: 0.4071	 bound: 0.3853	 transfer: 0.0122	 finalize: 0.2527
Accumulated time: update_bounds func: 257.7420	 prepare: 78.7927	 bound: 83.3804	 transfer: 0.0122	 finalize: 86.4952
batch bounding time:  1.0687198638916016
Current worst splitting domains [lb, ub] (depth):
[-0.07614,   inf] (71), [-0.07614,   inf] (85), [-0.07614,   inf] (87), [-0.07614,   inf] (151), [-0.07613,   inf] (53), [-0.07613,   inf] (99), [-0.07613,   inf] (89), [-0.07613,   inf] (123), [-0.07613,   inf] (91), [-0.07613,   inf] (109), [-0.07613,   inf] (103), [-0.07613,   inf] (121), [-0.07613,   inf] (77), [-0.07613,   inf] (107), [-0.07613,   inf] (129), [-0.07613,   inf] (107), [-0.07613,   inf] (109), [-0.07613,   inf] (103), [-0.07613,   inf] (101), [-0.07613,   inf] (139), 
length of domains: 85654
Total time: 1.8539	 pickout: 0.2615	 decision: 0.2800	 get_bound: 1.0731	 add_domain: 0.2393
Current lb:-0.07613550871610641
424314 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 485.87991166114807

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 69] [2, 64] [3, 35] [3, 0] [3, 22] [0, 29] [0, 88] [3, 84] [2, 82] [3, 38] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -8.004823684692383 with beta sum per layer: [826.5751342773438, 2334.640625, 2072.868408203125, 1760.516357421875, 2063.0654296875]
alpha/beta optimization time: 0.38491272926330566
This batch time : update_bounds func: 4.7292	 prepare: 0.4017	 bound: 0.3854	 transfer: 0.0124	 finalize: 3.9211
Accumulated time: update_bounds func: 262.4713	 prepare: 79.1945	 bound: 83.7658	 transfer: 0.0124	 finalize: 90.4163
batch bounding time:  4.732043027877808
Current worst splitting domains [lb, ub] (depth):
[-0.07558,   inf] (131), [-0.07558,   inf] (97), [-0.07558,   inf] (79), [-0.07558,   inf] (103), [-0.07558,   inf] (57), [-0.07558,   inf] (97), [-0.07558,   inf] (101), [-0.07558,   inf] (107), [-0.07558,   inf] (73), [-0.07558,   inf] (105), [-0.07558,   inf] (41), [-0.07558,   inf] (79), [-0.07558,   inf] (103), [-0.07558,   inf] (45), [-0.07558,   inf] (115), [-0.07557,   inf] (59), [-0.07557,   inf] (119), [-0.07557,   inf] (101), [-0.07557,   inf] (105), [-0.07557,   inf] (73), 
length of domains: 85690
Total time: 5.5194	 pickout: 0.2599	 decision: 0.2819	 get_bound: 4.7366	 add_domain: 0.2411
Current lb:-0.07558190822601318
426362 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 491.4779169559479

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 63] [2, 7] [2, 70] [2, 79] [2, 57] [2, 59] [2, 79] [4, 67] [2, 44] [0, 13] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -0.45586657524108887 with beta sum per layer: [881.9822998046875, 2386.004150390625, 2008.7666015625, 1660.0050048828125, 1880.489013671875]
alpha/beta optimization time: 0.39172983169555664
This batch time : update_bounds func: 1.0640	 prepare: 0.3996	 bound: 0.3922	 transfer: 0.0120	 finalize: 0.2509
Accumulated time: update_bounds func: 263.5353	 prepare: 79.5941	 bound: 84.1580	 transfer: 0.0120	 finalize: 90.6672
batch bounding time:  1.0667409896850586
Current worst splitting domains [lb, ub] (depth):
[-0.07504,   inf] (83), [-0.07504,   inf] (105), [-0.07504,   inf] (103), [-0.07504,   inf] (135), [-0.07504,   inf] (97), [-0.07504,   inf] (67), [-0.07504,   inf] (115), [-0.07503,   inf] (141), [-0.07503,   inf] (73), [-0.07503,   inf] (109), [-0.07503,   inf] (109), [-0.07503,   inf] (129), [-0.07503,   inf] (103), [-0.07503,   inf] (49), [-0.07503,   inf] (121), [-0.07503,   inf] (75), [-0.07503,   inf] (129), [-0.07503,   inf] (109), [-0.07503,   inf] (101), [-0.07503,   inf] (91), 
length of domains: 85735
Total time: 1.8622	 pickout: 0.2586	 decision: 0.2908	 get_bound: 1.0711	 add_domain: 0.2416
Current lb:-0.07503936439752579
428410 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 493.4168436527252

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 49] [1, 54] [4, 67] [4, 14] [1, 93] [0, 13] [0, 29] [3, 25] [3, 98] [2, 79] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -5.922266483306885 with beta sum per layer: [768.558837890625, 2446.09033203125, 2058.5, 1805.81005859375, 2101.50634765625]
alpha/beta optimization time: 0.38569164276123047
This batch time : update_bounds func: 1.0677	 prepare: 0.4070	 bound: 0.3862	 transfer: 0.0125	 finalize: 0.2531
Accumulated time: update_bounds func: 264.6031	 prepare: 80.0011	 bound: 84.5442	 transfer: 0.0125	 finalize: 90.9203
batch bounding time:  1.0702993869781494
Current worst splitting domains [lb, ub] (depth):
[-0.07495,   inf] (85), [-0.07446,   inf] (109), [-0.07446,   inf] (123), [-0.07446,   inf] (95), [-0.07446,   inf] (119), [-0.07446,   inf] (99), [-0.07446,   inf] (115), [-0.07446,   inf] (65), [-0.07446,   inf] (137), [-0.07446,   inf] (99), [-0.07446,   inf] (117), [-0.07446,   inf] (95), [-0.07446,   inf] (103), [-0.07446,   inf] (113), [-0.07446,   inf] (139), [-0.07446,   inf] (75), [-0.07446,   inf] (73), [-0.07445,   inf] (87), [-0.07445,   inf] (59), [-0.07445,   inf] (119), 
length of domains: 85751
Total time: 1.8534	 pickout: 0.2591	 decision: 0.2833	 get_bound: 1.0744	 add_domain: 0.2366
Current lb:-0.0749533548951149
430458 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 495.3449776172638

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 13] [3, 75] [0, 13] [1, 93] [2, 56] [1, 52] [2, 44] [3, 22] [4, 82] [4, 56] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -6.119158744812012 with beta sum per layer: [882.265625, 2399.681640625, 2049.857421875, 1767.4091796875, 2041.623779296875]
alpha/beta optimization time: 0.3860502243041992
This batch time : update_bounds func: 1.0612	 prepare: 0.3980	 bound: 0.3866	 transfer: 0.0124	 finalize: 0.2555
Accumulated time: update_bounds func: 265.6643	 prepare: 80.3991	 bound: 84.9308	 transfer: 0.0124	 finalize: 91.1758
batch bounding time:  1.0637757778167725
Current worst splitting domains [lb, ub] (depth):
[-0.07397,   inf] (101), [-0.07397,   inf] (117), [-0.07396,   inf] (155), [-0.07396,   inf] (73), [-0.07396,   inf] (65), [-0.07396,   inf] (117), [-0.07396,   inf] (121), [-0.07396,   inf] (91), [-0.07396,   inf] (93), [-0.07396,   inf] (79), [-0.07396,   inf] (161), [-0.07396,   inf] (123), [-0.07396,   inf] (77), [-0.07396,   inf] (73), [-0.07396,   inf] (101), [-0.07396,   inf] (123), [-0.07396,   inf] (75), [-0.07396,   inf] (101), [-0.07396,   inf] (105), [-0.07396,   inf] (101), 
length of domains: 85756
Total time: 1.8512	 pickout: 0.2646	 decision: 0.2820	 get_bound: 1.0679	 add_domain: 0.2366
Current lb:-0.07396558672189713
432506 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 497.2707996368408

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 56] [2, 82] [1, 49] [1, 68] [1, 80] [2, 22] [4, 71] [2, 60] [1, 49] [0, 2] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -0.5031765699386597 with beta sum per layer: [873.6934814453125, 2471.194580078125, 1939.60595703125, 1771.087646484375, 2052.63330078125]
alpha/beta optimization time: 0.38451385498046875
This batch time : update_bounds func: 1.0650	 prepare: 0.4006	 bound: 0.3850	 transfer: 0.0126	 finalize: 0.2583
Accumulated time: update_bounds func: 266.7293	 prepare: 80.7997	 bound: 85.3158	 transfer: 0.0126	 finalize: 91.4341
batch bounding time:  1.0677616596221924
Current worst splitting domains [lb, ub] (depth):
[-0.07343,   inf] (95), [-0.07343,   inf] (107), [-0.07343,   inf] (143), [-0.07343,   inf] (81), [-0.07343,   inf] (105), [-0.07343,   inf] (61), [-0.07343,   inf] (81), [-0.07343,   inf] (133), [-0.07343,   inf] (107), [-0.07343,   inf] (123), [-0.07343,   inf] (95), [-0.07343,   inf] (107), [-0.07343,   inf] (113), [-0.07343,   inf] (111), [-0.07342,   inf] (103), [-0.07342,   inf] (101), [-0.07342,   inf] (129), [-0.07342,   inf] (129), [-0.07342,   inf] (103), [-0.07342,   inf] (45), 
length of domains: 85781
Total time: 1.8636	 pickout: 0.2702	 decision: 0.2781	 get_bound: 1.0723	 add_domain: 0.2430
Current lb:-0.0734311044216156
434554 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 499.2068409919739

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 35] [2, 79] [3, 10] [1, 80] [4, 67] [3, 37] [3, 75] [3, 78] [1, 7] [2, 44] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -13.261270523071289 with beta sum per layer: [849.8465576171875, 2423.0615234375, 1963.361328125, 1723.837158203125, 2155.46337890625]
alpha/beta optimization time: 0.384324312210083
This batch time : update_bounds func: 1.0550	 prepare: 0.3961	 bound: 0.3848	 transfer: 0.0120	 finalize: 0.2535
Accumulated time: update_bounds func: 267.7842	 prepare: 81.1959	 bound: 85.7006	 transfer: 0.0120	 finalize: 91.6877
batch bounding time:  1.0581700801849365
Current worst splitting domains [lb, ub] (depth):
[-0.07310,   inf] (87), [-0.07292,   inf] (75), [-0.07292,   inf] (155), [-0.07292,   inf] (111), [-0.07292,   inf] (85), [-0.07292,   inf] (115), [-0.07291,   inf] (143), [-0.07291,   inf] (133), [-0.07291,   inf] (97), [-0.07291,   inf] (129), [-0.07291,   inf] (73), [-0.07291,   inf] (143), [-0.07291,   inf] (101), [-0.07291,   inf] (101), [-0.07291,   inf] (79), [-0.07291,   inf] (85), [-0.07291,   inf] (89), [-0.07291,   inf] (101), [-0.07291,   inf] (75), [-0.07291,   inf] (107), 
length of domains: 85767
Total time: 1.8440	 pickout: 0.2695	 decision: 0.2810	 get_bound: 1.0629	 add_domain: 0.2307
Current lb:-0.07310432195663452
436602 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 501.1267468929291

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 7] [2, 70] [0, 11] [3, 38] [0, 72] [2, 59] [2, 22] [2, 22] [2, 27] [2, 10] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -7.1751909255981445 with beta sum per layer: [858.6390380859375, 2345.77734375, 2006.9896240234375, 1707.53515625, 2156.499267578125]
alpha/beta optimization time: 0.3960552215576172
This batch time : update_bounds func: 1.0687	 prepare: 0.3969	 bound: 0.3966	 transfer: 0.0119	 finalize: 0.2548
Accumulated time: update_bounds func: 268.8530	 prepare: 81.5928	 bound: 86.0972	 transfer: 0.0119	 finalize: 91.9424
batch bounding time:  1.0715126991271973
Current worst splitting domains [lb, ub] (depth):
[-0.07276,   inf] (39), [-0.07238,   inf] (115), [-0.07238,   inf] (99), [-0.07238,   inf] (153), [-0.07238,   inf] (125), [-0.07238,   inf] (53), [-0.07238,   inf] (117), [-0.07238,   inf] (141), [-0.07238,   inf] (61), [-0.07237,   inf] (99), [-0.07237,   inf] (121), [-0.07237,   inf] (117), [-0.07237,   inf] (123), [-0.07237,   inf] (79), [-0.07237,   inf] (91), [-0.07237,   inf] (59), [-0.07237,   inf] (121), [-0.07237,   inf] (101), [-0.07237,   inf] (109), [-0.07237,   inf] (81), 
length of domains: 85774
Total time: 1.8686	 pickout: 0.2727	 decision: 0.2834	 get_bound: 1.0760	 add_domain: 0.2366
Current lb:-0.0727601945400238
438650 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 503.0704026222229

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 15] [2, 7] [2, 82] [3, 19] [2, 69] [1, 69] [4, 28] [2, 7] [3, 10] [2, 53] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -9.653977394104004 with beta sum per layer: [819.5556030273438, 2392.525390625, 2034.066162109375, 1794.82568359375, 2031.93310546875]
alpha/beta optimization time: 0.384096622467041
This batch time : update_bounds func: 4.9016	 prepare: 0.4047	 bound: 0.3846	 transfer: 0.0126	 finalize: 4.0908
Accumulated time: update_bounds func: 273.7545	 prepare: 81.9974	 bound: 86.4818	 transfer: 0.0126	 finalize: 96.0333
batch bounding time:  4.9039201736450195
Current worst splitting domains [lb, ub] (depth):
[-0.07223,   inf] (85), [-0.07186,   inf] (81), [-0.07186,   inf] (107), [-0.07186,   inf] (137), [-0.07186,   inf] (49), [-0.07186,   inf] (47), [-0.07186,   inf] (141), [-0.07186,   inf] (123), [-0.07186,   inf] (59), [-0.07186,   inf] (107), [-0.07186,   inf] (49), [-0.07186,   inf] (105), [-0.07186,   inf] (105), [-0.07186,   inf] (141), [-0.07186,   inf] (67), [-0.07186,   inf] (87), [-0.07186,   inf] (101), [-0.07185,   inf] (83), [-0.07185,   inf] (127), [-0.07185,   inf] (57), 
length of domains: 85761
Total time: 5.7127	 pickout: 0.2761	 decision: 0.2969	 get_bound: 4.9080	 add_domain: 0.2317
Current lb:-0.0722254291176796
440698 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 508.8554666042328

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 7] [4, 56] [1, 52] [3, 84] [4, 43] [2, 63] [2, 40] [1, 52] [3, 62] [0, 36] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -15.343095779418945 with beta sum per layer: [846.2462768554688, 2401.85205078125, 2060.981201171875, 1724.5242919921875, 1870.525146484375]
alpha/beta optimization time: 0.3835902214050293
This batch time : update_bounds func: 1.0596	 prepare: 0.3988	 bound: 0.3841	 transfer: 0.0124	 finalize: 0.2553
Accumulated time: update_bounds func: 274.8142	 prepare: 82.3963	 bound: 86.8659	 transfer: 0.0124	 finalize: 96.2886
batch bounding time:  1.0623087882995605
Current worst splitting domains [lb, ub] (depth):
[-0.07131,   inf] (155), [-0.07131,   inf] (111), [-0.07131,   inf] (123), [-0.07131,   inf] (135), [-0.07131,   inf] (91), [-0.07131,   inf] (61), [-0.07131,   inf] (101), [-0.07131,   inf] (101), [-0.07131,   inf] (159), [-0.07131,   inf] (119), [-0.07131,   inf] (115), [-0.07131,   inf] (91), [-0.07131,   inf] (113), [-0.07131,   inf] (99), [-0.07131,   inf] (105), [-0.07130,   inf] (67), [-0.07130,   inf] (91), [-0.07130,   inf] (99), [-0.07130,   inf] (151), [-0.07130,   inf] (133), 
length of domains: 85782
Total time: 1.8573	 pickout: 0.2634	 decision: 0.2871	 get_bound: 1.0666	 add_domain: 0.2401
Current lb:-0.07131179422140121
442746 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 510.7853298187256

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 10] [1, 54] [3, 37] [4, 82] [3, 38] [3, 19] [3, 38] [2, 7] [0, 11] [2, 63] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -6.440621376037598 with beta sum per layer: [864.6373291015625, 2251.31591796875, 1972.505126953125, 1815.571044921875, 1968.82421875]
alpha/beta optimization time: 0.38300180435180664
This batch time : update_bounds func: 1.0545	 prepare: 0.3975	 bound: 0.3835	 transfer: 0.0120	 finalize: 0.2522
Accumulated time: update_bounds func: 275.8687	 prepare: 82.7938	 bound: 87.2494	 transfer: 0.0120	 finalize: 96.5408
batch bounding time:  1.057180404663086
Current worst splitting domains [lb, ub] (depth):
[-0.07079,   inf] (119), [-0.07079,   inf] (97), [-0.07079,   inf] (125), [-0.07079,   inf] (119), [-0.07079,   inf] (71), [-0.07079,   inf] (77), [-0.07079,   inf] (71), [-0.07079,   inf] (103), [-0.07079,   inf] (79), [-0.07079,   inf] (97), [-0.07079,   inf] (39), [-0.07079,   inf] (59), [-0.07078,   inf] (77), [-0.07078,   inf] (83), [-0.07078,   inf] (73), [-0.07078,   inf] (123), [-0.07078,   inf] (155), [-0.07078,   inf] (87), [-0.07078,   inf] (141), [-0.07078,   inf] (153), 
length of domains: 85764
Total time: 1.8381	 pickout: 0.2636	 decision: 0.2830	 get_bound: 1.0617	 add_domain: 0.2298
Current lb:-0.07078920304775238
444794 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 512.7027885913849

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 44] [2, 27] [3, 78] [1, 93] [2, 44] [1, 69] [2, 70] [3, 38] [2, 82] [2, 27] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -12.166525840759277 with beta sum per layer: [884.73095703125, 2507.921875, 2028.65185546875, 1722.4677734375, 1996.931884765625]
alpha/beta optimization time: 0.38390445709228516
This batch time : update_bounds func: 1.0481	 prepare: 0.3928	 bound: 0.3844	 transfer: 0.0126	 finalize: 0.2495
Accumulated time: update_bounds func: 276.9169	 prepare: 83.1866	 bound: 87.6338	 transfer: 0.0126	 finalize: 96.7903
batch bounding time:  1.0506715774536133
Current worst splitting domains [lb, ub] (depth):
[-0.07030,   inf] (111), [-0.07030,   inf] (47), [-0.07030,   inf] (169), [-0.07029,   inf] (59), [-0.07029,   inf] (93), [-0.07029,   inf] (103), [-0.07029,   inf] (121), [-0.07029,   inf] (109), [-0.07029,   inf] (91), [-0.07029,   inf] (117), [-0.07029,   inf] (103), [-0.07029,   inf] (121), [-0.07029,   inf] (123), [-0.07029,   inf] (91), [-0.07029,   inf] (127), [-0.07029,   inf] (31), [-0.07029,   inf] (63), [-0.07029,   inf] (99), [-0.07029,   inf] (109), [-0.07029,   inf] (103), 
length of domains: 85763
Total time: 1.8394	 pickout: 0.2638	 decision: 0.2853	 get_bound: 1.0550	 add_domain: 0.2354
Current lb:-0.07029638439416885
446842 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 514.6163060665131

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 0] [1, 43] [3, 73] [0, 21] [0, 13] [3, 49] [1, 70] [2, 44] [2, 53] [2, 82] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -12.995773315429688 with beta sum per layer: [829.1826171875, 2293.63671875, 1967.5673828125, 1758.713134765625, 1970.01123046875]
alpha/beta optimization time: 0.38178133964538574
This batch time : update_bounds func: 1.0463	 prepare: 0.3944	 bound: 0.3823	 transfer: 0.0121	 finalize: 0.2487
Accumulated time: update_bounds func: 277.9631	 prepare: 83.5810	 bound: 88.0161	 transfer: 0.0121	 finalize: 97.0391
batch bounding time:  1.0487186908721924
Current worst splitting domains [lb, ub] (depth):
[-0.06979,   inf] (125), [-0.06979,   inf] (87), [-0.06979,   inf] (75), [-0.06979,   inf] (79), [-0.06979,   inf] (93), [-0.06979,   inf] (109), [-0.06979,   inf] (133), [-0.06979,   inf] (135), [-0.06979,   inf] (103), [-0.06979,   inf] (87), [-0.06978,   inf] (117), [-0.06978,   inf] (127), [-0.06978,   inf] (111), [-0.06978,   inf] (75), [-0.06978,   inf] (135), [-0.06978,   inf] (77), [-0.06978,   inf] (145), [-0.06978,   inf] (115), [-0.06977,   inf] (111), [-0.06977,   inf] (129), 
length of domains: 85760
Total time: 1.8256	 pickout: 0.2615	 decision: 0.2774	 get_bound: 1.0529	 add_domain: 0.2338
Current lb:-0.06978952884674072
448890 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 516.5158808231354

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 78] [3, 35] [3, 2] [3, 86] [2, 60] [0, 89] [4, 14] [3, 84] [3, 87] [1, 49] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -10.721384048461914 with beta sum per layer: [852.30224609375, 2329.7509765625, 1971.3914794921875, 1773.641357421875, 2025.51318359375]
alpha/beta optimization time: 0.38352441787719727
This batch time : update_bounds func: 1.0577	 prepare: 0.3989	 bound: 0.3840	 transfer: 0.0123	 finalize: 0.2538
Accumulated time: update_bounds func: 279.0208	 prepare: 83.9798	 bound: 88.4001	 transfer: 0.0123	 finalize: 97.2928
batch bounding time:  1.0601775646209717
Current worst splitting domains [lb, ub] (depth):
[-0.06926,   inf] (105), [-0.06926,   inf] (89), [-0.06926,   inf] (73), [-0.06926,   inf] (93), [-0.06926,   inf] (71), [-0.06926,   inf] (91), [-0.06926,   inf] (103), [-0.06926,   inf] (105), [-0.06926,   inf] (135), [-0.06926,   inf] (137), [-0.06926,   inf] (79), [-0.06926,   inf] (151), [-0.06925,   inf] (79), [-0.06925,   inf] (89), [-0.06925,   inf] (81), [-0.06925,   inf] (125), [-0.06925,   inf] (111), [-0.06925,   inf] (125), [-0.06925,   inf] (115), [-0.06925,   inf] (141), 
length of domains: 85754
Total time: 1.8726	 pickout: 0.2748	 decision: 0.2996	 get_bound: 1.0644	 add_domain: 0.2338
Current lb:-0.06926140189170837
450938 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 518.4615507125854

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 82] [0, 89] [3, 75] [2, 7] [0, 21] [0, 21] [1, 52] [0, 89] [2, 57] [3, 25] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -11.916242599487305 with beta sum per layer: [910.2487182617188, 2196.70703125, 2048.2861328125, 1777.4271240234375, 2029.1168212890625]
alpha/beta optimization time: 0.38328099250793457
This batch time : update_bounds func: 1.0532	 prepare: 0.3950	 bound: 0.3838	 transfer: 0.0121	 finalize: 0.2535
Accumulated time: update_bounds func: 280.0740	 prepare: 84.3749	 bound: 88.7839	 transfer: 0.0121	 finalize: 97.5464
batch bounding time:  1.0559887886047363
Current worst splitting domains [lb, ub] (depth):
[-0.06908,   inf] (85), [-0.06874,   inf] (99), [-0.06874,   inf] (145), [-0.06874,   inf] (81), [-0.06874,   inf] (135), [-0.06874,   inf] (129), [-0.06874,   inf] (131), [-0.06874,   inf] (105), [-0.06874,   inf] (103), [-0.06874,   inf] (87), [-0.06873,   inf] (55), [-0.06873,   inf] (125), [-0.06873,   inf] (77), [-0.06873,   inf] (133), [-0.06873,   inf] (99), [-0.06873,   inf] (49), [-0.06873,   inf] (129), [-0.06873,   inf] (101), [-0.06873,   inf] (81), [-0.06873,   inf] (63), 
length of domains: 85749
Total time: 1.8388	 pickout: 0.2612	 decision: 0.2849	 get_bound: 1.0605	 add_domain: 0.2322
Current lb:-0.0690772607922554
452986 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 520.3746073246002

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 7] [3, 98] [2, 44] [1, 70] [2, 59] [2, 59] [3, 84] [1, 49] [3, 25] [2, 59] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -15.485447883605957 with beta sum per layer: [830.93359375, 2407.8681640625, 1959.60205078125, 1822.4560546875, 2022.90771484375]
alpha/beta optimization time: 0.38292479515075684
This batch time : update_bounds func: 4.8242	 prepare: 0.4040	 bound: 0.3834	 transfer: 0.0124	 finalize: 4.0158
Accumulated time: update_bounds func: 284.8982	 prepare: 84.7789	 bound: 89.1673	 transfer: 0.0124	 finalize: 101.5622
batch bounding time:  4.8267598152160645
Current worst splitting domains [lb, ub] (depth):
[-0.06824,   inf] (117), [-0.06824,   inf] (99), [-0.06824,   inf] (125), [-0.06824,   inf] (69), [-0.06824,   inf] (79), [-0.06824,   inf] (145), [-0.06824,   inf] (123), [-0.06824,   inf] (77), [-0.06824,   inf] (123), [-0.06824,   inf] (127), [-0.06824,   inf] (117), [-0.06824,   inf] (85), [-0.06824,   inf] (109), [-0.06824,   inf] (141), [-0.06823,   inf] (121), [-0.06823,   inf] (85), [-0.06823,   inf] (77), [-0.06823,   inf] (109), [-0.06823,   inf] (61), [-0.06823,   inf] (47), 
length of domains: 85752
Total time: 5.6068	 pickout: 0.2595	 decision: 0.2835	 get_bound: 4.8311	 add_domain: 0.2327
Current lb:-0.06824266910552979
455034 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 526.0542063713074

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 89] [1, 93] [2, 22] [2, 44] [1, 95] [2, 44] [4, 92] [2, 75] [4, 71] [4, 14] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -15.240068435668945 with beta sum per layer: [863.8595581054688, 2200.97119140625, 2056.353515625, 1713.81494140625, 2171.917236328125]
alpha/beta optimization time: 0.38754940032958984
This batch time : update_bounds func: 1.0704	 prepare: 0.4030	 bound: 0.3881	 transfer: 0.0122	 finalize: 0.2586
Accumulated time: update_bounds func: 285.9686	 prepare: 85.1819	 bound: 89.5554	 transfer: 0.0122	 finalize: 101.8208
batch bounding time:  1.0732574462890625
Current worst splitting domains [lb, ub] (depth):
[-0.06775,   inf] (115), [-0.06775,   inf] (99), [-0.06774,   inf] (117), [-0.06774,   inf] (99), [-0.06774,   inf] (111), [-0.06774,   inf] (107), [-0.06774,   inf] (109), [-0.06774,   inf] (173), [-0.06774,   inf] (133), [-0.06774,   inf] (133), [-0.06774,   inf] (71), [-0.06774,   inf] (103), [-0.06774,   inf] (31), [-0.06774,   inf] (91), [-0.06774,   inf] (117), [-0.06774,   inf] (55), [-0.06774,   inf] (125), [-0.06774,   inf] (87), [-0.06774,   inf] (119), [-0.06774,   inf] (99), 
length of domains: 85716
Total time: 1.8482	 pickout: 0.2585	 decision: 0.2849	 get_bound: 1.0778	 add_domain: 0.2270
Current lb:-0.06774526089429855
457082 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 527.978761434555

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 71] [3, 25] [2, 82] [3, 17] [2, 82] [4, 71] [1, 54] [3, 19] [2, 69] [2, 69] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -11.911437034606934 with beta sum per layer: [843.76123046875, 2373.953125, 1975.8397216796875, 1798.2080078125, 2163.672607421875]
alpha/beta optimization time: 0.3884260654449463
This batch time : update_bounds func: 1.0761	 prepare: 0.4055	 bound: 0.3889	 transfer: 0.0120	 finalize: 0.2604
Accumulated time: update_bounds func: 287.0447	 prepare: 85.5873	 bound: 89.9444	 transfer: 0.0120	 finalize: 102.0813
batch bounding time:  1.0788488388061523
Current worst splitting domains [lb, ub] (depth):
[-0.06725,   inf] (109), [-0.06725,   inf] (39), [-0.06725,   inf] (31), [-0.06725,   inf] (123), [-0.06725,   inf] (121), [-0.06725,   inf] (97), [-0.06725,   inf] (131), [-0.06725,   inf] (79), [-0.06725,   inf] (119), [-0.06724,   inf] (71), [-0.06724,   inf] (87), [-0.06724,   inf] (101), [-0.06724,   inf] (123), [-0.06724,   inf] (111), [-0.06724,   inf] (101), [-0.06724,   inf] (121), [-0.06724,   inf] (119), [-0.06724,   inf] (93), [-0.06724,   inf] (87), [-0.06724,   inf] (123), 
length of domains: 85676
Total time: 1.8579	 pickout: 0.2603	 decision: 0.2882	 get_bound: 1.0833	 add_domain: 0.2260
Current lb:-0.06724858283996582
459130 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 529.914715051651

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [4, 20] [0, 98] [0, 72] [4, 98] [1, 14] [2, 60] [2, 40] [2, 22] [2, 22] [1, 54] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -12.979796409606934 with beta sum per layer: [844.4053955078125, 2300.251220703125, 1992.2130126953125, 1747.16845703125, 2109.365966796875]
alpha/beta optimization time: 0.38913965225219727
This batch time : update_bounds func: 1.0744	 prepare: 0.4076	 bound: 0.3896	 transfer: 0.0121	 finalize: 0.2560
Accumulated time: update_bounds func: 288.1191	 prepare: 85.9949	 bound: 90.3340	 transfer: 0.0121	 finalize: 102.3373
batch bounding time:  1.0770914554595947
Current worst splitting domains [lb, ub] (depth):
[-0.06678,   inf] (47), [-0.06673,   inf] (125), [-0.06673,   inf] (119), [-0.06673,   inf] (69), [-0.06673,   inf] (89), [-0.06673,   inf] (71), [-0.06673,   inf] (99), [-0.06673,   inf] (137), [-0.06673,   inf] (107), [-0.06673,   inf] (133), [-0.06673,   inf] (81), [-0.06673,   inf] (81), [-0.06673,   inf] (133), [-0.06673,   inf] (131), [-0.06673,   inf] (151), [-0.06673,   inf] (127), [-0.06673,   inf] (67), [-0.06672,   inf] (99), [-0.06672,   inf] (95), [-0.06672,   inf] (105), 
length of domains: 85609
Total time: 1.8538	 pickout: 0.2620	 decision: 0.2911	 get_bound: 1.0816	 add_domain: 0.2191
Current lb:-0.06677615642547607
461178 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 531.8458700180054

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 21] [2, 59] [2, 59] [3, 98] [1, 51] [2, 7] [0, 88] [3, 10] [2, 82] [3, 78] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -16.32071304321289 with beta sum per layer: [851.3059692382812, 2322.265625, 1993.87158203125, 1606.772216796875, 2047.0751953125]
alpha/beta optimization time: 0.39084577560424805
This batch time : update_bounds func: 1.0804	 prepare: 0.4130	 bound: 0.3914	 transfer: 0.0122	 finalize: 0.2547
Accumulated time: update_bounds func: 289.1995	 prepare: 86.4080	 bound: 90.7254	 transfer: 0.0122	 finalize: 102.5920
batch bounding time:  1.0831358432769775
Current worst splitting domains [lb, ub] (depth):
[-0.06623,   inf] (87), [-0.06623,   inf] (83), [-0.06623,   inf] (65), [-0.06623,   inf] (103), [-0.06623,   inf] (167), [-0.06623,   inf] (81), [-0.06623,   inf] (91), [-0.06623,   inf] (91), [-0.06623,   inf] (121), [-0.06623,   inf] (115), [-0.06623,   inf] (55), [-0.06623,   inf] (97), [-0.06623,   inf] (59), [-0.06622,   inf] (95), [-0.06622,   inf] (79), [-0.06622,   inf] (113), [-0.06622,   inf] (111), [-0.06622,   inf] (85), [-0.06622,   inf] (93), [-0.06622,   inf] (117), 
length of domains: 85566
Total time: 1.8530	 pickout: 0.2550	 decision: 0.2824	 get_bound: 1.0874	 add_domain: 0.2282
Current lb:-0.0662328451871872
463226 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 533.7865748405457

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 86] [2, 63] [0, 21] [2, 82] [2, 29] [2, 82] [1, 95] [0, 89] [0, 89] [2, 7] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -19.57061195373535 with beta sum per layer: [839.202880859375, 2527.898681640625, 1988.908203125, 1803.87451171875, 2055.122314453125]
alpha/beta optimization time: 0.39038729667663574
This batch time : update_bounds func: 1.0884	 prepare: 0.4157	 bound: 0.3909	 transfer: 0.0121	 finalize: 0.2606
Accumulated time: update_bounds func: 290.2879	 prepare: 86.8237	 bound: 91.1163	 transfer: 0.0121	 finalize: 102.8526
batch bounding time:  1.0910723209381104
Current worst splitting domains [lb, ub] (depth):
[-0.06617,   inf] (37), [-0.06605,   inf] (37), [-0.06575,   inf] (109), [-0.06575,   inf] (77), [-0.06574,   inf] (129), [-0.06574,   inf] (97), [-0.06574,   inf] (141), [-0.06574,   inf] (81), [-0.06574,   inf] (57), [-0.06574,   inf] (89), [-0.06574,   inf] (59), [-0.06574,   inf] (61), [-0.06574,   inf] (113), [-0.06574,   inf] (93), [-0.06574,   inf] (79), [-0.06574,   inf] (127), [-0.06574,   inf] (115), [-0.06574,   inf] (105), [-0.06574,   inf] (75), [-0.06574,   inf] (97), 
length of domains: 85515
Total time: 1.8761	 pickout: 0.2626	 decision: 0.2888	 get_bound: 1.0955	 add_domain: 0.2292
Current lb:-0.06616955995559692
465274 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 535.740739107132

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 66] [2, 66] [0, 32] [2, 7] [3, 78] [2, 53] [1, 70] [3, 90] [3, 19] [0, 30] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -19.398488998413086 with beta sum per layer: [780.0089111328125, 2315.7861328125, 2059.833740234375, 1698.281982421875, 2118.403564453125]
alpha/beta optimization time: 0.390993595123291
This batch time : update_bounds func: 1.0800	 prepare: 0.4091	 bound: 0.3915	 transfer: 0.0121	 finalize: 0.2580
Accumulated time: update_bounds func: 291.3679	 prepare: 87.2328	 bound: 91.5078	 transfer: 0.0121	 finalize: 103.1106
batch bounding time:  1.0826921463012695
Current worst splitting domains [lb, ub] (depth):
[-0.06528,   inf] (75), [-0.06528,   inf] (81), [-0.06528,   inf] (111), [-0.06528,   inf] (115), [-0.06528,   inf] (97), [-0.06528,   inf] (125), [-0.06528,   inf] (97), [-0.06528,   inf] (129), [-0.06528,   inf] (111), [-0.06528,   inf] (81), [-0.06528,   inf] (107), [-0.06528,   inf] (105), [-0.06528,   inf] (65), [-0.06527,   inf] (79), [-0.06527,   inf] (103), [-0.06527,   inf] (89), [-0.06527,   inf] (75), [-0.06527,   inf] (143), [-0.06527,   inf] (145), [-0.06527,   inf] (79), 
length of domains: 85464
Total time: 1.8684	 pickout: 0.2611	 decision: 0.2908	 get_bound: 1.0871	 add_domain: 0.2294
Current lb:-0.06528378278017044
467322 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 537.6883723735809

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 17] [0, 98] [4, 67] [4, 71] [4, 67] [2, 7] [4, 67] [0, 13] [2, 82] [4, 50] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -14.681386947631836 with beta sum per layer: [896.0852661132812, 2427.10791015625, 2030.49462890625, 1688.557373046875, 1915.735595703125]
alpha/beta optimization time: 0.39162397384643555
This batch time : update_bounds func: 4.9823	 prepare: 0.4091	 bound: 0.3921	 transfer: 0.0122	 finalize: 4.1598
Accumulated time: update_bounds func: 296.3502	 prepare: 87.6418	 bound: 91.8999	 transfer: 0.0122	 finalize: 107.2704
batch bounding time:  4.98498797416687
Current worst splitting domains [lb, ub] (depth):
[-0.06524,   inf] (83), [-0.06480,   inf] (65), [-0.06479,   inf] (105), [-0.06479,   inf] (119), [-0.06479,   inf] (139), [-0.06479,   inf] (143), [-0.06479,   inf] (77), [-0.06479,   inf] (87), [-0.06479,   inf] (105), [-0.06479,   inf] (115), [-0.06479,   inf] (121), [-0.06479,   inf] (139), [-0.06479,   inf] (135), [-0.06479,   inf] (95), [-0.06479,   inf] (127), [-0.06479,   inf] (109), [-0.06479,   inf] (57), [-0.06479,   inf] (87), [-0.06479,   inf] (89), [-0.06479,   inf] (75), 
length of domains: 85423
Total time: 5.7729	 pickout: 0.2604	 decision: 0.2945	 get_bound: 4.9894	 add_domain: 0.2286
Current lb:-0.0652393326163292
469370 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 543.5383763313293

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [0, 25] [4, 43] [2, 82] [2, 40] [1, 14] [2, 96] [1, 80] [1, 70] [2, 63] [4, 98] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -22.06262969970703 with beta sum per layer: [844.2804565429688, 2368.120849609375, 1985.7647705078125, 1799.866943359375, 2106.5068359375]
alpha/beta optimization time: 0.38713574409484863
This batch time : update_bounds func: 1.0718	 prepare: 0.4062	 bound: 0.3876	 transfer: 0.0123	 finalize: 0.2559
Accumulated time: update_bounds func: 297.4220	 prepare: 88.0480	 bound: 92.2875	 transfer: 0.0123	 finalize: 107.5263
batch bounding time:  1.074315071105957
Current worst splitting domains [lb, ub] (depth):
[-0.06432,   inf] (81), [-0.06432,   inf] (71), [-0.06432,   inf] (65), [-0.06432,   inf] (113), [-0.06432,   inf] (105), [-0.06432,   inf] (71), [-0.06432,   inf] (119), [-0.06432,   inf] (97), [-0.06432,   inf] (85), [-0.06432,   inf] (111), [-0.06432,   inf] (101), [-0.06432,   inf] (107), [-0.06432,   inf] (113), [-0.06432,   inf] (97), [-0.06431,   inf] (121), [-0.06431,   inf] (109), [-0.06431,   inf] (103), [-0.06431,   inf] (57), [-0.06431,   inf] (109), [-0.06431,   inf] (87), 
length of domains: 85362
Total time: 1.8627	 pickout: 0.2543	 decision: 0.3054	 get_bound: 1.0787	 add_domain: 0.2243
Current lb:-0.06432050466537476
471418 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 545.4779417514801

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 93] [0, 25] [2, 40] [1, 49] [0, 36] [3, 86] [0, 36] [1, 49] [0, 29] [2, 79] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -24.066749572753906 with beta sum per layer: [823.4888305664062, 2418.681640625, 1969.329345703125, 1800.1097412109375, 2036.962890625]
alpha/beta optimization time: 0.3854949474334717
This batch time : update_bounds func: 1.0562	 prepare: 0.3968	 bound: 0.3860	 transfer: 0.0125	 finalize: 0.2517
Accumulated time: update_bounds func: 298.4782	 prepare: 88.4448	 bound: 92.6735	 transfer: 0.0125	 finalize: 107.7780
batch bounding time:  1.058701992034912
Current worst splitting domains [lb, ub] (depth):
[-0.06381,   inf] (53), [-0.06381,   inf] (105), [-0.06381,   inf] (149), [-0.06381,   inf] (131), [-0.06381,   inf] (57), [-0.06381,   inf] (147), [-0.06380,   inf] (139), [-0.06380,   inf] (115), [-0.06380,   inf] (101), [-0.06380,   inf] (95), [-0.06380,   inf] (85), [-0.06380,   inf] (139), [-0.06380,   inf] (97), [-0.06380,   inf] (89), [-0.06380,   inf] (141), [-0.06380,   inf] (93), [-0.06380,   inf] (127), [-0.06380,   inf] (99), [-0.06380,   inf] (131), [-0.06380,   inf] (125), 
length of domains: 85301
Total time: 1.8235	 pickout: 0.2544	 decision: 0.2818	 get_bound: 1.0629	 add_domain: 0.2243
Current lb:-0.0638093575835228
473466 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 547.3774635791779

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 17] [4, 68] [3, 0] [3, 0] [3, 21] [1, 14] [3, 37] [4, 20] [2, 59] [3, 17] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -25.821680068969727 with beta sum per layer: [864.5128173828125, 2329.953125, 1973.5728759765625, 1742.36767578125, 1982.598876953125]
alpha/beta optimization time: 0.38341379165649414
This batch time : update_bounds func: 1.0500	 prepare: 0.3951	 bound: 0.3839	 transfer: 0.0118	 finalize: 0.2501
Accumulated time: update_bounds func: 299.5281	 prepare: 88.8399	 bound: 93.0574	 transfer: 0.0118	 finalize: 108.0281
batch bounding time:  1.052541732788086
Current worst splitting domains [lb, ub] (depth):
[-0.06333,   inf] (105), [-0.06333,   inf] (125), [-0.06333,   inf] (131), [-0.06332,   inf] (135), [-0.06332,   inf] (141), [-0.06332,   inf] (109), [-0.06332,   inf] (89), [-0.06332,   inf] (135), [-0.06332,   inf] (57), [-0.06332,   inf] (119), [-0.06332,   inf] (67), [-0.06332,   inf] (119), [-0.06332,   inf] (69), [-0.06332,   inf] (81), [-0.06332,   inf] (45), [-0.06332,   inf] (65), [-0.06332,   inf] (91), [-0.06332,   inf] (127), [-0.06331,   inf] (71), [-0.06331,   inf] (123), 
length of domains: 85270
Total time: 1.8234	 pickout: 0.2541	 decision: 0.2801	 get_bound: 1.0569	 add_domain: 0.2324
Current lb:-0.06332533061504364
475514 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 549.2764177322388

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 7] [3, 84] [3, 78] [3, 37] [3, 0] [2, 59] [1, 63] [3, 37] [0, 21] [1, 7] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -20.409053802490234 with beta sum per layer: [832.500244140625, 2302.73779296875, 2017.1064453125, 1825.9761962890625, 2045.982177734375]
alpha/beta optimization time: 0.3840353488922119
This batch time : update_bounds func: 1.0558	 prepare: 0.3987	 bound: 0.3845	 transfer: 0.0120	 finalize: 0.2516
Accumulated time: update_bounds func: 300.5840	 prepare: 89.2386	 bound: 93.4420	 transfer: 0.0120	 finalize: 108.2797
batch bounding time:  1.0584073066711426
Current worst splitting domains [lb, ub] (depth):
[-0.06283,   inf] (105), [-0.06283,   inf] (59), [-0.06283,   inf] (97), [-0.06282,   inf] (123), [-0.06282,   inf] (115), [-0.06282,   inf] (85), [-0.06282,   inf] (129), [-0.06282,   inf] (111), [-0.06282,   inf] (79), [-0.06282,   inf] (89), [-0.06282,   inf] (105), [-0.06282,   inf] (75), [-0.06282,   inf] (91), [-0.06282,   inf] (97), [-0.06282,   inf] (75), [-0.06282,   inf] (97), [-0.06282,   inf] (71), [-0.06282,   inf] (141), [-0.06282,   inf] (131), [-0.06282,   inf] (123), 
length of domains: 85185
Total time: 1.8176	 pickout: 0.2555	 decision: 0.2799	 get_bound: 1.0626	 add_domain: 0.2197
Current lb:-0.06282605230808258
477562 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 551.1697657108307

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [1, 68] [3, 4] [2, 82] [4, 92] [4, 20] [4, 0] [3, 78] [1, 52] [2, 44] [1, 7] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -16.82585906982422 with beta sum per layer: [829.0546875, 2491.71484375, 1975.2596435546875, 1760.7850341796875, 1894.908447265625]
alpha/beta optimization time: 0.38271188735961914
This batch time : update_bounds func: 1.0430	 prepare: 0.3896	 bound: 0.3832	 transfer: 0.0122	 finalize: 0.2492
Accumulated time: update_bounds func: 301.6270	 prepare: 89.6282	 bound: 93.8252	 transfer: 0.0122	 finalize: 108.5289
batch bounding time:  1.0457005500793457
Current worst splitting domains [lb, ub] (depth):
[-0.06233,   inf] (131), [-0.06233,   inf] (121), [-0.06233,   inf] (113), [-0.06233,   inf] (37), [-0.06233,   inf] (87), [-0.06233,   inf] (119), [-0.06233,   inf] (137), [-0.06233,   inf] (45), [-0.06233,   inf] (69), [-0.06233,   inf] (99), [-0.06233,   inf] (85), [-0.06232,   inf] (137), [-0.06232,   inf] (143), [-0.06232,   inf] (145), [-0.06232,   inf] (119), [-0.06232,   inf] (95), [-0.06232,   inf] (79), [-0.06232,   inf] (105), [-0.06232,   inf] (93), [-0.06232,   inf] (73), 
length of domains: 85145
Total time: 1.8099	 pickout: 0.2551	 decision: 0.2763	 get_bound: 1.0501	 add_domain: 0.2284
Current lb:-0.06233016401529312
479610 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 553.0556013584137

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [3, 78] [3, 38] [1, 7] [2, 99] [2, 60] [2, 53] [4, 20] [0, 89] [2, 93] [0, 88] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -23.833059310913086 with beta sum per layer: [865.0222778320312, 2249.893798828125, 2059.40087890625, 1786.4755859375, 2219.275146484375]
alpha/beta optimization time: 0.38481903076171875
This batch time : update_bounds func: 1.0869	 prepare: 0.4100	 bound: 0.3853	 transfer: 0.0181	 finalize: 0.2646
Accumulated time: update_bounds func: 302.7139	 prepare: 90.0382	 bound: 94.2105	 transfer: 0.0181	 finalize: 108.7935
batch bounding time:  1.0896103382110596
Current worst splitting domains [lb, ub] (depth):
[-0.06184,   inf] (123), [-0.06184,   inf] (133), [-0.06184,   inf] (59), [-0.06184,   inf] (105), [-0.06184,   inf] (79), [-0.06184,   inf] (71), [-0.06184,   inf] (149), [-0.06184,   inf] (51), [-0.06184,   inf] (63), [-0.06184,   inf] (103), [-0.06184,   inf] (105), [-0.06184,   inf] (141), [-0.06183,   inf] (111), [-0.06183,   inf] (59), [-0.06183,   inf] (39), [-0.06183,   inf] (71), [-0.06183,   inf] (115), [-0.06183,   inf] (83), [-0.06183,   inf] (111), [-0.06183,   inf] (39), 
length of domains: 85046
Total time: 1.8638	 pickout: 0.2566	 decision: 0.2937	 get_bound: 1.0940	 add_domain: 0.2194
Current lb:-0.0618380643427372
481658 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 554.9965074062347

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 100]) pre split depth:  1
batch:  torch.Size([1024, 100]) post split depth:  1
splitting decisions: 
split level 0: [2, 40] [0, 13] [2, 63] [4, 71] [3, 98] [3, 98] [3, 25] [2, 59] [2, 66] [2, 7] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -20.567668914794922 with beta sum per layer: [840.8648681640625, 2360.4453125, 1972.32861328125, 1738.6571044921875, 1987.60009765625]
alpha/beta optimization time: 0.3955070972442627
This batch time : update_bounds func: 4.9361	 prepare: 0.4216	 bound: 0.3960	 transfer: 0.0131	 finalize: 4.0962
Accumulated time: update_bounds func: 307.6500	 prepare: 90.4598	 bound: 94.6065	 transfer: 0.0131	 finalize: 112.8897
batch bounding time:  4.93871808052063
Current worst splitting domains [lb, ub] (depth):
[-0.06135,   inf] (149), [-0.06135,   inf] (143), [-0.06135,   inf] (109), [-0.06135,   inf] (143), [-0.06135,   inf] (85), [-0.06135,   inf] (123), [-0.06135,   inf] (131), [-0.06135,   inf] (121), [-0.06134,   inf] (133), [-0.06134,   inf] (107), [-0.06134,   inf] (121), [-0.06134,   inf] (71), [-0.06134,   inf] (51), [-0.06134,   inf] (151), [-0.06134,   inf] (99), [-0.06134,   inf] (115), [-0.06134,   inf] (105), [-0.06134,   inf] (133), [-0.06134,   inf] (109), [-0.06134,   inf] (105), 
length of domains: 84980
Total time: 5.7162	 pickout: 0.2584	 decision: 0.2876	 get_bound: 4.9431	 add_domain: 0.2270
Current lb:-0.061347007751464844
483706 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Time out!!!!!!!!
Image 20 label 7 verification end, final lower bound -0.061347007751464844, upper bound inf, time: 564.5524761676788
20 -0.061347007751464844
Result: image 20 verification failure (with branch and bound).
Wall time: 904.515631198883

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 0): []
verification failure idx (total 1): [20]
final verified acc: 0.0%[1]
verifier is called on 1 examples.
total verified: 0
mean time [cnt:1] (excluding attack success): 904.2231385707855
