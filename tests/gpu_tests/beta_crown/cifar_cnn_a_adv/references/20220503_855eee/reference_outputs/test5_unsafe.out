Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_cnn_a_adv.model
  name: cnn_4layer_adv
data:
  start: 18
  end: 19
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR_SDP
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.00784313725
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 4096
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 30
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 20:52:16 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Flatten()
  (5): Linear(in_features=2048, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([200, 3, 32, 32]) torch.Size([200]) torch.Size([200])
X range: tensor(2.1256) tensor(-1.9889) tensor(-0.0131)
############################
epsilon after preprocessing: tensor([[[[0.0317]],

         [[0.0322]],

         [[0.0300]]]]), data_max = tensor([[[[2.0587]],

         [[2.1256]],

         [[2.1154]]]]), data_min = tensor([[[[-1.9889]],

         [[-1.9807]],

         [[-1.7076]]]])
Task length: 1
saving results to Verified_ret_[cnn_4layer_adv]_start=18_end=19_iter=20_b=4096_timeout=30_branching=kfsb-max-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 18 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 6, correct label 6, image norm 1670.1436767578125, logits tensor([-13.9768, -17.0807,  -8.9228, -11.5371,  -9.3435, -11.1954,  -8.1218,
        -11.5838, -17.6023, -15.8377], device='cuda:0',
       grad_fn=<SelectBackward>)
Model prediction is: tensor([[-13.9768, -17.0807,  -8.9228, -11.5371,  -9.3435, -11.1954,  -8.1218,
         -11.5838, -17.6023, -15.8377]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 3.6381,  6.8016, -0.7569,  2.1704, -0.2997,  1.5982,  1.6551,  7.4160,
          5.9109]], device='cuda:0') None
best_l after optimization: -28.800373077392578 with beta sum per layer: []
alpha/beta optimization time: 7.859165191650391
initial alpha-CROWN bounds: tensor([[ 3.7405,  6.9067, -0.6845,  2.2105, -0.2403,  1.6439,  1.7164,  7.5099,
          5.9974]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.6845, device='cuda:0', grad_fn=<MinBackward1>)
##### [0:18] Tested against 2 ######
Model prediction is: tensor([[-13.9768, -17.0807,  -8.9228, -11.5371,  -9.3435, -11.1954,  -8.1218,
         -11.5838, -17.6023, -15.8377]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 16, 16]) != torch.Size([2, 9, 1, 16, 16, 16]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 8, 8]) != torch.Size([2, 9, 1, 32, 8, 8]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 16, 16])
1 /11 torch.Size([1, 32, 8, 8])
2 /21 torch.Size([1, 100])
best_l after optimization: 0.6844472885131836 with beta sum per layer: []
alpha/beta optimization time: 2.159672975540161
alpha-CROWN with fixed intermediate bounds: tensor([[-0.6844]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.6844472885131836
layer 0 size torch.Size([4096]) unstable 512
layer 1 size torch.Size([2048]) unstable 255
layer 2 size torch.Size([100]) unstable 20
-----------------
# of unstable neurons: 787
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 16, 16]) pre split depth:  8
batch:  torch.Size([1, 16, 16, 16]) post split depth:  8
splitting decisions: 
split level 0: [2, 1] 
split level 1: [2, 38] 
split level 2: [2, 11] 
split level 3: [2, 51] 
split level 4: [2, 6] 
split level 5: [2, 17] 
split level 6: [2, 29] 
split level 7: [2, 92] 
regular batch size: 2*128, diving batch size 1*0
best_l after optimization: -69.40550231933594 with beta sum per layer: [0.0, 0.0, 18.428388595581055]
alpha/beta optimization time: 0.341508150100708
This batch time : update_bounds func: 0.3883	 prepare: 0.0192	 bound: 0.3418	 transfer: 0.0108	 finalize: 0.0157
Accumulated time: update_bounds func: 0.3883	 prepare: 0.0192	 bound: 0.3418	 transfer: 0.0108	 finalize: 0.0157
batch bounding time:  0.38866090774536133
Current worst splitting domains [lb, ub] (depth):
[-0.32349,   inf] (9), [-0.26626,   inf] (9), [-0.25140,   inf] (9), [-0.19722,   inf] (9), [-0.16159,   inf] (9), [-0.09539,   inf] (9), [-0.08861,   inf] (9), [-0.03190,   inf] (9), [-0.00769,   inf] (9), 
length of domains: 9
Total time: 0.6905	 pickout: 0.0010	 decision: 0.2674	 get_bound: 0.4213	 add_domain: 0.0008
Current lb:-0.32349079847335815
256 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.723646879196167

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([9, 16, 16, 16]) pre split depth:  5
batch:  torch.Size([9, 16, 16, 16]) post split depth:  5
splitting decisions: 
split level 0: [2, 68] [2, 68] [2, 68] [2, 68] [2, 68] [2, 68] [2, 68] [2, 68] [2, 68] 
split level 1: [1, 98] [1, 484] [1, 98] [2, 33] [1, 98] [1, 1363] [1, 98] [1, 1363] [1, 484] 
split level 2: [2, 33] [1, 476] [2, 33] [1, 484] [1, 1363] [1, 476] [1, 1363] [1, 476] [1, 476] 
split level 3: [1, 484] [1, 689] [1, 484] [1, 103] [1, 476] [1, 612] [1, 476] [1, 1114] [1, 1067] 
split level 4: [1, 476] [1, 612] [1, 476] [1, 612] [1, 1373] [1, 1373] [1, 1373] [1, 1373] [1, 1076] 
regular batch size: 2*144, diving batch size 1*0
best_l after optimization: -3.0807652473449707 with beta sum per layer: [0.0, 67.356201171875, 55.635902404785156]
alpha/beta optimization time: 0.3108499050140381
This batch time : update_bounds func: 0.3697	 prepare: 0.0269	 bound: 0.3112	 transfer: 0.0137	 finalize: 0.0171
Accumulated time: update_bounds func: 0.7579	 prepare: 0.0461	 bound: 0.6530	 transfer: 0.0137	 finalize: 0.0328
batch bounding time:  0.3701326847076416
Current worst splitting domains [lb, ub] (depth):
[-0.28291,   inf] (15), [-0.27746,   inf] (15), [-0.27378,   inf] (15), [-0.25623,   inf] (15), [-0.21911,   inf] (15), [-0.21383,   inf] (15), [-0.21350,   inf] (15), [-0.21169,   inf] (15), [-0.21148,   inf] (15), [-0.20997,   inf] (15), [-0.20923,   inf] (15), [-0.20759,   inf] (15), [-0.20653,   inf] (15), [-0.20641,   inf] (15), [-0.20607,   inf] (15), [-0.20588,   inf] (15), [-0.20265,   inf] (15), [-0.20188,   inf] (15), [-0.20076,   inf] (15), [-0.19891,   inf] (15), 
length of domains: 106
Total time: 0.4526	 pickout: 0.0022	 decision: 0.0371	 get_bound: 0.4071	 add_domain: 0.0062
Current lb:-0.28291448950767517
544 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.177296161651611

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([106, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([106, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1363] [1, 1363] [1, 1363] [1, 1363] [2, 33] [2, 33] [2, 33] [2, 33] [1, 1363] [1, 1363] 
regular batch size: 2*106, diving batch size 1*0
best_l after optimization: 14.195276260375977 with beta sum per layer: [0.0, 95.64456939697266, 29.47366714477539]
alpha/beta optimization time: 0.285571813583374
This batch time : update_bounds func: 0.3265	 prepare: 0.0234	 bound: 0.2859	 transfer: 0.0030	 finalize: 0.0137
Accumulated time: update_bounds func: 1.0845	 prepare: 0.0696	 bound: 0.9389	 transfer: 0.0030	 finalize: 0.0464
batch bounding time:  0.3268871307373047
Current worst splitting domains [lb, ub] (depth):
[-0.27701,   inf] (17), [-0.27171,   inf] (17), [-0.26781,   inf] (17), [-0.26707,   inf] (17), [-0.25957,   inf] (17), [-0.25779,   inf] (17), [-0.25032,   inf] (17), [-0.23675,   inf] (17), [-0.21261,   inf] (17), [-0.20725,   inf] (17), [-0.20689,   inf] (17), [-0.20494,   inf] (17), [-0.20488,   inf] (17), [-0.20310,   inf] (17), [-0.20265,   inf] (17), [-0.20158,   inf] (17), [-0.19991,   inf] (17), [-0.19962,   inf] (17), [-0.19947,   inf] (17), [-0.19929,   inf] (17), 
length of domains: 176
Total time: 0.4063	 pickout: 0.0175	 decision: 0.0504	 get_bound: 0.3272	 add_domain: 0.0112
Current lb:-0.2770131826400757
756 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.5853283405303955

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([176, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([176, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 612] [1, 612] [1, 612] [1, 612] [1, 612] [1, 612] [1, 612] [1, 612] [1, 103] [1, 103] 
regular batch size: 2*176, diving batch size 1*0
best_l after optimization: 24.89414405822754 with beta sum per layer: [0.0, 201.19024658203125, 46.713592529296875]
alpha/beta optimization time: 0.32692551612854004
This batch time : update_bounds func: 0.3920	 prepare: 0.0353	 bound: 0.3273	 transfer: 0.0066	 finalize: 0.0219
Accumulated time: update_bounds func: 1.4765	 prepare: 0.1049	 bound: 1.2662	 transfer: 0.0066	 finalize: 0.0684
batch bounding time:  0.39246392250061035
Current worst splitting domains [lb, ub] (depth):
[-0.27005,   inf] (19), [-0.26505,   inf] (19), [-0.26464,   inf] (19), [-0.26153,   inf] (19), [-0.25986,   inf] (19), [-0.25970,   inf] (19), [-0.25492,   inf] (19), [-0.25324,   inf] (19), [-0.25230,   inf] (19), [-0.25128,   inf] (19), [-0.24767,   inf] (19), [-0.24356,   inf] (19), [-0.24273,   inf] (19), [-0.23696,   inf] (19), [-0.22971,   inf] (19), [-0.22293,   inf] (19), [-0.20905,   inf] (19), [-0.20375,   inf] (19), [-0.20185,   inf] (19), [-0.20130,   inf] (19), 
length of domains: 295
Total time: 0.5103	 pickout: 0.0279	 decision: 0.0698	 get_bound: 0.3930	 add_domain: 0.0195
Current lb:-0.2700471580028534
1108 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.098705053329468

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([295, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([295, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 790] [1, 790] [1, 790] [1, 790] [1, 790] [1, 790] [1, 790] [1, 790] [1, 790] [1, 790] 
regular batch size: 2*295, diving batch size 1*0
best_l after optimization: 44.58173751831055 with beta sum per layer: [0.0, 415.14453125, 72.07563781738281]
alpha/beta optimization time: 0.42609596252441406
This batch time : update_bounds func: 0.6002	 prepare: 0.0577	 bound: 0.4264	 transfer: 0.0192	 finalize: 0.0954
Accumulated time: update_bounds func: 2.0767	 prepare: 0.1626	 bound: 1.6927	 transfer: 0.0192	 finalize: 0.1637
batch bounding time:  0.60085129737854
Current worst splitting domains [lb, ub] (depth):
[-0.26713,   inf] (21), [-0.26206,   inf] (21), [-0.26174,   inf] (21), [-0.25858,   inf] (21), [-0.25682,   inf] (21), [-0.25675,   inf] (21), [-0.25561,   inf] (21), [-0.25181,   inf] (21), [-0.25054,   inf] (21), [-0.25025,   inf] (21), [-0.25022,   inf] (21), [-0.24922,   inf] (21), [-0.24826,   inf] (21), [-0.24681,   inf] (21), [-0.24527,   inf] (21), [-0.24522,   inf] (21), [-0.24464,   inf] (21), [-0.24063,   inf] (21), [-0.24027,   inf] (21), [-0.23962,   inf] (21), 
length of domains: 481
Total time: 0.7855	 pickout: 0.0470	 decision: 0.1039	 get_bound: 0.6018	 add_domain: 0.0327
Current lb:-0.26712924242019653
1698 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.889240980148315

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([481, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([481, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1379] [1, 1379] [1, 1379] [1, 1379] [1, 1379] [1, 1379] [1, 1379] [1, 1379] [1, 1379] [1, 1114] 
regular batch size: 2*481, diving batch size 1*0
best_l after optimization: 70.19296264648438 with beta sum per layer: [0.0, 794.798095703125, 120.76315307617188]
alpha/beta optimization time: 0.5681829452514648
This batch time : update_bounds func: 0.7504	 prepare: 0.0944	 bound: 0.5685	 transfer: 0.0262	 finalize: 0.0572
Accumulated time: update_bounds func: 2.8271	 prepare: 0.2569	 bound: 2.2612	 transfer: 0.0262	 finalize: 0.2209
batch bounding time:  0.7513413429260254
Current worst splitting domains [lb, ub] (depth):
[-0.25946,   inf] (23), [-0.25825,   inf] (23), [-0.25414,   inf] (23), [-0.25378,   inf] (23), [-0.25372,   inf] (23), [-0.25269,   inf] (23), [-0.25040,   inf] (23), [-0.25016,   inf] (23), [-0.24920,   inf] (23), [-0.24918,   inf] (23), [-0.24793,   inf] (23), [-0.24784,   inf] (23), [-0.24782,   inf] (23), [-0.24663,   inf] (23), [-0.24351,   inf] (23), [-0.24349,   inf] (23), [-0.24311,   inf] (23), [-0.24251,   inf] (23), [-0.24216,   inf] (23), [-0.24209,   inf] (23), 
length of domains: 779
Total time: 1.0701	 pickout: 0.0784	 decision: 0.1840	 get_bound: 0.7528	 add_domain: 0.0549
Current lb:-0.25945907831192017
2660 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.967690467834473

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([779, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([779, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 475] [1, 475] [1, 475] [1, 475] [1, 475] [1, 475] [1, 475] [1, 475] [1, 475] [1, 475] 
regular batch size: 2*779, diving batch size 1*0
best_l after optimization: 136.381591796875 with beta sum per layer: [0.0, 1604.464599609375, 156.62631225585938]
alpha/beta optimization time: 0.8230657577514648
This batch time : update_bounds func: 1.1718	 prepare: 0.1493	 bound: 0.8234	 transfer: 0.0458	 finalize: 0.1494
Accumulated time: update_bounds func: 3.9989	 prepare: 0.4062	 bound: 3.0846	 transfer: 0.0458	 finalize: 0.3703
batch bounding time:  1.1732287406921387
Current worst splitting domains [lb, ub] (depth):
[-0.25329,   inf] (25), [-0.25205,   inf] (25), [-0.24938,   inf] (25), [-0.24856,   inf] (25), [-0.24848,   inf] (25), [-0.24770,   inf] (25), [-0.24767,   inf] (25), [-0.24730,   inf] (25)/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:462: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(preprocess_cifar(eps_temp, perturbation=True)).reshape(1,-1,1,1)
, [-0.24374,   inf] (25), [-0.24353,   inf] (25), [-0.24340,   inf] (25), [-0.24316,   inf] (25), [-0.24294,   inf] (25), [-0.24264,   inf] (25), [-0.24226,   inf] (25), [-0.24195,   inf] (25), [-0.24192,   inf] (25), [-0.24180,   inf] (25), [-0.24165,   inf] (25), [-0.24043,   inf] (25), 
length of domains: 1377
Total time: 1.6916	 pickout: 0.1267	 decision: 0.2882	 get_bound: 1.1757	 add_domain: 0.1011
Current lb:-0.25328996777534485
4218 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.672355890274048

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1377, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1377, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 525] [1, 525] [1, 525] [1, 525] [1, 525] [1, 525] [1, 525] [1, 525] [1, 525] [1, 525] 
regular batch size: 2*1377, diving batch size 1*0
best_l after optimization: 235.81922912597656 with beta sum per layer: [0.0, 3335.833740234375, 257.8973388671875]
alpha/beta optimization time: 1.342275619506836
This batch time : update_bounds func: 1.9285	 prepare: 0.2656	 bound: 1.3427	 transfer: 0.0815	 finalize: 0.2321
Accumulated time: update_bounds func: 5.9274	 prepare: 0.6718	 bound: 4.4273	 transfer: 0.0815	 finalize: 0.6024
batch bounding time:  1.9312458038330078
Current worst splitting domains [lb, ub] (depth):
[-0.24852,   inf] (27), [-0.24726,   inf] (27), [-0.24448,   inf] (27), [-0.24378,   inf] (27), [-0.24358,   inf] (27), [-0.24293,   inf] (27), [-0.24289,   inf] (27), [-0.24289,   inf] (27), [-0.24254,   inf] (27), [-0.24164,   inf] (27), [-0.23898,   inf] (27), [-0.23885,   inf] (27), [-0.23877,   inf] (27), [-0.23862,   inf] (27), [-0.23857,   inf] (27), [-0.23819,   inf] (27), [-0.23808,   inf] (27), [-0.23795,   inf] (27), [-0.23780,   inf] (27), [-0.23749,   inf] (27), 
length of domains: 2499
Total time: 2.8762	 pickout: 0.2519	 decision: 0.4961	 get_bound: 1.9358	 add_domain: 0.1924
Current lb:-0.2485164999961853
6972 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.572293043136597

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2499, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([2499, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 103] [1, 103] [1, 103] [1, 103] [1, 103] [1, 103] [1, 103] [1, 103] [1, 103] [1, 103] 
regular batch size: 2*2499, diving batch size 1*0
best_l after optimization: 429.56695556640625 with beta sum per layer: [0.0, 6958.9765625, 402.40728759765625]
alpha/beta optimization time: 2.396925210952759
This batch time : update_bounds func: 3.5312	 prepare: 0.5022	 bound: 2.3973	 transfer: 0.1715	 finalize: 0.3791
Accumulated time: update_bounds func: 9.4586	 prepare: 1.1740	 bound: 6.8247	 transfer: 0.1715	 finalize: 0.9815
batch bounding time:  3.536050796508789
Current worst splitting domains [lb, ub] (depth):
[-0.24657,   inf] (29), [-0.24531,   inf] (29), [-0.24253,   inf] (29), [-0.24184,   inf] (29), [-0.24157,   inf] (29), [-0.24099,   inf] (29), [-0.24095,   inf] (29), [-0.24091,   inf] (29), [-0.24059,   inf] (29), [-0.23965,   inf] (29), [-0.23703,   inf] (29), [-0.23687,   inf] (29), [-0.23680,   inf] (29), [-0.23666,   inf] (29), [-0.23662,   inf] (29), [-0.23616,   inf] (29), [-0.23616,   inf] (29), [-0.23590,   inf] (29), [-0.23587,   inf] (29), [-0.23557,   inf] (29), 
length of domains: 4659
Total time: 5.2960	 pickout: 0.4579	 decision: 0.9230	 get_bound: 3.5444	 add_domain: 0.3707
Current lb:-0.24657343327999115
11970 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.911560535430908

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4096, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([4096, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1307] [1, 1307] [1, 1307] [1, 1307] [1, 1307] [1, 1307] [1, 1307] [1, 1307] [1, 1307] [1, 1307] 
regular batch size: 2*4096, diving batch size 1*0
best_l after optimization: 740.0435791015625 with beta sum per layer: [0.0, 12995.880859375, 467.6357116699219]
alpha/beta optimization time: 3.8242454528808594
This batch time : update_bounds func: 5.8098	 prepare: 0.8161	 bound: 3.8247	 transfer: 0.2780	 finalize: 0.7684
Accumulated time: update_bounds func: 15.2684	 prepare: 1.9901	 bound: 10.6493	 transfer: 0.2780	 finalize: 1.7499
batch bounding time:  5.818751096725464
Current worst splitting domains [lb, ub] (depth):
[-0.24192,   inf] (31), [-0.24067,   inf] (31), [-0.23820,   inf] (31), [-0.23725,   inf] (31), [-0.23719,   inf] (31), [-0.23626,   inf] (31), [-0.23625,   inf] (31), [-0.23625,   inf] (31), [-0.23586,   inf] (31), [-0.23501,   inf] (31), [-0.23269,   inf] (31), [-0.23254,   inf] (31), [-0.23226,   inf] (31), [-0.23210,   inf] (31), [-0.23204,   inf] (31), [-0.23159,   inf] (31), [-0.23152,   inf] (31), [-0.23151,   inf] (31), [-0.23128,   inf] (31), [-0.23086,   inf] (31), 
length of domains: 8465
Total time: 8.9605	 pickout: 0.7308	 decision: 1.5629	 get_bound: 5.8344	 add_domain: 0.8323
Current lb:-0.24191835522651672
20162 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Time out!!!!!!!!
Image 18 label 2 verification end, final lower bound -0.24191835522651672, upper bound inf, time: 26.118526935577393
18 -0.24191835522651672
Result: image 18 verification failure (with branch and bound).
Wall time: 35.92282295227051

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 0): []
verification failure idx (total 1): [18]
final verified acc: 0.0%[1]
verifier is called on 1 examples.
total verified: 0
mean time [cnt:1] (excluding attack success): 35.864476919174194
