Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_cnn_a_adv.model
  name: cnn_4layer_adv
data:
  start: 42
  end: 43
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR_SDP
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.00784313725
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 4096
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 90
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 20:50:17 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Flatten()
  (5): Linear(in_features=2048, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([200, 3, 32, 32]) torch.Size([200]) torch.Size([200])
X range: tensor(2.1256) tensor(-1.9889) tensor(-0.0131)
############################
epsilon after preprocessing: tensor([[[[0.0317]],

         [[0.0322]],

         [[0.0300]]]]), data_max = tensor([[[[2.0587]],

         [[2.1256]],

         [[2.1154]]]]), data_min = tensor([[[[-1.9889]],

         [[-1.9807]],

         [[-1.7076]]]])
Task length: 1
saving results to Verified_ret_[cnn_4layer_adv]_start=42_end=43_iter=20_b=4096_timeout=90_branching=kfsb-max-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 42 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 6, correct label 6, image norm 2156.1474609375, logits tensor([-6.2352, -9.2286, -3.7581, -3.2744, -4.2941, -3.5855, -2.4106, -6.2941,
        -6.6657, -8.3439], device='cuda:0', grad_fn=<SelectBackward>)
##### PGD attack: True label: 6, Tested against: ['all'] ######
pgd prediction: tensor([-6.0195, -9.0708, -3.5289, -2.8235, -4.0369, -2.9852, -2.6246, -5.9173,
        -6.3029, -8.0928], device='cuda:0', grad_fn=<SqueezeBackward1>)
attack margin tensor([3.3950, 6.4462, 0.9043, 0.1989, 1.4123, 0.3606,    inf, 3.2927, 3.6783,
        5.4683], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[-6.2352, -9.2286, -3.7581, -3.2744, -4.2941, -3.5855, -2.4106, -6.2941,
         -6.6657, -8.3439]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 1.8762,  4.3069, -0.0665, -0.2615,  0.3073, -0.2485,  2.1300,  1.8816,
          3.7122]], device='cuda:0') None
best_l after optimization: -14.588364601135254 with beta sum per layer: []
alpha/beta optimization time: 7.940426588058472
initial alpha-CROWN bounds: tensor([[ 1.9810,  4.4628,  0.0185, -0.2162,  0.4013, -0.1846,  2.2260,  2.0315,
          3.8680]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.2162, device='cuda:0', grad_fn=<MinBackward1>)
Sorted order for labels to verify: [3, 5, 2, 4, 7, 0, 8, 9, 1, 6]
##### [0:42] Tested against 3 ######
Model prediction is: tensor([[-6.2352, -9.2286, -3.7581, -3.2744, -4.2941, -3.5855, -2.4106, -6.2941,
         -6.6657, -8.3439]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 16, 16]) != torch.Size([2, 9, 1, 16, 16, 16]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 8, 8]) != torch.Size([2, 9, 1, 32, 8, 8]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 16, 16])
1 /11 torch.Size([1, 32, 8, 8])
2 /21 torch.Size([1, 100])
best_l after optimization: 0.216081440448761 with beta sum per layer: []
alpha/beta optimization time: 2.123441457748413
alpha-CROWN with fixed intermediate bounds: tensor([[-0.2161]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.216081440448761
layer 0 size torch.Size([4096]) unstable 590
layer 1 size torch.Size([2048]) unstable 242
layer 2 size torch.Size([100]) unstable 21
-----------------
# of unstable neurons: 853
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 16, 16]) pre split depth:  8
batch:  torch.Size([1, 16, 16, 16]) post split depth:  8
splitting decisions: 
split level 0: [2, 33] 
split level 1: [2, 1] 
split level 2: [2, 11] 
split level 3: [2, 51] 
split level 4: [2, 41] 
split level 5: [2, 13] 
split level 6: [2, 45] 
split level 7: [2, 82] 
regular batch size: 2*128, diving batch size 1*0
best_l after optimization: -39.74478530883789 with beta sum per layer: [0.0, 0.0, 11.504568099975586]
alpha/beta optimization time: 0.28688931465148926
This batch time : update_bounds func: 0.3324	 prepare: 0.0185	 bound: 0.2872	 transfer: 0.0105	 finalize: 0.0154
Accumulated time: update_bounds func: 0.3324	 prepare: 0.0185	 bound: 0.2872	 transfer: 0.0105	 finalize: 0.0154
batch bounding time:  0.33277463912963867
Current worst splitting domains [lb, ub] (depth):
[-0.09091,   inf] (9), [-0.08867,   inf] (9), [-0.04890,   inf] (9), [-0.04779,   inf] (9), [-0.03342,   inf] (9), [-0.03117,   inf] (9), [-0.02867,   inf] (9), [-0.02408,   inf] (9), 
length of domains: 8
Total time: 0.6364	 pickout: 0.0009	 decision: 0.2686	 get_bound: 0.3664	 add_domain: 0.0005
Current lb:-0.09091146290302277
256 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.6133651733398438

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 16, 16]) pre split depth:  5
batch:  torch.Size([8, 16, 16, 16]) post split depth:  5
splitting decisions: 
split level 0: [1, 850] [1, 1308] [1, 1308] [1, 1308] [1, 850] [1, 850] [1, 1308] [1, 1308] 
split level 1: [1, 1308] [1, 1909] [1, 92] [1, 92] [1, 92] [1, 92] [1, 117] [1, 117] 
split level 2: [1, 1909] [1, 483] [1, 483] [1, 483] [1, 484] [1, 484] [1, 1909] [1, 92] 
split level 3: [1, 483] [1, 94] [1, 94] [1, 94] [1, 654] [1, 654] [1, 92] [1, 1909] 
split level 4: [1, 94] [1, 484] [1, 1468] [1, 1468] [1, 620] [1, 620] [1, 620] [1, 483] 
regular batch size: 2*128, diving batch size 1*0
best_l after optimization: 0.6778585910797119 with beta sum per layer: [0.0, 44.978755950927734, 11.710186004638672]
alpha/beta optimization time: 0.30080413818359375
This batch time : update_bounds func: 0.3520	 prepare: 0.0229	 bound: 0.3011	 transfer: 0.0126	 finalize: 0.0147
Accumulated time: update_bounds func: 0.6844	 prepare: 0.0413	 bound: 0.5883	 transfer: 0.0126	 finalize: 0.0301
batch bounding time:  0.35234498977661133
Current worst splitting domains [lb, ub] (depth):
[-0.06382,   inf] (15), [-0.06068,   inf] (15), [-0.06067,   inf] (15), [-0.05949,   inf] (15), [-0.05923,   inf] (15), [-0.05822,   inf] (15), [-0.05753,   inf] (15), [-0.05738,   inf] (15), [-0.05634,   inf] (15), [-0.05628,   inf] (15), [-0.05572,   inf] (15), [-0.05537,   inf] (15), [-0.05470,   inf] (15), [-0.05453,   inf] (15), [-0.05391,   inf] (15), [-0.05341,   inf] (15), [-0.05314,   inf] (15), [-0.05194,   inf] (15), [-0.05193,   inf] (15), [-0.05134,   inf] (15), 
length of domains: 88
Total time: 0.4295	 pickout: 0.0019	 decision: 0.0366	 get_bound: 0.3858	 add_domain: 0.0052
Current lb:-0.06381543725728989
512 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.0438244342803955

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([88, 16, 16, 16]) pre split depth:  2
batch:  torch.Size([88, 16, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [1, 92] [1, 92] [1, 92] [1, 92] [1, 850] [1, 850] [1, 92] [1, 850] [1, 92] [1, 92] 
split level 1: [1, 654] [1, 484] [1, 654] [1, 654] [1, 92] [1, 92] [1, 484] [1, 92] [1, 654] [1, 484] 
regular batch size: 2*176, diving batch size 1*0
best_l after optimization: 5.454900741577148 with beta sum per layer: [0.0, 216.23617553710938, 6.169247627258301]
alpha/beta optimization time: 0.3302309513092041
This batch time : update_bounds func: 0.3939	 prepare: 0.0333	 bound: 0.3306	 transfer: 0.0091	 finalize: 0.0199
Accumulated time: update_bounds func: 1.0783	 prepare: 0.0746	 bound: 0.9189	 transfer: 0.0091	 finalize: 0.0500
batch bounding time:  0.39431333541870117
Current worst splitting domains [lb, ub] (depth):
[-0.05317,   inf] (18), [-0.05237,   inf] (18), [-0.05089,   inf] (18), [-0.04977,   inf] (18), [-0.04955,   inf] (18), [-0.04896,   inf] (18), [-0.04873,   inf] (18), [-0.04857,   inf] (18), [-0.04778,   inf] (18), [-0.04760,   inf] (18), [-0.04750,   inf] (18), [-0.04616,   inf] (18), [-0.04588,   inf] (18), [-0.04587,   inf] (18), [-0.04566,   inf] (18), [-0.04517,   inf] (18), [-0.04506,   inf] (18), [-0.04498,   inf] (18), [-0.04436,   inf] (18), [-0.04386,   inf] (18), 
length of domains: 246
Total time: 0.5083	 pickout: 0.0141	 decision: 0.0585	 get_bound: 0.4200	 add_domain: 0.0157
Current lb:-0.05316859111189842
864 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.554165363311768

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([246, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([246, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 979] [1, 979] [1, 979] [1, 979] [1, 654] [1, 979] [1, 654] [1, 979] [1, 979] [1, 979] 
regular batch size: 2*246, diving batch size 1*0
best_l after optimization: 8.758367538452148 with beta sum per layer: [0.0, 356.9488830566406, 2.7503104209899902]
alpha/beta optimization time: 0.3816096782684326
This batch time : update_bounds func: 0.4724	 prepare: 0.0464	 bound: 0.3819	 transfer: 0.0149	 finalize: 0.0280
Accumulated time: update_bounds func: 1.5507	 prepare: 0.1210	 bound: 1.3009	 transfer: 0.0149	 finalize: 0.0780
batch bounding time:  0.47300028800964355
Current worst splitting domains [lb, ub] (depth):
[-0.04759,   inf] (20), [-0.04705,   inf] (20), [-0.04554,   inf] (20), [-0.04490,   inf] (20), [-0.04443,   inf] (20), [-0.04399,   inf] (20), [-0.04397,   inf] (20), [-0.04342,   inf] (20), [-0.04301,   inf] (20), [-0.04298,   inf] (20), [-0.04296,   inf] (20), [-0.04278,   inf] (20), [-0.04242,   inf] (20), [-0.04209,   inf] (20), [-0.04185,   inf] (20), [-0.04181,   inf] (20), [-0.04127,   inf] (20), [-0.04076,   inf] (20), [-0.04072,   inf] (20), [-0.04064,   inf] (20), 
length of domains: 429
Total time: 0.6306	 pickout: 0.0366	 decision: 0.0906	 get_bound: 0.4738	 add_domain: 0.0296
Current lb:-0.04758945107460022
1356 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.18880033493042

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([429, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([429, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 475] [1, 484] [1, 654] [1, 484] [1, 484] [1, 475] [1, 475] [1, 475] [1, 475] [1, 475] 
regular batch size: 2*429, diving batch size 1*0
best_l after optimization: 12.140600204467773 with beta sum per layer: [0.0, 583.2969970703125, 3.798363447189331]
alpha/beta optimization time: 0.5496227741241455
This batch time : update_bounds func: 0.7089	 prepare: 0.0793	 bound: 0.5500	 transfer: 0.0280	 finalize: 0.0497
Accumulated time: update_bounds func: 2.2596	 prepare: 0.2003	 bound: 1.8508	 transfer: 0.0280	 finalize: 0.1277
batch bounding time:  0.7097949981689453
Current worst splitting domains [lb, ub] (depth):
[-0.04173,   inf] (22), [-0.04113,   inf] (22), [-0.04080,   inf] (22), [-0.04037,   inf] (22), [-0.03932,   inf] (22), [-0.03910,   inf] (22), [-0.03874,   inf] (22), [-0.03848,   inf] (22), [-0.03811,   inf] (22), [-0.03805,   inf] (22), [-0.03805,   inf] (22), [-0.03759,   inf] (22), [-0.03756,   inf] (22), [-0.03717,   inf] (22), [-0.03713,   inf] (22), [-0.03711,   inf] (22), [-0.03703,   inf] (22), [-0.03697,   inf] (22), [-0.03664,   inf] (22), [-0.03660,   inf] (22), 
length of domains: 760
Total time: 1.0213	 pickout: 0.0674	 decision: 0.1879	 get_bound: 0.7111	 add_domain: 0.0549
Current lb:-0.04172694683074951
2214 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.218606233596802

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([760, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([760, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 484] [1, 475] [1, 484] [1, 475] [1, 475] [1, 475] [1, 475] [1, 475] [1, 979] [1, 484] 
regular batch size: 2*760, diving batch size 1*0
best_l after optimization: 15.064620018005371 with beta sum per layer: [0.0, 950.4127807617188, 6.770162105560303]
alpha/beta optimization time: 0.8064248561859131
This batch time : update_bounds func: 1.0858	 prepare: 0.1423	 bound: 0.8068	 transfer: 0.0446	 finalize: 0.0884
Accumulated time: update_bounds func: 3.3454	 prepare: 0.3426	 bound: 2.6577	 transfer: 0.0446	 finalize: 0.2162
batch bounding time:  1.0871567726135254
Current worst splitting domains [lb, ub] (depth):
[-0.03594,   inf] (24), [-0.03549,   inf] (24), [-0.03518,   inf] (24), [-0.03513,   inf] (24), [-0.03474,   inf] (24), [-0.03472,   inf] (24), [-0.03401,   inf] (24), [-0.03360,   inf] (24), [-0.03311,   inf] (24), [-0.03301,   inf] (24), [-0.03287,   inf] (24), [-0.03284,   inf] (24), [-0.03278,   inf] (24), [-0.03275,   inf] (24), [-0.03246,   inf] (24), [-0.03246,   inf] (24), [-0.03240,   inf] (24), [-0.03225,   inf] (24), [-0.03204,   inf] (24), [-0.03200,   inf] (24), 
length of domains: 1202
Total time: 1.6096	 pickout: 0.1299	 decision: 0.3015	 get_bound: 1.0895	 add_domain: 0.0886
Current lb:-0.03593951836228371
3734 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.841139793395996

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1202, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1202, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1468] [1, 1468] [1, 1468] [1, 1468] [1, 1468] [1, 1468] [1, 1468] [1, 1468] [1, 1468] [1, 878] 
regular batch size: 2*1202, diving batch size 1*0
best_l after optimization: 18.525590896606445 with beta sum per layer: [0.0, 1282.15087890625, 11.790175437927246]
alpha/beta optimization time: 1.1943764686584473
This batch time : update_bounds func: 1.7451	 prepare: 0.2234	 bound: 1.1949	 transfer: 0.0824	 finalize: 0.1883
Accumulated time: update_bounds func: 5.0905	 prepare: 0.5661	 bound: 3.8526	 transfer: 0.0824	 finalize: 0.4044
batch bounding time:  1.7474067211151123
Current worst splitting domains [lb, ub] (depth):
[-0.03243,   inf] (26), [-0.03183,   inf] (26), [-0.03167,   inf] (26), [-0.03158,   inf] (26), [-0.03117,   inf] (26), [-0.03108,   inf] (26), [-0.03043,   inf] (26), [-0.03017,   inf] (26), [-0.03004,   inf] (26), [-0.02978,   inf] (26), [-0.02956,   inf] (26), [-0.02941,   inf] (26), [-0.02938,   inf] (26), [-0.02931,   inf] (26), [-0.02930,   inf] (26), [-0.02927,   inf] (26), [-0.02907,   inf] (26), [-0.02903,   inf] (26), [-0.02898,   inf] (26), [-0.02883,   inf] (26), 
length of domains: 1803
Total time: 2.5402	 pickout: 0.1875	 decision: 0.4345	 get_bound: 1.7513	 add_domain: 0.1669
Current lb:-0.03242907300591469
6138 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.405420064926147

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1803, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1803, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 117] [1, 117] [1, 117] [1, 117] [1, 117] [1, 117] [1, 117] [1, 117] [1, 117] [1, 117] 
regular batch size: 2*1803, diving batch size 1*0
best_l after optimization: 9.45201301574707 with beta sum per layer: [0.0, 1767.4052734375, 14.597891807556152]
alpha/beta optimization time: 1.7545530796051025
This batch time : update_bounds func: 2.6659	 prepare: 0.5065	 bound: 1.7550	 transfer: 0.1189	 finalize: 0.2769
Accumulated time: update_bounds func: 7.7564	 prepare: 1.0725	 bound: 5.6076	 transfer: 0.1189	 finalize: 0.6813
batch bounding time:  2.6695125102996826
Current worst splitting domains [lb, ub] (depth):
[-0.03037,   inf] (28), [-0.02976,   inf] (28), [-0.02963,   inf] (28), [-0.02957,   inf] (28), [-0.02911,   inf] (28), [-0.02900,   inf] (28), [-0.02838,   inf] (28), [-0.02819,   inf] (28), [-0.02796,   inf] (28), [-0.02777,   inf] (28), [-0.02746,   inf] (28), [-0.02744,   inf] (28), [-0.02738,   inf] (28), [-0.02732,   inf] (28), [-0.02722,   inf] (28), [-0.02719,   inf] (28), [-0.02702,   inf] (28), [-0.02702,   inf] (28), [-0.02696,   inf] (28), [-0.02673,   inf] (28), 
length of domains: 1812
Total time: 3.9691	 pickout: 0.3196	 decision: 0.8262	 get_bound: 2.6757	 add_domain: 0.1475
Current lb:-0.030367152765393257
9744 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.412054538726807

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1812, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1812, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 485] [1, 485] [1, 485] [1, 485] [1, 485] [1, 485] [1, 485] [1, 485] [1, 485] [1, 485] 
regular batch size: 2*1812, diving batch size 1*0
best_l after optimization: 8.838916778564453 with beta sum per layer: [0.0, 1554.768798828125, 15.725666999816895]
alpha/beta optimization time: 1.774679183959961
This batch time : update_bounds func: 2.5806	 prepare: 0.3542	 bound: 1.7751	 transfer: 0.1074	 finalize: 0.3350
Accumulated time: update_bounds func: 10.3371	 prepare: 1.4267	 bound: 7.3827	 transfer: 0.1074	 finalize: 1.0164
batch bounding time:  2.584223985671997
Current worst splitting domains [lb, ub] (depth):
[-0.02659,   inf] (30), [-0.02605,   inf] (30), [-0.02590,   inf] (30), [-0.02582,   inf] (30), [-0.02549,   inf] (30), [-0.02517,   inf] (30), [-0.02493,   inf] (30), [-0.02443,   inf] (30), [-0.02439,   inf] (30), [-0.02394,   inf] (30), [-0.02388,   inf] (30), [-0.02367,   inf] (30), [-0.02365,   inf] (30), [-0.02356,   inf] (30), [-0.02349,   inf] (30), [-0.02345,   inf] (30), [-0.02344,   inf] (30), [-0.02320,   inf] (30), [-0.02305,   inf] (30), [-0.02292,   inf] (30), 
length of domains: 1917
Total time: 3.7178	 pickout: 0.2864	 decision: 0.6819	 get_bound: 2.5904	 add_domain: 0.1592
Current lb:-0.02658756449818611
13368 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.174168825149536

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1917, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1917, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 507] [1, 507] [1, 828] [1, 507] [1, 507] [1, 828] [1, 507] [1, 620] [1, 828] [1, 620] 
regular batch size: 2*1917, diving batch size 1*0
best_l after optimization: 8.70995044708252 with beta sum per layer: [0.0, 1313.499267578125, 18.19449806213379]
alpha/beta optimization time: 1.8778140544891357
This batch time : update_bounds func: 2.6713	 prepare: 0.3724	 bound: 1.8783	 transfer: 0.1249	 finalize: 0.2860
Accumulated time: update_bounds func: 13.0084	 prepare: 1.7991	 bound: 9.2610	 transfer: 0.1249	 finalize: 1.3024
batch bounding time:  2.6752116680145264
Current worst splitting domains [lb, ub] (depth):
[-0.02390,   inf] (32), [-0.02341,   inf] (32), [-0.02312,   inf] (32), [-0.02265,   inf] (32), [-0.02264,   inf] (32), [-0.02229,   inf] (32), [-0.02190,   inf] (32), [-0.02113,   inf] (32), [-0.02101,   inf] (32), [-0.02095,   inf] (32), [-0.02087,   inf] (32), [-0.02077,   inf] (32), [-0.02075,   inf] (32), [-0.02041,   inf] (32), [-0.02028,   inf] (32), [-0.02019,   inf] (32), [-0.02017,   inf] (32), [-0.02009,   inf] (32), [-0.02001,   inf] (32), [-0.02000,   inf] (32), 
length of domains: 2144
Total time: 4.0018	 pickout: 0.3239	 decision: 0.7257	 get_bound: 2.6818	 add_domain: 0.2705
Current lb:-0.023903943598270416
17202 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 22.21976351737976

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2144, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([2144, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 620] [1, 620] [1, 620] [1, 620] [1, 620] [1, 620] [1, 620] [1, 620] [1, 620] [1, 828] 
regular batch size: 2*2144, diving batch size 1*0
best_l after optimization: 6.104016304016113 with beta sum per layer: [0.0, 1122.165283203125, 19.845840454101562]
alpha/beta optimization time: 2.050992012023926
This batch time : update_bounds func: 2.9928	 prepare: 0.4141	 bound: 2.0514	 transfer: 0.1412	 finalize: 0.3750
Accumulated time: update_bounds func: 16.0012	 prepare: 2.2132	 bound: 11.3124	 transfer: 0.1412	 finalize: 1.6773
batch bounding time:  3.0000834465026855
Current worst splitting domains [lb, ub] (depth):
[-0.01858,   inf] (34), [-0.01833,   inf] (34), [-0.01804,   inf] (34), [-0.01782,   inf] (34), [-0.01781,   inf] (34), [-0.01772,   inf] (34), [-0.01760,   inf] (34), [-0.01737,   inf] (34), [-0.01734,   inf] (34), [-0.01721,   inf] (34), [-0.01718,   inf] (34), [-0.01716,   inf] (34), [-0.01716,   inf] (34), [-0.01694,   inf] (34), [-0.01687,   inf] (34), [-0.01679,   inf] (34), [-0.01672,   inf] (34), [-0.01662,   inf] (34), [-0.01642,   inf] (34), [-0.01641,   inf] (34), 
length of domains: 2269
Total time: 4.3713	 pickout: 0.3461	 decision: 0.8118	 get_bound: 3.0124	 add_domain: 0.2009
Current lb:-0.01857968233525753
21490 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 26.641764402389526

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2269, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([2269, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 878] [1, 878] [1, 878] [1, 878] [1, 878] [1, 620] [1, 878] [1, 620] [1, 878] [1, 620] 
regular batch size: 2*2269, diving batch size 1*0
best_l after optimization: 1.5633842945098877 with beta sum per layer: [0.0, 808.185791015625, 19.92519760131836]
alpha/beta optimization time: 2.177786111831665
This batch time : update_bounds func: 3.4224	 prepare: 0.6538	 bound: 2.1783	 transfer: 0.1578	 finalize: 0.3512
Accumulated time: update_bounds func: 19.4235	 prepare: 2.8671	 bound: 13.4907	 transfer: 0.1578	 finalize: 2.0286
batch bounding time:  3.426959276199341
Current worst splitting domains [lb, ub] (depth):
[-0.01422,   inf] (36), [-0.01404,   inf] (36), [-0.01369,   inf] (36), [-0.01350,   inf] (36), [-0.01329,   inf] (36), [-0.01316,   inf] (36), [-0.01314,   inf] (36), [-0.01299,   inf] (36), [-0.01294,   inf] (36), [-0.01264,   inf] (36), [-0.01263,   inf] (36), [-0.01260,   inf] (36), [-0.01246,   inf] (36), [-0.01242,   inf] (36), [-0.01241,   inf] (36), [-0.01240,   inf] (36), [-0.01225,   inf] (36), [-0.01220,   inf] (36), [-0.01214,   inf] (36), [-0.01202,   inf] (36), 
length of domains: 2103
Total time: 5.0973	 pickout: 0.3866	 decision: 1.0861	 get_bound: 3.4347	 add_domain: 0.1899
Current lb:-0.014222631230950356
26028 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 31.793873071670532

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2103, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([2103, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 307] [1, 307] [1, 307] [1, 307] [1, 307] [1, 307] [1, 307] [1, 307] [1, 307] [1, 307] 
regular batch size: 2*2103, diving batch size 1*0
best_l after optimization: -6.913090229034424 with beta sum per layer: [0.0, 439.6627197265625, 14.675090789794922]
alpha/beta optimization time: 2.0128986835479736
This batch time : update_bounds func: 3.0798	 prepare: 0.6038	 bound: 2.0133	 transfer: 0.1366	 finalize: 0.3147
Accumulated time: update_bounds func: 22.5033	 prepare: 3.4709	 bound: 15.5040	 transfer: 0.1366	 finalize: 2.3432
batch bounding time:  3.0841081142425537
Current worst splitting domains [lb, ub] (depth):
[-0.01209,   inf] (38), [-0.01187,   inf] (38), [-0.01152,   inf] (38), [-0.01133,   inf] (38), [-0.01112,   inf] (38), [-0.01105,   inf] (38), [-0.01102,   inf] (38), [-0.01084,   inf] (38), [-0.01079,   inf] (38), [-0.01050,   inf] (38), [-0.01047,   inf] (38), [-0.01044,   inf] (38), [-0.01030,   inf] (38), [-0.01030,   inf] (38), [-0.01028,   inf] (38), [-0.01025,   inf] (38), [-0.01010,   inf] (38), [-0.01005,   inf] (38), [-0.01002,   inf] (38), [-0.00990,   inf] (38), 
length of domains: 1220
Total time: 4.4680	 pickout: 0.3410	 decision: 0.9188	 get_bound: 3.0915	 add_domain: 0.1167
Current lb:-0.012087583541870117
30234 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 36.31854510307312

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1220, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([1220, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1940] [1, 1940] [1, 878] [1, 878] [1, 878] [1, 1453] [1, 1453] [1, 1453] [1, 1453] [1, 1453] 
regular batch size: 2*1220, diving batch size 1*0
best_l after optimization: -4.956202983856201 with beta sum per layer: [0.0, 154.13607788085938, 7.500759124755859]
alpha/beta optimization time: 1.195239543914795
This batch time : update_bounds func: 1.7246	 prepare: 0.2445	 bound: 1.1956	 transfer: 0.0741	 finalize: 0.1454
Accumulated time: update_bounds func: 24.2279	 prepare: 3.7153	 bound: 16.6996	 transfer: 0.0741	 finalize: 2.4886
batch bounding time:  1.7270362377166748
Current worst splitting domains [lb, ub] (depth):
[-0.00978,   inf] (40), [-0.00958,   inf] (40), [-0.00891,   inf] (40), [-0.00891,   inf] (40), [-0.00861,   inf] (40), [-0.00852,   inf] (40), [-0.00835,   inf] (40), [-0.00829,   inf] (40), [-0.00816,   inf] (40), [-0.00815,   inf] (40), [-0.00814,   inf] (40), [-0.00800,   inf] (40), [-0.00787,   inf] (40), [-0.00778,   inf] (40), [-0.00777,   inf] (40), [-0.00771,   inf] (40), [-0.00742,   inf] (40), [-0.00738,   inf] (40), [-0.00737,   inf] (40), [-0.00725,   inf] (40), 
length of domains: 637
Total time: 2.4357	 pickout: 0.2005	 decision: 0.4426	 get_bound: 1.7311	 add_domain: 0.0615
Current lb:-0.009782608598470688
32674 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 38.791393518447876

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([637, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([637, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 878] [1, 878] [1, 1298] [1, 1298] [1, 1298] [1, 1298] [1, 828] [1, 828] [1, 828] [1, 828] 
regular batch size: 2*637, diving batch size 1*0
best_l after optimization: -3.074726104736328 with beta sum per layer: [0.0, 63.77378845214844, 1.86613130569458]
alpha/beta optimization time: 0.7007861137390137
This batch time : update_bounds func: 0.9330	 prepare: 0.1233	 bound: 0.7012	 transfer: 0.0303	 finalize: 0.0746
Accumulated time: update_bounds func: 25.1609	 prepare: 3.8387	 bound: 17.4008	 transfer: 0.0303	 finalize: 2.5632
batch bounding time:  0.9342777729034424
Current worst splitting domains [lb, ub] (depth):
[-0.00658,   inf] (42), [-0.00657,   inf] (42), [-0.00628,   inf] (42), [-0.00620,   inf] (42), [-0.00544,   inf] (42), [-0.00537,   inf] (42), [-0.00510,   inf] (42), [-0.00504,   inf] (42), [-0.00470,   inf] (42), [-0.00465,   inf] (42), [-0.00451,   inf] (42), [-0.00450,   inf] (42), [-0.00450,   inf] (42), [-0.00446,   inf] (42), [-0.00445,   inf] (42), [-0.00437,   inf] (42), [-0.00428,   inf] (42), [-0.00426,   inf] (42), [-0.00424,   inf] (42), [-0.00414,   inf] (42), 
length of domains: 237
Total time: 1.3438	 pickout: 0.1053	 decision: 0.2793	 get_bound: 0.9363	 add_domain: 0.0230
Current lb:-0.006580233573913574
33948 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 40.154568910598755

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([237, 16, 16, 16]) pre split depth:  1
batch:  torch.Size([237, 16, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 1940] [1, 1940] [1, 1940] [1, 1940] [1, 1940] [1, 1940] [1, 1940] [1, 1940] [1, 1298] [1, 1298] 
regular batch size: 2*237, diving batch size 1*0
best_l after optimization: -1.5388970375061035 with beta sum per layer: [0.0, 17.337173461914062, 0.021282725036144257]
alpha/beta optimization time: 0.3688681125640869
This batch time : update_bounds func: 0.4953	 prepare: 0.0472	 bound: 0.3692	 transfer: 0.0055	 finalize: 0.0722
Accumulated time: update_bounds func: 25.6562	 prepare: 3.8859	 bound: 17.7700	 transfer: 0.0055	 finalize: 2.6354
batch bounding time:  0.4959716796875
Current worst splitting domains [lb, ub] (depth):
[-0.00435,   inf] (44), [-0.00434,   inf] (44), [-0.00405,   inf] (44), [-0.00397,   inf] (44), [-0.00321,   inf] (44), [-0.00314,   inf] (44), [-0.00286,   inf] (44), [-0.00281,   inf] (44), [-0.00252,   inf] (44), [-0.00251,   inf] (44), [-0.00240,   inf] (44), [-0.00235,   inf] (44), [-0.00230,   inf] (44), [-0.00225,   inf] (44), [-0.00211,   inf] (44), [-0.00210,   inf] (44), [-0.00209,   inf] (44), [-0.00198,   inf] (44), [-0.00194,   inf] (44), [-0.00191,   inf] (44), 
length of domains: 57
Total time: 0.6295	 pickout: 0.0390	 decision: 0.0877	 get_bound: 0.4967	 add_domain: 0.0061
Current lb:-0.004354596138000488
34422 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 40.79185700416565

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([57, 16, 16, 16]) pre split depth:  2
batch:  torch.Size([57, 16, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [1, 828] [1, 828] [1, 828] [1, 828] [1, 878] [1, 878] [1, 878] [1, 878] [0, 391] [0, 391] 
split level 1: [0, 391] [0, 391] [0, 391] [0, 391] [0, 391] [0, 391] [0, 391] [0, 391] [1, 1348] [1, 1348] 
regular batch size: 2*114, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -1.4955320358276367 with beta sum per layer: [0.0, 5.0849080085754395, 0.0]
alpha/beta optimization time: 0.01037740707397461
This batch time : update_bounds func: 0.0508	 prepare: 0.0227	 bound: 0.0107	 transfer: 0.0040	 finalize: 0.0129
Accumulated time: update_bounds func: 25.7071	 prepare: 3.9085	 bound: 17.7807	 transfer: 0.0040	 finalize: 2.6483
batch bounding time:  0.05108165740966797
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.1205	 pickout: 0.0099	 decision: 0.0404	 get_bound: 0.0701	 add_domain: 0.0001
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 40.91516160964966

Image 42 label 3 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 40.982927322387695/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:462: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(preprocess_cifar(eps_temp, perturbation=True)).reshape(1,-1,1,1)

42 1.0000000116860974e-07
##### [0:42] Tested against 5 ######
Model prediction is: tensor([[-6.2352, -9.2286, -3.7581, -3.2744, -4.2941, -3.5855, -2.4106, -6.2941,
         -6.6657, -8.3439]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 16, 16]) != torch.Size([2, 9, 1, 16, 16, 16]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 8, 8]) != torch.Size([2, 9, 1, 32, 8, 8]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 16, 16])
1 /11 torch.Size([1, 32, 8, 8])
2 /21 torch.Size([1, 100])
best_l after optimization: 0.1844879388809204 with beta sum per layer: []
alpha/beta optimization time: 1.0673484802246094
alpha-CROWN with fixed intermediate bounds: tensor([[-0.1845]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.1844879388809204
layer 0 size torch.Size([4096]) unstable 590
layer 1 size torch.Size([2048]) unstable 242
layer 2 size torch.Size([100]) unstable 21
-----------------
# of unstable neurons: 853
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 16, 16]) pre split depth:  8
batch:  torch.Size([1, 16, 16, 16]) post split depth:  8
splitting decisions: 
split level 0: [2, 33] 
split level 1: [2, 41] 
split level 2: [2, 51] 
split level 3: [2, 11] 
split level 4: [2, 13] 
split level 5: [2, 45] 
split level 6: [1, 483] 
split level 7: [1, 475] 
regular batch size: 2*128, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -88.58116149902344 with beta sum per layer: [0.0, 0.0, 0.0]
alpha/beta optimization time: 0.011093854904174805
This batch time : update_bounds func: 0.0510	 prepare: 0.0205	 bound: 0.0114	 transfer: 0.0038	 finalize: 0.0146
Accumulated time: update_bounds func: 25.7580	 prepare: 3.9290	 bound: 17.7921	 transfer: 0.0038	 finalize: 2.6629
batch bounding time:  0.05122876167297363
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.1808	 pickout: 0.0012	 decision: 0.0811	 get_bound: 0.0985	 add_domain: 0.0001
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 1.2808804512023926

Image 42 label 5 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 1.342806339263916
42 1.0000000116860974e-07
##### [0:42] Tested against 2 ######
Initial alpha-CROWN verified for label 2 with bound 0.018527045845985413
Image 42 label 2 verification end, final lower bound 0.018527045845985413, upper bound inf, time: 0.0003867149353027344
42 0.018527045845985413
##### [0:42] Tested against 4 ######
Initial alpha-CROWN verified for label 4 with bound 0.4012793302536011
Image 42 label 4 verification end, final lower bound 0.4012793302536011, upper bound inf, time: 0.0003845691680908203
42 0.4012793302536011
##### [0:42] Tested against 7 ######
Initial alpha-CROWN verified for label 7 with bound 2.2260353565216064
Image 42 label 7 verification end, final lower bound 2.2260353565216064, upper bound inf, time: 0.0003848075866699219
42 2.2260353565216064
##### [0:42] Tested against 0 ######
Initial alpha-CROWN verified for label 0 with bound 1.980950951576233
Image 42 label 0 verification end, final lower bound 1.980950951576233, upper bound inf, time: 0.000385284423828125
42 1.980950951576233
##### [0:42] Tested against 8 ######
Initial alpha-CROWN verified for label 8 with bound 2.031489133834839
Image 42 label 8 verification end, final lower bound 2.031489133834839, upper bound inf, time: 0.00039076805114746094
42 2.031489133834839
##### [0:42] Tested against 9 ######
Initial alpha-CROWN verified for label 9 with bound 3.8680355548858643
Image 42 label 9 verification end, final lower bound 3.8680355548858643, upper bound inf, time: 0.0003898143768310547
42 3.8680355548858643
##### [0:42] Tested against 1 ######
Initial alpha-CROWN verified for label 1 with bound 4.462770938873291
Image 42 label 1 verification end, final lower bound 4.462770938873291, upper bound inf, time: 0.0003821849822998047
42 4.462770938873291
##### [0:42] Tested against 6 ######
groundtruth label, skip!
Result: image 42 verification success (with branch and bound)!
Wall time: 53.644952058792114

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 1): [42]
verification failure idx (total 0): []
final verified acc: 100.0%[1]
verifier is called on 1 examples.
total verified: 1
mean time [cnt:1] (excluding attack success): 52.11654472351074
