Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_cnn_a_adv.model
  name: cnn_4layer_adv
data:
  start: 11
  end: 12
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR_SDP
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.00784313725
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 4096
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 30
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 20:49:51 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(3, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Flatten()
  (5): Linear(in_features=2048, out_features=100, bias=True)
  (6): ReLU()
  (7): Linear(in_features=100, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([200, 3, 32, 32]) torch.Size([200]) torch.Size([200])
X range: tensor(2.1256) tensor(-1.9889) tensor(-0.0131)
############################
epsilon after preprocessing: tensor([[[[0.0317]],

         [[0.0322]],

         [[0.0300]]]]), data_max = tensor([[[[2.0587]],

         [[2.1256]],

         [[2.1154]]]]), data_min = tensor([[[[-1.9889]],

         [[-1.9807]],

         [[-1.7076]]]])
Task length: 1
saving results to Verified_ret_[cnn_4layer_adv]_start=11_end=12_iter=20_b=4096_timeout=30_branching=kfsb-max-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 11 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 2, correct label 2, image norm 2018.199462890625, logits tensor([-5.6348, -9.9728, -2.4218, -5.9818, -3.0130, -6.4999, -5.3587, -6.0945,
        -8.4953, -9.4824], device='cuda:0', grad_fn=<SelectBackward>)
##### PGD attack: True label: 2, Tested against: ['all'] ######
pgd prediction: tensor([-5.8551, -9.9511, -2.6910, -5.9507, -2.8365, -6.4559, -5.3537, -5.9761,
        -8.5269, -9.4123], device='cuda:0', grad_fn=<SqueezeBackward1>)
attack margin tensor([3.1641, 7.2601,    inf, 3.2598, 0.1456, 3.7649, 2.6627, 3.2851, 5.8359,
        6.7213], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[-5.6348, -9.9728, -2.4218, -5.9818, -3.0130, -6.4999, -5.3587, -6.0945,
         -8.4953, -9.4824]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 1.9306,  5.5086,  2.4372, -0.2856,  2.9580,  1.6414,  2.4906,  4.0699,
          5.1385]], device='cuda:0') None
best_l after optimization: -26.603717803955078 with beta sum per layer: []
alpha/beta optimization time: 7.849377155303955
initial alpha-CROWN bounds: tensor([[ 1.9994,  5.6278,  2.4938, -0.2059,  3.0099,  1.7213,  2.5522,  4.1691,
          5.2360]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.2059, device='cuda:0', grad_fn=<MinBackward1>)
Sorted order for labels to verify: [4, 6, 0, 3, 7, 5, 8, 9, 1, 2]
##### [0:11] Tested against 4 ######
Model prediction is: tensor([[-5.6348, -9.9728, -2.4218, -5.9818, -3.0130, -6.4999, -5.3587, -6.0945,
         -8.4953, -9.4824]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /10 start_node /11
setting alpha for layer /10 start_node /21
not setting layer /10 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 16, 16, 16]) != torch.Size([2, 9, 1, 16, 16, 16]))
setting alpha for layer /12 start_node /21
not setting layer /12 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 32, 8, 8]) != torch.Size([2, 9, 1, 32, 8, 8]))
not setting layer /22 start_node /23 because shape mismatch (torch.Size([2, 1, 1, 100]) != torch.Size([2, 9, 1, 100]))
0 /9 torch.Size([1, 16, 16, 16])
1 /11 torch.Size([1, 32, 8, 8])
2 /21 torch.Size([1, 100])
best_l after optimization: 0.20587970316410065 with beta sum per layer: []
alpha/beta optimization time: 2.0569050312042236
alpha-CROWN with fixed intermediate bounds: tensor([[-0.2059]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.20587971806526184
layer 0 size torch.Size([4096]) unstable 507
layer 1 size torch.Size([2048]) unstable 252
layer 2 size torch.Size([100]) unstable 23
-----------------
# of unstable neurons: 782
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 16, 16]) pre split depth:  8
batch:  torch.Size([1, 16, 16, 16]) post split depth:  8
splitting decisions: 
split level 0: [2, 41] 
split level 1: [2, 35] 
split level 2: [2, 45] 
split level 3: [2, 58] 
split level 4: [2, 61] 
split level 5: [2, 4] 
split level 6: [2, 40] 
split level 7: [0, 393] 
regular batch size: 2*128, diving batch size 1*0
best_l after optimization: -57.31093215942383 with beta sum per layer: [0.31586912274360657, 0.0, 0.33133137226104736]
alpha/beta optimization time: 0.28713154792785645
This batch time : update_bounds func: 0.3579	 prepare: 0.0322	 bound: 0.2874	 transfer: 0.0130	 finalize: 0.0246
Accumulated time: update_bounds func: 0.3579	 prepare: 0.0322	 bound: 0.2874	 transfer: 0.0130	 finalize: 0.0246
batch bounding time:  0.3582310676574707
Current worst splitting domains [lb, ub] (depth):
[-0.03261,   inf] (9), [-0.02890,   inf] (9), 
length of domains: 2
Total time: 0.7194	 pickout: 0.0010	 decision: 0.3279	 get_bound: 0.3903	 add_domain: 0.0002
Current lb:-0.032613977789878845
256 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.6771857738494873

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2, 16, 16, 16]) pre split depth:  7
batch:  torch.Size([2, 16, 16, 16]) post split depth:  7
splitting decisions: 
split level 0: [2, 80] [2, 80] 
split level 1: [0, 377] [0, 392] 
split level 2: [1, 1411] [1, 1411] 
split level 3: [1, 1251] [1, 1251] 
split level 4: [1, 2043] [1, 2043] 
split level 5: [0, 378] [0, 428] 
split level 6: [0, 428] [0, 378] 
regular batch size: 2*128, diving batch size 1*0
best_l after optimization: -6.587960243225098 with beta sum per layer: [25.425533294677734, 2.305234909057617, 0.0]
alpha/beta optimization time: 0.3061091899871826
This batch time : update_bounds func: 0.3618	 prepare: 0.0248	 bound: 0.3065	 transfer: 0.0141	 finalize: 0.0157
Accumulated time: update_bounds func: 0.7197	 prepare: 0.0570	 bound: 0.5940	 transfer: 0.0141	 finalize: 0.0402
batch bounding time:  0.36212754249572754
Current worst splitting domains [lb, ub] (depth):
[-0.01334,   inf] (17), [-0.01316,   inf] (17), [-0.01290,   inf] (17), [-0.01272,   inf] (17), [-0.01216,   inf] (17), [-0.01198,   inf] (17), [-0.01186,   inf] (17), [-0.01172,   inf] (17), [-0.01168,   inf] (17), [-0.01154,   inf] (17), [-0.01142,   inf] (17), [-0.01124,   inf] (17), [-0.01068,   inf] (17), [-0.01050,   inf] (17), [-0.01024,   inf] (17), [-0.01006,   inf] (17), [-0.00877,   inf] (17), [-0.00872,   inf] (17), [-0.00863,   inf] (17), [-0.00859,   inf] (17), 
length of domains: 70
Total time: 0.4464	 pickout: 0.0025	 decision: 0.0433	 get_bound: 0.3961	 add_domain: 0.0044
Current lb:-0.013339033350348473
512 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.124532222747803

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([70, 16, 16, 16]) pre split depth:  2
batch:  torch.Size([70, 16, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [0, 392] [0, 392] [0, 392] [0, 392] [0, 392] [0, 392] [0, 392] [0, 392] [0, 392] [0, 392] 
split level 1: [1, 818] [1, 818] [1, 818] [1, 818] [1, 818] [1, 818] [1, 818] [1, 818] [1, 818] [1, 818] 
regular batch size: 2*140, diving batch size 1*0
best_l after optimization: -0.7703363299369812 with beta sum per layer: [25.794153213500977, 13.302192687988281, 0.0]
alpha/beta optimization time: 0.3110034465789795
This batch time : update_bounds func: 0.3647	 prepare: 0.0286	 bound: 0.3113	 transfer: 0.0080	 finalize: 0.0157
Accumulated time: update_bounds func: 1.0844	 prepare: 0.0856	 bound: 0.9053	 transfer: 0.0080	 finalize: 0.0559
batch bounding time:  0.3650627136230469
Current worst splitting domains [lb, ub] (depth):
[-0.01038,   inf] (20), [-0.01020,   inf] (20), [-0.01000,   inf] (20), [-0.00982,   inf] (20), [-0.00920,   inf] (20), [-0.00902,   inf] (20), [-0.00900,   inf] (20), [-0.00882,   inf] (20), [-0.00882,   inf] (20), [-0.00864,   inf] (20), [-0.00861,   inf] (20), [-0.00843,   inf] (20), [-0.00782,   inf] (20), [-0.00764,   inf] (20), [-0.00743,   inf] (20), [-0.00725,   inf] (20), [-0.00580,   inf] (20), [-0.00562,   inf] (20), [-0.00541,   inf] (20), [-0.00523,   inf] (20), 
length of domains: 57
Total time: 0.4709	 pickout: 0.0120	 decision: 0.0696	 get_bound: 0.3851	 add_domain: 0.0041
Current lb:-0.010380484163761139
792 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.597733497619629

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([57, 16, 16, 16]) pre split depth:  2
batch:  torch.Size([57, 16, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [1, 1389] [1, 1389] [1, 1389] [1, 1389] [1, 1389] [1, 1389] [1, 1389] [1, 1389] [1, 1389] [1, 1389] 
split level 1: [1, 610] [1, 610] [1, 292] [1, 292] [1, 610] [1, 610] [1, 610] [1, 610] [1, 292] [1, 292] 
regular batch size: 2*114, diving batch size 1*0
best_l after optimization: -0.47055792808532715 with beta sum per layer: [14.567434310913086, 10.085091590881348, 0.0]
alpha/beta optimization time: 0.2956259250640869
This batch time : update_bounds func: 0.3383	 prepare: 0.0240	 bound: 0.2960	 transfer: 0.0046	 finalize: 0.0130
Accumulated time: update_bounds func: 1.4226	 prepare: 0.1096	 bound: 1.2013	 transfer: 0.0046	 finalize: 0.0690
batch bounding time:  0.3385746479034424
Current worst splitting domains [lb, ub] (depth):
[-0.00479,   inf] (23), [-0.00454,   inf] (23), [-0.00422,   inf] (23), [-0.00409,   inf] (23), [-0.00397,   inf] (23), [-0.00384,   inf] (23), [-0.00360,   inf] (23), [-0.00349,   inf] (23), [-0.00341,   inf] (23), [-0.00335,   inf] (23), [-0.00324,   inf] (23), [-0.00316,   inf] (23), [-0.00300,   inf] (23), [-0.00291,   inf] (23), [-0.00284,   inf] (23), [-0.00275,   inf] (23), [-0.00271,   inf] (23), [-0.00266,   inf] (23), [-0.00259,   inf] (23), [-0.00246,   inf] (23), 
length of domains: 51
Total time: 0.4156	 pickout: 0.0095	 decision: 0.0468	 get_bound: 0.3556	 add_domain: 0.0038
Current lb:-0.004786134231835604
1020 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.014986276626587

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([51, 16, 16, 16]) pre split depth:  3
batch:  torch.Size([51, 16, 16, 16]) post split depth:  3
splitting decisions: 
split level 0: [0, 327] [0, 327] [0, 327] [0, 327] [0, 327] [0, 327] [0, 327] [0, 327] [0, 327] [0, 327] 
split level 1: [1, 292] [1, 292] [1, 610] [1, 292] [1, 610] [1, 292] [1, 292] [1, 610] [1, 292] [1, 292] 
split level 2: [1, 1410] [1, 1410] [1, 1410] [1, 1410] [1, 1410] [1, 1410] [1, 1410] [1, 1410] [1, 1410] [1, 1410] 
regular batch size: 2*204, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -2.5513031482696533 with beta sum per layer: [0.0, 20.730510711669922, 0.0]
alpha/beta optimization time: 0.013678789138793945
This batch time : update_bounds func: 0.0934	 prepare: 0.0416	 bound: 0.0140	 transfer: 0.0127	 finalize: 0.0240
Accumulated time: update_bounds func: 1.5161	 prepare: 0.1513	 bound: 1.2153	 transfer: 0.0127	 finalize: 0.0930
batch bounding time:  0.09380722045898438
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.1886	 pickout: 0.0084	 decision: 0.0416	 get_bound: 0.1385	 add_domain: 0.0001
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 5.206270217895508

Image 11 label 4 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 5.266965389251709
11 1.0000000116860974e-07
##### [0:11] Tested against 6 ######
Initial alpha-CROWN verified for label 6 with bound 1.721309781074524
Image 11 label 6 verification end, final lower bound 1.721309781074524, upper bound inf, time: 0.00041031837463378906
11 1.721309781074524
##### [0:11] Tested against 0 ######
Initial alpha-CROWN verified for label 0 with bound 1.9994169473648071
Image 11 label 0 verification end, final lower bound 1.9994169473648071, upper bound inf, time: 0.0003952980041503906
11 1.9994169473648071
##### [0:11] Tested against 3 ######
Initial alpha-CROWN verified for label 3 with bound 2.4938225746154785
Image 11 label 3 verification end, final lower bound 2.4938225746154785, upper bound inf, time: 0.00038695335388183594
11 2.4938225746154785
##### [0:11] Tested against 7 ######
Initial alpha-CROWN verified for label 7 with bound 2.552208423614502
Image 11 label 7 verification end, final lower bound 2.552208423614502, upper bound inf, time: 0.00039839744567871094
11 2.552208423614502
##### [0:11] Tested against 5 ######
Initial alpha-CROWN verified for label 5 with bound 3.009944438934326
Image 11 label 5 verification end, final lower bound 3.009944438934326, upper bound inf, time: 0.00038886070251464844
11 3.009944438934326
##### [0:11] Tested against 8 ######
Initial alpha-CROWN verified for label 8 with bound 4.169148921966553
Image 11 label 8 verification end, final lower bound 4.169148921966553, upper bound inf, time: 0.00039505958557128906
11 4.169148921966553
##### [0:11] Tested against 9 ######
Initial alpha-CROWN verified for label 9 with bound 5.235984802246094
Image 11 label 9 verification end, final lower bound 5.235984802246094, upper bound inf, time: 0.00038170814514160156
11 5.235984802246094
##### [0:11] Tested against 1 ######
Initial alpha-CROWN verified for label 1 with bound 5.627817153930664
Image 11 label 1 verification end, final lower bound 5.627817153930664, upper bound inf, time: 0.00039458274841308594
11 5.627817153930664
##### [0:11] Tested against 2 ######
groundtruth label, skip!
Result: image 11 verification success (with branch and bound)!
Wall time: 17.41071319580078

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 1): [11]
verification failure idx (total 0): []
final verified acc: 100.0%[1]
verifier is called on 1 examples./home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:462: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(preprocess_cifar(eps_temp, perturbation=True)).reshape(1,-1,1,1)

total verified: 1
mean time [cnt:1] (excluding attack success): 15.36922025680542
