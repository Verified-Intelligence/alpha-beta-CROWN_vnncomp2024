Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  sparse_alpha: true
  save_adv_example: false
  precompile_jit: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
  csv_name: null
  results_file: null
  root_path: ''
model:
  path: cifar_resnet_8px.pth
  cache_onnx_conversion: false
  onnx_quirks: null
  name: model_resnet
  onnx_path: null
  onnx_path_prefix: ''
  onnx_optimization_flags: none
data:
  start: 9134
  end: 9135
  select_instance: null
  num_outputs: 10
  mean: [0.485, 0.456, 0.406]
  std: [0.225, 0.225, 0.225]
  pkl_path: null
  dataset: CIFAR
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.03137254901
  vnnlib_path: null
  vnnlib_path_prefix: ''
solver:
  batch_size: 8
  no_float64_last_iter: true
  no_amp: false
  early_stop_patience: 10
  start_save_best: 2
  bound_prop_method: alpha-crown
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
    full_conv_alpha: true
  beta-crown:
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  multi_class:
    multi_class_method: allclass_domain
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
bab:
  initial_max_domains: 1
  max_domains: 200000
  decision_thresh: 0
  timeout: 180
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_intermediate_layers: ''
  interm_transfer: true
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 100
    batch_size_primal: 100
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    max_num: 1000000000
    fixed_cuts: false
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
    lr: 0.01
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    sb_coeff_thresh: 0.001
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      sort_domain_interval: -1
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  attack_mode: PGD
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 5000000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
  enable_mip_attack: false
  cex_path: ./test_cex.txt
debug:
  lp_test: null

Experiments at Tue Aug 23 12:33:40 2022 on diablo.cs.ucla.edu
DenseSequential(
  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): ReLU()
  (2): Dense(
    (Ws): ModuleList(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (3): ReLU()
  (4): Dense(
    (Ws): ModuleList(
      (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))
      (1): None
      (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (5): ReLU()
  (6): Dense(
    (Ws): ModuleList(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (7): ReLU()
  (8): Dense(
    (Ws): ModuleList(
      (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))
      (1): None
      (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (9): ReLU()
  (10): Dense(
    (Ws): ModuleList(
      (0): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
  )
  (11): ReLU()
  (12): Dense(
    (Ws): ModuleList(
      (0): Conv2d(16, 32, kernel_size=(2, 2), stride=(2, 2))
      (1): None
      (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (13): ReLU()
  (14): Dense(
    (Ws): ModuleList(
      (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
  )
  (15): ReLU()
  (16): Dense(
    (Ws): ModuleList(
      (0): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): None
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (17): ReLU()
  (18): Flatten()
  (19): Linear(in_features=4096, out_features=1000, bias=True)
  (20): ReLU()
  (21): Linear(in_features=1000, out_features=10, bias=True)
)
Trying generic MNIST/CIFAR data loader.
Files already downloaded and verified
/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/abcrown.py:95: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_new.cpp:210.)
  arguments.Config["bab"]["decision_thresh"] = torch.tensor([item[1] for item in vnnlib[1]]).to(data)
saving results to Verified_ret_[model_resnet]_start=9134_end=9135_iter=20_b=8_timeout=180_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before_cplex_cuts=False_multiclass=allclass_domain.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 9134 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Attack parameters: initialization=uniform, steps=100, restarts=50, alpha=0.03485840559005737, initialization=uniform, GAMA=False
model output: tensor([[-0.59828854,  0.12625828,  0.10629036,  0.24961883, -0.04826543,
          0.38121414,  0.18064415,  0.13789693, -0.44081759, -0.09459238]],
       device='cuda:0')
pgd prediction: tensor([[[-0.67715406,  0.04697692,  0.20717074,  0.29121250,  0.10057102,
           0.38928604,  0.36587292,  0.13424551, -0.58664531, -0.27158061],
         [-0.67715406,  0.04697692,  0.20717074,  0.29121250,  0.10057102,
           0.38928604,  0.36587292,  0.13424551, -0.58664531, -0.27158061]]],
       device='cuda:0')
pgd attack margin tensor([[[1.06644011, 0.34230912, 0.18211530, 0.09807354, 0.28871500,
          0.02341312, 0.25504053, 0.97593135, 0.66086662]]], device='cuda:0')
number of violation:  0
Attack finished in 4.8636 seconds.
pgd attack failed
Model prediction is: tensor([[-0.59828854,  0.12625828,  0.10629036,  0.24961883, -0.04826543,
          0.38121414,  0.18064415,  0.13789693, -0.44081759, -0.09459238]],
       device='cuda:0')
layer /input.4 using sparse-features alpha with shape [1680]; unstable size 1680; total size 16384 (torch.Size([1, 16, 32, 32]))
layer /input.4 start_node /input.12 using sparse-spec alpha with unstable size 6 total_size 16 output_shape 16
layer /input.4 start_node /39 using sparse-spec alpha with unstable size 8 total_size 16384 output_shape (16, 32, 32)
layer /input.4 start_node /input.24 using sparse-spec alpha with unstable size 97 total_size 16384 output_shape (16, 32, 32)
layer /input.4 start_node /input.48 using sparse-spec alpha with unstable size 7 total_size 4096 output_shape (64, 8, 8)
layer /input.4 start_node /input.52 using sparse-spec alpha with unstable size 46 total_size 1000 output_shape torch.Size([1000])
layer /input.4 start_node /67 using full alpha with unstable size None total_size 9 output_shape 9
layer /input.8 using sparse-features alpha with shape [0]; unstable size 0; total size 16384 (torch.Size([1, 16, 32, 32]))
layer /input.8 start_node /input.12 using sparse-spec alpha with unstable size 6 total_size 16 output_shape 16
layer /input.8 start_node /39 using sparse-spec alpha with unstable size 8 total_size 16384 output_shape (16, 32, 32)
layer /input.8 start_node /input.24 using sparse-spec alpha with unstable size 97 total_size 16384 output_shape (16, 32, 32)
layer /input.8 start_node /input.48 using sparse-spec alpha with unstable size 7 total_size 4096 output_shape (64, 8, 8)
layer /input.8 start_node /input.52 using sparse-spec alpha with unstable size 46 total_size 1000 output_shape torch.Size([1000])
layer /input.8 start_node /67 using full alpha with unstable size None total_size 9 output_shape 9
layer /input.16 using sparse-features alpha with shape [564]; unstable size 564; total size 16384 (torch.Size([1, 16, 32, 32]))
layer /input.16 start_node /39 using sparse-spec alpha with unstable size 8 total_size 16384 output_shape (16, 32, 32)
layer /input.16 start_node /input.24 using sparse-spec alpha with unstable size 97 total_size 16384 output_shape (16, 32, 32)
layer /input.16 start_node /input.48 using sparse-spec alpha with unstable size 7 total_size 4096 output_shape (64, 8, 8)
layer /input.16 start_node /input.52 using sparse-spec alpha with unstable size 46 total_size 1000 output_shape torch.Size([1000])
layer /input.16 start_node /67 using full alpha with unstable size None total_size 9 output_shape 9
layer /input.20 using sparse-features alpha with shape [8]; unstable size 8; total size 16384 (torch.Size([1, 16, 32, 32]))
layer /input.20 start_node /input.24 using sparse-spec alpha with unstable size 97 total_size 16384 output_shape (16, 32, 32)
layer /input.20 start_node /input.48 using sparse-spec alpha with unstable size 7 total_size 4096 output_shape (64, 8, 8)
layer /input.20 start_node /input.52 using sparse-spec alpha with unstable size 46 total_size 1000 output_shape torch.Size([1000])
layer /input.20 start_node /67 using full alpha with unstable size None total_size 9 output_shape 9
layer /input.28 using sparse-features alpha with shape [97]; unstable size 97; total size 16384 (torch.Size([1, 16, 32, 32]))
layer /input.28 start_node /input.48 using sparse-spec alpha with unstable size 7 total_size 4096 output_shape (64, 8, 8)
layer /input.28 start_node /input.52 using sparse-spec alpha with unstable size 46 total_size 1000 output_shape torch.Size([1000])
layer /input.28 start_node /67 using full alpha with unstable size None total_size 9 output_shape 9
layer /input.32 using sparse-features alpha with shape [0]; unstable size 0; total size 8192 (torch.Size([1, 32, 16, 16]))
layer /input.32 start_node /input.48 using sparse-spec alpha with unstable size 7 total_size 4096 output_shape (64, 8, 8)
layer /input.32 start_node /input.52 using sparse-spec alpha with unstable size 46 total_size 1000 output_shape torch.Size([1000])
layer /input.32 start_node /67 using full alpha with unstable size None total_size 9 output_shape 9
layer /input.40 using sparse-features alpha with shape [0]; unstable size 0; total size 8192 (torch.Size([1, 32, 16, 16]))
layer /input.40 start_node /input.48 using sparse-spec alpha with unstable size 7 total_size 4096 output_shape (64, 8, 8)
layer /input.40 start_node /input.52 using sparse-spec alpha with unstable size 46 total_size 1000 output_shape torch.Size([1000])
layer /input.40 start_node /67 using full alpha with unstable size None total_size 9 output_shape 9
layer /input.44 using sparse-features alpha with shape [0]; unstable size 0; total size 4096 (torch.Size([1, 64, 8, 8]))
layer /input.44 start_node /input.48 using sparse-spec alpha with unstable size 7 total_size 4096 output_shape (64, 8, 8)
layer /input.44 start_node /input.52 using sparse-spec alpha with unstable size 46 total_size 1000 output_shape torch.Size([1000])
layer /input.44 start_node /67 using full alpha with unstable size None total_size 9 output_shape 9
layer /56 using sparse-features alpha with shape [7]; unstable size 7; total size 4096 (torch.Size([1, 64, 8, 8]))
layer /56 start_node /input.52 using sparse-spec alpha with unstable size 46 total_size 1000 output_shape torch.Size([1000])
layer /56 start_node /67 using full alpha with unstable size None total_size 9 output_shape 9
layer /66 using sparse-features alpha with shape [46]; unstable size 46; total size 1000 (torch.Size([1, 1000]))
layer /66 start_node /67 using full alpha with unstable size None total_size 9 output_shape 9
Optimizable variables initialized.
initial CROWN bounds: tensor([[ 0.79195005,  0.05841732,  0.16422272,  0.04038174,  0.26246753,
         -0.00224346,  0.10815085,  0.55881691,  0.13666284]], device='cuda:0') None

all verified at 2th iter
best_l after optimization: 2.147946834564209 with beta sum per layer: []
alpha/beta optimization time: 4.081631422042847
initial alpha-CROWN bounds: tensor([[0.79460853, 0.06122690, 0.16644675, 0.04168467, 0.26584730, 0.00162518,
         0.11085552, 0.56245148, 0.14320040]], device='cuda:0')
Worst class: (+ rhs) 0.0016251802444458008
verified with init bound!
Result: safe-incomplete in 12.9997 seconds
############# Summary #############
Final verified acc: 100.0% [total 1 examples]
Total verification count: 1 , total verified safe: 1 , verified unsafe: 0 , timeout: 0
mean time [1] 12.999659299850464 max time 12.999659299850464
safe-incomplete (total 1): [0]
