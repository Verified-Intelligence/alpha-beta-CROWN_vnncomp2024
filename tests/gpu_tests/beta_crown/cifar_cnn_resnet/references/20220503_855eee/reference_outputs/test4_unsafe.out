Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_resnet_8px.pth
  name: model_resnet
data:
  start: 240
  end: 241
  num_outputs: 10
  mean: [0.485, 0.456, 0.406]
  std: [0.225, 0.225, 0.225]
  pkl_path: null
  dataset: CIFAR
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.03137254901
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 8
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 180
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:40:43 2022 on diablo.cs.ucla.edu
DenseSequential(
  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): ReLU()
  (2): Dense(
    (Ws): ModuleList(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (3): ReLU()
  (4): Dense(
    (Ws): ModuleList(
      (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))
      (1): None
      (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (5): ReLU()
  (6): Dense(
    (Ws): ModuleList(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (7): ReLU()
  (8): Dense(
    (Ws): ModuleList(
      (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))
      (1): None
      (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (9): ReLU()
  (10): Dense(
    (Ws): ModuleList(
      (0): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
  )
  (11): ReLU()
  (12): Dense(
    (Ws): ModuleList(
      (0): Conv2d(16, 32, kernel_size=(2, 2), stride=(2, 2))
      (1): None
      (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (13): ReLU()
  (14): Dense(
    (Ws): ModuleList(
      (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
  )
  (15): ReLU()
  (16): Dense(
    (Ws): ModuleList(
      (0): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): None
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (17): ReLU()
  (18): Flatten()
  (19): Linear(in_features=4096, out_features=1000, bias=True)
  (20): ReLU()
  (21): Linear(in_features=1000, out_features=10, bias=True)
)
Trying generic MNIST/CIFAR data loader.
Files already downloaded and verified
epsilon after preprocessing: tensor([[[[0.1394]],

         [[0.1394]],

         [[0.1394]]]]), data_max = tensor([[[[2.2889]],

         [[2.4178]],

         [[2.6400]]]]), data_min = tensor([[[[-2.1556]],

         [[-2.0267]],

         [[-1.8044]]]])
Task length: 1
saving results to Verified_ret_[model_resnet]_start=240_end=241_iter=20_b=8_timeout=180_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 240 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 1, correct label 1, image norm 3302.126953125, logits tensor([-0.3165,  0.5765, -0.0974,  0.1644, -0.3322,  0.4914, -0.1023,  0.0288,
        -0.1340, -0.2788], device='cuda:0', grad_fn=<SelectBackward>)
Model prediction is: tensor([[-0.3165,  0.5765, -0.0974,  0.1644, -0.3322,  0.4914, -0.1023,  0.0288,
         -0.1340, -0.2788]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 0.8608,  0.5694,  0.3254,  0.7893, -0.0091,  0.5403,  0.4903,  0.6574,
          0.7666]], device='cuda:0') None
best_l after optimization: -5.042444229125977 with beta sum per layer: []
alpha/beta optimization time: 32.71456789970398
initial alpha-CROWN bounds: tensor([[ 0.8639,  0.5786,  0.3295,  0.8001, -0.0054,  0.5550,  0.4923,  0.6589,
          0.7696]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.0054, device='cuda:0', grad_fn=<MinBackward1>)
##### [0:240] Tested against 5 ######
Model prediction is: tensor([[-0.3165,  0.5765, -0.0974,  0.1644, -0.3322,  0.4914, -0.1023,  0.0288,
         -0.1340, -0.2788]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /32 start_node /41
setting alpha for layer /32 start_node /45
setting alpha for layer /32 start_node /51
setting alpha for layer /32 start_node /71
setting alpha for layer /32 start_node /81
not setting layer /32 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 16, 32, 32]) != torch.Size([2, 9, 1, 16, 32, 32]))
setting alpha for layer /36 start_node /41
setting alpha for layer /36 start_node /45
setting alpha for layer /36 start_node /51
setting alpha for layer /36 start_node /71
setting alpha for layer /36 start_node /81
not setting layer /36 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 16, 32, 32]) != torch.Size([2, 9, 1, 16, 32, 32]))
setting alpha for layer /42 start_node /45
setting alpha for layer /42 start_node /51
setting alpha for layer /42 start_node /71
setting alpha for layer /42 start_node /81
not setting layer /42 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 16, 32, 32]) != torch.Size([2, 9, 1, 16, 32, 32]))
setting alpha for layer /46 start_node /51
setting alpha for layer /46 start_node /71
setting alpha for layer /46 start_node /81
not setting layer /46 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 16, 32, 32]) != torch.Size([2, 9, 1, 16, 32, 32]))
setting alpha for layer /52 start_node /71
setting alpha for layer /52 start_node /81
not setting layer /52 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 16, 32, 32]) != torch.Size([2, 9, 1, 16, 32, 32]))
setting alpha for layer /56 start_node /71
setting alpha for layer /56 start_node /81
not setting layer /56 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /62 start_node /71
setting alpha for layer /62 start_node /81
not setting layer /62 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /66 start_node /71
setting alpha for layer /66 start_node /81
not setting layer /66 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 64, 8, 8]) != torch.Size([2, 9, 1, 64, 8, 8]))
setting alpha for layer /72 start_node /81
not setting layer /72 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 64, 8, 8]) != torch.Size([2, 9, 1, 64, 8, 8]))
not setting layer /82 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 1000]) != torch.Size([2, 9, 1, 1000]))
0 /31 torch.Size([1, 16, 32, 32])
1 /35 torch.Size([1, 16, 32, 32])
2 /41 torch.Size([1, 16, 32, 32])
3 /45 torch.Size([1, 16, 32, 32])
4 /51 torch.Size([1, 16, 32, 32])
5 /55 torch.Size([1, 32, 16, 16])
6 /61 torch.Size([1, 32, 16, 16])
7 /65 torch.Size([1, 64, 8, 8])
8 /71 torch.Size([1, 64, 8, 8])
9 /81 torch.Size([1, 1000])
best_l after optimization: 0.005426362156867981 with beta sum per layer: []
alpha/beta optimization time: 4.9546403884887695
alpha-CROWN with fixed intermediate bounds: tensor([[-0.0054]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.005426362156867981
layer 0 size torch.Size([16384]) unstable 1631
layer 1 size torch.Size([16384]) unstable 0
layer 2 size torch.Size([16384]) unstable 319
layer 3 size torch.Size([16384]) unstable 12
layer 4 size torch.Size([16384]) unstable 45
layer 5 size torch.Size([8192]) unstable 0
layer 6 size torch.Size([8192]) unstable 0
layer 7 size torch.Size([4096]) unstable 0
layer 8 size torch.Size([4096]) unstable 1
layer 9 size torch.Size([1000]) unstable 25
-----------------
# of unstable neurons: 2033
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([1, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3473] 
regular batch size: 2*1, diving batch size 1*0
best_l after optimization: 0.005332590080797672 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0009080885211005807, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.694732666015625
This batch time : update_bounds func: 0.7012	 prepare: 0.0035	 bound: 0.6953	 transfer: 0.0018	 finalize: 0.0006
Accumulated time: update_bounds func: 0.7012	 prepare: 0.0035	 bound: 0.6953	 transfer: 0.0018	 finalize: 0.0006
batch bounding time:  0.7014768123626709
Current worst splitting domains [lb, ub] (depth):
[-0.00536,   inf] (2), 
length of domains: 1
Total time: 0.7739	 pickout: 0.0023	 decision: 0.0699	 get_bound: 0.7015	 add_domain: 0.0002
Current lb:-0.0053628915920853615
2 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.726808786392212

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([1, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3475] 
regular batch size: 2*1, diving batch size 1*0
best_l after optimization: 0.003324860241264105 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.7022216320037842
This batch time : update_bounds func: 0.7090	 prepare: 0.0035	 bound: 0.7028	 transfer: 0.0019	 finalize: 0.0008
Accumulated time: update_bounds func: 1.4102	 prepare: 0.0070	 bound: 1.3982	 transfer: 0.0019	 finalize: 0.0014
batch bounding time:  0.7093310356140137
Current worst splitting domains [lb, ub] (depth):
[-0.00528,   inf] (4), 
length of domains: 1
Total time: 0.7770	 pickout: 0.0024	 decision: 0.0650	 get_bound: 0.7093	 add_domain: 0.0002
Current lb:-0.005283903330564499
4 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.503998517990112

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([1, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 527] 
regular batch size: 2*1, diving batch size 1*0
best_l after optimization: 0.008042516186833382 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016629023477435112]
alpha/beta optimization time: 0.7866950035095215
This batch time : update_bounds func: 0.7934	 prepare: 0.0036	 bound: 0.7873	 transfer: 0.0018	 finalize: 0.0007
Accumulated time: update_bounds func: 2.2036	 prepare: 0.0105	 bound: 2.1854	 transfer: 0.0018	 finalize: 0.0021
batch bounding time:  0.7936351299285889
Current worst splitting domains [lb, ub] (depth):
[-0.00412,   inf] (6), [-0.00392,   inf] (6), 
length of domains: 2
Total time: 0.8625	 pickout: 0.0024	 decision: 0.0662	 get_bound: 0.7936	 add_domain: 0.0003
Current lb:-0.004122775048017502
6 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.366753101348877

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([2, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3474] [4, 3474] 
regular batch size: 2*2, diving batch size 1*0
best_l after optimization: -0.0010995334014296532 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17849256098270416]
alpha/beta optimization time: 0.7167279720306396
This batch time : update_bounds func: 0.7250	 prepare: 0.0041	 bound: 0.7174	 transfer: 0.0024	 finalize: 0.0012
Accumulated time: update_bounds func: 2.9286	 prepare: 0.0147	 bound: 2.9028	 transfer: 0.0024	 finalize: 0.0032
batch bounding time:  0.7253313064575195
Current worst splitting domains [lb, ub] (depth):
[-0.00410,   inf] (8), [-0.00388,   inf] (8), 
length of domains: 2
Total time: 0.7986	 pickout: 0.0033	 decision: 0.0697	 get_bound: 0.7254	 add_domain: 0.0003
Current lb:-0.004096883814781904
10 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.165607213973999

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([2, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 514] [9, 514] 
regular batch size: 2*2, diving batch size 1*0
best_l after optimization: -0.0033067669719457626 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32166820764541626]
alpha/beta optimization time: 0.7328948974609375
This batch time : update_bounds func: 0.7411	 prepare: 0.0040	 bound: 0.7335	 transfer: 0.0024	 finalize: 0.0011
Accumulated time: update_bounds func: 3.6697	 prepare: 0.0187	 bound: 3.6363	 transfer: 0.0024	 finalize: 0.0043
batch bounding time:  0.7413637638092041
Current worst splitting domains [lb, ub] (depth):
[-0.00394,   inf] (10), [-0.00359,   inf] (10), 
length of domains: 2
Total time: 0.8125	 pickout: 0.0034	 decision: 0.0674	 get_bound: 0.7414	 add_domain: 0.0003
Current lb:-0.003935725893825293
14 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.97831130027771

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([2, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [0, 7816] [0, 7816] 
regular batch size: 2*2, diving batch size 1*0
best_l after optimization: 0.012971943244338036 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3474867045879364]
alpha/beta optimization time: 0.804147481918335
This batch time : update_bounds func: 0.8126	 prepare: 0.0041	 bound: 0.8047	 transfer: 0.0024	 finalize: 0.0014
Accumulated time: update_bounds func: 4.4823	 prepare: 0.0228	 bound: 4.4410	 transfer: 0.0024	 finalize: 0.0057
batch bounding time:  0.8129053115844727
Current worst splitting domains [lb, ub] (depth):
[-0.00391,   inf] (12), [-0.00352,   inf] (12), [-0.00305,   inf] (12), [-0.00250,   inf] (12), 
length of domains: 4
Total time: 0.8835	 pickout: 0.0035	 decision: 0.0667	 get_bound: 0.8130	 add_domain: 0.0004
Current lb:-0.0039062199648469687
18 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.86202359199524

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([4, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3466] [8, 3276] [4, 3466] [4, 3463] 
regular batch size: 2*4, diving batch size 1*0
best_l after optimization: 0.01784825697541237 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0003077335422858596, 0.0, 0.0, 0.0, 0.0, 0.6624178886413574]
alpha/beta optimization time: 0.8423192501068115
This batch time : update_bounds func: 0.8536	 prepare: 0.0053	 bound: 0.8430	 transfer: 0.0035	 finalize: 0.0018
Accumulated time: update_bounds func: 5.3359	 prepare: 0.0281	 bound: 5.2840	 transfer: 0.0035	 finalize: 0.0075
batch bounding time:  0.8539605140686035
Current worst splitting domains [lb, ub] (depth):
[-0.00390,   inf] (14), [-0.00352,   inf] (14), [-0.00304,   inf] (14), [-0.00234,   inf] (14), [-0.00201,   inf] (14), [-0.00195,   inf] (14), [-0.00109,   inf] (14), 
length of domains: 7
Total time: 0.9395	 pickout: 0.0051	 decision: 0.0797	 get_bound: 0.8540	 add_domain: 0.0007
Current lb:-0.0038980317767709494
26 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.801880121231079

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([7, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([7, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3463] [9, 797] [4, 3463] [9, 797] [9, 797] [4, 3463] [4, 3463] 
regular batch size: 2*7, diving batch size 1*0
best_l after optimization: 0.017357518896460533 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 9.066513302968815e-05, 0.0, 0.0, 0.0, 0.0, 3.0981287956237793]
alpha/beta optimization time: 0.9210474491119385
This batch time : update_bounds func: 0.9413	 prepare: 0.0068	 bound: 0.9217	 transfer: 0.0084	 finalize: 0.0043
Accumulated time: update_bounds func: 6.2772	 prepare: 0.0349	 bound: 6.2057	 transfer: 0.0084	 finalize: 0.0118
batch bounding time:  0.9416167736053467
Current worst splitting domains [lb, ub] (depth):
[-0.00387,   inf] (16), [-0.00344,   inf] (16), [-0.00335,   inf] (16), [-0.00301,   inf] (16), [-0.00258,   inf] (16), [-0.00205,   inf] (16), [-0.00192,   inf] (16), [-0.00179,   inf] (16), [-0.00149,   inf] (16), [-0.00106,   inf] (16), [-0.00063,   inf] (16), 
length of domains: 11
Total time: 1.0270	 pickout: 0.0080	 decision: 0.0763	 get_bound: 0.9417	 add_domain: 0.0010
Current lb:-0.0038703354075551033
40 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.82933235168457

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 797] [9, 797] [4, 3463] [9, 797] [9, 797] [8, 3276] [9, 797] [8, 3276] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.025936851277947426 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.00011149443889735267, 0.0, 0.0, 0.0, 0.0, 3.0202810764312744]
alpha/beta optimization time: 0.9227426052093506
This batch time : update_bounds func: 0.9495	 prepare: 0.0108	 bound: 0.9235	 transfer: 0.0116	 finalize: 0.0034
Accumulated time: update_bounds func: 7.2267	 prepare: 0.0457	 bound: 7.1292	 transfer: 0.0116	 finalize: 0.0152
batch bounding time:  0.9498286247253418
Current worst splitting domains [lb, ub] (depth):
[-0.00358,   inf] (18), [-0.00333,   inf] (18), [-0.00315,   inf] (18), [-0.00292,   inf] (18), [-0.00280,   inf] (18), [-0.00272,   inf] (18), [-0.00232,   inf] (18), [-0.00229,   inf] (18), [-0.00202,   inf] (18), [-0.00192,   inf] (18), [-0.00172,   inf] (18), [-0.00163,   inf] (18), [-0.00153,   inf] (18), [-0.00149,   inf] (16), [-0.00106,   inf] (16), [-0.00070,   inf] (18), [-0.00063,   inf] (16), 
length of domains: 17
Total time: 1.0537	 pickout: 0.0114	 decision: 0.0911	 get_bound: 0.9499	 add_domain: 0.0013
Current lb:-0.0035792961716651917
56 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.883541107177734

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 833] [9, 833] [9, 833] [9, 833] [9, 768] [9, 833] [9, 768] [9, 833] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.011533823795616627 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.87239933013916]
alpha/beta optimization time: 0.8839740753173828
This batch time : update_bounds func: 0.9153	 prepare: 0.0071	 bound: 0.8846	 transfer: 0.0199	 finalize: 0.0035
Accumulated time: update_bounds func: 8.1419	 prepare: 0.0528	 bound: 8.0139	 transfer: 0.0199	 finalize: 0.0188
batch bounding time:  0.915726900100708
Current worst splitting domains [lb, ub] (depth):
[-0.00343,   inf] (20), [-0.00311,   inf] (20), [-0.00300,   inf] (20), [-0.00270,   inf] (20), [-0.00262,   inf] (20), [-0.00257,   inf] (20), [-0.00215,   inf] (20), [-0.00214,   inf] (20), [-0.00202,   inf] (18), [-0.00192,   inf] (18), [-0.00172,   inf] (18), [-0.00163,   inf] (18), [-0.00153,   inf] (18), [-0.00149,   inf] (16), [-0.00106,   inf] (16), [-0.00070,   inf] (18), [-0.00063,   inf] (16), 
length of domains: 17
Total time: 1.0021	 pickout: 0.0099	 decision: 0.0756	 get_bound: 0.9158	 add_domain: 0.0009
Current lb:-0.0034286335576325655
72 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.886292457580566

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 768] [9, 768] [9, 768] [9, 768] [9, 931] [9, 768] [9, 931] [9, 768] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.008687375113368034 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.912003993988037]
alpha/beta optimization time: 0.8765237331390381
This batch time : update_bounds func: 0.9060	 prepare: 0.0071	 bound: 0.8771	 transfer: 0.0184	 finalize: 0.0033
Accumulated time: update_bounds func: 9.0480	 prepare: 0.0599	 bound: 8.8910	 transfer: 0.0184	 finalize: 0.0221
batch bounding time:  0.9063282012939453
Current worst splitting domains [lb, ub] (depth):
[-0.00327,   inf] (22), [-0.00298,   inf] (22), [-0.00283,   inf] (22), [-0.00256,   inf] (22), [-0.00248,   inf] (22), [-0.00241,   inf] (22), [-0.00202,   inf] (18), [-0.00200,   inf] (22), [-0.00197,   inf] (22), [-0.00192,   inf] (18), [-0.00172,   inf] (18), [-0.00163,   inf] (18), [-0.00153,   inf] (18), [-0.00149,   inf] (16), [-0.00106,   inf] (16), [-0.00070,   inf] (18), [-0.00063,   inf] (16), 
length of domains: 17
Total time: 0.9919	 pickout: 0.0089	 decision: 0.0758	 get_bound: 0.9064	 add_domain: 0.0009
Current lb:-0.003267785767093301
88 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.878745794296265

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 931] [9, 931] [9, 931] [9, 931] [9, 833] [9, 931] [9, 768] [9, 833] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.02156907692551613 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0712175369262695]
alpha/beta optimization time: 0.8695242404937744
This batch time : update_bounds func: 0.8908	 prepare: 0.0071	 bound: 0.8701	 transfer: 0.0098	 finalize: 0.0038
Accumulated time: update_bounds func: 9.9388	 prepare: 0.0670	 bound: 9.7611	 transfer: 0.0098	 finalize: 0.0258
batch bounding time:  0.8911895751953125
Current worst splitting domains [lb, ub] (depth):
[-0.00311,   inf] (24), [-0.00280,   inf] (24), [-0.00268,   inf] (24), [-0.00239,   inf] (24), [-0.00236,   inf] (24), [-0.00225,   inf] (24), [-0.00223,   inf] (24), [-0.00203,   inf] (24), [-0.00197,   inf] (22), [-0.00192,   inf] (18), [-0.00188,   inf] (24), [-0.00183,   inf] (20), [-0.00175,   inf] (24), [-0.00172,   inf] (18), [-0.00163,   inf] (18), [-0.00158,   inf] (24), [-0.00153,   inf] (18), [-0.00149,   inf] (16), [-0.00116,   inf] (24), [-0.00106,   inf] (16), 
length of domains: 22
Total time: 0.9769	 pickout: 0.0088	 decision: 0.0756	 get_bound: 0.8913	 add_domain: 0.0013
Current lb:-0.003111526370048523
104 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.856119394302368

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 415] [9, 415] [9, 415] [9, 415] [9, 415] [9, 415] [9, 415] [9, 415] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.030274782329797745 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10.88060474395752]
alpha/beta optimization time: 0.875880241394043
This batch time : update_bounds func: 0.9070	 prepare: 0.0072	 bound: 0.8765	 transfer: 0.0198	 finalize: 0.0035
Accumulated time: update_bounds func: 10.8458	 prepare: 0.0742	 bound: 10.6376	 transfer: 0.0198	 finalize: 0.0293
batch bounding time:  0.9074020385742188
Current worst splitting domains [lb, ub] (depth):
[-0.00297,   inf] (26), [-0.00263,   inf] (26), [-0.00257,   inf] (26), [-0.00254,   inf] (26), [-0.00239,   inf] (26), [-0.00223,   inf] (26), [-0.00222,   inf] (26), [-0.00214,   inf] (26), [-0.00211,   inf] (26), [-0.00199,   inf] (26), [-0.00197,   inf] (22), [-0.00192,   inf] (18), [-0.00188,   inf] (24), [-0.00183,   inf] (20), [-0.00175,   inf] (24), [-0.00172,   inf] (18), [-0.00171,   inf] (26), [-0.00163,   inf] (18), [-0.00158,   inf] (24), [-0.00153,   inf] (18), 
length of domains: 29
Total time: 0.9953	 pickout: 0.0099	 decision: 0.0762	 get_bound: 0.9075	 add_domain: 0.0016
Current lb:-0.002972938120365143
120 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.851914405822754

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3477] [4, 3466] [8, 3276] [4, 3477] [9, 340] [4, 3477] [4, 3466] [8, 3276] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.0006845779716968536 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.559330940246582]
alpha/beta optimization time: 0.879286527633667
This batch time : update_bounds func: 0.9102	 prepare: 0.0074	 bound: 0.8799	 transfer: 0.0194	 finalize: 0.0034
Accumulated time: update_bounds func: 11.7561	 prepare: 0.0817	 bound: 11.5176	 transfer: 0.0194	 finalize: 0.0327
batch bounding time:  0.9105868339538574
Current worst splitting domains [lb, ub] (depth):
[-0.00297,   inf] (28), [-0.00263,   inf] (28), [-0.00253,   inf] (28), [-0.00229,   inf] (28), [-0.00222,   inf] (28), [-0.00221,   inf] (28), [-0.00211,   inf] (26), [-0.00199,   inf] (26), [-0.00197,   inf] (22), [-0.00192,   inf] (18), [-0.00188,   inf] (24), [-0.00187,   inf] (28), [-0.00183,   inf] (20), [-0.00180,   inf] (28), [-0.00175,   inf] (24), [-0.00172,   inf] (18), [-0.00171,   inf] (26), [-0.00163,   inf] (18), [-0.00158,   inf] (24), [-0.00153,   inf] (18), 
length of domains: 32
Total time: 1.0013	 pickout: 0.0099	 decision: 0.0760	 get_bound: 0.9106	 add_domain: 0.0048
Current lb:-0.0029663890600204468
136 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.854259729385376

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2453] [9, 340] [2, 2453] [4, 3477] [2, 2453] [9, 340] [4, 3477] [9, 340] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.004055038094520569 with beta sum per layer: [0.0, 0.0, 0.2025679647922516, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.770075798034668]
alpha/beta optimization time: 0.9316842555999756
This batch time : update_bounds func: 0.9667	 prepare: 0.0111	 bound: 0.9325	 transfer: 0.0196	 finalize: 0.0034
Accumulated time: update_bounds func: 12.7228	 prepare: 0.0928	 bound: 12.4501	 transfer: 0.0196	 finalize: 0.0361
batch bounding time:  0.9670965671539307
Current worst splitting domains [lb, ub] (depth):
[-0.00296,   inf] (30), [-0.00253,   inf] (30), [-0.00252,   inf] (30), [-0.00221,   inf] (30), [-0.00216,   inf] (30), [-0.00211,   inf] (28), [-0.00210,   inf] (30), [-0.00197,   inf] (22), [-0.00192,   inf] (18), [-0.00188,   inf] (24), [-0.00187,   inf] (28), [-0.00183,   inf] (20), [-0.00180,   inf] (28), [-0.00175,   inf] (24), [-0.00172,   inf] (18), [-0.00171,   inf] (30), [-0.00171,   inf] (26), [-0.00163,   inf] (18), [-0.00158,   inf] (24), [-0.00153,   inf] (18), 
length of domains: 35
Total time: 1.0873	 pickout: 0.0159	 decision: 0.1029	 get_bound: 0.9671	 add_domain: 0.0014
Current lb:-0.002961456775665283
152 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 19.94211721420288

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2450] [2, 2450] [4, 3477] [9, 340] [9, 340] [2, 2453] [4, 3477] [9, 931] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.008130403235554695 with beta sum per layer: [0.0, 0.0, 0.2508698105812073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.260312080383301]
alpha/beta optimization time: 0.8960306644439697
This batch time : update_bounds func: 0.9258	 prepare: 0.0076	 bound: 0.8967	 transfer: 0.0182	 finalize: 0.0033
Accumulated time: update_bounds func: 13.6486	 prepare: 0.1004	 bound: 13.3467	 transfer: 0.0182	 finalize: 0.0395
batch bounding time:  0.9261667728424072
Current worst splitting domains [lb, ub] (depth):
[-0.00296,   inf] (32), [-0.00252,   inf] (32), [-0.00251,   inf] (32), [-0.00211,   inf] (32), [-0.00210,   inf] (30), [-0.00209,   inf] (32), [-0.00204,   inf] (32), [-0.00192,   inf] (18), [-0.00188,   inf] (24), [-0.00187,   inf] (28), [-0.00183,   inf] (20), [-0.00182,   inf] (24), [-0.00180,   inf] (28), [-0.00175,   inf] (24), [-0.00172,   inf] (18), [-0.00171,   inf] (30), [-0.00171,   inf] (26), [-0.00163,   inf] (18), [-0.00158,   inf] (24), [-0.00153,   inf] (18), 
length of domains: 39
Total time: 1.0128	 pickout: 0.0088	 decision: 0.0764	 get_bound: 0.9262	 add_domain: 0.0014
Current lb:-0.0029569119215011597
168 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 20.955552577972412

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 340] [9, 340] [2, 2453] [2, 2450] [2, 2450] [2, 2453] [2, 2453] [9, 833] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.010099820792675018 with beta sum per layer: [0.0, 0.0, 0.3671243190765381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.1542277336120605]
alpha/beta optimization time: 0.880993127822876
This batch time : update_bounds func: 0.9023	 prepare: 0.0076	 bound: 0.8817	 transfer: 0.0096	 finalize: 0.0033
Accumulated time: update_bounds func: 14.5509	 prepare: 0.1080	 bound: 14.2284	 transfer: 0.0096	 finalize: 0.0428
batch bounding time:  0.9025969505310059
Current worst splitting domains [lb, ub] (depth):
[-0.00285,   inf] (34), [-0.00251,   inf] (34), [-0.00241,   inf] (34), [-0.00211,   inf] (34), [-0.00210,   inf] (32), [-0.00209,   inf] (34), [-0.00204,   inf] (34), [-0.00189,   inf] (34), [-0.00188,   inf] (24), [-0.00187,   inf] (28), [-0.00183,   inf] (20), [-0.00182,   inf] (24), [-0.00180,   inf] (28), [-0.00175,   inf] (24), [-0.00172,   inf] (18), [-0.00171,   inf] (30), [-0.00171,   inf] (26), [-0.00165,   inf] (20), [-0.00163,   inf] (18), [-0.00160,   inf] (34), 
length of domains: 41
Total time: 0.9889	 pickout: 0.0089	 decision: 0.0762	 get_bound: 0.9027	 add_domain: 0.0012
Current lb:-0.002850867807865143
184 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 21.944981575012207

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2454] [2, 2450] [2, 2454] [8, 3276] [9, 340] [2, 2450] [2, 2454] [2, 2454] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.009574620053172112 with beta sum per layer: [0.0, 0.0, 0.42656707763671875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.417660713195801]
alpha/beta optimization time: 0.8729960918426514
This batch time : update_bounds func: 0.9044	 prepare: 0.0076	 bound: 0.8737	 transfer: 0.0197	 finalize: 0.0034
Accumulated time: update_bounds func: 15.4553	 prepare: 0.1156	 bound: 15.1021	 transfer: 0.0197	 finalize: 0.0462
batch bounding time:  0.9047794342041016
Current worst splitting domains [lb, ub] (depth):
[-0.00285,   inf] (36), [-0.00250,   inf] (36), [-0.00241,   inf] (36), [-0.00210,   inf] (36), [-0.00208,   inf] (36), [-0.00204,   inf] (36), [-0.00199,   inf] (34), [-0.00188,   inf] (24), [-0.00187,   inf] (28), [-0.00183,   inf] (20), [-0.00182,   inf] (24), [-0.00180,   inf] (28), [-0.00175,   inf] (24), [-0.00172,   inf] (18), [-0.00171,   inf] (30), [-0.00171,   inf] (26), [-0.00165,   inf] (20), [-0.00163,   inf] (18), [-0.00160,   inf] (34), [-0.00158,   inf] (24), 
length of domains: 44
Total time: 0.9924	 pickout: 0.0101	 decision: 0.0762	 get_bound: 0.9048	 add_domain: 0.0013
Current lb:-0.002848297357559204
200 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 22.937933921813965

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3478] [2, 3720] [4, 3478] [2, 2454] [2, 3720] [4, 3478] [2, 2454] [9, 415] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.002351822331547737 with beta sum per layer: [0.0, 0.0, 0.12224519997835159, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.340619087219238]
alpha/beta optimization time: 0.8810429573059082
This batch time : update_bounds func: 0.9129	 prepare: 0.0081	 bound: 0.8817	 transfer: 0.0196	 finalize: 0.0034
Accumulated time: update_bounds func: 16.3682	 prepare: 0.1237	 bound: 15.9838	 transfer: 0.0196	 finalize: 0.0496
batch bounding time:  0.9132707118988037
Current worst splitting domains [lb, ub] (depth):
[-0.00285,   inf] (38), [-0.00250,   inf] (38), [-0.00241,   inf] (38), [-0.00210,   inf] (38), [-0.00208,   inf] (38), [-0.00203,   inf] (38), [-0.00199,   inf] (36), [-0.00187,   inf] (28), [-0.00183,   inf] (20), [-0.00182,   inf] (24), [-0.00180,   inf] (28), [-0.00175,   inf] (24), [-0.00175,   inf] (26), [-0.00172,   inf] (18), [-0.00171,   inf] (30), [-0.00171,   inf] (26), [-0.00171,   inf] (38), [-0.00165,   inf] (20), [-0.00163,   inf] (18), [-0.00160,   inf] (34), 
length of domains: 46
Total time: 1.0021	 pickout: 0.0101	 decision: 0.0774	 get_bound: 0.9133	 add_domain: 0.0013
Current lb:-0.0028472095727920532
216 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 23.94057559967041

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [8, 3276] [2, 2454] [8, 3276] [4, 3478] [2, 2454] [4, 3340] [4, 3478] [4, 3477] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.0035020895302295685 with beta sum per layer: [0.0, 0.0, 0.11302777379751205, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.659279823303223]
alpha/beta optimization time: 0.8205325603485107
This batch time : update_bounds func: 0.8519	 prepare: 0.0077	 bound: 0.8212	 transfer: 0.0197	 finalize: 0.0033
Accumulated time: update_bounds func: 17.2202	 prepare: 0.1314	 bound: 16.8049	 transfer: 0.0197	 finalize: 0.0529
batch bounding time:  0.8522381782531738
Current worst splitting domains [lb, ub] (depth):
[-0.00285,   inf] (40), [-0.00250,   inf] (40), [-0.00241,   inf] (40), [-0.00210,   inf] (40), [-0.00208,   inf] (40), [-0.00203,   inf] (40), [-0.00203,   inf] (40), [-0.00199,   inf] (38), [-0.00183,   inf] (20), [-0.00182,   inf] (24), [-0.00180,   inf] (28), [-0.00175,   inf] (24), [-0.00175,   inf] (26), [-0.00172,   inf] (18), [-0.00172,   inf] (30), [-0.00171,   inf] (30), [-0.00171,   inf] (26), [-0.00171,   inf] (38), [-0.00165,   inf] (20), [-0.00163,   inf] (18), 
length of domains: 47
Total time: 0.9401	 pickout: 0.0100	 decision: 0.0767	 get_bound: 0.8523	 add_domain: 0.0012
Current lb:-0.00284702330827713
232 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 24.881206512451172

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 675] [4, 3478] [9, 675] [4, 3620] [4, 3478] [9, 675] [9, 675] [8, 3276] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.07928986847400665 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.23732653260231018, 0.0, 0.0, 0.0, 0.0, 9.210256576538086]
alpha/beta optimization time: 0.8862459659576416
This batch time : update_bounds func: 0.9180	 prepare: 0.0078	 bound: 0.8869	 transfer: 0.0197	 finalize: 0.0035
Accumulated time: update_bounds func: 18.1381	 prepare: 0.1392	 bound: 17.6918	 transfer: 0.0197	 finalize: 0.0563
batch bounding time:  0.9183213710784912
Current worst splitting domains [lb, ub] (depth):
[-0.00285,   inf] (42), [-0.00250,   inf] (42), [-0.00241,   inf] (42), [-0.00210,   inf] (42), [-0.00208,   inf] (42), [-0.00203,   inf] (42), [-0.00203,   inf] (42), [-0.00199,   inf] (40), [-0.00183,   inf] (20), [-0.00182,   inf] (24), [-0.00180,   inf] (28), [-0.00175,   inf] (24), [-0.00175,   inf] (26), [-0.00174,   inf] (42), [-0.00172,   inf] (18), [-0.00172,   inf] (30), [-0.00171,   inf] (30), [-0.00171,   inf] (26), [-0.00171,   inf] (38), [-0.00165,   inf] (20), 
length of domains: 48
Total time: 1.0072	 pickout: 0.0099	 decision: 0.0777	 get_bound: 0.9184	 add_domain: 0.0012
Current lb:-0.00284702330827713
248 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 25.889086484909058

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3757] [9, 675] [4, 3340] [9, 675] [9, 675] [9, 664] [9, 664] [9, 675] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.10731446743011475 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.37474125623703003, 0.0, 0.0, 0.0, 0.0243690125644207, 9.882591247558594]
alpha/beta optimization time: 0.861752986907959
This batch time : update_bounds func: 0.8928	 prepare: 0.0076	 bound: 0.8624	 transfer: 0.0195	 finalize: 0.0033
Accumulated time: update_bounds func: 19.0310	 prepare: 0.1469	 bound: 18.5542	 transfer: 0.0195	 finalize: 0.0596
batch bounding time:  0.8931515216827393
Current worst splitting domains [lb, ub] (depth):
[-0.00285,   inf] (44), [-0.00250,   inf] (44), [-0.00241,   inf] (44), [-0.00241,   inf] (44), [-0.00210,   inf] (44), [-0.00209,   inf] (44), [-0.00208,   inf] (44), [-0.00203,   inf] (44), [-0.00203,   inf] (44), [-0.00199,   inf] (42), [-0.00183,   inf] (20), [-0.00182,   inf] (24), [-0.00180,   inf] (28), [-0.00175,   inf] (24), [-0.00175,   inf] (26), [-0.00174,   inf] (42), [-0.00172,   inf] (18), [-0.00172,   inf] (30), [-0.00171,   inf] (30), [-0.00171,   inf] (26), 
length of domains: 50
Total time: 0.9808	 pickout: 0.0099	 decision: 0.0763	 get_bound: 0.8932	 add_domain: 0.0014
Current lb:-0.00284702330827713
264 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 26.87040901184082

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3340] [4, 3340] [9, 664] [9, 664] [4, 3340] [4, 3340] [4, 3340] [4, 3757] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.012690066359937191 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 2.6501355171203613, 0.0, 0.0, 0.0, 0.0, 5.007715225219727]
alpha/beta optimization time: 0.8807845115661621
This batch time : update_bounds func: 0.9129	 prepare: 0.0076	 bound: 0.8814	 transfer: 0.0205	 finalize: 0.0033
Accumulated time: update_bounds func: 19.9438	 prepare: 0.1544	 bound: 19.4356	 transfer: 0.0205	 finalize: 0.0629
batch bounding time:  0.9132223129272461
Current worst splitting domains [lb, ub] (depth):
[-0.00285,   inf] (46), [-0.00285,   inf] (46), [-0.00250,   inf] (46), [-0.00250,   inf] (46), [-0.00241,   inf] (46), [-0.00241,   inf] (46), [-0.00210,   inf] (46), [-0.00210,   inf] (46), [-0.00208,   inf] (46), [-0.00208,   inf] (46), [-0.00203,   inf] (44), [-0.00203,   inf] (46), [-0.00199,   inf] (42), [-0.00193,   inf] (46), [-0.00192,   inf] (46), [-0.00183,   inf] (20), [-0.00182,   inf] (24), [-0.00180,   inf] (28), [-0.00175,   inf] (24), [-0.00175,   inf] (26), 
length of domains: 56
Total time: 1.0016	 pickout: 0.0101	 decision: 0.0758	 get_bound: 0.9133	 add_domain: 0.0024
Current lb:-0.00284702330827713
280 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 27.87247085571289

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 664] [9, 664] [9, 664] [9, 664] [4, 3757] [4, 3757] [9, 664] [9, 664] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.020689552649855614 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.1754000186920166, 0.0, 0.0, 0.0, 0.010556506924331188, 3.5659193992614746]
alpha/beta optimization time: 0.8675591945648193
This batch time : update_bounds func: 0.8990	 prepare: 0.0076	 bound: 0.8682	 transfer: 0.0198	 finalize: 0.0033
Accumulated time: update_bounds func: 20.8428	 prepare: 0.1620	 bound: 20.3038	 transfer: 0.0198	 finalize: 0.0662
batch bounding time:  0.8993122577667236
Current worst splitting domains [lb, ub] (depth):
[-0.00285,   inf] (48), [-0.00285,   inf] (48), [-0.00250,   inf] (48), [-0.00250,   inf] (48), [-0.00241,   inf] (48), [-0.00241,   inf] (48), [-0.00237,   inf] (48), [-0.00210,   inf] (48), [-0.00210,   inf] (48), [-0.00208,   inf] (46), [-0.00208,   inf] (46), [-0.00203,   inf] (44), [-0.00203,   inf] (46), [-0.00199,   inf] (42), [-0.00193,   inf] (46), [-0.00192,   inf] (46), [-0.00183,   inf] (20), [-0.00182,   inf] (24), [-0.00180,   inf] (28), [-0.00175,   inf] (24), 
length of domains: 58
Total time: 0.9877	 pickout: 0.0103	 decision: 0.0767	 get_bound: 0.8994	 add_domain: 0.0014
Current lb:-0.00284702330827713
296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 28.860767126083374

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3756] [4, 3756] [4, 3757] [4, 3757] [4, 3756] [4, 3756] [4, 3756] [4, 3757] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.037951864302158356 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 1.383044719696045, 0.0, 0.0, 0.0, 0.0, 1.2543020248413086]
alpha/beta optimization time: 0.9123296737670898
This batch time : update_bounds func: 0.9435	 prepare: 0.0074	 bound: 0.9130	 transfer: 0.0197	 finalize: 0.0034
Accumulated time: update_bounds func: 21.7863	 prepare: 0.1694	 bound: 21.2168	 transfer: 0.0197	 finalize: 0.0696
batch bounding time:  0.9438660144805908
Current worst splitting domains [lb, ub] (depth):
[-0.00285,   inf] (50), [-0.00285,   inf] (50), [-0.00285,   inf] (50), [-0.00285,   inf] (50), [-0.00250,   inf] (50), [-0.00250,   inf] (50), [-0.00244,   inf] (50), [-0.00241,   inf] (50), [-0.00241,   inf] (50), [-0.00241,   inf] (50), [-0.00241,   inf] (50), [-0.00210,   inf] (48), [-0.00210,   inf] (50), [-0.00210,   inf] (50), [-0.00208,   inf] (46), [-0.00208,   inf] (46), [-0.00203,   inf] (44), [-0.00203,   inf] (46), [-0.00199,   inf] (42), [-0.00193,   inf] (46), 
length of domains: 66
Total time: 1.0326	 pickout: 0.0100	 decision: 0.0764	 get_bound: 0.9439	 add_domain: 0.0023
Current lb:-0.00284702330827713
312 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 29.89391326904297

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3718] [4, 3718] [4, 3718] [4, 3718] [4, 3756] [4, 3756] [4, 3756] [4, 3718] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04103019833564758 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.7136432528495789, 0.0, 0.0, 0.0, 0.0, 0.5102675557136536]
alpha/beta optimization time: 0.7510514259338379
This batch time : update_bounds func: 0.7820	 prepare: 0.0075	 bound: 0.7517	 transfer: 0.0194	 finalize: 0.0033
Accumulated time: update_bounds func: 22.5683	 prepare: 0.1769	 bound: 21.9684	 transfer: 0.0194	 finalize: 0.0728
batch bounding time:  0.7823123931884766
Current worst splitting domains [lb, ub] (depth):
[-0.00285,   inf] (52), [-0.00285,   inf] (52), [-0.00285,   inf] (52), [-0.00285,   inf] (52), [-0.00285,   inf] (52), [-0.00285,   inf] (52), [-0.00285,   inf] (52), [-0.00284,   inf] (52), [-0.00250,   inf] (52), [-0.00250,   inf] (52), [-0.00250,   inf] (52), [-0.00250,   inf] (52), [-0.00241,   inf] (50), [-0.00241,   inf] (50), [-0.00241,   inf] (50), [-0.00241,   inf] (52), [-0.00241,   inf] (52), [-0.00210,   inf] (48), [-0.00210,   inf] (50), [-0.00210,   inf] (50), 
length of domains: 74
Total time: 0.8723	 pickout: 0.0101	 decision: 0.0775	 get_bound: 0.7823	 add_domain: 0.0023
Current lb:-0.00284702330827713
328 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 30.766688585281372

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3620] [4, 3620] [4, 3620] [4, 3620] [4, 3620] [4, 3620] [4, 3620] [4, 3620] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.043194785714149475 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0007832355913706124, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.7772910594940186
This batch time : update_bounds func: 0.8104	 prepare: 0.0075	 bound: 0.7780	 transfer: 0.0202	 finalize: 0.0048
Accumulated time: update_bounds func: 23.3787	 prepare: 0.1844	 bound: 22.7464	 transfer: 0.0202	 finalize: 0.0776
batch bounding time:  0.8108022212982178
Current worst splitting domains [lb, ub] (depth):
[-0.00285,   inf] (54), [-0.00285,   inf] (54), [-0.00285,   inf] (54), [-0.00285,   inf] (54), [-0.00285,   inf] (54), [-0.00285,   inf] (54), [-0.00285,   inf] (54), [-0.00284,   inf] (54), [-0.00255,   inf] (54), [-0.00255,   inf] (54), [-0.00255,   inf] (54), [-0.00255,   inf] (54), [-0.00255,   inf] (54), [-0.00255,   inf] (54), [-0.00255,   inf] (54), [-0.00255,   inf] (54), [-0.00250,   inf] (52), [-0.00250,   inf] (52), [-0.00250,   inf] (52), [-0.00250,   inf] (52), 
length of domains: 82
Total time: 0.8994	 pickout: 0.0104	 decision: 0.0756	 get_bound: 0.8108	 add_domain: 0.0025
Current lb:-0.00284702330827713
344 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 31.66659641265869

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 419] [9, 419] [9, 419] [9, 419] [9, 419] [9, 419] [9, 419] [9, 419] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03889300674200058 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.20819199085235596, 0.0, 0.0, 0.0, 0.0, 4.531116008758545]
alpha/beta optimization time: 0.9895212650299072
This batch time : update_bounds func: 1.0241	 prepare: 0.0109	 bound: 0.9903	 transfer: 0.0196	 finalize: 0.0032
Accumulated time: update_bounds func: 24.4029	 prepare: 0.1953	 bound: 23.7367	 transfer: 0.0196	 finalize: 0.0808
batch bounding time:  1.0244746208190918
Current worst splitting domains [lb, ub] (depth):
[-0.00283,   inf] (56), [-0.00283,   inf] (56), [-0.00283,   inf] (56), [-0.00283,   inf] (56), [-0.00283,   inf] (56), [-0.00283,   inf] (56), [-0.00283,   inf] (56), [-0.00282,   inf] (56), [-0.00276,   inf] (56), [-0.00276,   inf] (56), [-0.00255,   inf] (54), [-0.00255,   inf] (54), [-0.00255,   inf] (54), [-0.00255,   inf] (54), [-0.00255,   inf] (54), [-0.00255,   inf] (54), [-0.00255,   inf] (54), [-0.00255,   inf] (54), [-0.00250,   inf] (52), [-0.00250,   inf] (52), 
length of domains: 90
Total time: 1.1283	 pickout: 0.0125	 decision: 0.0888	 get_bound: 1.0245	 add_domain: 0.0024
Current lb:-0.0028279349207878113
360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 32.79530882835388

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 509] [9, 509] [9, 509] [9, 509] [9, 509] [9, 509] [9, 509] [9, 509] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.043730009347200394 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0007832355913706124, 0.0, 0.0, 0.0, 0.0, 0.019306382164359093]
alpha/beta optimization time: 0.7887170314788818
This batch time : update_bounds func: 0.8197	 prepare: 0.0074	 bound: 0.7894	 transfer: 0.0194	 finalize: 0.0033
Accumulated time: update_bounds func: 25.2226	 prepare: 0.2028	 bound: 24.5261	 transfer: 0.0194	 finalize: 0.0841
batch bounding time:  0.8200359344482422
Current worst splitting domains [lb, ub] (depth):
[-0.00276,   inf] (56), [-0.00276,   inf] (56), [-0.00275,   inf] (58), [-0.00275,   inf] (58), [-0.00275,   inf] (58), [-0.00275,   inf] (58), [-0.00275,   inf] (58), [-0.00275,   inf] (58), [-0.00275,   inf] (58), [-0.00274,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (58), [-0.00271,   inf] (58), [-0.00270,   inf] (58), [-0.00255,   inf] (54), [-0.00255,   inf] (54), 
length of domains: 98
Total time: 0.9083	 pickout: 0.0101	 decision: 0.0757	 get_bound: 0.8201	 add_domain: 0.0025
Current lb:-0.0027622655034065247
376 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 33.70412468910217

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 509] [9, 509] [9, 853] [4, 3373] [9, 853] [9, 853] [4, 3373] [9, 853] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04246121644973755 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.20397910475730896, 0.0, 0.0, 0.0, 0.0, 2.1752495765686035]
alpha/beta optimization time: 0.7371976375579834
This batch time : update_bounds func: 0.7682	 prepare: 0.0076	 bound: 0.7378	 transfer: 0.0195	 finalize: 0.0033
Accumulated time: update_bounds func: 25.9908	 prepare: 0.2103	 bound: 25.2639	 transfer: 0.0195	 finalize: 0.0874
batch bounding time:  0.7686021327972412
Current worst splitting domains [lb, ub] (depth):
[-0.00275,   inf] (60), [-0.00275,   inf] (60), [-0.00275,   inf] (60), [-0.00275,   inf] (60), [-0.00275,   inf] (60), [-0.00275,   inf] (60), [-0.00275,   inf] (60), [-0.00275,   inf] (60), [-0.00275,   inf] (60), [-0.00275,   inf] (60), [-0.00275,   inf] (60), [-0.00275,   inf] (60), [-0.00275,   inf] (58), [-0.00274,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (58), 
length of domains: 106
Total time: 0.8573	 pickout: 0.0103	 decision: 0.0759	 get_bound: 0.7686	 add_domain: 0.0025
Current lb:-0.0027466118335723877
392 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 34.561906814575195

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3524] [4, 3524] [4, 3524] [4, 3524] [4, 3524] [4, 3524] [4, 3524] [4, 3524] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04307742416858673 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.7110521793365479
This batch time : update_bounds func: 0.7419	 prepare: 0.0075	 bound: 0.7117	 transfer: 0.0195	 finalize: 0.0032
Accumulated time: update_bounds func: 26.7327	 prepare: 0.2178	 bound: 25.9756	 transfer: 0.0195	 finalize: 0.0906
batch bounding time:  0.7423310279846191
Current worst splitting domains [lb, ub] (depth):
[-0.00275,   inf] (60), [-0.00275,   inf] (60), [-0.00275,   inf] (60), [-0.00275,   inf] (60), [-0.00275,   inf] (58), [-0.00274,   inf] (62), [-0.00274,   inf] (62), [-0.00274,   inf] (62), [-0.00274,   inf] (62), [-0.00274,   inf] (62), [-0.00274,   inf] (62), [-0.00274,   inf] (62), [-0.00274,   inf] (62), [-0.00274,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (58), 
length of domains: 114
Total time: 0.8317	 pickout: 0.0102	 decision: 0.0766	 get_bound: 0.7424	 add_domain: 0.0025
Current lb:-0.002746567130088806
408 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 35.39411687850952

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3524] [4, 3524] [4, 3524] [4, 3524] [9, 853] [4, 3727] [4, 3373] [9, 853] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04283018410205841 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6663690209388733]
alpha/beta optimization time: 0.8656437397003174
This batch time : update_bounds func: 0.8970	 prepare: 0.0077	 bound: 0.8663	 transfer: 0.0196	 finalize: 0.0033
Accumulated time: update_bounds func: 27.6298	 prepare: 0.2256	 bound: 26.8419	 transfer: 0.0196	 finalize: 0.0939
batch bounding time:  0.8973932266235352
Current worst splitting domains [lb, ub] (depth):
[-0.00275,   inf] (60), [-0.00274,   inf] (62), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (62), [-0.00274,   inf] (62), [-0.00274,   inf] (62), [-0.00274,   inf] (62), [-0.00274,   inf] (62), [-0.00274,   inf] (62), [-0.00274,   inf] (62), [-0.00274,   inf] (62), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (58), 
length of domains: 122
Total time: 0.9864	 pickout: 0.0100	 decision: 0.0764	 get_bound: 0.8975	 add_domain: 0.0025
Current lb:-0.0027465494349598885
424 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 36.38101530075073

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3524] [4, 3727] [4, 3373] [9, 496] [4, 3373] [4, 3373] [2, 2703] [4, 3373] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03799999877810478 with beta sum per layer: [0.0, 0.0, 0.03806484118103981, 0.0, 0.16464847326278687, 0.0, 0.0, 0.0, 0.0, 1.424419641494751]
alpha/beta optimization time: 0.8217601776123047
This batch time : update_bounds func: 0.8544	 prepare: 0.0078	 bound: 0.8224	 transfer: 0.0208	 finalize: 0.0034
Accumulated time: update_bounds func: 28.4842	 prepare: 0.2333	 bound: 27.6643	 transfer: 0.0208	 finalize: 0.0973
batch bounding time:  0.8547933101654053
Current worst splitting domains [lb, ub] (depth):
[-0.00274,   inf] (64), [-0.00274,   inf] (66), [-0.00274,   inf] (66), [-0.00274,   inf] (62), [-0.00274,   inf] (62), [-0.00274,   inf] (62), [-0.00274,   inf] (62), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (62), 
length of domains: 129
Total time: 0.9437	 pickout: 0.0102	 decision: 0.0761	 get_bound: 0.8548	 add_domain: 0.0025
Current lb:-0.0027440637350082397
440 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 37.325289487838745

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 853] [9, 496] [9, 496] [9, 853] [9, 853] [4, 3373] [2, 2703] [4, 3373] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.034849412739276886 with beta sum per layer: [0.0, 0.0, 0.03806484118103981, 0.0, 0.18429115414619446, 0.0, 0.0, 0.0, 0.0, 1.5510976314544678]
alpha/beta optimization time: 0.8393540382385254
This batch time : update_bounds func: 0.8721	 prepare: 0.0080	 bound: 0.8400	 transfer: 0.0206	 finalize: 0.0034
Accumulated time: update_bounds func: 29.3563	 prepare: 0.2413	 bound: 28.5044	 transfer: 0.0206	 finalize: 0.1006
batch bounding time:  0.8724775314331055
Current worst splitting domains [lb, ub] (depth):
[-0.00274,   inf] (66), [-0.00274,   inf] (66), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), 
length of domains: 135
Total time: 0.9634	 pickout: 0.0106	 decision: 0.0778	 get_bound: 0.8725	 add_domain: 0.0024
Current lb:-0.0027440637350082397
456 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 38.28925347328186

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 496] [9, 496] [9, 496] [9, 496] [4, 3727] [4, 3248] [2, 2703] [2, 2703] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.02394791878759861 with beta sum per layer: [0.0, 0.0, 0.07612968236207962, 0.0, 0.4598090946674347, 0.0, 0.0, 0.0, 0.0, 5.0304274559021]
alpha/beta optimization time: 0.8412380218505859
This batch time : update_bounds func: 0.8739	 prepare: 0.0080	 bound: 0.8419	 transfer: 0.0207	 finalize: 0.0033
Accumulated time: update_bounds func: 30.2302	 prepare: 0.2493	 bound: 29.3462	 transfer: 0.0207	 finalize: 0.1039
batch bounding time:  0.8742563724517822
Current worst splitting domains [lb, ub] (depth):
[-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (66), [-0.00274,   inf] (66), [-0.00274,   inf] (66), [-0.00274,   inf] (66), [-0.00274,   inf] (66), [-0.00274,   inf] (66), [-0.00274,   inf] (66), [-0.00274,   inf] (66), 
length of domains: 139
Total time: 0.9667	 pickout: 0.0123	 decision: 0.0782	 get_bound: 0.8743	 add_domain: 0.0020
Current lb:-0.002744048833847046
472 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 39.25653052330017

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 496] [9, 496] [4, 3373] [9, 496] [9, 496] [9, 496] [2, 2703] [9, 496] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.017653813585639 with beta sum per layer: [0.0, 0.0, 0.03691616654396057, 0.0, 0.7420481443405151, 0.0, 0.0, 0.0, 0.0, 8.44188117980957]
alpha/beta optimization time: 0.9133014678955078
This batch time : update_bounds func: 0.9484	 prepare: 0.0077	 bound: 0.9140	 transfer: 0.0211	 finalize: 0.0055
Accumulated time: update_bounds func: 31.1786	 prepare: 0.2570	 bound: 30.2602	 transfer: 0.0211	 finalize: 0.1094
batch bounding time:  0.9488027095794678
Current worst splitting domains [lb, ub] (depth):
[-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (64), [-0.00274,   inf] (66), [-0.00274,   inf] (66), [-0.00274,   inf] (66), [-0.00274,   inf] (66), [-0.00274,   inf] (66), [-0.00274,   inf] (66), [-0.00274,   inf] (66), [-0.00274,   inf] (66), [-0.00274,   inf] (66), [-0.00274,   inf] (66), [-0.00274,   inf] (66), [-0.00274,   inf] (62), [-0.00274,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (58), 
length of domains: 141
Total time: 1.0371	 pickout: 0.0104	 decision: 0.0760	 get_bound: 0.9488	 add_domain: 0.0018
Current lb:-0.002744048833847046
488 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 40.29413032531738

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2703] [9, 496] [9, 496] [4, 3727] [9, 496] [9, 496] [9, 496] [9, 496] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.01616353914141655 with beta sum per layer: [0.0, 0.0, 0.03806484118103981, 0.0, 0.47282880544662476, 0.0, 0.0, 0.0, 0.0, 5.850764274597168]
alpha/beta optimization time: 0.8808791637420654
This batch time : update_bounds func: 0.9178	 prepare: 0.0114	 bound: 0.8818	 transfer: 0.0210	 finalize: 0.0036
Accumulated time: update_bounds func: 32.0964	 prepare: 0.2685	 bound: 31.1420	 transfer: 0.0210	 finalize: 0.1130
batch bounding time:  0.9183158874511719
Current worst splitting domains [lb, ub] (depth):
[-0.00274,   inf] (66), [-0.00274,   inf] (66), [-0.00274,   inf] (66), [-0.00274,   inf] (66), [-0.00274,   inf] (66), [-0.00274,   inf] (66), [-0.00274,   inf] (66), [-0.00274,   inf] (66), [-0.00274,   inf] (66), [-0.00274,   inf] (66), [-0.00274,   inf] (62), [-0.00274,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (58), [-0.00271,   inf] (58), [-0.00271,   inf] (66), 
length of domains: 143
Total time: 1.0219	 pickout: 0.0128	 decision: 0.0890	 get_bound: 0.9184	 add_domain: 0.0018
Current lb:-0.002744048833847046
504 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 41.316802740097046

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 496] [9, 496] [9, 496] [9, 496] [9, 496] [9, 496] [9, 496] [9, 496] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.011474224738776684 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.7178550958633423, 0.0, 0.0, 0.0, 0.0, 6.1814188957214355]
alpha/beta optimization time: 0.8947868347167969
This batch time : update_bounds func: 0.9267	 prepare: 0.0077	 bound: 0.8954	 transfer: 0.0201	 finalize: 0.0033
Accumulated time: update_bounds func: 33.0231	 prepare: 0.2762	 bound: 32.0374	 transfer: 0.0201	 finalize: 0.1163
batch bounding time:  0.9270694255828857
Current worst splitting domains [lb, ub] (depth):
[-0.00274,   inf] (66), [-0.00274,   inf] (66), [-0.00274,   inf] (62), [-0.00274,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (58), [-0.00271,   inf] (58), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (68), 
length of domains: 143
Total time: 1.0171	 pickout: 0.0112	 decision: 0.0774	 get_bound: 0.9272	 add_domain: 0.0014
Current lb:-0.002744048833847046
520 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 42.33456826210022

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 496] [9, 496] [2, 2703] [9, 853] [9, 853] [9, 853] [9, 853] [9, 853] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.027607694268226624 with beta sum per layer: [0.0, 0.0, 0.03806484118103981, 0.0, 0.47238224744796753, 0.0, 0.0, 0.0, 0.0, 8.251530647277832]
alpha/beta optimization time: 0.8717420101165771
This batch time : update_bounds func: 0.9042	 prepare: 0.0077	 bound: 0.8724	 transfer: 0.0204	 finalize: 0.0036
Accumulated time: update_bounds func: 33.9273	 prepare: 0.2839	 bound: 32.9098	 transfer: 0.0204	 finalize: 0.1199
batch bounding time:  0.9046492576599121
Current worst splitting domains [lb, ub] (depth):
[-0.00274,   inf] (64), [-0.00274,   inf] (60), [-0.00272,   inf] (58), [-0.00272,   inf] (58), [-0.00272,   inf] (60), [-0.00272,   inf] (60), [-0.00272,   inf] (60), [-0.00272,   inf] (60), [-0.00271,   inf] (58), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), 
length of domains: 148
Total time: 0.9934	 pickout: 0.0105	 decision: 0.0762	 get_bound: 0.9047	 add_domain: 0.0021
Current lb:-0.002744033932685852
536 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 43.32865881919861

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3373] [4, 3524] [9, 853] [9, 853] [4, 3524] [4, 3524] [4, 3524] [4, 3524] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03994295746088028 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.1163736879825592, 0.0, 0.0, 0.0, 0.0, 3.061436176300049]
alpha/beta optimization time: 0.83732008934021
This batch time : update_bounds func: 0.8692	 prepare: 0.0080	 bound: 0.8380	 transfer: 0.0196	 finalize: 0.0035
Accumulated time: update_bounds func: 34.7966	 prepare: 0.2919	 bound: 33.7479	 transfer: 0.0196	 finalize: 0.1234
batch bounding time:  0.8697319030761719
Current worst splitting domains [lb, ub] (depth):
[-0.00274,   inf] (66), [-0.00274,   inf] (66), [-0.00273,   inf] (62), [-0.00272,   inf] (60), [-0.00272,   inf] (60), [-0.00272,   inf] (62), [-0.00272,   inf] (62), [-0.00272,   inf] (62), [-0.00272,   inf] (62), [-0.00271,   inf] (58), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (68), [-0.00271,   inf] (68), 
length of domains: 156
Total time: 0.9658	 pickout: 0.0107	 decision: 0.0803	 get_bound: 0.8698	 add_domain: 0.0049
Current lb:-0.002744033932685852
552 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 44.29526710510254

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 496] [9, 496] [4, 3373] [4, 3524] [4, 3524] [4, 3373] [4, 3373] [4, 3373] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03395669907331467 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0007832355913706124, 0.0, 0.0, 0.0, 0.0, 1.2496862411499023]
alpha/beta optimization time: 0.9039220809936523
This batch time : update_bounds func: 0.9355	 prepare: 0.0078	 bound: 0.9046	 transfer: 0.0196	 finalize: 0.0033
Accumulated time: update_bounds func: 35.7320	 prepare: 0.2998	 bound: 34.6525	 transfer: 0.0196	 finalize: 0.1267
batch bounding time:  0.9358103275299072
Current worst splitting domains [lb, ub] (depth):
[-0.00273,   inf] (64), [-0.00273,   inf] (64), [-0.00272,   inf] (62), [-0.00272,   inf] (62), [-0.00272,   inf] (64), [-0.00272,   inf] (64), [-0.00272,   inf] (64), [-0.00272,   inf] (62), [-0.00272,   inf] (64), [-0.00272,   inf] (64), [-0.00272,   inf] (64), [-0.00271,   inf] (58), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), 
length of domains: 162
Total time: 1.0512	 pickout: 0.0166	 decision: 0.0954	 get_bound: 0.9359	 add_domain: 0.0032
Current lb:-0.002734728157520294
568 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 45.34699892997742

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2703] [2, 2703] [4, 3373] [4, 3373] [2, 2703] [2, 2703] [2, 2703] [4, 3727] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03618632256984711 with beta sum per layer: [0.0, 0.0, 0.19251418113708496, 0.0, 0.3246961236000061, 0.0, 0.0, 0.0, 0.0, 0.05856934189796448]
alpha/beta optimization time: 0.8235218524932861
This batch time : update_bounds func: 0.8548	 prepare: 0.0078	 bound: 0.8242	 transfer: 0.0195	 finalize: 0.0033
Accumulated time: update_bounds func: 36.5868	 prepare: 0.3076	 bound: 35.4767	 transfer: 0.0195	 finalize: 0.1300
batch bounding time:  0.8552150726318359
Current worst splitting domains [lb, ub] (depth):
[-0.00273,   inf] (66), [-0.00273,   inf] (66), [-0.00272,   inf] (64), [-0.00272,   inf] (64), [-0.00272,   inf] (64), [-0.00272,   inf] (64), [-0.00272,   inf] (66), [-0.00272,   inf] (66), [-0.00272,   inf] (64), [-0.00272,   inf] (64), [-0.00272,   inf] (64), [-0.00272,   inf] (64), [-0.00272,   inf] (64), [-0.00272,   inf] (66), [-0.00271,   inf] (58), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), 
length of domains: 170
Total time: 0.9468	 pickout: 0.0101	 decision: 0.0788	 get_bound: 0.8553	 add_domain: 0.0026
Current lb:-0.002734728157520294
584 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 46.294352293014526

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 496] [9, 496] [2, 2703] [2, 2703] [2, 2703] [2, 2703] [9, 496] [9, 496] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.018170595169067383 with beta sum per layer: [0.0, 0.0, 0.15023483335971832, 0.0, 0.5047954320907593, 0.0, 0.0, 0.0, 0.0, 3.65494966506958]
alpha/beta optimization time: 0.8491439819335938
This batch time : update_bounds func: 0.8804	 prepare: 0.0077	 bound: 0.8498	 transfer: 0.0195	 finalize: 0.0034
Accumulated time: update_bounds func: 37.4673	 prepare: 0.3153	 bound: 36.3265	 transfer: 0.0195	 finalize: 0.1334
batch bounding time:  0.8808169364929199
Current worst splitting domains [lb, ub] (depth):
[-0.00272,   inf] (66), [-0.00272,   inf] (66), [-0.00272,   inf] (66), [-0.00272,   inf] (64), [-0.00272,   inf] (64), [-0.00272,   inf] (64), [-0.00272,   inf] (64), [-0.00272,   inf] (64), [-0.00272,   inf] (66), [-0.00272,   inf] (66), [-0.00271,   inf] (58), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (68), 
length of domains: 174
Total time: 0.9708	 pickout: 0.0100	 decision: 0.0779	 get_bound: 0.8809	 add_domain: 0.0020
Current lb:-0.0027221590280532837
600 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 47.265811920166016

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 496] [9, 496] [9, 496] [2, 2703] [2, 2703] [4, 3373] [2, 2703] [2, 2703] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.01759379915893078 with beta sum per layer: [0.0, 0.0, 0.2952839732170105, 0.0, 0.8674006462097168, 0.0, 0.0, 0.0, 0.0, 3.262479066848755]
alpha/beta optimization time: 0.883561372756958
This batch time : update_bounds func: 0.9159	 prepare: 0.0079	 bound: 0.8842	 transfer: 0.0202	 finalize: 0.0035
Accumulated time: update_bounds func: 38.3832	 prepare: 0.3232	 bound: 37.2107	 transfer: 0.0202	 finalize: 0.1369
batch bounding time:  0.9163913726806641
Current worst splitting domains [lb, ub] (depth):
[-0.00272,   inf] (66), [-0.00272,   inf] (66), [-0.00272,   inf] (66), [-0.00272,   inf] (66), [-0.00272,   inf] (66), [-0.00272,   inf] (66), [-0.00272,   inf] (66), [-0.00272,   inf] (66), [-0.00271,   inf] (58), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), 
length of domains: 178
Total time: 1.0067	 pickout: 0.0103	 decision: 0.0778	 get_bound: 0.9164	 add_domain: 0.0021
Current lb:-0.0027221515774726868
616 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 48.273253202438354

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 496] [9, 496] [9, 496] [9, 496] [9, 496] [9, 496] [9, 496] [9, 496] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.0070613594725728035 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.6355859041213989, 0.0, 0.0, 0.0, 0.0, 8.531320571899414]
alpha/beta optimization time: 0.8460392951965332
This batch time : update_bounds func: 0.8774	 prepare: 0.0077	 bound: 0.8467	 transfer: 0.0195	 finalize: 0.0034
Accumulated time: update_bounds func: 39.2606	 prepare: 0.3309	 bound: 38.0574	 transfer: 0.0195	 finalize: 0.1402
batch bounding time:  0.8777992725372314
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (58), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (66), [-0.00271,   inf] (68), 
length of domains: 178
Total time: 0.9676	 pickout: 0.0111	 decision: 0.0772	 get_bound: 0.8778	 add_domain: 0.0014
Current lb:-0.002714894711971283
632 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 49.24147987365723

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 853] [2, 2703] [2, 2703] [2, 2703] [2, 2703] [2, 2703] [2, 2703] [2, 2703] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.027571380138397217 with beta sum per layer: [0.0, 0.0, 0.2656746208667755, 0.0, 0.5997610092163086, 0.0, 0.0, 0.0, 0.0, 5.638944149017334]
alpha/beta optimization time: 0.8582949638366699
This batch time : update_bounds func: 0.8894	 prepare: 0.0078	 bound: 0.8590	 transfer: 0.0193	 finalize: 0.0033
Accumulated time: update_bounds func: 40.1501	 prepare: 0.3387	 bound: 38.9164	 transfer: 0.0193	 finalize: 0.1435
batch bounding time:  0.8897912502288818
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (60), [-0.00271,   inf] (66), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (66), [-0.00271,   inf] (68), 
length of domains: 186
Total time: 0.9896	 pickout: 0.0155	 decision: 0.0810	 get_bound: 0.8898	 add_domain: 0.0034
Current lb:-0.002714894711971283
648 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 50.23181509971619

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3524] [2, 2703] [4, 3656] [4, 3656] [4, 3656] [4, 3656] [4, 3656] [4, 3656] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04033378139138222 with beta sum per layer: [0.0, 0.0, 0.03786551579833031, 0.0, 0.059350986033678055, 0.0, 0.0, 0.0, 0.0, 0.5982182025909424]
alpha/beta optimization time: 0.8470067977905273
This batch time : update_bounds func: 0.8784	 prepare: 0.0077	 bound: 0.8477	 transfer: 0.0196	 finalize: 0.0034
Accumulated time: update_bounds func: 41.0285	 prepare: 0.3464	 bound: 39.7641	 transfer: 0.0196	 finalize: 0.1469
batch bounding time:  0.8787930011749268
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (66), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (66), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), 
length of domains: 194
Total time: 0.9747	 pickout: 0.0154	 decision: 0.0778	 get_bound: 0.8788	 add_domain: 0.0027
Current lb:-0.0027145221829414368
664 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 51.207098722457886

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3656] [4, 3656] [4, 3727] [4, 3727] [4, 3727] [4, 3727] [4, 3727] [4, 3727] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.043282926082611084 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.7513670921325684
This batch time : update_bounds func: 0.7827	 prepare: 0.0077	 bound: 0.7520	 transfer: 0.0196	 finalize: 0.0033
Accumulated time: update_bounds func: 41.8112	 prepare: 0.3541	 bound: 40.5161	 transfer: 0.0196	 finalize: 0.1502
batch bounding time:  0.7830920219421387
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (70), [-0.00271,   inf] (70), [-0.00271,   inf] (70), [-0.00271,   inf] (70), [-0.00271,   inf] (70), [-0.00271,   inf] (70), [-0.00271,   inf] (70), [-0.00271,   inf] (70), [-0.00271,   inf] (70), [-0.00271,   inf] (70), [-0.00271,   inf] (70), [-0.00271,   inf] (70), [-0.00271,   inf] (68), [-0.00271,   inf] (66), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (66), [-0.00271,   inf] (68), 
length of domains: 202
Total time: 0.8758	 pickout: 0.0111	 decision: 0.0787	 get_bound: 0.7831	 add_domain: 0.0028
Current lb:-0.0027145221829414368
680 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 52.083428382873535

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3727] [4, 3727] [4, 3252] [4, 3252] [4, 3252] [4, 3252] [4, 3252] [4, 3252] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04343007504940033 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.7423005104064941
This batch time : update_bounds func: 0.7801	 prepare: 0.0140	 bound: 0.7431	 transfer: 0.0195	 finalize: 0.0033
Accumulated time: update_bounds func: 42.5913	 prepare: 0.3680	 bound: 41.2592	 transfer: 0.0195	 finalize: 0.1535
batch bounding time:  0.7804703712463379
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (70), [-0.00271,   inf] (70), [-0.00271,   inf] (70), [-0.00271,   inf] (70), [-0.00271,   inf] (70), [-0.00271,   inf] (70), [-0.00271,   inf] (70), [-0.00271,   inf] (70), [-0.00271,   inf] (70), [-0.00271,   inf] (70), [-0.00271,   inf] (68), [-0.00271,   inf] (66), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (66), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), 
length of domains: 210
Total time: 0.8762	 pickout: 0.0102	 decision: 0.0826	 get_bound: 0.7805	 add_domain: 0.0029
Current lb:-0.0027145221829414368
696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 52.96020436286926

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3252] [4, 3252] [4, 3252] [4, 3252] [4, 3252] [4, 3252] [4, 3252] [4, 3252] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04338103532791138 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.13407668471336365, 0.0, 0.0, 0.0, 0.0, 1.3157899379730225]
alpha/beta optimization time: 0.7661504745483398
This batch time : update_bounds func: 0.7977	 prepare: 0.0077	 bound: 0.7668	 transfer: 0.0197	 finalize: 0.0034
Accumulated time: update_bounds func: 43.3890	 prepare: 0.3758	 bound: 42.0261	 transfer: 0.0197	 finalize: 0.1569
batch bounding time:  0.7981147766113281
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (70), [-0.00271,   inf] (70), [-0.00271,   inf] (68), [-0.00271,   inf] (66), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (66), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (66), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), 
length of domains: 218
Total time: 0.8898	 pickout: 0.0103	 decision: 0.0778	 get_bound: 0.7982	 add_domain: 0.0036
Current lb:-0.0027145221829414368
712 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 53.85050916671753

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3252] [4, 3252] [4, 3656] [2, 2703] [4, 3656] [9, 751] [2, 2703] [4, 3656] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03639155626296997 with beta sum per layer: [0.0, 0.0, 0.07588503509759903, 0.0, 0.27405717968940735, 0.0, 0.0, 0.0, 0.0, 3.8692331314086914]
alpha/beta optimization time: 0.7869203090667725
This batch time : update_bounds func: 0.8185	 prepare: 0.0079	 bound: 0.7876	 transfer: 0.0196	 finalize: 0.0032
Accumulated time: update_bounds func: 44.2075	 prepare: 0.3837	 bound: 42.8136	 transfer: 0.0196	 finalize: 0.1601
batch bounding time:  0.81880784034729
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (70), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (66), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), 
length of domains: 225
Total time: 0.9141	 pickout: 0.0148	 decision: 0.0778	 get_bound: 0.8188	 add_domain: 0.0026
Current lb:-0.002714499831199646
728 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 54.7652485370636

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3656] [4, 3656] [4, 3656] [4, 3252] [4, 3656] [4, 3656] [2, 2703] [4, 3656] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.040646493434906006 with beta sum per layer: [0.0, 0.0, 0.03786551579833031, 0.0, 0.04286252707242966, 0.0, 0.0, 0.0, 0.0, 0.611294150352478]
alpha/beta optimization time: 0.8011915683746338
This batch time : update_bounds func: 0.8327	 prepare: 0.0079	 bound: 0.8019	 transfer: 0.0195	 finalize: 0.0034
Accumulated time: update_bounds func: 45.0402	 prepare: 0.3916	 bound: 43.6155	 transfer: 0.0195	 finalize: 0.1635
batch bounding time:  0.8330979347229004
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (68), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), 
length of domains: 233
Total time: 0.9304	 pickout: 0.0163	 decision: 0.0782	 get_bound: 0.8331	 add_domain: 0.0028
Current lb:-0.0027144700288772583
744 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 55.6962103843689

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3656] [4, 3656] [4, 3252] [9, 751] [4, 3252] [2, 2476] [2, 2476] [2, 2476] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.0404796227812767 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0487515814602375, 0.0, 0.0, 0.0, 0.0, 1.321987271308899]
alpha/beta optimization time: 0.7692215442657471
This batch time : update_bounds func: 0.7991	 prepare: 0.0079	 bound: 0.7699	 transfer: 0.0178	 finalize: 0.0033
Accumulated time: update_bounds func: 45.8393	 prepare: 0.3995	 bound: 44.3854	 transfer: 0.0178	 finalize: 0.1668
batch bounding time:  0.7994551658630371
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (70), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (70), [-0.00271,   inf] (70), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), 
length of domains: 241
Total time: 0.8926	 pickout: 0.0117	 decision: 0.0786	 get_bound: 0.7995	 add_domain: 0.0028
Current lb:-0.0027144700288772583
760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 56.58940601348877

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3252] [2, 2476] [2, 2476] [2, 2476] [2, 2476] [2, 2476] [2, 2476] [2, 2476] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.041805997490882874 with beta sum per layer: [0.0, 0.0, 0.06671787798404694, 0.0, 0.13425445556640625, 0.0, 0.0, 0.0, 0.0, 1.3052642345428467]
alpha/beta optimization time: 0.7657806873321533
This batch time : update_bounds func: 0.7893	 prepare: 0.0077	 bound: 0.7664	 transfer: 0.0118	 finalize: 0.0033
Accumulated time: update_bounds func: 46.6286	 prepare: 0.4073	 bound: 45.1518	 transfer: 0.0118	 finalize: 0.1701
batch bounding time:  0.789680004119873
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (70), [-0.00271,   inf] (70), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), 
length of domains: 249
Total time: 0.8824	 pickout: 0.0109	 decision: 0.0780	 get_bound: 0.7897	 add_domain: 0.0038
Current lb:-0.002714402973651886
776 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 57.47232627868652

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2476] [2, 2476] [2, 2476] [2, 2476] [2, 2476] [2, 2476] [2, 2476] [4, 3727] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03924071788787842 with beta sum per layer: [0.0, 0.0, 0.2002587914466858, 0.0, 0.3714514374732971, 0.0, 0.0, 0.0, 0.0, 3.979374647140503]
alpha/beta optimization time: 0.8308992385864258
This batch time : update_bounds func: 0.8623	 prepare: 0.0078	 bound: 0.8315	 transfer: 0.0196	 finalize: 0.0033
Accumulated time: update_bounds func: 47.4909	 prepare: 0.4151	 bound: 45.9834	 transfer: 0.0196	 finalize: 0.1734
batch bounding time:  0.8626852035522461
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (70), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (70), [-0.00271,   inf] (72), [-0.00271,   inf] (74), [-0.00271,   inf] (74), 
length of domains: 257
Total time: 0.9541	 pickout: 0.0103	 decision: 0.0782	 get_bound: 0.8627	 add_domain: 0.0028
Current lb:-0.0027143433690071106
792 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 58.426974296569824

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3727] [2, 2476] [2, 2476] [2, 2476] [2, 2476] [2, 2476] [2, 2476] [2, 2476] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04204726219177246 with beta sum per layer: [0.0, 0.0, 0.06675293296575546, 0.0, 0.09259511530399323, 0.0, 0.0, 0.0, 0.0, 1.3503696918487549]
alpha/beta optimization time: 0.745898962020874
This batch time : update_bounds func: 0.7771	 prepare: 0.0078	 bound: 0.7465	 transfer: 0.0194	 finalize: 0.0033
Accumulated time: update_bounds func: 48.2680	 prepare: 0.4229	 bound: 46.7299	 transfer: 0.0194	 finalize: 0.1766
batch bounding time:  0.7774994373321533
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (70), [-0.00271,   inf] (72), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), 
length of domains: 265
Total time: 0.8696	 pickout: 0.0102	 decision: 0.0790	 get_bound: 0.7775	 add_domain: 0.0028
Current lb:-0.0027143433690071106
808 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 59.29714322090149

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2476] [2, 2476] [2, 2476] [2, 2476] [2, 2476] [2, 2476] [2, 2476] [2, 2476] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04052434116601944 with beta sum per layer: [0.0, 0.0, 0.13350586593151093, 0.0, 0.231498122215271, 0.0, 0.0, 0.0, 0.0, 2.7090396881103516]
alpha/beta optimization time: 0.7776579856872559
This batch time : update_bounds func: 0.8069	 prepare: 0.0076	 bound: 0.7783	 transfer: 0.0176	 finalize: 0.0033
Accumulated time: update_bounds func: 49.0749	 prepare: 0.4305	 bound: 47.5082	 transfer: 0.0176	 finalize: 0.1800
batch bounding time:  0.8072845935821533
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (70), [-0.00271,   inf] (72), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), 
length of domains: 273
Total time: 0.8970	 pickout: 0.0090	 decision: 0.0778	 get_bound: 0.8073	 add_domain: 0.0029
Current lb:-0.0027142614126205444
824 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 60.194732427597046

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2476] [2, 2476] [4, 3727] [2, 2476] [2, 405] [2, 405] [2, 405] [2, 405] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.02990902028977871 with beta sum per layer: [0.0, 0.0, 0.709589958190918, 0.0, 0.5720036029815674, 0.0, 0.0, 0.0, 0.0, 3.9056293964385986]
alpha/beta optimization time: 0.7840290069580078
This batch time : update_bounds func: 0.8055	 prepare: 0.0079	 bound: 0.7847	 transfer: 0.0095	 finalize: 0.0032
Accumulated time: update_bounds func: 49.8804	 prepare: 0.4384	 bound: 48.2929	 transfer: 0.0095	 finalize: 0.1832
batch bounding time:  0.8058187961578369
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (72), [-0.00271,   inf] (70), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), 
length of domains: 277
Total time: 0.8956	 pickout: 0.0091	 decision: 0.0785	 get_bound: 0.8059	 add_domain: 0.0022
Current lb:-0.00271422415971756
840 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 61.09089374542236

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2476] [2, 2476] [2, 405] [2, 405] [2, 405] [2, 405] [2, 405] [2, 405] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.024205707013607025 with beta sum per layer: [0.0, 0.0, 1.031804084777832, 0.0, 0.755292534828186, 0.0, 0.0, 0.0, 0.0, 4.950151443481445]
alpha/beta optimization time: 0.8439631462097168
This batch time : update_bounds func: 0.8762	 prepare: 0.0076	 bound: 0.8446	 transfer: 0.0194	 finalize: 0.0045
Accumulated time: update_bounds func: 50.7566	 prepare: 0.4461	 bound: 49.1376	 transfer: 0.0194	 finalize: 0.1877
batch bounding time:  0.8765795230865479
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (72), [-0.00271,   inf] (70), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), 
length of domains: 279
Total time: 0.9667	 pickout: 0.0102	 decision: 0.0781	 get_bound: 0.8766	 add_domain: 0.0018
Current lb:-0.002714216709136963
856 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 62.05820059776306

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 405] [2, 405] [2, 405] [2, 405] [2, 405] [2, 405] [2, 2476] [4, 3727] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.023806866258382797 with beta sum per layer: [0.0, 0.0, 1.018471598625183, 0.0, 0.7449542284011841, 0.0, 0.0, 0.0, 0.0, 4.0276336669921875]
alpha/beta optimization time: 0.8233191967010498
This batch time : update_bounds func: 0.8545	 prepare: 0.0078	 bound: 0.8240	 transfer: 0.0193	 finalize: 0.0034
Accumulated time: update_bounds func: 51.6112	 prepare: 0.4538	 bound: 49.9615	 transfer: 0.0193	 finalize: 0.1911
batch bounding time:  0.8549306392669678
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (72), [-0.00271,   inf] (72), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), 
length of domains: 281
Total time: 0.9458	 pickout: 0.0103	 decision: 0.0786	 get_bound: 0.8550	 add_domain: 0.0019
Current lb:-0.002714194357395172
872 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 63.00461483001709

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 405] [2, 405] [2, 405] [2, 405] [2, 405] [2, 405] [2, 2476] [2, 2476] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.021912619471549988 with beta sum per layer: [0.0, 0.0, 1.0311386585235596, 0.0, 0.3878181576728821, 0.0, 0.0, 0.0, 0.0, 5.33223819732666]
alpha/beta optimization time: 0.857555627822876
This batch time : update_bounds func: 0.8887	 prepare: 0.0077	 bound: 0.8582	 transfer: 0.0193	 finalize: 0.0034
Accumulated time: update_bounds func: 52.4999	 prepare: 0.4615	 bound: 50.8198	 transfer: 0.0193	 finalize: 0.1945
batch bounding time:  0.8890724182128906
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (76), [-0.00271,   inf] (76), 
length of domains: 283
Total time: 0.9792	 pickout: 0.0105	 decision: 0.0778	 get_bound: 0.8891	 add_domain: 0.0019
Current lb:-0.0027140602469444275
888 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 63.98450064659119

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 405] [2, 405] [2, 405] [2, 405] [2, 405] [2, 405] [2, 405] [2, 405] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.01855102926492691 with beta sum per layer: [0.0, 0.0, 1.2856738567352295, 0.0, 0.8770368099212646, 0.0, 0.0, 0.0, 0.0, 5.31706428527832]
alpha/beta optimization time: 0.838421106338501
This batch time : update_bounds func: 0.8697	 prepare: 0.0077	 bound: 0.8391	 transfer: 0.0195	 finalize: 0.0034
Accumulated time: update_bounds func: 53.3696	 prepare: 0.4692	 bound: 51.6589	 transfer: 0.0195	 finalize: 0.1978
batch bounding time:  0.8702261447906494
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), 
length of domains: 283
Total time: 0.9601	 pickout: 0.0102	 decision: 0.0781	 get_bound: 0.8703	 add_domain: 0.0015
Current lb:-0.0027140602469444275
904 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 64.94530749320984

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 405] [2, 405] [2, 405] [2, 405] [2, 405] [2, 405] [2, 405] [2, 405] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.018740084022283554 with beta sum per layer: [0.0, 0.0, 1.2875093221664429, 0.0, 0.7554576396942139, 0.0, 0.0, 0.0, 0.0, 4.866352081298828]
alpha/beta optimization time: 0.8330228328704834
This batch time : update_bounds func: 0.8644	 prepare: 0.0077	 bound: 0.8337	 transfer: 0.0194	 finalize: 0.0035
Accumulated time: update_bounds func: 54.2341	 prepare: 0.4769	 bound: 52.4926	 transfer: 0.0194	 finalize: 0.2013
batch bounding time:  0.8648722171783447
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (74), [-0.00271,   inf] (74), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), 
length of domains: 283
Total time: 0.9553	 pickout: 0.0103	 decision: 0.0785	 get_bound: 0.8650	 add_domain: 0.0015
Current lb:-0.0027140453457832336
920 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 65.90131449699402

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 405] [2, 405] [2, 15765] [2, 15765] [2, 15765] [2, 15765] [2, 15765] [2, 15765] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.020020488649606705 with beta sum per layer: [0.0, 0.0, 1.2975068092346191, 0.0, 0.7648781538009644, 0.0, 0.0, 0.0, 0.0, 5.157530307769775]
alpha/beta optimization time: 0.8251669406890869
This batch time : update_bounds func: 0.8566	 prepare: 0.0076	 bound: 0.8258	 transfer: 0.0196	 finalize: 0.0035
Accumulated time: update_bounds func: 55.0906	 prepare: 0.4846	 bound: 53.3184	 transfer: 0.0196	 finalize: 0.2048
batch bounding time:  0.8569865226745605
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), 
length of domains: 283
Total time: 0.9468	 pickout: 0.0105	 decision: 0.0777	 get_bound: 0.8570	 add_domain: 0.0016
Current lb:-0.0027129724621772766
936 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 66.84881258010864

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 15765] [2, 15765] [2, 15765] [2, 15765] [2, 15765] [2, 15765] [2, 15765] [2, 15765] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.01719176396727562 with beta sum per layer: [0.0, 0.0, 1.3631184101104736, 0.0, 0.8035680651664734, 0.0, 0.0, 0.0, 0.0, 4.81230354309082]
alpha/beta optimization time: 0.84765625
This batch time : update_bounds func: 0.8801	 prepare: 0.0078	 bound: 0.8483	 transfer: 0.0194	 finalize: 0.0045
Accumulated time: update_bounds func: 55.9707	 prepare: 0.4923	 bound: 54.1668	 transfer: 0.0194	 finalize: 0.2093
batch bounding time:  0.880462646484375
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), 
length of domains: 283
Total time: 0.9708	 pickout: 0.0102	 decision: 0.0786	 get_bound: 0.8805	 add_domain: 0.0015
Current lb:-0.0027129724621772766
952 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 67.82025218009949

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 15765] [2, 15765] [2, 15765] [2, 15765] [2, 15765] [2, 15765] [2, 15765] [2, 15765] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.017292827367782593 with beta sum per layer: [0.0, 0.0, 1.3566858768463135, 0.0, 0.5241203308105469, 0.0, 0.0, 0.0, 0.0, 5.148377418518066]
alpha/beta optimization time: 0.8598592281341553
This batch time : update_bounds func: 0.8913	 prepare: 0.0077	 bound: 0.8605	 transfer: 0.0194	 finalize: 0.0036
Accumulated time: update_bounds func: 56.8620	 prepare: 0.5001	 bound: 55.0273	 transfer: 0.0194	 finalize: 0.2129
batch bounding time:  0.8917396068572998
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (62), [-0.00271,   inf] (78), 
length of domains: 283
Total time: 0.9813	 pickout: 0.0103	 decision: 0.0776	 get_bound: 0.8918	 add_domain: 0.0016
Current lb:-0.002712823450565338
968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 68.8022677898407

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 15765] [2, 15765] [2, 15765] [2, 15765] [2, 15765] [2, 15765] [2, 15765] [2, 15765] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.018627390265464783 with beta sum per layer: [0.0, 0.0, 1.3011746406555176, 0.0, 0.8770368099212646, 0.0, 0.0, 0.0, 0.0, 5.315154552459717]
alpha/beta optimization time: 0.8065619468688965
This batch time : update_bounds func: 0.8363	 prepare: 0.0077	 bound: 0.8072	 transfer: 0.0180	 finalize: 0.0034
Accumulated time: update_bounds func: 57.6983	 prepare: 0.5078	 bound: 55.8345	 transfer: 0.0180	 finalize: 0.2163
batch bounding time:  0.8366904258728027
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (62), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), 
length of domains: 283
Total time: 0.9252	 pickout: 0.0090	 decision: 0.0778	 get_bound: 0.8367	 add_domain: 0.0017
Current lb:-0.002712823450565338
984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 69.72819876670837

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 15765] [2, 15765] [2, 15765] [2, 15765] [2, 15765] [2, 15765] [2, 15765] [2, 15765] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.016739964485168457 with beta sum per layer: [0.0, 0.0, 1.3703864812850952, 0.0, 0.7673455476760864, 0.0, 0.0, 0.0, 0.0, 5.081569194793701]
alpha/beta optimization time: 0.847022294998169
This batch time : update_bounds func: 0.8653	 prepare: 0.0078	 bound: 0.8477	 transfer: 0.0064	 finalize: 0.0034
Accumulated time: update_bounds func: 58.5636	 prepare: 0.5155	 bound: 56.6822	 transfer: 0.0064	 finalize: 0.2196
batch bounding time:  0.8656764030456543
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (76), [-0.00271,   inf] (76), [-0.00271,   inf] (62), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), 
length of domains: 283
Total time: 0.9544	 pickout: 0.0091	 decision: 0.0780	 get_bound: 0.8657	 add_domain: 0.0016
Current lb:-0.0027127861976623535
1000 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 70.68330025672913

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 15765] [2, 15765] [4, 3373] [9, 751] [9, 751] [9, 751] [9, 751] [9, 751] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.025311116129159927 with beta sum per layer: [0.0, 0.0, 0.32825326919555664, 0.0, 0.6824749708175659, 0.0, 0.0, 0.0, 0.0, 7.930543899536133]
alpha/beta optimization time: 0.8285977840423584
This batch time : update_bounds func: 0.8501	 prepare: 0.0080	 bound: 0.8293	 transfer: 0.0094	 finalize: 0.0033
Accumulated time: update_bounds func: 59.4138	 prepare: 0.5235	 bound: 57.5115	 transfer: 0.0094	 finalize: 0.2230
batch bounding time:  0.8504843711853027
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (64), [-0.00271,   inf] (64), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (78), [-0.00271,   inf] (78), 
length of domains: 289
Total time: 0.9411	 pickout: 0.0094	 decision: 0.0785	 get_bound: 0.8505	 add_domain: 0.0026
Current lb:-0.002712361514568329
1016 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 71.62497091293335

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2703] [2, 2703] [9, 751] [9, 751] [2, 406] [9, 751] [9, 751] [9, 751] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.020189009606838226 with beta sum per layer: [0.0, 0.0, 0.246912881731987, 0.0, 0.5191130638122559, 0.0, 0.0, 0.0, 0.0, 7.292906761169434]
alpha/beta optimization time: 0.866225004196167
This batch time : update_bounds func: 0.8960	 prepare: 0.0079	 bound: 0.8669	 transfer: 0.0177	 finalize: 0.0034
Accumulated time: update_bounds func: 60.3098	 prepare: 0.5314	 bound: 58.3784	 transfer: 0.0177	 finalize: 0.2264
batch bounding time:  0.8964118957519531
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (66), [-0.00271,   inf] (66), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), 
length of domains: 292
Total time: 0.9863	 pickout: 0.0091	 decision: 0.0786	 get_bound: 0.8965	 add_domain: 0.0021
Current lb:-0.002712361514568329
1032 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 72.61193799972534

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 496] [9, 496] [9, 751] [9, 751] [9, 751] [9, 751] [2, 406] [2, 406] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.01578943431377411 with beta sum per layer: [0.0, 0.0, 0.3705675005912781, 0.0, 0.47467562556266785, 0.0, 0.0, 0.0, 0.0, 8.325973510742188]
alpha/beta optimization time: 0.8936164379119873
This batch time : update_bounds func: 0.9123	 prepare: 0.0079	 bound: 0.8943	 transfer: 0.0066	 finalize: 0.0034
Accumulated time: update_bounds func: 61.2221	 prepare: 0.5393	 bound: 59.2727	 transfer: 0.0066	 finalize: 0.2298
batch bounding time:  0.9127194881439209
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), 
length of domains: 292
Total time: 1.0034	 pickout: 0.0091	 decision: 0.0800	 get_bound: 0.9128	 add_domain: 0.0016
Current lb:-0.002711668610572815
1048 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 73.61606740951538

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 406] [2, 406] [2, 406] [2, 406] [2, 406] [2, 406] [2, 406] [2, 406] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.017062924802303314 with beta sum per layer: [0.0, 0.0, 1.3555307388305664, 0.0, 0.8722492456436157, 0.0, 0.0, 0.0, 0.0, 4.952967166900635]
alpha/beta optimization time: 0.8239076137542725
This batch time : update_bounds func: 0.8473	 prepare: 0.0080	 bound: 0.8246	 transfer: 0.0098	 finalize: 0.0047
Accumulated time: update_bounds func: 62.0694	 prepare: 0.5474	 bound: 60.0973	 transfer: 0.0098	 finalize: 0.2345
batch bounding time:  0.8476817607879639
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), 
length of domains: 292
Total time: 0.9364	 pickout: 0.0091	 decision: 0.0778	 get_bound: 0.8477	 add_domain: 0.0018
Current lb:-0.002711668610572815
1064 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 74.5531256198883

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 406] [2, 406] [2, 406] [2, 406] [2, 406] [2, 406] [4, 3727] [2, 406] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.020105399191379547 with beta sum per layer: [0.0, 0.0, 1.1930444240570068, 0.0, 0.7306229472160339, 0.0, 0.0, 0.0, 0.0, 4.104408264160156]
alpha/beta optimization time: 0.8880579471588135
This batch time : update_bounds func: 0.9232	 prepare: 0.0114	 bound: 0.8889	 transfer: 0.0194	 finalize: 0.0034
Accumulated time: update_bounds func: 62.9926	 prepare: 0.5588	 bound: 60.9862	 transfer: 0.0194	 finalize: 0.2379
batch bounding time:  0.9235866069793701
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), 
length of domains: 293
Total time: 1.0294	 pickout: 0.0129	 decision: 0.0911	 get_bound: 0.9236	 add_domain: 0.0018
Current lb:-0.0027116313576698303
1080 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 75.58320498466492

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 406] [2, 406] [2, 406] [2, 406] [2, 406] [2, 406] [2, 406] [2, 406] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.01794283650815487 with beta sum per layer: [0.0, 0.0, 1.3563311100006104, 0.0, 0.7361048460006714, 0.0, 0.0, 0.0, 0.0, 4.998200416564941]
alpha/beta optimization time: 0.8758285045623779
This batch time : update_bounds func: 0.9056	 prepare: 0.0077	 bound: 0.8765	 transfer: 0.0178	 finalize: 0.0036
Accumulated time: update_bounds func: 63.8982	 prepare: 0.5665	 bound: 61.8627	 transfer: 0.0178	 finalize: 0.2415
batch bounding time:  0.9060218334197998
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (80), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), 
length of domains: 293
Total time: 0.9946	 pickout: 0.0090	 decision: 0.0780	 get_bound: 0.9061	 add_domain: 0.0016
Current lb:-0.0027115121483802795
1096 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 76.57860326766968

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 406] [2, 406] [2, 406] [2, 406] [2, 406] [2, 406] [2, 406] [2, 406] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.015930980443954468 with beta sum per layer: [0.0, 0.0, 1.3569790124893188, 0.0, 0.9111220836639404, 0.0, 0.0, 0.0, 0.0, 5.123050689697266]
alpha/beta optimization time: 0.8397259712219238
This batch time : update_bounds func: 0.8577	 prepare: 0.0077	 bound: 0.8404	 transfer: 0.0062	 finalize: 0.0033
Accumulated time: update_bounds func: 64.7560	 prepare: 0.5742	 bound: 62.7031	 transfer: 0.0062	 finalize: 0.2448
batch bounding time:  0.8581137657165527
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (78), [-0.00271,   inf] (80), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (80), [-0.00271,   inf] (82), 
length of domains: 293
Total time: 0.9470	 pickout: 0.0093	 decision: 0.0779	 get_bound: 0.8582	 add_domain: 0.0016
Current lb:-0.0027115121483802795
1112 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 77.52628517150879

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 406] [2, 406] [2, 406] [2, 406] [2, 406] [2, 406] [2, 406] [9, 751] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.01771872118115425 with beta sum per layer: [0.0, 0.0, 1.1901602745056152, 0.0, 0.7596286535263062, 0.0, 0.0, 0.0, 0.0, 5.640140533447266]
alpha/beta optimization time: 0.8698852062225342
This batch time : update_bounds func: 0.8874	 prepare: 0.0078	 bound: 0.8705	 transfer: 0.0057	 finalize: 0.0033
Accumulated time: update_bounds func: 65.6433	 prepare: 0.5820	 bound: 63.5737	 transfer: 0.0057	 finalize: 0.2481
batch bounding time:  0.8877315521240234
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (80), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), 
length of domains: 293
Total time: 0.9763	 pickout: 0.0091	 decision: 0.0779	 get_bound: 0.8879	 add_domain: 0.0015
Current lb:-0.0027110353112220764
1128 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 78.50333428382874

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2698] [2, 2698] [2, 2698] [2, 2698] [2, 2698] [2, 2698] [2, 2698] [2, 2698] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.0412876158952713 with beta sum per layer: [0.0, 0.0, 0.07924233376979828, 0.0, 0.23093613982200623, 0.0, 0.0, 0.0, 0.0, 1.754976511001587]
alpha/beta optimization time: 0.8138833045959473
This batch time : update_bounds func: 0.8357	 prepare: 0.0077	 bound: 0.8146	 transfer: 0.0096	 finalize: 0.0036
Accumulated time: update_bounds func: 66.4790	 prepare: 0.5898	 bound: 64.3883	 transfer: 0.0096	 finalize: 0.2517
batch bounding time:  0.8361468315124512
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (80), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), 
length of domains: 301
Total time: 0.9258	 pickout: 0.0090	 decision: 0.0774	 get_bound: 0.8362	 add_domain: 0.0032
Current lb:-0.0027110353112220764
1144 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 79.42974853515625

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2698] [2, 2698] [2, 2698] [2, 15766] [2, 15766] [2, 15766] [2, 15766] [2, 15766] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.02662031725049019 with beta sum per layer: [0.0, 0.0, 1.0340650081634521, 0.0, 0.8270868062973022, 0.0, 0.0, 0.0, 0.0, 4.908089637756348]
alpha/beta optimization time: 0.8595521450042725
This batch time : update_bounds func: 0.8927	 prepare: 0.0079	 bound: 0.8602	 transfer: 0.0209	 finalize: 0.0035
Accumulated time: update_bounds func: 67.3717	 prepare: 0.5976	 bound: 65.2485	 transfer: 0.0209	 finalize: 0.2552
batch bounding time:  0.8931066989898682
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (80), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), 
length of domains: 306
Total time: 1.0036	 pickout: 0.0107	 decision: 0.0971	 get_bound: 0.8931	 add_domain: 0.0026
Current lb:-0.0027110353112220764
1160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 80.4339907169342

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 15766] [2, 15766] [2, 15766] [2, 15766] [9, 751] [2, 2698] [2, 2698] [2, 2698] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.027255000546574593 with beta sum per layer: [0.0, 0.0, 0.7342239618301392, 0.0, 0.5610148906707764, 0.0, 0.0, 0.0, 0.0, 4.402017593383789]
alpha/beta optimization time: 0.8133800029754639
This batch time : update_bounds func: 0.8439	 prepare: 0.0077	 bound: 0.8140	 transfer: 0.0187	 finalize: 0.0033
Accumulated time: update_bounds func: 68.2156	 prepare: 0.6054	 bound: 66.0626	 transfer: 0.0187	 finalize: 0.2586
batch bounding time:  0.8442447185516357
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (82), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (82), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (82), [-0.00271,   inf] (80), 
length of domains: 311
Total time: 0.9339	 pickout: 0.0091	 decision: 0.0780	 get_bound: 0.8444	 add_domain: 0.0024
Current lb:-0.0027110204100608826
1176 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 81.36854386329651

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2698] [2, 15766] [2, 15766] [2, 15766] [2, 15766] [2, 15766] [2, 15766] [2, 15766] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.020854337140917778 with beta sum per layer: [0.0, 0.0, 1.350776195526123, 0.0, 0.8624269366264343, 0.0, 0.0, 0.0, 0.0, 4.878962993621826]
alpha/beta optimization time: 0.8655867576599121
This batch time : update_bounds func: 0.8870	 prepare: 0.0077	 bound: 0.8663	 transfer: 0.0096	 finalize: 0.0033
Accumulated time: update_bounds func: 69.1026	 prepare: 0.6131	 bound: 66.9288	 transfer: 0.0096	 finalize: 0.2619
batch bounding time:  0.8873765468597412
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (82), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (82), [-0.00271,   inf] (80), [-0.00271,   inf] (82), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), 
length of domains: 314
Total time: 0.9764	 pickout: 0.0091	 decision: 0.0778	 get_bound: 0.8874	 add_domain: 0.0022
Current lb:-0.0027110204100608826
1192 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 82.34560966491699

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2698] [2, 15766] [2, 15766] [2, 15766] [2, 15766] [2, 15766] [2, 15766] [2, 2698] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.023823730647563934 with beta sum per layer: [0.0, 0.0, 1.1043914556503296, 0.0, 0.6717592477798462, 0.0, 0.0, 0.0, 0.0, 3.715000867843628]
alpha/beta optimization time: 0.8419029712677002
This batch time : update_bounds func: 0.8736	 prepare: 0.0077	 bound: 0.8426	 transfer: 0.0197	 finalize: 0.0035
Accumulated time: update_bounds func: 69.9762	 prepare: 0.6208	 bound: 67.7714	 transfer: 0.0197	 finalize: 0.2654
batch bounding time:  0.8740541934967041
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (80), [-0.00271,   inf] (82), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), 
length of domains: 318
Total time: 0.9655	 pickout: 0.0102	 decision: 0.0788	 get_bound: 0.8741	 add_domain: 0.0024
Current lb:-0.0027110204100608826
1208 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 83.31173133850098

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 15766] [2, 15766] [9, 751] [9, 751] [9, 751] [2, 2698] [2, 2703] [2, 2703] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.010763563215732574 with beta sum per layer: [0.0, 0.0, 1.0531467199325562, 0.0, 1.1169323921203613, 0.0, 0.0, 0.0, 0.0, 6.116305351257324]
alpha/beta optimization time: 0.9159111976623535
This batch time : update_bounds func: 0.9477	 prepare: 0.0079	 bound: 0.9166	 transfer: 0.0187	 finalize: 0.0044
Accumulated time: update_bounds func: 70.9239	 prepare: 0.6287	 bound: 68.6881	 transfer: 0.0187	 finalize: 0.2699
batch bounding time:  0.9481220245361328
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (82), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (80), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), 
length of domains: 320
Total time: 1.0385	 pickout: 0.0091	 decision: 0.0793	 get_bound: 0.9482	 add_domain: 0.0019
Current lb:-0.0027110055088996887
1224 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 84.35097026824951

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 15766] [2, 15766] [2, 15766] [9, 751] [4, 3248] [2, 2698] [2, 2698] [2, 15766] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.025002529844641685 with beta sum per layer: [0.0, 0.0, 0.8245075941085815, 0.0, 0.36869895458221436, 0.0, 0.0, 0.0, 0.0, 5.13275146484375]
alpha/beta optimization time: 0.8312640190124512
This batch time : update_bounds func: 0.8530	 prepare: 0.0078	 bound: 0.8319	 transfer: 0.0099	 finalize: 0.0033
Accumulated time: update_bounds func: 71.7770	 prepare: 0.6365	 bound: 69.5199	 transfer: 0.0099	 finalize: 0.2731
batch bounding time:  0.8533914089202881
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (84), [-0.00271,   inf] (82), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), 
length of domains: 324
Total time: 0.9431	 pickout: 0.0091	 decision: 0.0782	 get_bound: 0.8534	 add_domain: 0.0023
Current lb:-0.002710990607738495
1240 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 85.29463791847229

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 15766] [4, 3248] [2, 15766] [2, 15766] [2, 15766] [2, 15766] [9, 751] [9, 751] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.02351406216621399 with beta sum per layer: [0.0, 0.0, 0.8710039854049683, 0.0, 0.49866926670074463, 0.0, 0.0, 0.0, 0.0, 5.913027286529541]
alpha/beta optimization time: 0.8362941741943359
This batch time : update_bounds func: 0.8683	 prepare: 0.0079	 bound: 0.8370	 transfer: 0.0199	 finalize: 0.0034
Accumulated time: update_bounds func: 72.6453	 prepare: 0.6445	 bound: 70.3569	 transfer: 0.0199	 finalize: 0.2766
batch bounding time:  0.8687152862548828
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), 
length of domains: 330
Total time: 0.9602	 pickout: 0.0103	 decision: 0.0784	 get_bound: 0.8688	 add_domain: 0.0028
Current lb:-0.002710990607738495
1256 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 86.25549960136414

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 15766] [2, 15766] [2, 2698] [9, 751] [9, 751] [2, 2698] [9, 751] [9, 751] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.025018615648150444 with beta sum per layer: [0.0, 0.0, 0.35199105739593506, 0.0, 0.4697640836238861, 0.0, 0.0, 0.0, 0.0, 6.6058759689331055]
alpha/beta optimization time: 0.8333992958068848
This batch time : update_bounds func: 0.8650	 prepare: 0.0079	 bound: 0.8341	 transfer: 0.0196	 finalize: 0.0033
Accumulated time: update_bounds func: 73.5102	 prepare: 0.6524	 bound: 71.1910	 transfer: 0.0196	 finalize: 0.2798
batch bounding time:  0.8653178215026855
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), 
length of domains: 334
Total time: 0.9569	 pickout: 0.0102	 decision: 0.0790	 get_bound: 0.8654	 add_domain: 0.0022
Current lb:-0.002710886299610138
1272 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 87.21298551559448

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 751] [9, 751] [2, 15766] [2, 2698] [9, 751] [2, 15766] [2, 15766] [9, 751] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.024482764303684235 with beta sum per layer: [0.0, 0.0, 0.5228551030158997, 0.0, 0.6892936825752258, 0.0, 0.0, 0.0, 0.0, 7.2503156661987305]
alpha/beta optimization time: 0.8382954597473145
This batch time : update_bounds func: 0.8701	 prepare: 0.0080	 bound: 0.8390	 transfer: 0.0195	 finalize: 0.0035
Accumulated time: update_bounds func: 74.3803	 prepare: 0.6604	 bound: 72.0300	 transfer: 0.0195	 finalize: 0.2834
batch bounding time:  0.870518684387207
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (82), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (84), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (86), [-0.00271,   inf] (86), 
length of domains: 339
Total time: 0.9615	 pickout: 0.0102	 decision: 0.0783	 get_bound: 0.8706	 add_domain: 0.0025
Current lb:-0.002710886299610138
1288 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 88.1751720905304

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 15766] [2, 15766] [2, 15766] [2, 15766] [9, 751] [9, 751] [9, 751] [2, 15766] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.022021807730197906 with beta sum per layer: [0.0, 0.0, 0.9086070656776428, 0.0, 0.9111917018890381, 0.0, 0.0, 0.0, 0.0, 7.081089019775391]
alpha/beta optimization time: 0.8655531406402588
This batch time : update_bounds func: 0.8939	 prepare: 0.0079	 bound: 0.8663	 transfer: 0.0160	 finalize: 0.0036
Accumulated time: update_bounds func: 75.2742	 prepare: 0.6682	 bound: 72.8963	 transfer: 0.0160	 finalize: 0.2870
batch bounding time:  0.8944194316864014
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (84), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (84), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), 
length of domains: 345
Total time: 0.9877	 pickout: 0.0092	 decision: 0.0800	 get_bound: 0.8945	 add_domain: 0.0040
Current lb:-0.002710871398448944
1304 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 89.1636734008789

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 15766] [2, 15766] [2, 15766] [2, 15766] [2, 15766] [2, 2698] [2, 15766] [4, 3727] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.024791482836008072 with beta sum per layer: [0.0, 0.0, 1.1170625686645508, 0.0, 0.7842835187911987, 0.0, 0.0, 0.0, 0.0, 3.539106845855713]
alpha/beta optimization time: 0.875988245010376
This batch time : update_bounds func: 0.8961	 prepare: 0.0081	 bound: 0.8768	 transfer: 0.0063	 finalize: 0.0049
Accumulated time: update_bounds func: 76.1703	 prepare: 0.6763	 bound: 73.7731	 transfer: 0.0063	 finalize: 0.2918
batch bounding time:  0.896472692489624
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (82), [-0.00271,   inf] (80), [-0.00271,   inf] (80), [-0.00271,   inf] (82), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), 
length of domains: 348
Total time: 1.0016	 pickout: 0.0096	 decision: 0.0932	 get_bound: 0.8965	 add_domain: 0.0023
Current lb:-0.002710871398448944
1320 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 90.16607189178467

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 15766] [2, 15766] [9, 751] [9, 751] [9, 751] [2, 15766] [9, 751] [2, 2703] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.002941119484603405 with beta sum per layer: [0.0, 0.0, 0.8663716912269592, 0.0, 0.866887092590332, 0.0, 0.0, 0.0, 0.0, 7.782127380371094]
alpha/beta optimization time: 1.001574993133545
This batch time : update_bounds func: 1.0286	 prepare: 0.0114	 bound: 1.0025	 transfer: 0.0112	 finalize: 0.0034
Accumulated time: update_bounds func: 77.1989	 prepare: 0.6877	 bound: 74.7755	 transfer: 0.0112	 finalize: 0.2952
batch bounding time:  1.0289809703826904
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (82), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), 
length of domains: 349
Total time: 1.1336	 pickout: 0.0117	 decision: 0.0911	 get_bound: 1.0290	 add_domain: 0.0019
Current lb:-0.0027108564972877502
1336 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 91.30041718482971

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 15766] [2, 15766] [2, 15766] [2, 15766] [2, 15766] [2, 15766] [4, 3248] [4, 3248] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.022386997938156128 with beta sum per layer: [0.0, 0.0, 1.0556564331054688, 0.0, 0.4034372568130493, 0.0, 0.0, 0.0, 0.0, 3.995493173599243]
alpha/beta optimization time: 0.8126945495605469
This batch time : update_bounds func: 0.8343	 prepare: 0.0078	 bound: 0.8134	 transfer: 0.0096	 finalize: 0.0034
Accumulated time: update_bounds func: 78.0332	 prepare: 0.6955	 bound: 75.5889	 transfer: 0.0096	 finalize: 0.2987
batch bounding time:  0.8346519470214844
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), 
length of domains: 351
Total time: 0.9234	 pickout: 0.0090	 decision: 0.0777	 get_bound: 0.8347	 add_domain: 0.0020
Current lb:-0.0027102306485176086
1352 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 92.22451829910278

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3248] [4, 3248] [4, 3248] [4, 3248] [4, 3248] [4, 3248] [4, 3248] [4, 3248] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04336369037628174 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.7345905303955078
This batch time : update_bounds func: 0.7659	 prepare: 0.0078	 bound: 0.7353	 transfer: 0.0193	 finalize: 0.0035
Accumulated time: update_bounds func: 78.7990	 prepare: 0.7033	 bound: 76.3241	 transfer: 0.0193	 finalize: 0.3021
batch bounding time:  0.766315221786499
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), 
length of domains: 359
Total time: 0.8575	 pickout: 0.0101	 decision: 0.0777	 get_bound: 0.7664	 add_domain: 0.0032
Current lb:-0.0027102306485176086
1368 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 93.08261394500732

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3248] [4, 3248] [4, 3248] [4, 3248] [4, 3248] [4, 3248] [4, 3248] [4, 3248] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04336369037628174 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.7261662483215332
This batch time : update_bounds func: 0.7574	 prepare: 0.0078	 bound: 0.7268	 transfer: 0.0193	 finalize: 0.0034
Accumulated time: update_bounds func: 79.5565	 prepare: 0.7110	 bound: 77.0510	 transfer: 0.0193	 finalize: 0.3055
batch bounding time:  0.7578530311584473
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), 
length of domains: 367
Total time: 0.8507	 pickout: 0.0102	 decision: 0.0783	 get_bound: 0.7579	 add_domain: 0.0042
Current lb:-0.0027102306485176086
1384 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 93.93384838104248

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3248] [4, 3248] [4, 3248] [4, 3248] [4, 3248] [9, 879] [2, 2516] [2, 2516] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.031350236386060715 with beta sum per layer: [0.0, 0.0, 0.27558547258377075, 0.0, 0.7173451781272888, 0.0, 0.0, 0.0, 0.0, 1.852107048034668]
alpha/beta optimization time: 0.8864426612854004
This batch time : update_bounds func: 0.9179	 prepare: 0.0080	 bound: 0.8871	 transfer: 0.0193	 finalize: 0.0034
Accumulated time: update_bounds func: 80.4744	 prepare: 0.7191	 bound: 77.9381	 transfer: 0.0193	 finalize: 0.3089
batch bounding time:  0.9183437824249268
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), 
length of domains: 374
Total time: 1.0099	 pickout: 0.0104	 decision: 0.0782	 get_bound: 0.9184	 add_domain: 0.0030
Current lb:-0.0027102306485176086
1400 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 94.94449305534363

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04219498485326767 with beta sum per layer: [0.0, 0.0, 0.5511709451675415, 0.0, 0.40531203150749207, 0.0, 0.0, 0.0, 0.0, 2.4640159606933594]
alpha/beta optimization time: 0.7762191295623779
This batch time : update_bounds func: 0.8073	 prepare: 0.0077	 bound: 0.7769	 transfer: 0.0193	 finalize: 0.0033
Accumulated time: update_bounds func: 81.2817	 prepare: 0.7267	 bound: 78.7150	 transfer: 0.0193	 finalize: 0.3122
batch bounding time:  0.8077514171600342
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), 
length of domains: 382
Total time: 0.8999	 pickout: 0.0100	 decision: 0.0788	 get_bound: 0.8078	 add_domain: 0.0033
Current lb:-0.0027102306485176086
1416 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 95.84501767158508

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04062853008508682 with beta sum per layer: [0.0, 0.0, 0.6351877450942993, 0.0, 0.38550180196762085, 0.0, 0.0, 0.0, 0.0, 3.816103219985962]
alpha/beta optimization time: 0.7587544918060303
This batch time : update_bounds func: 0.7898	 prepare: 0.0077	 bound: 0.7595	 transfer: 0.0193	 finalize: 0.0033
Accumulated time: update_bounds func: 82.0715	 prepare: 0.7344	 bound: 79.4745	 transfer: 0.0193	 finalize: 0.3156
batch bounding time:  0.7902355194091797
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), 
length of domains: 390
Total time: 0.8821	 pickout: 0.0103	 decision: 0.0783	 get_bound: 0.7903	 add_domain: 0.0032
Current lb:-0.0027102306485176086
1432 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 96.72764134407043

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04231152683496475 with beta sum per layer: [0.0, 0.0, 0.5511709451675415, 0.0, 0.43555572628974915, 0.0, 0.0, 0.0, 0.0, 2.4757211208343506]
alpha/beta optimization time: 0.7531991004943848
This batch time : update_bounds func: 0.7828	 prepare: 0.0077	 bound: 0.7539	 transfer: 0.0178	 finalize: 0.0033
Accumulated time: update_bounds func: 82.8544	 prepare: 0.7422	 bound: 80.2283	 transfer: 0.0178	 finalize: 0.3189
batch bounding time:  0.783212423324585
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), 
length of domains: 398
Total time: 0.8749	 pickout: 0.0091	 decision: 0.0782	 get_bound: 0.7833	 add_domain: 0.0044
Current lb:-0.0027102306485176086
1448 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 97.60314536094666

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.0405147559940815 with beta sum per layer: [0.0, 0.0, 0.9107732176780701, 0.0, 0.6025078296661377, 0.0, 0.0, 0.0, 0.0, 5.063358783721924]
alpha/beta optimization time: 0.7570788860321045
This batch time : update_bounds func: 0.7785	 prepare: 0.0077	 bound: 0.7578	 transfer: 0.0097	 finalize: 0.0033
Accumulated time: update_bounds func: 83.6329	 prepare: 0.7498	 bound: 80.9861	 transfer: 0.0097	 finalize: 0.3221
batch bounding time:  0.7789602279663086
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (84), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), 
length of domains: 406
Total time: 0.8694	 pickout: 0.0090	 decision: 0.0782	 get_bound: 0.7790	 add_domain: 0.0032
Current lb:-0.0027102306485176086
1464 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 98.47316575050354

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.041825100779533386 with beta sum per layer: [0.0, 0.0, 0.48731473088264465, 0.0, 0.34997326135635376, 0.0, 0.0, 0.0, 0.0, 2.5219287872314453]
alpha/beta optimization time: 0.7509043216705322
This batch time : update_bounds func: 0.7804	 prepare: 0.0077	 bound: 0.7516	 transfer: 0.0177	 finalize: 0.0033
Accumulated time: update_bounds func: 84.4133	 prepare: 0.7575	 bound: 81.7377	 transfer: 0.0177	 finalize: 0.3255
batch bounding time:  0.7808792591094971
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (84), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), 
length of domains: 414
Total time: 0.8714	 pickout: 0.0092	 decision: 0.0781	 get_bound: 0.7809	 add_domain: 0.0032
Current lb:-0.0027102306485176086
1480 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 99.34528183937073

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [9, 879] [4, 3248] [4, 3248] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.027074726298451424 with beta sum per layer: [0.0, 0.0, 0.48731473088264465, 0.0, 0.6227225065231323, 0.0, 0.0, 0.0, 0.0, 3.2047252655029297]
alpha/beta optimization time: 0.8866562843322754
This batch time : update_bounds func: 0.9083	 prepare: 0.0080	 bound: 0.8873	 transfer: 0.0095	 finalize: 0.0033
Accumulated time: update_bounds func: 85.3216	 prepare: 0.7656	 bound: 82.6250	 transfer: 0.0095	 finalize: 0.3288
batch bounding time:  0.9086487293243408
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), 
length of domains: 421
Total time: 1.0001	 pickout: 0.0094	 decision: 0.0789	 get_bound: 0.9088	 add_domain: 0.0029
Current lb:-0.002710200846195221
1496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 100.34593200683594

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3248] [4, 3248] [2, 2698] [2, 2698] [9, 879] [9, 879] [2, 2698] [2, 2698] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.0035396739840507507 with beta sum per layer: [0.0, 0.0, 0.06385624408721924, 0.0, 0.48656436800956726, 0.0, 0.0, 0.0, 0.0, 2.76893949508667]
alpha/beta optimization time: 0.8796448707580566
This batch time : update_bounds func: 0.9112	 prepare: 0.0080	 bound: 0.8803	 transfer: 0.0194	 finalize: 0.0034
Accumulated time: update_bounds func: 86.2327	 prepare: 0.7735	 bound: 83.5054	 transfer: 0.0194	 finalize: 0.3321
batch bounding time:  0.9115593433380127
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (86), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), 
length of domains: 427
Total time: 1.0045	 pickout: 0.0105	 decision: 0.0785	 get_bound: 0.9116	 add_domain: 0.0039
Current lb:-0.002710200846195221
1512 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 101.35100388526917

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2698] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04112911596894264 with beta sum per layer: [0.0, 0.0, 0.5830990672111511, 0.0, 0.2524965703487396, 0.0, 0.0, 0.0, 0.0, 3.15596866607666]
alpha/beta optimization time: 0.774277925491333
This batch time : update_bounds func: 0.8074	 prepare: 0.0078	 bound: 0.7750	 transfer: 0.0198	 finalize: 0.0048
Accumulated time: update_bounds func: 87.0401	 prepare: 0.7813	 bound: 84.2803	 transfer: 0.0198	 finalize: 0.3369
batch bounding time:  0.8078210353851318
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), 
length of domains: 435
Total time: 0.9000	 pickout: 0.0101	 decision: 0.0785	 get_bound: 0.8079	 add_domain: 0.0034
Current lb:-0.002710200846195221
1528 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 102.25154447555542

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04146101325750351 with beta sum per layer: [0.0, 0.0, 0.5931793451309204, 0.0, 0.23329856991767883, 0.0, 0.0, 0.0, 0.0, 3.2350363731384277]
alpha/beta optimization time: 0.7908182144165039
This batch time : update_bounds func: 0.8258	 prepare: 0.0113	 bound: 0.7917	 transfer: 0.0194	 finalize: 0.0033
Accumulated time: update_bounds func: 87.8659	 prepare: 0.7926	 bound: 85.0720	 transfer: 0.0194	 finalize: 0.3402
batch bounding time:  0.8262100219726562
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), 
length of domains: 443
Total time: 0.9346	 pickout: 0.0128	 decision: 0.0923	 get_bound: 0.8262	 add_domain: 0.0032
Current lb:-0.002710200846195221
1544 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 103.18674635887146

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2516] [2, 2516] [2, 2485] [2, 2485] [9, 879] [9, 879] [9, 879] [2, 2485] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.026923038065433502 with beta sum per layer: [0.0, 0.0, 0.3810381293296814, 0.0, 1.5168148279190063, 0.0, 0.0, 0.0, 0.0, 5.820751190185547]
alpha/beta optimization time: 0.8767540454864502
This batch time : update_bounds func: 0.9102	 prepare: 0.0080	 bound: 0.8775	 transfer: 0.0199	 finalize: 0.0048
Accumulated time: update_bounds func: 88.7762	 prepare: 0.8006	 bound: 85.9495	 transfer: 0.0199	 finalize: 0.3450
batch bounding time:  0.9106588363647461
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), 
length of domains: 448
Total time: 1.0024	 pickout: 0.0104	 decision: 0.0783	 get_bound: 0.9107	 add_domain: 0.0029
Current lb:-0.002710193395614624
1560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 104.18975925445557

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] [2, 2699] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.1015935018658638 with beta sum per layer: [0.0, 0.0, 0.24888357520103455, 0.0, 2.422602653503418, 0.0, 0.0, 0.0, 0.0, 6.710643768310547]
alpha/beta optimization time: 0.9123368263244629
This batch time : update_bounds func: 0.9479	 prepare: 0.0120	 bound: 0.9132	 transfer: 0.0193	 finalize: 0.0034
Accumulated time: update_bounds func: 89.7241	 prepare: 0.8126	 bound: 86.8627	 transfer: 0.0193	 finalize: 0.3484
batch bounding time:  0.9483225345611572
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), 
length of domains: 449
Total time: 1.0550	 pickout: 0.0128	 decision: 0.0920	 get_bound: 0.9484	 add_domain: 0.0020
Current lb:-0.002710193395614624
1576 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 105.2454845905304

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.1538493037223816 with beta sum per layer: [0.0, 0.0, 0.03617813438177109, 0.0, 2.247197151184082, 0.0, 0.0, 0.0, 0.0, 6.879137992858887]
alpha/beta optimization time: 0.8775546550750732
This batch time : update_bounds func: 0.9102	 prepare: 0.0078	 bound: 0.8782	 transfer: 0.0195	 finalize: 0.0046
Accumulated time: update_bounds func: 90.6343	 prepare: 0.8205	 bound: 87.7409	 transfer: 0.0195	 finalize: 0.3530
batch bounding time:  0.910656213760376
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), 
length of domains: 449
Total time: 1.0012	 pickout: 0.0104	 decision: 0.0784	 get_bound: 0.9107	 add_domain: 0.0017
Current lb:-0.002710193395614624
1592 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 106.24735188484192

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.16009816527366638 with beta sum per layer: [0.0, 0.0, 0.03617813438177109, 0.0, 2.332146644592285, 0.0, 0.0, 0.0, 0.0, 7.16195821762085]
alpha/beta optimization time: 0.8709096908569336
This batch time : update_bounds func: 0.9024	 prepare: 0.0077	 bound: 0.8716	 transfer: 0.0194	 finalize: 0.0035
Accumulated time: update_bounds func: 91.5367	 prepare: 0.8282	 bound: 88.6125	 transfer: 0.0194	 finalize: 0.3565
batch bounding time:  0.9028165340423584
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), 
length of domains: 449
Total time: 0.9936	 pickout: 0.0103	 decision: 0.0787	 get_bound: 0.9029	 add_domain: 0.0017
Current lb:-0.002710193395614624
1608 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 107.24160599708557

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.13587139546871185 with beta sum per layer: [0.0, 0.0, 0.07235626876354218, 0.0, 2.681925058364868, 0.0, 0.0, 0.0, 0.0, 6.767431259155273]
alpha/beta optimization time: 0.9650392532348633
This batch time : update_bounds func: 0.9966	 prepare: 0.0078	 bound: 0.9657	 transfer: 0.0195	 finalize: 0.0035
Accumulated time: update_bounds func: 92.5333	 prepare: 0.8359	 bound: 89.5783	 transfer: 0.0195	 finalize: 0.3600
batch bounding time:  0.997063159942627
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), 
length of domains: 449
Total time: 1.0874	 pickout: 0.0102	 decision: 0.0783	 get_bound: 0.9971	 add_domain: 0.0018
Current lb:-0.002710193395614624
1624 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 108.32978439331055

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.13067936897277832 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 2.4448041915893555, 0.0, 0.0, 0.0, 0.0, 6.425388813018799]
alpha/beta optimization time: 0.9596593379974365
This batch time : update_bounds func: 0.9910	 prepare: 0.0077	 bound: 0.9603	 transfer: 0.0194	 finalize: 0.0034
Accumulated time: update_bounds func: 93.5243	 prepare: 0.8436	 bound: 90.5386	 transfer: 0.0194	 finalize: 0.3635
batch bounding time:  0.991377592086792
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (90), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), 
length of domains: 449
Total time: 1.0848	 pickout: 0.0134	 decision: 0.0781	 get_bound: 0.9914	 add_domain: 0.0018
Current lb:-0.002710193395614624
1640 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 109.41529440879822

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3248] [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2485] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04233498126268387 with beta sum per layer: [0.0, 0.0, 0.1331307590007782, 0.0, 0.30388906598091125, 0.0, 0.0, 0.0, 0.0, 1.8319875001907349]
alpha/beta optimization time: 0.8012402057647705
This batch time : update_bounds func: 0.8326	 prepare: 0.0078	 bound: 0.8019	 transfer: 0.0193	 finalize: 0.0035
Accumulated time: update_bounds func: 94.3569	 prepare: 0.8514	 bound: 91.3405	 transfer: 0.0193	 finalize: 0.3670
batch bounding time:  0.8330395221710205
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), 
length of domains: 457
Total time: 0.9258	 pickout: 0.0109	 decision: 0.0785	 get_bound: 0.8331	 add_domain: 0.0033
Current lb:-0.002710193395614624
1656 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 110.34172677993774

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2699] [2, 2699] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03978361189365387 with beta sum per layer: [0.0, 0.0, 0.09985998272895813, 0.0, 0.3749336302280426, 0.0, 0.0, 0.0, 0.0, 3.7502357959747314]
alpha/beta optimization time: 0.7829608917236328
This batch time : update_bounds func: 0.8140	 prepare: 0.0076	 bound: 0.7836	 transfer: 0.0193	 finalize: 0.0034
Accumulated time: update_bounds func: 95.1709	 prepare: 0.8591	 bound: 92.1241	 transfer: 0.0193	 finalize: 0.3704
batch bounding time:  0.8144264221191406
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), 
length of domains: 465
Total time: 0.9089	 pickout: 0.0105	 decision: 0.0794	 get_bound: 0.8145	 add_domain: 0.0045
Current lb:-0.002710193395614624
1672 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 111.25119090080261

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2699] [2, 2699] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04226027801632881 with beta sum per layer: [0.0, 0.0, 0.177507683634758, 0.0, 0.43035024404525757, 0.0, 0.0, 0.0, 0.0, 2.4517130851745605]
alpha/beta optimization time: 0.7941906452178955
This batch time : update_bounds func: 0.8253	 prepare: 0.0077	 bound: 0.7949	 transfer: 0.0191	 finalize: 0.0035
Accumulated time: update_bounds func: 95.9962	 prepare: 0.8668	 bound: 92.9190	 transfer: 0.0191	 finalize: 0.3739
batch bounding time:  0.8257124423980713
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), 
length of domains: 473
Total time: 0.9169	 pickout: 0.0093	 decision: 0.0784	 get_bound: 0.8258	 add_domain: 0.0033
Current lb:-0.002710193395614624
1688 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 112.16879200935364

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2699] [2, 2699] [2, 2485] [2, 2485] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03953396901488304 with beta sum per layer: [0.0, 0.0, 0.18861383199691772, 0.0, 0.601616382598877, 0.0, 0.0, 0.0, 0.0, 4.985699653625488]
alpha/beta optimization time: 0.7932617664337158
This batch time : update_bounds func: 0.8165	 prepare: 0.0079	 bound: 0.7940	 transfer: 0.0112	 finalize: 0.0033
Accumulated time: update_bounds func: 96.8127	 prepare: 0.8747	 bound: 93.7130	 transfer: 0.0112	 finalize: 0.3772
batch bounding time:  0.8168823719024658
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), 
length of domains: 481
Total time: 0.9107	 pickout: 0.0125	 decision: 0.0780	 get_bound: 0.8169	 add_domain: 0.0033
Current lb:-0.002710193395614624
1704 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 113.0801613330841

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2699] [2, 2699] [2, 2699] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04119192063808441 with beta sum per layer: [0.0, 0.0, 0.138818621635437, 0.0, 0.34997326135635376, 0.0, 0.0, 0.0, 0.0, 2.4535555839538574]
alpha/beta optimization time: 0.7530190944671631
This batch time : update_bounds func: 0.7745	 prepare: 0.0077	 bound: 0.7537	 transfer: 0.0098	 finalize: 0.0033
Accumulated time: update_bounds func: 97.5872	 prepare: 0.8824	 bound: 94.4667	 transfer: 0.0098	 finalize: 0.3805
batch bounding time:  0.7748675346374512
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (90), [-0.00271,   inf] (90), 
length of domains: 489
Total time: 0.8682	 pickout: 0.0122	 decision: 0.0777	 get_bound: 0.7749	 add_domain: 0.0034
Current lb:-0.002710193395614624
1720 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 113.94897437095642

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2485] [2, 2485] [2, 2699] [2, 2699] [2, 2699] [2, 2699] [2, 16015] [2, 16015] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.01442701555788517 with beta sum per layer: [0.0, 0.0, 0.9115696549415588, 0.0, 0.8106127977371216, 0.0, 0.0, 0.0, 0.0, 3.1915998458862305]
alpha/beta optimization time: 0.870781421661377
This batch time : update_bounds func: 0.8915	 prepare: 0.0077	 bound: 0.8715	 transfer: 0.0089	 finalize: 0.0034
Accumulated time: update_bounds func: 98.4787	 prepare: 0.8901	 bound: 95.3381	 transfer: 0.0089	 finalize: 0.3839
batch bounding time:  0.8919370174407959
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (90), [-0.00271,   inf] (90), 
length of domains: 495
Total time: 0.9853	 pickout: 0.0122	 decision: 0.0779	 get_bound: 0.8920	 add_domain: 0.0032
Current lb:-0.002710193395614624
1736 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 114.93504500389099

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 15762] [2, 16015] [2, 15762] [2, 16015] [2, 16015] [2, 16015] [2, 15762] [2, 16015] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.016934644430875778 with beta sum per layer: [0.0, 0.0, 2.9548699855804443, 0.0, 2.3547348976135254, 0.0, 0.0, 0.0, 0.0, 4.075736999511719]
alpha/beta optimization time: 0.8927299976348877
This batch time : update_bounds func: 0.9163	 prepare: 0.0077	 bound: 0.8934	 transfer: 0.0117	 finalize: 0.0033
Accumulated time: update_bounds func: 99.3950	 prepare: 0.8978	 bound: 96.2315	 transfer: 0.0117	 finalize: 0.3872
batch bounding time:  0.9166543483734131
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), 
length of domains: 498
Total time: 1.0070	 pickout: 0.0097	 decision: 0.0782	 get_bound: 0.9168	 add_domain: 0.0022
Current lb:-0.002710193395614624
1752 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 115.94272327423096

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 16015] [2, 16015] [2, 16015] [2, 16015] [2, 16015] [2, 655] [2, 16015] [2, 16015] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.04351089894771576 with beta sum per layer: [0.0, 0.0, 3.718770980834961, 0.0, 3.177210807800293, 0.0, 0.0, 0.0, 0.0, 3.4254298210144043]
alpha/beta optimization time: 0.892554759979248
This batch time : update_bounds func: 0.9238	 prepare: 0.0078	 bound: 0.8933	 transfer: 0.0194	 finalize: 0.0033
Accumulated time: update_bounds func: 100.3188	 prepare: 0.9056	 bound: 97.1248	 transfer: 0.0194	 finalize: 0.3904
batch bounding time:  0.9242193698883057
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), 
length of domains: 498
Total time: 1.0145	 pickout: 0.0103	 decision: 0.0782	 get_bound: 0.9243	 add_domain: 0.0017
Current lb:-0.002710193395614624
1768 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 116.95784664154053

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2485] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04069637507200241 with beta sum per layer: [0.0, 0.0, 0.0622439980506897, 0.0, 0.341533899307251, 0.0, 0.0, 0.0, 0.0, 3.2079648971557617]
alpha/beta optimization time: 0.758075475692749
This batch time : update_bounds func: 0.7901	 prepare: 0.0083	 bound: 0.7588	 transfer: 0.0194	 finalize: 0.0034
Accumulated time: update_bounds func: 101.1088	 prepare: 0.9140	 bound: 97.8836	 transfer: 0.0194	 finalize: 0.3938
batch bounding time:  0.7904605865478516
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), 
length of domains: 506
Total time: 0.8822	 pickout: 0.0102	 decision: 0.0780	 get_bound: 0.7905	 add_domain: 0.0035
Current lb:-0.002710193395614624
1784 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 117.84073066711426

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2485] [9, 879] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.013689829036593437 with beta sum per layer: [0.0, 0.0, 0.1622963398694992, 0.0, 0.6476447582244873, 0.0, 0.0, 0.0, 0.0, 4.055814743041992]
alpha/beta optimization time: 0.8650765419006348
This batch time : update_bounds func: 0.8952	 prepare: 0.0079	 bound: 0.8658	 transfer: 0.0182	 finalize: 0.0033
Accumulated time: update_bounds func: 102.0040	 prepare: 0.9218	 bound: 98.7494	 transfer: 0.0182	 finalize: 0.3971
batch bounding time:  0.8955698013305664
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (92), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), 
length of domains: 513
Total time: 0.9868	 pickout: 0.0097	 decision: 0.0783	 get_bound: 0.8956	 add_domain: 0.0033
Current lb:-0.0027101561427116394
1800 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 118.82834553718567

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.15492305159568787 with beta sum per layer: [0.0, 0.0, 0.10853440314531326, 0.0, 1.5795047283172607, 0.0, 0.0, 0.0, 0.0, 7.000762939453125]
alpha/beta optimization time: 0.8814520835876465
This batch time : update_bounds func: 0.9028	 prepare: 0.0078	 bound: 0.8821	 transfer: 0.0096	 finalize: 0.0032
Accumulated time: update_bounds func: 102.9069	 prepare: 0.9296	 bound: 99.6315	 transfer: 0.0096	 finalize: 0.4004
batch bounding time:  0.9032292366027832
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), 
length of domains: 513
Total time: 0.9954	 pickout: 0.0119	 decision: 0.0786	 get_bound: 0.9033	 add_domain: 0.0017
Current lb:-0.0027101561427116394
1816 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 119.82443523406982

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 879] [9, 879] [9, 879] [4, 3248] [4, 3248] [9, 879] [9, 879] [4, 3248] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.08333391696214676 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.9408729076385498, 0.0, 0.0, 0.0, 0.0, 4.414154529571533]
alpha/beta optimization time: 0.878277063369751
This batch time : update_bounds func: 0.9096	 prepare: 0.0078	 bound: 0.8790	 transfer: 0.0194	 finalize: 0.0034
Accumulated time: update_bounds func: 103.8165	 prepare: 0.9375	 bound: 100.5105	 transfer: 0.0194	 finalize: 0.4037
batch bounding time:  0.9100384712219238
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), 
length of domains: 516
Total time: 1.0033	 pickout: 0.0131	 decision: 0.0779	 get_bound: 0.9101	 add_domain: 0.0023
Current lb:-0.0027101561427116394
1832 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 120.82841730117798

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2699] [2, 2699] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04137495160102844 with beta sum per layer: [0.0, 0.0, 0.21370378136634827, 0.0, 0.2757978141307831, 0.0, 0.0, 0.0, 0.0, 3.738361358642578]
alpha/beta optimization time: 0.7531797885894775
This batch time : update_bounds func: 0.7845	 prepare: 0.0078	 bound: 0.7539	 transfer: 0.0194	 finalize: 0.0034
Accumulated time: update_bounds func: 104.6010	 prepare: 0.9453	 bound: 101.2644	 transfer: 0.0194	 finalize: 0.4071
batch bounding time:  0.7848813533782959
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (86), [-0.00271,   inf] (86), 
length of domains: 524
Total time: 0.8766	 pickout: 0.0101	 decision: 0.0781	 get_bound: 0.7850	 add_domain: 0.0033
Current lb:-0.0027101561427116394
1848 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 121.70554971694946

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2485] [2, 2485] [2, 2485] [2, 2699] [2, 2485] [2, 2485] [2, 2699] [2, 2485] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.040678732097148895 with beta sum per layer: [0.0, 0.0, 0.1622963547706604, 0.0, 0.31278759241104126, 0.0, 0.0, 0.0, 0.0, 4.491276264190674]
alpha/beta optimization time: 0.7546565532684326
This batch time : update_bounds func: 0.7840	 prepare: 0.0078	 bound: 0.7554	 transfer: 0.0174	 finalize: 0.0033
Accumulated time: update_bounds func: 105.3850	 prepare: 0.9531	 bound: 102.0198	 transfer: 0.0174	 finalize: 0.4104
batch bounding time:  0.7843704223632812
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (86), 
length of domains: 532
Total time: 0.8758	 pickout: 0.0091	 decision: 0.0790	 get_bound: 0.7844	 add_domain: 0.0033
Current lb:-0.0027101561427116394
1864 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 122.58201956748962

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 16015] [2, 16015] [2, 16015] [2, 16015] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.0070657879114151 with beta sum per layer: [0.0, 0.0, 2.038578987121582, 0.0, 1.2355700731277466, 0.0, 0.0, 0.0, 0.0, 4.464629173278809]
alpha/beta optimization time: 0.8063910007476807
This batch time : update_bounds func: 0.8245	 prepare: 0.0077	 bound: 0.8070	 transfer: 0.0064	 finalize: 0.0032
Accumulated time: update_bounds func: 106.2095	 prepare: 0.9608	 bound: 102.8268	 transfer: 0.0064	 finalize: 0.4136
batch bounding time:  0.8248844146728516
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (86), [-0.00271,   inf] (84), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), 
length of domains: 536
Total time: 0.9146	 pickout: 0.0090	 decision: 0.0782	 get_bound: 0.8249	 add_domain: 0.0025
Current lb:-0.0027101561427116394
1880 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 123.49728846549988

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2698] [2, 2698] [2, 2698] [2, 2698] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04196673631668091 with beta sum per layer: [0.0, 0.0, 0.03555354103446007, 0.0, 0.14485853910446167, 0.0, 0.0, 0.0, 0.0, 1.2757477760314941]
alpha/beta optimization time: 0.7664840221405029
This batch time : update_bounds func: 0.7880	 prepare: 0.0079	 bound: 0.7672	 transfer: 0.0095	 finalize: 0.0033
Accumulated time: update_bounds func: 106.9975	 prepare: 0.9687	 bound: 103.5940	 transfer: 0.0095	 finalize: 0.4170
batch bounding time:  0.7883937358856201
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (84), [-0.00271,   inf] (86), [-0.00271,   inf] (84), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (84), 
length of domains: 544
Total time: 0.8818	 pickout: 0.0106	 decision: 0.0786	 get_bound: 0.7884	 add_domain: 0.0042
Current lb:-0.0027100741863250732
1896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 124.37967443466187

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3248] [4, 3248] [4, 3248] [9, 751] [2, 2698] [2, 2698] [2, 2698] [4, 3248] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.038195960223674774 with beta sum per layer: [0.0, 0.0, 0.06931421905755997, 0.0, 0.39253121614456177, 0.0, 0.0, 0.0, 0.0, 3.189499855041504]
alpha/beta optimization time: 0.7935059070587158
This batch time : update_bounds func: 0.8251	 prepare: 0.0080	 bound: 0.7942	 transfer: 0.0193	 finalize: 0.0034
Accumulated time: update_bounds func: 107.8225	 prepare: 0.9767	 bound: 104.3882	 transfer: 0.0193	 finalize: 0.4204
batch bounding time:  0.8254923820495605
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (84), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), 
length of domains: 552
Total time: 0.9204	 pickout: 0.0134	 decision: 0.0783	 get_bound: 0.8256	 add_domain: 0.0031
Current lb:-0.0027100741863250732
1912 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 125.30076599121094

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2698] [4, 3248] [4, 3248] [4, 3248] [4, 3248] [9, 879] [4, 3248] [9, 879] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.0005951300263404846 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.7464603185653687, 0.0, 0.0, 0.0, 0.0, 1.8000385761260986]
alpha/beta optimization time: 0.9044523239135742
This batch time : update_bounds func: 0.9361	 prepare: 0.0080	 bound: 0.9052	 transfer: 0.0193	 finalize: 0.0035
Accumulated time: update_bounds func: 108.7586	 prepare: 0.9847	 bound: 105.2934	 transfer: 0.0193	 finalize: 0.4239
batch bounding time:  0.9365234375
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), 
length of domains: 558
Total time: 1.0300	 pickout: 0.0120	 decision: 0.0786	 get_bound: 0.9366	 add_domain: 0.0029
Current lb:-0.0027100741863250732
1928 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 126.33146572113037

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3248] [9, 879] [9, 879] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.005745213478803635 with beta sum per layer: [0.0, 0.0, 0.27558547258377075, 0.0, 0.7756983637809753, 0.0, 0.0, 0.0, 0.0, 3.106783151626587]
alpha/beta optimization time: 0.8893916606903076
This batch time : update_bounds func: 0.9209	 prepare: 0.0081	 bound: 0.8901	 transfer: 0.0193	 finalize: 0.0034
Accumulated time: update_bounds func: 109.6795	 prepare: 0.9927	 bound: 106.1835	 transfer: 0.0193	 finalize: 0.4273
batch bounding time:  0.9213433265686035
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (88), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (86), [-0.00271,   inf] (86), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), 
length of domains: 564
Total time: 1.0137	 pickout: 0.0104	 decision: 0.0791	 get_bound: 0.9214	 add_domain: 0.0029
Current lb:-0.0027100741863250732
1944 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 127.34584760665894

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2516] [9, 879] [9, 879] [9, 879] [9, 879] [2, 2516] [2, 2516] [4, 3248] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.04772884398698807 with beta sum per layer: [0.0, 0.0, 0.3694220185279846, 0.0, 1.185705304145813, 0.0, 0.0, 0.0, 0.0, 4.801085472106934]
alpha/beta optimization time: 0.8882765769958496
This batch time : update_bounds func: 0.9201	 prepare: 0.0082	 bound: 0.8890	 transfer: 0.0194	 finalize: 0.0034
Accumulated time: update_bounds func: 110.5996	 prepare: 1.0010	 bound: 107.0724	 transfer: 0.0194	 finalize: 0.4307
batch bounding time:  0.9205117225646973
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (86), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), 
length of domains: 568
Total time: 1.0114	 pickout: 0.0102	 decision: 0.0782	 get_bound: 0.9206	 add_domain: 0.0024
Current lb:-0.0027100741863250732
1960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 128.3578815460205

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 879] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.020135890692472458 with beta sum per layer: [0.0, 0.0, 0.6889636516571045, 0.0, 0.9455758333206177, 0.0, 0.0, 0.0, 0.0, 4.152734756469727]
alpha/beta optimization time: 0.8600213527679443
This batch time : update_bounds func: 0.8914	 prepare: 0.0079	 bound: 0.8607	 transfer: 0.0194	 finalize: 0.0033
Accumulated time: update_bounds func: 111.4910	 prepare: 1.0088	 bound: 107.9331	 transfer: 0.0194	 finalize: 0.4340
batch bounding time:  0.8917853832244873
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), 
length of domains: 575
Total time: 0.9845	 pickout: 0.0104	 decision: 0.0793	 get_bound: 0.8918	 add_domain: 0.0031
Current lb:-0.0027100741863250732
1976 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 129.34305787086487

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.041805487126111984 with beta sum per layer: [0.0, 0.0, 0.6889636516571045, 0.0, 0.5606334209442139, 0.0, 0.0, 0.0, 0.0, 3.2902708053588867]
alpha/beta optimization time: 0.7669916152954102
This batch time : update_bounds func: 0.7962	 prepare: 0.0077	 bound: 0.7677	 transfer: 0.0174	 finalize: 0.0033
Accumulated time: update_bounds func: 112.2872	 prepare: 1.0166	 bound: 108.7008	 transfer: 0.0174	 finalize: 0.4372
batch bounding time:  0.7965548038482666
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (88), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), 
length of domains: 583
Total time: 0.8868	 pickout: 0.0091	 decision: 0.0779	 get_bound: 0.7966	 add_domain: 0.0032
Current lb:-0.0027100741863250732
1992 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 130.23045825958252

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] [2, 2516] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04047873243689537 with beta sum per layer: [0.0, 0.0, 0.6990439891815186, 0.0, 0.4968688488006592, 0.0, 0.0, 0.0, 0.0, 3.9766881465911865]
alpha/beta optimization time: 0.848015308380127
This batch time : update_bounds func: 0.8717	 prepare: 0.0078	 bound: 0.8487	 transfer: 0.0105	 finalize: 0.0046
Accumulated time: update_bounds func: 113.1589	 prepare: 1.0244	 bound: 109.5495	 transfer: 0.0105	 finalize: 0.4419
batch bounding time:  0.8721191883087158
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), 
length of domains: 591
Total time: 0.9638	 pickout: 0.0091	 decision: 0.0792	 get_bound: 0.8722	 add_domain: 0.0034
Current lb:-0.0027100443840026855
2008 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 131.1948425769806

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.12653593719005585 with beta sum per layer: [0.0, 0.0, 0.16619279980659485, 0.0, 2.917862892150879, 0.0, 0.0, 0.0, 0.0, 7.43377685546875]
alpha/beta optimization time: 0.9446911811828613
This batch time : update_bounds func: 0.9800	 prepare: 0.0112	 bound: 0.9456	 transfer: 0.0197	 finalize: 0.0034
Accumulated time: update_bounds func: 114.1389	 prepare: 1.0356	 bound: 110.4951	 transfer: 0.0197	 finalize: 0.4452
batch bounding time:  0.9804267883300781
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), 
length of domains: 591
Total time: 1.0858	 pickout: 0.0127	 decision: 0.0909	 get_bound: 0.9805	 add_domain: 0.0018
Current lb:-0.0027100443840026855
2024 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 132.2813160419464

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] [9, 879] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.11981479823589325 with beta sum per layer: [0.0, 0.0, 0.07235626876354218, 0.0, 3.251357316970825, 0.0, 0.0, 0.0, 0.0, 7.111024856567383]
alpha/beta optimization time: 0.8908724784851074
This batch time : update_bounds func: 0.9234	 prepare: 0.0078	 bound: 0.8916	 transfer: 0.0195	 finalize: 0.0044
Accumulated time: update_bounds func: 115.0623	 prepare: 1.0434	 bound: 111.3866	 transfer: 0.0195	 finalize: 0.4497
batch bounding time:  0.9237911701202393
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), 
length of domains: 591
Total time: 1.0149	 pickout: 0.0106	 decision: 0.0788	 get_bound: 0.9238	 add_domain: 0.0017
Current lb:-0.0027100443840026855
2040 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 133.29682540893555

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3248] [9, 879] [9, 879] [4, 3248] [9, 879] [9, 879] [4, 3248] [4, 3248] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.0447157621383667 with beta sum per layer: [0.0, 0.0, 0.07235626876354218, 0.0, 1.493035078048706, 0.0, 0.0, 0.0, 0.0, 3.764552116394043]
alpha/beta optimization time: 0.8861699104309082
This batch time : update_bounds func: 0.9176	 prepare: 0.0078	 bound: 0.8869	 transfer: 0.0194	 finalize: 0.0033
Accumulated time: update_bounds func: 115.9799	 prepare: 1.0512	 bound: 112.2736	 transfer: 0.0194	 finalize: 0.4530
batch bounding time:  0.9179539680480957
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (90), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), 
length of domains: 595
Total time: 1.0092	 pickout: 0.0103	 decision: 0.0783	 get_bound: 0.9180	 add_domain: 0.0026
Current lb:-0.0027100443840026855
2056 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 134.30664205551147

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3248] [4, 3248] [4, 3248] [4, 3248] [9, 879] [9, 879] [4, 3248] [2, 2699] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.0017491914331912994 with beta sum per layer: [0.0, 0.0, 0.08231286704540253, 0.0, 0.8111623525619507, 0.0, 0.0, 0.0, 0.0, 2.5112526416778564]
alpha/beta optimization time: 0.8674805164337158
This batch time : update_bounds func: 0.8991	 prepare: 0.0080	 bound: 0.8682	 transfer: 0.0194	 finalize: 0.0034
Accumulated time: update_bounds func: 116.8790	 prepare: 1.0592	 bound: 113.1418	 transfer: 0.0194	 finalize: 0.4564
batch bounding time:  0.8994858264923096
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), 
length of domains: 601
Total time: 0.9927	 pickout: 0.0106	 decision: 0.0797	 get_bound: 0.8995	 add_domain: 0.0029
Current lb:-0.0027100443840026855
2072 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 135.30000162124634

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2699] [2, 2699] [2, 2699] [2, 2699] [2, 2699] [2, 2699] [2, 2699] [2, 2699] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03918245807290077 with beta sum per layer: [0.0, 0.0, 0.18453893065452576, 0.0, 0.3905152678489685, 0.0, 0.0, 0.0, 0.0, 2.5622715950012207]
alpha/beta optimization time: 0.740248441696167
This batch time : update_bounds func: 0.7695	 prepare: 0.0076	 bound: 0.7409	 transfer: 0.0176	 finalize: 0.0033
Accumulated time: update_bounds func: 117.6484	 prepare: 1.0668	 bound: 113.8827	 transfer: 0.0176	 finalize: 0.4596
batch bounding time:  0.7698900699615479
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), 
length of domains: 609
Total time: 0.8602	 pickout: 0.0091	 decision: 0.0778	 get_bound: 0.7699	 add_domain: 0.0033
Current lb:-0.0027100443840026855
2088 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 136.16081619262695

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2699] [2, 2699] [2, 2699] [2, 2699] [2, 2699] [2, 2699] [2, 16015] [2, 2699] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.027270697057247162 with beta sum per layer: [0.0, 0.0, 0.668868899345398, 0.0, 0.8518168926239014, 0.0, 0.0, 0.0, 0.0, 3.018801689147949]
alpha/beta optimization time: 0.8071112632751465
This batch time : update_bounds func: 0.8253	 prepare: 0.0078	 bound: 0.8078	 transfer: 0.0064	 finalize: 0.0032
Accumulated time: update_bounds func: 118.4737	 prepare: 1.0746	 bound: 114.6905	 transfer: 0.0064	 finalize: 0.4628
batch bounding time:  0.8256552219390869
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), 
length of domains: 616
Total time: 0.9161	 pickout: 0.0091	 decision: 0.0782	 get_bound: 0.8257	 add_domain: 0.0031
Current lb:-0.0027100443840026855
2104 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 137.07758808135986

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2699] [2, 2699] [2, 2699] [2, 2699] [2, 2699] [2, 2699] [2, 2699] [2, 2699] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.039558880031108856 with beta sum per layer: [0.0, 0.0, 0.18453893065452576, 0.0, 0.41558074951171875, 0.0, 0.0, 0.0, 0.0, 2.5816245079040527]
alpha/beta optimization time: 0.7559630870819092
This batch time : update_bounds func: 0.7774	 prepare: 0.0077	 bound: 0.7566	 transfer: 0.0097	 finalize: 0.0033
Accumulated time: update_bounds func: 119.2511	 prepare: 1.0824	 bound: 115.4471	 transfer: 0.0097	 finalize: 0.4661
batch bounding time:  0.7777462005615234
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), 
length of domains: 624
Total time: 0.8679	 pickout: 0.0090	 decision: 0.0778	 get_bound: 0.7778	 add_domain: 0.0033
Current lb:-0.0027100443840026855
2120 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 137.946040391922

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2699] [2, 2699] [2, 2699] [2, 2699] [2, 2699] [2, 2699] [2, 2699] [2, 2699] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.0390232652425766 with beta sum per layer: [0.0, 0.0, 0.12516196072101593, 0.0, 0.3529541492462158, 0.0, 0.0, 0.0, 0.0, 3.2593677043914795]
alpha/beta optimization time: 0.7760553359985352
This batch time : update_bounds func: 0.8056	 prepare: 0.0076	 bound: 0.7767	 transfer: 0.0177	 finalize: 0.0034
Accumulated time: update_bounds func: 120.0566	 prepare: 1.0900	 bound: 116.2238	 transfer: 0.0177	 finalize: 0.4696
batch bounding time:  0.806117057800293
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (92), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), 
length of domains: 632
Total time: 0.8962	 pickout: 0.0090	 decision: 0.0776	 get_bound: 0.8062	 add_domain: 0.0034
Current lb:-0.0027100443840026855
2136 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 138.84297919273376

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2699] [2, 2699] [2, 2699] [2, 2699] [2, 2699] [2, 2699] [2, 2699] [2, 2485] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03843732923269272 with beta sum per layer: [0.0, 0.0, 0.21174356341362, 0.0, 0.5236213207244873, 0.0, 0.0, 0.0, 0.0, 3.902411937713623]
alpha/beta optimization time: 0.7808272838592529
This batch time : update_bounds func: 0.8022	 prepare: 0.0077	 bound: 0.7815	 transfer: 0.0096	 finalize: 0.0033
Accumulated time: update_bounds func: 120.8588	 prepare: 1.0977	 bound: 117.0054	 transfer: 0.0096	 finalize: 0.4729
batch bounding time:  0.8026008605957031
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), 
length of domains: 640
Total time: 0.8937	 pickout: 0.0093	 decision: 0.0785	 get_bound: 0.8026	 add_domain: 0.0033
Current lb:-0.0027100443840026855
2152 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 139.73725295066833

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 16015] [2, 16015] [2, 16015] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.010548099875450134 with beta sum per layer: [0.0, 0.0, 1.5389255285263062, 0.0, 1.7226183414459229, 0.0, 0.0, 0.0, 0.0, 3.388490676879883]
alpha/beta optimization time: 0.8340089321136475
This batch time : update_bounds func: 0.8648	 prepare: 0.0077	 bound: 0.8347	 transfer: 0.0192	 finalize: 0.0032
Accumulated time: update_bounds func: 121.7237	 prepare: 1.1054	 bound: 117.8400	 transfer: 0.0192	 finalize: 0.4761
batch bounding time:  0.865196704864502
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), 
length of domains: 645
Total time: 0.9566	 pickout: 0.0104	 decision: 0.0782	 get_bound: 0.8652	 add_domain: 0.0027
Current lb:-0.0027100443840026855
2168 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 140.69439101219177

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 16015] [2, 2485] [2, 2485] [2, 16015] [2, 16015] [2, 16015] [2, 16015] [2, 16015] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.016815923154354095 with beta sum per layer: [0.0, 0.0, 2.976208209991455, 0.0, 3.0869479179382324, 0.0, 0.0, 0.0, 0.0, 4.143699645996094]
alpha/beta optimization time: 0.8933730125427246
This batch time : update_bounds func: 0.9279	 prepare: 0.0077	 bound: 0.8941	 transfer: 0.0211	 finalize: 0.0049
Accumulated time: update_bounds func: 122.6516	 prepare: 1.1131	 bound: 118.7341	 transfer: 0.0211	 finalize: 0.4809
batch bounding time:  0.9283220767974854
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), 
length of domains: 647
Total time: 1.0190	 pickout: 0.0101	 decision: 0.0784	 get_bound: 0.9284	 add_domain: 0.0022
Current lb:-0.0027100443840026855
2184 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 141.71416091918945

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 16015] [2, 16015] [2, 16015] [2, 16015] [2, 2699] [2, 16015] [2, 2485] [2, 16015] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.01925050839781761 with beta sum per layer: [0.0, 0.0, 2.906905174255371, 0.0, 2.83404278755188, 0.0, 0.0, 0.0, 0.0, 3.4020471572875977]
alpha/beta optimization time: 0.9337358474731445
This batch time : update_bounds func: 0.9665	 prepare: 0.0077	 bound: 0.9345	 transfer: 0.0208	 finalize: 0.0034
Accumulated time: update_bounds func: 123.6180	 prepare: 1.1208	 bound: 119.6686	 transfer: 0.0208	 finalize: 0.4843
batch bounding time:  0.9668872356414795
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), 
length of domains: 649
Total time: 1.0589	 pickout: 0.0108	 decision: 0.0790	 get_bound: 0.9669	 add_domain: 0.0022
Current lb:-0.0027100443840026855
2200 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 142.77374386787415

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 16015] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.030362367630004883 with beta sum per layer: [0.0, 0.0, 0.6989002823829651, 0.0, 0.9425586462020874, 0.0, 0.0, 0.0, 0.0, 3.153346300125122]
alpha/beta optimization time: 0.8324425220489502
This batch time : update_bounds func: 0.8638	 prepare: 0.0077	 bound: 0.8332	 transfer: 0.0194	 finalize: 0.0034
Accumulated time: update_bounds func: 124.4818	 prepare: 1.1286	 bound: 120.5018	 transfer: 0.0194	 finalize: 0.4877
batch bounding time:  0.864224910736084
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), 
length of domains: 656
Total time: 0.9569	 pickout: 0.0105	 decision: 0.0789	 get_bound: 0.8643	 add_domain: 0.0033
Current lb:-0.0027100443840026855
2216 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 143.7312514781952

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 16015] [2, 16015] [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2485] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.01614508032798767 with beta sum per layer: [0.0, 0.0, 1.0915827751159668, 0.0, 1.2555170059204102, 0.0, 0.0, 0.0, 0.0, 3.5984842777252197]
alpha/beta optimization time: 0.8601093292236328
This batch time : update_bounds func: 0.8912	 prepare: 0.0078	 bound: 0.8608	 transfer: 0.0193	 finalize: 0.0033
Accumulated time: update_bounds func: 125.3730	 prepare: 1.1363	 bound: 121.3625	 transfer: 0.0193	 finalize: 0.4910
batch bounding time:  0.8916215896606445
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), 
length of domains: 662
Total time: 0.9840	 pickout: 0.0108	 decision: 0.0785	 get_bound: 0.8917	 add_domain: 0.0030
Current lb:-0.0027100443840026855
2232 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 144.71583318710327

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2485] [2, 2485] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.039623960852622986 with beta sum per layer: [0.0, 0.0, 0.09275174885988235, 0.0, 0.43484342098236084, 0.0, 0.0, 0.0, 0.0, 3.984365463256836]
alpha/beta optimization time: 0.7751297950744629
This batch time : update_bounds func: 0.8064	 prepare: 0.0077	 bound: 0.7758	 transfer: 0.0195	 finalize: 0.0033
Accumulated time: update_bounds func: 126.1795	 prepare: 1.1440	 bound: 122.1384	 transfer: 0.0195	 finalize: 0.4943
batch bounding time:  0.8068509101867676
Current worst splitting domains [lb, ub] (depth):
[-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (94), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), [-0.00271,   inf] (96), 
length of domains: 670
Total time: 0.8993	 pickout: 0.0103	 decision: 0.0785	 get_bound: 0.8069	 add_domain: 0.0036
Current lb:-0.0027100443840026855
2248 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Time out!!!!!!!!
Image 240 label 5 verification end, final lower bound -0.0027100443840026855, upper bound inf, time: 145.96718287467957
240 -0.0027100443840026855
Result: image 240 verification failure (with branch and bound).
Wall time: 180.8488564491272

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 0): []
verification failure idx (total 1): [240]
final verified acc: 0.0%[1]
verifier is called on 1 examples.
total verified: 0
mean time [cnt:1] (excluding attack success): 180.68362402915955
