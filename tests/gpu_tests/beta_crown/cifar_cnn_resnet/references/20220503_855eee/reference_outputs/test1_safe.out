Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_resnet_8px.pth
  name: model_resnet
data:
  start: 4854
  end: 4855
  num_outputs: 10
  mean: [0.485, 0.456, 0.406]
  std: [0.225, 0.225, 0.225]
  pkl_path: null
  dataset: CIFAR
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.03137254901
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 8
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 180
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:37:46 2022 on diablo.cs.ucla.edu
DenseSequential(
  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): ReLU()
  (2): Dense(
    (Ws): ModuleList(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (3): ReLU()
  (4): Dense(
    (Ws): ModuleList(
      (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))
      (1): None
      (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (5): ReLU()
  (6): Dense(
    (Ws): ModuleList(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (7): ReLU()
  (8): Dense(
    (Ws): ModuleList(
      (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))
      (1): None
      (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (9): ReLU()
  (10): Dense(
    (Ws): ModuleList(
      (0): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
  )
  (11): ReLU()
  (12): Dense(
    (Ws): ModuleList(
      (0): Conv2d(16, 32, kernel_size=(2, 2), stride=(2, 2))
      (1): None
      (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (13): ReLU()
  (14): Dense(
    (Ws): ModuleList(
      (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
  )
  (15): ReLU()
  (16): Dense(
    (Ws): ModuleList(
      (0): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): None
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (17): ReLU()
  (18): Flatten()
  (19): Linear(in_features=4096, out_features=1000, bias=True)
  (20): ReLU()
  (21): Linear(in_features=1000, out_features=10, bias=True)
)
Trying generic MNIST/CIFAR data loader.
Files already downloaded and verified
epsilon after preprocessing: tensor([[[[0.1394]],

         [[0.1394]],

         [[0.1394]]]]), data_max = tensor([[[[2.2889]],

         [[2.4178]],

         [[2.6400]]]]), data_min = tensor([[[[-2.1556]],

         [[-2.0267]],

         [[-1.8044]]]])
Task length: 1
saving results to Verified_ret_[model_resnet]_start=4854_end=4855_iter=20_b=8_timeout=180_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 4854 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 0, correct label 0, image norm 2427.572265625, logits tensor([ 0.9946, -0.2737,  0.3428,  0.1239, -0.5067,  0.2073, -0.1402, -0.2623,
         0.1001, -0.5860], device='cuda:0', grad_fn=<SelectBackward>)
##### PGD attack: True label: 0, Tested against: ['all'] ######
pgd prediction: tensor([ 0.4340, -0.1838,  0.0742,  0.2266, -0.4001,  0.4156, -0.1114, -0.1001,
         0.0103, -0.3654], device='cuda:0', grad_fn=<SqueezeBackward1>)
attack margin tensor([   inf, 0.6177, 0.3598, 0.2074, 0.8341, 0.0183, 0.5453, 0.5341, 0.4236,
        0.7994], device='cuda:0', grad_fn=<RsubBackward1>)
untargeted pgd failed
Model prediction is: tensor([[ 0.9946, -0.2737,  0.3428,  0.1239, -0.5067,  0.2073, -0.1402, -0.2623,
          0.1001, -0.5860]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 0.2783,  0.1206, -0.0162,  0.6872, -0.2086,  0.3331,  0.3970,  0.1926,
          0.4370]], device='cuda:0') None
best_l after optimization: -2.4598116874694824 with beta sum per layer: []
alpha/beta optimization time: 34.509695053100586
initial alpha-CROWN bounds: tensor([[ 0.3171,  0.1314,  0.0174,  0.7026, -0.1661,  0.3479,  0.4136,  0.2203,
          0.4757]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.1661, device='cuda:0', grad_fn=<MinBackward1>)
Sorted order for labels to verify: [5, 3, 2, 8, 7, 6, 1, 9, 4, 0]
##### [0:4854] Tested against 5 ######
Model prediction is: tensor([[ 0.9946, -0.2737,  0.3428,  0.1239, -0.5067,  0.2073, -0.1402, -0.2623,
          0.1001, -0.5860]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /32 start_node /41
setting alpha for layer /32 start_node /45
setting alpha for layer /32 start_node /51
setting alpha for layer /32 start_node /71
setting alpha for layer /32 start_node /81
not setting layer /32 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 16, 32, 32]) != torch.Size([2, 9, 1, 16, 32, 32]))
setting alpha for layer /36 start_node /41
setting alpha for layer /36 start_node /45
setting alpha for layer /36 start_node /51
setting alpha for layer /36 start_node /71
setting alpha for layer /36 start_node /81
not setting layer /36 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 16, 32, 32]) != torch.Size([2, 9, 1, 16, 32, 32]))
setting alpha for layer /42 start_node /45
setting alpha for layer /42 start_node /51
setting alpha for layer /42 start_node /71
setting alpha for layer /42 start_node /81
not setting layer /42 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 16, 32, 32]) != torch.Size([2, 9, 1, 16, 32, 32]))
setting alpha for layer /46 start_node /51
setting alpha for layer /46 start_node /71
setting alpha for layer /46 start_node /81
not setting layer /46 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 16, 32, 32]) != torch.Size([2, 9, 1, 16, 32, 32]))
setting alpha for layer /52 start_node /71
setting alpha for layer /52 start_node /81
not setting layer /52 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 16, 32, 32]) != torch.Size([2, 9, 1, 16, 32, 32]))
setting alpha for layer /56 start_node /71
setting alpha for layer /56 start_node /81
not setting layer /56 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /62 start_node /71
setting alpha for layer /62 start_node /81
not setting layer /62 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /66 start_node /71
setting alpha for layer /66 start_node /81
not setting layer /66 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 64, 8, 8]) != torch.Size([2, 9, 1, 64, 8, 8]))
setting alpha for layer /72 start_node /81
not setting layer /72 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 64, 8, 8]) != torch.Size([2, 9, 1, 64, 8, 8]))
not setting layer /82 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 1000]) != torch.Size([2, 9, 1, 1000]))
0 /31 torch.Size([1, 16, 32, 32])
1 /35 torch.Size([1, 16, 32, 32])
2 /41 torch.Size([1, 16, 32, 32])
3 /45 torch.Size([1, 16, 32, 32])
4 /51 torch.Size([1, 16, 32, 32])
5 /55 torch.Size([1, 32, 16, 16])
6 /61 torch.Size([1, 32, 16, 16])
7 /65 torch.Size([1, 64, 8, 8])
8 /71 torch.Size([1, 64, 8, 8])
9 /81 torch.Size([1, 1000])
best_l after optimization: 0.16614075005054474 with beta sum per layer: []
alpha/beta optimization time: 5.097428560256958
alpha-CROWN with fixed intermediate bounds: tensor([[-0.1661]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.16614075005054474
layer 0 size torch.Size([16384]) unstable 335
layer 1 size torch.Size([16384]) unstable 0
layer 2 size torch.Size([16384]) unstable 1938
layer 3 size torch.Size([16384]) unstable 1
layer 4 size torch.Size([16384]) unstable 292
layer 5 size torch.Size([8192]) unstable 0
layer 6 size torch.Size([8192]) unstable 0
layer 7 size torch.Size([4096]) unstable 0
layer 8 size torch.Size([4096]) unstable 4
layer 9 size torch.Size([1000]) unstable 96
-----------------
# of unstable neurons: 2666
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([1, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 972] 
regular batch size: 2*1, diving batch size 1*0
best_l after optimization: 0.2173318862915039 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31451767683029175]
alpha/beta optimization time: 0.8877303600311279
This batch time : update_bounds func: 0.8953	 prepare: 0.0033	 bound: 0.8883	 transfer: 0.0030	 finalize: 0.0006
Accumulated time: update_bounds func: 0.8953	 prepare: 0.0033	 bound: 0.8883	 transfer: 0.0030	 finalize: 0.0006
batch bounding time:  0.8956851959228516
Current worst splitting domains [lb, ub] (depth):
[-0.13791,   inf] (2), [-0.07942,   inf] (2), 
length of domains: 2
Total time: 0.9706	 pickout: 0.0025	 decision: 0.0719	 get_bound: 0.8957	 add_domain: 0.0005
Current lb:-0.1379094123840332
2 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.087677478790283

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([2, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 24] [9, 24] 
regular batch size: 2*2, diving batch size 1*0
best_l after optimization: 0.2898085117340088 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.259055256843567]
alpha/beta optimization time: 0.8830287456512451
This batch time : update_bounds func: 0.8928	 prepare: 0.0038	 bound: 0.8836	 transfer: 0.0041	 finalize: 0.0012
Accumulated time: update_bounds func: 1.7881	 prepare: 0.0071	 bound: 1.7720	 transfer: 0.0041	 finalize: 0.0018
batch bounding time:  0.8931488990783691
Current worst splitting domains [lb, ub] (depth):
[-0.11499,   inf] (4), [-0.11059,   inf] (4), [-0.05818,   inf] (4), [-0.00605,   inf] (4), 
length of domains: 4
Total time: 0.9707	 pickout: 0.0036	 decision: 0.0734	 get_bound: 0.8932	 add_domain: 0.0005
Current lb:-0.1149873211979866
6 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.058573961257935

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([4, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 421] [9, 421] [9, 514] [9, 421] 
regular batch size: 2*4, diving batch size 1*0
best_l after optimization: 0.2914687991142273 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.850700855255127]
alpha/beta optimization time: 0.9165735244750977
This batch time : update_bounds func: 0.9285	 prepare: 0.0050	 bound: 0.9172	 transfer: 0.0045	 finalize: 0.0017
Accumulated time: update_bounds func: 2.7167	 prepare: 0.0122	 bound: 2.6892	 transfer: 0.0045	 finalize: 0.0036
batch bounding time:  0.9288804531097412
Current worst splitting domains [lb, ub] (depth):
[-0.09471,   inf] (6), [-0.09381,   inf] (6), [-0.06484,   inf] (6), [-0.03558,   inf] (6), [-0.03228,   inf] (6), [-0.02340,   inf] (6), 
length of domains: 6
Total time: 1.0137	 pickout: 0.0053	 decision: 0.0790	 get_bound: 0.9289	 add_domain: 0.0005
Current lb:-0.0947134867310524
14 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.072649717330933

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([6, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([6, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 989] [9, 989] [9, 989] [9, 989] [9, 633] [9, 421] 
regular batch size: 2*6, diving batch size 1*0
best_l after optimization: 0.2650201618671417 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.147307395935059]
alpha/beta optimization time: 0.8546335697174072
This batch time : update_bounds func: 0.8698	 prepare: 0.0056	 bound: 0.8552	 transfer: 0.0064	 finalize: 0.0025
Accumulated time: update_bounds func: 3.5865	 prepare: 0.0178	 bound: 3.5444	 transfer: 0.0064	 finalize: 0.0061
batch bounding time:  0.8701457977294922
Current worst splitting domains [lb, ub] (depth):
[-0.07852,   inf] (8), [-0.07753,   inf] (8), [-0.04912,   inf] (8), [-0.03269,   inf] (8), [-0.03091,   inf] (8), [-0.01852,   inf] (8), [-0.01449,   inf] (8), [-0.00835,   inf] (8), [-0.00283,   inf] (8), 
length of domains: 9
Total time: 0.9518	 pickout: 0.0068	 decision: 0.0741	 get_bound: 0.8702	 add_domain: 0.0007
Current lb:-0.07851743698120117
26 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.02489185333252

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 514] [9, 633] [9, 633] [9, 514] [9, 633] [9, 633] [9, 989] [9, 989] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.27867433428764343 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.569952964782715]
alpha/beta optimization time: 0.8628382682800293
This batch time : update_bounds func: 0.8864	 prepare: 0.0064	 bound: 0.8634	 transfer: 0.0132	 finalize: 0.0033
Accumulated time: update_bounds func: 4.4729	 prepare: 0.0243	 bound: 4.4078	 transfer: 0.0132	 finalize: 0.0094
batch bounding time:  0.886709451675415
Current worst splitting domains [lb, ub] (depth):
[-0.06410,   inf] (10), [-0.06128,   inf] (10), [-0.05541,   inf] (10), [-0.04241,   inf] (10), [-0.03265,   inf] (10), [-0.02639,   inf] (10), [-0.01757,   inf] (10), [-0.01094,   inf] (10), [-0.00918,   inf] (10), [-0.00607,   inf] (10), [-0.00283,   inf] (8), [-0.00059,   inf] (10), 
length of domains: 12
Total time: 0.9727	 pickout: 0.0087	 decision: 0.0764	 get_bound: 0.8868	 add_domain: 0.0008
Current lb:-0.06409663707017899
42 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.998053073883057

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 633] [9, 236] [9, 236] [9, 633] [9, 236] [9, 236] [9, 633] [9, 236] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.2755645513534546 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.071263790130615]
alpha/beta optimization time: 0.8900480270385742
This batch time : update_bounds func: 0.9218	 prepare: 0.0065	 bound: 0.8906	 transfer: 0.0212	 finalize: 0.0034
Accumulated time: update_bounds func: 5.3947	 prepare: 0.0308	 bound: 5.2984	 transfer: 0.0212	 finalize: 0.0127
batch bounding time:  0.9227213859558105
Current worst splitting domains [lb, ub] (depth):
[-0.05075,   inf] (12), [-0.04850,   inf] (12), [-0.04460,   inf] (12), [-0.03730,   inf] (12), [-0.02313,   inf] (12), [-0.02195,   inf] (12), [-0.02169,   inf] (12), [-0.02088,   inf] (12), [-0.01476,   inf] (12), [-0.00918,   inf] (10), [-0.00607,   inf] (10), [-0.00607,   inf] (12), [-0.00283,   inf] (8), [-0.00100,   inf] (12), [-0.00074,   inf] (12), [-0.00059,   inf] (10), 
length of domains: 16
Total time: 1.0105	 pickout: 0.0099	 decision: 0.0767	 get_bound: 0.9228	 add_domain: 0.0012
Current lb:-0.050754304975271225
58 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.01017951965332

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 236] [9, 62] [9, 514] [9, 236] [9, 62] [9, 236] [9, 514] [9, 62] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.13443605601787567 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.135544776916504]
alpha/beta optimization time: 0.8671021461486816
This batch time : update_bounds func: 0.8994	 prepare: 0.0081	 bound: 0.8677	 transfer: 0.0201	 finalize: 0.0035
Accumulated time: update_bounds func: 6.2941	 prepare: 0.0389	 bound: 6.1661	 transfer: 0.0201	 finalize: 0.0162
batch bounding time:  0.8998439311981201
Current worst splitting domains [lb, ub] (depth):
[-0.04047,   inf] (14), [-0.04005,   inf] (14), [-0.03307,   inf] (14), [-0.02745,   inf] (14), [-0.01687,   inf] (14), [-0.01476,   inf] (12), [-0.01434,   inf] (14), [-0.01340,   inf] (14), [-0.01215,   inf] (14), [-0.00938,   inf] (14), [-0.00918,   inf] (10), [-0.00607,   inf] (10), [-0.00607,   inf] (12), [-0.00378,   inf] (14), [-0.00283,   inf] (8), [-0.00100,   inf] (12), [-0.00074,   inf] (12), [-0.00059,   inf] (10), 
length of domains: 18
Total time: 0.9946	 pickout: 0.0101	 decision: 0.0838	 get_bound: 0.8999	 add_domain: 0.0009
Current lb:-0.04047251492738724
74 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.00537633895874

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 514] [9, 62] [9, 62] [9, 62] [9, 514] [9, 514] [9, 514] [9, 62] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.016316425055265427 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.497629165649414]
alpha/beta optimization time: 0.904595136642456
This batch time : update_bounds func: 0.9389	 prepare: 0.0066	 bound: 0.9053	 transfer: 0.0232	 finalize: 0.0038
Accumulated time: update_bounds func: 7.2330	 prepare: 0.0455	 bound: 7.0714	 transfer: 0.0232	 finalize: 0.0200
batch bounding time:  0.9393315315246582
Current worst splitting domains [lb, ub] (depth):
[-0.03410,   inf] (16), [-0.03278,   inf] (16), [-0.02682,   inf] (16), [-0.02074,   inf] (16), [-0.01215,   inf] (14), [-0.01126,   inf] (16), [-0.00962,   inf] (16), [-0.00938,   inf] (14), [-0.00918,   inf] (10), [-0.00675,   inf] (16), [-0.00607,   inf] (10), [-0.00607,   inf] (12), [-0.00378,   inf] (14), [-0.00283,   inf] (8), [-0.00249,   inf] (14), [-0.00100,   inf] (12), [-0.00074,   inf] (12), [-0.00059,   inf] (10), 
length of domains: 18
Total time: 1.0293	 pickout: 0.0098	 decision: 0.0789	 get_bound: 0.9394	 add_domain: 0.0013
Current lb:-0.03409966453909874
90 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.035526990890503

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 674] [9, 674] [9, 674] [9, 674] [9, 62] [9, 674] [9, 674] [9, 62] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.000172443687915802 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.021980285644531]
alpha/beta optimization time: 0.8563337326049805
This batch time : update_bounds func: 0.8885	 prepare: 0.0066	 bound: 0.8569	 transfer: 0.0214	 finalize: 0.0034
Accumulated time: update_bounds func: 8.1215	 prepare: 0.0521	 bound: 7.9283	 transfer: 0.0214	 finalize: 0.0233
batch bounding time:  0.8889000415802002
Current worst splitting domains [lb, ub] (depth):
[-0.02987,   inf] (18), [-0.02860,   inf] (18), [-0.02343,   inf] (18), [-0.01725,   inf] (18), [-0.00918,   inf] (10), [-0.00740,   inf] (18), [-0.00686,   inf] (18), [-0.00675,   inf] (16), [-0.00607,   inf] (10), [-0.00607,   inf] (12), [-0.00443,   inf] (16), [-0.00378,   inf] (14), [-0.00340,   inf] (16), [-0.00283,   inf] (8), [-0.00249,   inf] (14), [-0.00100,   inf] (12), [-0.00074,   inf] (12), [-0.00059,   inf] (10), 
length of domains: 18
Total time: 0.9920	 pickout: 0.0148	 decision: 0.0875	 get_bound: 0.8889	 add_domain: 0.0008
Current lb:-0.029869189485907555
106 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.028108358383179

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 846] [9, 846] [9, 846] [9, 846] [9, 236] [9, 846] [9, 846] [9, 674] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.014626860618591309 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.120611190795898]
alpha/beta optimization time: 0.8668780326843262
This batch time : update_bounds func: 0.8975	 prepare: 0.0065	 bound: 0.8675	 transfer: 0.0201	 finalize: 0.0034
Accumulated time: update_bounds func: 9.0190	 prepare: 0.0585	 bound: 8.7957	 transfer: 0.0201	 finalize: 0.0267
batch bounding time:  0.8978509902954102
Current worst splitting domains [lb, ub] (depth):
[-0.02338,   inf] (20), [-0.02252,   inf] (20), [-0.01790,   inf] (20), [-0.01181,   inf] (20), [-0.00845,   inf] (20), [-0.00607,   inf] (10), [-0.00607,   inf] (12), [-0.00443,   inf] (16), [-0.00378,   inf] (14), [-0.00340,   inf] (16), [-0.00283,   inf] (8), [-0.00251,   inf] (18), [-0.00249,   inf] (14), [-0.00100,   inf] (12), [-0.00076,   inf] (20), [-0.00074,   inf] (12), [-0.00059,   inf] (10), 
length of domains: 17
Total time: 0.9855	 pickout: 0.0103	 decision: 0.0765	 get_bound: 0.8979	 add_domain: 0.0008
Current lb:-0.02338051050901413
122 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.014190435409546

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 409] [9, 409] [9, 409] [9, 409] [9, 409] [9, 236] [9, 62] [9, 674] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.03385687246918678 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.694917917251587]
alpha/beta optimization time: 0.8551857471466064
This batch time : update_bounds func: 0.8859	 prepare: 0.0066	 bound: 0.8558	 transfer: 0.0202	 finalize: 0.0033
Accumulated time: update_bounds func: 9.9050	 prepare: 0.0651	 bound: 9.6515	 transfer: 0.0202	 finalize: 0.0300
batch bounding time:  0.8863050937652588
Current worst splitting domains [lb, ub] (depth):
[-0.01829,   inf] (22), [-0.01779,   inf] (22), [-0.01300,   inf] (22), [-0.00716,   inf] (22), [-0.00378,   inf] (14), [-0.00340,   inf] (16), [-0.00283,   inf] (8), [-0.00251,   inf] (18), [-0.00249,   inf] (14), [-0.00137,   inf] (18), [-0.00100,   inf] (12), [-0.00076,   inf] (20), [-0.00074,   inf] (12), [-0.00059,   inf] (10), [-0.00003,   inf] (14), 
length of domains: 15
Total time: 0.9789	 pickout: 0.0148	 decision: 0.0770	 get_bound: 0.8863	 add_domain: 0.0008
Current lb:-0.018291473388671875
138 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.99369168281555

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 519] [9, 519] [9, 519] [9, 519] [9, 62] [9, 674] [9, 633] [9, 846] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.06559152901172638 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.949041843414307]
alpha/beta optimization time: 0.8794388771057129
This batch time : update_bounds func: 0.9063	 prepare: 0.0066	 bound: 0.8801	 transfer: 0.0162	 finalize: 0.0034
Accumulated time: update_bounds func: 10.8112	 prepare: 0.0717	 bound: 10.5316	 transfer: 0.0162	 finalize: 0.0333
batch bounding time:  0.9066388607025146
Current worst splitting domains [lb, ub] (depth):
[-0.01274,   inf] (24), [-0.01233,   inf] (24), [-0.00792,   inf] (24), [-0.00249,   inf] (14), [-0.00209,   inf] (24), [-0.00137,   inf] (18), [-0.00100,   inf] (12), [-0.00076,   inf] (20), [-0.00074,   inf] (12), [-0.00059,   inf] (10), [-0.00003,   inf] (14), 
length of domains: 11
Total time: 0.9941	 pickout: 0.0108	 decision: 0.0761	 get_bound: 0.9067	 add_domain: 0.0006
Current lb:-0.012735843658447266
154 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.98859214782715

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 132] [9, 132] [9, 132] [9, 62] [9, 132] [9, 846] [9, 236] [9, 409] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.11403147131204605 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0902557373046875]
alpha/beta optimization time: 0.8599417209625244
This batch time : update_bounds func: 0.8811	 prepare: 0.0065	 bound: 0.8605	 transfer: 0.0108	 finalize: 0.0032
Accumulated time: update_bounds func: 11.6923	 prepare: 0.0782	 bound: 11.3921	 transfer: 0.0108	 finalize: 0.0365
batch bounding time:  0.8814437389373779
Current worst splitting domains [lb, ub] (depth):
[-0.00810,   inf] (26), [-0.00764,   inf] (26), [-0.00309,   inf] (26), [-0.00074,   inf] (12), [-0.00059,   inf] (10), [-0.00003,   inf] (14), 
length of domains: 6
Total time: 0.9689	 pickout: 0.0104	 decision: 0.0765	 get_bound: 0.8815	 add_domain: 0.0004
Current lb:-0.0081024169921875
170 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.958213806152344

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([6, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([6, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 865] [9, 865] [9, 865] [9, 514] [9, 633] [9, 514] 
regular batch size: 2*6, diving batch size 1*0
best_l after optimization: -0.14550702273845673 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5201478004455566]
alpha/beta optimization time: 0.7097339630126953
This batch time : update_bounds func: 0.7262	 prepare: 0.0056	 bound: 0.7103	 transfer: 0.0077	 finalize: 0.0025
Accumulated time: update_bounds func: 12.4186	 prepare: 0.0839	 bound: 12.1024	 transfer: 0.0077	 finalize: 0.0391
batch bounding time:  0.7265546321868896
Current worst splitting domains [lb, ub] (depth):
[-0.00295,   inf] (28), [-0.00250,   inf] (28), 
length of domains: 2
Total time: 0.8073	 pickout: 0.0079	 decision: 0.0724	 get_bound: 0.7266	 add_domain: 0.0003
Current lb:-0.00295257568359375
182 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 19.766063451766968

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([2, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 578] [9, 578] 
regular batch size: 2*2, diving batch size 1*0
best_l after optimization: -0.025685865432024002 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.743300199508667
This batch time : update_bounds func: 0.7527	 prepare: 0.0038	 bound: 0.7440	 transfer: 0.0038	 finalize: 0.0011
Accumulated time: update_bounds func: 13.1713	 prepare: 0.0877	 bound: 12.8463	 transfer: 0.0038	 finalize: 0.0402
batch bounding time:  0.753049373626709
Current worst splitting domains [lb, ub] (depth):
[-0.00012,   inf] (30), 
length of domains: 1
Total time: 0.8245	 pickout: 0.0035	 decision: 0.0677	 get_bound: 0.7531	 add_domain: 0.0002
Current lb:-0.00011968612670898438
186 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 20.59082317352295

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([1, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 704] 
regular batch size: 2*1, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -0.007113456726074219 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.03019261360168457
This batch time : update_bounds func: 0.0372	 prepare: 0.0034	 bound: 0.0307	 transfer: 0.0025	 finalize: 0.0006
Accumulated time: update_bounds func: 13.2085	 prepare: 0.0911	 bound: 12.8770	 transfer: 0.0025	 finalize: 0.0407
batch bounding time:  0.037222862243652344
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.1053	 pickout: 0.0025	 decision: 0.0656	 get_bound: 0.0372	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 20.696391820907593

Image 4854 label 5 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 21.009763717651367
4854 1.0000000116860974e-07
##### [0:4854] Tested against 3 ######
Initial alpha-CROWN verified for label 3 with bound 0.017377428710460663
Image 4854 label 3 verification end, final lower bound 0.017377428710460663, upper bound inf, time: 0.0006167888641357422
4854 0.017377428710460663
##### [0:4854] Tested against 2 ######
Initial alpha-CROWN verified for label 2 with bound 0.13144905865192413
Image 4854 label 2 verification end, final lower bound 0.13144905865192413, upper bound inf, time: 0.0004177093505859375
4854 0.13144905865192413
##### [0:4854] Tested against 8 ######
Initial alpha-CROWN verified for label 8 with bound 0.2202894538640976
Image 4854 label 8 verification end, final lower bound 0.2202894538640976, upper bound inf, time: 0.00048470497131347656
4854 0.2202894538640976
##### [0:4854] Tested against 7 ######
Initial alpha-CROWN verified for label 7 with bound 0.4135718047618866
Image 4854 label 7 verification end, final lower bound 0.4135718047618866, upper bound inf, time: 0.0004367828369140625
4854 0.4135718047618866
##### [0:4854] Tested against 6 ######
Initial alpha-CROWN verified for label 6 with bound 0.3478781580924988
Image 4854 label 6 verification end, final lower bound 0.3478781580924988, upper bound inf, time: 0.00042510032653808594
4854 0.3478781580924988
##### [0:4854] Tested against 1 ######
Initial alpha-CROWN verified for label 1 with bound 0.3170859217643738
Image 4854 label 1 verification end, final lower bound 0.3170859217643738, upper bound inf, time: 0.0004210472106933594
4854 0.3170859217643738
##### [0:4854] Tested against 9 ######
Initial alpha-CROWN verified for label 9 with bound 0.47568997740745544
Image 4854 label 9 verification end, final lower bound 0.47568997740745544, upper bound inf, time: 0.0004191398620605469
4854 0.47568997740745544
##### [0:4854] Tested against 4 ######
Initial alpha-CROWN verified for label 4 with bound 0.7026146054267883
Image 4854 label 4 verification end, final lower bound 0.7026146054267883, upper bound inf, time: 0.0004303455352783203
4854 0.7026146054267883
##### [0:4854] Tested against 0 ######
groundtruth label, skip!
Result: image 4854 verification success (with branch and bound)!
Wall time: 65.64472651481628

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 1): [4854]
verification failure idx (total 0): []
final verified acc: 100.0%[1]
verifier is called on 1 examples.
total verified: 1
mean time [cnt:1] (excluding attack success): 57.6210401058197
