Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: cifar_resnet_8px.pth
  name: model_resnet
data:
  start: 193
  end: 194
  num_outputs: 10
  mean: [0.485, 0.456, 0.406]
  std: [0.225, 0.225, 0.225]
  pkl_path: null
  dataset: CIFAR
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.03137254901
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 8
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 180
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 50
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 21:43:53 2022 on diablo.cs.ucla.edu
DenseSequential(
  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): ReLU()
  (2): Dense(
    (Ws): ModuleList(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (3): ReLU()
  (4): Dense(
    (Ws): ModuleList(
      (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))
      (1): None
      (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (5): ReLU()
  (6): Dense(
    (Ws): ModuleList(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (7): ReLU()
  (8): Dense(
    (Ws): ModuleList(
      (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))
      (1): None
      (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (9): ReLU()
  (10): Dense(
    (Ws): ModuleList(
      (0): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
  )
  (11): ReLU()
  (12): Dense(
    (Ws): ModuleList(
      (0): Conv2d(16, 32, kernel_size=(2, 2), stride=(2, 2))
      (1): None
      (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (13): ReLU()
  (14): Dense(
    (Ws): ModuleList(
      (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
  )
  (15): ReLU()
  (16): Dense(
    (Ws): ModuleList(
      (0): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): None
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (17): ReLU()
  (18): Flatten()
  (19): Linear(in_features=4096, out_features=1000, bias=True)
  (20): ReLU()
  (21): Linear(in_features=1000, out_features=10, bias=True)
)
Trying generic MNIST/CIFAR data loader.
Files already downloaded and verified
epsilon after preprocessing: tensor([[[[0.1394]],

         [[0.1394]],

         [[0.1394]]]]), data_max = tensor([[[[2.2889]],

         [[2.4178]],

         [[2.6400]]]]), data_min = tensor([[[[-2.1556]],

         [[-2.0267]],

         [[-1.8044]]]])
Task length: 1
saving results to Verified_ret_[model_resnet]_start=193_end=194_iter=20_b=8_timeout=180_branching=kfsb-min-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 193 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 1, correct label 1, image norm 2554.2919921875, logits tensor([-0.3955,  0.4354,  0.0582,  0.1301,  0.0580,  0.2685,  0.2638, -0.0194,
        -0.3253, -0.4739], device='cuda:0', grad_fn=<SelectBackward>)
Model prediction is: tensor([[-0.3955,  0.4354,  0.0582,  0.1301,  0.0580,  0.2685,  0.2638, -0.0194,
         -0.3253, -0.4739]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 0.7982,  0.2262,  0.1850,  0.2178,  0.0620, -0.0105,  0.3532,  0.7317,
          0.8393]], device='cuda:0') None
best_l after optimization: -3.4369118213653564 with beta sum per layer: []
alpha/beta optimization time: 33.181647539138794
initial alpha-CROWN bounds: tensor([[ 0.7999,  0.2298,  0.1892,  0.2224,  0.0675, -0.0034,  0.3563,  0.7345,
          0.8407]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.0034, device='cuda:0', grad_fn=<MinBackward1>)
##### [0:193] Tested against 6 ######
Model prediction is: tensor([[-0.3955,  0.4354,  0.0582,  0.1301,  0.0580,  0.2685,  0.2638, -0.0194,
         -0.3253, -0.4739]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /32 start_node /41
setting alpha for layer /32 start_node /45
setting alpha for layer /32 start_node /51
setting alpha for layer /32 start_node /71
setting alpha for layer /32 start_node /81
not setting layer /32 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 16, 32, 32]) != torch.Size([2, 9, 1, 16, 32, 32]))
setting alpha for layer /36 start_node /41
setting alpha for layer /36 start_node /45
setting alpha for layer /36 start_node /51
setting alpha for layer /36 start_node /71
setting alpha for layer /36 start_node /81
not setting layer /36 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 16, 32, 32]) != torch.Size([2, 9, 1, 16, 32, 32]))
setting alpha for layer /42 start_node /45
setting alpha for layer /42 start_node /51
setting alpha for layer /42 start_node /71
setting alpha for layer /42 start_node /81
not setting layer /42 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 16, 32, 32]) != torch.Size([2, 9, 1, 16, 32, 32]))
setting alpha for layer /46 start_node /51
setting alpha for layer /46 start_node /71
setting alpha for layer /46 start_node /81
not setting layer /46 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 16, 32, 32]) != torch.Size([2, 9, 1, 16, 32, 32]))
setting alpha for layer /52 start_node /71
setting alpha for layer /52 start_node /81
not setting layer /52 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 16, 32, 32]) != torch.Size([2, 9, 1, 16, 32, 32]))
setting alpha for layer /56 start_node /71
setting alpha for layer /56 start_node /81
not setting layer /56 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /62 start_node /71
setting alpha for layer /62 start_node /81
not setting layer /62 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 32, 16, 16]) != torch.Size([2, 9, 1, 32, 16, 16]))
setting alpha for layer /66 start_node /71
setting alpha for layer /66 start_node /81
not setting layer /66 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 64, 8, 8]) != torch.Size([2, 9, 1, 64, 8, 8]))
setting alpha for layer /72 start_node /81
not setting layer /72 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 64, 8, 8]) != torch.Size([2, 9, 1, 64, 8, 8]))
not setting layer /82 start_node /83 because shape mismatch (torch.Size([2, 1, 1, 1000]) != torch.Size([2, 9, 1, 1000]))
0 /31 torch.Size([1, 16, 32, 32])
1 /35 torch.Size([1, 16, 32, 32])
2 /41 torch.Size([1, 16, 32, 32])
3 /45 torch.Size([1, 16, 32, 32])
4 /51 torch.Size([1, 16, 32, 32])
5 /55 torch.Size([1, 32, 16, 16])
6 /61 torch.Size([1, 32, 16, 16])
7 /65 torch.Size([1, 64, 8, 8])
8 /71 torch.Size([1, 64, 8, 8])
9 /81 torch.Size([1, 1000])
best_l after optimization: 0.0033603906631469727 with beta sum per layer: []
alpha/beta optimization time: 5.8175225257873535
alpha-CROWN with fixed intermediate bounds: tensor([[-0.0034]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.0033603906631469727
layer 0 size torch.Size([16384]) unstable 1464
layer 1 size torch.Size([16384]) unstable 0
layer 2 size torch.Size([16384]) unstable 332
layer 3 size torch.Size([16384]) unstable 16
layer 4 size torch.Size([16384]) unstable 40
layer 5 size torch.Size([8192]) unstable 0
layer 6 size torch.Size([8192]) unstable 0
layer 7 size torch.Size([4096]) unstable 0
layer 8 size torch.Size([4096]) unstable 1
layer 9 size torch.Size([1000]) unstable 12
-----------------
# of unstable neurons: 1865
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([1, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3592] 
regular batch size: 2*1, diving batch size 1*0
best_l after optimization: 0.004380565136671066 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.7671818733215332
This batch time : update_bounds func: 0.7734	 prepare: 0.0033	 bound: 0.7677	 transfer: 0.0018	 finalize: 0.0006
Accumulated time: update_bounds func: 0.7734	 prepare: 0.0033	 bound: 0.7677	 transfer: 0.0018	 finalize: 0.0006
batch bounding time:  0.7737338542938232
Current worst splitting domains [lb, ub] (depth):
[-0.00334,   inf] (2), [-0.00104,   inf] (2), 
length of domains: 2
Total time: 0.8431	 pickout: 0.0023	 decision: 0.0668	 get_bound: 0.7737	 add_domain: 0.0002
Current lb:-0.003339748829603195
2 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.618436098098755

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([2, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([2, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3625] [4, 3476] 
regular batch size: 2*2, diving batch size 1*0
best_l after optimization: 0.001417309045791626 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0006221327348612249, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.7852141857147217
This batch time : update_bounds func: 0.7932	 prepare: 0.0038	 bound: 0.7858	 transfer: 0.0024	 finalize: 0.0012
Accumulated time: update_bounds func: 1.5666	 prepare: 0.0071	 bound: 1.5535	 transfer: 0.0024	 finalize: 0.0017
batch bounding time:  0.7934625148773193
Current worst splitting domains [lb, ub] (depth):
[-0.00332,   inf] (4), [-0.00148,   inf] (4), [-0.00103,   inf] (4), 
length of domains: 3
Total time: 0.8670	 pickout: 0.0034	 decision: 0.0698	 get_bound: 0.7935	 add_domain: 0.0003
Current lb:-0.0033169107045978308
6 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.485665559768677

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([3, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3476] [4, 3476] [4, 3633] 
regular batch size: 2*3, diving batch size 1*0
best_l after optimization: -0.003158245235681534 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0009764931746758521, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.7823848724365234
This batch time : update_bounds func: 0.7926	 prepare: 0.0042	 bound: 0.7830	 transfer: 0.0034	 finalize: 0.0020
Accumulated time: update_bounds func: 2.3592	 prepare: 0.0113	 bound: 2.3365	 transfer: 0.0034	 finalize: 0.0037
batch bounding time:  0.7929236888885498
Current worst splitting domains [lb, ub] (depth):
[-0.00330,   inf] (6), [-0.00144,   inf] (6), [-0.00101,   inf] (6), 
length of domains: 3
Total time: 0.8651	 pickout: 0.0042	 decision: 0.0676	 get_bound: 0.7929	 add_domain: 0.0004
Current lb:-0.003302075667306781
12 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.351028442382812

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([3, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3718] [4, 3718] [4, 3718] 
regular batch size: 2*3, diving batch size 1*0
best_l after optimization: 0.008601113222539425 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0031636180356144905, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.8571865558624268
This batch time : update_bounds func: 0.8685	 prepare: 0.0062	 bound: 0.8579	 transfer: 0.0029	 finalize: 0.0015
Accumulated time: update_bounds func: 3.2277	 prepare: 0.0174	 bound: 3.1944	 transfer: 0.0029	 finalize: 0.0052
batch bounding time:  0.8688056468963623
Current worst splitting domains [lb, ub] (depth):
[-0.00328,   inf] (8), [-0.00232,   inf] (8), [-0.00143,   inf] (8), [-0.00100,   inf] (8), [-0.00053,   inf] (8), [-0.00004,   inf] (8), 
length of domains: 6
Total time: 0.9560	 pickout: 0.0056	 decision: 0.0811	 get_bound: 0.8688	 add_domain: 0.0005
Current lb:-0.003283098340034485
18 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.307277202606201

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([6, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([6, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3719] [4, 3719] [4, 3719] [4, 3719] [4, 3719] [4, 3719] 
regular batch size: 2*6, diving batch size 1*0
best_l after optimization: 0.01251267921179533 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.006507193669676781, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.7592172622680664
This batch time : update_bounds func: 0.7727	 prepare: 0.0055	 bound: 0.7598	 transfer: 0.0044	 finalize: 0.0029
Accumulated time: update_bounds func: 4.0004	 prepare: 0.0230	 bound: 3.9542	 transfer: 0.0044	 finalize: 0.0081
batch bounding time:  0.7729747295379639
Current worst splitting domains [lb, ub] (depth):
[-0.00326,   inf] (10), [-0.00251,   inf] (10), [-0.00230,   inf] (10), [-0.00157,   inf] (10), [-0.00140,   inf] (10), [-0.00097,   inf] (10), [-0.00066,   inf] (10), [-0.00051,   inf] (10), [-0.00023,   inf] (10), [-0.00002,   inf] (10), 
length of domains: 10
Total time: 0.8553	 pickout: 0.0068	 decision: 0.0747	 get_bound: 0.7730	 add_domain: 0.0008
Current lb:-0.0032564057037234306
30 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.162904024124146

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3626] [4, 3626] [4, 3626] [4, 3626] [4, 3626] [4, 3626] [4, 3626] [4, 3626] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.0189074594527483 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.009873693808913231, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.8116693496704102
This batch time : update_bounds func: 0.8331	 prepare: 0.0064	 bound: 0.8122	 transfer: 0.0111	 finalize: 0.0032
Accumulated time: update_bounds func: 4.8335	 prepare: 0.0294	 bound: 4.7664	 transfer: 0.0111	 finalize: 0.0113
batch bounding time:  0.8333907127380371
Current worst splitting domains [lb, ub] (depth):
[-0.00323,   inf] (12), [-0.00249,   inf] (12), [-0.00232,   inf] (12), [-0.00226,   inf] (12), [-0.00158,   inf] (12), [-0.00155,   inf] (12), [-0.00137,   inf] (12), [-0.00137,   inf] (12), [-0.00095,   inf] (12), [-0.00069,   inf] (12), [-0.00062,   inf] (12), [-0.00055,   inf] (12), [-0.00044,   inf] (12), [-0.00023,   inf] (10), [-0.00002,   inf] (10), [-0.00001,   inf] (12), 
length of domains: 16
Total time: 0.9288	 pickout: 0.0098	 decision: 0.0843	 get_bound: 0.8334	 add_domain: 0.0012
Current lb:-0.0032326807267963886
46 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.092085361480713

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3338] [4, 3338] [4, 3633] [4, 3338] [4, 3338] [4, 3338] [4, 3338] [4, 3633] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.008806967176496983 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.008527018129825592, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.7807955741882324
This batch time : update_bounds func: 0.8113	 prepare: 0.0067	 bound: 0.7814	 transfer: 0.0198	 finalize: 0.0033
Accumulated time: update_bounds func: 5.6448	 prepare: 0.0361	 bound: 5.5478	 transfer: 0.0198	 finalize: 0.0147
batch bounding time:  0.8116645812988281
Current worst splitting domains [lb, ub] (depth):
[-0.00322,   inf] (14), [-0.00248,   inf] (14), [-0.00231,   inf] (14), [-0.00225,   inf] (14), [-0.00157,   inf] (14), [-0.00154,   inf] (14), [-0.00135,   inf] (14), [-0.00130,   inf] (14), [-0.00095,   inf] (12), [-0.00069,   inf] (12), [-0.00066,   inf] (14), [-0.00062,   inf] (12), [-0.00055,   inf] (12), [-0.00044,   inf] (12), [-0.00023,   inf] (10), [-0.00002,   inf] (10), [-0.00001,   inf] (12), 
length of domains: 17
Total time: 0.9013	 pickout: 0.0102	 decision: 0.0785	 get_bound: 0.8117	 add_domain: 0.0008
Current lb:-0.003221453633159399
62 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.993996620178223

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3633] [4, 3633] [4, 3338] [4, 3633] [4, 3633] [4, 3633] [4, 3633] [4, 3338] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.003061019815504551 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.00803546141833067, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.7677979469299316
This batch time : update_bounds func: 0.7980	 prepare: 0.0064	 bound: 0.7684	 transfer: 0.0198	 finalize: 0.0034
Accumulated time: update_bounds func: 6.4429	 prepare: 0.0425	 bound: 6.3162	 transfer: 0.0198	 finalize: 0.0180
batch bounding time:  0.7984249591827393
Current worst splitting domains [lb, ub] (depth):
[-0.00321,   inf] (16), [-0.00247,   inf] (16), [-0.00230,   inf] (16), [-0.00224,   inf] (16), [-0.00156,   inf] (16), [-0.00153,   inf] (16), [-0.00134,   inf] (16), [-0.00129,   inf] (16), [-0.00095,   inf] (12), [-0.00069,   inf] (12), [-0.00066,   inf] (14), [-0.00062,   inf] (12), [-0.00055,   inf] (12), [-0.00044,   inf] (12), [-0.00023,   inf] (10), [-0.00002,   inf] (10), [-0.00001,   inf] (12), 
length of domains: 17
Total time: 0.8855	 pickout: 0.0097	 decision: 0.0766	 get_bound: 0.7985	 add_domain: 0.0008
Current lb:-0.0032102761324495077
78 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.88008975982666

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2573] [2, 2573] [2, 2573] [2, 2573] [2, 2573] [2, 2573] [2, 2573] [2, 2573] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.07217660546302795 with beta sum per layer: [0.0, 0.0, 0.9967032670974731, 0.0, 0.007745205424726009, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.8614027500152588
This batch time : update_bounds func: 0.8917	 prepare: 0.0067	 bound: 0.8620	 transfer: 0.0197	 finalize: 0.0032
Accumulated time: update_bounds func: 7.3345	 prepare: 0.0492	 bound: 7.1782	 transfer: 0.0197	 finalize: 0.0212
batch bounding time:  0.8920230865478516
Current worst splitting domains [lb, ub] (depth):
[-0.00320,   inf] (18), [-0.00246,   inf] (18), [-0.00229,   inf] (18), [-0.00223,   inf] (18), [-0.00155,   inf] (18), [-0.00152,   inf] (18), [-0.00134,   inf] (18), [-0.00128,   inf] (18), [-0.00095,   inf] (12), [-0.00069,   inf] (12), [-0.00066,   inf] (14), [-0.00062,   inf] (12), [-0.00055,   inf] (12), [-0.00044,   inf] (12), [-0.00023,   inf] (10), [-0.00002,   inf] (10), [-0.00001,   inf] (12), 
length of domains: 17
Total time: 0.9822	 pickout: 0.0086	 decision: 0.0806	 get_bound: 0.8921	 add_domain: 0.0009
Current lb:-0.003202954540029168
94 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.862852811813354

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3666] [4, 3666] [4, 3666] [4, 3666] [4, 3666] [4, 3666] [4, 3666] [4, 3666] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.020916447043418884 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.008035460487008095, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.7627730369567871
This batch time : update_bounds func: 0.7842	 prepare: 0.0069	 bound: 0.7634	 transfer: 0.0108	 finalize: 0.0032
Accumulated time: update_bounds func: 8.1188	 prepare: 0.0560	 bound: 7.9415	 transfer: 0.0108	 finalize: 0.0244
batch bounding time:  0.7845489978790283
Current worst splitting domains [lb, ub] (depth):
[-0.00320,   inf] (20), [-0.00245,   inf] (20), [-0.00229,   inf] (20), [-0.00223,   inf] (20), [-0.00185,   inf] (20), [-0.00154,   inf] (20), [-0.00151,   inf] (20), [-0.00133,   inf] (20), [-0.00128,   inf] (20), [-0.00111,   inf] (20), [-0.00095,   inf] (12), [-0.00094,   inf] (20), [-0.00088,   inf] (20), [-0.00069,   inf] (12), [-0.00066,   inf] (14), [-0.00062,   inf] (12), [-0.00055,   inf] (12), [-0.00044,   inf] (12), [-0.00023,   inf] (10), [-0.00020,   inf] (20), 
length of domains: 23
Total time: 0.8713	 pickout: 0.0086	 decision: 0.0764	 get_bound: 0.7846	 add_domain: 0.0017
Current lb:-0.0031985517125576735
110 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.734537363052368

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3540] [4, 3540] [4, 3540] [4, 3540] [4, 3540] [4, 3540] [4, 3540] [4, 3540] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.02971222624182701 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.004875462502241135, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.7827551364898682
This batch time : update_bounds func: 0.8031	 prepare: 0.0067	 bound: 0.7833	 transfer: 0.0097	 finalize: 0.0032
Accumulated time: update_bounds func: 8.9218	 prepare: 0.0628	 bound: 8.7249	 transfer: 0.0097	 finalize: 0.0276
batch bounding time:  0.8033952713012695
Current worst splitting domains [lb, ub] (depth):
[-0.00319,   inf] (22), [-0.00281,   inf] (22), [-0.00245,   inf] (22), [-0.00228,   inf] (22), [-0.00222,   inf] (22), [-0.00207,   inf] (22), [-0.00190,   inf] (22), [-0.00185,   inf] (22), [-0.00184,   inf] (22), [-0.00154,   inf] (22), [-0.00151,   inf] (22), [-0.00147,   inf] (22), [-0.00133,   inf] (22), [-0.00128,   inf] (20), [-0.00116,   inf] (22), [-0.00113,   inf] (22), [-0.00111,   inf] (20), [-0.00095,   inf] (12), [-0.00095,   inf] (22), [-0.00094,   inf] (20), 
length of domains: 31
Total time: 0.8900	 pickout: 0.0087	 decision: 0.0762	 get_bound: 0.8034	 add_domain: 0.0016
Current lb:-0.003193571697920561
126 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.624995946884155

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3509] [4, 3509] [4, 3509] [4, 3509] [4, 3509] [4, 3509] [4, 3509] [4, 3509] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.031510911881923676 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.006306001450866461, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.7804439067840576
This batch time : update_bounds func: 0.8113	 prepare: 0.0067	 bound: 0.7810	 transfer: 0.0202	 finalize: 0.0033
Accumulated time: update_bounds func: 9.7331	 prepare: 0.0694	 bound: 9.5059	 transfer: 0.0202	 finalize: 0.0309
batch bounding time:  0.8116323947906494
Current worst splitting domains [lb, ub] (depth):
[-0.00319,   inf] (24), [-0.00281,   inf] (24), [-0.00244,   inf] (24), [-0.00243,   inf] (24), [-0.00228,   inf] (24), [-0.00222,   inf] (24), [-0.00206,   inf] (24), [-0.00203,   inf] (24), [-0.00190,   inf] (24), [-0.00184,   inf] (24), [-0.00184,   inf] (22), [-0.00169,   inf] (24), [-0.00155,   inf] (24), [-0.00154,   inf] (22), [-0.00151,   inf] (22), [-0.00149,   inf] (24), [-0.00147,   inf] (22), [-0.00133,   inf] (22), [-0.00129,   inf] (24), [-0.00128,   inf] (20), 
length of domains: 39
Total time: 0.9006	 pickout: 0.0100	 decision: 0.0773	 get_bound: 0.8117	 add_domain: 0.0017
Current lb:-0.0031889083329588175
142 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.526016235351562

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3511] [4, 3511] [4, 3511] [4, 3511] [4, 3511] [4, 3511] [4, 3511] [4, 3511] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.032443612813949585 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0055036465637385845, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.7998900413513184
This batch time : update_bounds func: 0.8306	 prepare: 0.0068	 bound: 0.8005	 transfer: 0.0200	 finalize: 0.0034
Accumulated time: update_bounds func: 10.5638	 prepare: 0.0762	 bound: 10.3063	 transfer: 0.0200	 finalize: 0.0343
batch bounding time:  0.8310098648071289
Current worst splitting domains [lb, ub] (depth):
[-0.00319,   inf] (26), [-0.00280,   inf] (26), [-0.00244,   inf] (26), [-0.00243,   inf] (26), [-0.00239,   inf] (26), [-0.00227,   inf] (26), [-0.00221,   inf] (26), [-0.00206,   inf] (26), [-0.00203,   inf] (26), [-0.00199,   inf] (26), [-0.00190,   inf] (24), [-0.00184,   inf] (24), [-0.00184,   inf] (22), [-0.00169,   inf] (24), [-0.00164,   inf] (26), [-0.00162,   inf] (26), [-0.00155,   inf] (24), [-0.00154,   inf] (22), [-0.00151,   inf] (22), [-0.00149,   inf] (24), 
length of domains: 47
Total time: 0.9189	 pickout: 0.0097	 decision: 0.0764	 get_bound: 0.8311	 add_domain: 0.0016
Current lb:-0.0031851495150476694
158 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.44537115097046

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2578] [2, 2578] [2, 2578] [2, 2578] [2, 2578] [2, 2578] [2, 2578] [2, 2578] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.16762451827526093 with beta sum per layer: [0.0, 0.0, 2.0125186443328857, 0.0, 0.23429277539253235, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.8723869323730469
This batch time : update_bounds func: 0.9027	 prepare: 0.0067	 bound: 0.8730	 transfer: 0.0197	 finalize: 0.0032
Accumulated time: update_bounds func: 11.4664	 prepare: 0.0829	 bound: 11.1793	 transfer: 0.0197	 finalize: 0.0375
batch bounding time:  0.9030158519744873
Current worst splitting domains [lb, ub] (depth):
[-0.00318,   inf] (28), [-0.00280,   inf] (28), [-0.00244,   inf] (28), [-0.00242,   inf] (28), [-0.00238,   inf] (28), [-0.00227,   inf] (28), [-0.00221,   inf] (28), [-0.00205,   inf] (28), [-0.00203,   inf] (26), [-0.00199,   inf] (26), [-0.00190,   inf] (24), [-0.00184,   inf] (24), [-0.00184,   inf] (22), [-0.00169,   inf] (24), [-0.00164,   inf] (26), [-0.00162,   inf] (26), [-0.00155,   inf] (24), [-0.00154,   inf] (22), [-0.00151,   inf] (22), [-0.00149,   inf] (24), 
length of domains: 47
Total time: 0.9902	 pickout: 0.0098	 decision: 0.0764	 get_bound: 0.9031	 add_domain: 0.0010
Current lb:-0.003181873122230172
174 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 19.436228036880493

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3624] [4, 3624] [4, 3624] [4, 3624] [4, 3624] [4, 3624] [4, 3624] [4, 3624] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03824819251894951 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.004197394475340843, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.8259086608886719
This batch time : update_bounds func: 0.8547	 prepare: 0.0068	 bound: 0.8265	 transfer: 0.0181	 finalize: 0.0033
Accumulated time: update_bounds func: 12.3212	 prepare: 0.0896	 bound: 12.0058	 transfer: 0.0181	 finalize: 0.0408
batch bounding time:  0.8550894260406494
Current worst splitting domains [lb, ub] (depth):
[-0.00315,   inf] (30), [-0.00305,   inf] (30), [-0.00277,   inf] (30), [-0.00267,   inf] (30), [-0.00241,   inf] (30), [-0.00240,   inf] (30), [-0.00234,   inf] (30), [-0.00231,   inf] (30), [-0.00230,   inf] (30), [-0.00225,   inf] (30), [-0.00224,   inf] (30), [-0.00218,   inf] (30), [-0.00214,   inf] (30), [-0.00208,   inf] (30), [-0.00203,   inf] (26), [-0.00203,   inf] (30), [-0.00199,   inf] (26), [-0.00193,   inf] (30), [-0.00190,   inf] (24), [-0.00184,   inf] (24), 
length of domains: 55
Total time: 0.9420	 pickout: 0.0085	 decision: 0.0766	 get_bound: 0.8551	 add_domain: 0.0018
Current lb:-0.0031528202816843987
190 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 20.378750801086426

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3657] [4, 3389] [4, 3657] [4, 3389] [4, 3657] [4, 3657] [4, 3657] [4, 3389] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03229071944952011 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.012099474668502808, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.8712739944458008
This batch time : update_bounds func: 0.8914	 prepare: 0.0068	 bound: 0.8718	 transfer: 0.0096	 finalize: 0.0031
Accumulated time: update_bounds func: 13.2126	 prepare: 0.0964	 bound: 12.8776	 transfer: 0.0096	 finalize: 0.0439
batch bounding time:  0.8917598724365234
Current worst splitting domains [lb, ub] (depth):
[-0.00315,   inf] (32), [-0.00305,   inf] (32), [-0.00282,   inf] (32), [-0.00276,   inf] (32), [-0.00266,   inf] (32), [-0.00243,   inf] (32), [-0.00240,   inf] (32), [-0.00239,   inf] (32), [-0.00234,   inf] (32), [-0.00231,   inf] (32), [-0.00230,   inf] (30), [-0.00225,   inf] (30), [-0.00224,   inf] (30), [-0.00218,   inf] (30), [-0.00214,   inf] (30), [-0.00208,   inf] (30), [-0.00208,   inf] (32), [-0.00203,   inf] (26), [-0.00203,   inf] (30), [-0.00199,   inf] (26), 
length of domains: 63
Total time: 0.9791	 pickout: 0.0087	 decision: 0.0767	 get_bound: 0.8918	 add_domain: 0.0018
Current lb:-0.00314777297899127
206 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 21.35829520225525

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 409] [9, 409] [9, 409] [4, 3389] [4, 3657] [4, 3657] [9, 409] [9, 409] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.015385535545647144 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.008990246802568436, 0.0, 0.0, 0.0, 0.0, 3.116779088973999]
alpha/beta optimization time: 0.870668888092041
This batch time : update_bounds func: 0.9012	 prepare: 0.0069	 bound: 0.8712	 transfer: 0.0197	 finalize: 0.0033
Accumulated time: update_bounds func: 14.1138	 prepare: 0.1033	 bound: 13.7488	 transfer: 0.0197	 finalize: 0.0472
batch bounding time:  0.9015274047851562
Current worst splitting domains [lb, ub] (depth):
[-0.00306,   inf] (34), [-0.00296,   inf] (34), [-0.00276,   inf] (34), [-0.00273,   inf] (34), [-0.00266,   inf] (34), [-0.00252,   inf] (34), [-0.00243,   inf] (34), [-0.00234,   inf] (32), [-0.00231,   inf] (34), [-0.00231,   inf] (32), [-0.00230,   inf] (34), [-0.00230,   inf] (30), [-0.00225,   inf] (30), [-0.00224,   inf] (30), [-0.00218,   inf] (30), [-0.00214,   inf] (30), [-0.00208,   inf] (30), [-0.00208,   inf] (32), [-0.00203,   inf] (26), [-0.00203,   inf] (30), 
length of domains: 66
Total time: 0.9888	 pickout: 0.0098	 decision: 0.0761	 get_bound: 0.9016	 add_domain: 0.0013
Current lb:-0.003058174392208457
222 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 22.34761357307434

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3389] [4, 3657] [9, 409] [4, 3657] [9, 409] [9, 409] [9, 409] [4, 3389] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.022576890885829926 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.011552556417882442, 0.0, 0.0, 0.0, 0.0, 2.114675521850586]
alpha/beta optimization time: 0.8268599510192871
This batch time : update_bounds func: 0.8575	 prepare: 0.0070	 bound: 0.8275	 transfer: 0.0197	 finalize: 0.0033
Accumulated time: update_bounds func: 14.9713	 prepare: 0.1103	 bound: 14.5763	 transfer: 0.0197	 finalize: 0.0504
batch bounding time:  0.8578836917877197
Current worst splitting domains [lb, ub] (depth):
[-0.00306,   inf] (36), [-0.00296,   inf] (36), [-0.00282,   inf] (36), [-0.00273,   inf] (36), [-0.00266,   inf] (36), [-0.00257,   inf] (36), [-0.00243,   inf] (36), [-0.00234,   inf] (36), [-0.00233,   inf] (34), [-0.00231,   inf] (34), [-0.00231,   inf] (32), [-0.00230,   inf] (34), [-0.00230,   inf] (30), [-0.00225,   inf] (30), [-0.00224,   inf] (30), [-0.00218,   inf] (30), [-0.00214,   inf] (30), [-0.00210,   inf] (34), [-0.00208,   inf] (30), [-0.00208,   inf] (32), 
length of domains: 70
Total time: 0.9463	 pickout: 0.0099	 decision: 0.0770	 get_bound: 0.8579	 add_domain: 0.0014
Current lb:-0.003055095672607422
238 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 23.294393062591553

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 15885] [2, 15885] [2, 15885] [2, 15885] [2, 15885] [2, 15885] [2, 15885] [2, 15885] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.12480522692203522 with beta sum per layer: [0.0, 0.0, 3.2210028171539307, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.88327956199646
This batch time : update_bounds func: 0.9141	 prepare: 0.0070	 bound: 0.8839	 transfer: 0.0198	 finalize: 0.0033
Accumulated time: update_bounds func: 15.8855	 prepare: 0.1174	 bound: 15.4602	 transfer: 0.0198	 finalize: 0.0538
batch bounding time:  0.914492130279541
Current worst splitting domains [lb, ub] (depth):
[-0.00305,   inf] (38), [-0.00296,   inf] (38), [-0.00282,   inf] (38), [-0.00273,   inf] (38), [-0.00266,   inf] (38), [-0.00257,   inf] (38), [-0.00243,   inf] (38), [-0.00234,   inf] (38), [-0.00233,   inf] (34), [-0.00231,   inf] (34), [-0.00231,   inf] (32), [-0.00230,   inf] (34), [-0.00230,   inf] (30), [-0.00225,   inf] (30), [-0.00224,   inf] (30), [-0.00218,   inf] (30), [-0.00214,   inf] (30), [-0.00210,   inf] (34), [-0.00208,   inf] (30), [-0.00208,   inf] (32), 
length of domains: 70
Total time: 1.0020	 pickout: 0.0100	 decision: 0.0764	 get_bound: 0.9145	 add_domain: 0.0011
Current lb:-0.0030530691146850586
254 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 24.29702353477478

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3699] [4, 3699] [4, 3699] [4, 3699] [4, 3699] [4, 3699] [4, 3699] [4, 3699] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04162495955824852 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 5.4067742894403636e-05, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.8357563018798828
This batch time : update_bounds func: 0.8657	 prepare: 0.0068	 bound: 0.8364	 transfer: 0.0191	 finalize: 0.0033
Accumulated time: update_bounds func: 16.7512	 prepare: 0.1242	 bound: 16.2966	 transfer: 0.0191	 finalize: 0.0571
batch bounding time:  0.8660557270050049
Current worst splitting domains [lb, ub] (depth):
[-0.00305,   inf] (40), [-0.00295,   inf] (40), [-0.00287,   inf] (40), [-0.00282,   inf] (40), [-0.00278,   inf] (40), [-0.00272,   inf] (40), [-0.00266,   inf] (40), [-0.00264,   inf] (40), [-0.00256,   inf] (40), [-0.00255,   inf] (40), [-0.00248,   inf] (40), [-0.00243,   inf] (40), [-0.00239,   inf] (40), [-0.00233,   inf] (40), [-0.00233,   inf] (34), [-0.00231,   inf] (34), [-0.00231,   inf] (32), [-0.00230,   inf] (34), [-0.00230,   inf] (30), [-0.00225,   inf] (40), 
length of domains: 78
Total time: 0.9525	 pickout: 0.0087	 decision: 0.0758	 get_bound: 0.8661	 add_domain: 0.0020
Current lb:-0.003049015998840332
270 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 25.250068426132202

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 525] [2, 525] [2, 525] [2, 525] [2, 525] [2, 525] [2, 525] [2, 525] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.1201629638671875 with beta sum per layer: [0.0, 0.0, 3.110492706298828, 0.0, 4.055080717080273e-05, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.8982264995574951
This batch time : update_bounds func: 0.9190	 prepare: 0.0072	 bound: 0.8989	 transfer: 0.0097	 finalize: 0.0032
Accumulated time: update_bounds func: 17.6702	 prepare: 0.1314	 bound: 17.1954	 transfer: 0.0097	 finalize: 0.0602
batch bounding time:  0.91935133934021
Current worst splitting domains [lb, ub] (depth):
[-0.00305,   inf] (42), [-0.00295,   inf] (42), [-0.00287,   inf] (42), [-0.00282,   inf] (42), [-0.00277,   inf] (42), [-0.00272,   inf] (42), [-0.00266,   inf] (42), [-0.00264,   inf] (42), [-0.00256,   inf] (40), [-0.00255,   inf] (40), [-0.00248,   inf] (40), [-0.00243,   inf] (40), [-0.00239,   inf] (40), [-0.00233,   inf] (40), [-0.00233,   inf] (34), [-0.00231,   inf] (34), [-0.00231,   inf] (32), [-0.00230,   inf] (34), [-0.00230,   inf] (30), [-0.00225,   inf] (40), 
length of domains: 78
Total time: 1.0066	 pickout: 0.0087	 decision: 0.0775	 get_bound: 0.9194	 add_domain: 0.0011
Current lb:-0.0030469894409179688
286 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 26.257272720336914

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2453] [2, 2453] [2, 2453] [2, 2453] [2, 2453] [2, 2453] [2, 2453] [2, 2453] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.005700636655092239 with beta sum per layer: [0.0, 0.0, 0.6761960983276367, 0.0, 4.055080717080273e-05, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.8426985740661621
This batch time : update_bounds func: 0.8728	 prepare: 0.0070	 bound: 0.8434	 transfer: 0.0190	 finalize: 0.0033
Accumulated time: update_bounds func: 18.5430	 prepare: 0.1384	 bound: 18.0388	 transfer: 0.0190	 finalize: 0.0635
batch bounding time:  0.8731927871704102
Current worst splitting domains [lb, ub] (depth):
[-0.00305,   inf] (44), [-0.00295,   inf] (44), [-0.00287,   inf] (44), [-0.00282,   inf] (44), [-0.00277,   inf] (44), [-0.00272,   inf] (44), [-0.00265,   inf] (44), [-0.00264,   inf] (44), [-0.00256,   inf] (40), [-0.00255,   inf] (40), [-0.00248,   inf] (40), [-0.00243,   inf] (40), [-0.00239,   inf] (40), [-0.00233,   inf] (40), [-0.00233,   inf] (34), [-0.00231,   inf] (34), [-0.00231,   inf] (32), [-0.00230,   inf] (34), [-0.00230,   inf] (30), [-0.00225,   inf] (40), 
length of domains: 78
Total time: 0.9596	 pickout: 0.0089	 decision: 0.0764	 get_bound: 0.8732	 add_domain: 0.0011
Current lb:-0.0030455589294433594
302 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 27.21749782562256

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2584] [2, 2584] [2, 2574] [2, 2574] [2, 2574] [2, 2584] [2, 2584] [2, 2574] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.12816724181175232 with beta sum per layer: [0.0, 0.0, 2.123194694519043, 0.0, 0.0068827904760837555, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.886998176574707
This batch time : update_bounds func: 0.9043	 prepare: 0.0070	 bound: 0.8876	 transfer: 0.0065	 finalize: 0.0032
Accumulated time: update_bounds func: 19.4473	 prepare: 0.1454	 bound: 18.9264	 transfer: 0.0065	 finalize: 0.0667
batch bounding time:  0.9046611785888672
Current worst splitting domains [lb, ub] (depth):
[-0.00304,   inf] (46), [-0.00295,   inf] (46), [-0.00287,   inf] (46), [-0.00281,   inf] (46), [-0.00277,   inf] (46), [-0.00272,   inf] (46), [-0.00265,   inf] (46), [-0.00264,   inf] (46), [-0.00256,   inf] (40), [-0.00255,   inf] (40), [-0.00248,   inf] (40), [-0.00243,   inf] (40), [-0.00239,   inf] (40), [-0.00233,   inf] (40), [-0.00233,   inf] (34), [-0.00231,   inf] (34), [-0.00231,   inf] (32), [-0.00230,   inf] (34), [-0.00230,   inf] (30), [-0.00225,   inf] (40), 
length of domains: 78
Total time: 0.9923	 pickout: 0.0087	 decision: 0.0777	 get_bound: 0.9047	 add_domain: 0.0011
Current lb:-0.003044724464416504
318 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 28.21038556098938

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2574] [2, 2574] [2, 2584] [2, 2584] [2, 2584] [2, 2574] [2, 2574] [2, 2584] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.12477818131446838 with beta sum per layer: [0.0, 0.0, 2.093560218811035, 0.0, 0.0072128986939787865, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.8986697196960449
This batch time : update_bounds func: 0.9152	 prepare: 0.0071	 bound: 0.8993	 transfer: 0.0056	 finalize: 0.0032
Accumulated time: update_bounds func: 20.3625	 prepare: 0.1524	 bound: 19.8257	 transfer: 0.0056	 finalize: 0.0699
batch bounding time:  0.9155735969543457
Current worst splitting domains [lb, ub] (depth):
[-0.00304,   inf] (48), [-0.00295,   inf] (48), [-0.00287,   inf] (48), [-0.00281,   inf] (48), [-0.00277,   inf] (48), [-0.00272,   inf] (48), [-0.00265,   inf] (48), [-0.00264,   inf] (48), [-0.00256,   inf] (40), [-0.00255,   inf] (40), [-0.00248,   inf] (40), [-0.00243,   inf] (40), [-0.00239,   inf] (40), [-0.00233,   inf] (40), [-0.00233,   inf] (34), [-0.00231,   inf] (34), [-0.00231,   inf] (32), [-0.00230,   inf] (34), [-0.00230,   inf] (30), [-0.00225,   inf] (40), 
length of domains: 78
Total time: 1.0031	 pickout: 0.0086	 decision: 0.0777	 get_bound: 0.9156	 add_domain: 0.0012
Current lb:-0.0030438899993896484
334 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 29.21410036087036

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 526] [2, 526] [2, 526] [2, 526] [2, 526] [2, 526] [2, 526] [2, 526] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.1663210093975067 with beta sum per layer: [0.0, 0.0, 3.018252372741699, 0.0, 4.055080717080273e-05, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.901940107345581
This batch time : update_bounds func: 0.9187	 prepare: 0.0070	 bound: 0.9025	 transfer: 0.0056	 finalize: 0.0035
Accumulated time: update_bounds func: 21.2812	 prepare: 0.1594	 bound: 20.7282	 transfer: 0.0056	 finalize: 0.0734
batch bounding time:  0.9190037250518799
Current worst splitting domains [lb, ub] (depth):
[-0.00304,   inf] (50), [-0.00295,   inf] (50), [-0.00287,   inf] (50), [-0.00281,   inf] (50), [-0.00277,   inf] (50), [-0.00272,   inf] (50), [-0.00265,   inf] (50), [-0.00264,   inf] (50), [-0.00256,   inf] (40), [-0.00255,   inf] (40), [-0.00248,   inf] (40), [-0.00243,   inf] (40), [-0.00239,   inf] (40), [-0.00233,   inf] (40), [-0.00233,   inf] (34), [-0.00231,   inf] (34), [-0.00231,   inf] (32), [-0.00230,   inf] (34), [-0.00230,   inf] (30), [-0.00225,   inf] (40), 
length of domains: 78
Total time: 1.0065	 pickout: 0.0088	 decision: 0.0775	 get_bound: 0.9190	 add_domain: 0.0011
Current lb:-0.003043651580810547
350 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 30.221126317977905

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 15886] [2, 15886] [2, 15886] [8, 3306] [8, 3306] [2, 15886] [8, 3306] [2, 15886] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.08221284300088882 with beta sum per layer: [0.0, 0.0, 1.8264268636703491, 0.0, 5.4067742894403636e-05, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.8998968601226807
This batch time : update_bounds func: 0.9167	 prepare: 0.0073	 bound: 0.9005	 transfer: 0.0056	 finalize: 0.0032
Accumulated time: update_bounds func: 22.1980	 prepare: 0.1667	 bound: 21.6288	 transfer: 0.0056	 finalize: 0.0766
batch bounding time:  0.91709303855896
Current worst splitting domains [lb, ub] (depth):
[-0.00304,   inf] (52), [-0.00295,   inf] (52), [-0.00287,   inf] (52), [-0.00281,   inf] (52), [-0.00281,   inf] (52), [-0.00277,   inf] (52), [-0.00277,   inf] (52), [-0.00272,   inf] (52), [-0.00265,   inf] (52), [-0.00265,   inf] (52), [-0.00264,   inf] (52), [-0.00256,   inf] (40), [-0.00255,   inf] (40), [-0.00248,   inf] (40), [-0.00243,   inf] (40), [-0.00239,   inf] (40), [-0.00233,   inf] (40), [-0.00233,   inf] (34), [-0.00231,   inf] (34), [-0.00231,   inf] (32), 
length of domains: 81
Total time: 1.0060	 pickout: 0.0084	 decision: 0.0789	 get_bound: 0.9171	 add_domain: 0.0015
Current lb:-0.0030432939529418945
366 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 31.22768497467041

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 530] [2, 530] [2, 530] [2, 530] [2, 530] [2, 530] [2, 530] [2, 530] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.13830818235874176 with beta sum per layer: [0.0, 0.0, 3.01825213432312, 0.0, 4.055080717080273e-05, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.8968863487243652
This batch time : update_bounds func: 0.9167	 prepare: 0.0071	 bound: 0.8975	 transfer: 0.0088	 finalize: 0.0032
Accumulated time: update_bounds func: 23.1147	 prepare: 0.1738	 bound: 22.5263	 transfer: 0.0088	 finalize: 0.0799
batch bounding time:  0.9170417785644531
Current worst splitting domains [lb, ub] (depth):
[-0.00304,   inf] (54), [-0.00295,   inf] (54), [-0.00286,   inf] (54), [-0.00281,   inf] (54), [-0.00281,   inf] (54), [-0.00277,   inf] (54), [-0.00277,   inf] (54), [-0.00272,   inf] (54), [-0.00265,   inf] (52), [-0.00265,   inf] (52), [-0.00264,   inf] (52), [-0.00256,   inf] (40), [-0.00255,   inf] (40), [-0.00248,   inf] (40), [-0.00243,   inf] (40), [-0.00239,   inf] (40), [-0.00233,   inf] (40), [-0.00233,   inf] (34), [-0.00231,   inf] (34), [-0.00231,   inf] (32), 
length of domains: 81
Total time: 1.0038	 pickout: 0.0091	 decision: 0.0764	 get_bound: 0.9171	 add_domain: 0.0012
Current lb:-0.00304257869720459
382 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 32.23214626312256

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 15890] [2, 15890] [2, 15890] [2, 15890] [2, 15890] [2, 15890] [2, 15890] [2, 15890] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.13661052286624908 with beta sum per layer: [0.0, 0.0, 3.018251419067383, 0.0, 4.055080717080273e-05, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.8723812103271484
This batch time : update_bounds func: 0.9019	 prepare: 0.0074	 bound: 0.8730	 transfer: 0.0182	 finalize: 0.0032
Accumulated time: update_bounds func: 24.0165	 prepare: 0.1812	 bound: 23.3993	 transfer: 0.0182	 finalize: 0.0830
batch bounding time:  0.9021930694580078
Current worst splitting domains [lb, ub] (depth):
[-0.00304,   inf] (56), [-0.00295,   inf] (56), [-0.00286,   inf] (56), [-0.00281,   inf] (56), [-0.00281,   inf] (56), [-0.00277,   inf] (56), [-0.00277,   inf] (56), [-0.00272,   inf] (56), [-0.00265,   inf] (52), [-0.00265,   inf] (52), [-0.00264,   inf] (52), [-0.00256,   inf] (40), [-0.00255,   inf] (40), [-0.00248,   inf] (40), [-0.00243,   inf] (40), [-0.00239,   inf] (40), [-0.00233,   inf] (40), [-0.00233,   inf] (34), [-0.00231,   inf] (34), [-0.00231,   inf] (32), 
length of domains: 81
Total time: 0.9887	 pickout: 0.0089	 decision: 0.0763	 get_bound: 0.9022	 add_domain: 0.0012
Current lb:-0.003041505813598633
398 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 33.2214150428772

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2454] [2, 2454] [2, 2454] [2, 15886] [2, 2454] [2, 2454] [2, 2454] [2, 2454] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.03813245892524719 with beta sum per layer: [0.0, 0.0, 2.6379034519195557, 0.0, 4.055080717080273e-05, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.8825180530548096
This batch time : update_bounds func: 0.9000	 prepare: 0.0071	 bound: 0.8831	 transfer: 0.0066	 finalize: 0.0031
Accumulated time: update_bounds func: 24.9165	 prepare: 0.1883	 bound: 24.2824	 transfer: 0.0066	 finalize: 0.0862
batch bounding time:  0.9003133773803711
Current worst splitting domains [lb, ub] (depth):
[-0.00304,   inf] (58), [-0.00295,   inf] (58), [-0.00286,   inf] (58), [-0.00281,   inf] (58), [-0.00281,   inf] (58), [-0.00277,   inf] (58), [-0.00277,   inf] (58), [-0.00272,   inf] (58), [-0.00265,   inf] (52), [-0.00265,   inf] (52), [-0.00264,   inf] (52), [-0.00256,   inf] (40), [-0.00255,   inf] (40), [-0.00248,   inf] (40), [-0.00243,   inf] (40), [-0.00239,   inf] (40), [-0.00233,   inf] (40), [-0.00233,   inf] (34), [-0.00231,   inf] (34), [-0.00231,   inf] (32), 
length of domains: 81
Total time: 0.9859	 pickout: 0.0086	 decision: 0.0757	 get_bound: 0.9003	 add_domain: 0.0012
Current lb:-0.0030411481857299805
414 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 34.20788216590881

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3421] [4, 3421] [4, 3421] [4, 3421] [4, 3421] [4, 3421] [4, 3421] [4, 3421] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.043051883578300476 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 8.110161434160545e-05, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.7564880847930908
This batch time : update_bounds func: 0.7732	 prepare: 0.0071	 bound: 0.7571	 transfer: 0.0056	 finalize: 0.0032
Accumulated time: update_bounds func: 25.6897	 prepare: 0.1955	 bound: 25.0395	 transfer: 0.0056	 finalize: 0.0894
batch bounding time:  0.7736372947692871
Current worst splitting domains [lb, ub] (depth):
[-0.00304,   inf] (60), [-0.00294,   inf] (60), [-0.00286,   inf] (60), [-0.00281,   inf] (60), [-0.00281,   inf] (60), [-0.00277,   inf] (60), [-0.00277,   inf] (60), [-0.00274,   inf] (60), [-0.00271,   inf] (60), [-0.00265,   inf] (52), [-0.00265,   inf] (52), [-0.00265,   inf] (60), [-0.00264,   inf] (52), [-0.00256,   inf] (60), [-0.00256,   inf] (40), [-0.00255,   inf] (40), [-0.00251,   inf] (60), [-0.00251,   inf] (60), [-0.00248,   inf] (40), [-0.00247,   inf] (60), 
length of domains: 89
Total time: 0.8612	 pickout: 0.0085	 decision: 0.0766	 get_bound: 0.7737	 add_domain: 0.0024
Current lb:-0.003040267387405038
430 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 35.06962060928345

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [8, 3306] [8, 3306] [8, 3306] [2, 2454] [2, 15886] [2, 15886] [2, 15886] [8, 3306] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.04503226280212402 with beta sum per layer: [0.0, 0.0, 1.5265761613845825, 0.0, 5.4067742894403636e-05, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.8806352615356445
This batch time : update_bounds func: 0.9032	 prepare: 0.0072	 bound: 0.8813	 transfer: 0.0100	 finalize: 0.0046
Accumulated time: update_bounds func: 26.5929	 prepare: 0.2027	 bound: 25.9208	 transfer: 0.0100	 finalize: 0.0940
batch bounding time:  0.9035444259643555
Current worst splitting domains [lb, ub] (depth):
[-0.00304,   inf] (62), [-0.00304,   inf] (62), [-0.00294,   inf] (62), [-0.00294,   inf] (62), [-0.00286,   inf] (62), [-0.00286,   inf] (62), [-0.00281,   inf] (62), [-0.00281,   inf] (62), [-0.00277,   inf] (62), [-0.00277,   inf] (62), [-0.00274,   inf] (62), [-0.00274,   inf] (62), [-0.00271,   inf] (60), [-0.00265,   inf] (52), [-0.00265,   inf] (52), [-0.00265,   inf] (60), [-0.00264,   inf] (52), [-0.00256,   inf] (60), [-0.00256,   inf] (40), [-0.00255,   inf] (40), 
length of domains: 93
Total time: 0.9906	 pickout: 0.0087	 decision: 0.0764	 get_bound: 0.9036	 add_domain: 0.0019
Current lb:-0.003040267387405038
446 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 36.06079840660095

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3700] [4, 3700] [4, 3700] [4, 3700] [4, 3700] [4, 3700] [4, 3700] [4, 3700] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04433519020676613 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0009381328709423542, 0.0, 0.0, 0.0, 0.0025669897440820932, 0.0]
alpha/beta optimization time: 0.7887570858001709
This batch time : update_bounds func: 0.8231	 prepare: 0.0107	 bound: 0.7895	 transfer: 0.0195	 finalize: 0.0032
Accumulated time: update_bounds func: 27.4160	 prepare: 0.2134	 bound: 26.7103	 transfer: 0.0195	 finalize: 0.0972
batch bounding time:  0.8233990669250488
Current worst splitting domains [lb, ub] (depth):
[-0.00304,   inf] (64), [-0.00304,   inf] (64), [-0.00294,   inf] (64), [-0.00294,   inf] (64), [-0.00286,   inf] (64), [-0.00286,   inf] (64), [-0.00281,   inf] (64), [-0.00281,   inf] (64), [-0.00277,   inf] (62), [-0.00277,   inf] (62), [-0.00276,   inf] (64), [-0.00274,   inf] (62), [-0.00274,   inf] (62), [-0.00274,   inf] (64), [-0.00271,   inf] (60), [-0.00266,   inf] (64), [-0.00265,   inf] (52), [-0.00265,   inf] (52), [-0.00265,   inf] (60), [-0.00264,   inf] (64), 
length of domains: 101
Total time: 0.9281	 pickout: 0.0122	 decision: 0.0900	 get_bound: 0.8234	 add_domain: 0.0025
Current lb:-0.0030393600463867188
462 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 36.98939228057861

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 627] [9, 627] [9, 627] [9, 627] [9, 627] [9, 627] [9, 627] [9, 627] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.035300664603710175 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 2.7033871447201818e-05, 0.0, 0.0, 0.0, 0.0, 3.3991618156433105]
alpha/beta optimization time: 0.8811712265014648
This batch time : update_bounds func: 0.9121	 prepare: 0.0073	 bound: 0.8818	 transfer: 0.0197	 finalize: 0.0033
Accumulated time: update_bounds func: 28.3280	 prepare: 0.2206	 bound: 27.5921	 transfer: 0.0197	 finalize: 0.1005
batch bounding time:  0.9124739170074463
Current worst splitting domains [lb, ub] (depth):
[-0.00303,   inf] (66), [-0.00303,   inf] (66), [-0.00294,   inf] (66), [-0.00294,   inf] (66), [-0.00285,   inf] (66), [-0.00285,   inf] (66), [-0.00280,   inf] (66), [-0.00280,   inf] (66), [-0.00277,   inf] (62), [-0.00277,   inf] (62), [-0.00276,   inf] (64), [-0.00274,   inf] (62), [-0.00274,   inf] (62), [-0.00274,   inf] (64), [-0.00271,   inf] (60), [-0.00266,   inf] (64), [-0.00265,   inf] (52), [-0.00265,   inf] (52), [-0.00265,   inf] (60), [-0.00264,   inf] (64), 
length of domains: 101
Total time: 1.0018	 pickout: 0.0100	 decision: 0.0779	 get_bound: 0.9125	 add_domain: 0.0014
Current lb:-0.003031611442565918
478 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 37.99181270599365

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 536] [2, 536] [2, 536] [2, 536] [9, 756] [9, 756] [2, 536] [2, 536] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.0218372642993927 with beta sum per layer: [0.0, 0.0, 1.1222615242004395, 0.0, 3.610284693422727e-05, 0.0, 0.0, 0.0, 0.0009163226932287216, 1.5567638874053955]
alpha/beta optimization time: 0.8743233680725098
This batch time : update_bounds func: 0.9043	 prepare: 0.0075	 bound: 0.8750	 transfer: 0.0184	 finalize: 0.0033
Accumulated time: update_bounds func: 29.2323	 prepare: 0.2281	 bound: 28.4671	 transfer: 0.0184	 finalize: 0.1038
batch bounding time:  0.9046790599822998
Current worst splitting domains [lb, ub] (depth):
[-0.00303,   inf] (68), [-0.00303,   inf] (68), [-0.00294,   inf] (68), [-0.00294,   inf] (68), [-0.00285,   inf] (68), [-0.00285,   inf] (68), [-0.00281,   inf] (68), [-0.00280,   inf] (68), [-0.00280,   inf] (68), [-0.00279,   inf] (68), [-0.00277,   inf] (62), [-0.00277,   inf] (62), [-0.00276,   inf] (64), [-0.00274,   inf] (62), [-0.00274,   inf] (62), [-0.00274,   inf] (64), [-0.00271,   inf] (60), [-0.00266,   inf] (64), [-0.00265,   inf] (52), [-0.00265,   inf] (52), 
length of domains: 103
Total time: 0.9945	 pickout: 0.0090	 decision: 0.0791	 get_bound: 0.9047	 add_domain: 0.0017
Current lb:-0.003031134605407715
494 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 38.986971616744995

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 15896] [2, 15896] [2, 15896] [2, 15896] [9, 947] [9, 947] [4, 3337] [2, 15896] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.014453411102294922 with beta sum per layer: [0.0, 0.0, 0.936713457107544, 0.0, 0.0002364582906011492, 0.0, 0.0, 0.0, 0.002631868002936244, 3.834506034851074]
alpha/beta optimization time: 0.848590612411499
This batch time : update_bounds func: 0.8699	 prepare: 0.0076	 bound: 0.8492	 transfer: 0.0098	 finalize: 0.0032
Accumulated time: update_bounds func: 30.1022	 prepare: 0.2357	 bound: 29.3163	 transfer: 0.0098	 finalize: 0.1070
batch bounding time:  0.8702666759490967
Current worst splitting domains [lb, ub] (depth):
[-0.00303,   inf] (70), [-0.00303,   inf] (70), [-0.00294,   inf] (70), [-0.00294,   inf] (70), [-0.00285,   inf] (70), [-0.00285,   inf] (70), [-0.00280,   inf] (70), [-0.00280,   inf] (68), [-0.00279,   inf] (68), [-0.00277,   inf] (62), [-0.00277,   inf] (62), [-0.00276,   inf] (64), [-0.00274,   inf] (62), [-0.00274,   inf] (62), [-0.00274,   inf] (64), [-0.00271,   inf] (60), [-0.00266,   inf] (64), [-0.00265,   inf] (52), [-0.00265,   inf] (52), [-0.00265,   inf] (60), 
length of domains: 106
Total time: 0.9594	 pickout: 0.0089	 decision: 0.0783	 get_bound: 0.8703	 add_domain: 0.0019
Current lb:-0.003031015396118164
510 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 39.94694900512695

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2693] [2, 2693] [9, 756] [9, 756] [2, 536] [2, 15896] [2, 2693] [9, 756] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.015478269197046757 with beta sum per layer: [0.0, 0.0, 0.44893011450767517, 0.0, 2.7033871447201818e-05, 0.0, 0.0, 0.0, 0.0009163226932287216, 2.3554608821868896]
alpha/beta optimization time: 0.8868169784545898
This batch time : update_bounds func: 0.9183	 prepare: 0.0075	 bound: 0.8874	 transfer: 0.0195	 finalize: 0.0037
Accumulated time: update_bounds func: 31.0205	 prepare: 0.2432	 bound: 30.2037	 transfer: 0.0195	 finalize: 0.1107
batch bounding time:  0.9186041355133057
Current worst splitting domains [lb, ub] (depth):
[-0.00303,   inf] (72), [-0.00303,   inf] (72), [-0.00294,   inf] (72), [-0.00294,   inf] (72), [-0.00289,   inf] (72), [-0.00287,   inf] (72), [-0.00285,   inf] (72), [-0.00285,   inf] (72), [-0.00280,   inf] (70), [-0.00280,   inf] (72), [-0.00279,   inf] (68), [-0.00277,   inf] (62), [-0.00277,   inf] (62), [-0.00276,   inf] (64), [-0.00274,   inf] (62), [-0.00274,   inf] (62), [-0.00274,   inf] (64), [-0.00274,   inf] (70), [-0.00271,   inf] (60), [-0.00266,   inf] (64), 
length of domains: 112
Total time: 1.0075	 pickout: 0.0099	 decision: 0.0766	 get_bound: 0.9187	 add_domain: 0.0023
Current lb:-0.003031015396118164
526 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 40.95488786697388

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3698] [4, 3698] [4, 3698] [4, 3698] [4, 3337] [4, 3337] [4, 3698] [4, 3698] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04514037072658539 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 8.018626249395311e-05, 0.0, 0.0, 0.0, 0.002631871262565255, 6.1574835777282715]
alpha/beta optimization time: 0.8687357902526855
This batch time : update_bounds func: 0.8998	 prepare: 0.0073	 bound: 0.8694	 transfer: 0.0196	 finalize: 0.0034
Accumulated time: update_bounds func: 31.9203	 prepare: 0.2505	 bound: 31.0731	 transfer: 0.0196	 finalize: 0.1141
batch bounding time:  0.9001832008361816
Current worst splitting domains [lb, ub] (depth):
[-0.00303,   inf] (74), [-0.00303,   inf] (74), [-0.00293,   inf] (74), [-0.00293,   inf] (74), [-0.00290,   inf] (74), [-0.00290,   inf] (74), [-0.00285,   inf] (74), [-0.00285,   inf] (74), [-0.00280,   inf] (74), [-0.00280,   inf] (74), [-0.00280,   inf] (70), [-0.00280,   inf] (72), [-0.00279,   inf] (68), [-0.00277,   inf] (62), [-0.00277,   inf] (62), [-0.00276,   inf] (64), [-0.00274,   inf] (62), [-0.00274,   inf] (62), [-0.00274,   inf] (64), [-0.00274,   inf] (70), 
length of domains: 120
Total time: 0.9901	 pickout: 0.0102	 decision: 0.0770	 get_bound: 0.9002	 add_domain: 0.0027
Current lb:-0.003030061721801758
542 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 41.94548296928406

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2452] [2, 2452] [2, 2452] [2, 2452] [2, 2452] [2, 2452] [2, 2452] [2, 2452] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.031159741804003716 with beta sum per layer: [0.0, 0.0, 0.4020036458969116, 0.0, 0.0008639481384307146, 0.0, 0.0, 0.0, 0.0, 1.5972042083740234]
alpha/beta optimization time: 0.8302304744720459
This batch time : update_bounds func: 0.8612	 prepare: 0.0072	 bound: 0.8308	 transfer: 0.0197	 finalize: 0.0033
Accumulated time: update_bounds func: 32.7815	 prepare: 0.2577	 bound: 31.9039	 transfer: 0.0197	 finalize: 0.1175
batch bounding time:  0.8616325855255127
Current worst splitting domains [lb, ub] (depth):
[-0.00303,   inf] (76), [-0.00303,   inf] (76), [-0.00293,   inf] (76), [-0.00293,   inf] (76), [-0.00289,   inf] (76), [-0.00289,   inf] (76), [-0.00285,   inf] (76), [-0.00285,   inf] (76), [-0.00280,   inf] (74), [-0.00280,   inf] (74), [-0.00280,   inf] (70), [-0.00280,   inf] (72), [-0.00279,   inf] (68), [-0.00277,   inf] (62), [-0.00277,   inf] (62), [-0.00276,   inf] (64), [-0.00274,   inf] (62), [-0.00274,   inf] (62), [-0.00274,   inf] (64), [-0.00274,   inf] (70), 
length of domains: 128
Total time: 0.9505	 pickout: 0.0100	 decision: 0.0760	 get_bound: 0.8617	 add_domain: 0.0028
Current lb:-0.003027200698852539
558 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 42.89651417732239

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3337] [4, 3337] [4, 3337] [4, 3337] [4, 3337] [4, 3337] [4, 3337] [4, 3337] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.045461397618055344 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.00010630476754158735, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.7655234336853027
This batch time : update_bounds func: 0.7963	 prepare: 0.0073	 bound: 0.7662	 transfer: 0.0195	 finalize: 0.0033
Accumulated time: update_bounds func: 33.5778	 prepare: 0.2650	 bound: 32.6701	 transfer: 0.0195	 finalize: 0.1208
batch bounding time:  0.7967116832733154
Current worst splitting domains [lb, ub] (depth):
[-0.00295,   inf] (78), [-0.00295,   inf] (78), [-0.00293,   inf] (78), [-0.00293,   inf] (78), [-0.00286,   inf] (78), [-0.00286,   inf] (78), [-0.00284,   inf] (78), [-0.00284,   inf] (78), [-0.00282,   inf] (78), [-0.00282,   inf] (78), [-0.00280,   inf] (74), [-0.00280,   inf] (74), [-0.00280,   inf] (70), [-0.00280,   inf] (72), [-0.00280,   inf] (78), [-0.00280,   inf] (78), [-0.00279,   inf] (68), [-0.00278,   inf] (78), [-0.00277,   inf] (78), [-0.00277,   inf] (62), 
length of domains: 136
Total time: 0.8866	 pickout: 0.0102	 decision: 0.0768	 get_bound: 0.7967	 add_domain: 0.0028
Current lb:-0.002953052520751953
574 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 43.783631324768066

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2609] [2, 2609] [2, 2609] [2, 2609] [2, 2609] [2, 2609] [2, 2609] [2, 2609] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.033390384167432785 with beta sum per layer: [0.0, 0.0, 0.2729693055152893, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003422653069719672, 0.0]
alpha/beta optimization time: 0.8604116439819336
This batch time : update_bounds func: 0.8938	 prepare: 0.0073	 bound: 0.8611	 transfer: 0.0202	 finalize: 0.0052
Accumulated time: update_bounds func: 34.4716	 prepare: 0.2723	 bound: 33.5312	 transfer: 0.0202	 finalize: 0.1260
batch bounding time:  0.8941640853881836
Current worst splitting domains [lb, ub] (depth):
[-0.00295,   inf] (80), [-0.00295,   inf] (80), [-0.00293,   inf] (80), [-0.00293,   inf] (80), [-0.00285,   inf] (80), [-0.00285,   inf] (80), [-0.00283,   inf] (80), [-0.00283,   inf] (80), [-0.00282,   inf] (78), [-0.00282,   inf] (78), [-0.00280,   inf] (74), [-0.00280,   inf] (74), [-0.00280,   inf] (70), [-0.00280,   inf] (72), [-0.00280,   inf] (78), [-0.00280,   inf] (78), [-0.00279,   inf] (68), [-0.00278,   inf] (78), [-0.00277,   inf] (78), [-0.00277,   inf] (62), 
length of domains: 144
Total time: 0.9844	 pickout: 0.0102	 decision: 0.0770	 get_bound: 0.8942	 add_domain: 0.0030
Current lb:-0.0029495954513549805
590 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 44.76846385002136

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3688] [4, 3688] [4, 3688] [4, 3688] [4, 3688] [4, 3688] [4, 3688] [4, 3688] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04556393623352051 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.7879519462585449
This batch time : update_bounds func: 0.8226	 prepare: 0.0108	 bound: 0.7888	 transfer: 0.0196	 finalize: 0.0033
Accumulated time: update_bounds func: 35.2942	 prepare: 0.2831	 bound: 34.3199	 transfer: 0.0196	 finalize: 0.1293
batch bounding time:  0.8229517936706543
Current worst splitting domains [lb, ub] (depth):
[-0.00295,   inf] (82), [-0.00295,   inf] (82), [-0.00293,   inf] (82), [-0.00293,   inf] (82), [-0.00286,   inf] (82), [-0.00286,   inf] (82), [-0.00285,   inf] (82), [-0.00285,   inf] (82), [-0.00284,   inf] (82), [-0.00284,   inf] (82), [-0.00283,   inf] (82), [-0.00283,   inf] (82), [-0.00282,   inf] (78), [-0.00282,   inf] (78), [-0.00280,   inf] (74), [-0.00280,   inf] (74), [-0.00280,   inf] (70), [-0.00280,   inf] (72), [-0.00280,   inf] (78), [-0.00280,   inf] (78), 
length of domains: 152
Total time: 0.9289	 pickout: 0.0125	 decision: 0.0905	 get_bound: 0.8230	 add_domain: 0.0029
Current lb:-0.0029467344284057617
606 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 45.69788980484009

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 3697] [4, 3697] [4, 3697] [4, 3697] [4, 3697] [4, 3697] [4, 3697] [4, 3697] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.045649923384189606 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.7708308696746826
This batch time : update_bounds func: 0.8017	 prepare: 0.0074	 bound: 0.7715	 transfer: 0.0196	 finalize: 0.0032
Accumulated time: update_bounds func: 36.0959	 prepare: 0.2906	 bound: 35.0914	 transfer: 0.0196	 finalize: 0.1325
batch bounding time:  0.8020808696746826
Current worst splitting domains [lb, ub] (depth):
[-0.00294,   inf] (84), [-0.00294,   inf] (84), [-0.00292,   inf] (84), [-0.00292,   inf] (84), [-0.00286,   inf] (84), [-0.00286,   inf] (84), [-0.00286,   inf] (84), [-0.00286,   inf] (84), [-0.00285,   inf] (84), [-0.00285,   inf] (84), [-0.00284,   inf] (82), [-0.00284,   inf] (82), [-0.00284,   inf] (84), [-0.00284,   inf] (84), [-0.00283,   inf] (82), [-0.00283,   inf] (82), [-0.00282,   inf] (78), [-0.00282,   inf] (78), [-0.00280,   inf] (74), [-0.00280,   inf] (74), 
length of domains: 160
Total time: 0.8914	 pickout: 0.0099	 decision: 0.0764	 get_bound: 0.8021	 add_domain: 0.0029
Current lb:-0.002941608428955078
622 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 46.58979678153992

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 756] [2, 406] [2, 406] [2, 406] [9, 756] [2, 406] [9, 756] [9, 756] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.015968188643455505 with beta sum per layer: [0.0, 0.0, 1.2041929960250854, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0019142144592478871, 3.0423381328582764]
alpha/beta optimization time: 0.8856339454650879
This batch time : update_bounds func: 0.9171	 prepare: 0.0074	 bound: 0.8862	 transfer: 0.0200	 finalize: 0.0033
Accumulated time: update_bounds func: 37.0130	 prepare: 0.2980	 bound: 35.9776	 transfer: 0.0200	 finalize: 0.1358
batch bounding time:  0.9174900054931641
Current worst splitting domains [lb, ub] (depth):
[-0.00294,   inf] (86), [-0.00294,   inf] (86), [-0.00292,   inf] (86), [-0.00292,   inf] (86), [-0.00287,   inf] (86), [-0.00286,   inf] (86), [-0.00286,   inf] (86), [-0.00286,   inf] (86), [-0.00286,   inf] (86), [-0.00285,   inf] (84), [-0.00285,   inf] (84), [-0.00284,   inf] (82), [-0.00284,   inf] (82), [-0.00284,   inf] (84), [-0.00284,   inf] (84), [-0.00283,   inf] (82), [-0.00283,   inf] (82), [-0.00282,   inf] (86), [-0.00282,   inf] (78), [-0.00282,   inf] (78), 
length of domains: 164
Total time: 1.0060	 pickout: 0.0100	 decision: 0.0762	 get_bound: 0.9175	 add_domain: 0.0023
Current lb:-0.002941608428955078
638 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 47.59639286994934

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 15766] [2, 15766] [2, 15766] [2, 15766] [9, 294] [2, 15766] [2, 15766] [2, 15766] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: -0.009618930518627167 with beta sum per layer: [0.0, 0.0, 2.170712471008301, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00484239449724555, 3.5336434841156006]
alpha/beta optimization time: 0.8977422714233398
This batch time : update_bounds func: 0.9287	 prepare: 0.0074	 bound: 0.8984	 transfer: 0.0196	 finalize: 0.0032
Accumulated time: update_bounds func: 37.9416	 prepare: 0.3054	 bound: 36.8760	 transfer: 0.0196	 finalize: 0.1390
batch bounding time:  0.929020881652832
Current worst splitting domains [lb, ub] (depth):
[-0.00294,   inf] (88), [-0.00294,   inf] (88), [-0.00292,   inf] (88), [-0.00292,   inf] (88), [-0.00286,   inf] (88), [-0.00286,   inf] (88), [-0.00286,   inf] (86), [-0.00286,   inf] (88), [-0.00285,   inf] (84), [-0.00285,   inf] (84), [-0.00284,   inf] (82), [-0.00284,   inf] (82), [-0.00284,   inf] (84), [-0.00284,   inf] (84), [-0.00283,   inf] (82), [-0.00283,   inf] (82), [-0.00282,   inf] (86), [-0.00282,   inf] (78), [-0.00282,   inf] (78), [-0.00280,   inf] (74), 
length of domains: 164
Total time: 1.0174	 pickout: 0.0100	 decision: 0.0767	 get_bound: 0.9291	 add_domain: 0.0016
Current lb:-0.0029414892196655273
654 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 48.61444854736328

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 405] [2, 405] [2, 405] [2, 405] [2, 405] [2, 405] [2, 15766] [2, 405] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.004216372966766357 with beta sum per layer: [0.0, 0.0, 1.5034418106079102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001097763772122562, 0.05510341748595238]
alpha/beta optimization time: 0.8795573711395264
This batch time : update_bounds func: 0.9102	 prepare: 0.0073	 bound: 0.8802	 transfer: 0.0196	 finalize: 0.0032
Accumulated time: update_bounds func: 38.8519	 prepare: 0.3127	 bound: 37.7561	 transfer: 0.0196	 finalize: 0.1422
batch bounding time:  0.9105930328369141
Current worst splitting domains [lb, ub] (depth):
[-0.00294,   inf] (90), [-0.00294,   inf] (90), [-0.00292,   inf] (90), [-0.00292,   inf] (90), [-0.00286,   inf] (90), [-0.00286,   inf] (90), [-0.00286,   inf] (88), [-0.00286,   inf] (90), [-0.00285,   inf] (84), [-0.00285,   inf] (84), [-0.00284,   inf] (82), [-0.00284,   inf] (82), [-0.00284,   inf] (84), [-0.00284,   inf] (84), [-0.00283,   inf] (82), [-0.00283,   inf] (82), [-0.00282,   inf] (86), [-0.00282,   inf] (78), [-0.00282,   inf] (78), [-0.00280,   inf] (74), 
length of domains: 164
Total time: 0.9998	 pickout: 0.0101	 decision: 0.0774	 get_bound: 0.9106	 add_domain: 0.0016
Current lb:-0.0029407739639282227
670 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 49.614885091781616

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 15765] [2, 15765] [2, 15765] [2, 15765] [2, 15765] [2, 15765] [2, 405] [2, 15765] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.006892673671245575 with beta sum per layer: [0.0, 0.0, 1.484132170677185, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001097763772122562, 0.07931574434041977]
alpha/beta optimization time: 0.7934353351593018
This batch time : update_bounds func: 0.8229	 prepare: 0.0073	 bound: 0.7940	 transfer: 0.0182	 finalize: 0.0032
Accumulated time: update_bounds func: 39.6747	 prepare: 0.3200	 bound: 38.5502	 transfer: 0.0182	 finalize: 0.1454
batch bounding time:  0.823214054107666
Current worst splitting domains [lb, ub] (depth):
[-0.00294,   inf] (92), [-0.00294,   inf] (92), [-0.00292,   inf] (92), [-0.00292,   inf] (92), [-0.00286,   inf] (92), [-0.00286,   inf] (92), [-0.00286,   inf] (90), [-0.00286,   inf] (92), [-0.00285,   inf] (84), [-0.00285,   inf] (84), [-0.00284,   inf] (82), [-0.00284,   inf] (82), [-0.00284,   inf] (84), [-0.00284,   inf] (84), [-0.00283,   inf] (82), [-0.00283,   inf] (82), [-0.00282,   inf] (86), [-0.00282,   inf] (78), [-0.00282,   inf] (78), [-0.00280,   inf] (74), 
length of domains: 164
Total time: 0.9108	 pickout: 0.0089	 decision: 0.0770	 get_bound: 0.8233	 add_domain: 0.0016
Current lb:-0.0029404163360595703
686 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 50.52637195587158

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 294] [9, 294] [9, 294] [9, 294] [9, 294] [9, 294] [2, 15765] [9, 294] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.01639595627784729 with beta sum per layer: [0.0, 0.0, 0.2121644914150238, 0.0, 0.0, 0.0, 0.0, 0.0, 0.018325986340641975, 5.056884765625]
alpha/beta optimization time: 0.9436607360839844
This batch time : update_bounds func: 0.9672	 prepare: 0.0074	 bound: 0.9443	 transfer: 0.0109	 finalize: 0.0045
Accumulated time: update_bounds func: 40.6419	 prepare: 0.3274	 bound: 39.4945	 transfer: 0.0109	 finalize: 0.1499
batch bounding time:  0.9675765037536621
Current worst splitting domains [lb, ub] (depth):
[-0.00294,   inf] (94), [-0.00294,   inf] (94), [-0.00292,   inf] (94), [-0.00292,   inf] (94), [-0.00286,   inf] (94), [-0.00286,   inf] (94), [-0.00286,   inf] (92), [-0.00286,   inf] (94), [-0.00285,   inf] (84), [-0.00285,   inf] (84), [-0.00284,   inf] (82), [-0.00284,   inf] (82), [-0.00284,   inf] (84), [-0.00284,   inf] (84), [-0.00283,   inf] (82), [-0.00283,   inf] (82), [-0.00282,   inf] (86), [-0.00282,   inf] (78), [-0.00282,   inf] (78), [-0.00280,   inf] (74), 
length of domains: 164
Total time: 1.0555	 pickout: 0.0087	 decision: 0.0775	 get_bound: 0.9676	 add_domain: 0.0017
Current lb:-0.002939581871032715
702 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 51.58248496055603

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 728] [9, 728] [9, 728] [9, 728] [9, 728] [9, 728] [9, 294] [9, 728] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.009092727676033974 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005602603312581778, 5.060824394226074]
alpha/beta optimization time: 0.9679989814758301
This batch time : update_bounds func: 0.9888	 prepare: 0.0108	 bound: 0.9688	 transfer: 0.0058	 finalize: 0.0032
Accumulated time: update_bounds func: 41.6307	 prepare: 0.3382	 bound: 40.4633	 transfer: 0.0058	 finalize: 0.1532
batch bounding time:  0.9891166687011719
Current worst splitting domains [lb, ub] (depth):
[-0.00294,   inf] (96), [-0.00294,   inf] (96), [-0.00292,   inf] (96), [-0.00292,   inf] (96), [-0.00286,   inf] (96), [-0.00286,   inf] (96), [-0.00286,   inf] (94), [-0.00286,   inf] (96), [-0.00285,   inf] (84), [-0.00285,   inf] (84), [-0.00284,   inf] (82), [-0.00284,   inf] (82), [-0.00284,   inf] (84), [-0.00284,   inf] (84), [-0.00283,   inf] (82), [-0.00283,   inf] (82), [-0.00282,   inf] (86), [-0.00282,   inf] (78), [-0.00282,   inf] (78), [-0.00280,   inf] (74), 
length of domains: 164
Total time: 1.0914	 pickout: 0.0111	 decision: 0.0895	 get_bound: 0.9892	 add_domain: 0.0016
Current lb:-0.0029380321502685547
718 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 52.67453742027283

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 406] [9, 756] [9, 756] [9, 756] [2, 406] [9, 756] [9, 728] [9, 947] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.023736238479614258 with beta sum per layer: [0.0, 0.0, 0.7295399904251099, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0009571072296239436, 4.321288108825684]
alpha/beta optimization time: 0.8738002777099609
This batch time : update_bounds func: 0.8907	 prepare: 0.0075	 bound: 0.8744	 transfer: 0.0056	 finalize: 0.0031
Accumulated time: update_bounds func: 42.5214	 prepare: 0.3457	 bound: 41.3377	 transfer: 0.0056	 finalize: 0.1563
batch bounding time:  0.8910341262817383
Current worst splitting domains [lb, ub] (depth):
[-0.00294,   inf] (98), [-0.00294,   inf] (98), [-0.00292,   inf] (98), [-0.00292,   inf] (98), [-0.00286,   inf] (98), [-0.00286,   inf] (98), [-0.00286,   inf] (98), [-0.00285,   inf] (96), [-0.00285,   inf] (84), [-0.00285,   inf] (84), [-0.00284,   inf] (98), [-0.00284,   inf] (82), [-0.00284,   inf] (82), [-0.00284,   inf] (84), [-0.00284,   inf] (84), [-0.00284,   inf] (98), [-0.00283,   inf] (82), [-0.00283,   inf] (82), [-0.00282,   inf] (86), [-0.00282,   inf] (78), 
length of domains: 169
Total time: 0.9795	 pickout: 0.0087	 decision: 0.0771	 get_bound: 0.8911	 add_domain: 0.0026
Current lb:-0.002937912940979004
734 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 53.65456748008728

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2633] [2, 2633] [2, 2633] [2, 2633] [2, 2633] [2, 2633] [2, 2633] [2, 406] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.034391917288303375 with beta sum per layer: [0.0, 0.0, 0.4292674958705902, 0.0, 0.00024902026052586734, 0.0, 0.0, 0.0, 0.004562595393508673, 0.0]
alpha/beta optimization time: 0.8937921524047852
This batch time : update_bounds func: 0.9191	 prepare: 0.0076	 bound: 0.8944	 transfer: 0.0137	 finalize: 0.0033
Accumulated time: update_bounds func: 43.4405	 prepare: 0.3532	 bound: 42.2321	 transfer: 0.0137	 finalize: 0.1596
batch bounding time:  0.9194693565368652
Current worst splitting domains [lb, ub] (depth):
[-0.00294,   inf] (100), [-0.00294,   inf] (100), [-0.00292,   inf] (100), [-0.00292,   inf] (100), [-0.00286,   inf] (100), [-0.00286,   inf] (100), [-0.00285,   inf] (98), [-0.00285,   inf] (100), [-0.00285,   inf] (84), [-0.00285,   inf] (84), [-0.00284,   inf] (98), [-0.00284,   inf] (82), [-0.00284,   inf] (82), [-0.00284,   inf] (84), [-0.00284,   inf] (84), [-0.00284,   inf] (98), [-0.00283,   inf] (82), [-0.00283,   inf] (82), [-0.00282,   inf] (86), [-0.00282,   inf] (78), 
length of domains: 176
Total time: 1.0086	 pickout: 0.0087	 decision: 0.0767	 get_bound: 0.9195	 add_domain: 0.0036
Current lb:-0.0029364824295043945
750 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 54.663695096969604

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 947] [9, 947] [9, 947] [2, 645] [9, 947] [9, 947] [2, 2633] [2, 406] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.026393873617053032 with beta sum per layer: [0.0, 0.0, 0.30294594168663025, 0.0, 0.0004151548782829195, 0.0, 0.0, 0.0, 0.0, 2.1396737098693848]
alpha/beta optimization time: 0.8977196216583252
This batch time : update_bounds func: 0.9294	 prepare: 0.0078	 bound: 0.8985	 transfer: 0.0198	 finalize: 0.0033
Accumulated time: update_bounds func: 44.3699	 prepare: 0.3610	 bound: 43.1306	 transfer: 0.0198	 finalize: 0.1629
batch bounding time:  0.9297704696655273
Current worst splitting domains [lb, ub] (depth):
[-0.00294,   inf] (102), [-0.00294,   inf] (102), [-0.00292,   inf] (102), [-0.00292,   inf] (102), [-0.00286,   inf] (102), [-0.00286,   inf] (102), [-0.00285,   inf] (102), [-0.00285,   inf] (100), [-0.00285,   inf] (84), [-0.00285,   inf] (84), [-0.00284,   inf] (98), [-0.00284,   inf] (82), [-0.00284,   inf] (82), [-0.00284,   inf] (84), [-0.00284,   inf] (84), [-0.00284,   inf] (98), [-0.00283,   inf] (82), [-0.00283,   inf] (82), [-0.00282,   inf] (86), [-0.00282,   inf] (78), 
length of domains: 183
Total time: 1.0208	 pickout: 0.0103	 decision: 0.0775	 get_bound: 0.9298	 add_domain: 0.0032
Current lb:-0.0029364824295043945
766 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 55.685017824172974

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2519] [2, 2519] [2, 2519] [2, 2519] [2, 2519] [2, 2519] [2, 2519] [9, 947] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03995099663734436 with beta sum per layer: [0.0, 0.0, 0.07724594324827194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.4835424423217773]
alpha/beta optimization time: 0.7770178318023682
This batch time : update_bounds func: 0.8078	 prepare: 0.0074	 bound: 0.7776	 transfer: 0.0195	 finalize: 0.0032
Accumulated time: update_bounds func: 45.1777	 prepare: 0.3684	 bound: 43.9082	 transfer: 0.0195	 finalize: 0.1661
batch bounding time:  0.8081910610198975
Current worst splitting domains [lb, ub] (depth):
[-0.00294,   inf] (104), [-0.00294,   inf] (104), [-0.00292,   inf] (104), [-0.00292,   inf] (104), [-0.00286,   inf] (104), [-0.00286,   inf] (104), [-0.00285,   inf] (104), [-0.00285,   inf] (102), [-0.00285,   inf] (84), [-0.00285,   inf] (84), [-0.00284,   inf] (98), [-0.00284,   inf] (82), [-0.00284,   inf] (82), [-0.00284,   inf] (84), [-0.00284,   inf] (84), [-0.00284,   inf] (98), [-0.00283,   inf] (82), [-0.00283,   inf] (82), [-0.00282,   inf] (86), [-0.00282,   inf] (78), 
length of domains: 191
Total time: 0.8996	 pickout: 0.0100	 decision: 0.0780	 get_bound: 0.8083	 add_domain: 0.0033
Current lb:-0.0029363632202148438
782 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 56.58513355255127

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 16005] [2, 16005] [2, 645] [9, 947] [2, 645] [2, 3339] [2, 645] [2, 2519] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.029481736943125725 with beta sum per layer: [0.0, 0.0, 0.5852620601654053, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0009933318942785263, 2.0979881286621094]
alpha/beta optimization time: 0.8661258220672607
This batch time : update_bounds func: 0.8970	 prepare: 0.0074	 bound: 0.8667	 transfer: 0.0195	 finalize: 0.0032
Accumulated time: update_bounds func: 46.0747	 prepare: 0.3758	 bound: 44.7749	 transfer: 0.0195	 finalize: 0.1693
batch bounding time:  0.8973431587219238
Current worst splitting domains [lb, ub] (depth):
[-0.00294,   inf] (106), [-0.00294,   inf] (106), [-0.00292,   inf] (106), [-0.00292,   inf] (106), [-0.00286,   inf] (106), [-0.00286,   inf] (106), [-0.00286,   inf] (106), [-0.00285,   inf] (106), [-0.00285,   inf] (104), [-0.00285,   inf] (84), [-0.00285,   inf] (84), [-0.00284,   inf] (98), [-0.00284,   inf] (82), [-0.00284,   inf] (82), [-0.00284,   inf] (84), [-0.00284,   inf] (84), [-0.00284,   inf] (98), [-0.00283,   inf] (82), [-0.00283,   inf] (82), [-0.00282,   inf] (86), 
length of domains: 199
Total time: 0.9874	 pickout: 0.0100	 decision: 0.0766	 get_bound: 0.8974	 add_domain: 0.0034
Current lb:-0.0029360055923461914
798 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 57.57311534881592

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 3339] [2, 3339] [2, 16005] [2, 2517] [2, 3339] [2, 16005] [2, 16005] [2, 16005] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.034459035843610764 with beta sum per layer: [0.0, 0.0, 0.41837090253829956, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0015085588674992323, 1.5385279655456543]
alpha/beta optimization time: 0.8444728851318359
This batch time : update_bounds func: 0.8753	 prepare: 0.0076	 bound: 0.8451	 transfer: 0.0194	 finalize: 0.0032
Accumulated time: update_bounds func: 46.9500	 prepare: 0.3834	 bound: 45.6200	 transfer: 0.0194	 finalize: 0.1725
batch bounding time:  0.8757047653198242
Current worst splitting domains [lb, ub] (depth):
[-0.00294,   inf] (108), [-0.00294,   inf] (108), [-0.00294,   inf] (108), [-0.00292,   inf] (108), [-0.00292,   inf] (108), [-0.00291,   inf] (108), [-0.00286,   inf] (108), [-0.00286,   inf] (108), [-0.00286,   inf] (108), [-0.00286,   inf] (108), [-0.00285,   inf] (108), [-0.00285,   inf] (104), [-0.00285,   inf] (84), [-0.00285,   inf] (84), [-0.00284,   inf] (98), [-0.00284,   inf] (82), [-0.00284,   inf] (82), [-0.00284,   inf] (84), [-0.00284,   inf] (84), [-0.00284,   inf] (98), 
length of domains: 207
Total time: 0.9667	 pickout: 0.0100	 decision: 0.0769	 get_bound: 0.8757	 add_domain: 0.0041
Current lb:-0.0029360055923461914
814 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 58.540289640426636

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2642] [2, 2642] [2, 2642] [2, 2642] [2, 2642] [2, 2642] [2, 2642] [2, 2642] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04344010353088379 with beta sum per layer: [0.0, 0.0, 0.09369947016239166, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.8468446731567383
This batch time : update_bounds func: 0.8775	 prepare: 0.0073	 bound: 0.8475	 transfer: 0.0196	 finalize: 0.0032
Accumulated time: update_bounds func: 47.8275	 prepare: 0.3906	 bound: 46.4675	 transfer: 0.0196	 finalize: 0.1757
batch bounding time:  0.8778915405273438
Current worst splitting domains [lb, ub] (depth):
[-0.00294,   inf] (110), [-0.00294,   inf] (110), [-0.00293,   inf] (110), [-0.00292,   inf] (110), [-0.00292,   inf] (110), [-0.00291,   inf] (110), [-0.00286,   inf] (108), [-0.00286,   inf] (108), [-0.00286,   inf] (110), [-0.00286,   inf] (110), [-0.00285,   inf] (108), [-0.00285,   inf] (104), [-0.00285,   inf] (84), [-0.00285,   inf] (84), [-0.00284,   inf] (98), [-0.00284,   inf] (82), [-0.00284,   inf] (82), [-0.00284,   inf] (84), [-0.00284,   inf] (84), [-0.00284,   inf] (98), 
length of domains: 215
Total time: 0.9679	 pickout: 0.0099	 decision: 0.0766	 get_bound: 0.8779	 add_domain: 0.0035
Current lb:-0.002935051918029785
830 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 59.50875735282898

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2517] [2, 2517] [2, 2486] [2, 2486] [2, 3339] [2, 2486] [2, 2642] [2, 2642] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04282999038696289 with beta sum per layer: [0.0, 0.0, 0.07215491682291031, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001508469576947391, 1.7225022315979004]
alpha/beta optimization time: 0.8597812652587891
This batch time : update_bounds func: 0.8925	 prepare: 0.0073	 bound: 0.8604	 transfer: 0.0202	 finalize: 0.0045
Accumulated time: update_bounds func: 48.7200	 prepare: 0.3979	 bound: 47.3279	 transfer: 0.0202	 finalize: 0.1802
batch bounding time:  0.8928601741790771
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (112), [-0.00293,   inf] (112), [-0.00293,   inf] (112), [-0.00292,   inf] (112), [-0.00292,   inf] (112), [-0.00291,   inf] (112), [-0.00289,   inf] (112), [-0.00286,   inf] (110), [-0.00286,   inf] (110), [-0.00286,   inf] (110), [-0.00286,   inf] (110), [-0.00285,   inf] (108), [-0.00285,   inf] (104), [-0.00285,   inf] (84), [-0.00285,   inf] (84), [-0.00284,   inf] (98), [-0.00284,   inf] (82), [-0.00284,   inf] (82), [-0.00284,   inf] (84), [-0.00284,   inf] (84), 
length of domains: 223
Total time: 0.9827	 pickout: 0.0099	 decision: 0.0762	 get_bound: 0.8929	 add_domain: 0.0037
Current lb:-0.0029348134994506836
846 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 60.492106676101685

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 404] [2, 404] [2, 404] [2, 404] [2, 404] [2, 404] [2, 404] [2, 2517] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03167855739593506 with beta sum per layer: [0.0, 0.0, 0.9985314011573792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004594601225107908, 2.2350077629089355]
alpha/beta optimization time: 0.8305320739746094
This batch time : update_bounds func: 0.8654	 prepare: 0.0110	 bound: 0.8313	 transfer: 0.0197	 finalize: 0.0033
Accumulated time: update_bounds func: 49.5854	 prepare: 0.4089	 bound: 48.1592	 transfer: 0.0197	 finalize: 0.1834
batch bounding time:  0.8657994270324707
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (114), [-0.00293,   inf] (114), [-0.00293,   inf] (114), [-0.00291,   inf] (114), [-0.00291,   inf] (114), [-0.00291,   inf] (114), [-0.00289,   inf] (114), [-0.00286,   inf] (110), [-0.00286,   inf] (110), [-0.00286,   inf] (110), [-0.00286,   inf] (112), [-0.00285,   inf] (108), [-0.00285,   inf] (104), [-0.00285,   inf] (84), [-0.00285,   inf] (84), [-0.00284,   inf] (98), [-0.00284,   inf] (82), [-0.00284,   inf] (82), [-0.00284,   inf] (84), [-0.00284,   inf] (84), 
length of domains: 231
Total time: 0.9714	 pickout: 0.0128	 decision: 0.0892	 get_bound: 0.8658	 add_domain: 0.0036
Current lb:-0.0029343366622924805
862 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 61.46406102180481

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 15764] [2, 15764] [2, 15764] [2, 15764] [2, 15764] [2, 15764] [2, 15764] [2, 2517] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03235065937042236 with beta sum per layer: [0.0, 0.0, 0.9932652711868286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0012482486199587584, 2.181079864501953]
alpha/beta optimization time: 0.8608453273773193
This batch time : update_bounds func: 0.8917	 prepare: 0.0075	 bound: 0.8615	 transfer: 0.0195	 finalize: 0.0031
Accumulated time: update_bounds func: 50.4771	 prepare: 0.4164	 bound: 49.0207	 transfer: 0.0195	 finalize: 0.1866
batch bounding time:  0.8920607566833496
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (116), [-0.00293,   inf] (116), [-0.00293,   inf] (116), [-0.00291,   inf] (116), [-0.00291,   inf] (116), [-0.00291,   inf] (116), [-0.00289,   inf] (116), [-0.00286,   inf] (110), [-0.00286,   inf] (110), [-0.00286,   inf] (112), [-0.00286,   inf] (112), [-0.00285,   inf] (108), [-0.00285,   inf] (104), [-0.00285,   inf] (84), [-0.00285,   inf] (84), [-0.00284,   inf] (98), [-0.00284,   inf] (82), [-0.00284,   inf] (82), [-0.00284,   inf] (84), [-0.00284,   inf] (84), 
length of domains: 239
Total time: 0.9843	 pickout: 0.0102	 decision: 0.0783	 get_bound: 0.8921	 add_domain: 0.0036
Current lb:-0.002933502197265625
878 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 62.448867321014404

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2486] [2, 2486] [2, 561] [2, 561] [2, 3339] [2, 561] [2, 561] [2, 2486] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03858718276023865 with beta sum per layer: [0.0, 0.0, 0.3984489440917969, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.472190797328949]
alpha/beta optimization time: 0.8126652240753174
This batch time : update_bounds func: 0.8511	 prepare: 0.0146	 bound: 0.8137	 transfer: 0.0195	 finalize: 0.0032
Accumulated time: update_bounds func: 51.3282	 prepare: 0.4310	 bound: 49.8344	 transfer: 0.0195	 finalize: 0.1898
batch bounding time:  0.8515069484710693
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (118), [-0.00293,   inf] (118), [-0.00293,   inf] (118), [-0.00291,   inf] (118), [-0.00291,   inf] (118), [-0.00291,   inf] (118), [-0.00291,   inf] (118), [-0.00289,   inf] (118), [-0.00286,   inf] (110), [-0.00286,   inf] (112), [-0.00286,   inf] (112), [-0.00286,   inf] (112), [-0.00285,   inf] (108), [-0.00285,   inf] (104), [-0.00285,   inf] (84), [-0.00285,   inf] (84), [-0.00284,   inf] (98), [-0.00284,   inf] (82), [-0.00284,   inf] (82), [-0.00284,   inf] (84), 
length of domains: 247
Total time: 0.9605	 pickout: 0.0100	 decision: 0.0953	 get_bound: 0.8515	 add_domain: 0.0037
Current lb:-0.0029331445693969727
894 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 63.40995216369629

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 561] [2, 561] [2, 15921] [2, 561] [2, 561] [2, 15921] [2, 15921] [2, 15921] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03454709053039551 with beta sum per layer: [0.0, 0.0, 0.8023979067802429, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.848886251449585
This batch time : update_bounds func: 0.8835	 prepare: 0.0074	 bound: 0.8495	 transfer: 0.0205	 finalize: 0.0061
Accumulated time: update_bounds func: 52.2118	 prepare: 0.4384	 bound: 50.6839	 transfer: 0.0205	 finalize: 0.1959
batch bounding time:  0.8840804100036621
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (120), [-0.00293,   inf] (120), [-0.00293,   inf] (120), [-0.00291,   inf] (120), [-0.00291,   inf] (120), [-0.00291,   inf] (120), [-0.00291,   inf] (120), [-0.00289,   inf] (120), [-0.00286,   inf] (110), [-0.00286,   inf] (112), [-0.00286,   inf] (112), [-0.00286,   inf] (112), [-0.00285,   inf] (108), [-0.00285,   inf] (104), [-0.00285,   inf] (84), [-0.00285,   inf] (84), [-0.00284,   inf] (98), [-0.00284,   inf] (82), [-0.00284,   inf] (82), [-0.00284,   inf] (84), 
length of domains: 255
Total time: 0.9791	 pickout: 0.0101	 decision: 0.0774	 get_bound: 0.8842	 add_domain: 0.0074
Current lb:-0.002932429313659668
910 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 64.3898184299469

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 15921] [2, 15921] [2, 2517] [2, 15921] [2, 15921] [2, 2486] [2, 645] [2, 2486] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.036739468574523926 with beta sum per layer: [0.0, 0.0, 0.6231697201728821, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010665819980204105, 1.221818447113037]
alpha/beta optimization time: 0.8563492298126221
This batch time : update_bounds func: 0.8872	 prepare: 0.0074	 bound: 0.8570	 transfer: 0.0194	 finalize: 0.0033
Accumulated time: update_bounds func: 53.0990	 prepare: 0.4458	 bound: 51.5409	 transfer: 0.0194	 finalize: 0.1992
batch bounding time:  0.887587308883667
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (122), [-0.00293,   inf] (122), [-0.00293,   inf] (122), [-0.00291,   inf] (122), [-0.00291,   inf] (122), [-0.00291,   inf] (122), [-0.00291,   inf] (122), [-0.00289,   inf] (122), [-0.00286,   inf] (110), [-0.00286,   inf] (112), [-0.00286,   inf] (112), [-0.00286,   inf] (112), [-0.00285,   inf] (108), [-0.00285,   inf] (104), [-0.00285,   inf] (84), [-0.00285,   inf] (84), [-0.00284,   inf] (98), [-0.00284,   inf] (82), [-0.00284,   inf] (82), [-0.00284,   inf] (84), 
length of domains: 263
Total time: 0.9923	 pickout: 0.0161	 decision: 0.0849	 get_bound: 0.8876	 add_domain: 0.0038
Current lb:-0.002931356430053711
926 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 65.38272762298584

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 645] [2, 645] [2, 3628] [2, 2517] [2, 2517] [2, 3628] [2, 2517] [2, 3628] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.038831114768981934 with beta sum per layer: [0.0, 0.0, 0.3459824323654175, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003373226150870323, 1.7404963970184326]
alpha/beta optimization time: 0.8113529682159424
This batch time : update_bounds func: 0.8422	 prepare: 0.0074	 bound: 0.8120	 transfer: 0.0196	 finalize: 0.0032
Accumulated time: update_bounds func: 53.9412	 prepare: 0.4532	 bound: 52.3528	 transfer: 0.0196	 finalize: 0.2023
batch bounding time:  0.8425877094268799
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (124), [-0.00293,   inf] (124), [-0.00293,   inf] (124), [-0.00293,   inf] (124), [-0.00291,   inf] (124), [-0.00291,   inf] (124), [-0.00291,   inf] (124), [-0.00291,   inf] (124), [-0.00291,   inf] (124), [-0.00289,   inf] (124), [-0.00289,   inf] (124), [-0.00286,   inf] (110), [-0.00286,   inf] (112), [-0.00286,   inf] (112), [-0.00286,   inf] (112), [-0.00285,   inf] (108), [-0.00285,   inf] (104), [-0.00285,   inf] (84), [-0.00285,   inf] (84), [-0.00284,   inf] (98), 
length of domains: 270
Total time: 0.9600	 pickout: 0.0101	 decision: 0.1037	 get_bound: 0.8426	 add_domain: 0.0036
Current lb:-0.00293123722076416
942 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 66.3432412147522

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2601] [2, 2601] [4, 3720] [4, 3720] [4, 3720] [4, 3720] [2, 2601] [2, 2601] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04556281119585037 with beta sum per layer: [0.0, 0.0, 0.07554028928279877, 0.0, 0.000901584280654788, 0.0, 0.0, 0.0, 0.0032917424105107784, 0.0]
alpha/beta optimization time: 0.7967433929443359
This batch time : update_bounds func: 0.8276	 prepare: 0.0075	 bound: 0.7974	 transfer: 0.0194	 finalize: 0.0032
Accumulated time: update_bounds func: 54.7687	 prepare: 0.4607	 bound: 53.1502	 transfer: 0.0194	 finalize: 0.2055
batch bounding time:  0.82790207862854
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (126), [-0.00293,   inf] (126), [-0.00293,   inf] (126), [-0.00293,   inf] (126), [-0.00293,   inf] (126), [-0.00293,   inf] (126), [-0.00291,   inf] (126), [-0.00291,   inf] (126), [-0.00291,   inf] (126), [-0.00291,   inf] (126), [-0.00291,   inf] (124), [-0.00291,   inf] (126), [-0.00291,   inf] (126), [-0.00289,   inf] (124), [-0.00289,   inf] (124), [-0.00286,   inf] (110), [-0.00286,   inf] (112), [-0.00286,   inf] (112), [-0.00286,   inf] (112), [-0.00285,   inf] (108), 
length of domains: 278
Total time: 0.9197	 pickout: 0.0100	 decision: 0.0779	 get_bound: 0.8279	 add_domain: 0.0039
Current lb:-0.0029311180114746094
958 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 67.26344013214111

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 2601] [2, 2601] [2, 2601] [2, 2601] [2, 645] [2, 645] [2, 2601] [2, 2601] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03965817019343376 with beta sum per layer: [0.0, 0.0, 0.4094695448875427, 0.0, 0.001352376420982182, 0.0, 0.0, 0.0, 0.004937613382935524, 0.38959449529647827]
alpha/beta optimization time: 0.8476755619049072
This batch time : update_bounds func: 0.8789	 prepare: 0.0074	 bound: 0.8483	 transfer: 0.0198	 finalize: 0.0034
Accumulated time: update_bounds func: 55.6477	 prepare: 0.4682	 bound: 53.9985	 transfer: 0.0198	 finalize: 0.2089
batch bounding time:  0.8793559074401855
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (128), [-0.00293,   inf] (128), [-0.00293,   inf] (128), [-0.00293,   inf] (128), [-0.00293,   inf] (128), [-0.00293,   inf] (128), [-0.00291,   inf] (126), [-0.00291,   inf] (126), [-0.00291,   inf] (124), [-0.00291,   inf] (126), [-0.00291,   inf] (126), [-0.00291,   inf] (128), [-0.00291,   inf] (128), [-0.00289,   inf] (124), [-0.00289,   inf] (124), [-0.00286,   inf] (110), [-0.00286,   inf] (112), [-0.00286,   inf] (112), [-0.00286,   inf] (112), [-0.00285,   inf] (108), 
length of domains: 284
Total time: 0.9704	 pickout: 0.0102	 decision: 0.0773	 get_bound: 0.8794	 add_domain: 0.0035
Current lb:-0.002927541732788086
974 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 68.2344708442688

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 3661] [2, 3628] [2, 3628] [2, 3628] [2, 3661] [2, 2696] [2, 2601] [2, 2601] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.027084819972515106 with beta sum per layer: [0.0, 0.0, 0.3276987075805664, 0.0, 0.1379794180393219, 0.0, 0.0, 0.0, 0.0032917424105107784, 0.0]
alpha/beta optimization time: 0.8572399616241455
This batch time : update_bounds func: 0.8881	 prepare: 0.0075	 bound: 0.8579	 transfer: 0.0195	 finalize: 0.0032
Accumulated time: update_bounds func: 56.5358	 prepare: 0.4756	 bound: 54.8564	 transfer: 0.0195	 finalize: 0.2120
batch bounding time:  0.8884942531585693
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (130), [-0.00293,   inf] (130), [-0.00293,   inf] (130), [-0.00293,   inf] (130), [-0.00293,   inf] (130), [-0.00293,   inf] (130), [-0.00293,   inf] (130), [-0.00293,   inf] (130), [-0.00293,   inf] (130), [-0.00293,   inf] (130), [-0.00293,   inf] (130), [-0.00291,   inf] (124), [-0.00291,   inf] (126), [-0.00291,   inf] (126), [-0.00291,   inf] (128), [-0.00291,   inf] (128), [-0.00291,   inf] (128), [-0.00291,   inf] (128), [-0.00289,   inf] (124), [-0.00289,   inf] (124), 
length of domains: 291
Total time: 0.9809	 pickout: 0.0102	 decision: 0.0784	 get_bound: 0.8885	 add_domain: 0.0037
Current lb:-0.002927541732788086
990 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 69.21595740318298

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 2341] [3, 3059] [2, 3661] [2, 3661] [2, 3661] [2, 3661] [2, 3661] [2, 3661] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.046727851033210754 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.4041733741760254, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.8783583641052246
This batch time : update_bounds func: 0.9094	 prepare: 0.0077	 bound: 0.8790	 transfer: 0.0195	 finalize: 0.0032
Accumulated time: update_bounds func: 57.4452	 prepare: 0.4833	 bound: 55.7354	 transfer: 0.0195	 finalize: 0.2153
batch bounding time:  0.9098994731903076
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (132), [-0.00293,   inf] (132), [-0.00293,   inf] (132), [-0.00293,   inf] (130), [-0.00293,   inf] (130), [-0.00293,   inf] (132), [-0.00293,   inf] (132), [-0.00293,   inf] (132), [-0.00293,   inf] (132), [-0.00293,   inf] (132), [-0.00293,   inf] (132), [-0.00293,   inf] (132), [-0.00293,   inf] (132), [-0.00293,   inf] (132), [-0.00293,   inf] (132), [-0.00293,   inf] (132), [-0.00293,   inf] (132), [-0.00293,   inf] (130), [-0.00291,   inf] (124), [-0.00291,   inf] (126), 
length of domains: 299
Total time: 1.0015	 pickout: 0.0101	 decision: 0.0775	 get_bound: 0.9099	 add_domain: 0.0040
Current lb:-0.002927541732788086
1006 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 70.21797895431519

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 236] [0, 382] [4, 2341] [4, 2341] [3, 3059] [3, 3059] [9, 236] [9, 236] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.027736196294426918 with beta sum per layer: [0.17084908485412598, 0.0, 0.0, 0.0, 0.8083467483520508, 0.0, 0.0, 0.0, 0.0, 1.6974480152130127]
alpha/beta optimization time: 0.9321856498718262
This batch time : update_bounds func: 0.9637	 prepare: 0.0080	 bound: 0.9328	 transfer: 0.0196	 finalize: 0.0032
Accumulated time: update_bounds func: 58.4090	 prepare: 0.4913	 bound: 56.6682	 transfer: 0.0196	 finalize: 0.2184
batch bounding time:  0.964104413986206
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (132), [-0.00293,   inf] (132), [-0.00293,   inf] (132), [-0.00293,   inf] (132), [-0.00293,   inf] (132), [-0.00293,   inf] (132), [-0.00293,   inf] (132), [-0.00293,   inf] (132), [-0.00293,   inf] (132), [-0.00293,   inf] (132), [-0.00293,   inf] (132), [-0.00293,   inf] (132), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (130), [-0.00291,   inf] (134), [-0.00291,   inf] (134), [-0.00291,   inf] (134), 
length of domains: 304
Total time: 1.0560	 pickout: 0.0100	 decision: 0.0786	 get_bound: 0.9642	 add_domain: 0.0032
Current lb:-0.002927541732788086
1022 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 71.27451968193054

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3060] [4, 2418] [0, 382] [2, 2696] [3, 3059] [2, 2696] [4, 2341] [0, 382] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.006882350891828537 with beta sum per layer: [0.21755719184875488, 0.0, 0.6666236519813538, 0.0, 0.9495090246200562, 0.0, 0.0, 0.0, 0.002681303070858121, 0.0]
alpha/beta optimization time: 0.877448558807373
This batch time : update_bounds func: 0.9092	 prepare: 0.0081	 bound: 0.8781	 transfer: 0.0196	 finalize: 0.0034
Accumulated time: update_bounds func: 59.3182	 prepare: 0.4994	 bound: 57.5463	 transfer: 0.0196	 finalize: 0.2218
batch bounding time:  0.9096636772155762
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (136), [-0.00293,   inf] (136), [-0.00293,   inf] (136), [-0.00293,   inf] (132), [-0.00293,   inf] (132), [-0.00293,   inf] (132), [-0.00293,   inf] (132), [-0.00293,   inf] (132), [-0.00293,   inf] (132), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), 
length of domains: 310
Total time: 1.0019	 pickout: 0.0103	 decision: 0.0783	 get_bound: 0.9097	 add_domain: 0.0036
Current lb:-0.002927541732788086
1038 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 72.2770209312439

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3061] [3, 3061] [0, 382] [9, 236] [3, 3059] [9, 236] [0, 382] [2, 346] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03405255824327469 with beta sum per layer: [0.21570594608783722, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.1566681861877441]
alpha/beta optimization time: 0.875969648361206
This batch time : update_bounds func: 0.9076	 prepare: 0.0081	 bound: 0.8766	 transfer: 0.0194	 finalize: 0.0033
Accumulated time: update_bounds func: 60.2258	 prepare: 0.5075	 bound: 58.4230	 transfer: 0.0194	 finalize: 0.2251
batch bounding time:  0.9079976081848145
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (138), [-0.00293,   inf] (138), [-0.00293,   inf] (138), [-0.00293,   inf] (138), [-0.00293,   inf] (138), [-0.00293,   inf] (132), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), 
length of domains: 316
Total time: 0.9999	 pickout: 0.0102	 decision: 0.0781	 get_bound: 0.9080	 add_domain: 0.0036
Current lb:-0.002927541732788086
1054 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 73.27750897407532

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [0, 1162] [0, 1162] [4, 2341] [9, 236] [0, 1162] [0, 382] [9, 236] [3, 3060] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03420998901128769 with beta sum per layer: [0.23094619810581207, 0.0, 0.0, 0.012059087865054607, 0.4041733741760254, 0.0, 0.0, 0.0, 0.0, 1.119312047958374]
alpha/beta optimization time: 0.8909046649932861
This batch time : update_bounds func: 0.9225	 prepare: 0.0082	 bound: 0.8915	 transfer: 0.0194	 finalize: 0.0032
Accumulated time: update_bounds func: 61.1483	 prepare: 0.5157	 bound: 59.3145	 transfer: 0.0194	 finalize: 0.2283
batch bounding time:  0.9228355884552002
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (140), [-0.00293,   inf] (140), [-0.00293,   inf] (140), [-0.00293,   inf] (140), [-0.00293,   inf] (140), [-0.00293,   inf] (140), [-0.00293,   inf] (140), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), 
length of domains: 322
Total time: 1.0158	 pickout: 0.0102	 decision: 0.0791	 get_bound: 0.9229	 add_domain: 0.0036
Current lb:-0.002927541732788086
1070 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 74.29385995864868

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 346] [0, 1163] [9, 236] [9, 236] [3, 3062] [4, 2427] [9, 236] [0, 1162] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.027499860152602196 with beta sum per layer: [0.0, 0.0, 0.0, 0.030649565160274506, 0.5626234412193298, 0.0, 0.0, 0.0, 0.0, 1.698289155960083]
alpha/beta optimization time: 0.8769121170043945
This batch time : update_bounds func: 0.9099	 prepare: 0.0084	 bound: 0.8776	 transfer: 0.0197	 finalize: 0.0041
Accumulated time: update_bounds func: 62.0581	 prepare: 0.5241	 bound: 60.1921	 transfer: 0.0197	 finalize: 0.2324
batch bounding time:  0.9103243350982666
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (142), [-0.00293,   inf] (142), [-0.00293,   inf] (142), [-0.00293,   inf] (142), [-0.00293,   inf] (142), [-0.00293,   inf] (142), [-0.00293,   inf] (142), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), 
length of domains: 327
Total time: 1.0018	 pickout: 0.0102	 decision: 0.0780	 get_bound: 0.9104	 add_domain: 0.0033
Current lb:-0.002927541732788086
1086 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 75.2962474822998

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 236] [0, 1163] [9, 236] [4, 2341] [9, 236] [9, 236] [2, 346] [2, 346] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.022907011210918427 with beta sum per layer: [0.027630643919110298, 0.0, 0.0, 0.16359353065490723, 0.3362295925617218, 0.0, 0.0, 0.0, 0.0, 2.235949993133545]
alpha/beta optimization time: 0.9095175266265869
This batch time : update_bounds func: 0.9413	 prepare: 0.0083	 bound: 0.9102	 transfer: 0.0195	 finalize: 0.0033
Accumulated time: update_bounds func: 62.9994	 prepare: 0.5324	 bound: 61.1022	 transfer: 0.0195	 finalize: 0.2357
batch bounding time:  0.9416959285736084
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (144), [-0.00293,   inf] (144), [-0.00293,   inf] (144), [-0.00293,   inf] (144), [-0.00293,   inf] (144), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (136), [-0.00293,   inf] (136), [-0.00293,   inf] (136), 
length of domains: 331
Total time: 1.0340	 pickout: 0.0105	 decision: 0.0786	 get_bound: 0.9417	 add_domain: 0.0031
Current lb:-0.002927541732788086
1102 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 76.33087468147278

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [0, 1182] [3, 3062] [0, 1182] [4, 2657] [0, 1163] [2, 346] [2, 346] [0, 382] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04675491154193878 with beta sum per layer: [0.21197079122066498, 0.0, 0.0, 0.0, 0.2903466820716858, 0.0, 0.0, 0.0, 0.0016477961326017976, 0.0]
alpha/beta optimization time: 0.859764814376831
This batch time : update_bounds func: 0.8921	 prepare: 0.0082	 bound: 0.8605	 transfer: 0.0199	 finalize: 0.0035
Accumulated time: update_bounds func: 63.8915	 prepare: 0.5406	 bound: 61.9627	 transfer: 0.0199	 finalize: 0.2391
batch bounding time:  0.8925104141235352
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (146), [-0.00293,   inf] (146), [-0.00293,   inf] (146), [-0.00293,   inf] (146), [-0.00293,   inf] (146), [-0.00293,   inf] (146), [-0.00293,   inf] (146), [-0.00293,   inf] (146), [-0.00293,   inf] (146), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (136), [-0.00293,   inf] (136), 
length of domains: 339
Total time: 0.9856	 pickout: 0.0104	 decision: 0.0785	 get_bound: 0.8926	 add_domain: 0.0042
Current lb:-0.002927541732788086
1118 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 77.31710529327393

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 2341] [4, 2341] [3, 3063] [3, 3063] [2, 346] [4, 2418] [2, 349] [4, 2657] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.046471625566482544 with beta sum per layer: [0.0, 0.0, 0.004926194436848164, 0.017987387254834175, 1.3000872135162354, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.7891366481781006
This batch time : update_bounds func: 0.8207	 prepare: 0.0082	 bound: 0.7898	 transfer: 0.0194	 finalize: 0.0033
Accumulated time: update_bounds func: 64.7122	 prepare: 0.5487	 bound: 62.7525	 transfer: 0.0194	 finalize: 0.2424
batch bounding time:  0.821073055267334
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (146), [-0.00293,   inf] (148), [-0.00293,   inf] (148), [-0.00293,   inf] (148), [-0.00293,   inf] (148), [-0.00293,   inf] (148), [-0.00293,   inf] (148), [-0.00293,   inf] (148), [-0.00293,   inf] (148), [-0.00293,   inf] (148), [-0.00293,   inf] (148), [-0.00293,   inf] (148), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), 
length of domains: 347
Total time: 0.9142	 pickout: 0.0102	 decision: 0.0786	 get_bound: 0.8211	 add_domain: 0.0043
Current lb:-0.002927541732788086
1134 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 78.23191332817078

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [0, 1182] [9, 236] [0, 1191] [2, 349] [3, 3064] [0, 1182] [3, 3064] [3, 3062] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04028880223631859 with beta sum per layer: [0.0015141747426241636, 0.0, 0.004926194436848164, 0.0029026377014815807, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5784652829170227]
alpha/beta optimization time: 0.9032487869262695
This batch time : update_bounds func: 0.9360	 prepare: 0.0088	 bound: 0.9039	 transfer: 0.0198	 finalize: 0.0034
Accumulated time: update_bounds func: 65.6482	 prepare: 0.5576	 bound: 63.6564	 transfer: 0.0198	 finalize: 0.2458
batch bounding time:  0.936424732208252
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (148), [-0.00293,   inf] (148), [-0.00293,   inf] (148), [-0.00293,   inf] (148), [-0.00293,   inf] (148), [-0.00293,   inf] (148), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (134), [-0.00293,   inf] (134), [-0.00293,   inf] (134), 
length of domains: 354
Total time: 1.0290	 pickout: 0.0102	 decision: 0.0784	 get_bound: 0.9365	 add_domain: 0.0040
Current lb:-0.002927541732788086
1150 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 79.261549949646

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 236] [4, 2427] [0, 1163] [0, 1182] [3, 3060] [9, 236] [4, 2418] [2, 349] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03395475447177887 with beta sum per layer: [0.0047164419665932655, 0.0, 0.0, 0.0, 0.979315996170044, 0.0, 0.0, 0.0, 0.0, 1.119823932647705]
alpha/beta optimization time: 0.8809781074523926
This batch time : update_bounds func: 0.9131	 prepare: 0.0085	 bound: 0.8817	 transfer: 0.0196	 finalize: 0.0033
Accumulated time: update_bounds func: 66.5613	 prepare: 0.5661	 bound: 64.5380	 transfer: 0.0196	 finalize: 0.2491
batch bounding time:  0.9135072231292725
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (134), [-0.00293,   inf] (134), 
length of domains: 360
Total time: 1.0080	 pickout: 0.0104	 decision: 0.0800	 get_bound: 0.9135	 add_domain: 0.0039
Current lb:-0.002927541732788086
1166 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 80.27012896537781

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 381] [2, 349] [9, 236] [9, 236] [0, 1191] [0, 1182] [0, 1182] [9, 236] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.028381098061800003 with beta sum per layer: [0.0015141747426241636, 0.0, 0.004926194436848164, 0.18876266479492188, 0.0, 0.0, 0.0, 0.0, 0.0, 1.6611825227737427]
alpha/beta optimization time: 0.8724093437194824
This batch time : update_bounds func: 0.9042	 prepare: 0.0082	 bound: 0.8731	 transfer: 0.0195	 finalize: 0.0034
Accumulated time: update_bounds func: 67.4655	 prepare: 0.5742	 bound: 65.4111	 transfer: 0.0195	 finalize: 0.2525
batch bounding time:  0.9046099185943604
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (150), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (134), [-0.00293,   inf] (134), 
length of domains: 365
Total time: 0.9967	 pickout: 0.0101	 decision: 0.0785	 get_bound: 0.9047	 add_domain: 0.0034
Current lb:-0.002927541732788086
1182 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 81.26743793487549

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [0, 1191] [2, 346] [2, 381] [4, 2715] [4, 2715] [0, 1191] [0, 1191] [2, 349] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.046454865485429764 with beta sum per layer: [0.0019495865562930703, 0.0, 0.004926194436848164, 0.0, 1.2713836431503296, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.8760290145874023
This batch time : update_bounds func: 0.9076	 prepare: 0.0082	 bound: 0.8767	 transfer: 0.0195	 finalize: 0.0032
Accumulated time: update_bounds func: 68.3731	 prepare: 0.5824	 bound: 66.2878	 transfer: 0.0195	 finalize: 0.2557
batch bounding time:  0.9080455303192139
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), 
length of domains: 373
Total time: 1.0032	 pickout: 0.0117	 decision: 0.0791	 get_bound: 0.9081	 add_domain: 0.0042
Current lb:-0.002927541732788086
1198 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 82.27119612693787

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [0, 1192] [9, 236] [3, 3064] [9, 236] [3, 3064] [4, 2341] [9, 236] [0, 1191] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.028505155816674232 with beta sum per layer: [0.0, 0.0, 0.0, 0.4141461253166199, 0.3806387484073639, 0.0, 0.0, 0.0, 0.0, 1.6611822843551636]
alpha/beta optimization time: 0.8737211227416992
This batch time : update_bounds func: 0.9057	 prepare: 0.0083	 bound: 0.8744	 transfer: 0.0196	 finalize: 0.0033
Accumulated time: update_bounds func: 69.2788	 prepare: 0.5908	 bound: 67.1621	 transfer: 0.0196	 finalize: 0.2590
batch bounding time:  0.9061267375946045
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), 
length of domains: 378
Total time: 0.9983	 pickout: 0.0102	 decision: 0.0785	 get_bound: 0.9062	 add_domain: 0.0034
Current lb:-0.002927541732788086
1214 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 83.27010726928711

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 2341] [3, 3065] [0, 1192] [9, 236] [4, 2657] [0, 1191] [3, 3060] [3, 3060] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04022848606109619 with beta sum per layer: [0.0015141747426241636, 0.0, 0.0, 0.023045208305120468, 0.6197556257247925, 0.0, 0.0, 0.0, 0.0, 0.5784652829170227]
alpha/beta optimization time: 0.8773794174194336
This batch time : update_bounds func: 0.9093	 prepare: 0.0083	 bound: 0.8781	 transfer: 0.0196	 finalize: 0.0033
Accumulated time: update_bounds func: 70.1881	 prepare: 0.5991	 bound: 68.0402	 transfer: 0.0196	 finalize: 0.2623
batch bounding time:  0.9097335338592529
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (152), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), 
length of domains: 385
Total time: 1.0033	 pickout: 0.0104	 decision: 0.0781	 get_bound: 0.9098	 add_domain: 0.0049
Current lb:-0.002927541732788086
1230 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 84.27394008636475

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [0, 1191] [4, 2715] [3, 3060] [2, 349] [2, 349] [0, 1191] [0, 1195] [3, 3062] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.046522106975317 with beta sum per layer: [0.0, 0.0, 0.009852388873696327, 0.020312966778874397, 0.6356918215751648, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.8070368766784668
This batch time : update_bounds func: 0.8391	 prepare: 0.0083	 bound: 0.8077	 transfer: 0.0198	 finalize: 0.0033
Accumulated time: update_bounds func: 71.0272	 prepare: 0.6073	 bound: 68.8479	 transfer: 0.0198	 finalize: 0.2656
batch bounding time:  0.839585542678833
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), 
length of domains: 393
Total time: 0.9339	 pickout: 0.0103	 decision: 0.0797	 get_bound: 0.8396	 add_domain: 0.0043
Current lb:-0.002927541732788086
1246 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 85.208500623703

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 236] [3, 3065] [2, 349] [9, 236] [2, 349] [9, 236] [0, 1192] [9, 236] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.022525282576680183 with beta sum per layer: [0.0, 0.0, 0.009852388873696327, 0.37810176610946655, 0.0, 0.0, 0.0, 0.0, 0.0, 2.1654343605041504]
alpha/beta optimization time: 0.8916177749633789
This batch time : update_bounds func: 0.9244	 prepare: 0.0083	 bound: 0.8923	 transfer: 0.0203	 finalize: 0.0034
Accumulated time: update_bounds func: 71.9517	 prepare: 0.6156	 bound: 69.7402	 transfer: 0.0203	 finalize: 0.2691
batch bounding time:  0.9249451160430908
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), 
length of domains: 397
Total time: 1.0179	 pickout: 0.0104	 decision: 0.0791	 get_bound: 0.9250	 add_domain: 0.0034
Current lb:-0.002927541732788086
1262 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 86.22722864151001

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 349] [0, 1191] [9, 236] [3, 3063] [4, 2715] [3, 3062] [2, 349] [9, 236] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03389466181397438 with beta sum per layer: [0.0047164419665932655, 0.0, 0.004926194436848164, 0.09342435747385025, 0.6356918215751648, 0.0, 0.0, 0.0, 0.0, 1.156930685043335]
alpha/beta optimization time: 0.9224066734313965
This batch time : update_bounds func: 0.9567	 prepare: 0.0087	 bound: 0.9231	 transfer: 0.0201	 finalize: 0.0047
Accumulated time: update_bounds func: 72.9083	 prepare: 0.6243	 bound: 70.6633	 transfer: 0.0201	 finalize: 0.2737
batch bounding time:  0.9570639133453369
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), 
length of domains: 403
Total time: 1.0534	 pickout: 0.0137	 decision: 0.0786	 get_bound: 0.9572	 add_domain: 0.0039
Current lb:-0.002927541732788086
1278 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 87.28122997283936

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 437] [9, 236] [0, 1182] [3, 3060] [4, 2719] [4, 2719] [4, 2715] [9, 236] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03380405157804489 with beta sum per layer: [0.0012844164157286286, 0.0, 0.016964644193649292, 0.012001344934105873, 0.7818381190299988, 0.0, 0.0, 0.0, 0.0, 1.1983580589294434]
alpha/beta optimization time: 0.9591436386108398
This batch time : update_bounds func: 0.9950	 prepare: 0.0123	 bound: 0.9599	 transfer: 0.0194	 finalize: 0.0032
Accumulated time: update_bounds func: 73.9033	 prepare: 0.6366	 bound: 71.6233	 transfer: 0.0194	 finalize: 0.2769
batch bounding time:  0.9953579902648926
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (154), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), 
length of domains: 409
Total time: 1.1075	 pickout: 0.0159	 decision: 0.0924	 get_bound: 0.9955	 add_domain: 0.0037
Current lb:-0.002927541732788086
1294 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 88.38941788673401

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3061] [2, 381] [0, 1192] [0, 1192] [3, 3062] [3, 3062] [9, 236] [0, 1195] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.040279679000377655 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5784652829170227]
alpha/beta optimization time: 0.8882725238800049
This batch time : update_bounds func: 0.9202	 prepare: 0.0082	 bound: 0.8889	 transfer: 0.0198	 finalize: 0.0033
Accumulated time: update_bounds func: 74.8236	 prepare: 0.6448	 bound: 72.5122	 transfer: 0.0198	 finalize: 0.2802
batch bounding time:  0.920619010925293
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), 
length of domains: 416
Total time: 1.0163	 pickout: 0.0133	 decision: 0.0783	 get_bound: 0.9207	 add_domain: 0.0040
Current lb:-0.002927541732788086
1310 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 89.40630912780762

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 437] [2, 437] [0, 1192] [4, 2418] [3, 3065] [9, 236] [2, 381] [2, 349] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04043612629175186 with beta sum per layer: [0.0, 0.0, 0.029300827533006668, 0.3686670660972595, 0.39275431632995605, 0.0, 0.0, 0.0, 0.0, 0.7013777494430542]
alpha/beta optimization time: 0.8673727512359619
This batch time : update_bounds func: 0.8992	 prepare: 0.0084	 bound: 0.8680	 transfer: 0.0194	 finalize: 0.0032
Accumulated time: update_bounds func: 75.7227	 prepare: 0.6532	 bound: 73.3802	 transfer: 0.0194	 finalize: 0.2834
batch bounding time:  0.8995637893676758
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), 
length of domains: 423
Total time: 0.9922	 pickout: 0.0104	 decision: 0.0781	 get_bound: 0.8996	 add_domain: 0.0042
Current lb:-0.002927541732788086
1326 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 90.39913272857666

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 2341] [4, 2418] [2, 349] [0, 1191] [3, 3063] [4, 2657] [2, 381] [4, 2719] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04664328694343567 with beta sum per layer: [0.0, 0.0, 0.0026032631285488605, 0.04479653760790825, 1.0514432191848755, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.8114235401153564
This batch time : update_bounds func: 0.8430	 prepare: 0.0083	 bound: 0.8121	 transfer: 0.0194	 finalize: 0.0031
Accumulated time: update_bounds func: 76.5657	 prepare: 0.6615	 bound: 74.1923	 transfer: 0.0194	 finalize: 0.2865
batch bounding time:  0.843346118927002
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), 
length of domains: 431
Total time: 0.9379	 pickout: 0.0102	 decision: 0.0799	 get_bound: 0.8435	 add_domain: 0.0043
Current lb:-0.002927541732788086
1342 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 91.33755397796631

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 2719] [0, 1192] [3, 3060] [2, 349] [3, 3060] [3, 3061] [3, 3062] [2, 381] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.046838998794555664 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.7261371612548828
This batch time : update_bounds func: 0.7577	 prepare: 0.0083	 bound: 0.7268	 transfer: 0.0194	 finalize: 0.0032
Accumulated time: update_bounds func: 77.3234	 prepare: 0.6698	 bound: 74.9191	 transfer: 0.0194	 finalize: 0.2897
batch bounding time:  0.7580766677856445
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (156), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), 
length of domains: 439
Total time: 0.8519	 pickout: 0.0105	 decision: 0.0790	 get_bound: 0.7581	 add_domain: 0.0043
Current lb:-0.002927541732788086
1358 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 92.18996334075928

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3061] [0, 1195] [3, 3061] [9, 236] [0, 1195] [3, 3063] [2, 349] [9, 236] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03412056341767311 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.119823694229126]
alpha/beta optimization time: 0.8775012493133545
This batch time : update_bounds func: 0.9092	 prepare: 0.0083	 bound: 0.8782	 transfer: 0.0195	 finalize: 0.0031
Accumulated time: update_bounds func: 78.2326	 prepare: 0.6781	 bound: 75.7972	 transfer: 0.0195	 finalize: 0.2929
batch bounding time:  0.9095580577850342
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), 
length of domains: 445
Total time: 1.0025	 pickout: 0.0102	 decision: 0.0789	 get_bound: 0.9096	 add_domain: 0.0038
Current lb:-0.002927541732788086
1374 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 93.1930251121521

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 349] [9, 236] [9, 236] [3, 3065] [4, 2341] [0, 1192] [3, 3070] [4, 2341] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03330955654382706 with beta sum per layer: [0.0, 0.0, 0.0004659975238610059, 0.22887153923511505, 0.8083467483520508, 0.0, 0.0, 0.0, 0.0, 1.1903396844863892]
alpha/beta optimization time: 0.8702447414398193
This batch time : update_bounds func: 0.9020	 prepare: 0.0084	 bound: 0.8709	 transfer: 0.0193	 finalize: 0.0033
Accumulated time: update_bounds func: 79.1346	 prepare: 0.6865	 bound: 76.6681	 transfer: 0.0193	 finalize: 0.2962
batch bounding time:  0.9024195671081543
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), 
length of domains: 451
Total time: 0.9945	 pickout: 0.0102	 decision: 0.0780	 get_bound: 0.9025	 add_domain: 0.0038
Current lb:-0.002927541732788086
1390 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 94.18814420700073

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 236] [3, 3070] [2, 349] [9, 236] [3, 3064] [3, 3062] [0, 1192] [3, 3064] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03462047874927521 with beta sum per layer: [0.0015141747426241636, 0.0, 0.004926194436848164, 0.2936815917491913, 0.0, 0.0, 0.0, 0.0, 0.0, 1.119823694229126]
alpha/beta optimization time: 0.8694424629211426
This batch time : update_bounds func: 0.9014	 prepare: 0.0083	 bound: 0.8701	 transfer: 0.0195	 finalize: 0.0034
Accumulated time: update_bounds func: 80.0360	 prepare: 0.6948	 bound: 77.5382	 transfer: 0.0195	 finalize: 0.2996
batch bounding time:  0.9018478393554688
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), 
length of domains: 457
Total time: 0.9955	 pickout: 0.0102	 decision: 0.0794	 get_bound: 0.9019	 add_domain: 0.0040
Current lb:-0.002927541732788086
1406 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 95.18427205085754

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3064] [0, 1192] [9, 236] [3, 3061] [4, 2881] [2, 349] [9, 236] [4, 2719] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03419024124741554 with beta sum per layer: [0.0015141747426241636, 0.0, 0.0, 0.0, 0.1019279882311821, 0.0, 0.0, 0.0, 0.0, 1.119823932647705]
alpha/beta optimization time: 0.9437105655670166
This batch time : update_bounds func: 0.9783	 prepare: 0.0085	 bound: 0.9444	 transfer: 0.0206	 finalize: 0.0048
Accumulated time: update_bounds func: 81.0144	 prepare: 0.7033	 bound: 78.4826	 transfer: 0.0206	 finalize: 0.3043
batch bounding time:  0.978792667388916
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (160), [-0.00293,   inf] (160), 
length of domains: 463
Total time: 1.0727	 pickout: 0.0105	 decision: 0.0793	 get_bound: 0.9788	 add_domain: 0.0040
Current lb:-0.002927541732788086
1422 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 96.25756740570068

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3061] [2, 349] [2, 381] [9, 236] [9, 236] [9, 236] [3, 3062] [3, 3063] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.027736734598875046 with beta sum per layer: [0.006159814074635506, 0.0, 0.004926194436848164, 0.07184018939733505, 0.13493937253952026, 0.0, 0.0, 0.0, 0.0, 1.735395908355713]
alpha/beta optimization time: 1.008124828338623
This batch time : update_bounds func: 1.0463	 prepare: 0.0121	 bound: 1.0090	 transfer: 0.0205	 finalize: 0.0046
Accumulated time: update_bounds func: 82.0606	 prepare: 0.7154	 bound: 79.4916	 transfer: 0.0205	 finalize: 0.3089
batch bounding time:  1.046736240386963
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), 
length of domains: 468
Total time: 1.1551	 pickout: 0.0129	 decision: 0.0918	 get_bound: 1.0468	 add_domain: 0.0036
Current lb:-0.002927541732788086
1438 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 97.41333723068237

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3063] [3, 3062] [0, 1192] [3, 3062] [9, 236] [0, 1253] [0, 1195] [3, 3062] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.041191644966602325 with beta sum per layer: [0.016009394079446793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.541358470916748]
alpha/beta optimization time: 0.9568548202514648
This batch time : update_bounds func: 0.9928	 prepare: 0.0119	 bound: 0.9577	 transfer: 0.0199	 finalize: 0.0032
Accumulated time: update_bounds func: 83.0535	 prepare: 0.7273	 bound: 80.4493	 transfer: 0.0199	 finalize: 0.3121
batch bounding time:  0.9932136535644531
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (158), [-0.00293,   inf] (158), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), 
length of domains: 475
Total time: 1.1032	 pickout: 0.0130	 decision: 0.0927	 get_bound: 0.9933	 add_domain: 0.0042
Current lb:-0.002927541732788086
1454 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 98.51712965965271

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 2657] [9, 236] [2, 349] [9, 236] [0, 1253] [9, 236] [4, 2341] [2, 381] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.027076467871665955 with beta sum per layer: [0.0, 0.0, 0.0010273386724293232, 0.04148762300610542, 0.658957839012146, 0.0, 0.0, 0.0, 0.0, 1.7316980361938477]
alpha/beta optimization time: 0.9354832172393799
This batch time : update_bounds func: 0.9677	 prepare: 0.0085	 bound: 0.9362	 transfer: 0.0197	 finalize: 0.0034
Accumulated time: update_bounds func: 84.0212	 prepare: 0.7358	 bound: 81.3855	 transfer: 0.0197	 finalize: 0.3155
batch bounding time:  0.9681763648986816
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), 
length of domains: 480
Total time: 1.0629	 pickout: 0.0109	 decision: 0.0802	 get_bound: 0.9682	 add_domain: 0.0035
Current lb:-0.002927541732788086
1470 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 99.58070206642151

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3065] [0, 1195] [2, 381] [3, 3071] [3, 3071] [4, 2418] [2, 381] [9, 236] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04052671790122986 with beta sum per layer: [0.0, 0.0, 0.0, 1.1555607318878174, 0.4166925847530365, 0.0, 0.0, 0.0, 0.0, 0.541358470916748]
alpha/beta optimization time: 0.9057083129882812
This batch time : update_bounds func: 0.9381	 prepare: 0.0086	 bound: 0.9064	 transfer: 0.0196	 finalize: 0.0034
Accumulated time: update_bounds func: 84.9593	 prepare: 0.7444	 bound: 82.2919	 transfer: 0.0196	 finalize: 0.3189
batch bounding time:  0.9385716915130615
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), 
length of domains: 487
Total time: 1.0332	 pickout: 0.0105	 decision: 0.0799	 get_bound: 0.9386	 add_domain: 0.0042
Current lb:-0.002927541732788086
1486 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 100.6145372390747

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3070] [2, 381] [0, 1195] [2, 349] [0, 1192] [2, 349] [3, 3062] [2, 349] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04678142070770264 with beta sum per layer: [0.0, 0.0, 0.012410624884068966, 0.06543852388858795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.8123342990875244
This batch time : update_bounds func: 0.8442	 prepare: 0.0084	 bound: 0.8130	 transfer: 0.0195	 finalize: 0.0032
Accumulated time: update_bounds func: 85.8036	 prepare: 0.7528	 bound: 83.1049	 transfer: 0.0195	 finalize: 0.3221
batch bounding time:  0.8446993827819824
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), 
length of domains: 495
Total time: 0.9418	 pickout: 0.0106	 decision: 0.0809	 get_bound: 0.8448	 add_domain: 0.0056
Current lb:-0.002927541732788086
1502 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 101.55693936347961

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 349] [9, 236] [2, 349] [2, 381] [3, 3062] [4, 2881] [2, 381] [4, 2977] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04038628563284874 with beta sum per layer: [0.0, 0.0, 0.012410624884068966, 0.2029794156551361, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5784652829170227]
alpha/beta optimization time: 0.8774759769439697
This batch time : update_bounds func: 0.9094	 prepare: 0.0085	 bound: 0.8782	 transfer: 0.0194	 finalize: 0.0032
Accumulated time: update_bounds func: 86.7129	 prepare: 0.7612	 bound: 83.9830	 transfer: 0.0194	 finalize: 0.3253
batch bounding time:  0.9097552299499512
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), 
length of domains: 502
Total time: 1.0037	 pickout: 0.0105	 decision: 0.0793	 get_bound: 0.9098	 add_domain: 0.0041
Current lb:-0.002927541732788086
1518 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 102.56128239631653

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 236] [9, 236] [9, 236] [3, 3062] [9, 236] [0, 1192] [4, 2881] [4, 2719] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.02174832485616207 with beta sum per layer: [0.0060566989704966545, 0.0, 0.0, 0.10770602524280548, 0.5133256912231445, 0.0, 0.0, 0.0, 0.0, 2.3138608932495117]
alpha/beta optimization time: 0.9167196750640869
This batch time : update_bounds func: 0.9487	 prepare: 0.0084	 bound: 0.9174	 transfer: 0.0195	 finalize: 0.0033
Accumulated time: update_bounds func: 87.6616	 prepare: 0.7696	 bound: 84.9004	 transfer: 0.0195	 finalize: 0.3286
batch bounding time:  0.9490766525268555
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (162), [-0.00293,   inf] (162), 
length of domains: 506
Total time: 1.0419	 pickout: 0.0106	 decision: 0.0789	 get_bound: 0.9491	 add_domain: 0.0033
Current lb:-0.002927541732788086
1534 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 103.60379910469055

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 349] [9, 236] [2, 381] [9, 236] [3, 3064] [9, 236] [0, 1192] [2, 437] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.02901364117860794 with beta sum per layer: [0.00015788388554938138, 0.0, 0.01218731701374054, 0.18874815106391907, 0.0, 0.0, 0.0, 0.0, 0.0, 1.7040849924087524]
alpha/beta optimization time: 0.8805935382843018
This batch time : update_bounds func: 0.9124	 prepare: 0.0084	 bound: 0.8812	 transfer: 0.0194	 finalize: 0.0033
Accumulated time: update_bounds func: 88.5740	 prepare: 0.7780	 bound: 85.7817	 transfer: 0.0194	 finalize: 0.3319
batch bounding time:  0.9127459526062012
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), 
length of domains: 511
Total time: 1.0059	 pickout: 0.0104	 decision: 0.0792	 get_bound: 0.9128	 add_domain: 0.0035
Current lb:-0.002927541732788086
1550 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 104.61028170585632

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 236] [9, 236] [3, 3063] [9, 236] [4, 2657] [0, 1253] [0, 1253] [9, 236] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.022798698395490646 with beta sum per layer: [0.0, 0.0, 0.0, 0.09676039963960648, 0.27172231674194336, 0.0, 0.0, 0.0, 0.0, 2.165433883666992]
alpha/beta optimization time: 0.8805921077728271
This batch time : update_bounds func: 0.9123	 prepare: 0.0083	 bound: 0.8812	 transfer: 0.0193	 finalize: 0.0034
Accumulated time: update_bounds func: 89.4862	 prepare: 0.7863	 bound: 86.6629	 transfer: 0.0193	 finalize: 0.3353
batch bounding time:  0.9127628803253174
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (160), [-0.00293,   inf] (160), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), 
length of domains: 515
Total time: 1.0055	 pickout: 0.0102	 decision: 0.0791	 get_bound: 0.9128	 add_domain: 0.0034
Current lb:-0.002927541732788086
1566 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 105.61645650863647

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 236] [0, 1253] [9, 236] [2, 381] [2, 381] [9, 236] [9, 236] [2, 381] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.022908074781298637 with beta sum per layer: [0.0, 0.0, 0.0004659975238610059, 0.3410049080848694, 0.0, 0.0, 0.0, 0.0, 0.0, 2.235949754714966]
alpha/beta optimization time: 0.8737871646881104
This batch time : update_bounds func: 0.9054	 prepare: 0.0083	 bound: 0.8744	 transfer: 0.0193	 finalize: 0.0032
Accumulated time: update_bounds func: 90.3916	 prepare: 0.7946	 bound: 87.5373	 transfer: 0.0193	 finalize: 0.3385
batch bounding time:  0.9057731628417969
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), 
length of domains: 519
Total time: 0.9994	 pickout: 0.0106	 decision: 0.0797	 get_bound: 0.9058	 add_domain: 0.0033
Current lb:-0.002927541732788086
1582 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 106.61651396751404

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 381] [3, 3064] [0, 1253] [9, 236] [2, 349] [2, 349] [3, 15168] [9, 236] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03485015407204628 with beta sum per layer: [0.00031576777109876275, 0.0, 0.009852388873696327, 1.3619716167449951, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0827170610427856]
alpha/beta optimization time: 0.9162063598632812
This batch time : update_bounds func: 1.0218	 prepare: 0.0084	 bound: 0.9169	 transfer: 0.0193	 finalize: 0.0771
Accumulated time: update_bounds func: 91.4134	 prepare: 0.8030	 bound: 88.4542	 transfer: 0.0193	 finalize: 0.4156
batch bounding time:  1.022233486175537
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), 
length of domains: 525
Total time: 1.1158	 pickout: 0.0103	 decision: 0.0793	 get_bound: 1.0224	 add_domain: 0.0038
Current lb:-0.002927541732788086
1598 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 107.7329306602478

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3071] [2, 381] [3, 3071] [9, 236] [2, 381] [3, 3065] [0, 1192] [9, 236] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03397694602608681 with beta sum per layer: [0.0015141747426241636, 0.0, 0.0, 0.7189844846725464, 0.0, 0.0, 0.0, 0.0, 0.0, 1.156930685043335]
alpha/beta optimization time: 0.9046540260314941
This batch time : update_bounds func: 0.9393	 prepare: 0.0084	 bound: 0.9054	 transfer: 0.0214	 finalize: 0.0040
Accumulated time: update_bounds func: 92.3527	 prepare: 0.8114	 bound: 89.3596	 transfer: 0.0214	 finalize: 0.4196
batch bounding time:  0.9399006366729736
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), 
length of domains: 531
Total time: 1.0342	 pickout: 0.0103	 decision: 0.0795	 get_bound: 0.9399	 add_domain: 0.0044
Current lb:-0.002927541732788086
1614 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 108.76949644088745

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 2719] [3, 3062] [3, 3063] [4, 2719] [2, 381] [9, 236] [9, 236] [4, 2715] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03355947136878967 with beta sum per layer: [0.0032142263371497393, 0.0, 0.0, 0.0, 0.8430801033973694, 0.0, 0.0, 0.0, 0.0, 1.1569304466247559]
alpha/beta optimization time: 0.924170970916748
This batch time : update_bounds func: 0.9608	 prepare: 0.0121	 bound: 0.9250	 transfer: 0.0202	 finalize: 0.0034
Accumulated time: update_bounds func: 93.3135	 prepare: 0.8235	 bound: 90.2846	 transfer: 0.0202	 finalize: 0.4230
batch bounding time:  0.9613246917724609
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), 
length of domains: 537
Total time: 1.0723	 pickout: 0.0135	 decision: 0.0931	 get_bound: 0.9614	 add_domain: 0.0043
Current lb:-0.002927541732788086
1630 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 109.84257173538208

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [0, 1195] [0, 1195] [3, 3062] [4, 2977] [4, 2881] [4, 2978] [3, 3061] [4, 2881] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04684257507324219 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.7444736957550049
This batch time : update_bounds func: 0.7761	 prepare: 0.0083	 bound: 0.7451	 transfer: 0.0194	 finalize: 0.0032
Accumulated time: update_bounds func: 94.0896	 prepare: 0.8318	 bound: 91.0298	 transfer: 0.0194	 finalize: 0.4262
batch bounding time:  0.7765393257141113
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (164), 
length of domains: 545
Total time: 0.8768	 pickout: 0.0139	 decision: 0.0820	 get_bound: 0.7766	 add_domain: 0.0043
Current lb:-0.002927541732788086
1646 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 110.72014594078064

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 349] [0, 1192] [3, 3060] [0, 1192] [3, 3063] [3, 3064] [9, 236] [4, 2657] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04085550829768181 with beta sum per layer: [0.0, 0.0, 0.0, 0.24738039076328278, 0.27172231674194336, 0.0, 0.0, 0.0, 0.0, 0.541358470916748]
alpha/beta optimization time: 0.8823752403259277
This batch time : update_bounds func: 0.9159	 prepare: 0.0086	 bound: 0.8830	 transfer: 0.0195	 finalize: 0.0046
Accumulated time: update_bounds func: 95.0055	 prepare: 0.8404	 bound: 91.9128	 transfer: 0.0195	 finalize: 0.4308
batch bounding time:  0.9163272380828857
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), 
length of domains: 552
Total time: 1.0132	 pickout: 0.0136	 decision: 0.0790	 get_bound: 0.9164	 add_domain: 0.0041
Current lb:-0.002927541732788086
1662 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 111.73392581939697

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [0, 1195] [0, 1195] [2, 437] [4, 2657] [3, 3061] [4, 2657] [0, 1259] [2, 381] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04662179946899414 with beta sum per layer: [0.0017133319051936269, 0.0, 0.01218731701374054, 0.006986850872635841, 0.5434446334838867, 0.0, 0.0, 0.0, 0.0, 0.08000954985618591]
alpha/beta optimization time: 0.7780609130859375
This batch time : update_bounds func: 0.8133	 prepare: 0.0101	 bound: 0.7787	 transfer: 0.0210	 finalize: 0.0034
Accumulated time: update_bounds func: 95.8188	 prepare: 0.8505	 bound: 92.6915	 transfer: 0.0210	 finalize: 0.4342
batch bounding time:  0.8138384819030762
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (162), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), 
length of domains: 560
Total time: 0.9118	 pickout: 0.0138	 decision: 0.0797	 get_bound: 0.8139	 add_domain: 0.0045
Current lb:-0.002927541732788086
1678 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 112.64648985862732

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [0, 1259] [9, 236] [0, 1259] [4, 2427] [9, 236] [0, 1195] [3, 3070] [3, 3065] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03429827466607094 with beta sum per layer: [0.016009394079446793, 0.0, 0.0004659975238610059, 0.011560818180441856, 0.3363282382488251, 0.0, 0.0, 0.0, 0.0, 1.1532328128814697]
alpha/beta optimization time: 0.9341962337493896
This batch time : update_bounds func: 0.9757	 prepare: 0.0086	 bound: 0.9350	 transfer: 0.0255	 finalize: 0.0065
Accumulated time: update_bounds func: 96.7945	 prepare: 0.8591	 bound: 93.6265	 transfer: 0.0255	 finalize: 0.4406
batch bounding time:  0.9764442443847656
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), 
length of domains: 566
Total time: 1.0779	 pickout: 0.0136	 decision: 0.0803	 get_bound: 0.9765	 add_domain: 0.0075
Current lb:-0.002927541732788086
1694 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 113.72530388832092

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3065] [3, 3064] [0, 1259] [2, 381] [0, 1195] [4, 2341] [9, 236] [3, 15168] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.040840961039066315 with beta sum per layer: [0.0, 0.0, 0.0, 0.9231572151184082, 0.4041733741760254, 0.0, 0.0, 0.0, 0.0, 0.5413585901260376]
alpha/beta optimization time: 0.9092683792114258
This batch time : update_bounds func: 0.9463	 prepare: 0.0134	 bound: 0.9101	 transfer: 0.0194	 finalize: 0.0033
Accumulated time: update_bounds func: 97.7408	 prepare: 0.8725	 bound: 94.5367	 transfer: 0.0194	 finalize: 0.4439
batch bounding time:  0.9467511177062988
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), 
length of domains: 573
Total time: 1.0624	 pickout: 0.0179	 decision: 0.0935	 get_bound: 0.9468	 add_domain: 0.0043
Current lb:-0.002927541732788086
1710 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 114.78841590881348

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 236] [4, 2418] [3, 15168] [2, 437] [9, 236] [0, 1253] [3, 3063] [9, 236] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.027986997738480568 with beta sum per layer: [0.0037214942276477814, 0.0, 0.01218731701374054, 0.4266332685947418, 0.39275431632995605, 0.0, 0.0, 0.0, 0.0, 1.7782987356185913]
alpha/beta optimization time: 0.8802690505981445
This batch time : update_bounds func: 0.9142	 prepare: 0.0087	 bound: 0.8809	 transfer: 0.0197	 finalize: 0.0048
Accumulated time: update_bounds func: 98.6550	 prepare: 0.8812	 bound: 95.4176	 transfer: 0.0197	 finalize: 0.4488
batch bounding time:  0.91461181640625
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), 
length of domains: 578
Total time: 1.0244	 pickout: 0.0243	 decision: 0.0818	 get_bound: 0.9147	 add_domain: 0.0037
Current lb:-0.002927541732788086
1726 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 115.81356000900269

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 349] [4, 2719] [2, 381] [9, 236] [0, 1195] [2, 349] [3, 3065] [4, 2719] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.040212325751781464 with beta sum per layer: [0.0, 0.0, 0.005206526257097721, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5784652829170227]
alpha/beta optimization time: 0.8792612552642822
This batch time : update_bounds func: 0.9114	 prepare: 0.0086	 bound: 0.8799	 transfer: 0.0195	 finalize: 0.0033
Accumulated time: update_bounds func: 99.5664	 prepare: 0.8897	 bound: 96.2975	 transfer: 0.0195	 finalize: 0.4521
batch bounding time:  0.9118528366088867
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), 
length of domains: 585
Total time: 1.0088	 pickout: 0.0136	 decision: 0.0791	 get_bound: 0.9119	 add_domain: 0.0042
Current lb:-0.002927541732788086
1742 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 116.82296848297119

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 381] [3, 3063] [2, 381] [9, 236] [0, 1191] [9, 236] [9, 236] [3, 3062] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.027961069718003273 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.08149515092372894, 0.0, 0.0, 0.0, 0.0, 1.6611825227737427]
alpha/beta optimization time: 0.8817236423492432
This batch time : update_bounds func: 0.9137	 prepare: 0.0084	 bound: 0.8824	 transfer: 0.0195	 finalize: 0.0033
Accumulated time: update_bounds func: 100.4801	 prepare: 0.8981	 bound: 97.1800	 transfer: 0.0195	 finalize: 0.4554
batch bounding time:  0.9141805171966553
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), 
length of domains: 590
Total time: 1.0102	 pickout: 0.0133	 decision: 0.0790	 get_bound: 0.9142	 add_domain: 0.0036
Current lb:-0.002927541732788086
1758 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 117.83383560180664

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 2977] [4, 2977] [2, 349] [4, 2984] [2, 349] [9, 236] [4, 2977] [9, 236] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03439716622233391 with beta sum per layer: [0.017297564074397087, 0.0, 0.009852388873696327, 0.09710973501205444, 1.08211088180542, 0.0, 0.0, 0.0, 0.0, 1.1569305658340454]
alpha/beta optimization time: 0.8860569000244141
This batch time : update_bounds func: 0.9163	 prepare: 0.0083	 bound: 0.8868	 transfer: 0.0178	 finalize: 0.0033
Accumulated time: update_bounds func: 101.3963	 prepare: 0.9064	 bound: 98.0667	 transfer: 0.0178	 finalize: 0.4587
batch bounding time:  0.9167392253875732
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), 
length of domains: 596
Total time: 1.0121	 pickout: 0.0120	 decision: 0.0793	 get_bound: 0.9168	 add_domain: 0.0040
Current lb:-0.002927541732788086
1774 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 118.84656548500061

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3063] [0, 1195] [0, 1195] [0, 1192] [0, 1192] [2, 349] [3, 3063] [4, 2719] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04684042930603027 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.7322463989257812
This batch time : update_bounds func: 0.7541	 prepare: 0.0083	 bound: 0.7329	 transfer: 0.0096	 finalize: 0.0032
Accumulated time: update_bounds func: 102.1504	 prepare: 0.9147	 bound: 98.7996	 transfer: 0.0096	 finalize: 0.4619
batch bounding time:  0.7545022964477539
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (166), 
length of domains: 604
Total time: 0.8501	 pickout: 0.0122	 decision: 0.0790	 get_bound: 0.7545	 add_domain: 0.0044
Current lb:-0.002927541732788086
1790 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 119.69725251197815

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 236] [0, 1192] [3, 3065] [2, 381] [3, 3063] [3, 3063] [2, 437] [9, 236] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03441094607114792 with beta sum per layer: [0.0, 0.0, 0.010189258493483067, 0.5644750595092773, 0.0, 0.0, 0.0, 0.0, 0.0, 1.207085132598877]
alpha/beta optimization time: 0.8909268379211426
This batch time : update_bounds func: 0.9235	 prepare: 0.0084	 bound: 0.8916	 transfer: 0.0202	 finalize: 0.0032
Accumulated time: update_bounds func: 103.0739	 prepare: 0.9231	 bound: 99.6912	 transfer: 0.0202	 finalize: 0.4651
batch bounding time:  0.9239273071289062
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), 
length of domains: 610
Total time: 1.0204	 pickout: 0.0133	 decision: 0.0789	 get_bound: 0.9240	 add_domain: 0.0041
Current lb:-0.002927541732788086
1806 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 120.71834373474121

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 236] [2, 381] [4, 2715] [9, 236] [2, 381] [4, 2657] [4, 2657] [3, 3062] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03487662598490715 with beta sum per layer: [0.01614980213344097, 0.0, 0.0005613411776721478, 0.02881907857954502, 1.1247023344039917, 0.0, 0.0, 0.0, 0.0, 1.082716941833496]
alpha/beta optimization time: 0.9022932052612305
This batch time : update_bounds func: 0.9347	 prepare: 0.0085	 bound: 0.9030	 transfer: 0.0196	 finalize: 0.0034
Accumulated time: update_bounds func: 104.0086	 prepare: 0.9317	 bound: 100.5942	 transfer: 0.0196	 finalize: 0.4686
batch bounding time:  0.935171365737915
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (164), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), 
length of domains: 616
Total time: 1.0313	 pickout: 0.0134	 decision: 0.0786	 get_bound: 0.9352	 add_domain: 0.0040
Current lb:-0.002927541732788086
1822 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 121.75040650367737

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [0, 1285] [0, 1285] [9, 236] [4, 2657] [0, 1253] [9, 236] [0, 1195] [3, 3071] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03523546829819679 with beta sum per layer: [0.0, 0.0, 0.0, 0.23515522480010986, 0.18893247842788696, 0.0, 0.0, 0.0, 0.0, 1.0827245712280273]
alpha/beta optimization time: 0.8905148506164551
This batch time : update_bounds func: 0.9237	 prepare: 0.0085	 bound: 0.8912	 transfer: 0.0207	 finalize: 0.0033
Accumulated time: update_bounds func: 104.9323	 prepare: 0.9402	 bound: 101.4854	 transfer: 0.0207	 finalize: 0.4719
batch bounding time:  0.9241182804107666
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), 
length of domains: 622
Total time: 1.0208	 pickout: 0.0137	 decision: 0.0790	 get_bound: 0.9242	 add_domain: 0.0039
Current lb:-0.002927541732788086
1838 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 122.77181887626648

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 236] [0, 1253] [4, 2427] [2, 381] [3, 3065] [0, 1259] [9, 236] [0, 1285] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.0357603020966053 with beta sum per layer: [0.016009394079446793, 0.0, 0.0, 0.3432196378707886, 0.571999192237854, 0.0, 0.0, 0.0, 0.0, 1.082716941833496]
alpha/beta optimization time: 0.8839800357818604
This batch time : update_bounds func: 0.9172	 prepare: 0.0085	 bound: 0.8846	 transfer: 0.0206	 finalize: 0.0033
Accumulated time: update_bounds func: 105.8495	 prepare: 0.9487	 bound: 102.3700	 transfer: 0.0206	 finalize: 0.4752
batch bounding time:  0.9176125526428223
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), 
length of domains: 628
Total time: 1.0138	 pickout: 0.0135	 decision: 0.0786	 get_bound: 0.9177	 add_domain: 0.0040
Current lb:-0.002927541732788086
1854 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 123.78631663322449

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 15168] [2, 381] [4, 2341] [2, 349] [9, 236] [2, 437] [2, 381] [4, 2418] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04033118113875389 with beta sum per layer: [0.00015788388554938138, 0.0, 0.01711351051926613, 1.2371270656585693, 0.7969276905059814, 0.0, 0.0, 0.0, 0.0, 0.6213680505752563]
alpha/beta optimization time: 0.8789935111999512
This batch time : update_bounds func: 0.9115	 prepare: 0.0083	 bound: 0.8796	 transfer: 0.0201	 finalize: 0.0033
Accumulated time: update_bounds func: 106.7610	 prepare: 0.9570	 bound: 103.2496	 transfer: 0.0201	 finalize: 0.4785
batch bounding time:  0.9118862152099609
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), 
length of domains: 635
Total time: 1.0091	 pickout: 0.0138	 decision: 0.0791	 get_bound: 0.9119	 add_domain: 0.0043
Current lb:-0.002927541732788086
1870 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 124.79605650901794

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 381] [3, 3070] [3, 3070] [3, 3064] [9, 236] [9, 236] [2, 381] [0, 1195] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03371718153357506 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.156930685043335]
alpha/beta optimization time: 0.8694980144500732
This batch time : update_bounds func: 0.9020	 prepare: 0.0083	 bound: 0.8702	 transfer: 0.0201	 finalize: 0.0033
Accumulated time: update_bounds func: 107.6630	 prepare: 0.9654	 bound: 104.1198	 transfer: 0.0201	 finalize: 0.4818
batch bounding time:  0.9024631977081299
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), 
length of domains: 641
Total time: 1.0014	 pickout: 0.0154	 decision: 0.0795	 get_bound: 0.9025	 add_domain: 0.0039
Current lb:-0.002927541732788086
1886 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 125.7980728149414

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 437] [0, 1253] [9, 236] [3, 3063] [4, 2657] [2, 437] [2, 437] [3, 3062] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03999560326337814 with beta sum per layer: [0.006497239228338003, 0.0, 0.03256583213806152, 0.136793315410614, 0.37405622005462646, 0.0, 0.0, 0.0, 0.0, 0.8329976797103882]
alpha/beta optimization time: 0.9071898460388184
This batch time : update_bounds func: 0.9399	 prepare: 0.0085	 bound: 0.9078	 transfer: 0.0201	 finalize: 0.0034
Accumulated time: update_bounds func: 108.6029	 prepare: 0.9739	 bound: 105.0276	 transfer: 0.0201	 finalize: 0.4852
batch bounding time:  0.9403741359710693
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), 
length of domains: 648
Total time: 1.0379	 pickout: 0.0132	 decision: 0.0800	 get_bound: 0.9404	 add_domain: 0.0042
Current lb:-0.002927541732788086
1902 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 126.83674693107605

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3063] [4, 2715] [4, 2715] [4, 2715] [3, 3063] [4, 2977] [0, 1191] [2, 381] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04645645618438721 with beta sum per layer: [0.0006201894138939679, 0.0, 0.0016840235330164433, 0.01952887885272503, 1.6819872856140137, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.764047384262085
This batch time : update_bounds func: 0.7960	 prepare: 0.0082	 bound: 0.7647	 transfer: 0.0197	 finalize: 0.0032
Accumulated time: update_bounds func: 109.3988	 prepare: 0.9821	 bound: 105.7923	 transfer: 0.0197	 finalize: 0.4884
batch bounding time:  0.7964017391204834
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), 
length of domains: 656
Total time: 0.8928	 pickout: 0.0136	 decision: 0.0783	 get_bound: 0.7964	 add_domain: 0.0044
Current lb:-0.002927541732788086
1918 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 127.73012399673462

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3062] [2, 437] [2, 437] [0, 1191] [9, 236] [2, 349] [0, 1192] [0, 1192] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04029059037566185 with beta sum per layer: [0.007673989050090313, 0.0, 0.029300827533006668, 0.046078961342573166, 0.4016548991203308, 0.0, 0.0, 0.0, 0.0, 0.7384843230247498]
alpha/beta optimization time: 0.8710293769836426
This batch time : update_bounds func: 0.9026	 prepare: 0.0084	 bound: 0.8717	 transfer: 0.0194	 finalize: 0.0031
Accumulated time: update_bounds func: 110.3015	 prepare: 0.9905	 bound: 106.6640	 transfer: 0.0194	 finalize: 0.4915
batch bounding time:  0.9030647277832031
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), 
length of domains: 663
Total time: 0.9999	 pickout: 0.0134	 decision: 0.0793	 get_bound: 0.9031	 add_domain: 0.0042
Current lb:-0.002927541732788086
1934 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 128.73060584068298

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3063] [9, 236] [3, 3064] [3, 3060] [9, 236] [3, 3060] [0, 1253] [0, 1195] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.034241802990436554 with beta sum per layer: [0.005530191585421562, 0.0, 0.0, 0.045890431851148605, 0.1291782557964325, 0.0, 0.0, 0.0, 0.0, 1.1569304466247559]
alpha/beta optimization time: 0.8571999073028564
This batch time : update_bounds func: 0.8886	 prepare: 0.0081	 bound: 0.8578	 transfer: 0.0194	 finalize: 0.0032
Accumulated time: update_bounds func: 111.1901	 prepare: 0.9986	 bound: 107.5219	 transfer: 0.0194	 finalize: 0.4947
batch bounding time:  0.8890149593353271
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), 
length of domains: 669
Total time: 0.9846	 pickout: 0.0133	 decision: 0.0783	 get_bound: 0.8891	 add_domain: 0.0039
Current lb:-0.002927541732788086
1950 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 129.71580147743225

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 437] [4, 2977] [0, 1195] [2, 381] [9, 236] [4, 2881] [0, 1192] [3, 3064] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04049515724182129 with beta sum per layer: [0.0, 0.0, 0.006119033321738243, 0.08225058019161224, 0.2922925651073456, 0.0, 0.0, 0.0, 0.0, 0.6666827201843262]
alpha/beta optimization time: 0.8647739887237549
This batch time : update_bounds func: 0.8969	 prepare: 0.0087	 bound: 0.8655	 transfer: 0.0194	 finalize: 0.0033
Accumulated time: update_bounds func: 112.0870	 prepare: 1.0073	 bound: 108.3873	 transfer: 0.0194	 finalize: 0.4980
batch bounding time:  0.8973779678344727
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (168), 
length of domains: 676
Total time: 0.9964	 pickout: 0.0132	 decision: 0.0816	 get_bound: 0.8974	 add_domain: 0.0042
Current lb:-0.002927541732788086
1966 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 130.71285486221313

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [3, 3065] [9, 236] [0, 1192] [3, 3065] [3, 3064] [2, 437] [3, 3064] [2, 437] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.040790148079395294 with beta sum per layer: [0.0, 0.0, 0.02237657457590103, 0.6795761585235596, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7086294889450073]
alpha/beta optimization time: 0.8717617988586426
This batch time : update_bounds func: 0.9063	 prepare: 0.0104	 bound: 0.8724	 transfer: 0.0201	 finalize: 0.0034
Accumulated time: update_bounds func: 112.9933	 prepare: 1.0176	 bound: 109.2598	 transfer: 0.0201	 finalize: 0.5013
batch bounding time:  0.9067764282226562
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), 
length of domains: 683
Total time: 1.0032	 pickout: 0.0134	 decision: 0.0785	 get_bound: 0.9068	 add_domain: 0.0044
Current lb:-0.002927541732788086
1982 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 131.71690130233765

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 236] [4, 2719] [4, 2657] [2, 381] [2, 437] [2, 381] [0, 1285] [9, 236] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03430026024580002 with beta sum per layer: [0.00014040879614185542, 0.0, 0.012748658657073975, 0.0021898390259593725, 0.3897238075733185, 0.0, 0.0, 0.0, 0.0, 1.1627341508865356]
alpha/beta optimization time: 0.8685324192047119
This batch time : update_bounds func: 0.9004	 prepare: 0.0085	 bound: 0.8692	 transfer: 0.0194	 finalize: 0.0032
Accumulated time: update_bounds func: 113.8938	 prepare: 1.0261	 bound: 110.1290	 transfer: 0.0194	 finalize: 0.5046
batch bounding time:  0.900841474533081
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (166), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), 
length of domains: 689
Total time: 0.9975	 pickout: 0.0138	 decision: 0.0788	 get_bound: 0.9009	 add_domain: 0.0040
Current lb:-0.002927541732788086
1998 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 132.71502804756165

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 2657] [3, 3061] [3, 3061] [4, 2715] [4, 2418] [4, 2418] [0, 1253] [3, 3071] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.046402134001255035 with beta sum per layer: [0.0011211213422939181, 0.0, 0.0, 0.5822576284408569, 1.4810503721237183, 0.0, 0.0, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.7994070053100586
This batch time : update_bounds func: 0.8310	 prepare: 0.0083	 bound: 0.8001	 transfer: 0.0194	 finalize: 0.0032
Accumulated time: update_bounds func: 114.7248	 prepare: 1.0344	 bound: 110.9291	 transfer: 0.0194	 finalize: 0.5077
batch bounding time:  0.8313915729522705
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), 
length of domains: 697
Total time: 0.9290	 pickout: 0.0141	 decision: 0.0790	 get_bound: 0.8314	 add_domain: 0.0045
Current lb:-0.002927541732788086
2014 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 133.64458465576172

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 437] [9, 236] [2, 381] [4, 2427] [9, 236] [0, 1253] [9, 236] [9, 236] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.024681484326720238 with beta sum per layer: [0.016009394079446793, 0.0, 0.01218731701374054, 0.6462408304214478, 0.571999192237854, 0.0, 0.0, 0.0, 0.0, 2.245443344116211]
alpha/beta optimization time: 0.8698892593383789
This batch time : update_bounds func: 0.9016	 prepare: 0.0084	 bound: 0.8705	 transfer: 0.0194	 finalize: 0.0032
Accumulated time: update_bounds func: 115.6264	 prepare: 1.0428	 bound: 111.7996	 transfer: 0.0194	 finalize: 0.5109
batch bounding time:  0.9020617008209229
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), 
length of domains: 701
Total time: 0.9979	 pickout: 0.0138	 decision: 0.0785	 get_bound: 0.9021	 add_domain: 0.0034
Current lb:-0.002927541732788086
2030 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 134.64315509796143

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 236] [4, 2427] [2, 381] [3, 3064] [0, 1195] [0, 1195] [2, 437] [9, 236] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.034751731902360916 with beta sum per layer: [0.001730807009153068, 0.0, 0.01218731701374054, 1.027348518371582, 0.5017492771148682, 0.0, 0.0, 0.0, 0.0, 1.1627265214920044]
alpha/beta optimization time: 0.8608372211456299
This batch time : update_bounds func: 0.8940	 prepare: 0.0085	 bound: 0.8615	 transfer: 0.0207	 finalize: 0.0032
Accumulated time: update_bounds func: 116.5204	 prepare: 1.0513	 bound: 112.6611	 transfer: 0.0207	 finalize: 0.5141
batch bounding time:  0.8943803310394287
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), 
length of domains: 707
Total time: 0.9907	 pickout: 0.0137	 decision: 0.0786	 get_bound: 0.8944	 add_domain: 0.0039
Current lb:-0.002927541732788086
2046 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 135.63444900512695

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 2418] [3, 15168] [2, 381] [0, 1192] [3, 3071] [9, 236] [9, 236] [2, 381] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.033740293234586716 with beta sum per layer: [0.003968492150306702, 0.0, 0.0, 1.0543949604034424, 0.4166925847530365, 0.0, 0.0, 0.0, 0.0, 1.156930685043335]
alpha/beta optimization time: 0.942859411239624
This batch time : update_bounds func: 0.9767	 prepare: 0.0086	 bound: 0.9435	 transfer: 0.0200	 finalize: 0.0044
Accumulated time: update_bounds func: 117.4971	 prepare: 1.0599	 bound: 113.6046	 transfer: 0.0200	 finalize: 0.5186
batch bounding time:  0.9770801067352295
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), 
length of domains: 713
Total time: 1.0758	 pickout: 0.0141	 decision: 0.0806	 get_bound: 0.9771	 add_domain: 0.0039
Current lb:-0.002927541732788086
2062 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 136.71106338500977

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 236] [2, 381] [4, 2881] [2, 381] [4, 2881] [9, 236] [0, 1259] [0, 1195] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.033716507256031036 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.156930685043335]
alpha/beta optimization time: 0.8580901622772217
This batch time : update_bounds func: 0.8903	 prepare: 0.0083	 bound: 0.8587	 transfer: 0.0197	 finalize: 0.0034
Accumulated time: update_bounds func: 118.3874	 prepare: 1.0683	 bound: 114.4634	 transfer: 0.0197	 finalize: 0.5220
batch bounding time:  0.8907535076141357
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), 
length of domains: 719
Total time: 0.9867	 pickout: 0.0137	 decision: 0.0782	 get_bound: 0.8908	 add_domain: 0.0040
Current lb:-0.002927541732788086
2078 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 137.69843745231628

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 381] [9, 236] [4, 2881] [2, 437] [9, 236] [3, 3064] [3, 3064] [3, 3064] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.033689893782138824 with beta sum per layer: [0.001321163959801197, 0.0, 0.010189258493483067, 0.14297449588775635, 0.0, 0.0, 0.0, 0.0, 0.0, 1.2441918849945068]
alpha/beta optimization time: 0.8876368999481201
This batch time : update_bounds func: 0.9219	 prepare: 0.0085	 bound: 0.8883	 transfer: 0.0203	 finalize: 0.0047
Accumulated time: update_bounds func: 119.3093	 prepare: 1.0767	 bound: 115.3517	 transfer: 0.0203	 finalize: 0.5267
batch bounding time:  0.92238450050354
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), 
length of domains: 725
Total time: 1.0195	 pickout: 0.0139	 decision: 0.0790	 get_bound: 0.9224	 add_domain: 0.0042
Current lb:-0.002927541732788086
2094 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 138.71868181228638

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 2719] [9, 236] [4, 2977] [2, 381] [2, 381] [2, 381] [3, 3063] [2, 437] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.04051102325320244 with beta sum per layer: [0.0, 0.0, 0.01218731701374054, 0.0, 0.043397821485996246, 0.0, 0.0, 0.0, 0.0, 0.6213681697845459]
alpha/beta optimization time: 0.9674046039581299
This batch time : update_bounds func: 1.0048	 prepare: 0.0121	 bound: 0.9682	 transfer: 0.0211	 finalize: 0.0033
Accumulated time: update_bounds func: 120.3141	 prepare: 1.0888	 bound: 116.3199	 transfer: 0.0211	 finalize: 0.5300
batch bounding time:  1.00534987449646
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), 
length of domains: 732
Total time: 1.1181	 pickout: 0.0161	 decision: 0.0923	 get_bound: 1.0054	 add_domain: 0.0043
Current lb:-0.002927541732788086
2110 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 139.8374080657959

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [0, 1191] [0, 1191] [2, 437] [2, 437] [3, 3061] [9, 236] [0, 1195] [9, 236] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.034174513071775436 with beta sum per layer: [0.005530191585421562, 0.0, 0.02437463402748108, 0.07183544337749481, 0.2774334251880646, 0.0, 0.0, 0.0, 0.0, 1.3169496059417725]
alpha/beta optimization time: 0.8976655006408691
This batch time : update_bounds func: 0.9307	 prepare: 0.0085	 bound: 0.8983	 transfer: 0.0195	 finalize: 0.0044
Accumulated time: update_bounds func: 121.2449	 prepare: 1.0973	 bound: 117.2183	 transfer: 0.0195	 finalize: 0.5344
batch bounding time:  0.9311671257019043
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), 
length of domains: 738
Total time: 1.0535	 pickout: 0.0179	 decision: 0.1004	 get_bound: 0.9312	 add_domain: 0.0039
Current lb:-0.002927541732788086
2126 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 140.89148235321045

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [4, 2978] [2, 349] [9, 236] [3, 3065] [2, 381] [9, 236] [0, 1253] [4, 2977] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.03372252732515335 with beta sum per layer: [0.007673989050090313, 0.0, 0.005392191931605339, 0.045896977186203, 0.2850527763366699, 0.0, 0.0, 0.0, 0.0, 1.1903395652770996]
alpha/beta optimization time: 0.8629677295684814
This batch time : update_bounds func: 0.8947	 prepare: 0.0084	 bound: 0.8636	 transfer: 0.0194	 finalize: 0.0032
Accumulated time: update_bounds func: 122.1395	 prepare: 1.1057	 bound: 118.0819	 transfer: 0.0194	 finalize: 0.5375
batch bounding time:  0.8950912952423096
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), 
length of domains: 744
Total time: 0.9914	 pickout: 0.0135	 decision: 0.0789	 get_bound: 0.8951	 add_domain: 0.0040
Current lb:-0.002927541732788086
2142 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 141.88354182243347

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [9, 236] [9, 236] [9, 236] [3, 3061] [3, 3061] [3, 3061] [2, 437] [4, 2977] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.027355555444955826 with beta sum per layer: [0.016321983188390732, 0.0, 0.01218731701374054, 0.0, 0.07529734075069427, 0.0, 0.0, 0.0, 0.0, 1.815405249595642]
alpha/beta optimization time: 0.8680281639099121
This batch time : update_bounds func: 0.8996	 prepare: 0.0084	 bound: 0.8687	 transfer: 0.0193	 finalize: 0.0032
Accumulated time: update_bounds func: 123.0392	 prepare: 1.1141	 bound: 118.9505	 transfer: 0.0193	 finalize: 0.5407
batch bounding time:  0.9000809192657471
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), 
length of domains: 749
Total time: 0.9958	 pickout: 0.0133	 decision: 0.0788	 get_bound: 0.9001	 add_domain: 0.0036
Current lb:-0.002927541732788086
2158 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 142.87997770309448

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [0, 1253] [3, 3063] [9, 236] [9, 236] [0, 1192] [9, 236] [3, 3070] [9, 236] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.022082597017288208 with beta sum per layer: [0.0, 0.0, 0.0, 0.14242428541183472, 0.02509911358356476, 0.0, 0.0, 0.0, 0.0, 2.276754140853882]
alpha/beta optimization time: 0.879518985748291
This batch time : update_bounds func: 0.9108	 prepare: 0.0082	 bound: 0.8802	 transfer: 0.0192	 finalize: 0.0032
Accumulated time: update_bounds func: 123.9500	 prepare: 1.1222	 bound: 119.8307	 transfer: 0.0192	 finalize: 0.5440
batch bounding time:  0.9112584590911865
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (170), [-0.00293,   inf] (170), 
length of domains: 753
Total time: 1.0054	 pickout: 0.0127	 decision: 0.0781	 get_bound: 0.9113	 add_domain: 0.0033
Current lb:-0.002927541732788086
2174 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 143.88603711128235

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 16, 32, 32]) pre split depth:  1
batch:  torch.Size([8, 16, 32, 32]) post split depth:  1
splitting decisions: 
split level 0: [2, 437] [2, 437] [9, 236] [2, 437] [9, 236] [3, 3065] [9, 236] [2, 381] 
regular batch size: 2*8, diving batch size 1*0
best_l after optimization: 0.028613604605197906 with beta sum per layer: [0.016009394079446793, 0.0, 0.03456389158964157, 0.19570523500442505, 0.0, 0.0, 0.0, 0.0, 0.0, 1.8713560104370117]
alpha/beta optimization time: 0.8855876922607422
This batch time : update_bounds func: 0.9175	 prepare: 0.0083	 bound: 0.8862	 transfer: 0.0196	 finalize: 0.0033
Accumulated time: update_bounds func: 124.8674	 prepare: 1.1305	 bound: 120.7169	 transfer: 0.0196	 finalize: 0.5472
batch bounding time:  0.9178986549377441
Current worst splitting domains [lb, ub] (depth):
[-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (168), [-0.00293,   inf] (170), [-0.00293,   inf] (170), [-0.00293,   inf] (170), [-0.00293,   inf] (170), [-0.00293,   inf] (170), [-0.00293,   inf] (170), [-0.00293,   inf] (170), [-0.00293,   inf] (170), [-0.00293,   inf] (170), [-0.00293,   inf] (170), 
length of domains: 758
Total time: 1.0109	 pickout: 0.0105	 decision: 0.0789	 get_bound: 0.9179	 add_domain: 0.0037
Current lb:-0.002927541732788086
2190 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Time out!!!!!!!!
Image 193 label 6 verification end, final lower bound -0.002927541732788086, upper bound inf, time: 145.25712847709656
193 -0.002927541732788086
Result: image 193 verification failure (with branch and bound).
Wall time: 180.65940713882446

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 0): []
verification failure idx (total 1): [193]
final verified acc: 0.0%[1]
verifier is called on 1 examples.
total verified: 0
mean time [cnt:1] (excluding attack success): 180.45817160606384
