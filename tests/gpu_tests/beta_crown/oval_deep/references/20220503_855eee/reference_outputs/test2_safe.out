Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: specify-target
  complete_verifier: bab
  enable_incomplete_verification: false
  get_crown_verified_acc: false
model:
  path: cifar_deep.pth
  name: cifar_model_deep
data:
  start: 10
  end: 11
  num_outputs: 10
  mean: [0.485, 0.456, 0.406]
  std: [0.225, 0.225, 0.225]
  pkl_path: deep_100.pkl
  dataset: CIFAR
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: null
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 1024
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 42
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: fsb
    candidates: 1
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Tue May  3 01:32:08 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(3, 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (3): ReLU()
  (4): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (5): ReLU()
  (6): Conv2d(8, 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (7): ReLU()
  (8): Flatten()
  (9): Linear(in_features=512, out_features=100, bias=True)
  (10): ReLU()
  (11): Linear(in_features=100, out_features=10, bias=True)
)
No epsilon defined!
Files already downloaded and verified
Overwrite epsilon that saved in .pkl file, they should be after normalized!
Task length: 1
saving results to Verified_ret_[cifar_model_deep]_start=10_end=11_iter=20_b=1024_timeout=42_branching=fsb-min-1_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 10 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 1, correct label 1, image norm 2952.50830078125, logits tensor([-0.7493,  3.1937, -1.4729,  0.1323, -1.4910, -0.6065, -1.3620, -0.3009,
        -0.5264,  3.1831], device='cuda:0', grad_fn=<SelectBackward>)
##### [0:10] Tested against 7 ######
Model prediction is: tensor([[-0.7493,  3.1937, -1.4729,  0.1323, -1.4910, -0.6065, -1.3620, -0.3009,
         -0.5264,  3.1831]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-1.6984]], device='cuda:0') None
best_l after optimization: 1.0816928148269653 with beta sum per layer: []
alpha/beta optimization time: 12.301665782928467
initial alpha-CROWN bounds: tensor([[-1.0817]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-1.0817, device='cuda:0', grad_fn=<MinBackward1>)
-1.0816928148269653
layer 0 size torch.Size([2048]) unstable 252
layer 1 size torch.Size([2048]) unstable 334
layer 2 size torch.Size([2048]) unstable 295
layer 3 size torch.Size([512]) unstable 101
layer 4 size torch.Size([100]) unstable 40
-----------------
# of unstable neurons: 1022
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 8, 16, 16]) pre split depth:  6
batch:  torch.Size([1, 8, 16, 16]) post split depth:  6
splitting decisions: 
split level 0: [4, 85] 
split level 1: [4, 12] 
split level 2: [4, 42] 
split level 3: [4, 61] 
split level 4: [4, 4] 
split level 5: [4, 62] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: -33.41114044189453 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 3.0830044746398926]
alpha/beta optimization time: 0.4505126476287842
This batch time : update_bounds func: 0.4799	 prepare: 0.0127	 bound: 0.4510	 transfer: 0.0067	 finalize: 0.0093
Accumulated time: update_bounds func: 0.4799	 prepare: 0.0127	 bound: 0.4510	 transfer: 0.0067	 finalize: 0.0093
batch bounding time:  0.48030972480773926
Current worst splitting domains [lb, ub] (depth):
[-0.38817,   inf] (7), [-0.24259,   inf] (7), [-0.13278,   inf] (7), [-0.02253,   inf] (7), [-0.01044,   inf] (7), 
length of domains: 5
Total time: 0.7347	 pickout: 0.0016	 decision: 0.2376	 get_bound: 0.4949	 add_domain: 0.0006
Current lb:-0.3881673812866211
64 neurons visited
0 diving domains visited
Global ub: tensor([[inf]], device='cuda:0'), batch ub: inf
Cumulative time: 14.844928503036499

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([5, 8, 16, 16]) pre split depth:  4
batch:  torch.Size([5, 8, 16, 16]) post split depth:  4
splitting decisions: 
split level 0: [4, 77] [4, 77] [4, 77] [4, 77] [4, 77] 
split level 1: [4, 80] [4, 80] [4, 80] [4, 80] [4, 80] 
split level 2: [4, 98] [4, 98] [4, 98] [4, 98] [4, 98] 
split level 3: [4, 34] [4, 34] [4, 34] [4, 34] [4, 34] 
regular batch size: 2*40, diving batch size 1*0
best_l after optimization: -41.12936782836914 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 27.603370666503906]
alpha/beta optimization time: 0.39334630966186523
This batch time : update_bounds func: 0.4243	 prepare: 0.0174	 bound: 0.3938	 transfer: 0.0041	 finalize: 0.0081
Accumulated time: update_bounds func: 0.9043	 prepare: 0.0301	 bound: 0.8448	 transfer: 0.0041	 finalize: 0.0174
batch bounding time:  0.42458343505859375
Current worst splitting domains [lb, ub] (depth):
[-0.15945,   inf] (12), [-0.12911,   inf] (12), [-0.00265,   inf] (12), 
length of domains: 3
Total time: 0.6250	 pickout: 0.0029	 decision: 0.1810	 get_bound: 0.4409	 add_domain: 0.0002
Current lb:-0.1594499796628952
144 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.470704555511475

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([3, 8, 16, 16]) pre split depth:  5
batch:  torch.Size([3, 8, 16, 16]) post split depth:  5
splitting decisions: 
split level 0: [4, 49] [4, 49] [4, 49] 
split level 1: [4, 95] [4, 95] [4, 95] 
split level 2: [4, 57] [4, 57] [4, 57] 
split level 3: [2, 1912] [2, 1899] [2, 1912] 
split level 4: [4, 41] [4, 41] [4, 41] 
regular batch size: 2*48, diving batch size 1*0

all verified at 5th iter
best_l after optimization: -44.743370056152344 with beta sum per layer: [0.0, 0.0, 0.0, 0.0, 17.068586349487305]
alpha/beta optimization time: 0.10998153686523438
This batch time : update_bounds func: 0.1389	 prepare: 0.0137	 bound: 0.1103	 transfer: 0.0054	 finalize: 0.0093
Accumulated time: update_bounds func: 1.0432	 prepare: 0.0438	 bound: 0.9552	 transfer: 0.0054	 finalize: 0.0267
batch bounding time:  0.1391761302947998
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.3306	 pickout: 0.0015	 decision: 0.1755	 get_bound: 0.1535	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 15.802246332168579

Image 10 label 7 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 15.898922204971313
10 1.0000000116860974e-07
Result: image 10 verification success (with branch and bound)!
Wall time: 15.951035976409912

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 1): [10]
verification failure idx (total 0): []
final verified acc: 100.0%[1]
verifier is called on 1 examples.
total verified: 1
mean time [cnt:1] (excluding attack success): 15.898922204971313
