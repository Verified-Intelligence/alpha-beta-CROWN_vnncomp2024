Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: specify-target
  complete_verifier: bab
  enable_incomplete_verification: false
  get_crown_verified_acc: false
model:
  path: cifar_deep.pth
  name: cifar_model_deep
data:
  start: 20
  end: 21
  num_outputs: 10
  mean: [0.485, 0.456, 0.406]
  std: [0.225, 0.225, 0.225]
  pkl_path: deep_100.pkl
  dataset: CIFAR
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: null
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 1024
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 54
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: fsb
    candidates: 1
    reduceop: min
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Tue May  3 01:32:32 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(3, 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (3): ReLU()
  (4): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (5): ReLU()
  (6): Conv2d(8, 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (7): ReLU()
  (8): Flatten()
  (9): Linear(in_features=512, out_features=100, bias=True)
  (10): ReLU()
  (11): Linear(in_features=100, out_features=10, bias=True)
)
No epsilon defined!
Files already downloaded and verified
Overwrite epsilon that saved in .pkl file, they should be after normalized!
Task length: 1
saving results to Verified_ret_[cifar_model_deep]_start=20_end=21_iter=20_b=1024_timeout=54_branching=fsb-min-1_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 20 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 8, correct label 8, image norm 2030.254638671875, logits tensor([ 1.2156, -0.2628,  0.4284, -0.9912,  0.4599, -1.3512, -0.3510, -1.0509,
         1.5052,  0.3980], device='cuda:0', grad_fn=<SelectBackward>)
##### [0:20] Tested against 4 ######
Model prediction is: tensor([[ 1.2156, -0.2628,  0.4284, -0.9912,  0.4599, -1.3512, -0.3510, -1.0509,
          1.5052,  0.3980]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-0.4427]], device='cuda:0') None
best_l after optimization: 0.2912580966949463 with beta sum per layer: []
alpha/beta optimization time: 12.565523624420166
initial alpha-CROWN bounds: tensor([[-0.2913]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-0.2913, device='cuda:0', grad_fn=<MinBackward1>)
-0.2912580966949463
layer 0 size torch.Size([2048]) unstable 160
layer 1 size torch.Size([2048]) unstable 209
layer 2 size torch.Size([2048]) unstable 233
layer 3 size torch.Size([512]) unstable 66
layer 4 size torch.Size([100]) unstable 31
-----------------
# of unstable neurons: 699
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 8, 16, 16]) pre split depth:  6
batch:  torch.Size([1, 8, 16, 16]) post split depth:  6
splitting decisions: 
split level 0: [4, 10] 
split level 1: [4, 49] 
split level 2: [4, 51] 
split level 3: [4, 83] 
split level 4: [4, 59] 
split level 5: [3, 476] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: -6.82220983505249 with beta sum per layer: [0.0, 0.0, 0.0, 1.9603939056396484, 3.2500500679016113]
alpha/beta optimization time: 0.41768527030944824
This batch time : update_bounds func: 0.4377	 prepare: 0.0082	 bound: 0.4181	 transfer: 0.0022	 finalize: 0.0090
Accumulated time: update_bounds func: 0.4377	 prepare: 0.0082	 bound: 0.4181	 transfer: 0.0022	 finalize: 0.0090
batch bounding time:  0.4379277229309082
Current worst splitting domains [lb, ub] (depth):
[-0.03751,   inf] (7), [-0.03750,   inf] (7), [-0.02585,   inf] (7), [-0.02268,   inf] (7), [-0.01987,   inf] (7), [-0.01587,   inf] (7), [-0.00445,   inf] (7), [-0.00314,   inf] (7), 
length of domains: 8
Total time: 0.6436	 pickout: 0.0012	 decision: 0.1941	 get_bound: 0.4477	 add_domain: 0.0005
Current lb:-0.037512972950935364
64 neurons visited
0 diving domains visited
Global ub: tensor([[inf]], device='cuda:0'), batch ub: inf
Cumulative time: 15.002340316772461

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 8, 16, 16]) pre split depth:  3
batch:  torch.Size([8, 8, 16, 16]) post split depth:  3
splitting decisions: 
split level 0: [3, 92] [3, 92] [3, 93] [3, 93] [3, 93] [3, 93] [3, 92] [3, 93] 
split level 1: [3, 93] [3, 93] [3, 92] [3, 92] [3, 92] [3, 92] [2, 292] [3, 92] 
split level 2: [1, 425] [1, 425] [3, 101] [2, 308] [2, 308] [3, 101] [3, 469] [2, 308] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: 0.06776611506938934 with beta sum per layer: [0.0, 2.6530284881591797, 0.02098306640982628, 1.0357813835144043, 9.532147407531738]
alpha/beta optimization time: 0.45544934272766113
This batch time : update_bounds func: 0.4859	 prepare: 0.0186	 bound: 0.4559	 transfer: 0.0021	 finalize: 0.0091
Accumulated time: update_bounds func: 0.9236	 prepare: 0.0268	 bound: 0.8740	 transfer: 0.0021	 finalize: 0.0181
batch bounding time:  0.48612093925476074
Current worst splitting domains [lb, ub] (depth):
[-0.02766,   inf] (11), [-0.02759,   inf] (11), [-0.02156,   inf] (11), [-0.02153,   inf] (11), [-0.02079,   inf] (11), [-0.02057,   inf] (11), [-0.02014,   inf] (11), [-0.01999,   inf] (11), [-0.01651,   inf] (11), [-0.01631,   inf] (11), [-0.01399,   inf] (11), [-0.01391,   inf] (11), [-0.01382,   inf] (11), [-0.01305,   inf] (11), [-0.01289,   inf] (11), [-0.01236,   inf] (11), [-0.01103,   inf] (11), [-0.01087,   inf] (11), [-0.01005,   inf] (11), [-0.00881,   inf] (11), 
length of domains: 30
Total time: 0.6448	 pickout: 0.0036	 decision: 0.1423	 get_bound: 0.4974	 add_domain: 0.0014
Current lb:-0.027663111686706543
128 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.647627353668213

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([30, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([30, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [1, 153] [1, 153] [1, 153] [1, 153] [2, 1945] [2, 1945] [2, 1945] [2, 1945] [2, 1945] [2, 1945] 
regular batch size: 2*30, diving batch size 1*0
best_l after optimization: 0.16859501600265503 with beta sum per layer: [0.0, 4.511455059051514, 2.0058155059814453, 1.8367632627487183, 3.505347490310669]
alpha/beta optimization time: 0.4554612636566162
This batch time : update_bounds func: 0.4825	 prepare: 0.0157	 bound: 0.4561	 transfer: 0.0021	 finalize: 0.0085
Accumulated time: update_bounds func: 1.4061	 prepare: 0.0424	 bound: 1.3301	 transfer: 0.0021	 finalize: 0.0266
batch bounding time:  0.48267221450805664
Current worst splitting domains [lb, ub] (depth):
[-0.02411,   inf] (13), [-0.02398,   inf] (13), [-0.02394,   inf] (13), [-0.02382,   inf] (13), [-0.01813,   inf] (13), [-0.01807,   inf] (13), [-0.01798,   inf] (13), [-0.01792,   inf] (13), [-0.01732,   inf] (13), [-0.01709,   inf] (13), [-0.01610,   inf] (13), [-0.01594,   inf] (13), [-0.01314,   inf] (13), [-0.01282,   inf] (13), [-0.01071,   inf] (13), [-0.01026,   inf] (13), [-0.01014,   inf] (13), [-0.00995,   inf] (13), [-0.00897,   inf] (13), [-0.00853,   inf] (13), 
length of domains: 31
Total time: 0.5731	 pickout: 0.0098	 decision: 0.0786	 get_bound: 0.4828	 add_domain: 0.0019
Current lb:-0.024114925414323807
188 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.22149920463562

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([31, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([31, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [2, 1945] [2, 1945] [2, 1945] [2, 1945] [2, 1945] [2, 1945] [2, 1945] [2, 1945] [1, 153] [1, 153] 
regular batch size: 2*31, diving batch size 1*0
best_l after optimization: -0.3878485858440399 with beta sum per layer: [0.0, 8.327213287353516, 1.732325553894043, 1.6867107152938843, 1.6873291730880737]
alpha/beta optimization time: 0.4567146301269531
This batch time : update_bounds func: 0.4850	 prepare: 0.0168	 bound: 0.4572	 transfer: 0.0021	 finalize: 0.0088
Accumulated time: update_bounds func: 1.8911	 prepare: 0.0592	 bound: 1.7873	 transfer: 0.0021	 finalize: 0.0355
batch bounding time:  0.4852297306060791
Current worst splitting domains [lb, ub] (depth):
[-0.02073,   inf] (15), [-0.02057,   inf] (15), [-0.02055,   inf] (15), [-0.02040,   inf] (15), [-0.01481,   inf] (15), [-0.01469,   inf] (15), [-0.01466,   inf] (15), [-0.01455,   inf] (15), [-0.01401,   inf] (15), [-0.01379,   inf] (15), [-0.01373,   inf] (15), [-0.01357,   inf] (15), [-0.01330,   inf] (15), [-0.01311,   inf] (15), [-0.00976,   inf] (15), [-0.00958,   inf] (15), [-0.00957,   inf] (15), [-0.00935,   inf] (15), [-0.00739,   inf] (15), [-0.00737,   inf] (15), 
length of domains: 37
Total time: 0.5765	 pickout: 0.0102	 decision: 0.0793	 get_bound: 0.4853	 add_domain: 0.0017
Current lb:-0.020731881260871887
250 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.798778295516968

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([37, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([37, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [3, 101] [3, 101] [3, 101] [3, 101] [3, 101] [3, 101] [3, 101] [3, 101] [3, 101] [3, 101] 
regular batch size: 2*37, diving batch size 1*0
best_l after optimization: -1.2660020589828491 with beta sum per layer: [0.0, 10.001462936401367, 0.0, 2.819348096847534, 1.9156323671340942]
alpha/beta optimization time: 0.436506986618042
This batch time : update_bounds func: 0.4666	 prepare: 0.0197	 bound: 0.4370	 transfer: 0.0024	 finalize: 0.0073
Accumulated time: update_bounds func: 2.3577	 prepare: 0.0789	 bound: 2.2243	 transfer: 0.0024	 finalize: 0.0428
batch bounding time:  0.46683549880981445
Current worst splitting domains [lb, ub] (depth):
[-0.01738,   inf] (17), [-0.01722,   inf] (17), [-0.01721,   inf] (17), [-0.01705,   inf] (17), [-0.01085,   inf] (17), [-0.01071,   inf] (17), [-0.01071,   inf] (17), [-0.01069,   inf] (17), [-0.01061,   inf] (17), [-0.01045,   inf] (17), [-0.01030,   inf] (17), [-0.01015,   inf] (17), [-0.01004,   inf] (17), [-0.00984,   inf] (17), [-0.00583,   inf] (17), [-0.00571,   inf] (17), [-0.00562,   inf] (17), [-0.00545,   inf] (17), [-0.00424,   inf] (17), [-0.00352,   inf] (17), 
length of domains: 31
Total time: 0.5676	 pickout: 0.0121	 decision: 0.0869	 get_bound: 0.4670	 add_domain: 0.0016
Current lb:-0.017378810793161392
324 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.36756420135498

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([31, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([31, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [3, 467] [3, 467] [3, 467] [3, 467] [3, 467] [3, 467] [3, 494] [3, 467] [3, 467] [3, 467] 
regular batch size: 2*31, diving batch size 1*0
best_l after optimization: -1.4378843307495117 with beta sum per layer: [0.0, 7.188112258911133, 0.0, 3.9491381645202637, 1.2511143684387207]
alpha/beta optimization time: 0.4007394313812256
This batch time : update_bounds func: 0.4232	 prepare: 0.0113	 bound: 0.4011	 transfer: 0.0038	 finalize: 0.0068
Accumulated time: update_bounds func: 2.7809	 prepare: 0.0903	 bound: 2.6254	 transfer: 0.0038	 finalize: 0.0495
batch bounding time:  0.4234325885772705
Current worst splitting domains [lb, ub] (depth):
[-0.01532,   inf] (19), [-0.01518,   inf] (19), [-0.01516,   inf] (19), [-0.01500,   inf] (19), [-0.00877,   inf] (19), [-0.00859,   inf] (19), [-0.00859,   inf] (19), [-0.00859,   inf] (19), [-0.00856,   inf] (19), [-0.00828,   inf] (19), [-0.00818,   inf] (19), [-0.00798,   inf] (19), [-0.00794,   inf] (19), [-0.00777,   inf] (19), [-0.00379,   inf] (19), [-0.00359,   inf] (19), [-0.00344,   inf] (19), [-0.00319,   inf] (19), [-0.00196,   inf] (19), [-0.00152,   inf] (19), 
length of domains: 26
Total time: 0.4944	 pickout: 0.0075	 decision: 0.0621	 get_bound: 0.4235	 add_domain: 0.0013
Current lb:-0.015324950218200684
386 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.862892627716064

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([26, 8, 16, 16]) pre split depth:  1
batch:  torch.Size([26, 8, 16, 16]) post split depth:  1
splitting decisions: 
split level 0: [3, 494] [3, 494] [3, 494] [3, 494] [3, 494] [3, 494] [3, 467] [3, 494] [3, 494] [3, 494] 
regular batch size: 2*26, diving batch size 1*0
best_l after optimization: -1.616652250289917 with beta sum per layer: [0.0, 4.949436664581299, 0.0, 4.849821090698242, 0.6580967307090759]
alpha/beta optimization time: 0.39698219299316406
This batch time : update_bounds func: 0.4158	 prepare: 0.0101	 bound: 0.3974	 transfer: 0.0029	 finalize: 0.0053
Accumulated time: update_bounds func: 3.1968	 prepare: 0.1003	 bound: 3.0228	 transfer: 0.0029	 finalize: 0.0548
batch bounding time:  0.41605520248413086
Current worst splitting domains [lb, ub] (depth):
[-0.01315,   inf] (21), [-0.01301,   inf] (21), [-0.01298,   inf] (21), [-0.01286,   inf] (21), [-0.00659,   inf] (21), [-0.00648,   inf] (21), [-0.00645,   inf] (21), [-0.00641,   inf] (21), [-0.00634,   inf] (21), [-0.00613,   inf] (21), [-0.00607,   inf] (21), [-0.00593,   inf] (21), [-0.00572,   inf] (21), [-0.00551,   inf] (21), [-0.00162,   inf] (21), [-0.00143,   inf] (21), [-0.00137,   inf] (21), [-0.00116,   inf] (21), 
length of domains: 18
Total time: 0.4819	 pickout: 0.0066	 decision: 0.0581	 get_bound: 0.4161	 add_domain: 0.0010
Current lb:-0.013145946897566319
438 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.345659494400024

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([18, 8, 16, 16]) pre split depth:  2
batch:  torch.Size([18, 8, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [1, 119] [1, 119] [1, 119] [1, 119] [1, 119] [1, 119] [1, 119] [1, 119] [4, 41] [4, 41] 
split level 1: [4, 17] [4, 17] [4, 17] [4, 17] [4, 17] [4, 17] [4, 17] [4, 17] [1, 395] [4, 17] 
regular batch size: 2*36, diving batch size 1*0
best_l after optimization: -4.351804733276367 with beta sum per layer: [0.0, 2.4409444332122803, 0.0, 2.5118789672851562, 0.19743570685386658]
alpha/beta optimization time: 0.39739155769348145
This batch time : update_bounds func: 0.4202	 prepare: 0.0126	 bound: 0.3978	 transfer: 0.0028	 finalize: 0.0069
Accumulated time: update_bounds func: 3.6170	 prepare: 0.1129	 bound: 3.4206	 transfer: 0.0028	 finalize: 0.0617
batch bounding time:  0.42055296897888184
Current worst splitting domains [lb, ub] (depth):
[-0.00864,   inf] (24), [-0.00855,   inf] (24), [-0.00852,   inf] (24), [-0.00851,   inf] (24), [-0.00849,   inf] (24), [-0.00842,   inf] (24), [-0.00836,   inf] (24), [-0.00830,   inf] (24), [-0.00257,   inf] (24), [-0.00224,   inf] (24), [-0.00221,   inf] (24), [-0.00218,   inf] (24), [-0.00215,   inf] (24), [-0.00214,   inf] (24), [-0.00199,   inf] (24), [-0.00195,   inf] (24), [-0.00191,   inf] (24), [-0.00180,   inf] (24), [-0.00173,   inf] (24), [-0.00172,   inf] (24), 
length of domains: 25
Total time: 0.5286	 pickout: 0.0048	 decision: 0.0955	 get_bound: 0.4266	 add_domain: 0.0018
Current lb:-0.008636030368506908
510 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.875021934509277

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([25, 8, 16, 16]) pre split depth:  2
batch:  torch.Size([25, 8, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [4, 90] [4, 90] [4, 90] [4, 90] [4, 90] [4, 90] [4, 90] [4, 90] [4, 90] [4, 90] 
split level 1: [1, 168] [1, 168] [1, 168] [1, 168] [1, 168] [1, 168] [1, 168] [1, 168] [1, 411] [4, 41] 
regular batch size: 2*50, diving batch size 1*0
best_l after optimization: -5.718268394470215 with beta sum per layer: [0.0, 6.770575523376465, 0.0, 2.5534048080444336, 0.2101738154888153]
alpha/beta optimization time: 0.4220590591430664
This batch time : update_bounds func: 0.4560	 prepare: 0.0168	 bound: 0.4225	 transfer: 0.0063	 finalize: 0.0101
Accumulated time: update_bounds func: 4.0730	 prepare: 0.1297	 bound: 3.8431	 transfer: 0.0063	 finalize: 0.0719
batch bounding time:  0.4563915729522705
Current worst splitting domains [lb, ub] (depth):
[-0.00476,   inf] (27), [-0.00471,   inf] (27), [-0.00471,   inf] (27), [-0.00468,   inf] (27), [-0.00468,   inf] (27), [-0.00460,   inf] (27), [-0.00455,   inf] (27), [-0.00447,   inf] (27), [-0.00277,   inf] (27), [-0.00268,   inf] (27), [-0.00264,   inf] (27), [-0.00259,   inf] (27), [-0.00255,   inf] (27), [-0.00254,   inf] (27), [-0.00248,   inf] (27), [-0.00235,   inf] (27), 
length of domains: 16
Total time: 0.5804	 pickout: 0.0064	 decision: 0.1083	 get_bound: 0.4647	 add_domain: 0.0010
Current lb:-0.004763484001159668
610 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 19.45708656311035

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([16, 8, 16, 16]) pre split depth:  2
batch:  torch.Size([16, 8, 16, 16]) post split depth:  2
splitting decisions: 
split level 0: [4, 41] [1, 395] [4, 41] [4, 41] [1, 395] [4, 41] [4, 41] [1, 395] [1, 395] [1, 395] 
split level 1: [1, 411] [4, 60] [1, 411] [1, 411] [4, 60] [1, 411] [1, 411] [4, 60] [4, 60] [4, 60] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: -4.897727012634277 with beta sum per layer: [0.0, 7.555986404418945, 0.0, 0.0, 0.002141657518222928]
alpha/beta optimization time: 0.40808677673339844
This batch time : update_bounds func: 0.4291	 prepare: 0.0115	 bound: 0.4085	 transfer: 0.0022	 finalize: 0.0068
Accumulated time: update_bounds func: 4.5021	 prepare: 0.1412	 bound: 4.2516	 transfer: 0.0022	 finalize: 0.0786
batch bounding time:  0.429337739944458
Current worst splitting domains [lb, ub] (depth):
[-0.00138,   inf] (30), [-0.00137,   inf] (30), [-0.00134,   inf] (30), [-0.00131,   inf] (30), [-0.00129,   inf] (30), [-0.00126,   inf] (30), [-0.00119,   inf] (30), [-0.00112,   inf] (30), 
length of domains: 8
Total time: 0.5340	 pickout: 0.0045	 decision: 0.0940	 get_bound: 0.4349	 add_domain: 0.0005
Current lb:-0.001381188165396452
674 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 19.99186396598816

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([8, 8, 16, 16]) pre split depth:  3
batch:  torch.Size([8, 8, 16, 16]) post split depth:  3
splitting decisions: 
split level 0: [2, 170] [2, 170] [2, 170] [2, 170] [2, 170] [2, 170] [2, 170] [2, 170] 
split level 1: [1, 1465] [4, 88] [1, 1465] [1, 1465] [4, 88] [1, 1465] [1, 1465] [4, 88] 
split level 2: [3, 74] [3, 74] [3, 74] [3, 74] [3, 74] [3, 74] [3, 74] [3, 74] 
regular batch size: 2*32, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -0.6129504442214966 with beta sum per layer: [0.0, 0.03555591404438019, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.013130426406860352
This batch time : update_bounds func: 0.0330	 prepare: 0.0114	 bound: 0.0135	 transfer: 0.0022	 finalize: 0.0058
Accumulated time: update_bounds func: 4.5351	 prepare: 0.1526	 bound: 4.2650	 transfer: 0.0022	 finalize: 0.0845
batch bounding time:  0.033127784729003906
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.1600	 pickout: 0.0027	 decision: 0.1162	 get_bound: 0.0411	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 20.152504205703735

Image 20 label 4 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 20.24934697151184
20 1.0000000116860974e-07
Result: image 20 verification success (with branch and bound)!
Wall time: 20.298315048217773

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 1): [20]
verification failure idx (total 0): []
final verified acc: 100.0%[1]
verifier is called on 1 examples.
total verified: 1
mean time [cnt:1] (excluding attack success): 20.24934697151184
