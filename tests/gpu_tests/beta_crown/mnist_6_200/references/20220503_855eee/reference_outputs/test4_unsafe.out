Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab-refine
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: mnist_6_200_nat.pth
  name: mnist_6_200
data:
  start: 465
  end: 466
  num_outputs: 10
  mean: [0.0]
  std: [1.0]
  pkl_path: null
  dataset: MNIST_ERAN_UN
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.015
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 1024
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: 16
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 900
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 22:52:16 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Flatten()
  (1): Linear(in_features=784, out_features=200, bias=True)
  (2): ReLU()
  (3): Linear(in_features=200, out_features=200, bias=True)
  (4): ReLU()
  (5): Linear(in_features=200, out_features=200, bias=True)
  (6): ReLU()
  (7): Linear(in_features=200, out_features=200, bias=True)
  (8): ReLU()
  (9): Linear(in_features=200, out_features=200, bias=True)
  (10): ReLU()
  (11): Linear(in_features=200, out_features=10, bias=True)
)
############################
Sampled data loaded. No normalization used!
Shape: torch.Size([1000, 1, 28, 28]) torch.Size([1000]) torch.Size([1000])
X range: tensor(1.) tensor(0.) tensor(0.1223)
Note runnerup label is empty here!
############################
epsilon after preprocessing: tensor([[[[0.0150]]]]), data_max = tensor([[[[1.]]]]), data_min = tensor([[[[0.]]]])
Task length: 1
saving results to Verified_ret_[mnist_6_200]_start=465_end=466_iter=20_b=1024_timeout=900_branching=kfsb-max-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 465 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 8, correct label 8, image norm 143.03921508789062, logits tensor([-3.3627, -1.7483, -0.2121,  4.2042, -2.1517,  0.6109, -3.6509, -1.1626,
         5.1091,  2.7416], device='cuda:0', grad_fn=<SelectBackward>)
Model prediction is: tensor([[-3.3627, -1.7483, -0.2121,  4.2042, -2.1517,  0.6109, -3.6509, -1.1626,
          5.1091,  2.7416]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[ 1.0146,  0.7340, -1.9315, -5.8657, -1.7302, -2.7881,  1.5853, -2.8887,
         -6.6228]], device='cuda:0') None
best_l after optimization: 1.338366150856018 with beta sum per layer: []
alpha/beta optimization time: 8.14220404624939
initial alpha-CROWN bounds: tensor([[ 2.5903,  2.2083,  0.0346, -3.7258,  0.5957, -1.0662,  3.2174, -0.6057,
         -4.5869]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-4.5869, device='cuda:0', grad_fn=<MinBackward1>)
Start solving intermediate bounds with MIP...
alpha-CROWN optimizable variables initialized.
Academic license - for non-commercial use only - expires 2023-03-23
Using license file /home/zhouxingshi/gurobi.lic
mip_multi_proc: 16, mip_threads: 1,total threads used: 16, mip_perneuron_refine_timeout: 15
[total time budget for MIP: 712.8613645553589]

Linear(in_features=784, out_features=200, bias=True) 0 2 torch.Size([200])
Linear(in_features=200, out_features=200, bias=True) 1 4 torch.Size([200])
sorted candidates ['lay4_195', 'lay4_81', 'lay4_36', 'lay4_82', 'lay4_52', 'lay4_174', 'lay4_137', 'lay4_125', 'lay4_163', 'lay4_77', 'lay4_166', 'lay4_177', 'lay4_8', 'lay4_120', 'lay4_79', 'lay4_180', 'lay4_15', 'lay4_138', 'lay4_107', 'lay4_21', 'lay4_194', 'lay4_99', 'lay4_187', 'lay4_56', 'lay4_73', 'lay4_142', 'lay4_188', 'lay4_117', 'lay4_9', 'lay4_185', 'lay4_69', 'lay4_80', 'lay4_76'] filter: 1.0
/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:579: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(eps_temp).reshape(1, -1, 1, 1)
Solving MIP for lay4_82, [-0.04687776416540146,0.7835477590560913]=>[1e-05,0.7835477590560913] (15,-1; -1,-1), time: 0.2813s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_180, [-0.5326021909713745,0.06079716980457306]=>[-0.4462665302137712,0.01627450035310017] (2,-1; 2,-1), time: 0.8460s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_8, [-0.25302255153656006,0.26154983043670654]=>[-0.17314677606904366,0.22664148455933047] (2,-1; 2,-1), time: 0.8559s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_52, [-0.2455933690071106,0.21878573298454285]=>[-0.1867141506365621,0.16632071898931886] (2,-1; 2,-1), time: 0.8667s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_177, [-0.26772335171699524,0.3920755386352539]=>[-0.14274134225501905,0.3657406291713993] (2,-1; 2,-1), time: 0.8698s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_174, [-0.4811801612377167,0.26643630862236023]=>[-0.38865931598800285,0.18625059425116627] (2,-1; 2,-1), time: 0.9114s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_79, [-0.5834952592849731,0.21580836176872253]=>[-0.4472548268764524,0.16594606698414277] (2,-1; 2,-1), time: 0.9139s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_125, [-0.23608851432800293,0.6568626165390015]=>[-0.08851960796222104,0.5713571957416577] (2,-1; 2,-1), time: 0.9579s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_120, [-0.42082148790359497,0.15327873826026917]=>[-0.36862786921948965,0.06270922564625729] (2,-1; 2,-1), time: 0.9807s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_195, [-0.2706281244754791,0.4900208115577698]=>[-0.13107483617975396,0.45518667499506327] (2,-1; 2,-1), time: 1.0118s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_77, [-0.536790668964386,0.20379821956157684]=>[-0.43508497226912307,0.12893207757865235] (2,-1; 2,-1), time: 1.0314s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_163, [-0.16680604219436646,0.4844132959842682]=>[-0.09616521366984987,0.37762546498772853] (2,-1; 2,-1), time: 1.0328s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_36, [-0.6372323036193848,0.12971600890159607]=>[-0.4809823481420652,0.09305092982863815] (2,-1; 2,-1), time: 1.1575s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_81, [-0.30908671021461487,0.4245966672897339]=>[-0.23829416472553122,0.3443586764850285] (2,-1; 2,-1), time: 1.1617s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_137, [-0.3098061978816986,0.46142029762268066]=>[-0.1467650688987574,0.4347767958446106] (2,-1; 2,-1), time: 1.1918s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_187, [-0.06342177838087082,0.6336007118225098]=>[1e-05,0.6336007118225098] (15,-1; -1,-1), time: 0.3194s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_142, [-0.6488865613937378,0.017133206129074097]=>[-0.6488865613937378,-1e-05] (-1,-1; 15,-1), time: 0.3167s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_166, [-0.6768429279327393,0.1264457404613495]=>[-0.5305374534144799,0.06665510493888278] (2,-1; 2,-1), time: 1.3504s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_69, [-0.012059226632118225,0.47332072257995605]=>[1e-05,0.47332072257995605] (15,-1; -1,-1), time: 0.2653s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_15, [-0.6129966974258423,0.11656764149665833]=>[-0.524642791777367,0.007432344066839107] (2,-1; 2,-1), time: 1.2370s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_99, [-0.09599411487579346,0.39568042755126953]=>[-0.06193591401333133,0.33215199435549964] (2,-1; 2,-1), time: 0.7033s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_21, [-0.20178289711475372,0.45326462388038635]=>[-0.12046202395801543,0.4230514488720957] (2,-1; 2,-1), time: 0.7969s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_56, [-0.2595205307006836,0.28981056809425354]=>[-0.1843770281352398,0.21872589998255293] (2,-1; 2,-1), time: 0.7156s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_188, [-0.3174794614315033,0.3213489055633545]=>[-0.2315374083056306,0.25407694274298714] (2,-1; 2,-1), time: 0.7709s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_107, [-0.546007513999939,0.06573620438575745]=>[-0.4446311078433059,0.02784336670846438] (2,-1; 2,-1), time: 0.9843s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_185, [-0.31978633999824524,0.37382972240448]=>[-0.24130478645809791,0.2920667981976325] (2,-1; 2,-1), time: 0.6886s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_9, [-0.17585933208465576,0.6139492392539978]=>[-0.07785793665696907,0.5370872070438824] (2,-1; 2,-1), time: 0.7534s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_117, [-0.4519706666469574,0.06241552531719208]=>[-0.36849915887984314,0.026142612125230343] (2,-1; 2,-1), time: 0.8786s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_194, [-0.31502479314804077,0.1369091123342514]=>[-0.254486335266099,0.08309301898229032] (2,-1; 2,-1), time: 1.1033s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_138, [-0.4870067834854126,0.12048772722482681]=>[-0.3689357819926335,0.06541186141467198] (2,-1; 2,-1), time: 1.1826s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_76, [-0.34300917387008667,0.24802210927009583]=>[-0.2597632779371891,0.19257769293084806] (2,-1; 2,-1), time: 0.7140s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_73, [-0.31140273809432983,0.33435118198394775]=>[-0.24124311023078615,0.24973622566967135] (2,-1; 2,-1), time: 1.4314s, #vars: 1217, #constrs: 448, improved: True
Solving MIP for lay4_80, [-0.235373854637146,0.5011221170425415]=>[-0.2164225047542077,0.332246604493629] (2,-1; 2,-1), time: 1.5893s, #vars: 1217, #constrs: 448, improved: True
MIP improved 33 nodes out of 33 unstable nodes, lb improved 2.826390027999878, ub improved 1.8931734561920166, time 3.5011
maximum relu layer improved by MIP so far 1 last_relu_layer_refined: True
Linear(in_features=200, out_features=200, bias=True) 2 6 torch.Size([200])
sorted candidates ['lay6_141', 'lay6_97', 'lay6_104', 'lay6_99', 'lay6_166', 'lay6_135', 'lay6_30', 'lay6_3', 'lay6_66', 'lay6_39', 'lay6_102', 'lay6_20', 'lay6_122', 'lay6_139', 'lay6_123', 'lay6_72', 'lay6_75', 'lay6_9', 'lay6_80', 'lay6_114', 'lay6_175', 'lay6_147', 'lay6_71', 'lay6_67', 'lay6_73', 'lay6_53', 'lay6_194', 'lay6_174', 'lay6_14', 'lay6_15', 'lay6_52', 'lay6_13', 'lay6_64', 'lay6_197', 'lay6_7', 'lay6_82', 'lay6_167', 'lay6_24', 'lay6_165', 'lay6_160', 'lay6_185', 'lay6_45', 'lay6_88', 'lay6_126', 'lay6_138', 'lay6_50', 'lay6_81', 'lay6_127', 'lay6_101', 'lay6_112', 'lay6_70', 'lay6_103', 'lay6_85', 'lay6_176', 'lay6_198', 'lay6_32', 'lay6_4', 'lay6_51', 'lay6_159', 'lay6_18', 'lay6_142', 'lay6_117', 'lay6_120', 'lay6_19', 'lay6_69', 'lay6_187', 'lay6_98', 'lay6_164'] filter: 1.0
Solving MIP for lay6_102, [-0.6235713958740234,0.12865501642227173]=>[-0.6235713958740234,-1e-05] (-1,-1; 15,-1), time: 0.8029s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_166, [-0.813233494758606,0.11684200167655945]=>[-0.813233494758606,-1e-05] (-1,-1; 15,-1), time: 0.9038s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_20, [-0.08575811237096786,0.44383636116981506]=>[1e-05,0.44383636116981506] (15,-1; -1,-1), time: 1.9102s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_104, [-0.1121896430850029,0.39801204204559326]=>[1e-05,0.39801204204559326] (15,-1; -1,-1), time: 2.8198s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_139, [-0.6889346241950989,0.1409415304660797]=>[-0.6889346241950989,-1e-05] (-1,-1; 15,-1), time: 3.2056s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_39, [-0.22770872712135315,0.38361039757728577]=>[-0.07180799986673374,0.26914384058537183] (2,-1; 2,-1), time: 4.7439s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_9, [-0.46845439076423645,0.1282985955476761]=>[-0.46845439076423645,-1e-05] (-1,-1; 15,-1), time: 4.2369s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_141, [-0.5827348828315735,0.3954049348831177]=>[-0.4205801748332699,0.24038654644798657] (2,-1; 2,-1), time: 5.2096s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_80, [-0.3709304928779602,0.14173711836338043]=>[-0.3709304928779602,-1e-05] (-1,-1; 15,-1), time: 3.3184s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_72, [-0.22641615569591522,0.49153387546539307]=>[-0.03382014011644175,0.3836485695271085] (2,-1; 2,-1), time: 5.7241s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_66, [-0.1755584478378296,0.3895794451236725]=>[-0.06122823132734253,0.2593656338290184] (2,-1; 2,-1), time: 6.5423s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_147, [-0.09309369325637817,0.6317737102508545]=>[1e-05,0.6317737102508545] (15,-1; -1,-1), time: 1.8312s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_99, [-0.1969449669122696,0.3493669331073761]=>[-0.07079996594875168,0.2350064653277711] (2,-1; 2,-1), time: 6.7374s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_135, [-0.330752968788147,0.27538588643074036]=>[-0.1975407601129583,0.12828391943817247] (2,-1; 2,-1), time: 6.8113s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_123, [-0.2804170548915863,0.5609603524208069]=>[-0.052236038002716756,0.41733404722089074] (2,-1; 2,-1), time: 6.8126s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_75, [-0.28379011154174805,0.4347384572029114]=>[-0.11016883029838116,0.33033798546092896] (2,-1; 2,-1), time: 6.1177s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_174, [-0.6024253368377686,0.06925639510154724]=>[-0.6024253368377686,-1e-05] (-1,-1; 15,-1), time: 0.3503s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_3, [-0.37751322984695435,0.38867124915122986]=>[-0.19346375679920713,0.23234377572073114] (2,-1; 2,-1), time: 7.4859s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_15, [-0.6337350606918335,0.082628533244133]=>[-0.6337350606918335,-1e-05] (-1,-1; 15,-1), time: 0.8239s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_7, [-0.5197110176086426,0.05842798948287964]=>[-0.5197110176086426,-1e-05] (-1,-1; 15,-1), time: 0.4062s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_97, [-0.3507221043109894,0.2809799313545227]=>[-0.21270869737928993,0.11219688198441545] (2,-1; 2,-1), time: 8.3017s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_114, [-0.24544478952884674,0.21378645300865173]=>[-0.14594392191481242,0.1200496095794348] (2,-1; 2,-1), time: 6.0901s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_122, [-0.39703279733657837,0.24630679190158844]=>[-0.19836866671384626,0.10960465230777966] (2,-1; 2,-1), time: 9.3448s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_175, [-0.5113723874092102,0.15549322962760925]=>[-0.37252870983916275,0.0044547931254571935] (2,-1; 2,-1), time: 6.7753s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_167, [-0.48829641938209534,0.06783168017864227]=>[-0.48829641938209534,-1e-05] (-1,-1; 15,-1), time: 1.9139s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_67, [-0.17843973636627197,0.36073213815689087]=>[-0.052270019645135855,0.2334843612974398] (2,-1; 2,-1), time: 5.2392s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_71, [-0.5157896876335144,0.15334072709083557]=>[-0.3924111116154757,0.04037282075780723] (2,-1; 2,-1), time: 5.3101s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_82, [-0.4126240611076355,0.07426360249519348]=>[-0.4126240611076355,-1e-05] (-1,-1; 15,-1), time: 2.3984s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_53, [-0.45331355929374695,0.20501446723937988]=>[-0.3176157485216256,0.04658755129008966] (2,-1; 2,-1), time: 4.9817s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_73, [-0.5473141670227051,0.16055269539356232]=>[-0.3830637633232434,0.0013628463275174461] (2,-1; 2,-1), time: 5.6058s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_138, [-0.05875111371278763,0.4795641303062439]=>[1e-05,0.4795641303062439] (15,-1; -1,-1), time: 0.3840s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_24, [-0.14947812259197235,0.47346431016921997]=>[1e-05,0.47346431016921997] (15,-1; -1,-1), time: 3.0532s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_14, [-0.3588147461414337,0.12607979774475098]=>[-0.21548560940999315,0.04399307709094018] (2,-1; 2,-1), time: 5.4048s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_64, [-0.17598730325698853,0.4849071800708771]=>[-0.052292957934352374,0.33679388171663127] (2,-1; 2,-1), time: 5.2310s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_194, [-0.4967232346534729,0.11288150399923325]=>[-0.3157603031756242,0.0046931262974255865] (2,-1; 2,-1), time: 6.4190s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_101, [-0.0824442133307457,0.602339506149292]=>[1e-05,0.602339506149292] (15,-1; -1,-1), time: 0.8184s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_30, [-0.23149167001247406,0.3555026650428772]=>[-0.02482834913974614,0.24925507403355182] (2,-1; 2,-1), time: 13.0264s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_52, [-0.5031371116638184,0.0923907533288002]=>[-0.3135768997835599,0.0153238409188437] (2,-1; 2,-1), time: 6.3337s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_13, [-0.3568528890609741,0.34981569647789]=>[-0.18280066380784873,0.17513364353116456] (2,-1; 2,-1), time: 7.7870s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_45, [-0.3878142535686493,0.48992282152175903]=>[-0.2627665922753259,0.3438823069913365] (2,-1; 2,-1), time: 5.2502s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_81, [-0.31627845764160156,0.21482901275157928]=>[-0.16977556176414924,0.12857726186181948] (2,-1; 2,-1), time: 4.6956s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_32, [-0.6412052512168884,0.05410601198673248]=>[-0.6412052512168884,-1e-05] (-1,-1; 15,-1), time: 0.4290s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_4, [-0.04495896399021149,0.6403274536132812]=>[1e-05,0.6403274536132812] (15,-1; -1,-1), time: 0.3606s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_160, [-0.4619840979576111,0.18194016814231873]=>[-0.3509684762066585,0.03924225396770167] (2,-1; 2,-1), time: 6.2352s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_165, [-0.3783630132675171,0.3196592330932617]=>[-0.18707771054700756,0.1909358174040717] (2,-1; 2,-1), time: 6.9355s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_159, [-0.6663958430290222,0.014982074499130249]=>[-0.6663958430290222,-1e-05] (-1,-1; 15,-1), time: 0.1704s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_197, [-0.4186507761478424,0.15430325269699097]=>[-0.22883975080069272,0.07941775440256982] (2,-1; 2,-1), time: 9.5328s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_50, [-0.4451318085193634,0.352801650762558]=>[-0.24611801615867426,0.2237022863910914] (2,-1; 2,-1), time: 6.2459s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_198, [-0.5307589173316956,0.14857938885688782]=>[-0.5307589173316956,-1e-05] (-1,-1; 15,-1), time: 2.3862s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_69, [-0.025033652782440186,0.6686227917671204]=>[1e-05,0.6686227917671204] (15,-1; -1,-1), time: 0.1722s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_19, [-0.018562152981758118,0.4647138714790344]=>[1e-05,0.4647138714790344] (15,-1; -1,-1), time: 0.1749s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_98, [-0.5024393200874329,0.011282309889793396]=>[-0.5024393200874329,-1e-05] (-1,-1; 15,-1), time: 0.1957s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_164, [-0.5639025568962097,0.039851412177085876]=>[-0.5639025568962097,-1e-05] (-1,-1; 15,-1), time: 0.2904s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_112, [-0.4363018870353699,0.14539626240730286]=>[-0.3226106561040482,0.01188294733516492] (2,-1; 2,-1), time: 5.6298s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_127, [-0.21374011039733887,0.45352137088775635]=>[-0.07301532832878041,0.31116658679674103] (2,-1; 2,-1), time: 6.3732s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_126, [-0.39503905177116394,0.4053378403186798]=>[-0.22048972220088817,0.22989322758663994] (2,-1; 2,-1), time: 7.9548s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_185, [-0.27192258834838867,0.38549432158470154]=>[-0.15150981833090527,0.20518662006924193] (2,-1; 2,-1), time: 8.5215s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_85, [-0.33094722032546997,0.24056202173233032]=>[-0.17895740094628598,0.14370733194729604] (2,-1; 2,-1), time: 5.9499s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_117, [-0.10974997282028198,0.4599950313568115]=>[1e-05,0.4599950313568115] (15,-1; -1,-1), time: 2.6756s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_88, [-0.2759406864643097,0.38802245259284973]=>[-0.07879446655718235,0.2757086865446356] (2,-1; 2,-1), time: 8.5874s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_142, [-0.42467448115348816,0.10995560884475708]=>[-0.42467448115348816,-1e-05] (-1,-1; 15,-1), time: 2.8971s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_103, [-0.1557851880788803,0.5433674454689026]=>[-0.01871496149123932,0.4333797025970806] (2,-1; 2,-1), time: 6.3070s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_176, [-0.21606355905532837,0.39722853899002075]=>[-0.06516504641343192,0.24177472440855782] (2,-1; 2,-1), time: 6.1535s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_70, [-0.22000738978385925,0.4630068838596344]=>[-0.06031014196840101,0.3249001597766749] (2,-1; 2,-1), time: 6.6701s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_51, [-0.5041675567626953,0.13862408697605133]=>[-0.5041675567626953,-1e-05] (-1,-1; 15,-1), time: 3.7883s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_18, [-0.4486030042171478,0.12974298000335693]=>[-0.3355395556997054,0.0008932552482544] (2,-1; 2,-1), time: 5.3690s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_120, [-0.31006452441215515,0.2340622842311859]=>[-0.18807310373494518,0.12289327248344126] (2,-1; 2,-1), time: 5.6672s, #vars: 1475, #constrs: 735, improved: True
Solving MIP for lay6_187, [-0.40200868248939514,0.1401335597038269]=>[-0.2756339659390456,0.0015662159014197161] (2,-1; 2,-1), time: 5.6472s, #vars: 1475, #constrs: 735, improved: True
Run alpha-CROWN after refining layer 4 and relu idx 1
0 /21 torch.Size([1, 200])
1 /23 torch.Size([1, 200])
best_l after optimization: -11.113951683044434 with beta sum per layer: []
alpha/beta optimization time: 7.861622333526611
alpha-CROWN with intermediate bounds by MIP: tensor([[ 4.0426,  3.4140,  1.3863, -2.5515,  2.1247,  0.2410,  4.5226,  1.0358,
         -3.1017]], device='cuda:0', grad_fn=<AsStridedBackward>) None
MIP improved 68 nodes out of 68 unstable nodes, lb improved 7.063376426696777, ub improved 6.834935188293457, time 23.6631
maximum relu layer improved by MIP so far 2
Linear(in_features=200, out_features=200, bias=True) 3 8 torch.Size([200])
sorted candidates ['lay8_58', 'lay8_65', 'lay8_130', 'lay8_192', 'lay8_70', 'lay8_114', 'lay8_158', 'lay8_109', 'lay8_80', 'lay8_195', 'lay8_111', 'lay8_135', 'lay8_13', 'lay8_134', 'lay8_189', 'lay8_63', 'lay8_34', 'lay8_1', 'lay8_146', 'lay8_160', 'lay8_28', 'lay8_7', 'lay8_183', 'lay8_105', 'lay8_138', 'lay8_93', 'lay8_83', 'lay8_20', 'lay8_128', 'lay8_47', 'lay8_98', 'lay8_166', 'lay8_91', 'lay8_16', 'lay8_42', 'lay8_6', 'lay8_12', 'lay8_115', 'lay8_52', 'lay8_50', 'lay8_4', 'lay8_107', 'lay8_179', 'lay8_182', 'lay8_88', 'lay8_24', 'lay8_151', 'lay8_112', 'lay8_69', 'lay8_167', 'lay8_32', 'lay8_168', 'lay8_196', 'lay8_143', 'lay8_5', 'lay8_178', 'lay8_53', 'lay8_176', 'lay8_161', 'lay8_92', 'lay8_118', 'lay8_26', 'lay8_95', 'lay8_139', 'lay8_175', 'lay8_51', 'lay8_104', 'lay8_198', 'lay8_191', 'lay8_126', 'lay8_132', 'lay8_81', 'lay8_186', 'lay8_140', 'lay8_19', 'lay8_35', 'lay8_44', 'lay8_62', 'lay8_43', 'lay8_49', 'lay8_199', 'lay8_150', 'lay8_39', 'lay8_99', 'lay8_129', 'lay8_133', 'lay8_48', 'lay8_22', 'lay8_82', 'lay8_25', 'lay8_145', 'lay8_37'] filter: 1.0
Solving MIP for lay8_80, [-0.7766129374504089,0.3002532720565796]=>[-0.7766129374504089,-1e-05] (-1,-1; 15,-1), time: 4.7204s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_189, [-0.667772114276886,0.19265073537826538]=>[-0.667772114276886,-1e-05] (-1,-1; 15,-1), time: 5.5531s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_134, [-0.5552639365196228,0.2152065932750702]=>[-0.5552639365196228,-1e-05] (-1,-1; 15,-1), time: 5.9649s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_146, [-0.9743842482566833,0.1388256847858429]=>[-0.9743842482566833,-1e-05] (-1,-1; 15,-1), time: 0.3349s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_160, [-0.7059397101402283,0.18511223793029785]=>[-0.7059397101402283,-1e-05] (-1,-1; 15,-1), time: 0.7919s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_1, [-0.6402274370193481,0.264563649892807]=>[-0.6402274370193481,-1e-05] (-1,-1; 15,-1), time: 6.4451s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_7, [-0.01563100516796112,1.1887986660003662]=>[1e-05,1.1887986660003662] (15,-1; -1,-1), time: 0.3003s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_195, [-0.44900593161582947,0.69670569896698]=>[-0.16491389113651533,0.37263003142392515] (2,-1; 2,-1), time: 12.9595s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_13, [-0.7420251965522766,0.45516014099121094]=>[-0.36929168808105417,0.19233358538726983] (2,-1; 2,-1), time: 18.0288s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_138, [-0.5922500491142273,0.08963319659233093]=>[-0.5922500491142273,-1e-05] (-1,-1; 15,-1), time: 0.3814s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_65, [-0.8332905769348145,0.6460893750190735]=>[-0.5172483726730636,0.20708968972516537] (2,-1; 2,-1), time: 20.4225s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_183, [-0.3235032856464386,0.8411750793457031]=>[1e-05,0.8411750793457031] (15,-1; -1,-1), time: 8.4076s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_20, [-0.7383202314376831,0.07267773151397705]=>[-0.7383202314376831,-1e-05] (-1,-1; 15,-1), time: 0.2854s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_192, [-0.38275647163391113,0.4868983328342438]=>[-0.18413320897651042,0.19577823692085158] (2,-1; 9,-1), time: 21.6862s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_128, [-0.803939700126648,0.17392823100090027]=>[-0.803939700126648,-1e-05] (-1,-1; 15,-1), time: 0.9686s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_109, [-0.34247857332229614,0.6332908272743225]=>[-0.02102972970616359,0.4003877502285802] (9,-1; 2,-1), time: 22.0063s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_166, [-0.20822221040725708,0.8089107275009155]=>[1e-05,0.8089107275009155] (15,-1; -1,-1), time: 0.3863s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_91, [-0.7771613001823425,0.078928142786026]=>[-0.7771613001823425,-1e-05] (-1,-1; 15,-1), time: 0.4246s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_58, [-1.007700800895691,0.4502323567867279]=>[-0.6293161383132669,0.09544103231387553] (2,-1; 2,-1), time: 23.5235s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_70, [-0.32914814352989197,0.5154643058776855]=>[-0.007519593138177692,0.2867131149506068] (2,-1; 9,-1), time: 26.2816s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_6, [-0.6830896735191345,0.11928704380989075]=>[-0.6830896735191345,-1e-05] (-1,-1; 15,-1), time: 0.3418s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_12, [-0.8971361517906189,0.03274654224514961]=>[-0.8971361517906189,-1e-05] (-1,-1; 15,-1), time: 0.4258s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_47, [-0.5945682525634766,0.189489483833313]=>[-0.5945682525634766,-1e-05] (-1,-1; 15,-1), time: 5.4621s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_52, [-0.8697972893714905,0.1649884134531021]=>[-0.8697972893714905,-1e-05] (-1,-1; 15,-1), time: 0.7973s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_34, [-0.6527539491653442,0.4344768524169922]=>[-0.2852581934919101,0.1471182892985988] (2,-1; 9,-1), time: 23.6170s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_4, [-1.119367241859436,0.06147348880767822]=>[-1.119367241859436,-1e-05] (-1,-1; 15,-1), time: 0.2918s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_107, [-0.5778670310974121,0.0936131477355957]=>[-0.5778670310974121,-1e-05] (-1,-1; 15,-1), time: 0.2774s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_179, [-0.5735751986503601,0.13507044315338135]=>[-0.5735751986503601,-1e-05] (-1,-1; 15,-1), time: 0.5710s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_130, [-0.33658209443092346,0.9592209458351135]=>[-0.0045472306557253935,0.5618160749420523] (9,-1; 9,-1), time: 30.0279s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_111, [-0.5095632076263428,0.4571283757686615]=>[-0.18929044126082056,0.20074608347234377] (9,-1; 9,-1), time: 30.0320s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_114, [-0.5555701851844788,0.3765345513820648]=>[-0.2234092402403955,0.17490219664852477] (9,-1; 9,-1), time: 30.2604s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_135, [-0.4593374729156494,0.3866891860961914]=>[-0.18938975854512297,0.13936957320514023] (9,-1; 9,-1), time: 30.2813s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_158, [-0.46359410881996155,0.2934689223766327]=>[-0.23889842270858724,0.07570124820410157] (9,-1; 9,-1), time: 30.3233s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_63, [-0.6508368253707886,0.32977885007858276]=>[-0.3551099587343215,0.005666924704130808] (9,-1; 9,-1), time: 30.3378s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_24, [-0.7518555521965027,0.08149451017379761]=>[-0.7518555521965027,-1e-05] (-1,-1; 15,-1), time: 0.3597s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_88, [-0.9172452688217163,0.06829878687858582]=>[-0.9172452688217163,-1e-05] (-1,-1; 15,-1), time: 0.3952s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_42, [-0.6881943941116333,0.17678388953208923]=>[-0.6881943941116333,-1e-05] (-1,-1; 15,-1), time: 7.0235s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_151, [-0.8827288150787354,0.14949855208396912]=>[-0.8827288150787354,-1e-05] (-1,-1; 15,-1), time: 0.3793s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_69, [-0.8072811365127563,0.16302908957004547]=>[-0.8072811365127563,-1e-05] (-1,-1; 15,-1), time: 0.3251s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_196, [-0.8440564870834351,0.053322792053222656]=>[-0.8440564870834351,-1e-05] (-1,-1; 15,-1), time: 0.3814s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_143, [-0.07684007287025452,0.9016638994216919]=>[1e-05,0.9016638994216919] (15,-1; -1,-1), time: 0.3817s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_178, [-0.7904378175735474,0.05885762348771095]=>[-0.7904378175735474,-1e-05] (-1,-1; 15,-1), time: 0.3576s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_5, [-0.8257559537887573,0.1328580230474472]=>[-0.8257559537887573,-1e-05] (-1,-1; 15,-1), time: 0.7488s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_161, [-0.1313825249671936,1.021741509437561]=>[1e-05,1.021741509437561] (15,-1; -1,-1), time: 0.3782s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_176, [-0.20459461212158203,0.6100872159004211]=>[1e-05,0.6100872159004211] (15,-1; -1,-1), time: 0.7705s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_118, [-0.7831659317016602,0.013321667909622192]=>[-0.7831659317016602,-1e-05] (-1,-1; 15,-1), time: 0.3836s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_26, [-0.9495028257369995,0.036330610513687134]=>[-0.9495028257369995,-1e-05] (-1,-1; 15,-1), time: 0.3391s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_95, [-0.8141536116600037,0.01581820845603943]=>[-0.8141536116600037,-1e-05] (-1,-1; 15,-1), time: 0.4197s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_139, [-0.7721869945526123,0.076772540807724]=>[-0.7721869945526123,-1e-05] (-1,-1; 15,-1), time: 0.3994s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_175, [-0.09837155044078827,0.6570156812667847]=>[1e-05,0.6570156812667847] (15,-1; -1,-1), time: 0.3939s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_93, [-0.8065244555473328,0.31200745701789856]=>[-0.48809616203373746,0.050953030800609984] (2,-1; 2,-1), time: 16.7484s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_182, [-0.6555805206298828,0.2004013955593109]=>[-0.6555805206298828,-1e-05] (-1,-1; 15,-1), time: 5.8333s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_104, [-0.14336249232292175,0.9943581819534302]=>[1e-05,0.9943581819534302] (15,-1; -1,-1), time: 0.3518s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_198, [-0.9136648178100586,0.03644101321697235]=>[-0.9136648178100586,-1e-05] (-1,-1; 15,-1), time: 0.3293s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_191, [-0.8792235255241394,0.022176356986165047]=>[-0.8792235255241394,-1e-05] (-1,-1; 15,-1), time: 0.3891s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_126, [-0.7595282793045044,0.027282804250717163]=>[-0.7595282793045044,-1e-05] (-1,-1; 15,-1), time: 0.3003s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_132, [-0.9305625557899475,0.09659501910209656]=>[-0.9305625557899475,-1e-05] (-1,-1; 15,-1), time: 0.3683s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_186, [-0.8366042375564575,0.07322532683610916]=>[-0.8366042375564575,-1e-05] (-1,-1; 15,-1), time: 0.4007s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_81, [-0.25819045305252075,0.6434609889984131]=>[1e-05,0.6434609889984131] (15,-1; -1,-1), time: 0.8620s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_140, [-0.08376994729042053,0.9024335741996765]=>[1e-05,0.9024335741996765] (15,-1; -1,-1), time: 0.3874s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_28, [-0.6013281941413879,0.47741737961769104]=>[-0.29175104119265166,0.133451275993642] (9,-1; 9,-1), time: 30.0313s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_35, [-0.6506383419036865,0.1007145419716835]=>[-0.6506383419036865,-1e-05] (-1,-1; 15,-1), time: 0.3773s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_62, [-0.7040290832519531,0.16140756011009216]=>[-0.7040290832519531,-1e-05] (-1,-1; 15,-1), time: 0.3695s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_43, [-0.6762135028839111,0.1360521912574768]=>[-0.6762135028839111,-1e-05] (-1,-1; 15,-1), time: 0.3345s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_105, [-0.5931153297424316,0.2966642379760742]=>[-0.2960123251728503,0.07664515054075664] (9,-1; 9,-1), time: 30.0110s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_51, [-0.7275073528289795,0.25573307275772095]=>[-0.7275073528289795,-1e-05] (-1,-1; 15,-1), time: 9.2393s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_115, [-0.6417252421379089,0.3172164559364319]=>[-0.28496785002065333,0.10358822615258528] (9,-1; 2,-1), time: 21.2455s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_39, [-0.808380663394928,0.1593029946088791]=>[-0.808380663394928,-1e-05] (-1,-1; 15,-1), time: 0.7522s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_99, [-0.14623889327049255,0.7404820322990417]=>[1e-05,0.7404820322990417] (15,-1; -1,-1), time: 0.4021s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_199, [-0.22250857949256897,0.5073832273483276]=>[1e-05,0.5073832273483276] (15,-1; -1,-1), time: 6.8743s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_53, [-0.3552742004394531,0.6987975835800171]=>[-0.08292007649336133,0.3779116246917722] (2,-1; 2,-1), time: 19.2981s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_83, [-0.4477875232696533,0.26373863220214844]=>[-0.23792943535325434,0.025005597530224483] (9,-1; 9,-1), time: 30.1053s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_22, [-0.0881214439868927,0.7733978033065796]=>[1e-05,0.7733978033065796] (15,-1; -1,-1), time: 0.3871s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_16, [-0.5428861975669861,0.47116097807884216]=>[-0.23833699054209945,0.17802606814340174] (9,-1; 2,-1), time: 28.1953s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_32, [-0.6761870384216309,0.5166792273521423]=>[-0.35162129048241264,0.2179630300613641] (2,-1; 2,-1), time: 20.7625s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_82, [-0.002436092821881175,0.8112728595733643]=>[1e-05,0.8112728595733643] (15,-1; -1,-1), time: 0.3915s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_25, [-0.021081503480672836,1.0298393964767456]=>[1e-05,1.0298393964767456] (15,-1; -1,-1), time: 0.4092s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_112, [-0.560198187828064,0.32010236382484436]=>[-0.306423993010688,0.09054499011941118] (2,-1; 9,-1), time: 21.6663s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_98, [-0.479806125164032,0.44310295581817627]=>[-0.20058713280366164,0.17837287310178548] (9,-1; 9,-1), time: 30.0117s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_168, [-0.7922266125679016,0.30082836747169495]=>[-0.4117382579130584,0.0322807183091979] (9,-1; 2,-1), time: 22.9412s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_167, [-0.5019665956497192,0.33771660923957825]=>[-0.2172085980329488,0.12017438798652094] (9,-1; 2,-1), time: 28.0396s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_50, [-0.42373374104499817,0.5180514454841614]=>[-0.12454462082497483,0.2508747310813187] (9,-1; 9,-1), time: 30.4760s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_145, [-0.2612704932689667,0.5253955125808716]=>[1e-05,0.5253955125808716] (15,-1; -1,-1), time: 7.7720s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_92, [-0.46676546335220337,0.43601781129837036]=>[-0.20826061070970187,0.1645926644841115] (2,-1; 9,-1), time: 27.3630s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_19, [-0.5918565988540649,0.32675695419311523]=>[-0.32037553228298576,0.031064557203507988] (9,-1; 2,-1), time: 23.1880s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_48, [-0.8001965880393982,0.6181714534759521]=>[-0.37236434458769235,0.284007380376158] (2,-1; 2,-1), time: 14.2662s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_150, [-0.5836459398269653,0.5229887366294861]=>[-0.2617222093807462,0.2075119000420795] (2,-1; 9,-1), time: 21.7499s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_44, [-0.5744338631629944,0.3314839005470276]=>[-0.268609284416648,0.08723761415386155] (9,-1; 9,-1), time: 30.0271s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_49, [-0.49067994952201843,0.30133673548698425]=>[-0.1887576428672368,0.114197542549959] (9,-1; 9,-1), time: 30.0185s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_133, [-0.6312988996505737,0.3437900245189667]=>[-0.36553891890119355,0.04989078206869848] (2,-1; 9,-1), time: 19.9408s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_37, [-0.6204115748405457,0.5750343799591064]=>[-0.3058193551128789,0.254093738681786] (2,-1; 9,-1), time: 21.2492s, #vars: 1757, #constrs: 1058, improved: True
Solving MIP for lay8_129, [-0.6478503346443176,0.6049216985702515]=>[-0.30364157649245677,0.3264574173197652] (9,-1; 2,-1), time: 24.2841s, #vars: 1757, #constrs: 1058, improved: True
Run alpha-CROWN after refining layer 6 and relu idx 2
0 /21 torch.Size([1, 200])
1 /23 torch.Size([1, 200])
2 /25 torch.Size([1, 200])
best_l after optimization: -23.326250076293945 with beta sum per layer: []
alpha/beta optimization time: 7.937576055526733
alpha-CROWN with intermediate bounds by MIP: tensor([[ 5.5076,  4.6079,  2.7321, -1.4369,  3.6338,  1.5022,  5.7850,  2.6335,
         -1.6389]], device='cuda:0', grad_fn=<AsStridedBackward>) None
MIP improved 92 nodes out of 92 unstable nodes, lb improved 13.323647499084473, ub improved 14.849152565002441, time 74.4968
maximum relu layer improved by MIP so far 3
Linear(in_features=200, out_features=200, bias=True) 4 10 torch.Size([200])
sorted candidates ['lay10_142', 'lay10_94', 'lay10_33', 'lay10_187', 'lay10_88', 'lay10_119', 'lay10_149', 'lay10_190', 'lay10_95', 'lay10_150', 'lay10_49', 'lay10_101', 'lay10_132', 'lay10_57', 'lay10_193', 'lay10_117', 'lay10_44', 'lay10_125', 'lay10_109', 'lay10_159', 'lay10_140', 'lay10_154', 'lay10_115', 'lay10_30', 'lay10_195', 'lay10_17', 'lay10_122', 'lay10_38', 'lay10_155', 'lay10_3', 'lay10_198', 'lay10_180', 'lay10_186', 'lay10_6', 'lay10_118', 'lay10_18', 'lay10_86', 'lay10_80', 'lay10_91', 'lay10_83', 'lay10_82', 'lay10_66', 'lay10_137', 'lay10_90', 'lay10_106', 'lay10_75', 'lay10_145', 'lay10_116', 'lay10_23', 'lay10_156', 'lay10_170', 'lay10_55', 'lay10_60', 'lay10_64', 'lay10_134', 'lay10_59', 'lay10_42', 'lay10_162', 'lay10_26', 'lay10_174', 'lay10_172', 'lay10_123', 'lay10_73', 'lay10_152', 'lay10_99', 'lay10_37', 'lay10_136', 'lay10_96', 'lay10_178', 'lay10_72', 'lay10_24', 'lay10_54', 'lay10_36', 'lay10_15', 'lay10_35', 'lay10_81', 'lay10_61', 'lay10_189', 'lay10_69', 'lay10_41', 'lay10_157', 'lay10_181', 'lay10_107', 'lay10_14', 'lay10_84', 'lay10_146', 'lay10_46', 'lay10_32', 'lay10_143', 'lay10_87', 'lay10_4', 'lay10_102', 'lay10_5', 'lay10_168', 'lay10_185', 'lay10_12', 'lay10_40', 'lay10_139', 'lay10_85', 'lay10_68', 'lay10_43', 'lay10_103', 'lay10_113', 'lay10_131', 'lay10_78', 'lay10_110', 'lay10_151', 'lay10_141', 'lay10_51', 'lay10_184', 'lay10_128', 'lay10_62', 'lay10_171', 'lay10_98', 'lay10_63', 'lay10_28', 'lay10_76', 'lay10_39', 'lay10_114', 'lay10_9', 'lay10_11', 'lay10_163', 'lay10_22', 'lay10_48', 'lay10_158', 'lay10_179', 'lay10_166', 'lay10_31', 'lay10_19', 'lay10_74', 'lay10_21', 'lay10_53', 'lay10_45', 'lay10_111', 'lay10_196', 'lay10_138', 'lay10_0', 'lay10_100', 'lay10_130', 'lay10_167', 'lay10_127', 'lay10_92', 'lay10_177', 'lay10_97', 'lay10_52', 'lay10_67', 'lay10_161', 'lay10_27', 'lay10_197', 'lay10_79', 'lay10_34', 'lay10_105', 'lay10_16', 'lay10_108', 'lay10_112', 'lay10_71', 'lay10_58'] filter: 1.0
Solving MIP for lay10_187, [-1.4087327718734741,0.24383270740509033]=>[-1.4087327718734741,-1e-05] (-1,-1; 15,-1), time: 0.3801s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_119, [-1.0623139142990112,0.2729698419570923]=>[-1.0623139142990112,-1e-05] (-1,-1; 15,-1), time: 0.4011s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_117, [-1.3378868103027344,0.32702580094337463]=>[-1.3378868103027344,-1e-05] (-1,-1; 15,-1), time: 0.4223s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_94, [-1.3365862369537354,0.22712284326553345]=>[-1.3365862369537354,-1e-05] (-1,-1; 15,-1), time: 0.4495s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_149, [-0.960179328918457,0.35736310482025146]=>[-0.960179328918457,-1e-05] (-1,-1; 15,-1), time: 0.4650s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_44, [-0.805934727191925,0.43039658665657043]=>[-0.805934727191925,-1e-05] (-1,-1; 15,-1), time: 0.3315s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_150, [-1.3398542404174805,0.5292619466781616]=>[-1.3398542404174805,-1e-05] (-1,-1; 15,-1), time: 0.7608s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_159, [-0.40636202692985535,1.4237602949142456]=>[1e-05,1.4237602949142456] (15,-1; -1,-1), time: 0.3632s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_140, [-1.089721441268921,0.26124224066734314]=>[-1.089721441268921,-1e-05] (-1,-1; 15,-1), time: 0.3853s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_30, [-1.2177234888076782,0.36781272292137146]=>[-1.2177234888076782,-1e-05] (-1,-1; 15,-1), time: 0.3941s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_101, [-1.1606762409210205,0.382109671831131]=>[-1.1606762409210205,-1e-05] (-1,-1; 15,-1), time: 7.8876s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_88, [-0.5031147599220276,0.6199435591697693]=>[1e-05,0.6199435591697693] (15,-1; -1,-1), time: 8.2087s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_195, [-0.3979358673095703,0.9343468546867371]=>[1e-05,0.9343468546867371] (15,-1; -1,-1), time: 10.1320s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_155, [-0.35163870453834534,1.0203728675842285]=>[1e-05,1.0203728675842285] (15,-1; -1,-1), time: 0.4174s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_33, [-1.0640678405761719,0.7296692728996277]=>[-0.5445434699451923,0.10595904356418118] (9,-1; 9,-1), time: 30.0198s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_132, [-0.7810004949569702,0.6721324324607849]=>[-0.2824300716074767,0.1306542660114796] (9,-1; 9,-1), time: 30.0113s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_49, [-1.089878797531128,0.5511413216590881]=>[-0.4551823164176489,0.10036389832146964] (9,-1; 9,-1), time: 30.0601s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_193, [-0.9010873436927795,0.7034419775009155]=>[-0.3919340772710047,0.12657282887984247] (9,-1; 9,-1), time: 30.0919s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_57, [-0.8784493207931519,0.5218194127082825]=>[-0.3233435028806513,0.10123926679022147] (9,-1; 9,-1), time: 30.2026s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_142, [-0.5874006152153015,0.9168239235877991]=>[-0.11459548689761107,0.3252207598763862] (9,-1; 9,-1), time: 30.2731s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_190, [-0.5168214440345764,0.8976753354072571]=>[-0.09201677318827169,0.3728514113895979] (9,-1; 9,-1), time: 30.2984s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_180, [-0.9857569932937622,0.2927423119544983]=>[-0.9857569932937622,-1e-05] (-1,-1; 15,-1), time: 0.3298s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_109, [-1.305873990058899,0.7391932010650635]=>[-0.7201617045934983,0.009256890095233514] (9,-1; 9,-1), time: 30.0262s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_95, [-0.5672593712806702,0.8821658492088318]=>[-0.08167008764149737,0.3712858148625112] (9,-1; 9,-1), time: 30.5109s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_18, [-1.2872891426086426,0.43888163566589355]=>[-1.2872891426086426,-1e-05] (-1,-1; 15,-1), time: 0.3511s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_198, [-0.9822670221328735,0.4642055034637451]=>[-0.9822670221328735,-1e-05] (-1,-1; 15,-1), time: 0.6273s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_154, [-1.3093950748443604,1.0662662982940674]=>[-0.6353555691167699,0.31542277537592606] (9,-1; 9,-1), time: 30.0111s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_125, [-0.8321727514266968,0.5196329355239868]=>[-0.31412793681572576,0.026007165133111836] (9,-1; 9,-1), time: 30.3402s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_115, [-0.6856575608253479,0.7151001691818237]=>[-0.23739039205948534,0.15895529931795566] (9,-1; 9,-1), time: 30.0329s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_82, [-0.45230069756507874,1.031499981880188]=>[1e-05,1.031499981880188] (15,-1; -1,-1), time: 0.3423s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_66, [-1.170185923576355,0.4380040764808655]=>[-1.170185923576355,-1e-05] (-1,-1; 15,-1), time: 0.3316s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_90, [-0.23979096114635468,1.092256784439087]=>[1e-05,1.092256784439087] (15,-1; -1,-1), time: 0.4452s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_106, [-1.2237462997436523,0.18851283192634583]=>[-1.2237462997436523,-1e-05] (-1,-1; 15,-1), time: 0.4000s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_145, [-0.05601814389228821,1.4796334505081177]=>[1e-05,1.4796334505081177] (15,-1; -1,-1), time: 0.3330s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_75, [-1.0261582136154175,0.3243683874607086]=>[-1.0261582136154175,-1e-05] (-1,-1; 15,-1), time: 0.3468s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_17, [-0.6857247948646545,0.6570348143577576]=>[-0.11072125785314481,0.23991757995395357] (9,-1; 9,-1), time: 30.1120s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_23, [-1.3997900485992432,0.04579430818557739]=>[-1.3997900485992432,-1e-05] (-1,-1; 15,-1), time: 0.3996s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_170, [-1.8540195226669312,0.30403217673301697]=>[-1.8540195226669312,-1e-05] (-1,-1; 15,-1), time: 0.3224s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_156, [-1.4250259399414062,0.04508841037750244]=>[-1.4250259399414062,-1e-05] (-1,-1; 15,-1), time: 0.3355s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_64, [-0.982416033744812,0.3481879234313965]=>[-0.982416033744812,-1e-05] (-1,-1; 15,-1), time: 0.3418s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_6, [-0.9072203040122986,0.483692467212677]=>[-0.9072203040122986,-1e-05] (-1,-1; 15,-1), time: 8.2295s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_122, [-0.5746501088142395,0.708000898361206]=>[-0.0020770282666139994,0.3966175613599861] (9,-1; 9,-1), time: 30.5398s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_42, [-1.1962445974349976,0.38783490657806396]=>[-1.1962445974349976,-1e-05] (-1,-1; 15,-1), time: 0.3459s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_162, [-1.0556517839431763,0.2869928777217865]=>[-1.0556517839431763,-1e-05] (-1,-1; 15,-1), time: 0.3768s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_38, [-0.7547677159309387,0.5229658484458923]=>[-0.21638861770928397,0.13337913412825964] (9,-1; 9,-1), time: 30.6990s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_26, [-1.2379318475723267,0.3623107671737671]=>[-1.2379318475723267,-1e-05] (-1,-1; 15,-1), time: 0.3473s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_123, [-0.5437098145484924,1.1755352020263672]=>[1e-05,1.1755352020263672] (15,-1; -1,-1), time: 0.3555s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_172, [-0.5208225250244141,1.2185935974121094]=>[1e-05,1.2185935974121094] (15,-1; -1,-1), time: 0.7134s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_73, [-0.5683442950248718,0.8062382340431213]=>[1e-05,0.8062382340431213] (15,-1; -1,-1), time: 0.7292s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_99, [-0.38855671882629395,1.0972834825515747]=>[1e-05,1.0972834825515747] (15,-1; -1,-1), time: 0.3585s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_83, [-0.8616983890533447,0.39480751752853394]=>[-0.8616983890533447,-1e-05] (-1,-1; 15,-1), time: 10.1684s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_37, [-1.0883760452270508,0.24766479432582855]=>[-1.0883760452270508,-1e-05] (-1,-1; 15,-1), time: 0.3545s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_96, [-0.9379293918609619,0.3587484359741211]=>[-0.9379293918609619,-1e-05] (-1,-1; 15,-1), time: 0.3354s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_3, [-0.6713420748710632,0.6768830418586731]=>[-0.1514009924961439,0.2782936358538913] (9,-1; 9,-1), time: 30.0298s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_72, [-0.4902775287628174,1.716543436050415]=>[1e-05,1.716543436050415] (15,-1; -1,-1), time: 0.3765s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_186, [-0.5958938002586365,1.216915249824524]=>[1e-05,1.216915249824524] (15,-1; -1,-1), time: 12.1969s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_24, [-0.4777066707611084,0.9361852407455444]=>[1e-05,0.9361852407455444] (15,-1; -1,-1), time: 0.4278s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_36, [-1.4337977170944214,0.068148672580719]=>[-1.4337977170944214,-1e-05] (-1,-1; 15,-1), time: 0.4012s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_136, [-0.5361376404762268,0.903339147567749]=>[1e-05,0.903339147567749] (15,-1; -1,-1), time: 9.6086s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_116, [-1.180902361869812,0.7255644798278809]=>[-0.5516131842295734,0.24227766811043933] (9,-1; 2,-1), time: 22.6721s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_91, [-0.5434965491294861,0.7182576656341553]=>[-0.04904674883777028,0.2792410820249609] (9,-1; 9,-1), time: 30.0410s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_86, [-0.9896794557571411,0.4679968059062958]=>[-0.4337166479234973,0.07397488150832215] (9,-1; 9,-1), time: 30.2152s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_80, [-0.7242562174797058,0.49773484468460083]=>[-0.24711947782181348,0.13038670441882153] (9,-1; 9,-1), time: 30.1600s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_137, [-0.926813542842865,1.2353041172027588]=>[-0.21761211448710086,0.528377986437806] (9,-1; 9,-1), time: 30.0204s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_69, [-1.0395926237106323,0.25722193717956543]=>[-1.0395926237106323,-1e-05] (-1,-1; 15,-1), time: 0.3366s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_118, [-0.5886452198028564,0.800672173500061]=>[-0.13062041889840406,0.3271271247604591] (9,-1; 9,-1), time: 30.6835s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_61, [-1.1983731985092163,0.19049426913261414]=>[-1.1983731985092163,-1e-05] (-1,-1; 15,-1), time: 0.4738s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_41, [-1.4565492868423462,0.0324593186378479]=>[-1.4565492868423462,-1e-05] (-1,-1; 15,-1), time: 0.3452s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_181, [-1.3190525770187378,0.07859912514686584]=>[-1.3190525770187378,-1e-05] (-1,-1; 15,-1), time: 0.3718s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_55, [-0.6991865634918213,0.5064926743507385]=>[-0.17178377026414376,0.16561180836663397] (9,-1; 9,-1), time: 30.0116s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_107, [-0.442314475774765,0.9024016261100769]=>[1e-05,0.9024016261100769] (15,-1; -1,-1), time: 0.4337s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_84, [-0.9169557690620422,0.2011035680770874]=>[-0.9169557690620422,-1e-05] (-1,-1; 15,-1), time: 0.4245s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_134, [-0.6921412944793701,0.6377279758453369]=>[-0.13060841846387689,0.25116130436574313] (9,-1; 9,-1), time: 30.0638s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_157, [-1.1903398036956787,0.4605812132358551]=>[-1.1903398036956787,-1e-05] (-1,-1; 15,-1), time: 0.8911s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_60, [-0.8814663887023926,0.44647079706192017]=>[-0.30496962390643517,0.07183454917803002] (9,-1; 9,-1), time: 30.2257s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_59, [-1.0193129777908325,0.52586430311203]=>[-0.5085136722702978,0.0036866367190055097] (9,-1; 9,-1), time: 30.0289s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_87, [-0.3307172656059265,1.114063024520874]=>[1e-05,1.114063024520874] (15,-1; -1,-1), time: 0.3184s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_32, [-1.1483689546585083,0.06458041071891785]=>[-1.1483689546585083,-1e-05] (-1,-1; 15,-1), time: 0.4705s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_5, [-0.3727678656578064,1.018643856048584]=>[1e-05,1.018643856048584] (15,-1; -1,-1), time: 0.3351s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_168, [-0.2253745198249817,1.1401290893554688]=>[1e-05,1.1401290893554688] (15,-1; -1,-1), time: 0.3933s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_189, [-0.46817007660865784,1.0537726879119873]=>[1e-05,1.0537726879119873] (15,-1; -1,-1), time: 6.6283s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_174, [-0.562074601650238,0.5331634879112244]=>[-0.19207468920507717,0.09635833507842892] (9,-1; 9,-1), time: 30.2798s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_146, [-1.2152982950210571,0.4183126986026764]=>[-1.2152982950210571,-1e-05] (-1,-1; 15,-1), time: 7.8578s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_12, [-1.1175541877746582,0.5430659055709839]=>[-1.1175541877746582,-1e-05] (-1,-1; 15,-1), time: 6.6790s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_139, [-1.1465272903442383,0.14784011244773865]=>[-1.1465272903442383,-1e-05] (-1,-1; 15,-1), time: 0.4670s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_68, [-1.3044987916946411,0.01865781471133232]=>[-1.3044987916946411,-1e-05] (-1,-1; 15,-1), time: 0.3905s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_43, [-1.3058853149414062,0.2793380618095398]=>[-1.3058853149414062,-1e-05] (-1,-1; 15,-1), time: 0.4242s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_103, [-0.8461353778839111,0.3189856708049774]=>[-0.8461353778839111,-1e-05] (-1,-1; 15,-1), time: 0.3632s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_152, [-0.7286375761032104,0.5952998399734497]=>[-0.2722211805969414,0.05142151281242632] (9,-1; 9,-1), time: 30.5353s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_113, [-1.1165181398391724,0.19924917817115784]=>[-1.1165181398391724,-1e-05] (-1,-1; 15,-1), time: 0.4101s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_131, [-1.181850552558899,0.04449497535824776]=>[-1.181850552558899,-1e-05] (-1,-1; 15,-1), time: 0.3927s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_78, [-1.5974854230880737,0.005277872085571289]=>[-1.5974854230880737,-1e-05] (-1,-1; 15,-1), time: 0.3883s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_110, [-1.2448580265045166,0.20406953990459442]=>[-1.2448580265045166,-1e-05] (-1,-1; 15,-1), time: 0.4693s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_151, [-0.21914248168468475,1.018066167831421]=>[1e-05,1.018066167831421] (15,-1; -1,-1), time: 0.4586s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_141, [-0.24325473606586456,1.1688717603683472]=>[1e-05,1.1688717603683472] (15,-1; -1,-1), time: 0.4262s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_178, [-0.962027370929718,0.4270012378692627]=>[-0.41833493965727253,0.004922725239359126] (9,-1; 9,-1), time: 30.0805s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_51, [-1.4221360683441162,0.24570488929748535]=>[-1.4221360683441162,-1e-05] (-1,-1; 15,-1), time: 0.4239s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_128, [-1.164841890335083,0.26181891560554504]=>[-1.164841890335083,-1e-05] (-1,-1; 15,-1), time: 0.3758s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_184, [-1.146256923675537,0.24729084968566895]=>[-1.146256923675537,-1e-05] (-1,-1; 15,-1), time: 0.4558s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_62, [-1.1617363691329956,0.1118762195110321]=>[-1.1617363691329956,-1e-05] (-1,-1; 15,-1), time: 0.3291s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_98, [-0.1187671422958374,1.3899149894714355]=>[1e-05,1.3899149894714355] (15,-1; -1,-1), time: 0.4202s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_76, [-1.2969313859939575,0.03863831236958504]=>[-1.2969313859939575,-1e-05] (-1,-1; 15,-1), time: 0.3769s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_54, [-0.801873505115509,0.49364620447158813]=>[-0.3233886574493068,0.042295258138506465] (9,-1; 9,-1), time: 30.2304s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_39, [-0.24622021615505219,1.1449106931686401]=>[1e-05,1.1449106931686401] (15,-1; -1,-1), time: 0.3867s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_114, [-1.0852043628692627,0.15521645545959473]=>[-1.0852043628692627,-1e-05] (-1,-1; 15,-1), time: 0.4456s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_15, [-1.0028975009918213,0.45238277316093445]=>[-0.2983262008202169,0.08296501650535365] (9,-1; 9,-1), time: 30.3097s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_9, [-0.14371025562286377,1.0288118124008179]=>[1e-05,1.0288118124008179] (15,-1; -1,-1), time: 0.4110s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_11, [-0.24860835075378418,2.486112594604492]=>[1e-05,2.486112594604492] (15,-1; -1,-1), time: 0.4447s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_163, [-0.9033091068267822,0.31990307569503784]=>[-0.9033091068267822,-1e-05] (-1,-1; 15,-1), time: 0.6873s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_48, [-1.1420392990112305,0.0842847228050232]=>[-1.1420392990112305,-1e-05] (-1,-1; 15,-1), time: 0.4108s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_158, [-1.099001407623291,0.3463824987411499]=>[-1.099001407623291,-1e-05] (-1,-1; 15,-1), time: 0.3822s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_40, [-0.5066324472427368,0.7870273590087891]=>[1e-05,0.7870273590087891] (15,-1; -1,-1), time: 10.4376s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_35, [-0.6411981582641602,0.6803418397903442]=>[-0.05133153758063365,0.2834690911909044] (9,-1; 9,-1), time: 30.2204s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_81, [-1.0039796829223633,0.696455717086792]=>[-0.4047891359555731,0.12240530675684684] (9,-1; 9,-1), time: 30.1870s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_166, [-0.9752957224845886,0.35416141152381897]=>[-0.9752957224845886,-1e-05] (-1,-1; 15,-1), time: 10.4037s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_74, [-0.03827643394470215,1.6942495107650757]=>[1e-05,1.6942495107650757] (15,-1; -1,-1), time: 0.4263s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_21, [-1.2266513109207153,0.004976928234100342]=>[-1.2266513109207153,-1e-05] (-1,-1; 15,-1), time: 0.3881s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_53, [-1.0889089107513428,0.4687725305557251]=>[-1.0889089107513428,-1e-05] (-1,-1; 15,-1), time: 0.4122s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_45, [-1.600893259048462,0.021549534052610397]=>[-1.600893259048462,-1e-05] (-1,-1; 15,-1), time: 0.3815s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_14, [-0.8409594893455505,1.006311058998108]=>[-0.2774667761682423,0.49060050735264654] (9,-1; 2,-1), time: 24.2419s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_111, [-0.9669122695922852,0.2621707320213318]=>[-0.9669122695922852,-1e-05] (-1,-1; 15,-1), time: 0.4077s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_196, [-0.3316565752029419,1.009771466255188]=>[1e-05,1.009771466255188] (15,-1; -1,-1), time: 0.4008s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_138, [-0.09862303733825684,1.275917887687683]=>[1e-05,1.275917887687683] (15,-1; -1,-1), time: 0.3424s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_0, [-1.0167039632797241,0.3245347738265991]=>[-1.0167039632797241,-1e-05] (-1,-1; 15,-1), time: 0.3874s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_130, [-0.9324235320091248,0.20786985754966736]=>[-0.9324235320091248,-1e-05] (-1,-1; 15,-1), time: 0.3525s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_100, [-1.0117403268814087,0.22011390328407288]=>[-1.0117403268814087,-1e-05] (-1,-1; 15,-1), time: 0.4159s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_167, [-0.08346754312515259,1.653425693511963]=>[1e-05,1.653425693511963] (15,-1; -1,-1), time: 0.4315s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_127, [-0.0994962602853775,1.2253209352493286]=>[1e-05,1.2253209352493286] (15,-1; -1,-1), time: 0.3308s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_177, [-0.16333693265914917,1.3065879344940186]=>[1e-05,1.3065879344940186] (15,-1; -1,-1), time: 0.3918s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_97, [-0.013213900849223137,2.422356605529785]=>[1e-05,2.422356605529785] (15,-1; -1,-1), time: 0.3271s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_52, [-1.5147569179534912,0.12659788131713867]=>[-1.5147569179534912,-1e-05] (-1,-1; 15,-1), time: 0.4320s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_161, [-1.2286800146102905,0.13808439671993256]=>[-1.2286800146102905,-1e-05] (-1,-1; 15,-1), time: 0.4459s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_102, [-0.6919719576835632,1.0914709568023682]=>[-0.07736242950361076,0.5798863084705183] (9,-1; 2,-1), time: 25.7847s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_27, [-1.1372450590133667,0.1385844647884369]=>[-1.1372450590133667,-1e-05] (-1,-1; 15,-1), time: 0.3855s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_197, [-1.3938558101654053,0.08082789182662964]=>[-1.3938558101654053,-1e-05] (-1,-1; 15,-1), time: 0.3203s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_34, [-0.9520168304443359,0.2890046238899231]=>[-0.9520168304443359,-1e-05] (-1,-1; 15,-1), time: 0.3278s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_105, [-1.1648170948028564,0.2887812852859497]=>[-1.1648170948028564,-1e-05] (-1,-1; 15,-1), time: 0.3235s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_16, [-1.4613604545593262,0.263159841299057]=>[-1.4613604545593262,-1e-05] (-1,-1; 15,-1), time: 0.3299s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_108, [-1.0727856159210205,0.22246432304382324]=>[-1.0727856159210205,-1e-05] (-1,-1; 15,-1), time: 0.3311s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_112, [-1.4145219326019287,0.06014905497431755]=>[-1.4145219326019287,-1e-05] (-1,-1; 15,-1), time: 0.3304s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_71, [-1.159529685974121,0.23377841711044312]=>[-1.159529685974121,-1e-05] (-1,-1; 15,-1), time: 0.3285s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_46, [-0.7428494691848755,0.6330903172492981]=>[-0.262501680983963,0.15975278353920894] (9,-1; 9,-1), time: 30.4420s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_143, [-0.7892788052558899,0.6607455015182495]=>[-0.27015600461343964,0.16031501341676585] (9,-1; 9,-1), time: 30.3312s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_4, [-0.6983298659324646,0.6935952305793762]=>[-0.009593095577566046,0.41383680903924147] (9,-1; 9,-1), time: 30.4123s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_185, [-0.6531789898872375,0.6390934586524963]=>[-0.1297731968949156,0.23292932537753933] (9,-1; 9,-1), time: 30.0077s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_85, [-0.7821055054664612,0.48457974195480347]=>[-0.2676266651171408,0.0698284649788613] (9,-1; 9,-1), time: 30.3080s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_63, [-0.8605067729949951,0.49686047434806824]=>[-0.1793545443644642,0.166845867154653] (9,-1; 9,-1), time: 30.2605s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_171, [-0.9292686581611633,0.42059916257858276]=>[-0.360862646689534,0.04715719480319277] (9,-1; 9,-1), time: 30.3475s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_28, [-0.5797677040100098,0.9093737602233887]=>[-0.10866829378762867,0.3357651177205109] (9,-1; 9,-1), time: 30.2742s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_22, [-0.6819033026695251,0.5854290723800659]=>[-0.14770926516235466,0.16632260010426414] (9,-1; 9,-1), time: 30.2646s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_179, [-0.46934133768081665,0.7367982864379883]=>[-0.014633976709697478,0.385202907392173] (9,-1; 9,-1), time: 30.0244s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_31, [-0.5670074224472046,1.0337871313095093]=>[-0.0637484467596434,0.5415261060951564] (9,-1; 9,-1), time: 30.1458s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_19, [-0.7874838709831238,0.9043834209442139]=>[-0.18886275537268593,0.39138881532352454] (9,-1; 9,-1), time: 30.0208s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_92, [-0.7162617444992065,0.607392430305481]=>[-0.15529824640649365,0.25246561775378806] (9,-1; 9,-1), time: 30.1839s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_67, [-0.6742819547653198,0.9178399443626404]=>[-0.05974425956387961,0.5029077623135515] (9,-1; 9,-1), time: 30.0217s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_79, [-1.0418425798416138,0.3735411763191223]=>[-0.4229091930511985,0.049786624882195804] (9,-1; 9,-1), time: 30.2689s, #vars: 2029, #constrs: 1366, improved: True
Solving MIP for lay10_58, [-0.8504852056503296,0.6187788844108582]=>[-0.3197550390401953,0.13566804459732848] (9,-1; 9,-1), time: 30.0674s, #vars: 2029, #constrs: 1366, improved: True
Run alpha-CROWN after refining layer 8 and relu idx 3
0 /21 torch.Size([1, 200])
1 /23 torch.Size([1, 200])
2 /25 torch.Size([1, 200])
3 /27 torch.Size([1, 200])
best_l after optimization: -28.88295555114746 with beta sum per layer: []
alpha/beta optimization time: 7.454564332962036
alpha-CROWN with intermediate bounds by MIP: tensor([[ 6.2570,  5.0440,  3.3632, -0.9506,  4.3337,  2.0514,  6.3200,  3.3611,
         -0.8968]], device='cuda:0', grad_fn=<AsStridedBackward>) None
MIP improved 157 nodes out of 157 unstable nodes, lb improved 38.73822021484375, ub improved 41.56317901611328, time 120.9710
maximum relu layer improved by MIP so far 4
Linear(in_features=200, out_features=10, bias=True) 5 12 torch.Size([10])
MIP finished with 226.89964628219604s
Run final alpha-CROWN after MIP solving on layer 12 and relu idx 5
0 /21 torch.Size([1, 200])
1 /23 torch.Size([1, 200])
2 /25 torch.Size([1, 200])
3 /27 torch.Size([1, 200])
4 /29 torch.Size([1, 200])
best_l after optimization: -30.5587100982666 with beta sum per layer: []
alpha/beta optimization time: 5.839445352554321
alpha-CROWN with intermediate bounds improved by MIP: tensor([[ 6.4040,  5.1391,  3.5269, -0.7564,  4.5554,  2.2513,  6.4953,  3.5864,
         -0.6432]], device='cuda:0', grad_fn=<AsStridedBackward>) None
refined global lb: tensor([[ 6.4040,  5.1391,  3.5269, -0.7564,  4.5554,  2.2513,  6.4953,  3.5864,
          0.0000, -0.6432]], device='cuda:0') min: tensor(-0.7564, device='cuda:0')
time threshold left for bab: 658.3007035255432
##### [0:465] Tested against 9 ######
Model prediction is: tensor([[-3.3627, -1.7483, -0.2121,  4.2042, -2.1517,  0.6109, -3.6509, -1.1626,
          5.1091,  2.7416]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /22 start_node /23
setting alpha for layer /22 start_node /25
setting alpha for layer /22 start_node /27
setting alpha for layer /22 start_node /29
not setting layer /22 start_node /31 because shape mismatch (torch.Size([2, 1, 1, 200]) != torch.Size([2, 9, 1, 200]))
setting alpha for layer /24 start_node /25
setting alpha for layer /24 start_node /27
setting alpha for layer /24 start_node /29
not setting layer /24 start_node /31 because shape mismatch (torch.Size([2, 1, 1, 200]) != torch.Size([2, 9, 1, 200]))
setting alpha for layer /26 start_node /27
setting alpha for layer /26 start_node /29
not setting layer /26 start_node /31 because shape mismatch (torch.Size([2, 1, 1, 200]) != torch.Size([2, 9, 1, 200]))
setting alpha for layer /28 start_node /29
not setting layer /28 start_node /31 because shape mismatch (torch.Size([2, 1, 1, 200]) != torch.Size([2, 9, 1, 200]))
not setting layer /30 start_node /31 because shape mismatch (torch.Size([2, 1, 1, 200]) != torch.Size([2, 9, 1, 200]))
0 /21 torch.Size([1, 200])
1 /23 torch.Size([1, 200])
2 /25 torch.Size([1, 200])
3 /27 torch.Size([1, 200])
4 /29 torch.Size([1, 200])
best_l after optimization: 0.6432336568832397 with beta sum per layer: []
alpha/beta optimization time: 1.706651210784912
alpha-CROWN with fixed intermediate bounds: tensor([[-0.6432]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.6432336568832397
layer 0 size torch.Size([200]) unstable 16
layer 1 size torch.Size([200]) unstable 29
layer 2 size torch.Size([200]) unstable 41
layer 3 size torch.Size([200]) unstable 36
layer 4 size torch.Size([200]) unstable 51
-----------------
# of unstable neurons: 173
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 200]) pre split depth:  6
batch:  torch.Size([1, 200]) post split depth:  6
splitting decisions: 
split level 0: [0, 119] 
split level 1: [4, 154] 
split level 2: [3, 65] 
split level 3: [2, 45] 
split level 4: [0, 132] 
split level 5: [1, 174] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: -9.732954025268555 with beta sum per layer: [4.907920837402344, 0.07461200654506683, 1.747371792793274, 1.716448187828064, 1.84102201461792]
alpha/beta optimization time: 0.3580615520477295
This batch time : update_bounds func: 0.3734	 prepare: 0.0077	 bound: 0.3585	 transfer: 0.0009	 finalize: 0.0062
Accumulated time: update_bounds func: 0.3734	 prepare: 0.0077	 bound: 0.3585	 transfer: 0.0009	 finalize: 0.0062
batch bounding time:  0.3736107349395752
Current worst splitting domains [lb, ub] (depth):
[-0.39959,   inf] (7), [-0.35674,   inf] (7), [-0.17976,   inf] (7), [-0.14989,   inf] (7), [-0.11056,   inf] (7), [-0.09082,   inf] (7), 
length of domains: 6
Total time: 0.4343	 pickout: 0.0012	 decision: 0.0486	 get_bound: 0.3840	 add_domain: 0.0005
Current lb:-0.39958834648132324
64 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.595247268676758

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([6, 200]) pre split depth:  4
batch:  torch.Size([6, 200]) post split depth:  4
splitting decisions: 
split level 0: [0, 45] [4, 14] [0, 45] [4, 14] [0, 45] [4, 14] 
split level 1: [1, 195] [1, 195] [1, 195] [1, 195] [1, 195] [1, 195] 
split level 2: [3, 129] [3, 129] [3, 129] [3, 129] [3, 129] [3, 129] 
split level 3: [3, 58] [3, 58] [3, 58] [3, 58] [3, 58] [3, 58] 
regular batch size: 2*48, diving batch size 1*0
best_l after optimization: -15.378606796264648 with beta sum per layer: [44.61140441894531, 3.5904643535614014, 0.0, 10.242279052734375, 1.0160622596740723]
alpha/beta optimization time: 0.37198543548583984
This batch time : update_bounds func: 0.3984	 prepare: 0.0154	 bound: 0.3724	 transfer: 0.0010	 finalize: 0.0093
Accumulated time: update_bounds func: 0.7718	 prepare: 0.0231	 bound: 0.7309	 transfer: 0.0010	 finalize: 0.0155
batch bounding time:  0.3986489772796631
Current worst splitting domains [lb, ub] (depth):
[-0.35343,   inf] (12), [-0.33530,   inf] (12), [-0.19607,   inf] (12), [-0.14565,   inf] (12), [-0.11732,   inf] (12), [-0.10845,   inf] (12), [-0.06828,   inf] (12), [-0.01251,   inf] (12), [-0.00932,   inf] (12), [-0.00713,   inf] (12), 
length of domains: 10
Total time: 0.4507	 pickout: 0.0020	 decision: 0.0353	 get_bound: 0.4127	 add_domain: 0.0007
Current lb:-0.35343387722969055
160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.0467138290405273

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([10, 200]) pre split depth:  3
batch:  torch.Size([10, 200]) post split depth:  3
splitting decisions: 
split level 0: [4, 14] [0, 158] [4, 14] [0, 158] [4, 14] [4, 19] [4, 14] [0, 158] [4, 14] [0, 158] 
split level 1: [4, 19] [4, 19] [4, 19] [4, 19] [4, 19] [0, 158] [4, 19] [4, 19] [0, 158] [4, 19] 
split level 2: [0, 158] [0, 42] [2, 3] [2, 3] [3, 37] [0, 42] [0, 158] [0, 146] [4, 19] [0, 42] 
regular batch size: 2*40, diving batch size 1*0
best_l after optimization: -11.568181991577148 with beta sum per layer: [31.980331420898438, 4.030673980712891, 0.6054475903511047, 28.195571899414062, 2.938204050064087]
alpha/beta optimization time: 0.35616016387939453
This batch time : update_bounds func: 0.3789	 prepare: 0.0137	 bound: 0.3566	 transfer: 0.0009	 finalize: 0.0074
Accumulated time: update_bounds func: 1.1507	 prepare: 0.0368	 bound: 1.0874	 transfer: 0.0009	 finalize: 0.0229
batch bounding time:  0.3790898323059082
Current worst splitting domains [lb, ub] (depth):
[-0.30430,   inf] (16), [-0.23321,   inf] (16), [-0.19389,   inf] (16), [-0.14308,   inf] (16), [-0.06085,   inf] (16), [-0.03561,   inf] (16), [-0.00537,   inf] (16), 
length of domains: 7
Total time: 0.4226	 pickout: 0.0028	 decision: 0.0296	 get_bound: 0.3897	 add_domain: 0.0006
Current lb:-0.3043033182621002
240 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.47012996673584

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([7, 200]) pre split depth:  3
batch:  torch.Size([7, 200]) post split depth:  3
splitting decisions: 
split level 0: [1, 56] [0, 146] [0, 146] [0, 158] [0, 158] [3, 37] [0, 146] 
split level 1: [3, 111] [3, 37] [3, 37] [3, 111] [3, 111] [3, 111] [3, 37] 
split level 2: [3, 37] [1, 56] [1, 56] [3, 37] [1, 56] [3, 135] [1, 56] 
regular batch size: 2*28, diving batch size 1*0
best_l after optimization: -3.0227909088134766 with beta sum per layer: [21.733165740966797, 23.47026824951172, 0.0, 32.850563049316406, 0.0]
alpha/beta optimization time: 0.35660624504089355
This batch time : update_bounds func: 0.3735	 prepare: 0.0101	 bound: 0.3570	 transfer: 0.0009	 finalize: 0.0054
Accumulated time: update_bounds func: 1.5243	 prepare: 0.0470	 bound: 1.4444	 transfer: 0.0009	 finalize: 0.0282
batch bounding time:  0.3737220764160156
Current worst splitting domains [lb, ub] (depth):
[-0.22089,   inf] (20), [-0.12296,   inf] (20), [-0.12179,   inf] (20), [-0.11821,   inf] (20), [-0.10471,   inf] (20), [-0.07829,   inf] (20), [-0.04774,   inf] (20), [-0.03788,   inf] (20), [-0.03308,   inf] (20), [-0.00501,   inf] (20), [-0.00272,   inf] (20), 
length of domains: 11
Total time: 0.4121	 pickout: 0.0022	 decision: 0.0276	 get_bound: 0.3814	 add_domain: 0.0009
Current lb:-0.22088739275932312
296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.8828513622283936

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([11, 200]) pre split depth:  3
batch:  torch.Size([11, 200]) post split depth:  3
splitting decisions: 
split level 0: [1, 166] [1, 166] [0, 146] [1, 166] [2, 123] [1, 166] [2, 99] [3, 111] [1, 56] [1, 80] 
split level 1: [1, 120] [3, 111] [1, 80] [1, 120] [1, 80] [3, 111] [3, 135] [3, 135] [0, 146] [0, 146] 
split level 2: [3, 135] [3, 135] [3, 135] [3, 135] [3, 135] [3, 135] [3, 28] [0, 93] [3, 135] [3, 135] 
regular batch size: 2*44, diving batch size 1*0
best_l after optimization: -6.987675666809082 with beta sum per layer: [8.669780731201172, 59.10088348388672, 0.0, 60.483299255371094, 0.0]
alpha/beta optimization time: 0.35617899894714355
This batch time : update_bounds func: 0.3817	 prepare: 0.0149	 bound: 0.3566	 transfer: 0.0014	 finalize: 0.0084
Accumulated time: update_bounds func: 1.9060	 prepare: 0.0619	 bound: 1.8010	 transfer: 0.0014	 finalize: 0.0366
batch bounding time:  0.381974458694458
Current worst splitting domains [lb, ub] (depth):
[-0.12647,   inf] (24), [-0.12166,   inf] (24), [-0.02609,   inf] (24), [-0.02229,   inf] (24), 
length of domains: 4
Total time: 0.4311	 pickout: 0.0029	 decision: 0.0334	 get_bound: 0.3943	 add_domain: 0.0005
Current lb:-0.12646673619747162
384 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.3148887157440186

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([4, 200]) pre split depth:  4
batch:  torch.Size([4, 200]) post split depth:  4
splitting decisions: 
split level 0: [2, 123] [2, 123] [1, 120] [2, 123] 
split level 1: [2, 3] [0, 146] [2, 3] [1, 120] 
split level 2: [3, 28] [2, 97] [3, 28] [2, 97] 
split level 3: [2, 97] [3, 28] [2, 97] [3, 28] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: -8.184371948242188 with beta sum per layer: [0.23732653260231018, 30.218914031982422, 2.5849051475524902, 12.823720932006836, 0.0]
alpha/beta optimization time: 0.3569328784942627
This batch time : update_bounds func: 0.3756	 prepare: 0.0111	 bound: 0.3573	 transfer: 0.0011	 finalize: 0.0059
Accumulated time: update_bounds func: 2.2816	 prepare: 0.0730	 bound: 2.1584	 transfer: 0.0011	 finalize: 0.0426
batch bounding time:  0.3757946491241455
Current worst splitting domains [lb, ub] (depth):
[-0.05241,   inf] (29), [-0.04832,   inf] (29), [-0.02761,   inf] (29), [-0.02375,   inf] (29), [-0.02218,   inf] (29), [-0.01207,   inf] (29), [-0.00359,   inf] (29), 
length of domains: 7
Total time: 0.4233	 pickout: 0.0017	 decision: 0.0345	 get_bound: 0.3863	 add_domain: 0.0008
Current lb:-0.052412889897823334
448 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.738817930221558

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([7, 200]) pre split depth:  3
batch:  torch.Size([7, 200]) post split depth:  3
splitting decisions: 
split level 0: [0, 146] [1, 80] [2, 99] [0, 146] [2, 127] [2, 99] [2, 99] 
split level 1: [1, 80] [2, 127] [1, 80] [1, 36] [0, 173] [1, 80] [2, 66] 
split level 2: [2, 85] [2, 85] [1, 137] [0, 173] [2, 85] [1, 137] [2, 85] 
regular batch size: 2*28, diving batch size 1*0

all verified at 0th iter
best_l after optimization: -5.451458930969238 with beta sum per layer: [0.0, 0.0, 16.616369247436523, 35.11423110961914, 0.0]
alpha/beta optimization time: 0.012889385223388672
This batch time : update_bounds func: 0.0296	 prepare: 0.0102	 bound: 0.0132	 transfer: 0.0009	 finalize: 0.0051
Accumulated time: update_bounds func: 2.3112	 prepare: 0.0832	 bound: 2.1716	 transfer: 0.0009	 finalize: 0.0476
batch bounding time:  0.029641389846801758
Current worst splitting domains [lb, ub] (depth):

length of domains: 0
Total time: 0.0679	 pickout: 0.0022	 decision: 0.0278	 get_bound: 0.0379	 add_domain: 0.0000
No domains left, verification finished!
Global ub: inf, batch ub: inf
Cumulative time: 4.8072826862335205

Image 465 label 9 verification end, final lower bound 1.0000000116860974e-07, upper bound inf, time: 4.870579481124878
465 1.0000000116860974e-07
##### [0:465] Tested against 3 ######
Model prediction is: tensor([[-3.3627, -1.7483, -0.2121,  4.2042, -2.1517,  0.6109, -3.6509, -1.1626,
          5.1091,  2.7416]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /22 start_node /23
setting alpha for layer /22 start_node /25
setting alpha for layer /22 start_node /27
setting alpha for layer /22 start_node /29
not setting layer /22 start_node /31 because shape mismatch (torch.Size([2, 1, 1, 200]) != torch.Size([2, 9, 1, 200]))
setting alpha for layer /24 start_node /25
setting alpha for layer /24 start_node /27
setting alpha for layer /24 start_node /29
not setting layer /24 start_node /31 because shape mismatch (torch.Size([2, 1, 1, 200]) != torch.Size([2, 9, 1, 200]))
setting alpha for layer /26 start_node /27
setting alpha for layer /26 start_node /29
not setting layer /26 start_node /31 because shape mismatch (torch.Size([2, 1, 1, 200]) != torch.Size([2, 9, 1, 200]))
setting alpha for layer /28 start_node /29
not setting layer /28 start_node /31 because shape mismatch (torch.Size([2, 1, 1, 200]) != torch.Size([2, 9, 1, 200]))
not setting layer /30 start_node /31 because shape mismatch (torch.Size([2, 1, 1, 200]) != torch.Size([2, 9, 1, 200]))
0 /21 torch.Size([1, 200])
1 /23 torch.Size([1, 200])
2 /25 torch.Size([1, 200])
3 /27 torch.Size([1, 200])
4 /29 torch.Size([1, 200])
best_l after optimization: 0.7564190626144409 with beta sum per layer: []
alpha/beta optimization time: 1.4966394901275635
alpha-CROWN with fixed intermediate bounds: tensor([[-0.7564]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-0.7564191222190857
layer 0 size torch.Size([200]) unstable 16
layer 1 size torch.Size([200]) unstable 29
layer 2 size torch.Size([200]) unstable 41
layer 3 size torch.Size([200]) unstable 36
layer 4 size torch.Size([200]) unstable 51
-----------------
# of unstable neurons: 173
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 200]) pre split depth:  6
batch:  torch.Size([1, 200]) post split depth:  6
splitting decisions: 
split level 0: [1, 80] 
split level 1: [4, 154] 
split level 2: [0, 132] 
split level 3: [0, 119] 
split level 4: [3, 13] 
split level 5: [3, 65] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: 15.514137268066406 with beta sum per layer: [15.940610885620117, 23.821043014526367, 0.0, 30.42827796936035, 4.848651885986328]
alpha/beta optimization time: 0.35846447944641113
This batch time : update_bounds func: 0.3734	 prepare: 0.0075	 bound: 0.3588	 transfer: 0.0009	 finalize: 0.0059
Accumulated time: update_bounds func: 2.6845	 prepare: 0.0907	 bound: 2.5305	 transfer: 0.0009	 finalize: 0.0535
batch bounding time:  0.3735518455505371
Current worst splitting domains [lb, ub] (depth):
[-0.64180,   inf] (7), [-0.52552,   inf] (7), [-0.52424,   inf] (7), [-0.50767,   inf] (7), [-0.50239,   inf] (7), [-0.46272,   inf] (7), [-0.45140,   inf] (7), [-0.43219,   inf] (7), [-0.42978,   inf] (7), [-0.42479,   inf] (7), [-0.40494,   inf] (7), [-0.40136,   inf] (7), [-0.38277,   inf] (7), [-0.37349,   inf] (7), [-0.35745,   inf] (7), [-0.35714,   inf] (7), [-0.34023,   inf] (7), [-0.33231,   inf] (7), [-0.30821,   inf] (7), [-0.29628,   inf] (7), 
length of domains: 64
Total time: 0.4373	 pickout: 0.0010	 decision: 0.0492	 get_bound: 0.3838	 add_domain: 0.0033
Current lb:-0.6417969465255737
64 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 1.9599473476409912

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 200]) pre split depth:  1
batch:  torch.Size([64, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 158] [0, 158] [0, 158] [0, 158] [0, 158] [0, 158] [0, 158] [0, 158] [0, 158] [0, 158] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 18.483531951904297 with beta sum per layer: [53.696319580078125, 71.72148132324219, 0.0, 101.68063354492188, 13.729330062866211]
alpha/beta optimization time: 0.3571290969848633
This batch time : update_bounds func: 0.3905	 prepare: 0.0201	 bound: 0.3575	 transfer: 0.0012	 finalize: 0.0113
Accumulated time: update_bounds func: 3.0750	 prepare: 0.1109	 bound: 2.8880	 transfer: 0.0012	 finalize: 0.0648
batch bounding time:  0.3907299041748047
Current worst splitting domains [lb, ub] (depth):
[-0.60484,   inf] (9), [-0.48743,   inf] (9), [-0.48107,   inf] (9), [-0.47555,   inf] (9), [-0.46481,   inf] (9), [-0.46013,   inf] (9), [-0.41463,   inf] (9), [-0.41064,   inf] (9), [-0.40971,   inf] (9), [-0.38820,   inf] (9), [-0.38533,   inf] (9), [-0.38486,   inf] (9), [-0.38311,   inf] (9), [-0.37918,   inf] (9), [-0.35487,   inf] (9), [-0.35193,   inf] (9), [-0.33668,   inf] (9), [-0.32862,   inf] (9), [-0.31388,   inf] (9), [-0.30968,   inf] (9), 
length of domains: 100
Total time: 0.4468	 pickout: 0.0121	 decision: 0.0380	 get_bound: 0.3909	 add_domain: 0.0058
Current lb:-0.604843020439148
192 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.408367872238159

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([100, 200]) pre split depth:  1
batch:  torch.Size([100, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 37] [3, 37] [3, 37] [3, 37] [1, 174] [1, 174] [3, 37] [3, 37] [3, 37] [1, 174] 
regular batch size: 2*100, diving batch size 1*0
best_l after optimization: 23.50697898864746 with beta sum per layer: [87.76405334472656, 95.66062927246094, 3.443558692932129, 203.50955200195312, 27.338233947753906]
alpha/beta optimization time: 0.3633551597595215
This batch time : update_bounds func: 0.4180	 prepare: 0.0299	 bound: 0.3638	 transfer: 0.0019	 finalize: 0.0219
Accumulated time: update_bounds func: 3.4930	 prepare: 0.1408	 bound: 3.2518	 transfer: 0.0019	 finalize: 0.0867
batch bounding time:  0.41837143898010254
Current worst splitting domains [lb, ub] (depth):
[-0.58430,   inf] (11), [-0.47194,   inf] (11), [-0.45669,   inf] (11), [-0.44690,   inf] (11), [-0.44405,   inf] (11), [-0.43188,   inf] (11), [-0.42840,   inf] (11), [-0.42571,   inf] (11), [-0.42265,   inf] (11), [-0.39213,   inf] (11), [-0.39000,   inf] (11), [-0.38020,   inf] (11), [-0.36900,   inf] (11), [-0.35533,   inf] (11), [-0.35108,   inf] (11), [-0.35000,   inf] (11), [-0.34999,   inf] (11), [-0.34190,   inf] (11), [-0.34104,   inf] (11), [-0.34054,   inf] (11), 
length of domains: 149
Total time: 0.4936	 pickout: 0.0183	 decision: 0.0467	 get_bound: 0.4187	 add_domain: 0.0099
Current lb:-0.5843020677566528
392 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.9055354595184326

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([149, 200]) pre split depth:  1
batch:  torch.Size([149, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 10] [0, 10] [1, 174] [1, 174] [1, 174] [3, 37] [3, 37] [1, 76] [3, 37] [2, 45] 
regular batch size: 2*149, diving batch size 1*0
best_l after optimization: 29.281234741210938 with beta sum per layer: [140.56735229492188, 115.11643981933594, 19.215450286865234, 325.5713195800781, 50.892486572265625]
alpha/beta optimization time: 0.3840298652648926
This batch time : update_bounds func: 0.4589	 prepare: 0.0438	 bound: 0.3845	 transfer: 0.0026	 finalize: 0.0273
Accumulated time: update_bounds func: 3.9518	 prepare: 0.1846	 bound: 3.6363	 transfer: 0.0026	 finalize: 0.1140
batch bounding time:  0.4592773914337158
Current worst splitting domains [lb, ub] (depth):
[-0.56328,   inf] (13), [-0.45331,   inf] (13), [-0.42145,   inf] (13), [-0.41780,   inf] (13), [-0.41155,   inf] (13), [-0.39608,   inf] (13), [-0.39399,   inf] (13), [-0.39199,   inf] (13), [-0.38989,   inf] (13), [-0.38783,   inf] (13), [-0.38773,   inf] (13), [-0.37993,   inf] (13), [-0.37358,   inf] (13), [-0.35213,   inf] (13), [-0.34996,   inf] (13), [-0.33873,   inf] (13), [-0.33863,   inf] (13), [-0.33715,   inf] (13), [-0.33700,   inf] (13), [-0.33460,   inf] (13), 
length of domains: 213
Total time: 0.5565	 pickout: 0.0285	 decision: 0.0550	 get_bound: 0.4597	 add_domain: 0.0133
Current lb:-0.5632798671722412
690 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.4658660888671875

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([213, 200]) pre split depth:  1
batch:  torch.Size([213, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 174] [2, 45] [0, 10] [0, 10] [1, 76] [0, 146] [4, 190] [0, 146] [4, 190] [4, 190] 
regular batch size: 2*213, diving batch size 1*0
best_l after optimization: 34.17095947265625 with beta sum per layer: [229.92428588867188, 138.85064697265625, 67.67280578613281, 445.33843994140625, 82.39033508300781]
alpha/beta optimization time: 0.36663818359375
This batch time : update_bounds func: 0.4728	 prepare: 0.0613	 bound: 0.3671	 transfer: 0.0035	 finalize: 0.0399
Accumulated time: update_bounds func: 4.4246	 prepare: 0.2459	 bound: 4.0033	 transfer: 0.0035	 finalize: 0.1539
batch bounding time:  0.4733102321624756
Current worst splitting domains [lb, ub] (depth):
[-0.51426,   inf] (15), [-0.49320,   inf] (15), [-0.41777,   inf] (15), [-0.40811,   inf] (15), [-0.40701,   inf] (15), [-0.40354,   inf] (15), [-0.38377,   inf] (15), [-0.38118,   inf] (15), [-0.37944,   inf] (15), [-0.37656,   inf] (15), [-0.36698,   inf] (15), [-0.36117,   inf] (15), [-0.35733,   inf] (15), [-0.35334,   inf] (15), [-0.35262,   inf] (15), [-0.33961,   inf] (15), [-0.33265,   inf] (15), [-0.32242,   inf] (15), [-0.31904,   inf] (15), [-0.31570,   inf] (15), 
length of domains: 297
Total time: 0.6533	 pickout: 0.0388	 decision: 0.0651	 get_bound: 0.4740	 add_domain: 0.0755
Current lb:-0.5142603516578674
1116 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.124531507492065

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([297, 200]) pre split depth:  1
batch:  torch.Size([297, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 45] [2, 45] [1, 174] [2, 3] [1, 76] [4, 190] [4, 46] [4, 190] [4, 46] [4, 190] 
regular batch size: 2*297, diving batch size 1*0
best_l after optimization: 38.212005615234375 with beta sum per layer: [369.0530090332031, 159.00299072265625, 149.10943603515625, 577.3248291015625, 140.3538360595703]
alpha/beta optimization time: 0.3667135238647461
This batch time : update_bounds func: 0.5162	 prepare: 0.0869	 bound: 0.3671	 transfer: 0.0065	 finalize: 0.0544
Accumulated time: update_bounds func: 4.9408	 prepare: 0.3328	 bound: 4.3705	 transfer: 0.0065	 finalize: 0.2083
batch bounding time:  0.5167980194091797
Current worst splitting domains [lb, ub] (depth):
[-0.48748,   inf] (17), [-0.46395,   inf] (17), [-0.41139,   inf] (17), [-0.41049,   inf] (17), [-0.39524,   inf] (17), [-0.38943,   inf] (17), [-0.38449,   inf] (17), [-0.38300,   inf] (17), [-0.37927,   inf] (17), [-0.37403,   inf] (17), [-0.37135,   inf] (17), [-0.36673,   inf] (17), [-0.35840,   inf] (17), [-0.35727,   inf] (17), [-0.35375,   inf] (17), [-0.35340,   inf] (17), [-0.35222,   inf] (17), [-0.34548,   inf] (17), [-0.33093,   inf] (17), [-0.32972,   inf] (17), 
length of domains: 374
Total time: 0.6791	 pickout: 0.0555	 decision: 0.0817	 get_bound: 0.5177	 add_domain: 0.0241
Current lb:-0.48748400807380676
1710 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.811529636383057

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([374, 200]) pre split depth:  1
batch:  torch.Size([374, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 3] [2, 3] [2, 3] [2, 88] [2, 45] [4, 190] [2, 3] [2, 3] [2, 45] [4, 190] 
regular batch size: 2*374, diving batch size 1*0
best_l after optimization: 45.7978515625 with beta sum per layer: [486.7693786621094, 137.92962646484375, 257.9931640625, 738.912353515625, 173.92408752441406]
alpha/beta optimization time: 0.36305904388427734
This batch time : update_bounds func: 0.5929	 prepare: 0.1109	 bound: 0.3636	 transfer: 0.0074	 finalize: 0.1094
Accumulated time: update_bounds func: 5.5337	 prepare: 0.4437	 bound: 4.7340	 transfer: 0.0074	 finalize: 0.3177
batch bounding time:  0.5936398506164551
Current worst splitting domains [lb, ub] (depth):
[-0.47931,   inf] (19), [-0.45512,   inf] (19), [-0.39751,   inf] (19), [-0.39284,   inf] (19), [-0.38046,   inf] (19), [-0.37240,   inf] (19), [-0.37033,   inf] (19), [-0.36643,   inf] (19), [-0.36521,   inf] (19), [-0.35759,   inf] (19), [-0.35431,   inf] (19), [-0.34655,   inf] (19), [-0.34411,   inf] (19), [-0.34181,   inf] (19), [-0.33990,   inf] (19), [-0.33916,   inf] (19), [-0.33734,   inf] (19), [-0.33550,   inf] (19), [-0.33430,   inf] (19), [-0.33163,   inf] (19), 
length of domains: 452
Total time: 0.7952	 pickout: 0.0705	 decision: 0.0988	 get_bound: 0.5948	 add_domain: 0.0312
Current lb:-0.4793072044849396
2458 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.616896152496338

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([452, 200]) pre split depth:  1
batch:  torch.Size([452, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 76] [2, 88] [4, 190] [2, 88] [1, 174] [4, 190] [4, 190] [1, 76] [2, 45] [2, 3] 
regular batch size: 2*452, diving batch size 1*0
best_l after optimization: 56.678985595703125 with beta sum per layer: [584.16943359375, 173.08837890625, 417.09136962890625, 864.380126953125, 237.27932739257812]
alpha/beta optimization time: 0.36387062072753906
This batch time : update_bounds func: 0.6366	 prepare: 0.1343	 bound: 0.3643	 transfer: 0.0081	 finalize: 0.1278
Accumulated time: update_bounds func: 6.1703	 prepare: 0.5780	 bound: 5.0984	 transfer: 0.0081	 finalize: 0.4455
batch bounding time:  0.6375548839569092
Current worst splitting domains [lb, ub] (depth):
[-0.45516,   inf] (21), [-0.44573,   inf] (21), [-0.41869,   inf] (21), [-0.38672,   inf] (21), [-0.37924,   inf] (21), [-0.36367,   inf] (21), [-0.36162,   inf] (21), [-0.34929,   inf] (21), [-0.34775,   inf] (21), [-0.34624,   inf] (21), [-0.34580,   inf] (21), [-0.34080,   inf] (21), [-0.34036,   inf] (21), [-0.33450,   inf] (21), [-0.33426,   inf] (21), [-0.33365,   inf] (21), [-0.32907,   inf] (21), [-0.32375,   inf] (21), [-0.32335,   inf] (21), [-0.32057,   inf] (21), 
length of domains: 572
Total time: 0.8811	 pickout: 0.0859	 decision: 0.1138	 get_bound: 0.6389	 add_domain: 0.0424
Current lb:-0.45515525341033936
3362 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.5111565589904785

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([572, 200]) pre split depth:  1
batch:  torch.Size([572, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 88] [0, 146] [2, 88] [2, 3] [4, 190] [3, 135] [3, 135] [3, 135] [3, 135] [4, 46] 
regular batch size: 2*572, diving batch size 1*0
best_l after optimization: 67.65508270263672 with beta sum per layer: [724.5404052734375, 234.92971801757812, 585.3721923828125, 1042.754150390625, 342.33282470703125]
alpha/beta optimization time: 0.3699042797088623
This batch time : update_bounds func: 0.7046	 prepare: 0.1680	 bound: 0.3704	 transfer: 0.0101	 finalize: 0.1532
Accumulated time: update_bounds func: 6.8749	 prepare: 0.7460	 bound: 5.4687	 transfer: 0.0101	 finalize: 0.5987
batch bounding time:  0.7056732177734375
Current worst splitting domains [lb, ub] (depth):
[-0.44657,   inf] (23), [-0.41908,   inf] (23), [-0.40894,   inf] (23), [-0.37159,   inf] (23), [-0.36757,   inf] (23), [-0.34597,   inf] (23), [-0.33998,   inf] (23), [-0.33761,   inf] (23), [-0.33282,   inf] (23), [-0.33068,   inf] (23), [-0.32804,   inf] (23), [-0.32796,   inf] (23), [-0.32787,   inf] (23), [-0.32558,   inf] (23), [-0.32501,   inf] (23), [-0.32445,   inf] (23), [-0.32078,   inf] (23), [-0.31776,   inf] (23), [-0.31569,   inf] (23), [-0.31118,   inf] (23), 
length of domains: 699
Total time: 1.0054	 pickout: 0.1109	 decision: 0.1357	 get_bound: 0.7074	 add_domain: 0.0515
Current lb:-0.44656530022621155
4506 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.533360242843628

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([699, 200]) pre split depth:  1
batch:  torch.Size([699, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 135] [4, 190] [3, 135] [3, 135] [3, 135] [4, 190] [1, 76] [4, 46] [4, 19] [1, 76] 
regular batch size: 2*699, diving batch size 1*0
best_l after optimization: 89.14434814453125 with beta sum per layer: [910.56591796875, 321.68450927734375, 737.9972534179688, 1224.90771484375, 452.52777099609375]
alpha/beta optimization time: 0.37497639656066895
This batch time : update_bounds func: 0.7933	 prepare: 0.2069	 bound: 0.3755	 transfer: 0.0139	 finalize: 0.1327
Accumulated time: update_bounds func: 7.6682	 prepare: 0.9529	 bound: 5.8442	 transfer: 0.0139	 finalize: 0.7314
batch bounding time:  0.794579267501831
Current worst splitting domains [lb, ub] (depth):
[-0.41800,   inf] (25), [-0.41685,   inf] (25), [-0.41024,   inf] (25), [-0.38129,   inf] (25), [-0.37831,   inf] (25), [-0.34798,   inf] (25), [-0.34194,   inf] (25), [-0.33225,   inf] (25), [-0.31776,   inf] (25), [-0.31582,   inf] (25), [-0.31333,   inf] (25), [-0.31138,   inf] (25), [-0.31102,   inf] (25), [-0.31076,   inf] (25), [-0.30969,   inf] (25), [-0.30881,   inf] (25), [-0.30726,   inf] (25), [-0.30684,   inf] (25), [-0.30660,   inf] (25), [-0.30642,   inf] (25), 
length of domains: 920
Total time: 1.1706	 pickout: 0.1349	 decision: 0.1679	 get_bound: 0.7967	 add_domain: 0.0710
Current lb:-0.41799959540367126
5904 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.724773645401001

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([920, 200]) pre split depth:  1
batch:  torch.Size([920, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 190] [4, 190] [3, 135] [4, 190] [4, 190] [0, 146] [4, 19] [3, 135] [4, 46] [3, 115] 
regular batch size: 2*920, diving batch size 1*0
best_l after optimization: 117.74858856201172 with beta sum per layer: [1153.440673828125, 408.5885925292969, 1011.0444946289062, 1643.214599609375, 677.352294921875]
alpha/beta optimization time: 0.38431549072265625
This batch time : update_bounds func: 0.9178	 prepare: 0.2744	 bound: 0.3848	 transfer: 0.0177	 finalize: 0.2363
Accumulated time: update_bounds func: 8.5860	 prepare: 1.2274	 bound: 6.2290	 transfer: 0.0177	 finalize: 0.9677
batch bounding time:  0.9195644855499268
Current worst splitting domains [lb, ub] (depth):
[-0.40961,   inf] (27), [-0.40817,   inf] (27), [-0.38143,   inf] (27), [-0.37993,   inf] (27), [-0.37264,   inf] (27), [-0.36949,   inf] (27), [-0.32927,   inf] (27), [-0.31665,   inf] (27), [-0.31476,   inf] (27), [-0.30266,   inf] (27), [-0.30153,   inf] (27), [-0.30039,   inf] (27), [-0.29945,   inf] (27), [-0.29923,   inf] (27), [-0.29806,   inf] (27), [-0.29788,   inf] (27), [-0.29608,   inf] (27), [-0.29426,   inf] (27), [-0.29401,   inf] (27), [-0.29327,   inf] (27), 
length of domains: 1271
Total time: 1.4614	 pickout: 0.1803	 decision: 0.2555	 get_bound: 0.9224	 add_domain: 0.1032
Current lb:-0.409610390663147
7744 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.213929653167725

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 146] [1, 76] [1, 76] [1, 76] [0, 146] [0, 113] [4, 19] [0, 173] [4, 46] [4, 46] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 162.4561767578125 with beta sum per layer: [1152.8924560546875, 439.38616943359375, 1197.0216064453125, 1837.0555419921875, 887.8522338867188]
alpha/beta optimization time: 0.3923532962799072
This batch time : update_bounds func: 0.9785	 prepare: 0.3046	 bound: 0.3928	 transfer: 0.0172	 finalize: 0.2588
Accumulated time: update_bounds func: 9.5645	 prepare: 1.5320	 bound: 6.6218	 transfer: 0.0172	 finalize: 1.2265
batch bounding time:  0.9803717136383057
Current worst splitting domains [lb, ub] (depth):
[-0.38952,   inf] (29), [-0.38434,   inf] (29), [-0.37550,   inf] (29), [-0.35994,   inf] (29), [-0.35605,   inf] (29), [-0.35508,   inf] (29), [-0.35250,   inf] (29), [-0.35072,   inf] (29), [-0.34236,   inf] (29), [-0.33991,   inf] (29), [-0.30875,   inf] (29), [-0.30767,   inf] (29), [-0.30486,   inf] (29), [-0.29336,   inf] (29), [-0.29180,   inf] (29), [-0.29150,   inf] (29), [-0.28851,   inf] (29), [-0.28666,   inf] (29), [-0.28425,   inf] (29), [-0.28309,   inf] (29), 
length of domains: 1927
Total time: 1.6044	 pickout: 0.2021	 decision: 0.2793	 get_bound: 0.9835	 add_domain: 0.1395
Current lb:-0.3895171284675598
9792 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.84693694114685

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 46] [0, 146] [0, 173] [4, 19] [4, 19] [4, 46] [0, 113] [4, 46] [3, 115] [1, 76] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 195.5869140625 with beta sum per layer: [940.8519897460938, 473.72698974609375, 1106.666259765625, 1880.7371826171875, 1069.013427734375]
alpha/beta optimization time: 0.3842484951019287
This batch time : update_bounds func: 0.9922	 prepare: 0.3057	 bound: 0.3847	 transfer: 0.0227	 finalize: 0.2737
Accumulated time: update_bounds func: 10.5567	 prepare: 1.8377	 bound: 7.0065	 transfer: 0.0227	 finalize: 1.5002
batch bounding time:  0.9941670894622803
Current worst splitting domains [lb, ub] (depth):
[-0.36717,   inf] (31), [-0.36442,   inf] (31), [-0.36278,   inf] (31), [-0.34762,   inf] (31), [-0.34260,   inf] (31), [-0.33936,   inf] (31), [-0.33302,   inf] (31), [-0.33067,   inf] (31), [-0.32898,   inf] (31), [-0.32837,   inf] (31), [-0.32614,   inf] (31), [-0.32588,   inf] (31), [-0.32237,   inf] (31), [-0.31694,   inf] (31), [-0.31280,   inf] (31), [-0.30986,   inf] (31), [-0.30873,   inf] (31), [-0.30866,   inf] (31), [-0.29895,   inf] (31), [-0.29400,   inf] (31), 
length of domains: 2673
Total time: 1.6538	 pickout: 0.2036	 decision: 0.2988	 get_bound: 0.9973	 add_domain: 0.1541
Current lb:-0.3671690821647644
11840 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.529750108718872

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 19] [0, 113] [1, 76] [4, 19] [4, 46] [4, 46] [4, 19] [4, 19] [4, 46] [4, 19] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 219.72402954101562 with beta sum per layer: [688.388671875, 440.4527587890625, 1068.265625, 1794.207763671875, 1207.893310546875]
alpha/beta optimization time: 0.38300371170043945
This batch time : update_bounds func: 1.0078	 prepare: 0.3055	 bound: 0.3835	 transfer: 0.0229	 finalize: 0.2906
Accumulated time: update_bounds func: 11.5646	 prepare: 2.1432	 bound: 7.3899	 transfer: 0.0229	 finalize: 1.7909
batch bounding time:  1.0105335712432861
Current worst splitting domains [lb, ub] (depth):
[-0.35049,   inf] (33), [-0.33978,   inf] (33), [-0.33808,   inf] (33), [-0.33722,   inf] (33), [-0.33530,   inf] (33), [-0.33109,   inf] (33), [-0.32100,   inf] (33), [-0.31800,   inf] (33), [-0.31704,   inf] (33), [-0.31585,   inf] (33), [-0.31290,   inf] (33), [-0.31207,   inf] (33), [-0.31202,   inf] (33), [-0.31016,   inf] (33), [-0.30830,   inf] (33), [-0.30745,   inf] (33), [-0.30663,   inf] (33), [-0.30532,   inf] (33), [-0.30469,   inf] (33), [-0.30094,   inf] (33), 
length of domains: 3471
Total time: 1.6962	 pickout: 0.2064	 decision: 0.3077	 get_bound: 1.0139	 add_domain: 0.1681
Current lb:-0.3504903018474579
13888 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.263878583908081

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 173] [4, 19] [4, 19] [4, 19] [4, 19] [3, 115] [3, 32] [3, 32] [3, 32] [3, 50] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 228.38687133789062 with beta sum per layer: [491.23492431640625, 489.3421936035156, 858.101318359375, 2073.48291015625, 1330.6541748046875]
alpha/beta optimization time: 0.38362765312194824
This batch time : update_bounds func: 1.0590	 prepare: 0.3130	 bound: 0.3841	 transfer: 0.0221	 finalize: 0.3342
Accumulated time: update_bounds func: 12.6236	 prepare: 2.4562	 bound: 7.7741	 transfer: 0.0221	 finalize: 2.1250
batch bounding time:  1.0613505840301514
Current worst splitting domains [lb, ub] (depth):
[-0.33173,   inf] (35), [-0.32247,   inf] (35), [-0.32234,   inf] (35), [-0.32000,   inf] (35), [-0.31949,   inf] (35), [-0.31267,   inf] (35), [-0.30910,   inf] (35), [-0.30825,   inf] (35), [-0.30767,   inf] (35), [-0.30631,   inf] (35), [-0.30537,   inf] (35), [-0.30062,   inf] (35), [-0.29252,   inf] (35), [-0.29136,   inf] (35), [-0.29111,   inf] (35), [-0.28982,   inf] (35), [-0.28885,   inf] (35), [-0.28839,   inf] (35), [-0.28827,   inf] (35), [-0.28767,   inf] (35), 
length of domains: 4238
Total time: 1.7841	 pickout: 0.2156	 decision: 0.3364	 get_bound: 1.0649	 add_domain: 0.1672
Current lb:-0.3317280411720276
15936 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.07805347442627

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 76] [3, 50] [0, 173] [0, 173] [0, 173] [3, 32] [4, 91] [3, 115] [3, 50] [4, 91] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 221.32635498046875 with beta sum per layer: [361.68438720703125, 535.4237060546875, 612.7237548828125, 2432.72998046875, 1511.4339599609375]
alpha/beta optimization time: 0.38216447830200195
This batch time : update_bounds func: 1.0714	 prepare: 0.3102	 bound: 0.3826	 transfer: 0.0217	 finalize: 0.3517
Accumulated time: update_bounds func: 13.6950	 prepare: 2.7664	 bound: 8.1567	 transfer: 0.0217	 finalize: 2.4768
batch bounding time:  1.0734732151031494
Current worst splitting domains [lb, ub] (depth):
[-0.31398,   inf] (37), [-0.31186,   inf] (37), [-0.30553,   inf] (37), [-0.30498,   inf] (37), [-0.30472,   inf] (37), [-0.30255,   inf] (37), [-0.30214,   inf] (37), [-0.30063,   inf] (37), [-0.30049,   inf] (37), [-0.29735,   inf] (37), [-0.29655,   inf] (37), [-0.28588,   inf] (37), [-0.28406,   inf] (37), [-0.28380,   inf] (37), [-0.28339,   inf] (37), [-0.28202,   inf] (37), [-0.28071,   inf] (37), [-0.27999,   inf] (37), [-0.27617,   inf] (37), [-0.27491,   inf] (37), 
length of domains: 4915
Total time: 1.8122	 pickout: 0.2078	 decision: 0.3638	 get_bound: 1.0767	 add_domain: 0.1638
Current lb:-0.313976526260376
17984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.922014951705933

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 91] [3, 32] [3, 32] [3, 115] [0, 146] [3, 32] [3, 115] [4, 91] [4, 67] [3, 50] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 210.2010498046875 with beta sum per layer: [306.9344177246094, 557.91552734375, 510.1711120605469, 2504.06884765625, 1712.862060546875]
alpha/beta optimization time: 0.38643455505371094
This batch time : update_bounds func: 0.9222	 prepare: 0.3100	 bound: 0.3869	 transfer: 0.0217	 finalize: 0.1982
Accumulated time: update_bounds func: 14.6172	 prepare: 3.0764	 bound: 8.5436	 transfer: 0.0217	 finalize: 2.6750
batch bounding time:  0.9241628646850586
Current worst splitting domains [lb, ub] (depth):
[-0.30989,   inf] (39), [-0.30020,   inf] (39), [-0.29747,   inf] (39), [-0.29622,   inf] (39), [-0.29444,   inf] (39), [-0.29186,   inf] (39), [-0.28913,   inf] (39), [-0.28683,   inf] (39), [-0.28539,   inf] (39), [-0.28268,   inf] (39), [-0.28224,   inf] (39), [-0.28183,   inf] (39), [-0.27999,   inf] (39), [-0.27994,   inf] (39), [-0.27957,   inf] (39), [-0.27795,   inf] (39), [-0.27765,   inf] (39), [-0.27743,   inf] (39), [-0.27689,   inf] (39), [-0.27630,   inf] (39), 
length of domains: 5550
Total time: 1.8602	 pickout: 0.2095	 decision: 0.3752	 get_bound: 0.9273	 add_domain: 0.3483
Current lb:-0.3098924458026886
20032 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 20.817365646362305

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 115] [4, 91] [3, 115] [3, 32] [3, 115] [4, 91] [4, 91] [4, 91] [3, 114] [2, 165] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 213.73370361328125 with beta sum per layer: [272.2884521484375, 545.47607421875, 455.245849609375, 2448.42138671875, 1854.178955078125]
alpha/beta optimization time: 0.38523292541503906
This batch time : update_bounds func: 1.1123	 prepare: 0.3131	 bound: 0.3857	 transfer: 0.0217	 finalize: 0.3860
Accumulated time: update_bounds func: 15.7295	 prepare: 3.3896	 bound: 8.9293	 transfer: 0.0217	 finalize: 3.0610
batch bounding time:  1.1143395900726318
Current worst splitting domains [lb, ub] (depth):
[-0.29571,   inf] (41), [-0.28664,   inf] (41), [-0.28534,   inf] (41), [-0.28498,   inf] (41), [-0.28477,   inf] (41), [-0.28049,   inf] (41), [-0.27998,   inf] (41), [-0.27956,   inf] (41), [-0.27799,   inf] (41), [-0.27692,   inf] (41), [-0.27679,   inf] (41), [-0.27588,   inf] (41), [-0.27376,   inf] (41), [-0.27321,   inf] (41), [-0.27300,   inf] (41), [-0.27254,   inf] (41), [-0.27197,   inf] (41), [-0.26802,   inf] (41), [-0.26668,   inf] (41), [-0.26223,   inf] (41), 
length of domains: 6232
Total time: 1.7365	 pickout: 0.2120	 decision: 0.2329	 get_bound: 1.1176	 add_domain: 0.1741
Current lb:-0.2957102954387665
22080 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 22.585347890853882

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 115] [3, 115] [3, 115] [0, 45] [4, 67] [0, 42] [4, 46] [4, 67] [4, 67] [0, 42] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 213.8592529296875 with beta sum per layer: [244.889404296875, 523.733154296875, 445.05682373046875, 2255.04150390625, 1909.47607421875]
alpha/beta optimization time: 0.3856163024902344
This batch time : update_bounds func: 0.9323	 prepare: 0.3166	 bound: 0.3861	 transfer: 0.0218	 finalize: 0.2021
Accumulated time: update_bounds func: 16.6618	 prepare: 3.7061	 bound: 9.3154	 transfer: 0.0218	 finalize: 3.2631
batch bounding time:  0.9342374801635742
Current worst splitting domains [lb, ub] (depth):
[-0.28136,   inf] (43), [-0.27822,   inf] (43), [-0.27656,   inf] (43), [-0.27653,   inf] (43), [-0.27629,   inf] (43), [-0.27154,   inf] (43), [-0.26972,   inf] (43), [-0.26894,   inf] (43), [-0.26658,   inf] (43), [-0.26651,   inf] (43), [-0.26302,   inf] (43), [-0.26072,   inf] (43), [-0.26023,   inf] (43), [-0.25942,   inf] (43), [-0.25909,   inf] (43), [-0.25809,   inf] (43), [-0.25796,   inf] (43), [-0.25773,   inf] (43), [-0.25649,   inf] (43), [-0.25607,   inf] (43), 
length of domains: 6953
Total time: 1.9880	 pickout: 0.2082	 decision: 0.4289	 get_bound: 0.9375	 add_domain: 0.4133
Current lb:-0.28136488795280457
24128 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 24.608830213546753

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 115] [4, 67] [2, 165] [0, 113] [0, 42] [2, 165] [4, 67] [3, 50] [3, 50] [2, 165] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 219.0245361328125 with beta sum per layer: [229.42620849609375, 465.69525146484375, 418.5579833984375, 2026.073974609375, 1849.37353515625]
alpha/beta optimization time: 0.38416028022766113
This batch time : update_bounds func: 1.1679	 prepare: 0.3180	 bound: 0.3846	 transfer: 0.0216	 finalize: 0.4377
Accumulated time: update_bounds func: 17.8297	 prepare: 4.0241	 bound: 9.7000	 transfer: 0.0216	 finalize: 3.7008
batch bounding time:  1.170483112335205
Current worst splitting domains [lb, ub] (depth):
[-0.27585,   inf] (45), [-0.27177,   inf] (45), [-0.26777,   inf] (45), [-0.26721,   inf] (45), [-0.26280,   inf] (45), [-0.26215,   inf] (45), [-0.26035,   inf] (45), [-0.25781,   inf] (45), [-0.25732,   inf] (45), [-0.25729,   inf] (45), [-0.25502,   inf] (45), [-0.25461,   inf] (45), [-0.25411,   inf] (45), [-0.25387,   inf] (45), [-0.25367,   inf] (45), [-0.25354,   inf] (45), [-0.25187,   inf] (45), [-0.25130,   inf] (45), [-0.25106,   inf] (45), [-0.24973,   inf] (45), 
length of domains: 7722
Total time: 1.8144	 pickout: 0.2133	 decision: 0.2335	 get_bound: 1.1743	 add_domain: 0.1933
Current lb:-0.2758452296257019
26176 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 26.456341981887817

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 173] [0, 45] [0, 113] [4, 132] [4, 67] [4, 67] [4, 67] [2, 165] [4, 193] [4, 67] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 221.019775390625 with beta sum per layer: [192.2747802734375, 467.1257629394531, 375.93255615234375, 1893.818359375, 1918.489013671875]
alpha/beta optimization time: 0.39482665061950684
This batch time : update_bounds func: 1.1998	 prepare: 0.3150	 bound: 0.3953	 transfer: 0.0227	 finalize: 0.4610
Accumulated time: update_bounds func: 19.0295	 prepare: 4.3391	 bound: 10.0953	 transfer: 0.0227	 finalize: 4.1618
batch bounding time:  1.2026269435882568
Current worst splitting domains [lb, ub] (depth):
[-0.26439,   inf] (47), [-0.26136,   inf] (47), [-0.26069,   inf] (47), [-0.26030,   inf] (47), [-0.25820,   inf] (47), [-0.25566,   inf] (47), [-0.25512,   inf] (47), [-0.25501,   inf] (47), [-0.25269,   inf] (47), [-0.25207,   inf] (47), [-0.25192,   inf] (47), [-0.25003,   inf] (47), [-0.24982,   inf] (47), [-0.24858,   inf] (47), [-0.24550,   inf] (47), [-0.24279,   inf] (47), [-0.24134,   inf] (47), [-0.24083,   inf] (47), [-0.23844,   inf] (47), [-0.23739,   inf] (47), 
length of domains: 8540
Total time: 1.8615	 pickout: 0.2123	 decision: 0.2362	 get_bound: 1.2068	 add_domain: 0.2062
Current lb:-0.26438814401626587
28224 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 28.35260009765625

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 113] [2, 165] [4, 46] [0, 113] [2, 165] [0, 42] [0, 113] [4, 46] [4, 46] [2, 197] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 214.75119018554688 with beta sum per layer: [215.04263305664062, 516.4867553710938, 382.4183654785156, 1831.59033203125, 1990.38720703125]
alpha/beta optimization time: 0.3838653564453125
This batch time : update_bounds func: 1.2262	 prepare: 0.3299	 bound: 0.3843	 transfer: 0.0217	 finalize: 0.4843
Accumulated time: update_bounds func: 20.2557	 prepare: 4.6690	 bound: 10.4796	 transfer: 0.0217	 finalize: 4.6460
batch bounding time:  1.2284297943115234
Current worst splitting domains [lb, ub] (depth):
[-0.25680,   inf] (49), [-0.25491,   inf] (49), [-0.24499,   inf] (49), [-0.24426,   inf] (49), [-0.24330,   inf] (49), [-0.24312,   inf] (49), [-0.24285,   inf] (49), [-0.24211,   inf] (49), [-0.24141,   inf] (49), [-0.24055,   inf] (49), [-0.23951,   inf] (49), [-0.23706,   inf] (49), [-0.23537,   inf] (49), [-0.23475,   inf] (49), [-0.23387,   inf] (49), [-0.23377,   inf] (49), [-0.23376,   inf] (49), [-0.23252,   inf] (49), [-0.23200,   inf] (49), [-0.23121,   inf] (49), 
length of domains: 9359
Total time: 1.8921	 pickout: 0.2133	 decision: 0.2360	 get_bound: 1.2318	 add_domain: 0.2109
Current lb:-0.2567977011203766
30272 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 30.277628183364868

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 113] [4, 46] [4, 67] [4, 132] [1, 177] [3, 93] [4, 92] [4, 67] [4, 132] [4, 92] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 197.9686279296875 with beta sum per layer: [231.84417724609375, 564.6251220703125, 375.59100341796875, 1831.47119140625, 1861.093994140625]
alpha/beta optimization time: 0.384563684463501
This batch time : update_bounds func: 0.9395	 prepare: 0.3216	 bound: 0.3850	 transfer: 0.0226	 finalize: 0.2044
Accumulated time: update_bounds func: 21.1953	 prepare: 4.9906	 bound: 10.8646	 transfer: 0.0226	 finalize: 4.8504
batch bounding time:  0.9417634010314941
Current worst splitting domains [lb, ub] (depth):
[-0.24270,   inf] (51), [-0.23943,   inf] (51), [-0.23874,   inf] (51), [-0.23626,   inf] (51), [-0.23446,   inf] (51), [-0.23413,   inf] (51), [-0.23398,   inf] (51), [-0.23323,   inf] (51), [-0.23299,   inf] (51), [-0.23221,   inf] (51), [-0.23156,   inf] (51), [-0.23022,   inf] (51), [-0.22993,   inf] (51), [-0.22879,   inf] (51), [-0.22854,   inf] (51), [-0.22799,   inf] (51), [-0.22555,   inf] (51), [-0.22542,   inf] (51), [-0.22447,   inf] (51), [-0.22398,   inf] (51), 
length of domains: 10114
Total time: 1.9487	 pickout: 0.2437	 decision: 0.5498	 get_bound: 0.9453	 add_domain: 0.2100
Current lb:-0.24269993603229523
32320 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 32.26012396812439

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 132] [4, 132] [4, 95] [4, 95] [4, 132] [2, 70] [4, 132] [0, 113] [3, 50] [4, 132] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 191.8082275390625 with beta sum per layer: [227.55413818359375, 606.3624267578125, 400.31817626953125, 1977.17919921875, 1831.119140625]
alpha/beta optimization time: 0.383953332901001
This batch time : update_bounds func: 0.9411	 prepare: 0.3239	 bound: 0.3844	 transfer: 0.0217	 finalize: 0.2051
Accumulated time: update_bounds func: 22.1364	 prepare: 5.3145	 bound: 11.2490	 transfer: 0.0217	 finalize: 5.0555
batch bounding time:  0.9434998035430908
Current worst splitting domains [lb, ub] (depth):
[-0.23208,   inf] (53), [-0.23139,   inf] (53), [-0.22954,   inf] (53), [-0.22819,   inf] (53), [-0.22739,   inf] (53), [-0.22691,   inf] (53), [-0.22432,   inf] (53), [-0.22371,   inf] (53), [-0.22316,   inf] (53), [-0.22229,   inf] (53), [-0.22135,   inf] (53), [-0.22000,   inf] (53), [-0.21939,   inf] (53), [-0.21939,   inf] (53), [-0.21893,   inf] (53), [-0.21776,   inf] (53), [-0.21726,   inf] (53), [-0.21698,   inf] (53), [-0.21582,   inf] (53), [-0.21493,   inf] (53), 
length of domains: 10905
Total time: 1.9292	 pickout: 0.2208	 decision: 0.5422	 get_bound: 0.9471	 add_domain: 0.2192
Current lb:-0.23207707703113556
34368 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 34.223273038864136

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 132] [3, 114] [4, 132] [3, 114] [3, 150] [3, 114] [3, 114] [3, 150] [1, 73] [2, 197] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 180.17501831054688 with beta sum per layer: [251.53854370117188, 671.250244140625, 420.9161376953125, 2013.8736572265625, 1711.467041015625]
alpha/beta optimization time: 0.38393425941467285
This batch time : update_bounds func: 0.9465	 prepare: 0.3276	 bound: 0.3844	 transfer: 0.0226	 finalize: 0.2064
Accumulated time: update_bounds func: 23.0829	 prepare: 5.6421	 bound: 11.6334	 transfer: 0.0226	 finalize: 5.2619
batch bounding time:  0.948573112487793
Current worst splitting domains [lb, ub] (depth):
[-0.22679,   inf] (55), [-0.22213,   inf] (55), [-0.22111,   inf] (55), [-0.21978,   inf] (55), [-0.21932,   inf] (55), [-0.21862,   inf] (55), [-0.21607,   inf] (55), [-0.21529,   inf] (55), [-0.21437,   inf] (55), [-0.21287,   inf] (55), [-0.21220,   inf] (55), [-0.21196,   inf] (55), [-0.21121,   inf] (55), [-0.21032,   inf] (55), [-0.20982,   inf] (55), [-0.20952,   inf] (55), [-0.20854,   inf] (55), [-0.20834,   inf] (55), [-0.20823,   inf] (55), [-0.20814,   inf] (55), 
length of domains: 11656
Total time: 1.9651	 pickout: 0.2228	 decision: 0.5737	 get_bound: 0.9520	 add_domain: 0.2166
Current lb:-0.22678840160369873
36416 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 36.223475217819214

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 42] [4, 92] [4, 193] [4, 92] [3, 50] [4, 193] [3, 50] [1, 73] [1, 177] [1, 73] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 170.97293090820312 with beta sum per layer: [247.567626953125, 768.583740234375, 411.22625732421875, 2179.748046875, 1658.54052734375]
alpha/beta optimization time: 0.38569021224975586
This batch time : update_bounds func: 0.9388	 prepare: 0.3189	 bound: 0.3861	 transfer: 0.0217	 finalize: 0.2057
Accumulated time: update_bounds func: 24.0216	 prepare: 5.9610	 bound: 12.0196	 transfer: 0.0217	 finalize: 5.4676
batch bounding time:  0.9408755302429199
Current worst splitting domains [lb, ub] (depth):
[-0.21746,   inf] (57), [-0.21560,   inf] (57), [-0.21511,   inf] (57), [-0.21339,   inf] (57), [-0.21309,   inf] (57), [-0.21137,   inf] (57), [-0.21017,   inf] (57), [-0.20736,   inf] (57), [-0.20517,   inf] (57), [-0.20507,   inf] (57), [-0.20396,   inf] (57), [-0.20373,   inf] (57), [-0.20331,   inf] (57), [-0.20239,   inf] (57), [-0.20182,   inf] (57), [-0.20178,   inf] (57), [-0.20162,   inf] (57), [-0.20153,   inf] (57), [-0.20150,   inf] (57), [-0.20075,   inf] (57), 
length of domains: 12378
Total time: 1.9847	 pickout: 0.2253	 decision: 0.5969	 get_bound: 0.9444	 add_domain: 0.2182
Current lb:-0.2174634337425232
38464 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 38.24845814704895

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 197] [0, 173] [2, 197] [1, 73] [0, 173] [3, 32] [1, 73] [3, 32] [4, 92] [3, 32] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 167.4914093017578 with beta sum per layer: [271.067138671875, 779.1935424804688, 439.3910827636719, 2148.12841796875, 1655.73974609375]
alpha/beta optimization time: 0.38796234130859375
This batch time : update_bounds func: 0.9466	 prepare: 0.3217	 bound: 0.3884	 transfer: 0.0226	 finalize: 0.2082
Accumulated time: update_bounds func: 24.9683	 prepare: 6.2827	 bound: 12.4080	 transfer: 0.0226	 finalize: 5.6758
batch bounding time:  0.9487125873565674
Current worst splitting domains [lb, ub] (depth):
[-0.20739,   inf] (59), [-0.20519,   inf] (59), [-0.20446,   inf] (59), [-0.20281,   inf] (59), [-0.20239,   inf] (59), [-0.20229,   inf] (59), [-0.20122,   inf] (59), [-0.19986,   inf] (59), [-0.19951,   inf] (59), [-0.19862,   inf] (59), [-0.19814,   inf] (59), [-0.19812,   inf] (59), [-0.19776,   inf] (59), [-0.19751,   inf] (59), [-0.19731,   inf] (59), [-0.19569,   inf] (59), [-0.19531,   inf] (59), [-0.19528,   inf] (59), [-0.19458,   inf] (59), [-0.19421,   inf] (59), 
length of domains: 13108
Total time: 2.0015	 pickout: 0.2206	 decision: 0.6081	 get_bound: 0.9522	 add_domain: 0.2206
Current lb:-0.20739471912384033
40512 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 40.290764808654785

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 177] [1, 177] [0, 45] [4, 92] [3, 114] [0, 45] [4, 95] [4, 95] [4, 92] [4, 95] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 154.8682098388672 with beta sum per layer: [277.2489929199219, 784.1605224609375, 471.5981750488281, 2207.611328125, 1631.917724609375]
alpha/beta optimization time: 0.387664794921875
This batch time : update_bounds func: 1.3374	 prepare: 0.3201	 bound: 0.3882	 transfer: 0.0224	 finalize: 0.6011
Accumulated time: update_bounds func: 26.3056	 prepare: 6.6028	 bound: 12.7961	 transfer: 0.0224	 finalize: 6.2768
batch bounding time:  1.3394489288330078
Current worst splitting domains [lb, ub] (depth):
[-0.19895,   inf] (61), [-0.19774,   inf] (61), [-0.19719,   inf] (61), [-0.19574,   inf] (61), [-0.19551,   inf] (61), [-0.19519,   inf] (61), [-0.19323,   inf] (61), [-0.19237,   inf] (61), [-0.19184,   inf] (61), [-0.19088,   inf] (61), [-0.19032,   inf] (61), [-0.18998,   inf] (61), [-0.18868,   inf] (61), [-0.18854,   inf] (61), [-0.18816,   inf] (61), [-0.18779,   inf] (61), [-0.18765,   inf] (61), [-0.18724,   inf] (61), [-0.18720,   inf] (61), [-0.18719,   inf] (61), 
length of domains: 13766
Total time: 2.0132	 pickout: 0.2206	 decision: 0.2373	 get_bound: 1.3429	 add_domain: 0.2123
Current lb:-0.19894850254058838
42560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 42.34835982322693

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 95] [3, 93] [2, 70] [4, 95] [4, 95] [2, 70] [2, 197] [2, 70] [0, 113] [2, 197] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 147.33982849121094 with beta sum per layer: [280.01470947265625, 802.2247314453125, 504.5981750488281, 2265.7294921875, 1655.096435546875]
alpha/beta optimization time: 0.3879415988922119
This batch time : update_bounds func: 1.3721	 prepare: 0.3199	 bound: 0.3885	 transfer: 0.0216	 finalize: 0.6353
Accumulated time: update_bounds func: 27.6778	 prepare: 6.9228	 bound: 13.1846	 transfer: 0.0216	 finalize: 6.9122
batch bounding time:  1.374394178390503
Current worst splitting domains [lb, ub] (depth):
[-0.19160,   inf] (63), [-0.19122,   inf] (63), [-0.18931,   inf] (63), [-0.18899,   inf] (63), [-0.18875,   inf] (63), [-0.18798,   inf] (63), [-0.18609,   inf] (63), [-0.18443,   inf] (63), [-0.18435,   inf] (63), [-0.18374,   inf] (63), [-0.18260,   inf] (63), [-0.18187,   inf] (63), [-0.18173,   inf] (63), [-0.18066,   inf] (63), [-0.18045,   inf] (63), [-0.18019,   inf] (63), [-0.17976,   inf] (63), [-0.17961,   inf] (63), [-0.17945,   inf] (63), [-0.17891,   inf] (63), 
length of domains: 14383
Total time: 2.0537	 pickout: 0.2204	 decision: 0.2435	 get_bound: 1.3780	 add_domain: 0.2118
Current lb:-0.1915973424911499
44608 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 44.44551110267639

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 177] [2, 197] [2, 165] [3, 93] [4, 95] [2, 197] [1, 99] [3, 114] [0, 45] [1, 99] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 142.70428466796875 with beta sum per layer: [304.3544616699219, 860.2840576171875, 501.97259521484375, 2184.8935546875, 1477.8997802734375]
alpha/beta optimization time: 0.3891620635986328
This batch time : update_bounds func: 0.9525	 prepare: 0.3230	 bound: 0.3896	 transfer: 0.0225	 finalize: 0.2113
Accumulated time: update_bounds func: 28.6303	 prepare: 7.2457	 bound: 13.5742	 transfer: 0.0225	 finalize: 7.1235
batch bounding time:  0.9548883438110352
Current worst splitting domains [lb, ub] (depth):
[-0.18655,   inf] (65), [-0.18415,   inf] (65), [-0.18217,   inf] (65), [-0.18217,   inf] (65), [-0.17998,   inf] (65), [-0.17892,   inf] (65), [-0.17856,   inf] (65), [-0.17801,   inf] (65), [-0.17632,   inf] (65), [-0.17625,   inf] (65), [-0.17532,   inf] (65), [-0.17480,   inf] (65), [-0.17479,   inf] (65), [-0.17475,   inf] (65), [-0.17424,   inf] (65), [-0.17420,   inf] (65), [-0.17409,   inf] (65), [-0.17319,   inf] (65), [-0.17257,   inf] (65), [-0.17237,   inf] (65), 
length of domains: 14997
Total time: 1.6350	 pickout: 0.2213	 decision: 0.2412	 get_bound: 0.9591	 add_domain: 0.2135
Current lb:-0.18654537200927734
46656 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 46.1268150806427

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 177] [2, 165] [3, 32] [2, 70] [3, 32] [2, 70] [1, 73] [2, 70] [3, 32] [1, 73] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 138.80682373046875 with beta sum per layer: [301.50103759765625, 850.827880859375, 520.8213500976562, 2334.75048828125, 1492.064208984375]
alpha/beta optimization time: 0.39069056510925293
This batch time : update_bounds func: 0.9563	 prepare: 0.3257	 bound: 0.3912	 transfer: 0.0223	 finalize: 0.2105
Accumulated time: update_bounds func: 29.5866	 prepare: 7.5714	 bound: 13.9654	 transfer: 0.0223	 finalize: 7.3340
batch bounding time:  0.9586358070373535
Current worst splitting domains [lb, ub] (depth):
[-0.18130,   inf] (67), [-0.17916,   inf] (67), [-0.17638,   inf] (67), [-0.17606,   inf] (67), [-0.17405,   inf] (67), [-0.17296,   inf] (67), [-0.17220,   inf] (67), [-0.17058,   inf] (67), [-0.16986,   inf] (67), [-0.16939,   inf] (67), [-0.16938,   inf] (67), [-0.16828,   inf] (67), [-0.16779,   inf] (67), [-0.16747,   inf] (67), [-0.16739,   inf] (67), [-0.16559,   inf] (67), [-0.16511,   inf] (67), [-0.16468,   inf] (67), [-0.16429,   inf] (67), [-0.16338,   inf] (67), 
length of domains: 15590
Total time: 2.1068	 pickout: 0.2181	 decision: 0.7143	 get_bound: 0.9623	 add_domain: 0.2121
Current lb:-0.18130338191986084
48704 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 48.2792911529541

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 32] [3, 32] [2, 99] [2, 99] [2, 70] [2, 99] [2, 99] [2, 70] [1, 73] [2, 197] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 135.11083984375 with beta sum per layer: [296.5195617675781, 814.6279296875, 574.758544921875, 2431.12109375, 1526.6309814453125]
alpha/beta optimization time: 0.3938753604888916
This batch time : update_bounds func: 1.4847	 prepare: 0.3358	 bound: 0.3944	 transfer: 0.0224	 finalize: 0.2110
Accumulated time: update_bounds func: 31.0712	 prepare: 7.9072	 bound: 14.3598	 transfer: 0.0224	 finalize: 7.5449
batch bounding time:  1.4869041442871094
Current worst splitting domains [lb, ub] (depth):
[-0.17595,   inf] (69), [-0.17330,   inf] (69), [-0.17197,   inf] (69), [-0.17114,   inf] (69), [-0.16987,   inf] (69), [-0.16798,   inf] (69), [-0.16724,   inf] (69), [-0.16614,   inf] (69), [-0.16476,   inf] (69), [-0.16441,   inf] (69), [-0.16392,   inf] (69), [-0.16238,   inf] (69), [-0.16184,   inf] (69), [-0.16149,   inf] (69), [-0.16026,   inf] (69), [-0.16006,   inf] (69), [-0.15969,   inf] (69), [-0.15816,   inf] (69), [-0.15750,   inf] (69), [-0.15704,   inf] (69), 
length of domains: 16192
Total time: 2.1687	 pickout: 0.2192	 decision: 0.2421	 get_bound: 1.4905	 add_domain: 0.2168
Current lb:-0.17594745755195618
50752 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 50.49713850021362

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 73] [3, 114] [2, 70] [3, 150] [4, 193] [3, 150] [3, 150] [4, 193] [3, 93] [3, 150] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 129.99234008789062 with beta sum per layer: [263.2540588378906, 862.220703125, 536.8187255859375, 2310.627685546875, 1586.447509765625]
alpha/beta optimization time: 0.38987088203430176
This batch time : update_bounds func: 1.5354	 prepare: 0.3253	 bound: 0.3903	 transfer: 0.0223	 finalize: 0.7908
Accumulated time: update_bounds func: 32.6066	 prepare: 8.2326	 bound: 14.7501	 transfer: 0.0223	 finalize: 8.3357
batch bounding time:  1.5380501747131348
Current worst splitting domains [lb, ub] (depth):
[-0.17003,   inf] (71), [-0.16842,   inf] (71), [-0.16807,   inf] (71), [-0.16688,   inf] (71), [-0.16601,   inf] (71), [-0.16539,   inf] (71), [-0.16318,   inf] (71), [-0.16303,   inf] (71), [-0.15959,   inf] (71), [-0.15936,   inf] (71), [-0.15712,   inf] (71), [-0.15681,   inf] (71), [-0.15530,   inf] (71), [-0.15484,   inf] (71), [-0.15351,   inf] (71), [-0.15274,   inf] (71), [-0.15229,   inf] (71), [-0.15051,   inf] (71), [-0.15017,   inf] (71), [-0.15007,   inf] (71), 
length of domains: 16793
Total time: 2.2210	 pickout: 0.2190	 decision: 0.2416	 get_bound: 1.5421	 add_domain: 0.2183
Current lb:-0.17003047466278076
52800 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 52.764055013656616

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 99] [3, 114] [4, 193] [1, 99] [1, 99] [1, 73] [1, 99] [2, 99] [2, 99] [2, 75] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 127.48345947265625 with beta sum per layer: [260.3204345703125, 831.6633911132812, 546.4652099609375, 2398.745849609375, 1588.9117431640625]
alpha/beta optimization time: 0.386411190032959
This batch time : update_bounds func: 0.9533	 prepare: 0.3265	 bound: 0.3869	 transfer: 0.0224	 finalize: 0.2113
Accumulated time: update_bounds func: 33.5600	 prepare: 8.5590	 bound: 15.1370	 transfer: 0.0224	 finalize: 8.5470
batch bounding time:  0.9556987285614014
Current worst splitting domains [lb, ub] (depth):
[-0.16387,   inf] (73), [-0.16098,   inf] (73), [-0.16067,   inf] (73), [-0.15970,   inf] (73), [-0.15955,   inf] (73), [-0.15859,   inf] (73), [-0.15700,   inf] (73), [-0.15695,   inf] (73), [-0.15525,   inf] (73), [-0.15361,   inf] (73), [-0.15346,   inf] (73), [-0.15289,   inf] (73), [-0.15138,   inf] (73), [-0.15093,   inf] (73), [-0.14911,   inf] (73), [-0.14911,   inf] (73), [-0.14591,   inf] (73), [-0.14496,   inf] (73), [-0.14449,   inf] (73), [-0.14432,   inf] (73), 
length of domains: 17403
Total time: 1.6484	 pickout: 0.2225	 decision: 0.2419	 get_bound: 0.9595	 add_domain: 0.2245
Current lb:-0.1638697385787964
54848 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 54.46719193458557

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 193] [1, 73] [4, 193] [4, 193] [1, 99] [1, 73] [1, 99] [4, 193] [1, 73] [3, 150] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 122.65977478027344 with beta sum per layer: [272.2485046386719, 836.8192138671875, 535.0074462890625, 2386.349365234375, 1536.7269287109375]
alpha/beta optimization time: 0.3901176452636719
This batch time : update_bounds func: 0.9586	 prepare: 0.3255	 bound: 0.3906	 transfer: 0.0232	 finalize: 0.2121
Accumulated time: update_bounds func: 34.5186	 prepare: 8.8845	 bound: 15.5276	 transfer: 0.0232	 finalize: 8.7590
batch bounding time:  0.9608790874481201
Current worst splitting domains [lb, ub] (depth):
[-0.15460,   inf] (75), [-0.15414,   inf] (75), [-0.15319,   inf] (75), [-0.15247,   inf] (75), [-0.15201,   inf] (75), [-0.15090,   inf] (75), [-0.15034,   inf] (75), [-0.14989,   inf] (75), [-0.14974,   inf] (75), [-0.14893,   inf] (75), [-0.14720,   inf] (75), [-0.14650,   inf] (75), [-0.14573,   inf] (75), [-0.14261,   inf] (75), [-0.14116,   inf] (75), [-0.14073,   inf] (75), [-0.14000,   inf] (75), [-0.13926,   inf] (75), [-0.13907,   inf] (75), [-0.13878,   inf] (75), 
length of domains: 17979
Total time: 2.2379	 pickout: 0.2356	 decision: 0.8179	 get_bound: 0.9645	 add_domain: 0.2199
Current lb:-0.15460240840911865
56896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 56.74867916107178

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 114] [3, 93] [2, 75] [4, 49] [3, 114] [3, 93] [2, 75] [3, 93] [4, 49] [3, 114] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 122.22639465332031 with beta sum per layer: [275.7716369628906, 877.1714477539062, 537.2991943359375, 2364.4560546875, 1599.503662109375]
alpha/beta optimization time: 0.39231419563293457
This batch time : update_bounds func: 0.9630	 prepare: 0.3249	 bound: 0.3929	 transfer: 0.0216	 finalize: 0.2173
Accumulated time: update_bounds func: 35.4817	 prepare: 9.2094	 bound: 15.9204	 transfer: 0.0216	 finalize: 8.9763
batch bounding time:  0.9652121067047119
Current worst splitting domains [lb, ub] (depth):
[-0.15055,   inf] (77), [-0.14851,   inf] (77), [-0.14827,   inf] (77), [-0.14782,   inf] (77), [-0.14665,   inf] (77), [-0.14595,   inf] (77), [-0.14507,   inf] (77), [-0.14400,   inf] (77), [-0.14326,   inf] (77), [-0.14127,   inf] (77), [-0.14116,   inf] (77), [-0.13930,   inf] (77), [-0.13881,   inf] (77), [-0.13722,   inf] (77), [-0.13702,   inf] (77), [-0.13631,   inf] (77), [-0.13544,   inf] (77), [-0.13517,   inf] (77), [-0.13504,   inf] (77), [-0.13482,   inf] (77), 
length of domains: 18590
Total time: 2.3068	 pickout: 0.2517	 decision: 0.2485	 get_bound: 0.9688	 add_domain: 0.8377
Current lb:-0.15054583549499512
58944 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 59.1032657623291

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 28] [2, 197] [3, 28] [3, 28] [3, 28] [2, 197] [3, 28] [3, 28] [3, 28] [3, 28] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 120.60086822509766 with beta sum per layer: [286.417236328125, 884.519775390625, 498.19342041015625, 2381.21728515625, 1710.023193359375]
alpha/beta optimization time: 0.3927896022796631
This batch time : update_bounds func: 0.9901	 prepare: 0.3413	 bound: 0.3933	 transfer: 0.0227	 finalize: 0.2259
Accumulated time: update_bounds func: 36.4718	 prepare: 9.5507	 bound: 16.3137	 transfer: 0.0227	 finalize: 9.2022
batch bounding time:  0.9926738739013672
Current worst splitting domains [lb, ub] (depth):
[-0.14126,   inf] (79), [-0.13850,   inf] (79), [-0.13756,   inf] (79), [-0.13739,   inf] (79), [-0.13608,   inf] (79), [-0.13542,   inf] (79), [-0.13517,   inf] (79), [-0.13471,   inf] (79), [-0.13457,   inf] (79), [-0.13406,   inf] (79), [-0.13365,   inf] (79), [-0.13349,   inf] (79), [-0.13289,   inf] (79), [-0.13191,   inf] (79), [-0.13111,   inf] (79), [-0.13100,   inf] (79), [-0.13095,   inf] (79), [-0.13067,   inf] (79), [-0.13054,   inf] (79), [-0.13021,   inf] (79), 
length of domains: 19210
Total time: 1.7347	 pickout: 0.2397	 decision: 0.2640	 get_bound: 0.9967	 add_domain: 0.2344
Current lb:-0.14126431941986084
60992 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 60.88671112060547

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 99] [2, 99] [1, 177] [1, 177] [2, 75] [4, 49] [3, 28] [2, 99] [4, 35] [1, 99] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 114.64091491699219 with beta sum per layer: [284.7359619140625, 841.0389404296875, 557.66259765625, 2272.9140625, 1644.637939453125]
alpha/beta optimization time: 0.3976438045501709
This batch time : update_bounds func: 1.5931	 prepare: 0.3226	 bound: 0.3981	 transfer: 0.0224	 finalize: 0.8428
Accumulated time: update_bounds func: 38.0649	 prepare: 9.8734	 bound: 16.7118	 transfer: 0.0224	 finalize: 10.0450
batch bounding time:  1.5956130027770996
Current worst splitting domains [lb, ub] (depth):
[-0.13771,   inf] (81), [-0.13498,   inf] (81), [-0.13375,   inf] (81), [-0.13332,   inf] (81), [-0.13324,   inf] (81), [-0.13173,   inf] (81), [-0.13099,   inf] (81), [-0.13030,   inf] (81), [-0.12833,   inf] (81), [-0.12830,   inf] (81), [-0.12787,   inf] (81), [-0.12787,   inf] (81), [-0.12778,   inf] (81), [-0.12603,   inf] (81), [-0.12534,   inf] (81), [-0.12508,   inf] (81), [-0.12480,   inf] (81), [-0.12477,   inf] (81), [-0.12451,   inf] (81), [-0.12399,   inf] (81), 
length of domains: 19812
Total time: 2.3263	 pickout: 0.2470	 decision: 0.2532	 get_bound: 1.5995	 add_domain: 0.2265
Current lb:-0.1377112865447998
63040 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 63.260581254959106

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 49] [4, 49] [1, 99] [2, 165] [2, 99] [2, 165] [4, 49] [1, 99] [4, 22] [4, 49] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 110.46577453613281 with beta sum per layer: [293.2447814941406, 853.1480712890625, 521.444091796875, 2438.65087890625, 1636.5511474609375]
alpha/beta optimization time: 0.39254045486450195
This batch time : update_bounds func: 0.9568	 prepare: 0.3227	 bound: 0.3931	 transfer: 0.0216	 finalize: 0.2135
Accumulated time: update_bounds func: 39.0217	 prepare: 10.1961	 bound: 17.1049	 transfer: 0.0216	 finalize: 10.2585
batch bounding time:  0.958899974822998
Current worst splitting domains [lb, ub] (depth):
[-0.13595,   inf] (83), [-0.13320,   inf] (83), [-0.13007,   inf] (83), [-0.13006,   inf] (83), [-0.12946,   inf] (83), [-0.12889,   inf] (83), [-0.12874,   inf] (83), [-0.12677,   inf] (83), [-0.12632,   inf] (83), [-0.12631,   inf] (83), [-0.12542,   inf] (83), [-0.12362,   inf] (83), [-0.12322,   inf] (83), [-0.12311,   inf] (83), [-0.12280,   inf] (83), [-0.12264,   inf] (83), [-0.12247,   inf] (83), [-0.12230,   inf] (83), [-0.12207,   inf] (83), [-0.12041,   inf] (83), 
length of domains: 20397
Total time: 1.6706	 pickout: 0.2388	 decision: 0.2437	 get_bound: 0.9625	 add_domain: 0.2257
Current lb:-0.13595008850097656
65088 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 64.97488975524902

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 28] [3, 28] [2, 165] [2, 197] [1, 177] [2, 197] [2, 39] [4, 35] [1, 177] [1, 56] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 108.95808410644531 with beta sum per layer: [290.9637145996094, 837.334716796875, 552.8284301757812, 2445.54736328125, 1650.119140625]
alpha/beta optimization time: 0.3885958194732666
This batch time : update_bounds func: 0.9542	 prepare: 0.3239	 bound: 0.3891	 transfer: 0.0217	 finalize: 0.2119
Accumulated time: update_bounds func: 39.9759	 prepare: 10.5200	 bound: 17.4939	 transfer: 0.0217	 finalize: 10.4704
batch bounding time:  0.9564001560211182
Current worst splitting domains [lb, ub] (depth):
[-0.12695,   inf] (85), [-0.12408,   inf] (85), [-0.12389,   inf] (85), [-0.12369,   inf] (85), [-0.12362,   inf] (85), [-0.12323,   inf] (85), [-0.12142,   inf] (85), [-0.12129,   inf] (85), [-0.12109,   inf] (85), [-0.12087,   inf] (85), [-0.12064,   inf] (85), [-0.12049,   inf] (85), [-0.12031,   inf] (85), [-0.11891,   inf] (85), [-0.11840,   inf] (85), [-0.11813,   inf] (85), [-0.11751,   inf] (85), [-0.11659,   inf] (85), [-0.11636,   inf] (85), [-0.11603,   inf] (85), 
length of domains: 20978
Total time: 2.3255	 pickout: 0.2339	 decision: 0.9046	 get_bound: 0.9601	 add_domain: 0.2269
Current lb:-0.12695050239562988
67136 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 67.35424947738647

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 197] [4, 35] [2, 99] [2, 39] [2, 39] [1, 177] [2, 75] [4, 35] [2, 39] [2, 39] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 106.84760284423828 with beta sum per layer: [293.59307861328125, 857.6810302734375, 605.6689453125, 2336.1435546875, 1730.010986328125]
alpha/beta optimization time: 0.392991304397583
This batch time : update_bounds func: 0.9657	 prepare: 0.3275	 bound: 0.3935	 transfer: 0.0224	 finalize: 0.2160
Accumulated time: update_bounds func: 40.9415	 prepare: 10.8475	 bound: 17.8874	 transfer: 0.0224	 finalize: 10.6864
batch bounding time:  0.9683036804199219
Current worst splitting domains [lb, ub] (depth):
[-0.12103,   inf] (87), [-0.12054,   inf] (87), [-0.11918,   inf] (87), [-0.11860,   inf] (87), [-0.11815,   inf] (87), [-0.11793,   inf] (87), [-0.11622,   inf] (87), [-0.11602,   inf] (87), [-0.11580,   inf] (87), [-0.11577,   inf] (87), [-0.11559,   inf] (87), [-0.11514,   inf] (87), [-0.11444,   inf] (87), [-0.11379,   inf] (87), [-0.11319,   inf] (87), [-0.11292,   inf] (87), [-0.11258,   inf] (87), [-0.11224,   inf] (87), [-0.11211,   inf] (87), [-0.11069,   inf] (87), 
length of domains: 21540
Total time: 2.4059	 pickout: 0.2327	 decision: 0.2483	 get_bound: 0.9724	 add_domain: 0.9525
Current lb:-0.12102515250444412
69184 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 69.80843377113342

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 35] [4, 35] [4, 35] [4, 35] [1, 120] [1, 120] [4, 35] [4, 35] [1, 120] [1, 56] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 105.79027557373047 with beta sum per layer: [292.7694091796875, 861.4171142578125, 600.94482421875, 2378.5068359375, 1705.0396728515625]
alpha/beta optimization time: 0.3885209560394287
This batch time : update_bounds func: 0.9632	 prepare: 0.3328	 bound: 0.3890	 transfer: 0.0222	 finalize: 0.2124
Accumulated time: update_bounds func: 41.9048	 prepare: 11.1803	 bound: 18.2764	 transfer: 0.0222	 finalize: 10.8987
batch bounding time:  0.9653644561767578
Current worst splitting domains [lb, ub] (depth):
[-0.11604,   inf] (89), [-0.11546,   inf] (89), [-0.11473,   inf] (89), [-0.11419,   inf] (89), [-0.11336,   inf] (89), [-0.11258,   inf] (89), [-0.11255,   inf] (89), [-0.11226,   inf] (89), [-0.11130,   inf] (89), [-0.11039,   inf] (89), [-0.10973,   inf] (89), [-0.10968,   inf] (89), [-0.10948,   inf] (89), [-0.10914,   inf] (89), [-0.10871,   inf] (89), [-0.10844,   inf] (89), [-0.10755,   inf] (89), [-0.10751,   inf] (89), [-0.10740,   inf] (89), [-0.10659,   inf] (89), 
length of domains: 22126
Total time: 1.6757	 pickout: 0.2277	 decision: 0.2505	 get_bound: 0.9690	 add_domain: 0.2285
Current lb:-0.11603951454162598
71232 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 71.53235054016113

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 39] [4, 35] [4, 22] [4, 22] [4, 35] [4, 22] [2, 165] [1, 56] [4, 86] [4, 86] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 96.9393310546875 with beta sum per layer: [304.1630859375, 855.4706420898438, 591.3634033203125, 2298.9306640625, 1724.9124755859375]
alpha/beta optimization time: 0.3988940715789795
This batch time : update_bounds func: 1.7532	 prepare: 0.3435	 bound: 0.3994	 transfer: 0.0235	 finalize: 0.9793
Accumulated time: update_bounds func: 43.6580	 prepare: 11.5238	 bound: 18.6758	 transfer: 0.0235	 finalize: 11.8780
batch bounding time:  1.756103277206421
Current worst splitting domains [lb, ub] (depth):
[-0.11220,   inf] (91), [-0.10922,   inf] (91), [-0.10917,   inf] (91), [-0.10909,   inf] (91), [-0.10853,   inf] (91), [-0.10839,   inf] (91), [-0.10782,   inf] (91), [-0.10766,   inf] (91), [-0.10693,   inf] (91), [-0.10676,   inf] (91), [-0.10670,   inf] (91), [-0.10589,   inf] (91), [-0.10575,   inf] (91), [-0.10525,   inf] (91), [-0.10500,   inf] (91), [-0.10494,   inf] (91), [-0.10492,   inf] (91), [-0.10484,   inf] (91), [-0.10439,   inf] (91), [-0.10384,   inf] (91), 
length of domains: 22646
Total time: 2.4892	 pickout: 0.2380	 decision: 0.2704	 get_bound: 1.7603	 add_domain: 0.2205
Current lb:-0.11219930648803711
73280 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 74.0723328590393

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 86] [2, 99] [4, 86] [4, 31] [4, 31] [4, 31] [4, 22] [2, 39] [4, 31] [4, 86] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 95.99415588378906 with beta sum per layer: [295.924072265625, 842.5904541015625, 643.8545532226562, 2446.32666015625, 1790.4725341796875]
alpha/beta optimization time: 0.392594575881958
This batch time : update_bounds func: 0.9660	 prepare: 0.3328	 bound: 0.3931	 transfer: 0.0229	 finalize: 0.2108
Accumulated time: update_bounds func: 44.6240	 prepare: 11.8566	 bound: 19.0689	 transfer: 0.0229	 finalize: 12.0889
batch bounding time:  0.9681210517883301
Current worst splitting domains [lb, ub] (depth):
[-0.10762,   inf] (93), [-0.10639,   inf] (93), [-0.10626,   inf] (93), [-0.10582,   inf] (93), [-0.10570,   inf] (93), [-0.10495,   inf] (93), [-0.10449,   inf] (93), [-0.10404,   inf] (93), [-0.10374,   inf] (93), [-0.10322,   inf] (93), [-0.10289,   inf] (93), [-0.10240,   inf] (93), [-0.10221,   inf] (93), [-0.10207,   inf] (93), [-0.10192,   inf] (93), [-0.10177,   inf] (93), [-0.10170,   inf] (93), [-0.10106,   inf] (93), [-0.10096,   inf] (93), [-0.10041,   inf] (93), 
length of domains: 23191
Total time: 1.6760	 pickout: 0.2294	 decision: 0.2485	 get_bound: 0.9718	 add_domain: 0.2262
Current lb:-0.10762035846710205
75328 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 75.79782128334045

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 31] [4, 86] [2, 197] [4, 86] [4, 86] [4, 31] [4, 31] [1, 120] [4, 31] [4, 31] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 97.03958129882812 with beta sum per layer: [284.41876220703125, 871.5592041015625, 627.9718017578125, 2337.57373046875, 1686.175537109375]
alpha/beta optimization time: 0.39200592041015625
This batch time : update_bounds func: 1.7846	 prepare: 0.3270	 bound: 0.3926	 transfer: 0.0224	 finalize: 1.0360
Accumulated time: update_bounds func: 46.4087	 prepare: 12.1836	 bound: 19.4615	 transfer: 0.0224	 finalize: 13.1248
batch bounding time:  1.787367343902588
Current worst splitting domains [lb, ub] (depth):
[-0.10491,   inf] (95), [-0.10226,   inf] (95), [-0.10214,   inf] (95), [-0.10179,   inf] (95), [-0.10178,   inf] (95), [-0.10120,   inf] (95), [-0.10107,   inf] (95), [-0.10092,   inf] (95), [-0.10037,   inf] (95), [-0.10014,   inf] (95), [-0.09964,   inf] (95), [-0.09938,   inf] (95), [-0.09923,   inf] (95), [-0.09913,   inf] (95), [-0.09910,   inf] (95), [-0.09908,   inf] (95), [-0.09879,   inf] (95), [-0.09829,   inf] (95), [-0.09758,   inf] (95), [-0.09673,   inf] (95), 
length of domains: 23751
Total time: 2.5137	 pickout: 0.2316	 decision: 0.2554	 get_bound: 1.7914	 add_domain: 0.2353
Current lb:-0.10491383075714111
77376 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 78.3632299900055

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 22] [4, 22] [4, 86] [4, 22] [1, 56] [2, 39] [1, 56] [4, 86] [2, 71] [2, 71] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 95.66508483886719 with beta sum per layer: [302.0809020996094, 877.7393188476562, 597.69873046875, 2444.0439453125, 1835.6058349609375]
alpha/beta optimization time: 0.40894389152526855
This batch time : update_bounds func: 1.0059	 prepare: 0.3506	 bound: 0.4094	 transfer: 0.0225	 finalize: 0.2163
Accumulated time: update_bounds func: 47.4146	 prepare: 12.5341	 bound: 19.8709	 transfer: 0.0225	 finalize: 13.3411
batch bounding time:  1.008589267730713
Current worst splitting domains [lb, ub] (depth):
[-0.09917,   inf] (97), [-0.09884,   inf] (97), [-0.09872,   inf] (97), [-0.09836,   inf] (97), [-0.09827,   inf] (97), [-0.09802,   inf] (97), [-0.09768,   inf] (97), [-0.09743,   inf] (97), [-0.09656,   inf] (97), [-0.09614,   inf] (97), [-0.09611,   inf] (97), [-0.09610,   inf] (97), [-0.09568,   inf] (97), [-0.09563,   inf] (97), [-0.09488,   inf] (97), [-0.09481,   inf] (97), [-0.09463,   inf] (97), [-0.09460,   inf] (97), [-0.09443,   inf] (97), [-0.09441,   inf] (97), 
length of domains: 24317
Total time: 1.7566	 pickout: 0.2382	 decision: 0.2687	 get_bound: 1.0128	 add_domain: 0.2369
Current lb:-0.09917052090167999
79424 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 80.17370867729187

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 57] [4, 86] [4, 22] [4, 57] [3, 19] [3, 168] [3, 19] [2, 71] [1, 56] [4, 86] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 91.9661636352539 with beta sum per layer: [333.6209411621094, 869.0020751953125, 666.044677734375, 2425.5185546875, 1783.404541015625]
alpha/beta optimization time: 0.3964579105377197
This batch time : update_bounds func: 1.8557	 prepare: 0.3453	 bound: 0.3969	 transfer: 0.0228	 finalize: 1.0830
Accumulated time: update_bounds func: 49.2702	 prepare: 12.8794	 bound: 20.2679	 transfer: 0.0228	 finalize: 14.4241
batch bounding time:  1.858426809310913
Current worst splitting domains [lb, ub] (depth):
[-0.09618,   inf] (99), [-0.09593,   inf] (99), [-0.09544,   inf] (99), [-0.09530,   inf] (99), [-0.09495,   inf] (99), [-0.09426,   inf] (99), [-0.09409,   inf] (99), [-0.09364,   inf] (99), [-0.09347,   inf] (99), [-0.09337,   inf] (99), [-0.09325,   inf] (99), [-0.09324,   inf] (99), [-0.09309,   inf] (99), [-0.09275,   inf] (99), [-0.09274,   inf] (99), [-0.09232,   inf] (99), [-0.09201,   inf] (99), [-0.09147,   inf] (99), [-0.09143,   inf] (99), [-0.09135,   inf] (99), 
length of domains: 24868
Total time: 2.6051	 pickout: 0.2407	 decision: 0.2705	 get_bound: 1.8627	 add_domain: 0.2312
Current lb:-0.0961838960647583
81472 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 82.82883787155151

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 123] [4, 57] [4, 57] [4, 57] [3, 19] [3, 19] [3, 168] [4, 57] [3, 19] [4, 57] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 91.49746704101562 with beta sum per layer: [294.803466796875, 860.834716796875, 531.165283203125, 2441.62353515625, 1817.8521728515625]
alpha/beta optimization time: 0.39358043670654297
This batch time : update_bounds func: 0.9750	 prepare: 0.3369	 bound: 0.3941	 transfer: 0.0227	 finalize: 0.2139
Accumulated time: update_bounds func: 50.2452	 prepare: 13.2163	 bound: 20.6619	 transfer: 0.0227	 finalize: 14.6380
batch bounding time:  0.977363109588623
Current worst splitting domains [lb, ub] (depth):
[-0.09487,   inf] (101), [-0.09259,   inf] (101), [-0.09208,   inf] (101), [-0.09189,   inf] (101), [-0.09168,   inf] (101), [-0.09140,   inf] (101), [-0.09114,   inf] (101), [-0.09104,   inf] (101), [-0.09103,   inf] (101), [-0.09058,   inf] (101), [-0.09047,   inf] (101), [-0.09032,   inf] (101), [-0.09000,   inf] (101), [-0.08999,   inf] (101), [-0.08937,   inf] (101), [-0.08931,   inf] (79), [-0.08924,   inf] (101), [-0.08907,   inf] (101), [-0.08904,   inf] (69), [-0.08904,   inf] (53), 
length of domains: 25421
Total time: 1.7020	 pickout: 0.2306	 decision: 0.2572	 get_bound: 0.9824	 add_domain: 0.2318
Current lb:-0.09486863017082214
83520 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 84.58219647407532

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 19] [2, 67] [2, 67] [3, 19] [3, 158] [2, 160] [3, 158] [4, 38] [2, 67] [2, 67] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 87.25977325439453 with beta sum per layer: [335.6153564453125, 901.9420166015625, 646.8218994140625, 2392.691650390625, 1805.75830078125]
alpha/beta optimization time: 0.39679861068725586
This batch time : update_bounds func: 0.9742	 prepare: 0.3323	 bound: 0.3973	 transfer: 0.0223	 finalize: 0.2154
Accumulated time: update_bounds func: 51.2194	 prepare: 13.5486	 bound: 21.0592	 transfer: 0.0223	 finalize: 14.8534
batch bounding time:  0.9764833450317383
Current worst splitting domains [lb, ub] (depth):
[-0.09270,   inf] (103), [-0.09042,   inf] (103), [-0.09041,   inf] (103), [-0.09010,   inf] (103), [-0.08996,   inf] (103), [-0.08965,   inf] (103), [-0.08933,   inf] (103), [-0.08924,   inf] (103), [-0.08876,   inf] (103), [-0.08870,   inf] (103), [-0.08846,   inf] (103), [-0.08831,   inf] (103), [-0.08824,   inf] (77), [-0.08814,   inf] (103), [-0.08802,   inf] (81), [-0.08800,   inf] (39), [-0.08799,   inf] (51), [-0.08799,   inf] (49), [-0.08799,   inf] (67), [-0.08799,   inf] (49), 
length of domains: 25978
Total time: 2.6013	 pickout: 0.2322	 decision: 0.2557	 get_bound: 0.9802	 add_domain: 1.1332
Current lb:-0.09269757568836212
85568 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 87.23356032371521

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 57] [4, 38] [1, 56] [1, 56] [4, 38] [4, 57] [4, 57] [4, 57] [2, 160] [4, 57] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 88.92591857910156 with beta sum per layer: [323.3212585449219, 872.704833984375, 591.339599609375, 2481.0166015625, 1907.94482421875]
alpha/beta optimization time: 0.39171743392944336
This batch time : update_bounds func: 0.9844	 prepare: 0.3465	 bound: 0.3922	 transfer: 0.0223	 finalize: 0.2157
Accumulated time: update_bounds func: 52.2038	 prepare: 13.8951	 bound: 21.4514	 transfer: 0.0223	 finalize: 15.0691
batch bounding time:  0.9869821071624756
Current worst splitting domains [lb, ub] (depth):
[-0.08858,   inf] (105), [-0.08756,   inf] (105), [-0.08741,   inf] (105), [-0.08720,   inf] (79), [-0.08698,   inf] (97), [-0.08698,   inf] (65), [-0.08698,   inf] (87), [-0.08698,   inf] (31), [-0.08698,   inf] (67), [-0.08697,   inf] (59), [-0.08697,   inf] (67), [-0.08697,   inf] (49), [-0.08697,   inf] (99), [-0.08697,   inf] (63), [-0.08697,   inf] (73), [-0.08697,   inf] (47), [-0.08697,   inf] (85), [-0.08697,   inf] (79), [-0.08697,   inf] (53), [-0.08697,   inf] (83), 
length of domains: 26546
Total time: 1.7132	 pickout: 0.2277	 decision: 0.2601	 get_bound: 0.9910	 add_domain: 0.2344
Current lb:-0.08857619762420654
87616 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 88.99681615829468

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 158] [3, 158] [4, 38] [3, 93] [2, 67] [2, 197] [4, 57] [3, 32] [0, 45] [0, 173] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 86.55014038085938 with beta sum per layer: [326.87567138671875, 851.3101806640625, 650.4846801757812, 2419.0869140625, 1853.660400390625]
alpha/beta optimization time: 0.400005578994751
This batch time : update_bounds func: 0.9812	 prepare: 0.3360	 bound: 0.4005	 transfer: 0.0223	 finalize: 0.2153
Accumulated time: update_bounds func: 53.1850	 prepare: 14.2311	 bound: 21.8519	 transfer: 0.0223	 finalize: 15.2845
batch bounding time:  0.9833991527557373
Current worst splitting domains [lb, ub] (depth):
[-0.08740,   inf] (107), [-0.08644,   inf] (107), [-0.08604,   inf] (79), [-0.08604,   inf] (71), [-0.08604,   inf] (57), [-0.08604,   inf] (95), [-0.08604,   inf] (67), [-0.08604,   inf] (57), [-0.08604,   inf] (43), [-0.08604,   inf] (59), [-0.08603,   inf] (83), [-0.08603,   inf] (73), [-0.08603,   inf] (47), [-0.08603,   inf] (63), [-0.08603,   inf] (91), [-0.08603,   inf] (97), [-0.08603,   inf] (55), [-0.08603,   inf] (37), [-0.08603,   inf] (85), [-0.08603,   inf] (49), 
length of domains: 27103
Total time: 1.7149	 pickout: 0.2324	 decision: 0.2610	 get_bound: 0.9871	 add_domain: 0.2344
Current lb:-0.08739995956420898
89664 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 90.77045917510986

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 160] [4, 38] [3, 158] [4, 35] [1, 138] [2, 71] [4, 35] [1, 77] [0, 42] [1, 73] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 85.41527557373047 with beta sum per layer: [340.14093017578125, 871.526611328125, 637.6024169921875, 2377.4599609375, 1856.493408203125]
alpha/beta optimization time: 0.39262866973876953
This batch time : update_bounds func: 0.9814	 prepare: 0.3380	 bound: 0.3931	 transfer: 0.0223	 finalize: 0.2208
Accumulated time: update_bounds func: 54.1664	 prepare: 14.5691	 bound: 22.2450	 transfer: 0.0223	 finalize: 15.5052
batch bounding time:  0.9837610721588135
Current worst splitting domains [lb, ub] (depth):
[-0.08556,   inf] (109), [-0.08509,   inf] (53), [-0.08509,   inf] (65), [-0.08509,   inf] (73), [-0.08509,   inf] (55), [-0.08508,   inf] (67), [-0.08508,   inf] (41), [-0.08508,   inf] (87), [-0.08508,   inf] (55), [-0.08508,   inf] (41), [-0.08507,   inf] (75), [-0.08507,   inf] (55), [-0.08507,   inf] (59), [-0.08507,   inf] (55), [-0.08507,   inf] (63), [-0.08507,   inf] (67), [-0.08507,   inf] (69), [-0.08507,   inf] (57), [-0.08507,   inf] (71), [-0.08506,   inf] (91), 
length of domains: 27646
Total time: 2.6512	 pickout: 0.2350	 decision: 1.1951	 get_bound: 0.9876	 add_domain: 0.2336
Current lb:-0.08556103706359863
91712 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 93.4738781452179

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 38] [1, 56] [3, 150] [2, 75] [1, 73] [3, 93] [3, 115] [2, 71] [1, 177] [3, 114] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 82.220703125 with beta sum per layer: [287.83026123046875, 897.998779296875, 604.2916870117188, 2462.869140625, 1910.061767578125]
alpha/beta optimization time: 0.39699363708496094
This batch time : update_bounds func: 0.9951	 prepare: 0.3507	 bound: 0.3975	 transfer: 0.0222	 finalize: 0.2175
Accumulated time: update_bounds func: 55.1616	 prepare: 14.9198	 bound: 22.6425	 transfer: 0.0222	 finalize: 15.7228
batch bounding time:  0.9972953796386719
Current worst splitting domains [lb, ub] (depth):
[-0.08414,   inf] (45), [-0.08413,   inf] (55), [-0.08413,   inf] (45), [-0.08413,   inf] (59), [-0.08413,   inf] (67), [-0.08413,   inf] (99), [-0.08413,   inf] (69), [-0.08413,   inf] (59), [-0.08413,   inf] (61), [-0.08413,   inf] (59), [-0.08413,   inf] (53), [-0.08413,   inf] (89), [-0.08413,   inf] (73), [-0.08413,   inf] (57), [-0.08412,   inf] (83), [-0.08412,   inf] (63), [-0.08412,   inf] (95), [-0.08412,   inf] (77), [-0.08412,   inf] (77), [-0.08412,   inf] (53), 
length of domains: 28178
Total time: 1.7196	 pickout: 0.2292	 decision: 0.2561	 get_bound: 1.0010	 add_domain: 0.2332
Current lb:-0.08413508534431458
93760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 95.24687004089355

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 39] [0, 113] [1, 76] [0, 173] [0, 45] [3, 19] [4, 49] [2, 99] [2, 88] [1, 73] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 82.99505615234375 with beta sum per layer: [302.50653076171875, 867.8338623046875, 644.2373657226562, 2572.2724609375, 1989.96923828125]
alpha/beta optimization time: 0.3924903869628906
This batch time : update_bounds func: 1.9100	 prepare: 0.3349	 bound: 0.3930	 transfer: 0.0222	 finalize: 0.2202
Accumulated time: update_bounds func: 57.0716	 prepare: 15.2547	 bound: 23.0355	 transfer: 0.0222	 finalize: 15.9429
batch bounding time:  1.913036823272705
Current worst splitting domains [lb, ub] (depth):
[-0.08329,   inf] (63), [-0.08325,   inf] (71), [-0.08325,   inf] (81), [-0.08325,   inf] (49), [-0.08325,   inf] (71), [-0.08325,   inf] (59), [-0.08325,   inf] (103), [-0.08324,   inf] (89), [-0.08324,   inf] (91), [-0.08324,   inf] (33), [-0.08324,   inf] (91), [-0.08324,   inf] (97), [-0.08324,   inf] (53), [-0.08324,   inf] (53), [-0.08324,   inf] (87), [-0.08324,   inf] (63), [-0.08324,   inf] (79), [-0.08324,   inf] (73), [-0.08324,   inf] (91), [-0.08324,   inf] (43), 
length of domains: 28727
Total time: 2.6499	 pickout: 0.2363	 decision: 0.2598	 get_bound: 1.9174	 add_domain: 0.2365
Current lb:-0.08329081535339355
95808 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 97.94359564781189

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 173] [2, 71] [1, 177] [4, 132] [4, 49] [4, 95] [4, 57] [2, 67] [2, 75] [4, 19] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 81.43913269042969 with beta sum per layer: [322.16357421875, 856.0086669921875, 617.46337890625, 2455.903564453125, 1923.8289794921875]
alpha/beta optimization time: 0.3931586742401123
This batch time : update_bounds func: 0.9790	 prepare: 0.3395	 bound: 0.3936	 transfer: 0.0216	 finalize: 0.2167
Accumulated time: update_bounds func: 58.0506	 prepare: 15.5941	 bound: 23.4291	 transfer: 0.0216	 finalize: 16.1597
batch bounding time:  0.9813461303710938
Current worst splitting domains [lb, ub] (depth):
[-0.08237,   inf] (45), [-0.08236,   inf] (93), [-0.08236,   inf] (63), [-0.08236,   inf] (85), [-0.08236,   inf] (93), [-0.08236,   inf] (37), [-0.08236,   inf] (69), [-0.08236,   inf] (71), [-0.08236,   inf] (83), [-0.08236,   inf] (49), [-0.08236,   inf] (65), [-0.08236,   inf] (83), [-0.08236,   inf] (73), [-0.08236,   inf] (69), [-0.08236,   inf] (81), [-0.08236,   inf] (51), [-0.08235,   inf] (75), [-0.08235,   inf] (41), [-0.08235,   inf] (57), [-0.08235,   inf] (97), 
length of domains: 29271
Total time: 1.7272	 pickout: 0.2506	 decision: 0.2560	 get_bound: 0.9851	 add_domain: 0.2355
Current lb:-0.08236539363861084
97856 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 99.72299551963806

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 73] [1, 177] [3, 93] [4, 86] [4, 86] [4, 67] [0, 45] [3, 150] [4, 49] [4, 132] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 76.5660400390625 with beta sum per layer: [330.7808837890625, 947.77001953125, 620.98046875, 2385.3623046875, 1961.22900390625]
alpha/beta optimization time: 0.39656758308410645
This batch time : update_bounds func: 2.0309	 prepare: 0.3366	 bound: 0.3970	 transfer: 0.0223	 finalize: 1.2676
Accumulated time: update_bounds func: 60.0815	 prepare: 15.9307	 bound: 23.8262	 transfer: 0.0223	 finalize: 17.4273
batch bounding time:  2.0333895683288574
Current worst splitting domains [lb, ub] (depth):
[-0.08186,   inf] (77), [-0.08158,   inf] (75), [-0.08156,   inf] (73), [-0.08156,   inf] (75), [-0.08156,   inf] (45), [-0.08156,   inf] (37), [-0.08156,   inf] (45), [-0.08156,   inf] (79), [-0.08156,   inf] (53), [-0.08156,   inf] (99), [-0.08156,   inf] (91), [-0.08155,   inf] (51), [-0.08155,   inf] (83), [-0.08155,   inf] (91), [-0.08155,   inf] (47), [-0.08155,   inf] (89), [-0.08155,   inf] (41), [-0.08155,   inf] (107), [-0.08155,   inf] (67), [-0.08155,   inf] (45), 
length of domains: 29776
Total time: 2.7711	 pickout: 0.2394	 decision: 0.2645	 get_bound: 2.0374	 add_domain: 0.2299
Current lb:-0.08185970783233643
99904 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 102.54130434989929

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 22] [2, 160] [2, 39] [2, 39] [0, 173] [4, 91] [3, 115] [3, 28] [3, 115] [4, 38] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 78.72465515136719 with beta sum per layer: [321.13140869140625, 887.8358764648438, 655.6285400390625, 2333.13232421875, 1903.5347900390625]
alpha/beta optimization time: 0.3942091464996338
This batch time : update_bounds func: 0.9770	 prepare: 0.3353	 bound: 0.3947	 transfer: 0.0223	 finalize: 0.2174
Accumulated time: update_bounds func: 61.0585	 prepare: 16.2661	 bound: 24.2209	 transfer: 0.0223	 finalize: 17.6447
batch bounding time:  0.9792163372039795
Current worst splitting domains [lb, ub] (depth):
[-0.08074,   inf] (59), [-0.08074,   inf] (51), [-0.08074,   inf] (53), [-0.08074,   inf] (101), [-0.08074,   inf] (41), [-0.08074,   inf] (51), [-0.08074,   inf] (97), [-0.08074,   inf] (59), [-0.08074,   inf] (81), [-0.08074,   inf] (43), [-0.08074,   inf] (99), [-0.08074,   inf] (47), [-0.08073,   inf] (75), [-0.08073,   inf] (79), [-0.08073,   inf] (37), [-0.08073,   inf] (43), [-0.08073,   inf] (69), [-0.08073,   inf] (101), [-0.08073,   inf] (81), [-0.08073,   inf] (73), 
length of domains: 30308
Total time: 1.7218	 pickout: 0.2365	 decision: 0.2624	 get_bound: 0.9830	 add_domain: 0.2400
Current lb:-0.08074343204498291
101952 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 104.3118064403534

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 193] [4, 193] [4, 95] [4, 142] [1, 73] [4, 193] [2, 123] [2, 71] [4, 57] [0, 173] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 77.83927917480469 with beta sum per layer: [319.63897705078125, 849.55126953125, 644.9860229492188, 2277.561279296875, 1861.36572265625]
alpha/beta optimization time: 0.40016698837280273
This batch time : update_bounds func: 0.9953	 prepare: 0.3416	 bound: 0.4007	 transfer: 0.0217	 finalize: 0.2240
Accumulated time: update_bounds func: 62.0538	 prepare: 16.6077	 bound: 24.6215	 transfer: 0.0217	 finalize: 17.8687
batch bounding time:  0.9976756572723389
Current worst splitting domains [lb, ub] (depth):
[-0.07992,   inf] (95), [-0.07992,   inf] (53), [-0.07992,   inf] (71), [-0.07992,   inf] (51), [-0.07991,   inf] (93), [-0.07991,   inf] (73), [-0.07991,   inf] (49), [-0.07991,   inf] (47), [-0.07991,   inf] (35), [-0.07991,   inf] (85), [-0.07991,   inf] (85), [-0.07991,   inf] (53), [-0.07991,   inf] (97), [-0.07991,   inf] (73), [-0.07990,   inf] (79), [-0.07990,   inf] (35), [-0.07990,   inf] (57), [-0.07990,   inf] (47), [-0.07990,   inf] (67), [-0.07990,   inf] (105), 
length of domains: 30846
Total time: 1.7405	 pickout: 0.2395	 decision: 0.2573	 get_bound: 1.0014	 add_domain: 0.2422
Current lb:-0.07991889864206314
104000 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 106.10191535949707

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 93] [4, 193] [1, 138] [0, 173] [4, 22] [2, 67] [1, 120] [1, 177] [0, 76] [1, 195] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 77.8818359375 with beta sum per layer: [286.5893859863281, 850.1157836914062, 598.7099609375, 2417.763671875, 1925.4422607421875]
alpha/beta optimization time: 0.39383506774902344
This batch time : update_bounds func: 0.9742	 prepare: 0.3305	 bound: 0.3943	 transfer: 0.0217	 finalize: 0.2204
Accumulated time: update_bounds func: 63.0280	 prepare: 16.9381	 bound: 25.0159	 transfer: 0.0217	 finalize: 18.0891
batch bounding time:  0.9765448570251465
Current worst splitting domains [lb, ub] (depth):
[-0.07931,   inf] (115), [-0.07920,   inf] (105), [-0.07915,   inf] (85), [-0.07915,   inf] (101), [-0.07915,   inf] (49), [-0.07915,   inf] (45), [-0.07915,   inf] (47), [-0.07915,   inf] (57), [-0.07915,   inf] (55), [-0.07915,   inf] (87), [-0.07915,   inf] (91), [-0.07915,   inf] (57), [-0.07915,   inf] (53), [-0.07914,   inf] (57), [-0.07914,   inf] (85), [-0.07914,   inf] (65), [-0.07914,   inf] (59), [-0.07914,   inf] (69), [-0.07914,   inf] (61), [-0.07914,   inf] (55), 
length of domains: 31398
Total time: 2.8157	 pickout: 0.2427	 decision: 1.3460	 get_bound: 0.9803	 add_domain: 0.2467
Current lb:-0.07930872589349747
106048 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 108.9647307395935

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 52] [4, 142] [3, 16] [4, 57] [1, 73] [0, 76] [0, 113] [4, 92] [2, 75] [4, 22] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 74.8200454711914 with beta sum per layer: [319.884521484375, 848.916015625, 617.7308349609375, 2438.32373046875, 1939.69091796875]
alpha/beta optimization time: 0.4008970260620117
This batch time : update_bounds func: 0.9828	 prepare: 0.3334	 bound: 0.4014	 transfer: 0.0224	 finalize: 0.2181
Accumulated time: update_bounds func: 64.0108	 prepare: 17.2716	 bound: 25.4172	 transfer: 0.0224	 finalize: 18.3072
batch bounding time:  0.9849762916564941
Current worst splitting domains [lb, ub] (depth):
[-0.07845,   inf] (117), [-0.07841,   inf] (79), [-0.07841,   inf] (55), [-0.07841,   inf] (91), [-0.07840,   inf] (87), [-0.07840,   inf] (53), [-0.07840,   inf] (59), [-0.07840,   inf] (107), [-0.07840,   inf] (47), [-0.07840,   inf] (83), [-0.07840,   inf] (49), [-0.07840,   inf] (67), [-0.07840,   inf] (53), [-0.07840,   inf] (99), [-0.07840,   inf] (55), [-0.07840,   inf] (35), [-0.07839,   inf] (89), [-0.07839,   inf] (77), [-0.07839,   inf] (55), [-0.07839,   inf] (89), 
length of domains: 31913
Total time: 1.7476	 pickout: 0.2534	 decision: 0.2661	 get_bound: 0.9888	 add_domain: 0.2394
Current lb:-0.07844854146242142
108096 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 110.7615795135498

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 52] [2, 165] [4, 132] [4, 22] [4, 86] [0, 113] [4, 95] [4, 142] [3, 53] [4, 22] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 72.17750549316406 with beta sum per layer: [296.0372314453125, 877.1736450195312, 644.3272705078125, 2440.7705078125, 1920.699951171875]
alpha/beta optimization time: 0.409163236618042
This batch time : update_bounds func: 2.1990	 prepare: 0.3584	 bound: 0.4096	 transfer: 0.0223	 finalize: 1.4010
Accumulated time: update_bounds func: 66.2098	 prepare: 17.6300	 bound: 25.8269	 transfer: 0.0223	 finalize: 19.7083
batch bounding time:  2.2016732692718506
Current worst splitting domains [lb, ub] (depth):
[-0.07796,   inf] (119), [-0.07776,   inf] (117), [-0.07768,   inf] (81), [-0.07768,   inf] (71), [-0.07768,   inf] (67), [-0.07768,   inf] (63), [-0.07768,   inf] (61), [-0.07768,   inf] (47), [-0.07768,   inf] (69), [-0.07768,   inf] (67), [-0.07768,   inf] (85), [-0.07768,   inf] (69), [-0.07768,   inf] (67), [-0.07767,   inf] (53), [-0.07767,   inf] (107), [-0.07767,   inf] (103), [-0.07767,   inf] (95), [-0.07767,   inf] (41), [-0.07767,   inf] (117), [-0.07767,   inf] (67), 
length of domains: 32416
Total time: 2.9621	 pickout: 0.2478	 decision: 0.2712	 get_bound: 2.2058	 add_domain: 0.2373
Current lb:-0.07796072959899902
110144 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 113.77291297912598

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 180] [3, 168] [2, 67] [0, 47] [2, 75] [0, 45] [1, 73] [0, 146] [3, 158] [3, 150] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 72.6533203125 with beta sum per layer: [277.25848388671875, 874.4491577148438, 627.881591796875, 2388.721435546875, 2015.920166015625]
alpha/beta optimization time: 0.41348862648010254
This batch time : update_bounds func: 1.0043	 prepare: 0.3336	 bound: 0.4140	 transfer: 0.0222	 finalize: 0.2271
Accumulated time: update_bounds func: 67.2141	 prepare: 17.9636	 bound: 26.2409	 transfer: 0.0222	 finalize: 19.9354
batch bounding time:  1.0066816806793213
Current worst splitting domains [lb, ub] (depth):
[-0.07699,   inf] (45), [-0.07699,   inf] (101), [-0.07699,   inf] (75), [-0.07699,   inf] (85), [-0.07699,   inf] (43), [-0.07699,   inf] (61), [-0.07699,   inf] (99), [-0.07699,   inf] (117), [-0.07699,   inf] (87), [-0.07699,   inf] (85), [-0.07699,   inf] (103), [-0.07699,   inf] (93), [-0.07699,   inf] (61), [-0.07699,   inf] (63), [-0.07698,   inf] (53), [-0.07698,   inf] (47), [-0.07698,   inf] (53), [-0.07698,   inf] (79), [-0.07698,   inf] (83), [-0.07698,   inf] (109), 
length of domains: 32943
Total time: 1.7656	 pickout: 0.2499	 decision: 0.2618	 get_bound: 1.0106	 add_domain: 0.2432
Current lb:-0.07699329406023026
112192 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 115.58718633651733

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 76] [3, 19] [3, 16] [2, 197] [2, 165] [1, 73] [3, 19] [2, 52] [4, 57] [4, 35] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 70.8884048461914 with beta sum per layer: [346.41497802734375, 880.2648315429688, 653.4627685546875, 2450.7548828125, 1926.633544921875]
alpha/beta optimization time: 0.4155881404876709
This batch time : update_bounds func: 1.0051	 prepare: 0.3390	 bound: 0.4161	 transfer: 0.0214	 finalize: 0.2210
Accumulated time: update_bounds func: 68.2193	 prepare: 18.3027	 bound: 26.6570	 transfer: 0.0214	 finalize: 20.1564
batch bounding time:  1.0078580379486084
Current worst splitting domains [lb, ub] (depth):
[-0.07629,   inf] (65), [-0.07629,   inf] (81), [-0.07629,   inf] (43), [-0.07629,   inf] (63), [-0.07629,   inf] (45), [-0.07629,   inf] (45), [-0.07629,   inf] (81), [-0.07629,   inf] (123), [-0.07629,   inf] (59), [-0.07628,   inf] (75), [-0.07628,   inf] (59), [-0.07628,   inf] (55), [-0.07628,   inf] (59), [-0.07628,   inf] (97), [-0.07628,   inf] (71), [-0.07628,   inf] (45), [-0.07628,   inf] (103), [-0.07628,   inf] (65), [-0.07628,   inf] (43), [-0.07628,   inf] (121), 
length of domains: 33469
Total time: 1.7686	 pickout: 0.2499	 decision: 0.2627	 get_bound: 1.0120	 add_domain: 0.2440
Current lb:-0.07629115879535675
114240 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 117.40525650978088

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 47] [2, 67] [4, 91] [2, 160] [4, 92] [2, 197] [4, 49] [2, 72] [1, 120] [1, 99] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 71.63241577148438 with beta sum per layer: [290.20416259765625, 890.540283203125, 625.798095703125, 2483.5146484375, 1990.2335205078125]
alpha/beta optimization time: 0.41430068016052246
This batch time : update_bounds func: 2.2073	 prepare: 0.3479	 bound: 0.4148	 transfer: 0.0221	 finalize: 1.4151
Accumulated time: update_bounds func: 70.4266	 prepare: 18.6506	 bound: 27.0717	 transfer: 0.0221	 finalize: 21.5715
batch bounding time:  2.209667444229126
Current worst splitting domains [lb, ub] (depth):
[-0.07581,   inf] (125), [-0.07563,   inf] (93), [-0.07563,   inf] (107), [-0.07563,   inf] (111), [-0.07563,   inf] (63), [-0.07563,   inf] (91), [-0.07563,   inf] (51), [-0.07563,   inf] (37), [-0.07563,   inf] (53), [-0.07563,   inf] (53), [-0.07563,   inf] (73), [-0.07563,   inf] (107), [-0.07563,   inf] (61), [-0.07562,   inf] (57), [-0.07562,   inf] (61), [-0.07562,   inf] (59), [-0.07562,   inf] (75), [-0.07562,   inf] (65), [-0.07562,   inf] (59), [-0.07562,   inf] (63), 
length of domains: 33991
Total time: 2.9900	 pickout: 0.2637	 decision: 0.2635	 get_bound: 2.2135	 add_domain: 0.2493
Current lb:-0.07580924034118652
116288 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 120.45485019683838

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 142] [4, 22] [2, 175] [4, 142] [2, 39] [2, 71] [2, 99] [1, 73] [0, 173] [4, 132] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 69.81526184082031 with beta sum per layer: [316.35595703125, 855.7953491210938, 605.4964599609375, 2339.33056640625, 2059.3720703125]
alpha/beta optimization time: 0.4155423641204834
This batch time : update_bounds func: 1.0134	 prepare: 0.3466	 bound: 0.4160	 transfer: 0.0215	 finalize: 0.2223
Accumulated time: update_bounds func: 71.4400	 prepare: 18.9972	 bound: 27.4878	 transfer: 0.0215	 finalize: 21.7938
batch bounding time:  1.0161657333374023
Current worst splitting domains [lb, ub] (depth):
[-0.07505,   inf] (125), [-0.07502,   inf] (67), [-0.07502,   inf] (81), [-0.07502,   inf] (47), [-0.07502,   inf] (115), [-0.07502,   inf] (65), [-0.07502,   inf] (53), [-0.07502,   inf] (103), [-0.07502,   inf] (87), [-0.07502,   inf] (79), [-0.07502,   inf] (75), [-0.07502,   inf] (45), [-0.07501,   inf] (35), [-0.07501,   inf] (69), [-0.07501,   inf] (95), [-0.07501,   inf] (75), [-0.07501,   inf] (89), [-0.07501,   inf] (87), [-0.07501,   inf] (109), [-0.07501,   inf] (65), 
length of domains: 34504
Total time: 1.7916	 pickout: 0.2644	 decision: 0.2589	 get_bound: 1.0203	 add_domain: 0.2479
Current lb:-0.07505238056182861
118336 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 122.30063986778259

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 171] [3, 19] [3, 192] [4, 193] [4, 179] [2, 70] [3, 150] [2, 67] [4, 57] [4, 49] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 69.03030395507812 with beta sum per layer: [307.24835205078125, 866.55126953125, 619.0554809570312, 2364.126953125, 2002.816162109375]
alpha/beta optimization time: 0.4021303653717041
This batch time : update_bounds func: 1.0054	 prepare: 0.3473	 bound: 0.4026	 transfer: 0.0222	 finalize: 0.2255
Accumulated time: update_bounds func: 72.4455	 prepare: 19.3444	 bound: 27.8904	 transfer: 0.0222	 finalize: 22.0193
batch bounding time:  1.007887363433838
Current worst splitting domains [lb, ub] (depth):
[-0.07477,   inf] (127), [-0.07463,   inf] (117), [-0.07439,   inf] (65), [-0.07439,   inf] (75), [-0.07439,   inf] (91), [-0.07439,   inf] (49), [-0.07439,   inf] (41), [-0.07439,   inf] (83), [-0.07439,   inf] (47), [-0.07439,   inf] (97), [-0.07439,   inf] (73), [-0.07439,   inf] (75), [-0.07439,   inf] (105), [-0.07439,   inf] (47), [-0.07439,   inf] (63), [-0.07439,   inf] (53), [-0.07439,   inf] (79), [-0.07439,   inf] (87), [-0.07439,   inf] (95), [-0.07439,   inf] (65), 
length of domains: 35032
Total time: 1.7735	 pickout: 0.2514	 decision: 0.2601	 get_bound: 1.0124	 add_domain: 0.2496
Current lb:-0.07476794719696045
120384 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 124.12336802482605

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 80] [3, 168] [3, 19] [4, 35] [4, 86] [0, 47] [4, 19] [4, 86] [4, 132] [3, 168] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 68.12716674804688 with beta sum per layer: [292.49749755859375, 832.1175537109375, 646.9871215820312, 2465.665771484375, 1967.392822265625]
alpha/beta optimization time: 0.40175914764404297
This batch time : update_bounds func: 1.0118	 prepare: 0.3576	 bound: 0.4022	 transfer: 0.0222	 finalize: 0.2217
Accumulated time: update_bounds func: 73.4573	 prepare: 19.7020	 bound: 28.2926	 transfer: 0.0222	 finalize: 22.2409
batch bounding time:  1.0139851570129395
Current worst splitting domains [lb, ub] (depth):
[-0.07375,   inf] (119), [-0.07374,   inf] (73), [-0.07374,   inf] (69), [-0.07374,   inf] (69), [-0.07374,   inf] (71), [-0.07374,   inf] (43), [-0.07374,   inf] (93), [-0.07374,   inf] (107), [-0.07374,   inf] (57), [-0.07374,   inf] (31), [-0.07374,   inf] (91), [-0.07374,   inf] (73), [-0.07374,   inf] (103), [-0.07374,   inf] (87), [-0.07374,   inf] (47), [-0.07374,   inf] (83), [-0.07374,   inf] (75), [-0.07374,   inf] (111), [-0.07374,   inf] (75), [-0.07374,   inf] (57), 
length of domains: 35539
Total time: 3.0781	 pickout: 0.2894	 decision: 1.5253	 get_bound: 1.0178	 add_domain: 0.2456
Current lb:-0.0737454891204834
122432 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 127.2494490146637

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 52] [4, 35] [3, 19] [2, 39] [0, 47] [2, 75] [4, 57] [3, 19] [4, 92] [4, 19] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 67.52764129638672 with beta sum per layer: [296.41204833984375, 875.78466796875, 535.8343505859375, 2478.42578125, 1967.8671875]
alpha/beta optimization time: 0.4075198173522949
This batch time : update_bounds func: 1.0176	 prepare: 0.3570	 bound: 0.4081	 transfer: 0.0223	 finalize: 0.2231
Accumulated time: update_bounds func: 74.4749	 prepare: 20.0590	 bound: 28.7007	 transfer: 0.0223	 finalize: 22.4640
batch bounding time:  1.0199549198150635
Current worst splitting domains [lb, ub] (depth):
[-0.07335,   inf] (113), [-0.07331,   inf] (117), [-0.07323,   inf] (129), [-0.07314,   inf] (53), [-0.07314,   inf] (93), [-0.07314,   inf] (79), [-0.07314,   inf] (61), [-0.07314,   inf] (35), [-0.07314,   inf] (59), [-0.07314,   inf] (65), [-0.07314,   inf] (57), [-0.07314,   inf] (99), [-0.07314,   inf] (51), [-0.07314,   inf] (91), [-0.07313,   inf] (71), [-0.07313,   inf] (55), [-0.07313,   inf] (61), [-0.07313,   inf] (81), [-0.07313,   inf] (49), [-0.07313,   inf] (93), 
length of domains: 36039
Total time: 1.7789	 pickout: 0.2480	 decision: 0.2584	 get_bound: 1.0238	 add_domain: 0.2487
Current lb:-0.07335293292999268
124480 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 129.07819175720215

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 176] [2, 52] [4, 80] [4, 193] [4, 31] [3, 158] [2, 39] [2, 45] [0, 173] [0, 173] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 67.44160461425781 with beta sum per layer: [260.4940185546875, 886.2015991210938, 630.0888671875, 2406.117431640625, 2006.0819091796875]
alpha/beta optimization time: 0.40154457092285156
This batch time : update_bounds func: 0.9931	 prepare: 0.3430	 bound: 0.4020	 transfer: 0.0222	 finalize: 0.2185
Accumulated time: update_bounds func: 75.4679	 prepare: 20.4020	 bound: 29.1027	 transfer: 0.0222	 finalize: 22.6825
batch bounding time:  0.9953060150146484
Current worst splitting domains [lb, ub] (depth):
[-0.07281,   inf] (115), [-0.07281,   inf] (127), [-0.07258,   inf] (123), [-0.07258,   inf] (77), [-0.07258,   inf] (81), [-0.07258,   inf] (85), [-0.07257,   inf] (53), [-0.07257,   inf] (103), [-0.07257,   inf] (65), [-0.07257,   inf] (47), [-0.07257,   inf] (37), [-0.07257,   inf] (83), [-0.07257,   inf] (47), [-0.07257,   inf] (75), [-0.07257,   inf] (87), [-0.07257,   inf] (103), [-0.07257,   inf] (75), [-0.07257,   inf] (93), [-0.07257,   inf] (97), [-0.07256,   inf] (31), 
length of domains: 36547
Total time: 1.7783	 pickout: 0.2476	 decision: 0.2583	 get_bound: 0.9991	 add_domain: 0.2733
Current lb:-0.07281150668859482
126528 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 130.9074215888977

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 168] [1, 180] [2, 39] [1, 120] [0, 45] [3, 93] [4, 92] [2, 71] [3, 93] [1, 120] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 64.758056640625 with beta sum per layer: [310.1689453125, 847.21875, 630.0459594726562, 2322.12841796875, 1991.876953125]
alpha/beta optimization time: 0.3997793197631836
This batch time : update_bounds func: 1.0066	 prepare: 0.3534	 bound: 0.4003	 transfer: 0.0216	 finalize: 0.2241
Accumulated time: update_bounds func: 76.4746	 prepare: 20.7554	 bound: 29.5030	 transfer: 0.0216	 finalize: 22.9066
batch bounding time:  1.008850336074829
Current worst splitting domains [lb, ub] (depth):
[-0.07224,   inf] (129), [-0.07222,   inf] (131), [-0.07202,   inf] (41), [-0.07202,   inf] (43), [-0.07202,   inf] (107), [-0.07202,   inf] (97), [-0.07202,   inf] (63), [-0.07202,   inf] (65), [-0.07202,   inf] (71), [-0.07202,   inf] (77), [-0.07202,   inf] (57), [-0.07202,   inf] (55), [-0.07202,   inf] (73), [-0.07202,   inf] (115), [-0.07202,   inf] (61), [-0.07202,   inf] (103), [-0.07202,   inf] (57), [-0.07202,   inf] (47), [-0.07201,   inf] (73), [-0.07201,   inf] (109), 
length of domains: 37055
Total time: 3.0426	 pickout: 0.2492	 decision: 1.5335	 get_bound: 1.0126	 add_domain: 0.2473
Current lb:-0.0722353458404541
128576 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 133.99865412712097

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 171] [4, 122] [4, 91] [3, 50] [3, 158] [3, 158] [0, 113] [4, 35] [1, 73] [2, 39] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 63.53094482421875 with beta sum per layer: [270.0472412109375, 874.0134887695312, 629.9821166992188, 2312.794921875, 1993.8702392578125]
alpha/beta optimization time: 0.41751980781555176
This batch time : update_bounds func: 1.0142	 prepare: 0.3444	 bound: 0.4180	 transfer: 0.0222	 finalize: 0.2217
Accumulated time: update_bounds func: 77.4888	 prepare: 21.0998	 bound: 29.9210	 transfer: 0.0222	 finalize: 23.1283
batch bounding time:  1.0165085792541504
Current worst splitting domains [lb, ub] (depth):
[-0.07214,   inf] (133), [-0.07200,   inf] (131), [-0.07158,   inf] (111), [-0.07153,   inf] (111), [-0.07149,   inf] (69), [-0.07149,   inf] (57), [-0.07149,   inf] (83), [-0.07148,   inf] (43), [-0.07148,   inf] (73), [-0.07148,   inf] (87), [-0.07148,   inf] (107), [-0.07148,   inf] (85), [-0.07148,   inf] (81), [-0.07148,   inf] (37), [-0.07148,   inf] (111), [-0.07148,   inf] (59), [-0.07148,   inf] (65), [-0.07148,   inf] (103), [-0.07148,   inf] (55), [-0.07148,   inf] (91), 
length of domains: 37544
Total time: 1.7769	 pickout: 0.2444	 decision: 0.2629	 get_bound: 1.0203	 add_domain: 0.2493
Current lb:-0.07214069366455078
130624 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 135.8247561454773

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 178] [1, 117] [2, 71] [2, 52] [1, 99] [4, 92] [4, 57] [4, 91] [2, 39] [4, 31] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 63.36817932128906 with beta sum per layer: [279.7576599121094, 856.2171630859375, 555.423583984375, 2441.05224609375, 2075.86328125]
alpha/beta optimization time: 0.40024375915527344
This batch time : update_bounds func: 0.9985	 prepare: 0.3454	 bound: 0.4007	 transfer: 0.0216	 finalize: 0.2231
Accumulated time: update_bounds func: 78.4873	 prepare: 21.4452	 bound: 30.3218	 transfer: 0.0216	 finalize: 23.3514
batch bounding time:  1.0016121864318848
Current worst splitting domains [lb, ub] (depth):
[-0.07184,   inf] (135), [-0.07173,   inf] (133), [-0.07102,   inf] (115), [-0.07097,   inf] (63), [-0.07096,   inf] (97), [-0.07096,   inf] (85), [-0.07096,   inf] (91), [-0.07096,   inf] (65), [-0.07096,   inf] (55), [-0.07096,   inf] (101), [-0.07096,   inf] (49), [-0.07096,   inf] (73), [-0.07096,   inf] (73), [-0.07096,   inf] (87), [-0.07096,   inf] (75), [-0.07096,   inf] (69), [-0.07096,   inf] (79), [-0.07096,   inf] (57), [-0.07096,   inf] (49), [-0.07096,   inf] (79), 
length of domains: 38004
Total time: 1.7625	 pickout: 0.2404	 decision: 0.2679	 get_bound: 1.0061	 add_domain: 0.2481
Current lb:-0.071844682097435
132672 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 137.63753008842468

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 142] [4, 80] [2, 52] [0, 146] [4, 57] [1, 177] [3, 168] [0, 173] [2, 71] [2, 123] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 62.10289764404297 with beta sum per layer: [275.38433837890625, 820.73486328125, 633.9593505859375, 2343.4990234375, 2063.4697265625]
alpha/beta optimization time: 0.40366578102111816
This batch time : update_bounds func: 1.0116	 prepare: 0.3575	 bound: 0.4042	 transfer: 0.0221	 finalize: 0.2200
Accumulated time: update_bounds func: 79.4989	 prepare: 21.8027	 bound: 30.7260	 transfer: 0.0221	 finalize: 23.5713
batch bounding time:  1.0140016078948975
Current worst splitting domains [lb, ub] (depth):
[-0.07056,   inf] (133), [-0.07049,   inf] (119), [-0.07046,   inf] (117), [-0.07044,   inf] (35), [-0.07044,   inf] (75), [-0.07044,   inf] (43), [-0.07044,   inf] (89), [-0.07044,   inf] (51), [-0.07043,   inf] (51), [-0.07043,   inf] (61), [-0.07043,   inf] (47), [-0.07043,   inf] (131), [-0.07043,   inf] (97), [-0.07043,   inf] (99), [-0.07043,   inf] (81), [-0.07043,   inf] (97), [-0.07043,   inf] (59), [-0.07043,   inf] (91), [-0.07043,   inf] (65), [-0.07043,   inf] (89), 
length of domains: 38480
Total time: 3.1267	 pickout: 0.2417	 decision: 1.6177	 get_bound: 1.0180	 add_domain: 0.2493
Current lb:-0.0705556869506836
134720 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 140.81380009651184

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 15] [4, 142] [1, 180] [3, 92] [0, 113] [0, 45] [4, 31] [3, 115] [0, 113] [1, 76] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 58.65679168701172 with beta sum per layer: [287.6612243652344, 882.5892333984375, 623.6136474609375, 2391.187744140625, 2168.039306640625]
alpha/beta optimization time: 0.3996868133544922
This batch time : update_bounds func: 1.0079	 prepare: 0.3567	 bound: 0.4002	 transfer: 0.0221	 finalize: 0.2213
Accumulated time: update_bounds func: 80.5068	 prepare: 22.1594	 bound: 31.1261	 transfer: 0.0221	 finalize: 23.7926
batch bounding time:  1.0102195739746094
Current worst splitting domains [lb, ub] (depth):
[-0.07024,   inf] (135), [-0.07012,   inf] (125), [-0.07006,   inf] (131), [-0.06994,   inf] (83), [-0.06994,   inf] (85), [-0.06994,   inf] (83), [-0.06994,   inf] (85), [-0.06994,   inf] (79), [-0.06994,   inf] (81), [-0.06994,   inf] (83), [-0.06994,   inf] (111), [-0.06994,   inf] (103), [-0.06994,   inf] (71), [-0.06994,   inf] (67), [-0.06994,   inf] (113), [-0.06994,   inf] (79), [-0.06994,   inf] (41), [-0.06994,   inf] (45), [-0.06994,   inf] (71), [-0.06994,   inf] (127), 
length of domains: 38949
Total time: 1.7665	 pickout: 0.2453	 decision: 0.2612	 get_bound: 1.0141	 add_domain: 0.2459
Current lb:-0.07023501396179199
136768 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 142.63505339622498

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 142] [4, 80] [4, 80] [3, 158] [4, 57] [2, 67] [4, 22] [3, 28] [1, 120] [3, 28] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 59.980384826660156 with beta sum per layer: [295.18450927734375, 807.759521484375, 596.868408203125, 2483.18603515625, 2090.4169921875]
alpha/beta optimization time: 0.4140617847442627
This batch time : update_bounds func: 1.0234	 prepare: 0.3540	 bound: 0.4146	 transfer: 0.0221	 finalize: 0.2252
Accumulated time: update_bounds func: 81.5302	 prepare: 22.5134	 bound: 31.5407	 transfer: 0.0221	 finalize: 24.0178
batch bounding time:  1.0264203548431396
Current worst splitting domains [lb, ub] (depth):
[-0.06964,   inf] (125), [-0.06948,   inf] (135), [-0.06946,   inf] (57), [-0.06946,   inf] (47), [-0.06946,   inf] (91), [-0.06946,   inf] (59), [-0.06945,   inf] (81), [-0.06945,   inf] (79), [-0.06945,   inf] (95), [-0.06945,   inf] (117), [-0.06945,   inf] (107), [-0.06945,   inf] (117), [-0.06945,   inf] (97), [-0.06945,   inf] (107), [-0.06945,   inf] (85), [-0.06945,   inf] (77), [-0.06945,   inf] (59), [-0.06945,   inf] (85), [-0.06945,   inf] (105), [-0.06945,   inf] (65), 
length of domains: 39421
Total time: 1.7816	 pickout: 0.2379	 decision: 0.2648	 get_bound: 1.0309	 add_domain: 0.2480
Current lb:-0.06964325904846191
138816 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 144.4662618637085

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 142] [2, 85] [4, 193] [4, 91] [2, 75] [0, 146] [2, 39] [0, 173] [4, 38] [1, 180] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 58.718910217285156 with beta sum per layer: [283.4220886230469, 830.5006103515625, 617.3294677734375, 2246.253662109375, 2095.54736328125]
alpha/beta optimization time: 0.39841604232788086
This batch time : update_bounds func: 0.9996	 prepare: 0.3489	 bound: 0.3989	 transfer: 0.0223	 finalize: 0.2219
Accumulated time: update_bounds func: 82.5298	 prepare: 22.8623	 bound: 31.9396	 transfer: 0.0223	 finalize: 24.2397
batch bounding time:  1.0022664070129395
Current worst splitting domains [lb, ub] (depth):
[-0.06907,   inf] (133), [-0.06906,   inf] (137), [-0.06905,   inf] (115), [-0.06900,   inf] (79), [-0.06900,   inf] (65), [-0.06900,   inf] (83), [-0.06900,   inf] (77), [-0.06899,   inf] (103), [-0.06899,   inf] (87), [-0.06899,   inf] (89), [-0.06899,   inf] (73), [-0.06899,   inf] (71), [-0.06899,   inf] (83), [-0.06899,   inf] (79), [-0.06899,   inf] (79), [-0.06899,   inf] (35), [-0.06899,   inf] (105), [-0.06899,   inf] (101), [-0.06899,   inf] (55), [-0.06899,   inf] (85), 
length of domains: 39882
Total time: 3.1524	 pickout: 0.2373	 decision: 1.6599	 get_bound: 1.0064	 add_domain: 0.2488
Current lb:-0.06906509399414062
140864 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 147.66871285438538

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 142] [4, 122] [2, 52] [3, 16] [0, 173] [2, 39] [4, 35] [3, 19] [0, 47] [4, 31] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 58.816505432128906 with beta sum per layer: [273.0212707519531, 835.9273681640625, 639.2623291015625, 2384.4541015625, 2068.677490234375]
alpha/beta optimization time: 0.3993234634399414
This batch time : update_bounds func: 1.0043	 prepare: 0.3517	 bound: 0.3998	 transfer: 0.0222	 finalize: 0.2229
Accumulated time: update_bounds func: 83.5341	 prepare: 23.2140	 bound: 32.3394	 transfer: 0.0222	 finalize: 24.4627
batch bounding time:  1.0068955421447754
Current worst splitting domains [lb, ub] (depth):
[-0.06899,   inf] (139), [-0.06854,   inf] (83), [-0.06854,   inf] (87), [-0.06854,   inf] (39), [-0.06854,   inf] (109), [-0.06854,   inf] (47), [-0.06854,   inf] (73), [-0.06854,   inf] (91), [-0.06854,   inf] (97), [-0.06854,   inf] (57), [-0.06854,   inf] (75), [-0.06854,   inf] (103), [-0.06854,   inf] (55), [-0.06854,   inf] (113), [-0.06854,   inf] (59), [-0.06854,   inf] (87), [-0.06854,   inf] (81), [-0.06854,   inf] (63), [-0.06854,   inf] (113), [-0.06854,   inf] (77), 
length of domains: 40331
Total time: 1.7630	 pickout: 0.2412	 decision: 0.2647	 get_bound: 1.0110	 add_domain: 0.2461
Current lb:-0.0689852237701416
142912 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 149.48233580589294

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 178] [4, 35] [2, 122] [1, 120] [3, 168] [0, 113] [4, 49] [1, 56] [2, 13] [2, 165] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 60.203495025634766 with beta sum per layer: [307.4278564453125, 826.0977783203125, 602.23486328125, 2197.814453125, 1995.4676513671875]
alpha/beta optimization time: 0.39884066581726074
This batch time : update_bounds func: 1.0121	 prepare: 0.3576	 bound: 0.3993	 transfer: 0.0222	 finalize: 0.2259
Accumulated time: update_bounds func: 84.5462	 prepare: 23.5716	 bound: 32.7387	 transfer: 0.0222	 finalize: 24.6886
batch bounding time:  1.0143938064575195
Current worst splitting domains [lb, ub] (depth):
[-0.06872,   inf] (141), [-0.06812,   inf] (91), [-0.06812,   inf] (35), [-0.06811,   inf] (89), [-0.06811,   inf] (79), [-0.06811,   inf] (31), [-0.06811,   inf] (57), [-0.06811,   inf] (85), [-0.06811,   inf] (89), [-0.06811,   inf] (109), [-0.06811,   inf] (91), [-0.06811,   inf] (51), [-0.06811,   inf] (37), [-0.06811,   inf] (33), [-0.06811,   inf] (47), [-0.06811,   inf] (89), [-0.06811,   inf] (37), [-0.06811,   inf] (51), [-0.06811,   inf] (81), [-0.06811,   inf] (39), 
length of domains: 40816
Total time: 1.7749	 pickout: 0.2378	 decision: 0.2601	 get_bound: 1.0183	 add_domain: 0.2586
Current lb:-0.06872451305389404
144960 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 151.3126118183136

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 142] [4, 38] [0, 10] [4, 57] [0, 45] [0, 173] [2, 99] [1, 120] [3, 158] [1, 180] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 59.5063362121582 with beta sum per layer: [285.93072509765625, 778.9571533203125, 612.0233764648438, 2134.95849609375, 2178.48046875]
alpha/beta optimization time: 0.41178345680236816
This batch time : update_bounds func: 1.0305	 prepare: 0.3610	 bound: 0.4123	 transfer: 0.0232	 finalize: 0.2262
Accumulated time: update_bounds func: 85.5767	 prepare: 23.9325	 bound: 33.1511	 transfer: 0.0232	 finalize: 24.9148
batch bounding time:  1.032942771911621
Current worst splitting domains [lb, ub] (depth):
[-0.06775,   inf] (127), [-0.06773,   inf] (117), [-0.06772,   inf] (135), [-0.06772,   inf] (135), [-0.06770,   inf] (139), [-0.06765,   inf] (47), [-0.06765,   inf] (31), [-0.06765,   inf] (55), [-0.06765,   inf] (121), [-0.06765,   inf] (71), [-0.06765,   inf] (113), [-0.06765,   inf] (51), [-0.06765,   inf] (47), [-0.06765,   inf] (81), [-0.06765,   inf] (49), [-0.06765,   inf] (73), [-0.06765,   inf] (109), [-0.06764,   inf] (53), [-0.06764,   inf] (63), [-0.06764,   inf] (99), 
length of domains: 41289
Total time: 3.2511	 pickout: 0.2373	 decision: 1.7214	 get_bound: 1.0368	 add_domain: 0.2556
Current lb:-0.06775486469268799
147008 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 154.6215696334839

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 80] [2, 176] [4, 178] [3, 109] [4, 178] [3, 32] [3, 114] [4, 95] [1, 180] [0, 45] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 58.03609848022461 with beta sum per layer: [275.68341064453125, 826.3675537109375, 540.380859375, 2275.78857421875, 2176.2568359375]
alpha/beta optimization time: 0.3963756561279297
This batch time : update_bounds func: 1.0053	 prepare: 0.3522	 bound: 0.3969	 transfer: 0.0221	 finalize: 0.2263
Accumulated time: update_bounds func: 86.5821	 prepare: 24.2848	 bound: 33.5479	 transfer: 0.0221	 finalize: 25.1411
batch bounding time:  1.0075674057006836
Current worst splitting domains [lb, ub] (depth):
[-0.06751,   inf] (139), [-0.06744,   inf] (141), [-0.06744,   inf] (137), [-0.06741,   inf] (137), [-0.06736,   inf] (139), [-0.06734,   inf] (125), [-0.06732,   inf] (141), [-0.06731,   inf] (125), [-0.06730,   inf] (129), [-0.06730,   inf] (135), [-0.06724,   inf] (141), [-0.06722,   inf] (133), [-0.06722,   inf] (123), [-0.06722,   inf] (55), [-0.06722,   inf] (51), [-0.06722,   inf] (71), [-0.06721,   inf] (95), [-0.06721,   inf] (45), [-0.06721,   inf] (81), [-0.06721,   inf] (111), 
length of domains: 41753
Total time: 1.7792	 pickout: 0.2449	 decision: 0.2692	 get_bound: 1.0114	 add_domain: 0.2537
Current lb:-0.06751084327697754
149056 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 156.4521186351776

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 178] [4, 79] [4, 122] [1, 117] [4, 178] [2, 52] [4, 178] [4, 80] [1, 120] [2, 176] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 56.808326721191406 with beta sum per layer: [249.77764892578125, 822.7177734375, 609.77099609375, 2215.2353515625, 2076.162109375]
alpha/beta optimization time: 0.413128137588501
This batch time : update_bounds func: 1.0222	 prepare: 0.3568	 bound: 0.4136	 transfer: 0.0221	 finalize: 0.2223
Accumulated time: update_bounds func: 87.6043	 prepare: 24.6415	 bound: 33.9616	 transfer: 0.0221	 finalize: 25.3634
batch bounding time:  1.024503231048584
Current worst splitting domains [lb, ub] (depth):
[-0.06734,   inf] (139), [-0.06725,   inf] (141), [-0.06719,   inf] (137), [-0.06715,   inf] (139), [-0.06714,   inf] (143), [-0.06708,   inf] (141), [-0.06703,   inf] (135), [-0.06699,   inf] (131), [-0.06698,   inf] (143), [-0.06693,   inf] (143), [-0.06691,   inf] (127), [-0.06691,   inf] (139), [-0.06690,   inf] (147), [-0.06685,   inf] (131), [-0.06684,   inf] (127), [-0.06680,   inf] (121), [-0.06680,   inf] (41), [-0.06680,   inf] (67), [-0.06679,   inf] (99), [-0.06679,   inf] (61), 
length of domains: 42210
Total time: 1.7874	 pickout: 0.2425	 decision: 0.2597	 get_bound: 1.0283	 add_domain: 0.2568
Current lb:-0.0673445463180542
151104 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 158.29621505737305

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 178] [2, 176] [2, 85] [4, 80] [4, 28] [2, 176] [4, 80] [4, 122] [4, 79] [3, 63] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 54.754432678222656 with beta sum per layer: [306.10052490234375, 810.4664306640625, 581.6341552734375, 2105.462890625, 2056.133544921875]
alpha/beta optimization time: 0.3979990482330322
This batch time : update_bounds func: 2.5437	 prepare: 0.3584	 bound: 0.3985	 transfer: 0.0221	 finalize: 1.7568
Accumulated time: update_bounds func: 90.1480	 prepare: 25.0000	 bound: 34.3601	 transfer: 0.0221	 finalize: 27.1202
batch bounding time:  2.5460128784179688
Current worst splitting domains [lb, ub] (depth):
[-0.06710,   inf] (143), [-0.06707,   inf] (141), [-0.06692,   inf] (133), [-0.06691,   inf] (143), [-0.06677,   inf] (145), [-0.06666,   inf] (145), [-0.06666,   inf] (145), [-0.06659,   inf] (147), [-0.06658,   inf] (133), [-0.06655,   inf] (149), [-0.06651,   inf] (137), [-0.06651,   inf] (129), [-0.06646,   inf] (127), [-0.06639,   inf] (113), [-0.06639,   inf] (89), [-0.06639,   inf] (63), [-0.06639,   inf] (127), [-0.06639,   inf] (73), [-0.06639,   inf] (109), [-0.06639,   inf] (93), 
length of domains: 42639
Total time: 3.3100	 pickout: 0.2420	 decision: 0.2659	 get_bound: 2.5498	 add_domain: 0.2523
Current lb:-0.06709563732147217
153152 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 161.65778970718384

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 18] [4, 79] [4, 178] [3, 63] [4, 28] [2, 18] [3, 63] [2, 72] [2, 176] [3, 63] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 56.85224914550781 with beta sum per layer: [272.77459716796875, 785.3062744140625, 618.59130859375, 2233.409912109375, 2155.81298828125]
alpha/beta optimization time: 0.41744136810302734
This batch time : update_bounds func: 1.0242	 prepare: 0.3529	 bound: 0.4180	 transfer: 0.0221	 finalize: 0.2235
Accumulated time: update_bounds func: 91.1722	 prepare: 25.3528	 bound: 34.7780	 transfer: 0.0221	 finalize: 27.3437
batch bounding time:  1.026519536972046
Current worst splitting domains [lb, ub] (depth):
[-0.06695,   inf] (145), [-0.06676,   inf] (143), [-0.06674,   inf] (145), [-0.06666,   inf] (135), [-0.06653,   inf] (147), [-0.06650,   inf] (147), [-0.06641,   inf] (149), [-0.06641,   inf] (151), [-0.06627,   inf] (135), [-0.06627,   inf] (147), [-0.06626,   inf] (131), [-0.06612,   inf] (129), [-0.06610,   inf] (127), [-0.06603,   inf] (145), [-0.06599,   inf] (77), [-0.06599,   inf] (75), [-0.06599,   inf] (109), [-0.06599,   inf] (103), [-0.06599,   inf] (47), [-0.06599,   inf] (113), 
length of domains: 43077
Total time: 1.7925	 pickout: 0.2428	 decision: 0.2609	 get_bound: 1.0304	 add_domain: 0.2585
Current lb:-0.06695306301116943
155200 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 163.5093834400177

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 79] [4, 28] [3, 109] [4, 79] [3, 63] [4, 28] [2, 18] [2, 18] [4, 122] [1, 56] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 57.82183837890625 with beta sum per layer: [242.1349639892578, 785.748291015625, 542.2066650390625, 2235.049560546875, 2150.21484375]
alpha/beta optimization time: 0.4108145236968994
This batch time : update_bounds func: 1.0291	 prepare: 0.3585	 bound: 0.4113	 transfer: 0.0220	 finalize: 0.2300
Accumulated time: update_bounds func: 92.2013	 prepare: 25.7113	 bound: 35.1894	 transfer: 0.0220	 finalize: 27.5737
batch bounding time:  1.0314571857452393
Current worst splitting domains [lb, ub] (depth):
[-0.06665,   inf] (147), [-0.06659,   inf] (147), [-0.06645,   inf] (149), [-0.06635,   inf] (137), [-0.06626,   inf] (151), [-0.06625,   inf] (145), [-0.06620,   inf] (153), [-0.06616,   inf] (137), [-0.06602,   inf] (149), [-0.06593,   inf] (149), [-0.06588,   inf] (147), [-0.06586,   inf] (141), [-0.06585,   inf] (137), [-0.06583,   inf] (129), [-0.06573,   inf] (125), [-0.06572,   inf] (141), [-0.06563,   inf] (143), [-0.06560,   inf] (103), [-0.06560,   inf] (89), [-0.06560,   inf] (115), 
length of domains: 43549
Total time: 1.8036	 pickout: 0.2396	 decision: 0.2650	 get_bound: 1.0354	 add_domain: 0.2636
Current lb:-0.06665253639221191
157248 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 165.37294483184814

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 63] [4, 79] [3, 109] [2, 18] [4, 28] [2, 160] [4, 28] [4, 178] [2, 18] [2, 18] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 55.815189361572266 with beta sum per layer: [290.313720703125, 810.2525024414062, 582.5675048828125, 2202.15478515625, 2138.375]
alpha/beta optimization time: 0.4044625759124756
This batch time : update_bounds func: 1.0292	 prepare: 0.3683	 bound: 0.4050	 transfer: 0.0215	 finalize: 0.2267
Accumulated time: update_bounds func: 93.2305	 prepare: 26.0796	 bound: 35.5943	 transfer: 0.0215	 finalize: 27.8004
batch bounding time:  1.031508207321167
Current worst splitting domains [lb, ub] (depth):
[-0.06658,   inf] (149), [-0.06641,   inf] (151), [-0.06629,   inf] (149), [-0.06619,   inf] (139), [-0.06609,   inf] (147), [-0.06590,   inf] (139), [-0.06589,   inf] (151), [-0.06579,   inf] (151), [-0.06574,   inf] (153), [-0.06570,   inf] (155), [-0.06559,   inf] (143), [-0.06558,   inf] (149), [-0.06545,   inf] (143), [-0.06539,   inf] (151), [-0.06537,   inf] (145), [-0.06533,   inf] (137), [-0.06532,   inf] (141), [-0.06532,   inf] (155), [-0.06532,   inf] (139), [-0.06532,   inf] (145), 
length of domains: 44004
Total time: 1.7974	 pickout: 0.2344	 decision: 0.2693	 get_bound: 1.0354	 add_domain: 0.2583
Current lb:-0.06657826900482178
159296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 167.2304801940918

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 28] [4, 174] [2, 18] [1, 117] [2, 67] [4, 142] [1, 138] [1, 138] [1, 117] [4, 174] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 57.751731872558594 with beta sum per layer: [251.6780548095703, 740.4843139648438, 592.3197021484375, 2176.1201171875, 2176.156982421875]
alpha/beta optimization time: 0.4024369716644287
This batch time : update_bounds func: 1.0259	 prepare: 0.3604	 bound: 0.4030	 transfer: 0.0221	 finalize: 0.2328
Accumulated time: update_bounds func: 94.2565	 prepare: 26.4401	 bound: 35.9973	 transfer: 0.0221	 finalize: 28.0332
batch bounding time:  1.0282301902770996
Current worst splitting domains [lb, ub] (depth):
[-0.06621,   inf] (153), [-0.06617,   inf] (151), [-0.06610,   inf] (151), [-0.06607,   inf] (141), [-0.06557,   inf] (155), [-0.06549,   inf] (151), [-0.06548,   inf] (157), [-0.06545,   inf] (149), [-0.06518,   inf] (149), [-0.06515,   inf] (145), [-0.06506,   inf] (147), [-0.06506,   inf] (147), [-0.06504,   inf] (143), [-0.06504,   inf] (141), [-0.06502,   inf] (157), [-0.06502,   inf] (139), [-0.06502,   inf] (143), [-0.06497,   inf] (151), [-0.06497,   inf] (125), [-0.06494,   inf] (145), 
length of domains: 44478
Total time: 3.4420	 pickout: 0.2436	 decision: 1.9032	 get_bound: 1.0320	 add_domain: 0.2631
Current lb:-0.06621336936950684
161344 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 170.72540855407715

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 138] [4, 28] [3, 109] [3, 63] [4, 174] [4, 28] [1, 125] [2, 18] [4, 174] [4, 174] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 53.33778381347656 with beta sum per layer: [264.04510498046875, 846.5797119140625, 542.4876098632812, 2209.42236328125, 2140.32763671875]
alpha/beta optimization time: 0.405318021774292
This batch time : update_bounds func: 1.0238	 prepare: 0.3542	 bound: 0.4058	 transfer: 0.0222	 finalize: 0.2341
Accumulated time: update_bounds func: 95.2802	 prepare: 26.7943	 bound: 36.4031	 transfer: 0.0222	 finalize: 28.2673
batch bounding time:  1.0261213779449463
Current worst splitting domains [lb, ub] (depth):
[-0.06605,   inf] (153), [-0.06593,   inf] (143), [-0.06568,   inf] (153), [-0.06553,   inf] (155), [-0.06547,   inf] (159), [-0.06546,   inf] (159), [-0.06537,   inf] (157), [-0.06534,   inf] (151), [-0.06502,   inf] (153), [-0.06496,   inf] (151), [-0.06496,   inf] (147), [-0.06488,   inf] (149), [-0.06478,   inf] (145), [-0.06476,   inf] (157), [-0.06475,   inf] (137), [-0.06474,   inf] (143), [-0.06472,   inf] (149), [-0.06469,   inf] (153), [-0.06467,   inf] (145), [-0.06465,   inf] (147), 
length of domains: 44911
Total time: 1.8012	 pickout: 0.2414	 decision: 0.2699	 get_bound: 1.0300	 add_domain: 0.2599
Current lb:-0.06605255603790283
163392 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 172.5823495388031

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 174] [4, 28] [4, 174] [1, 125] [4, 137] [4, 137] [1, 125] [4, 174] [3, 63] [3, 44] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 52.12725830078125 with beta sum per layer: [275.98046875, 766.9492797851562, 575.0236206054688, 2071.28955078125, 2223.326171875]
alpha/beta optimization time: 0.39909839630126953
This batch time : update_bounds func: 1.0223	 prepare: 0.3606	 bound: 0.3996	 transfer: 0.0222	 finalize: 0.2324
Accumulated time: update_bounds func: 96.3026	 prepare: 27.1548	 bound: 36.8027	 transfer: 0.0222	 finalize: 28.4997
batch bounding time:  1.0247416496276855
Current worst splitting domains [lb, ub] (depth):
[-0.06586,   inf] (155), [-0.06548,   inf] (155), [-0.06546,   inf] (161), [-0.06546,   inf] (145), [-0.06545,   inf] (161), [-0.06541,   inf] (157), [-0.06540,   inf] (157), [-0.06537,   inf] (159), [-0.06536,   inf] (159), [-0.06513,   inf] (153), [-0.06497,   inf] (155), [-0.06486,   inf] (149), [-0.06481,   inf] (145), [-0.06475,   inf] (151), [-0.06461,   inf] (145), [-0.06452,   inf] (157), [-0.06451,   inf] (157), [-0.06449,   inf] (139), [-0.06448,   inf] (147), [-0.06444,   inf] (137), 
length of domains: 45342
Total time: 1.8026	 pickout: 0.2479	 decision: 0.2628	 get_bound: 1.0287	 add_domain: 0.2631
Current lb:-0.06585556268692017
165440 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 174.43776416778564

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 125] [1, 125] [1, 8] [2, 85] [1, 8] [4, 137] [4, 137] [4, 137] [4, 137] [1, 138] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 49.99142074584961 with beta sum per layer: [242.64825439453125, 750.7476806640625, 620.0046997070312, 2064.822265625, 2071.6884765625]
alpha/beta optimization time: 0.40252089500427246
This batch time : update_bounds func: 2.6924	 prepare: 0.3577	 bound: 0.4030	 transfer: 0.0221	 finalize: 1.9016
Accumulated time: update_bounds func: 98.9950	 prepare: 27.5126	 bound: 37.2058	 transfer: 0.0221	 finalize: 30.4012
batch bounding time:  2.6949315071105957
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (157), [-0.06585,   inf] (157), [-0.06548,   inf] (157), [-0.06548,   inf] (157), [-0.06546,   inf] (163), [-0.06544,   inf] (163), [-0.06537,   inf] (161), [-0.06536,   inf] (161), [-0.06531,   inf] (159), [-0.06531,   inf] (159), [-0.06504,   inf] (147), [-0.06503,   inf] (147), [-0.06475,   inf] (157), [-0.06468,   inf] (153), [-0.06446,   inf] (159), [-0.06445,   inf] (155), [-0.06445,   inf] (159), [-0.06440,   inf] (157), [-0.06435,   inf] (149), [-0.06433,   inf] (159), 
length of domains: 45740
Total time: 3.4768	 pickout: 0.2460	 decision: 0.2719	 get_bound: 2.6990	 add_domain: 0.2599
Current lb:-0.06585466861724854
167488 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 177.97348594665527

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 137] [4, 137] [4, 137] [4, 137] [1, 185] [1, 185] [1, 8] [1, 8] [1, 185] [1, 185] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 50.22142028808594 with beta sum per layer: [267.1175231933594, 775.946044921875, 519.2212524414062, 2072.359619140625, 2085.600341796875]
alpha/beta optimization time: 0.4001460075378418
This batch time : update_bounds func: 1.0190	 prepare: 0.3617	 bound: 0.4006	 transfer: 0.0220	 finalize: 0.2270
Accumulated time: update_bounds func: 100.0140	 prepare: 27.8743	 bound: 37.6064	 transfer: 0.0220	 finalize: 30.6283
batch bounding time:  1.021467924118042
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (159), [-0.06585,   inf] (159), [-0.06548,   inf] (159), [-0.06548,   inf] (159), [-0.06546,   inf] (165), [-0.06543,   inf] (165), [-0.06537,   inf] (163), [-0.06536,   inf] (163), [-0.06524,   inf] (161), [-0.06524,   inf] (161), [-0.06475,   inf] (159), [-0.06475,   inf] (159), [-0.06442,   inf] (161), [-0.06442,   inf] (161), [-0.06428,   inf] (161), [-0.06425,   inf] (161), [-0.06415,   inf] (157), [-0.06414,   inf] (143), [-0.06411,   inf] (141), [-0.06405,   inf] (145), 
length of domains: 46136
Total time: 1.8013	 pickout: 0.2502	 decision: 0.2653	 get_bound: 1.0254	 add_domain: 0.2603
Current lb:-0.0658489465713501
169536 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 179.82794213294983

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 185] [1, 185] [1, 185] [1, 185] [3, 195] [3, 195] [1, 185] [1, 185] [1, 8] [1, 8] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 52.87620544433594 with beta sum per layer: [261.1903076171875, 730.71142578125, 604.7230834960938, 1906.940185546875, 2223.20361328125]
alpha/beta optimization time: 0.40262579917907715
This batch time : update_bounds func: 1.0222	 prepare: 0.3602	 bound: 0.4031	 transfer: 0.0222	 finalize: 0.2292
Accumulated time: update_bounds func: 101.0362	 prepare: 28.2344	 bound: 38.0096	 transfer: 0.0222	 finalize: 30.8575
batch bounding time:  1.0243773460388184
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (161), [-0.06585,   inf] (161), [-0.06548,   inf] (161), [-0.06548,   inf] (161), [-0.06546,   inf] (167), [-0.06541,   inf] (167), [-0.06537,   inf] (165), [-0.06536,   inf] (165), [-0.06522,   inf] (163), [-0.06516,   inf] (163), [-0.06436,   inf] (163), [-0.06435,   inf] (163), [-0.06425,   inf] (163), [-0.06420,   inf] (163), [-0.06400,   inf] (145), [-0.06396,   inf] (159), [-0.06393,   inf] (159), [-0.06386,   inf] (143), [-0.06384,   inf] (157), [-0.06375,   inf] (153), 
length of domains: 46564
Total time: 1.8045	 pickout: 0.2438	 decision: 0.2685	 get_bound: 1.0282	 add_domain: 0.2640
Current lb:-0.06584835052490234
171584 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 181.6867380142212

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 8] [1, 8] [1, 8] [1, 8] [2, 141] [2, 141] [3, 195] [3, 195] [3, 195] [3, 195] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 53.01753616333008 with beta sum per layer: [248.35916137695312, 729.1617431640625, 511.9343566894531, 2071.75537109375, 2192.572265625]
alpha/beta optimization time: 0.3975250720977783
This batch time : update_bounds func: 1.0156	 prepare: 0.3581	 bound: 0.3980	 transfer: 0.0221	 finalize: 0.2295
Accumulated time: update_bounds func: 102.0518	 prepare: 28.5925	 bound: 38.4076	 transfer: 0.0221	 finalize: 31.0870
batch bounding time:  1.0185129642486572
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (163), [-0.06584,   inf] (163), [-0.06548,   inf] (163), [-0.06548,   inf] (163), [-0.06546,   inf] (169), [-0.06540,   inf] (169), [-0.06537,   inf] (167), [-0.06536,   inf] (167), [-0.06521,   inf] (165), [-0.06515,   inf] (165), [-0.06434,   inf] (165), [-0.06433,   inf] (165), [-0.06420,   inf] (165), [-0.06419,   inf] (165), [-0.06380,   inf] (161), [-0.06375,   inf] (161), [-0.06369,   inf] (147), [-0.06367,   inf] (161), [-0.06365,   inf] (161), [-0.06365,   inf] (149), 
length of domains: 46996
Total time: 1.8168	 pickout: 0.2516	 decision: 0.2704	 get_bound: 1.0230	 add_domain: 0.2718
Current lb:-0.06584525108337402
173632 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 183.56000566482544

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 195] [3, 195] [3, 195] [3, 195] [1, 81] [1, 81] [2, 141] [2, 141] [2, 85] [2, 141] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 49.673828125 with beta sum per layer: [258.0262145996094, 756.25439453125, 526.521240234375, 2014.544921875, 2179.18505859375]
alpha/beta optimization time: 0.40578198432922363
This batch time : update_bounds func: 1.0269	 prepare: 0.3557	 bound: 0.4063	 transfer: 0.0222	 finalize: 0.2350
Accumulated time: update_bounds func: 103.0787	 prepare: 28.9482	 bound: 38.8138	 transfer: 0.0222	 finalize: 31.3220
batch bounding time:  1.0292282104492188
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (165), [-0.06584,   inf] (165), [-0.06548,   inf] (165), [-0.06548,   inf] (165), [-0.06546,   inf] (171), [-0.06540,   inf] (171), [-0.06537,   inf] (169), [-0.06536,   inf] (169), [-0.06513,   inf] (167), [-0.06486,   inf] (167), [-0.06478,   inf] (167), [-0.06429,   inf] (167), [-0.06428,   inf] (167), [-0.06416,   inf] (167), [-0.06403,   inf] (167), [-0.06367,   inf] (163), [-0.06362,   inf] (163), [-0.06359,   inf] (163), [-0.06358,   inf] (149), [-0.06358,   inf] (163), 
length of domains: 47399
Total time: 3.5546	 pickout: 0.2573	 decision: 1.9982	 get_bound: 1.0332	 add_domain: 0.2659
Current lb:-0.06584525108337402
175680 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 187.16978883743286

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 163] [1, 163] [1, 163] [1, 163] [1, 163] [1, 163] [1, 81] [1, 81] [1, 81] [2, 141] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 49.22285079956055 with beta sum per layer: [234.36106872558594, 735.2191772460938, 564.1396484375, 1995.3486328125, 2189.201416015625]
alpha/beta optimization time: 0.40084028244018555
This batch time : update_bounds func: 1.0163	 prepare: 0.3603	 bound: 0.4014	 transfer: 0.0221	 finalize: 0.2245
Accumulated time: update_bounds func: 104.0950	 prepare: 29.3085	 bound: 39.2152	 transfer: 0.0221	 finalize: 31.5465
batch bounding time:  1.0186383724212646
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (167), [-0.06584,   inf] (167), [-0.06548,   inf] (167), [-0.06548,   inf] (167), [-0.06546,   inf] (173), [-0.06539,   inf] (173), [-0.06537,   inf] (171), [-0.06536,   inf] (171), [-0.06510,   inf] (169), [-0.06474,   inf] (169), [-0.06464,   inf] (169), [-0.06429,   inf] (169), [-0.06428,   inf] (169), [-0.06413,   inf] (169), [-0.06398,   inf] (169), [-0.06367,   inf] (165), [-0.06359,   inf] (165), [-0.06345,   inf] (151), [-0.06343,   inf] (165), [-0.06334,   inf] (165), 
length of domains: 47805
Total time: 1.8217	 pickout: 0.2626	 decision: 0.2665	 get_bound: 1.0225	 add_domain: 0.2701
Current lb:-0.06584525108337402
177728 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 189.0460331439972

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 141] [2, 141] [2, 141] [2, 141] [3, 130] [3, 130] [3, 130] [1, 163] [1, 163] [1, 81] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 49.38671112060547 with beta sum per layer: [237.53952026367188, 742.5015869140625, 614.6251220703125, 1966.24853515625, 2136.624755859375]
alpha/beta optimization time: 0.4004395008087158
This batch time : update_bounds func: 1.0174	 prepare: 0.3611	 bound: 0.4009	 transfer: 0.0221	 finalize: 0.2252
Accumulated time: update_bounds func: 105.1125	 prepare: 29.6696	 bound: 39.6161	 transfer: 0.0221	 finalize: 31.7717
batch bounding time:  1.0198071002960205
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (169), [-0.06584,   inf] (169), [-0.06548,   inf] (169), [-0.06548,   inf] (169), [-0.06546,   inf] (175), [-0.06539,   inf] (175), [-0.06537,   inf] (173), [-0.06536,   inf] (173), [-0.06508,   inf] (171), [-0.06464,   inf] (171), [-0.06461,   inf] (171), [-0.06429,   inf] (171), [-0.06428,   inf] (171), [-0.06412,   inf] (171), [-0.06396,   inf] (171), [-0.06367,   inf] (167), [-0.06359,   inf] (167), [-0.06332,   inf] (167), [-0.06320,   inf] (167), [-0.06310,   inf] (169), 
length of domains: 48220
Total time: 1.8422	 pickout: 0.2723	 decision: 0.2727	 get_bound: 1.0237	 add_domain: 0.2734
Current lb:-0.06584525108337402
179776 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 190.94494700431824

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 81] [1, 81] [1, 81] [1, 81] [2, 127] [2, 127] [1, 163] [3, 130] [3, 130] [1, 163] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 49.33757781982422 with beta sum per layer: [221.01451110839844, 762.970947265625, 565.4282836914062, 2078.255126953125, 2073.984375]
alpha/beta optimization time: 0.3984231948852539
This batch time : update_bounds func: 1.0372	 prepare: 0.3652	 bound: 0.3989	 transfer: 0.0229	 finalize: 0.2422
Accumulated time: update_bounds func: 106.1496	 prepare: 30.0348	 bound: 40.0151	 transfer: 0.0229	 finalize: 32.0139
batch bounding time:  1.039623498916626
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (171), [-0.06584,   inf] (171), [-0.06548,   inf] (171), [-0.06548,   inf] (171), [-0.06546,   inf] (177), [-0.06545,   inf] (177), [-0.06539,   inf] (177), [-0.06539,   inf] (177), [-0.06537,   inf] (175), [-0.06536,   inf] (175), [-0.06508,   inf] (173), [-0.06464,   inf] (173), [-0.06459,   inf] (173), [-0.06429,   inf] (173), [-0.06428,   inf] (173), [-0.06409,   inf] (173), [-0.06395,   inf] (173), [-0.06367,   inf] (169), [-0.06359,   inf] (169), [-0.06329,   inf] (169), 
length of domains: 48625
Total time: 1.8662	 pickout: 0.2621	 decision: 0.2677	 get_bound: 1.0443	 add_domain: 0.2922
Current lb:-0.06584525108337402
181824 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 192.870938539505

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 130] [3, 130] [3, 129] [3, 129] [3, 70] [3, 70] [3, 70] [3, 70] [2, 127] [2, 127] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 49.469242095947266 with beta sum per layer: [244.08917236328125, 703.1300048828125, 522.9224853515625, 1924.882568359375, 2209.055908203125]
alpha/beta optimization time: 0.3989682197570801
This batch time : update_bounds func: 1.0287	 prepare: 0.3707	 bound: 0.3995	 transfer: 0.0221	 finalize: 0.2287
Accumulated time: update_bounds func: 107.1783	 prepare: 30.4055	 bound: 40.4145	 transfer: 0.0221	 finalize: 32.2426
batch bounding time:  1.0314700603485107
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (173), [-0.06584,   inf] (173), [-0.06548,   inf] (173), [-0.06548,   inf] (173), [-0.06546,   inf] (179), [-0.06544,   inf] (179), [-0.06539,   inf] (179), [-0.06539,   inf] (179), [-0.06536,   inf] (177), [-0.06536,   inf] (177), [-0.06536,   inf] (177), [-0.06535,   inf] (177), [-0.06477,   inf] (175), [-0.06469,   inf] (175), [-0.06458,   inf] (175), [-0.06429,   inf] (175), [-0.06428,   inf] (175), [-0.06409,   inf] (175), [-0.06395,   inf] (175), [-0.06393,   inf] (175), 
length of domains: 49049
Total time: 3.6635	 pickout: 0.2652	 decision: 2.0822	 get_bound: 1.0357	 add_domain: 0.2804
Current lb:-0.06584525108337402
183872 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 196.58908605575562

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 48] [3, 48] [2, 127] [2, 127] [3, 48] [3, 48] [3, 48] [3, 48] [3, 70] [3, 70] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 50.060997009277344 with beta sum per layer: [226.30722045898438, 720.6737060546875, 465.45263671875, 1957.1318359375, 2211.114501953125]
alpha/beta optimization time: 0.4011538028717041
This batch time : update_bounds func: 1.0225	 prepare: 0.3631	 bound: 0.4017	 transfer: 0.0220	 finalize: 0.2276
Accumulated time: update_bounds func: 108.2009	 prepare: 30.7686	 bound: 40.8162	 transfer: 0.0220	 finalize: 32.4702
batch bounding time:  1.0249226093292236
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (175), [-0.06584,   inf] (175), [-0.06548,   inf] (175), [-0.06548,   inf] (175), [-0.06548,   inf] (175), [-0.06548,   inf] (175), [-0.06546,   inf] (181), [-0.06543,   inf] (181), [-0.06539,   inf] (181), [-0.06539,   inf] (181), [-0.06536,   inf] (179), [-0.06536,   inf] (179), [-0.06535,   inf] (179), [-0.06534,   inf] (179), [-0.06469,   inf] (177), [-0.06467,   inf] (177), [-0.06458,   inf] (177), [-0.06429,   inf] (177), [-0.06428,   inf] (177), [-0.06409,   inf] (177), 
length of domains: 49462
Total time: 1.8352	 pickout: 0.2555	 decision: 0.2706	 get_bound: 1.0290	 add_domain: 0.2801
Current lb:-0.06584525108337402
185920 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 198.4890308380127

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 127] [2, 127] [3, 48] [3, 48] [3, 48] [3, 48] [3, 129] [3, 129] [3, 129] [3, 129] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 47.480865478515625 with beta sum per layer: [251.398193359375, 705.9527587890625, 554.532470703125, 1816.6552734375, 2155.8759765625]
alpha/beta optimization time: 0.400115966796875
This batch time : update_bounds func: 1.0163	 prepare: 0.3613	 bound: 0.4006	 transfer: 0.0222	 finalize: 0.2243
Accumulated time: update_bounds func: 109.2172	 prepare: 31.1298	 bound: 41.2168	 transfer: 0.0222	 finalize: 32.6946
batch bounding time:  1.0189917087554932
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (177), [-0.06585,   inf] (177), [-0.06584,   inf] (177), [-0.06584,   inf] (177), [-0.06548,   inf] (177), [-0.06548,   inf] (177), [-0.06548,   inf] (177), [-0.06548,   inf] (177), [-0.06546,   inf] (183), [-0.06543,   inf] (183), [-0.06539,   inf] (183), [-0.06539,   inf] (183), [-0.06536,   inf] (181), [-0.06536,   inf] (181), [-0.06535,   inf] (181), [-0.06534,   inf] (181), [-0.06459,   inf] (179), [-0.06458,   inf] (179), [-0.06454,   inf] (179), [-0.06429,   inf] (179), 
length of domains: 49853
Total time: 1.8176	 pickout: 0.2532	 decision: 0.2644	 get_bound: 1.0235	 add_domain: 0.2765
Current lb:-0.06584525108337402
187968 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 200.36354660987854

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 129] [3, 129] [3, 129] [3, 129] [2, 13] [2, 13] [2, 13] [2, 13] [2, 13] [2, 13] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 48.912452697753906 with beta sum per layer: [198.06166076660156, 711.3195190429688, 584.6519775390625, 1840.1396484375, 2136.7265625]
alpha/beta optimization time: 0.39774394035339355
This batch time : update_bounds func: 1.0261	 prepare: 0.3592	 bound: 0.3982	 transfer: 0.0216	 finalize: 0.2389
Accumulated time: update_bounds func: 110.2433	 prepare: 31.4890	 bound: 41.6150	 transfer: 0.0216	 finalize: 32.9335
batch bounding time:  1.0283920764923096
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (179), [-0.06585,   inf] (179), [-0.06584,   inf] (179), [-0.06584,   inf] (179), [-0.06548,   inf] (179), [-0.06548,   inf] (179), [-0.06548,   inf] (179), [-0.06548,   inf] (179), [-0.06546,   inf] (185), [-0.06542,   inf] (185), [-0.06539,   inf] (185), [-0.06539,   inf] (185), [-0.06536,   inf] (183), [-0.06536,   inf] (183), [-0.06535,   inf] (183), [-0.06534,   inf] (183), [-0.06459,   inf] (181), [-0.06458,   inf] (181), [-0.06444,   inf] (181), [-0.06429,   inf] (181), 
length of domains: 50271
Total time: 3.6828	 pickout: 0.2543	 decision: 0.2684	 get_bound: 1.0322	 add_domain: 2.1278
Current lb:-0.06584525108337402
190016 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 204.10114407539368

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 70] [3, 70] [3, 70] [3, 70] [3, 70] [3, 70] [3, 70] [3, 70] [4, 185] [4, 185] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 47.8258171081543 with beta sum per layer: [214.37960815429688, 694.7423095703125, 548.160888671875, 1797.718994140625, 2136.9326171875]
alpha/beta optimization time: 0.4017512798309326
This batch time : update_bounds func: 1.0244	 prepare: 0.3625	 bound: 0.4023	 transfer: 0.0221	 finalize: 0.2295
Accumulated time: update_bounds func: 111.2677	 prepare: 31.8515	 bound: 42.0173	 transfer: 0.0221	 finalize: 33.1630
batch bounding time:  1.02691650390625
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (181), [-0.06585,   inf] (181), [-0.06584,   inf] (181), [-0.06584,   inf] (181), [-0.06548,   inf] (181), [-0.06548,   inf] (181), [-0.06548,   inf] (181), [-0.06548,   inf] (181), [-0.06546,   inf] (187), [-0.06541,   inf] (187), [-0.06539,   inf] (187), [-0.06539,   inf] (187), [-0.06536,   inf] (185), [-0.06536,   inf] (185), [-0.06535,   inf] (185), [-0.06534,   inf] (185), [-0.06459,   inf] (183), [-0.06459,   inf] (183), [-0.06458,   inf] (183), [-0.06458,   inf] (183), 
length of domains: 50682
Total time: 1.8341	 pickout: 0.2528	 decision: 0.2647	 get_bound: 1.0309	 add_domain: 0.2856
Current lb:-0.06584525108337402
192064 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 205.9904887676239

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 13] [2, 13] [2, 13] [2, 13] [3, 130] [3, 130] [3, 130] [3, 130] [1, 9] [1, 9] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 47.86100769042969 with beta sum per layer: [208.87741088867188, 759.82958984375, 534.23681640625, 1838.8924560546875, 2214.92919921875]
alpha/beta optimization time: 0.40128302574157715
This batch time : update_bounds func: 1.0281	 prepare: 0.3628	 bound: 0.4018	 transfer: 0.0216	 finalize: 0.2344
Accumulated time: update_bounds func: 112.2958	 prepare: 32.2143	 bound: 42.4191	 transfer: 0.0216	 finalize: 33.3974
batch bounding time:  1.03037691116333
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (183), [-0.06585,   inf] (183), [-0.06584,   inf] (183), [-0.06584,   inf] (183), [-0.06548,   inf] (183), [-0.06548,   inf] (183), [-0.06548,   inf] (183), [-0.06548,   inf] (183), [-0.06546,   inf] (189), [-0.06540,   inf] (189), [-0.06539,   inf] (189), [-0.06539,   inf] (189), [-0.06536,   inf] (187), [-0.06536,   inf] (187), [-0.06535,   inf] (187), [-0.06534,   inf] (187), [-0.06459,   inf] (185), [-0.06459,   inf] (185), [-0.06458,   inf] (185), [-0.06441,   inf] (185), 
length of domains: 51082
Total time: 1.8394	 pickout: 0.2570	 decision: 0.2663	 get_bound: 1.0343	 add_domain: 0.2819
Current lb:-0.06584525108337402
194112 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 207.88484263420105

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 185] [4, 185] [4, 185] [4, 185] [4, 185] [4, 185] [4, 185] [4, 185] [3, 98] [3, 98] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 48.9080696105957 with beta sum per layer: [221.28189086914062, 661.1159057617188, 523.3258056640625, 1878.711181640625, 2127.4111328125]
alpha/beta optimization time: 0.39882659912109375
This batch time : update_bounds func: 1.0242	 prepare: 0.3611	 bound: 0.3993	 transfer: 0.0221	 finalize: 0.2342
Accumulated time: update_bounds func: 113.3200	 prepare: 32.5754	 bound: 42.8184	 transfer: 0.0221	 finalize: 33.6317
batch bounding time:  1.0265870094299316
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (185), [-0.06585,   inf] (185), [-0.06584,   inf] (185), [-0.06584,   inf] (185), [-0.06548,   inf] (185), [-0.06548,   inf] (185), [-0.06548,   inf] (185), [-0.06548,   inf] (185), [-0.06546,   inf] (191), [-0.06540,   inf] (191), [-0.06539,   inf] (191), [-0.06539,   inf] (191), [-0.06536,   inf] (189), [-0.06536,   inf] (189), [-0.06535,   inf] (189), [-0.06534,   inf] (189), [-0.06459,   inf] (187), [-0.06459,   inf] (187), [-0.06458,   inf] (187), [-0.06441,   inf] (187), 
length of domains: 51494
Total time: 1.8355	 pickout: 0.2490	 decision: 0.2681	 get_bound: 1.0305	 add_domain: 0.2879
Current lb:-0.06584525108337402
196160 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 209.77580428123474

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 98] [3, 98] [3, 98] [3, 98] [3, 98] [3, 98] [3, 98] [3, 98] [2, 126] [2, 126] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 45.044639587402344 with beta sum per layer: [209.97964477539062, 698.057861328125, 519.3605346679688, 1832.697265625, 2100.916748046875]
alpha/beta optimization time: 0.39853477478027344
This batch time : update_bounds func: 1.0307	 prepare: 0.3623	 bound: 0.3990	 transfer: 0.0222	 finalize: 0.2395
Accumulated time: update_bounds func: 114.3507	 prepare: 32.9377	 bound: 43.2174	 transfer: 0.0222	 finalize: 33.8712
batch bounding time:  1.0332465171813965
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (187), [-0.06585,   inf] (187), [-0.06584,   inf] (187), [-0.06584,   inf] (187), [-0.06548,   inf] (187), [-0.06548,   inf] (187), [-0.06548,   inf] (187), [-0.06548,   inf] (187), [-0.06546,   inf] (193), [-0.06540,   inf] (193), [-0.06539,   inf] (193), [-0.06539,   inf] (193), [-0.06536,   inf] (191), [-0.06536,   inf] (191), [-0.06535,   inf] (191), [-0.06534,   inf] (191), [-0.06459,   inf] (189), [-0.06459,   inf] (189), [-0.06458,   inf] (189), [-0.06441,   inf] (189), 
length of domains: 51869
Total time: 1.8420	 pickout: 0.2475	 decision: 0.2739	 get_bound: 1.0373	 add_domain: 0.2833
Current lb:-0.06584525108337402
198208 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 211.67417573928833

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 126] [2, 126] [2, 126] [2, 126] [2, 126] [2, 126] [2, 126] [2, 126] [4, 33] [4, 33] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 45.93425750732422 with beta sum per layer: [200.94090270996094, 691.9337158203125, 535.679443359375, 1800.462158203125, 2054.527099609375]
alpha/beta optimization time: 0.4058222770690918
This batch time : update_bounds func: 1.0494	 prepare: 0.3729	 bound: 0.4063	 transfer: 0.0216	 finalize: 0.2409
Accumulated time: update_bounds func: 115.4002	 prepare: 33.3106	 bound: 43.6237	 transfer: 0.0216	 finalize: 34.1121
batch bounding time:  1.0521419048309326
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (189), [-0.06585,   inf] (189), [-0.06584,   inf] (189), [-0.06584,   inf] (189), [-0.06548,   inf] (189), [-0.06548,   inf] (189), [-0.06548,   inf] (189), [-0.06548,   inf] (189), [-0.06546,   inf] (195), [-0.06540,   inf] (195), [-0.06539,   inf] (195), [-0.06539,   inf] (195), [-0.06536,   inf] (193), [-0.06536,   inf] (193), [-0.06535,   inf] (193), [-0.06534,   inf] (193), [-0.06459,   inf] (191), [-0.06459,   inf] (191), [-0.06458,   inf] (191), [-0.06441,   inf] (191), 
length of domains: 52244
Total time: 3.8124	 pickout: 0.2449	 decision: 2.2264	 get_bound: 1.0563	 add_domain: 0.2848
Current lb:-0.06584525108337402
200256 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 215.5427827835083

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 33] [4, 33] [4, 33] [4, 33] [4, 33] [4, 33] [4, 33] [4, 33] [2, 66] [2, 66] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 47.567298889160156 with beta sum per layer: [210.4336700439453, 613.2940673828125, 487.30712890625, 1757.459228515625, 2201.171142578125]
alpha/beta optimization time: 0.40233278274536133
This batch time : update_bounds func: 1.0239	 prepare: 0.3552	 bound: 0.4028	 transfer: 0.0217	 finalize: 0.2370
Accumulated time: update_bounds func: 116.4240	 prepare: 33.6658	 bound: 44.0266	 transfer: 0.0217	 finalize: 34.3491
batch bounding time:  1.026106357574463
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (191), [-0.06585,   inf] (191), [-0.06584,   inf] (191), [-0.06584,   inf] (191), [-0.06548,   inf] (191), [-0.06548,   inf] (191), [-0.06548,   inf] (191), [-0.06548,   inf] (191), [-0.06546,   inf] (197), [-0.06540,   inf] (197), [-0.06539,   inf] (197), [-0.06539,   inf] (197), [-0.06536,   inf] (195), [-0.06536,   inf] (195), [-0.06535,   inf] (195), [-0.06534,   inf] (195), [-0.06459,   inf] (193), [-0.06459,   inf] (193), [-0.06458,   inf] (193), [-0.06441,   inf] (193), 
length of domains: 52671
Total time: 1.8358	 pickout: 0.2432	 decision: 0.2622	 get_bound: 1.0300	 add_domain: 0.3004
Current lb:-0.06584525108337402
202304 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 217.43878388404846

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 9] [1, 9] [1, 9] [1, 9] [2, 66] [2, 66] [2, 66] [2, 66] [1, 79] [1, 79] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 44.84904861450195 with beta sum per layer: [206.39605712890625, 677.1009521484375, 513.5587768554688, 1723.6256103515625, 2223.043701171875]
alpha/beta optimization time: 0.4116497039794922
This batch time : update_bounds func: 1.0552	 prepare: 0.3715	 bound: 0.4122	 transfer: 0.0222	 finalize: 0.2415
Accumulated time: update_bounds func: 117.4793	 prepare: 34.0374	 bound: 44.4388	 transfer: 0.0222	 finalize: 34.5906
batch bounding time:  1.0578835010528564
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (193), [-0.06585,   inf] (193), [-0.06584,   inf] (193), [-0.06584,   inf] (193), [-0.06548,   inf] (193), [-0.06548,   inf] (193), [-0.06548,   inf] (193), [-0.06548,   inf] (193), [-0.06546,   inf] (199), [-0.06540,   inf] (199), [-0.06539,   inf] (199), [-0.06539,   inf] (199), [-0.06536,   inf] (197), [-0.06536,   inf] (197), [-0.06535,   inf] (197), [-0.06534,   inf] (197), [-0.06459,   inf] (195), [-0.06459,   inf] (195), [-0.06458,   inf] (195), [-0.06441,   inf] (195), 
length of domains: 53037
Total time: 1.8711	 pickout: 0.2434	 decision: 0.2686	 get_bound: 1.0622	 add_domain: 0.2969
Current lb:-0.06584525108337402
204352 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 219.37687301635742

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 66] [2, 66] [2, 66] [2, 66] [1, 79] [1, 9] [1, 9] [1, 9] [2, 135] [2, 135] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 43.84959411621094 with beta sum per layer: [236.13812255859375, 693.6236572265625, 522.67919921875, 1630.1468505859375, 2102.18359375]
alpha/beta optimization time: 0.3996410369873047
This batch time : update_bounds func: 1.0494	 prepare: 0.3810	 bound: 0.4001	 transfer: 0.0216	 finalize: 0.2388
Accumulated time: update_bounds func: 118.5287	 prepare: 34.4184	 bound: 44.8389	 transfer: 0.0216	 finalize: 34.8295
batch bounding time:  1.0517973899841309
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (195), [-0.06585,   inf] (195), [-0.06584,   inf] (195), [-0.06584,   inf] (195), [-0.06548,   inf] (195), [-0.06548,   inf] (195), [-0.06548,   inf] (195), [-0.06548,   inf] (195), [-0.06546,   inf] (201), [-0.06540,   inf] (201), [-0.06539,   inf] (201), [-0.06539,   inf] (201), [-0.06536,   inf] (199), [-0.06536,   inf] (199), [-0.06535,   inf] (199), [-0.06534,   inf] (199), [-0.06459,   inf] (197), [-0.06459,   inf] (197), [-0.06458,   inf] (197), [-0.06441,   inf] (197), 
length of domains: 53392
Total time: 1.8967	 pickout: 0.2634	 decision: 0.2847	 get_bound: 1.0558	 add_domain: 0.2928
Current lb:-0.06584525108337402
206400 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 221.33103489875793

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 79] [1, 79] [1, 79] [1, 79] [1, 9] [1, 79] [1, 79] [1, 79] [4, 3] [4, 3] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 45.645233154296875 with beta sum per layer: [218.810302734375, 623.568115234375, 448.51177978515625, 1689.3057861328125, 2177.20166015625]
alpha/beta optimization time: 0.4058101177215576
This batch time : update_bounds func: 1.0464	 prepare: 0.3749	 bound: 0.4064	 transfer: 0.0219	 finalize: 0.2356
Accumulated time: update_bounds func: 119.5751	 prepare: 34.7933	 bound: 45.2453	 transfer: 0.0219	 finalize: 35.0650
batch bounding time:  1.0487380027770996
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (197), [-0.06585,   inf] (197), [-0.06584,   inf] (197), [-0.06584,   inf] (197), [-0.06548,   inf] (197), [-0.06548,   inf] (197), [-0.06548,   inf] (197), [-0.06548,   inf] (197), [-0.06546,   inf] (203), [-0.06540,   inf] (203), [-0.06539,   inf] (203), [-0.06539,   inf] (203), [-0.06536,   inf] (201), [-0.06536,   inf] (201), [-0.06535,   inf] (201), [-0.06534,   inf] (201), [-0.06459,   inf] (199), [-0.06459,   inf] (199), [-0.06458,   inf] (199), [-0.06441,   inf] (199), 
length of domains: 53774
Total time: 3.8524	 pickout: 0.2444	 decision: 2.2544	 get_bound: 1.0527	 add_domain: 0.3009
Current lb:-0.06584525108337402
208448 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 225.2425458431244

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 135] [2, 135] [2, 135] [2, 135] [2, 135] [2, 135] [2, 135] [2, 135] [2, 185] [2, 185] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 46.70362854003906 with beta sum per layer: [225.55422973632812, 650.108154296875, 485.632080078125, 1704.843505859375, 2122.430419921875]
alpha/beta optimization time: 0.409090518951416
This batch time : update_bounds func: 1.0442	 prepare: 0.3615	 bound: 0.4097	 transfer: 0.0216	 finalize: 0.2437
Accumulated time: update_bounds func: 120.6193	 prepare: 35.1548	 bound: 45.6550	 transfer: 0.0216	 finalize: 35.3087
batch bounding time:  1.0469367504119873
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (199), [-0.06585,   inf] (199), [-0.06584,   inf] (199), [-0.06584,   inf] (199), [-0.06548,   inf] (199), [-0.06548,   inf] (199), [-0.06548,   inf] (199), [-0.06548,   inf] (199), [-0.06546,   inf] (205), [-0.06540,   inf] (205), [-0.06539,   inf] (205), [-0.06539,   inf] (205), [-0.06536,   inf] (203), [-0.06536,   inf] (203), [-0.06535,   inf] (203), [-0.06534,   inf] (203), [-0.06459,   inf] (201), [-0.06459,   inf] (201), [-0.06458,   inf] (201), [-0.06441,   inf] (201), 
length of domains: 54177
Total time: 1.8657	 pickout: 0.2441	 decision: 0.2671	 get_bound: 1.0512	 add_domain: 0.3033
Current lb:-0.06584525108337402
210496 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 227.17240118980408

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 3] [4, 3] [4, 3] [4, 3] [4, 3] [4, 3] [4, 3] [4, 3] [3, 112] [3, 112] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 45.79034423828125 with beta sum per layer: [204.8190155029297, 609.33251953125, 502.7567443847656, 1594.19287109375, 2126.4072265625]
alpha/beta optimization time: 0.39825439453125
This batch time : update_bounds func: 1.0311	 prepare: 0.3620	 bound: 0.3987	 transfer: 0.0216	 finalize: 0.2407
Accumulated time: update_bounds func: 121.6504	 prepare: 35.5168	 bound: 46.0537	 transfer: 0.0216	 finalize: 35.5494
batch bounding time:  1.0335266590118408
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (201), [-0.06585,   inf] (201), [-0.06584,   inf] (201), [-0.06584,   inf] (201), [-0.06548,   inf] (201), [-0.06548,   inf] (201), [-0.06548,   inf] (201), [-0.06548,   inf] (201), [-0.06546,   inf] (207), [-0.06540,   inf] (207), [-0.06539,   inf] (207), [-0.06539,   inf] (207), [-0.06536,   inf] (205), [-0.06536,   inf] (205), [-0.06535,   inf] (205), [-0.06534,   inf] (205), [-0.06459,   inf] (203), [-0.06459,   inf] (203), [-0.06458,   inf] (203), [-0.06441,   inf] (203), 
length of domains: 54560
Total time: 1.8602	 pickout: 0.2457	 decision: 0.2685	 get_bound: 1.0375	 add_domain: 0.3085
Current lb:-0.06584525108337402
212544 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 229.09589648246765

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 30] [2, 30] [2, 30] [2, 30] [2, 185] [2, 185] [2, 185] [2, 185] [1, 137] [1, 137] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 47.619449615478516 with beta sum per layer: [179.42758178710938, 624.4566650390625, 452.70196533203125, 1698.89404296875, 2271.8173828125]
alpha/beta optimization time: 0.40183496475219727
This batch time : update_bounds func: 1.0202	 prepare: 0.3644	 bound: 0.4023	 transfer: 0.0221	 finalize: 0.2235
Accumulated time: update_bounds func: 122.6706	 prepare: 35.8812	 bound: 46.4560	 transfer: 0.0221	 finalize: 35.7729
batch bounding time:  1.0227923393249512
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (203), [-0.06585,   inf] (203), [-0.06584,   inf] (203), [-0.06584,   inf] (203), [-0.06548,   inf] (203), [-0.06548,   inf] (203), [-0.06548,   inf] (203), [-0.06548,   inf] (203), [-0.06546,   inf] (209), [-0.06540,   inf] (209), [-0.06539,   inf] (209), [-0.06539,   inf] (209), [-0.06536,   inf] (207), [-0.06536,   inf] (207), [-0.06535,   inf] (207), [-0.06534,   inf] (207), [-0.06459,   inf] (205), [-0.06459,   inf] (205), [-0.06458,   inf] (205), [-0.06441,   inf] (205), 
length of domains: 54977
Total time: 1.8610	 pickout: 0.2522	 decision: 0.2654	 get_bound: 1.0270	 add_domain: 0.3164
Current lb:-0.06584525108337402
214592 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 231.02003526687622

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 185] [2, 185] [2, 185] [2, 185] [3, 112] [3, 112] [3, 112] [3, 112] [4, 134] [4, 134] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 44.12232208251953 with beta sum per layer: [195.53140258789062, 569.3723754882812, 479.363525390625, 1613.2950439453125, 2134.518310546875]
alpha/beta optimization time: 0.4004521369934082
This batch time : update_bounds func: 3.0817	 prepare: 0.3630	 bound: 0.4009	 transfer: 0.0220	 finalize: 2.2876
Accumulated time: update_bounds func: 125.7522	 prepare: 36.2442	 bound: 46.8570	 transfer: 0.0220	 finalize: 38.0605
batch bounding time:  3.0842232704162598
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (205), [-0.06585,   inf] (205), [-0.06584,   inf] (205), [-0.06584,   inf] (205), [-0.06548,   inf] (205), [-0.06548,   inf] (205), [-0.06548,   inf] (205), [-0.06548,   inf] (205), [-0.06546,   inf] (211), [-0.06540,   inf] (211), [-0.06539,   inf] (211), [-0.06539,   inf] (211), [-0.06536,   inf] (209), [-0.06536,   inf] (209), [-0.06535,   inf] (209), [-0.06534,   inf] (209), [-0.06459,   inf] (207), [-0.06459,   inf] (207), [-0.06458,   inf] (207), [-0.06456,   inf] (207), 
length of domains: 55369
Total time: 3.9183	 pickout: 0.2509	 decision: 0.2665	 get_bound: 3.0883	 add_domain: 0.3126
Current lb:-0.06584525108337402
216640 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 234.9953842163086

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 134] [4, 134] [4, 134] [4, 134] [2, 30] [2, 30] [2, 30] [2, 30] [1, 21] [1, 21] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 46.88341522216797 with beta sum per layer: [185.03086853027344, 582.50048828125, 528.54541015625, 1686.2117919921875, 2153.02197265625]
alpha/beta optimization time: 0.4033069610595703
This batch time : update_bounds func: 1.0275	 prepare: 0.3671	 bound: 0.4038	 transfer: 0.0221	 finalize: 0.2266
Accumulated time: update_bounds func: 126.7797	 prepare: 36.6113	 bound: 47.2608	 transfer: 0.0221	 finalize: 38.2871
batch bounding time:  1.0298488140106201
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (207), [-0.06585,   inf] (207), [-0.06584,   inf] (207), [-0.06584,   inf] (207), [-0.06548,   inf] (207), [-0.06548,   inf] (207), [-0.06548,   inf] (207), [-0.06548,   inf] (207), [-0.06546,   inf] (213), [-0.06540,   inf] (213), [-0.06539,   inf] (213), [-0.06539,   inf] (213), [-0.06536,   inf] (211), [-0.06536,   inf] (211), [-0.06535,   inf] (211), [-0.06534,   inf] (211), [-0.06512,   inf] (213), [-0.06509,   inf] (213), [-0.06505,   inf] (213), [-0.06502,   inf] (213), 
length of domains: 55788
Total time: 1.8723	 pickout: 0.2420	 decision: 0.2744	 get_bound: 1.0337	 add_domain: 0.3222
Current lb:-0.06584525108337402
218688 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 236.92967081069946

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 112] [3, 112] [3, 112] [3, 112] [4, 134] [4, 134] [4, 134] [4, 134] [4, 55] [4, 55] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 44.22696304321289 with beta sum per layer: [175.89950561523438, 626.9473876953125, 529.8368530273438, 1528.389404296875, 2055.288330078125]
alpha/beta optimization time: 0.4066009521484375
This batch time : update_bounds func: 1.0280	 prepare: 0.3633	 bound: 0.4071	 transfer: 0.0222	 finalize: 0.2277
Accumulated time: update_bounds func: 127.8077	 prepare: 36.9746	 bound: 47.6679	 transfer: 0.0222	 finalize: 38.5148
batch bounding time:  1.03035569190979
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (209), [-0.06585,   inf] (209), [-0.06584,   inf] (209), [-0.06584,   inf] (209), [-0.06548,   inf] (209), [-0.06548,   inf] (209), [-0.06548,   inf] (209), [-0.06548,   inf] (209), [-0.06546,   inf] (215), [-0.06540,   inf] (215), [-0.06539,   inf] (215), [-0.06539,   inf] (215), [-0.06536,   inf] (213), [-0.06536,   inf] (213), [-0.06535,   inf] (213), [-0.06534,   inf] (213), [-0.06512,   inf] (213), [-0.06509,   inf] (213), [-0.06509,   inf] (215), [-0.06507,   inf] (215), 
length of domains: 56184
Total time: 1.8766	 pickout: 0.2411	 decision: 0.2736	 get_bound: 1.0343	 add_domain: 0.3277
Current lb:-0.06584525108337402
220736 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 238.8657557964325

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 21] [1, 21] [1, 21] [1, 21] [3, 53] [3, 53] [3, 53] [3, 53] [2, 30] [2, 30] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 47.44312286376953 with beta sum per layer: [196.871826171875, 588.6441650390625, 480.20947265625, 1534.054443359375, 2030.0794677734375]
alpha/beta optimization time: 0.40032148361206055
This batch time : update_bounds func: 1.0213	 prepare: 0.3636	 bound: 0.4008	 transfer: 0.0221	 finalize: 0.2271
Accumulated time: update_bounds func: 128.8290	 prepare: 37.3381	 bound: 48.0687	 transfer: 0.0221	 finalize: 38.7418
batch bounding time:  1.0236279964447021
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (211), [-0.06585,   inf] (211), [-0.06584,   inf] (211), [-0.06584,   inf] (211), [-0.06572,   inf] (211), [-0.06572,   inf] (211), [-0.06571,   inf] (211), [-0.06571,   inf] (211), [-0.06548,   inf] (211), [-0.06548,   inf] (211), [-0.06548,   inf] (211), [-0.06548,   inf] (211), [-0.06548,   inf] (211), [-0.06548,   inf] (211), [-0.06548,   inf] (211), [-0.06548,   inf] (211), [-0.06546,   inf] (217), [-0.06540,   inf] (217), [-0.06539,   inf] (217), [-0.06539,   inf] (217), 
length of domains: 56611
Total time: 1.8859	 pickout: 0.2477	 decision: 0.2704	 get_bound: 1.0276	 add_domain: 0.3402
Current lb:-0.06584525108337402
222784 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 240.81277322769165

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 55] [4, 55] [4, 55] [4, 55] [4, 55] [4, 55] [4, 55] [4, 55] [3, 34] [3, 34] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 47.641597747802734 with beta sum per layer: [171.84417724609375, 544.4837036132812, 492.10009765625, 1599.52099609375, 2031.053466796875]
alpha/beta optimization time: 0.4021284580230713
This batch time : update_bounds func: 1.0300	 prepare: 0.3699	 bound: 0.4026	 transfer: 0.0221	 finalize: 0.2276
Accumulated time: update_bounds func: 129.8590	 prepare: 37.7080	 bound: 48.4713	 transfer: 0.0221	 finalize: 38.9694
batch bounding time:  1.0322823524475098
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (213), [-0.06585,   inf] (213), [-0.06584,   inf] (213), [-0.06584,   inf] (213), [-0.06572,   inf] (213), [-0.06572,   inf] (213), [-0.06571,   inf] (213), [-0.06570,   inf] (213), [-0.06548,   inf] (213), [-0.06548,   inf] (213), [-0.06548,   inf] (213), [-0.06548,   inf] (213), [-0.06548,   inf] (213), [-0.06548,   inf] (213), [-0.06548,   inf] (213), [-0.06546,   inf] (219), [-0.06546,   inf] (219), [-0.06540,   inf] (219), [-0.06540,   inf] (219), [-0.06539,   inf] (219), 
length of domains: 57037
Total time: 4.0393	 pickout: 0.2455	 decision: 0.2693	 get_bound: 1.0361	 add_domain: 2.4884
Current lb:-0.06584525108337402
224832 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 244.9085340499878

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 137] [1, 137] [1, 137] [1, 137] [1, 137] [1, 137] [1, 137] [3, 53] [1, 21] [1, 21] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 47.28609848022461 with beta sum per layer: [165.33090209960938, 586.2603149414062, 508.25067138671875, 1528.822509765625, 2023.7723388671875]
alpha/beta optimization time: 0.40304017066955566
This batch time : update_bounds func: 1.0220	 prepare: 0.3640	 bound: 0.4035	 transfer: 0.0222	 finalize: 0.2245
Accumulated time: update_bounds func: 130.8810	 prepare: 38.0720	 bound: 48.8749	 transfer: 0.0222	 finalize: 39.1939
batch bounding time:  1.024324655532837
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (215), [-0.06585,   inf] (215), [-0.06584,   inf] (215), [-0.06584,   inf] (215), [-0.06572,   inf] (215), [-0.06572,   inf] (215), [-0.06571,   inf] (215), [-0.06570,   inf] (215), [-0.06570,   inf] (215), [-0.06548,   inf] (215), [-0.06548,   inf] (215), [-0.06548,   inf] (215), [-0.06548,   inf] (215), [-0.06548,   inf] (215), [-0.06548,   inf] (215), [-0.06548,   inf] (215), [-0.06548,   inf] (215), [-0.06548,   inf] (215), [-0.06548,   inf] (215), [-0.06547,   inf] (215), 
length of domains: 57460
Total time: 1.9010	 pickout: 0.2539	 decision: 0.2680	 get_bound: 1.0282	 add_domain: 0.3510
Current lb:-0.06584525108337402
226880 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 246.86664509773254

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 53] [3, 53] [3, 53] [3, 53] [3, 53] [3, 53] [3, 53] [1, 137] [1, 137] [4, 55] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 48.66358947753906 with beta sum per layer: [153.88497924804688, 602.3895874023438, 466.6851501464844, 1386.27490234375, 1932.8514404296875]
alpha/beta optimization time: 0.4017653465270996
This batch time : update_bounds func: 1.0381	 prepare: 0.3710	 bound: 0.4023	 transfer: 0.0218	 finalize: 0.2352
Accumulated time: update_bounds func: 131.9191	 prepare: 38.4431	 bound: 49.2771	 transfer: 0.0218	 finalize: 39.4291
batch bounding time:  1.0407001972198486
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (217), [-0.06585,   inf] (217), [-0.06585,   inf] (217), [-0.06585,   inf] (217), [-0.06584,   inf] (217), [-0.06584,   inf] (217), [-0.06584,   inf] (217), [-0.06584,   inf] (217), [-0.06572,   inf] (217), [-0.06572,   inf] (217), [-0.06572,   inf] (217), [-0.06571,   inf] (217), [-0.06571,   inf] (217), [-0.06571,   inf] (217), [-0.06570,   inf] (217), [-0.06570,   inf] (217), [-0.06548,   inf] (217), [-0.06548,   inf] (217), [-0.06548,   inf] (217), [-0.06548,   inf] (217), 
length of domains: 57880
Total time: 1.9228	 pickout: 0.2446	 decision: 0.2717	 get_bound: 1.0448	 add_domain: 0.3617
Current lb:-0.06584525108337402
228928 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 248.85361647605896

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 64] [2, 64] [4, 143] [0, 42] [2, 64] [2, 64] [4, 143] [2, 64] [2, 64] [2, 64] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 48.470611572265625 with beta sum per layer: [185.6258544921875, 570.2691650390625, 479.4554443359375, 1284.297119140625, 1830.561279296875]
alpha/beta optimization time: 0.4030885696411133
This batch time : update_bounds func: 1.0362	 prepare: 0.3706	 bound: 0.4036	 transfer: 0.0222	 finalize: 0.2324
Accumulated time: update_bounds func: 132.9553	 prepare: 38.8137	 bound: 49.6807	 transfer: 0.0222	 finalize: 39.6615
batch bounding time:  1.038581371307373
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (219), [-0.06585,   inf] (219), [-0.06585,   inf] (219), [-0.06584,   inf] (219), [-0.06584,   inf] (219), [-0.06584,   inf] (219), [-0.06584,   inf] (219), [-0.06572,   inf] (219), [-0.06572,   inf] (219), [-0.06572,   inf] (219), [-0.06571,   inf] (219), [-0.06571,   inf] (219), [-0.06571,   inf] (219), [-0.06570,   inf] (219), [-0.06570,   inf] (219), [-0.06548,   inf] (219), [-0.06548,   inf] (219), [-0.06548,   inf] (219), [-0.06548,   inf] (219), [-0.06548,   inf] (219), 
length of domains: 58300
Total time: 1.9240	 pickout: 0.2417	 decision: 0.2699	 get_bound: 1.0425	 add_domain: 0.3699
Current lb:-0.06584525108337402
230976 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 250.8361370563507

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 143] [4, 143] [2, 64] [4, 143] [4, 143] [2, 64] [4, 143] [4, 143] [4, 143] [4, 143] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 49.562583923339844 with beta sum per layer: [151.91842651367188, 536.1624145507812, 479.7025146484375, 1268.3524169921875, 1807.0394287109375]
alpha/beta optimization time: 0.40499019622802734
This batch time : update_bounds func: 1.0244	 prepare: 0.3609	 bound: 0.4055	 transfer: 0.0221	 finalize: 0.2285
Accumulated time: update_bounds func: 133.9797	 prepare: 39.1746	 bound: 50.0862	 transfer: 0.0221	 finalize: 39.8900
batch bounding time:  1.0269205570220947
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (221), [-0.06585,   inf] (221), [-0.06585,   inf] (221), [-0.06584,   inf] (221), [-0.06584,   inf] (221), [-0.06584,   inf] (221), [-0.06584,   inf] (221), [-0.06572,   inf] (221), [-0.06572,   inf] (221), [-0.06572,   inf] (221), [-0.06571,   inf] (221), [-0.06571,   inf] (221), [-0.06571,   inf] (221), [-0.06570,   inf] (221), [-0.06570,   inf] (221), [-0.06548,   inf] (221), [-0.06548,   inf] (221), [-0.06548,   inf] (221), [-0.06548,   inf] (221), [-0.06548,   inf] (221), 
length of domains: 58740
Total time: 1.9334	 pickout: 0.2476	 decision: 0.2694	 get_bound: 1.0309	 add_domain: 0.3855
Current lb:-0.06584525108337402
233024 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 252.83005118370056

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 34] [3, 34] [3, 34] [3, 34] [3, 34] [3, 34] [3, 34] [3, 34] [3, 34] [3, 34] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 47.928951263427734 with beta sum per layer: [173.0120849609375, 500.8359375, 478.6531982421875, 1226.8939208984375, 1813.645751953125]
alpha/beta optimization time: 0.402240514755249
This batch time : update_bounds func: 3.2477	 prepare: 0.3717	 bound: 0.4027	 transfer: 0.0222	 finalize: 2.4436
Accumulated time: update_bounds func: 137.2274	 prepare: 39.5463	 bound: 50.4889	 transfer: 0.0222	 finalize: 42.3336
batch bounding time:  3.2500550746917725
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (223), [-0.06585,   inf] (223), [-0.06585,   inf] (223), [-0.06584,   inf] (223), [-0.06584,   inf] (223), [-0.06584,   inf] (223), [-0.06584,   inf] (223), [-0.06572,   inf] (223), [-0.06572,   inf] (223), [-0.06572,   inf] (223), [-0.06571,   inf] (223), [-0.06571,   inf] (223), [-0.06571,   inf] (223), [-0.06570,   inf] (223), [-0.06570,   inf] (223), [-0.06548,   inf] (223), [-0.06548,   inf] (223), [-0.06548,   inf] (223), [-0.06548,   inf] (223), [-0.06548,   inf] (223), 
length of domains: 59186
Total time: 4.1669	 pickout: 0.2497	 decision: 0.2640	 get_bound: 3.2539	 add_domain: 0.3992
Current lb:-0.06584525108337402
235072 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 257.05771374702454

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 97] [2, 97] [2, 97] [2, 97] [2, 97] [2, 97] [2, 97] [2, 97] [2, 97] [2, 97] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 46.390785217285156 with beta sum per layer: [152.39425659179688, 506.3437805175781, 486.4211120605469, 1195.46826171875, 1762.2747802734375]
alpha/beta optimization time: 0.4024088382720947
This batch time : update_bounds func: 1.0347	 prepare: 0.3691	 bound: 0.4029	 transfer: 0.0218	 finalize: 0.2333
Accumulated time: update_bounds func: 138.2621	 prepare: 39.9154	 bound: 50.8919	 transfer: 0.0218	 finalize: 42.5668
batch bounding time:  1.0370302200317383
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (225), [-0.06585,   inf] (225), [-0.06585,   inf] (225), [-0.06584,   inf] (225), [-0.06584,   inf] (225), [-0.06584,   inf] (225), [-0.06584,   inf] (225), [-0.06572,   inf] (225), [-0.06572,   inf] (225), [-0.06572,   inf] (225), [-0.06571,   inf] (225), [-0.06571,   inf] (225), [-0.06571,   inf] (225), [-0.06570,   inf] (225), [-0.06570,   inf] (225), [-0.06548,   inf] (225), [-0.06548,   inf] (225), [-0.06548,   inf] (225), [-0.06548,   inf] (225), [-0.06548,   inf] (225), 
length of domains: 59596
Total time: 1.9843	 pickout: 0.2580	 decision: 0.2703	 get_bound: 1.0410	 add_domain: 0.4151
Current lb:-0.06584525108337402
237120 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 259.11498045921326

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 135] [0, 135] [0, 135] [0, 135] [0, 135] [0, 135] [0, 135] [0, 135] [0, 135] [0, 135] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 49.67887878417969 with beta sum per layer: [170.6912841796875, 498.2640380859375, 466.7874450683594, 1133.64306640625, 1663.536865234375]
alpha/beta optimization time: 0.40543198585510254
This batch time : update_bounds func: 1.0520	 prepare: 0.3829	 bound: 0.4059	 transfer: 0.0219	 finalize: 0.2342
Accumulated time: update_bounds func: 139.3141	 prepare: 40.2983	 bound: 51.2978	 transfer: 0.0219	 finalize: 42.8010
batch bounding time:  1.0543944835662842
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (227), [-0.06585,   inf] (227), [-0.06585,   inf] (227), [-0.06584,   inf] (227), [-0.06584,   inf] (227), [-0.06584,   inf] (227), [-0.06584,   inf] (227), [-0.06572,   inf] (227), [-0.06572,   inf] (227), [-0.06572,   inf] (227), [-0.06571,   inf] (227), [-0.06571,   inf] (227), [-0.06571,   inf] (227), [-0.06570,   inf] (227), [-0.06570,   inf] (227), [-0.06548,   inf] (227), [-0.06548,   inf] (227), [-0.06548,   inf] (227), [-0.06548,   inf] (227), [-0.06548,   inf] (227), 
length of domains: 60056
Total time: 2.0084	 pickout: 0.2636	 decision: 0.2631	 get_bound: 1.0584	 add_domain: 0.4234
Current lb:-0.06584525108337402
239168 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 261.2142262458801

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 116] [4, 116] [4, 116] [4, 116] [4, 116] [4, 116] [4, 116] [4, 116] [4, 116] [4, 116] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 49.05348587036133 with beta sum per layer: [178.1475830078125, 492.38922119140625, 437.205078125, 1023.441650390625, 1503.341796875]
alpha/beta optimization time: 0.40068912506103516
This batch time : update_bounds func: 1.0289	 prepare: 0.3720	 bound: 0.4012	 transfer: 0.0217	 finalize: 0.2267
Accumulated time: update_bounds func: 140.3430	 prepare: 40.6703	 bound: 51.6990	 transfer: 0.0217	 finalize: 43.0277
batch bounding time:  1.0312509536743164
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (229), [-0.06585,   inf] (229), [-0.06585,   inf] (229), [-0.06584,   inf] (229), [-0.06584,   inf] (229), [-0.06584,   inf] (229), [-0.06584,   inf] (229), [-0.06572,   inf] (229), [-0.06572,   inf] (229), [-0.06572,   inf] (229), [-0.06571,   inf] (229), [-0.06571,   inf] (229), [-0.06571,   inf] (229), [-0.06570,   inf] (229), [-0.06570,   inf] (229), [-0.06548,   inf] (229), [-0.06548,   inf] (229), [-0.06548,   inf] (229), [-0.06548,   inf] (229), [-0.06548,   inf] (229), 
length of domains: 60523
Total time: 2.0090	 pickout: 0.2595	 decision: 0.2637	 get_bound: 1.0351	 add_domain: 0.4506
Current lb:-0.06584525108337402
241216 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 263.2840623855591

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 14] [4, 14] [4, 14] [4, 14] [4, 14] [4, 14] [4, 14] [4, 14] [4, 14] [4, 14] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 43.26964569091797 with beta sum per layer: [167.70370483398438, 444.7454528808594, 443.6413879394531, 1011.1831665039062, 1522.1063232421875]
alpha/beta optimization time: 0.40311121940612793
This batch time : update_bounds func: 1.0333	 prepare: 0.3727	 bound: 0.4036	 transfer: 0.0222	 finalize: 0.2277
Accumulated time: update_bounds func: 141.3764	 prepare: 41.0430	 bound: 52.1026	 transfer: 0.0222	 finalize: 43.2554
batch bounding time:  1.0356853008270264
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (231), [-0.06585,   inf] (231), [-0.06585,   inf] (231), [-0.06584,   inf] (231), [-0.06584,   inf] (231), [-0.06584,   inf] (231), [-0.06584,   inf] (231), [-0.06572,   inf] (231), [-0.06572,   inf] (231), [-0.06572,   inf] (231), [-0.06571,   inf] (231), [-0.06571,   inf] (231), [-0.06571,   inf] (231), [-0.06570,   inf] (231), [-0.06570,   inf] (231), [-0.06548,   inf] (231), [-0.06548,   inf] (231), [-0.06548,   inf] (231), [-0.06548,   inf] (231), [-0.06548,   inf] (231), 
length of domains: 60957
Total time: 2.0185	 pickout: 0.2533	 decision: 0.2751	 get_bound: 1.0396	 add_domain: 0.4504
Current lb:-0.06584525108337402
243264 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 265.3626570701599

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 92] [0, 160] [0, 160] [0, 160] [0, 160] [0, 160] [0, 160] [0, 160] [0, 160] [0, 160] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 46.807029724121094 with beta sum per layer: [172.546630859375, 397.58349609375, 419.672119140625, 895.4312744140625, 1465.1962890625]
alpha/beta optimization time: 0.4041316509246826
This batch time : update_bounds func: 1.0254	 prepare: 0.3693	 bound: 0.4046	 transfer: 0.0220	 finalize: 0.2219
Accumulated time: update_bounds func: 142.4017	 prepare: 41.4123	 bound: 52.5072	 transfer: 0.0220	 finalize: 43.4773
batch bounding time:  1.027712106704712
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (233), [-0.06585,   inf] (233), [-0.06585,   inf] (233), [-0.06584,   inf] (233), [-0.06584,   inf] (233), [-0.06584,   inf] (233), [-0.06584,   inf] (233), [-0.06572,   inf] (233), [-0.06572,   inf] (233), [-0.06572,   inf] (233), [-0.06571,   inf] (233), [-0.06571,   inf] (233), [-0.06571,   inf] (233), [-0.06570,   inf] (233), [-0.06570,   inf] (233), [-0.06548,   inf] (233), [-0.06548,   inf] (233), [-0.06548,   inf] (233), [-0.06548,   inf] (233), [-0.06548,   inf] (233), 
length of domains: 61437
Total time: 4.3258	 pickout: 0.2425	 decision: 2.5757	 get_bound: 1.0316	 add_domain: 0.4761
Current lb:-0.06584525108337402
245312 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 269.7533452510834

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 160] [3, 92] [3, 92] [3, 92] [3, 92] [3, 92] [3, 92] [3, 92] [3, 92] [3, 92] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 52.105804443359375 with beta sum per layer: [172.86392211914062, 354.0906066894531, 426.32305908203125, 839.8419799804688, 1297.17919921875]
alpha/beta optimization time: 0.4027385711669922
This batch time : update_bounds func: 1.0173	 prepare: 0.3638	 bound: 0.4032	 transfer: 0.0222	 finalize: 0.2205
Accumulated time: update_bounds func: 143.4190	 prepare: 41.7761	 bound: 52.9105	 transfer: 0.0222	 finalize: 43.6978
batch bounding time:  1.019542932510376
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (235), [-0.06585,   inf] (235), [-0.06585,   inf] (235), [-0.06584,   inf] (235), [-0.06584,   inf] (235), [-0.06584,   inf] (235), [-0.06584,   inf] (235), [-0.06572,   inf] (235), [-0.06572,   inf] (235), [-0.06572,   inf] (235), [-0.06571,   inf] (235), [-0.06571,   inf] (235), [-0.06571,   inf] (235), [-0.06570,   inf] (235), [-0.06570,   inf] (235), [-0.06548,   inf] (235), [-0.06548,   inf] (235), [-0.06548,   inf] (235), [-0.06548,   inf] (235), [-0.06548,   inf] (235), 
length of domains: 61911
Total time: 2.0209	 pickout: 0.2394	 decision: 0.2643	 get_bound: 1.0234	 add_domain: 0.4937
Current lb:-0.06584525108337402
247360 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 271.83362317085266

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 125] [4, 125] [4, 125] [4, 125] [4, 125] [4, 125] [4, 125] [4, 125] [4, 125] [4, 125] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 50.36442565917969 with beta sum per layer: [180.09640502929688, 334.3312683105469, 468.2908630371094, 682.1541137695312, 1048.11474609375]
alpha/beta optimization time: 0.40387749671936035
This batch time : update_bounds func: 1.0141	 prepare: 0.3587	 bound: 0.4044	 transfer: 0.0220	 finalize: 0.2213
Accumulated time: update_bounds func: 144.4331	 prepare: 42.1348	 bound: 53.3148	 transfer: 0.0220	 finalize: 43.9190
batch bounding time:  1.0163321495056152
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (237), [-0.06585,   inf] (237), [-0.06585,   inf] (237), [-0.06584,   inf] (237), [-0.06584,   inf] (237), [-0.06584,   inf] (237), [-0.06584,   inf] (237), [-0.06572,   inf] (237), [-0.06572,   inf] (237), [-0.06572,   inf] (237), [-0.06571,   inf] (237), [-0.06571,   inf] (237), [-0.06571,   inf] (237), [-0.06570,   inf] (237), [-0.06570,   inf] (237), [-0.06548,   inf] (237), [-0.06548,   inf] (237), [-0.06548,   inf] (237), [-0.06548,   inf] (237), [-0.06548,   inf] (237), 
length of domains: 62358
Total time: 2.0357	 pickout: 0.2371	 decision: 0.2675	 get_bound: 1.0201	 add_domain: 0.5110
Current lb:-0.06584525108337402
249408 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 273.9336099624634

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 111] [3, 111] [3, 111] [3, 111] [3, 111] [3, 111] [3, 111] [3, 111] [3, 111] [3, 111] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 56.58317947387695 with beta sum per layer: [188.52720642089844, 303.7769470214844, 466.11505126953125, 565.437255859375, 853.8704833984375]
alpha/beta optimization time: 0.4015495777130127
This batch time : update_bounds func: 1.0045	 prepare: 0.3566	 bound: 0.4021	 transfer: 0.0221	 finalize: 0.2162
Accumulated time: update_bounds func: 145.4376	 prepare: 42.4914	 bound: 53.7169	 transfer: 0.0221	 finalize: 44.1352
batch bounding time:  1.006739854812622
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (239), [-0.06585,   inf] (239), [-0.06585,   inf] (239), [-0.06585,   inf] (239), [-0.06585,   inf] (239), [-0.06585,   inf] (239), [-0.06584,   inf] (239), [-0.06584,   inf] (239), [-0.06584,   inf] (239), [-0.06584,   inf] (239), [-0.06584,   inf] (239), [-0.06584,   inf] (239), [-0.06584,   inf] (239), [-0.06584,   inf] (239), [-0.06572,   inf] (239), [-0.06572,   inf] (239), [-0.06572,   inf] (239), [-0.06572,   inf] (239), [-0.06571,   inf] (239), [-0.06571,   inf] (239), 
length of domains: 62857
Total time: 2.0585	 pickout: 0.2282	 decision: 0.2687	 get_bound: 1.0105	 add_domain: 0.5512
Current lb:-0.06584525108337402
251456 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 276.0567488670349

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 72] [3, 49] [2, 72] [3, 49] [3, 49] [3, 49] [2, 72] [0, 42] [0, 42] [3, 49] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 57.33580017089844 with beta sum per layer: [198.85617065429688, 296.646484375, 470.9906005859375, 535.6506958007812, 732.7218627929688]
alpha/beta optimization time: 0.4019019603729248
This batch time : update_bounds func: 1.0095	 prepare: 0.3587	 bound: 0.4025	 transfer: 0.0219	 finalize: 0.2188
Accumulated time: update_bounds func: 146.4471	 prepare: 42.8502	 bound: 54.1193	 transfer: 0.0219	 finalize: 44.3541
batch bounding time:  1.011918067932129
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (241), [-0.06585,   inf] (241), [-0.06585,   inf] (241), [-0.06585,   inf] (241), [-0.06585,   inf] (241), [-0.06585,   inf] (241), [-0.06585,   inf] (241), [-0.06585,   inf] (241), [-0.06584,   inf] (241), [-0.06584,   inf] (241), [-0.06584,   inf] (241), [-0.06584,   inf] (241), [-0.06584,   inf] (241), [-0.06584,   inf] (241), [-0.06584,   inf] (241), [-0.06584,   inf] (241), [-0.06584,   inf] (241), [-0.06584,   inf] (241), [-0.06583,   inf] (241), [-0.06583,   inf] (241), 
length of domains: 63364
Total time: 2.0778	 pickout: 0.2269	 decision: 0.2676	 get_bound: 1.0159	 add_domain: 0.5674
Current lb:-0.06584525108337402
253504 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 278.1926245689392

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 42] [0, 42] [2, 81] [2, 81] [2, 81] [2, 81] [2, 81] [2, 81] [0, 42] [2, 81] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 58.24665832519531 with beta sum per layer: [165.28335571289062, 297.5648193359375, 471.05279541015625, 550.3052368164062, 663.0569458007812]
alpha/beta optimization time: 0.405454158782959
This batch time : update_bounds func: 1.0091	 prepare: 0.3561	 bound: 0.4060	 transfer: 0.0218	 finalize: 0.2178
Accumulated time: update_bounds func: 147.4561	 prepare: 43.2063	 bound: 54.5253	 transfer: 0.0218	 finalize: 44.5719
batch bounding time:  1.0113115310668945
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (243), [-0.06585,   inf] (243), [-0.06585,   inf] (243), [-0.06585,   inf] (243), [-0.06585,   inf] (243), [-0.06585,   inf] (243), [-0.06584,   inf] (243), [-0.06584,   inf] (243), [-0.06584,   inf] (243), [-0.06584,   inf] (243), [-0.06584,   inf] (243), [-0.06584,   inf] (243), [-0.06584,   inf] (243), [-0.06584,   inf] (243), [-0.06584,   inf] (243), [-0.06584,   inf] (243), [-0.06584,   inf] (243), [-0.06583,   inf] (243), [-0.06583,   inf] (243), [-0.06583,   inf] (243), 
length of domains: 63895
Total time: 4.4379	 pickout: 0.2302	 decision: 2.6115	 get_bound: 1.0151	 add_domain: 0.5811
Current lb:-0.06584525108337402
255552 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 282.69117069244385

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 93] [1, 138] [0, 93] [0, 93] [0, 93] [0, 93] [0, 93] [1, 138] [0, 93] [0, 93] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 66.09468841552734 with beta sum per layer: [123.91928100585938, 298.56304931640625, 476.149169921875, 578.6820068359375, 551.4728393554688]
alpha/beta optimization time: 0.40073108673095703
This batch time : update_bounds func: 0.9917	 prepare: 0.3473	 bound: 0.4012	 transfer: 0.0244	 finalize: 0.2116
Accumulated time: update_bounds func: 148.4479	 prepare: 43.5536	 bound: 54.9265	 transfer: 0.0244	 finalize: 44.7836
batch bounding time:  0.9941494464874268
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (245), [-0.06585,   inf] (245), [-0.06585,   inf] (245), [-0.06585,   inf] (245), [-0.06585,   inf] (245), [-0.06585,   inf] (245), [-0.06585,   inf] (245), [-0.06585,   inf] (245), [-0.06585,   inf] (245), [-0.06585,   inf] (245), [-0.06584,   inf] (245), [-0.06584,   inf] (245), [-0.06584,   inf] (245), [-0.06584,   inf] (245), [-0.06584,   inf] (245), [-0.06584,   inf] (245), [-0.06584,   inf] (245), [-0.06584,   inf] (245), [-0.06584,   inf] (245), [-0.06584,   inf] (245), 
length of domains: 64461
Total time: 2.0977	 pickout: 0.2283	 decision: 0.2655	 get_bound: 0.9978	 add_domain: 0.6061
Current lb:-0.06584525108337402
257600 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 284.849134683609

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 81] [0, 42] [0, 42] [0, 42] [1, 138] [4, 81] [4, 81] [4, 81] [4, 81] [1, 138] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 57.624595642089844 with beta sum per layer: [99.29833221435547, 324.1239318847656, 479.6605224609375, 597.17919921875, 414.7149963378906]
alpha/beta optimization time: 0.40775346755981445
This batch time : update_bounds func: 0.9897	 prepare: 0.3437	 bound: 0.4083	 transfer: 0.0230	 finalize: 0.2074
Accumulated time: update_bounds func: 149.4375	 prepare: 43.8972	 bound: 55.3348	 transfer: 0.0230	 finalize: 44.9909
batch bounding time:  0.9919097423553467
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (247), [-0.06585,   inf] (247), [-0.06585,   inf] (247), [-0.06585,   inf] (247), [-0.06585,   inf] (247), [-0.06584,   inf] (247), [-0.06584,   inf] (247), [-0.06584,   inf] (247), [-0.06584,   inf] (247), [-0.06584,   inf] (247), [-0.06584,   inf] (247), [-0.06584,   inf] (247), [-0.06584,   inf] (247), [-0.06584,   inf] (247), [-0.06584,   inf] (247), [-0.06583,   inf] (247), [-0.06583,   inf] (247), [-0.06583,   inf] (247), [-0.06582,   inf] (247), [-0.06582,   inf] (247), 
length of domains: 64952
Total time: 2.0815	 pickout: 0.2364	 decision: 0.2617	 get_bound: 0.9956	 add_domain: 0.5879
Current lb:-0.06584525108337402
259648 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 286.99496245384216

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 80] [0, 80] [0, 80] [0, 80] [0, 80] [0, 80] [0, 80] [0, 80] [0, 80] [0, 80] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 37.438392639160156 with beta sum per layer: [134.14059448242188, 370.3232421875, 458.46612548828125, 622.181884765625, 360.7008972167969]
alpha/beta optimization time: 0.4111976623535156
This batch time : update_bounds func: 0.9974	 prepare: 0.3495	 bound: 0.4117	 transfer: 0.0225	 finalize: 0.2062
Accumulated time: update_bounds func: 150.4349	 prepare: 44.2468	 bound: 55.7465	 transfer: 0.0225	 finalize: 45.1971
batch bounding time:  0.9996242523193359
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (249), [-0.06585,   inf] (249), [-0.06585,   inf] (249), [-0.06585,   inf] (249), [-0.06585,   inf] (249), [-0.06584,   inf] (249), [-0.06584,   inf] (249), [-0.06584,   inf] (249), [-0.06584,   inf] (249), [-0.06584,   inf] (249), [-0.06584,   inf] (249), [-0.06584,   inf] (249), [-0.06584,   inf] (249), [-0.06584,   inf] (249), [-0.06584,   inf] (249), [-0.06583,   inf] (249), [-0.06583,   inf] (249), [-0.06582,   inf] (249), [-0.06582,   inf] (249), [-0.06582,   inf] (249), 
length of domains: 65298
Total time: 2.0344	 pickout: 0.2298	 decision: 0.2637	 get_bound: 1.0034	 add_domain: 0.5375
Current lb:-0.06584525108337402
261696 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 289.09086322784424

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 133] [3, 133] [3, 133] [3, 133] [3, 133] [3, 133] [3, 133] [3, 133] [3, 133] [3, 133] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 30.72169303894043 with beta sum per layer: [105.03288269042969, 357.601318359375, 435.07965087890625, 663.8035888671875, 390.797607421875]
alpha/beta optimization time: 0.40317416191101074
This batch time : update_bounds func: 0.9984	 prepare: 0.3569	 bound: 0.4037	 transfer: 0.0224	 finalize: 0.2081
Accumulated time: update_bounds func: 151.4333	 prepare: 44.6037	 bound: 56.1502	 transfer: 0.0224	 finalize: 45.4052
batch bounding time:  1.0006284713745117
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (251), [-0.06585,   inf] (251), [-0.06585,   inf] (251), [-0.06585,   inf] (251), [-0.06585,   inf] (251), [-0.06584,   inf] (251), [-0.06584,   inf] (251), [-0.06584,   inf] (251), [-0.06584,   inf] (251), [-0.06584,   inf] (251), [-0.06584,   inf] (251), [-0.06584,   inf] (251), [-0.06584,   inf] (251), [-0.06584,   inf] (251), [-0.06584,   inf] (251), [-0.06583,   inf] (251), [-0.06583,   inf] (251), [-0.06582,   inf] (251), [-0.06582,   inf] (251), [-0.06582,   inf] (251), 
length of domains: 65522
Total time: 1.9904	 pickout: 0.2342	 decision: 0.2578	 get_bound: 1.0043	 add_domain: 0.4940
Current lb:-0.06584525108337402
263744 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 291.1446416378021

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 115] [4, 115] [4, 115] [4, 115] [4, 115] [4, 115] [4, 115] [4, 115] [4, 115] [4, 115] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 35.94076919555664 with beta sum per layer: [88.52940368652344, 447.94085693359375, 466.2347412109375, 682.4275512695312, 354.3421325683594]
alpha/beta optimization time: 0.40262556076049805
This batch time : update_bounds func: 0.9955	 prepare: 0.3555	 bound: 0.4031	 transfer: 0.0222	 finalize: 0.2080
Accumulated time: update_bounds func: 152.4288	 prepare: 44.9592	 bound: 56.5533	 transfer: 0.0222	 finalize: 45.6132
batch bounding time:  0.9977712631225586
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (253), [-0.06585,   inf] (253), [-0.06585,   inf] (253), [-0.06585,   inf] (253), [-0.06585,   inf] (253), [-0.06584,   inf] (253), [-0.06584,   inf] (253), [-0.06584,   inf] (253), [-0.06584,   inf] (253), [-0.06584,   inf] (253), [-0.06584,   inf] (253), [-0.06584,   inf] (253), [-0.06584,   inf] (253), [-0.06584,   inf] (253), [-0.06584,   inf] (253), [-0.06583,   inf] (253), [-0.06583,   inf] (253), [-0.06582,   inf] (253), [-0.06582,   inf] (253), [-0.06582,   inf] (253), 
length of domains: 65738
Total time: 4.4091	 pickout: 0.2331	 decision: 2.6833	 get_bound: 1.0015	 add_domain: 0.4912
Current lb:-0.06584525108337402
265792 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 295.6156361103058

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 36] [1, 36] [1, 36] [1, 36] [1, 36] [1, 36] [1, 36] [1, 36] [1, 36] [1, 36] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 34.32105255126953 with beta sum per layer: [83.89945983886719, 410.54901123046875, 400.93798828125, 610.6324462890625, 417.6815185546875]
alpha/beta optimization time: 0.4045431613922119
This batch time : update_bounds func: 0.9901	 prepare: 0.3500	 bound: 0.4050	 transfer: 0.0223	 finalize: 0.2061
Accumulated time: update_bounds func: 153.4189	 prepare: 45.3092	 bound: 56.9583	 transfer: 0.0223	 finalize: 45.8193
batch bounding time:  0.9924750328063965
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (255), [-0.06585,   inf] (255), [-0.06585,   inf] (255), [-0.06585,   inf] (255), [-0.06585,   inf] (255), [-0.06584,   inf] (255), [-0.06584,   inf] (255), [-0.06584,   inf] (255), [-0.06584,   inf] (255), [-0.06584,   inf] (255), [-0.06584,   inf] (255), [-0.06584,   inf] (255), [-0.06584,   inf] (255), [-0.06584,   inf] (255), [-0.06584,   inf] (255), [-0.06583,   inf] (255), [-0.06583,   inf] (255), [-0.06582,   inf] (255), [-0.06582,   inf] (255), [-0.06582,   inf] (255), 
length of domains: 65925
Total time: 1.9758	 pickout: 0.2409	 decision: 0.2546	 get_bound: 0.9962	 add_domain: 0.4840
Current lb:-0.06584525108337402
267840 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 297.65326023101807

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 194] [1, 194] [1, 194] [1, 194] [1, 194] [1, 194] [1, 194] [1, 194] [1, 194] [1, 194] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 34.518455505371094 with beta sum per layer: [68.79263305664062, 405.8443603515625, 359.3055419921875, 613.5529174804688, 403.87725830078125]
alpha/beta optimization time: 0.3993375301361084
This batch time : update_bounds func: 0.9837	 prepare: 0.3461	 bound: 0.3999	 transfer: 0.0220	 finalize: 0.2094
Accumulated time: update_bounds func: 154.4026	 prepare: 45.6552	 bound: 57.3582	 transfer: 0.0220	 finalize: 46.0287
batch bounding time:  0.9860556125640869
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (257), [-0.06585,   inf] (257), [-0.06585,   inf] (257), [-0.06585,   inf] (257), [-0.06585,   inf] (257), [-0.06584,   inf] (257), [-0.06584,   inf] (257), [-0.06584,   inf] (257), [-0.06584,   inf] (257), [-0.06584,   inf] (257), [-0.06584,   inf] (257), [-0.06584,   inf] (257), [-0.06584,   inf] (257), [-0.06584,   inf] (257), [-0.06584,   inf] (257), [-0.06583,   inf] (257), [-0.06583,   inf] (257), [-0.06582,   inf] (257), [-0.06582,   inf] (257), [-0.06582,   inf] (257), 
length of domains: 66138
Total time: 1.9858	 pickout: 0.2390	 decision: 0.2550	 get_bound: 0.9900	 add_domain: 0.5018
Current lb:-0.06584525108337402
269888 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 299.70153617858887

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 167] [3, 167] [3, 167] [3, 167] [3, 167] [3, 167] [3, 167] [3, 167] [3, 167] [3, 167] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 37.971466064453125 with beta sum per layer: [75.0596923828125, 359.695556640625, 344.94696044921875, 653.0353393554688, 391.5623779296875]
alpha/beta optimization time: 0.39916110038757324
This batch time : update_bounds func: 0.9867	 prepare: 0.3494	 bound: 0.3996	 transfer: 0.0219	 finalize: 0.2091
Accumulated time: update_bounds func: 155.3893	 prepare: 46.0047	 bound: 57.7578	 transfer: 0.0219	 finalize: 46.2378
batch bounding time:  0.988990068435669
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (259), [-0.06585,   inf] (259), [-0.06585,   inf] (259), [-0.06585,   inf] (259), [-0.06585,   inf] (259), [-0.06584,   inf] (259), [-0.06584,   inf] (259), [-0.06584,   inf] (259), [-0.06584,   inf] (259), [-0.06584,   inf] (259), [-0.06584,   inf] (259), [-0.06584,   inf] (259), [-0.06584,   inf] (259), [-0.06584,   inf] (259), [-0.06584,   inf] (259), [-0.06583,   inf] (259), [-0.06583,   inf] (259), [-0.06582,   inf] (259), [-0.06582,   inf] (259), [-0.06582,   inf] (259), 
length of domains: 66335
Total time: 1.9769	 pickout: 0.2414	 decision: 0.2517	 get_bound: 0.9927	 add_domain: 0.4912
Current lb:-0.06584525108337402
271936 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 301.7462100982666

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 4] [4, 4] [4, 4] [4, 4] [4, 4] [4, 4] [4, 4] [4, 4] [4, 4] [4, 4] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 33.78600311279297 with beta sum per layer: [78.02288818359375, 306.8705749511719, 306.75238037109375, 604.357177734375, 490.779296875]
alpha/beta optimization time: 0.3996236324310303
This batch time : update_bounds func: 0.9923	 prepare: 0.3537	 bound: 0.4001	 transfer: 0.0232	 finalize: 0.2082
Accumulated time: update_bounds func: 156.3816	 prepare: 46.3583	 bound: 58.1580	 transfer: 0.0232	 finalize: 46.4459
batch bounding time:  0.9946844577789307
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (261), [-0.06585,   inf] (261), [-0.06585,   inf] (261), [-0.06585,   inf] (261), [-0.06585,   inf] (261), [-0.06584,   inf] (261), [-0.06584,   inf] (261), [-0.06584,   inf] (261), [-0.06584,   inf] (261), [-0.06584,   inf] (261), [-0.06584,   inf] (261), [-0.06584,   inf] (261), [-0.06584,   inf] (261), [-0.06584,   inf] (261), [-0.06584,   inf] (261), [-0.06583,   inf] (261), [-0.06583,   inf] (261), [-0.06582,   inf] (261), [-0.06582,   inf] (261), [-0.06582,   inf] (261), 
length of domains: 66514
Total time: 1.9790	 pickout: 0.2354	 decision: 0.2558	 get_bound: 0.9985	 add_domain: 0.4892
Current lb:-0.06584525108337402
273984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 303.7898418903351

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 102] [4, 102] [4, 102] [4, 102] [4, 102] [4, 102] [4, 102] [4, 102] [4, 102] [4, 102] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 17.100147247314453 with beta sum per layer: [95.81344604492188, 281.841796875, 280.1890869140625, 613.7930297851562, 437.4349365234375]
alpha/beta optimization time: 0.40102291107177734
This batch time : update_bounds func: 0.9832	 prepare: 0.3454	 bound: 0.4015	 transfer: 0.0222	 finalize: 0.2073
Accumulated time: update_bounds func: 157.3649	 prepare: 46.7037	 bound: 58.5595	 transfer: 0.0222	 finalize: 46.6532
batch bounding time:  0.985630989074707
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (263), [-0.06585,   inf] (263), [-0.06585,   inf] (263), [-0.06585,   inf] (263), [-0.06585,   inf] (263), [-0.06584,   inf] (263), [-0.06584,   inf] (263), [-0.06584,   inf] (263), [-0.06584,   inf] (263), [-0.06584,   inf] (263), [-0.06584,   inf] (263), [-0.06584,   inf] (263), [-0.06584,   inf] (263), [-0.06584,   inf] (263), [-0.06584,   inf] (263), [-0.06583,   inf] (263), [-0.06583,   inf] (263), [-0.06582,   inf] (263), [-0.06582,   inf] (263), [-0.06582,   inf] (263), 
length of domains: 66632
Total time: 4.4290	 pickout: 0.2333	 decision: 2.7396	 get_bound: 0.9894	 add_domain: 0.4666
Current lb:-0.06584525108337402
276032 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 308.2846438884735

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 105] [3, 105] [3, 105] [3, 105] [3, 105] [3, 105] [3, 105] [3, 105] [3, 105] [3, 105] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 23.94934844970703 with beta sum per layer: [70.72161865234375, 269.0275573730469, 262.52667236328125, 624.537353515625, 452.96533203125]
alpha/beta optimization time: 0.4001944065093994
This batch time : update_bounds func: 0.9873	 prepare: 0.3468	 bound: 0.4007	 transfer: 0.0218	 finalize: 0.2113
Accumulated time: update_bounds func: 158.3521	 prepare: 47.0505	 bound: 58.9602	 transfer: 0.0218	 finalize: 46.8645
batch bounding time:  0.9896516799926758
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (265), [-0.06585,   inf] (265), [-0.06585,   inf] (265), [-0.06585,   inf] (265), [-0.06585,   inf] (265), [-0.06584,   inf] (265), [-0.06584,   inf] (265), [-0.06584,   inf] (265), [-0.06584,   inf] (265), [-0.06584,   inf] (265), [-0.06584,   inf] (265), [-0.06584,   inf] (265), [-0.06584,   inf] (265), [-0.06584,   inf] (265), [-0.06584,   inf] (265), [-0.06583,   inf] (265), [-0.06583,   inf] (265), [-0.06582,   inf] (265), [-0.06582,   inf] (265), [-0.06582,   inf] (265), 
length of domains: 66761
Total time: 1.9558	 pickout: 0.2353	 decision: 0.2544	 get_bound: 0.9934	 add_domain: 0.4726
Current lb:-0.06584525108337402
278080 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 310.30855345726013

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 85] [4, 85] [1, 188] [1, 188] [1, 188] [1, 188] [1, 188] [1, 188] [1, 188] [1, 188] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 41.55411148071289 with beta sum per layer: [49.82392501831055, 289.80975341796875, 294.98419189453125, 526.7136840820312, 571.688232421875]
alpha/beta optimization time: 0.3988018035888672
This batch time : update_bounds func: 0.9811	 prepare: 0.3459	 bound: 0.3993	 transfer: 0.0224	 finalize: 0.2071
Accumulated time: update_bounds func: 159.3332	 prepare: 47.3963	 bound: 59.3595	 transfer: 0.0224	 finalize: 47.0716
batch bounding time:  0.9837584495544434
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (267), [-0.06585,   inf] (267), [-0.06585,   inf] (267), [-0.06585,   inf] (267), [-0.06585,   inf] (267), [-0.06585,   inf] (267), [-0.06585,   inf] (267), [-0.06585,   inf] (267), [-0.06584,   inf] (267), [-0.06584,   inf] (267), [-0.06584,   inf] (267), [-0.06584,   inf] (267), [-0.06584,   inf] (267), [-0.06584,   inf] (267), [-0.06584,   inf] (267), [-0.06584,   inf] (267), [-0.06584,   inf] (267), [-0.06584,   inf] (267), [-0.06584,   inf] (267), [-0.06584,   inf] (267), 
length of domains: 67050
Total time: 2.0089	 pickout: 0.2300	 decision: 0.2499	 get_bound: 0.9878	 add_domain: 0.5412
Current lb:-0.06584525108337402
280128 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 312.38304376602173

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 188] [1, 188] [4, 85] [4, 85] [4, 85] [4, 85] [4, 85] [4, 85] [1, 138] [0, 42] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 50.80193328857422 with beta sum per layer: [56.2686767578125, 365.3875732421875, 361.64263916015625, 533.6795043945312, 404.8043212890625]
alpha/beta optimization time: 0.4007890224456787
This batch time : update_bounds func: 0.9823	 prepare: 0.3454	 bound: 0.4013	 transfer: 0.0224	 finalize: 0.2066
Accumulated time: update_bounds func: 160.3155	 prepare: 47.7418	 bound: 59.7608	 transfer: 0.0224	 finalize: 47.2782
batch bounding time:  0.9846525192260742
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (269), [-0.06585,   inf] (269), [-0.06585,   inf] (269), [-0.06585,   inf] (269), [-0.06585,   inf] (269), [-0.06585,   inf] (269), [-0.06585,   inf] (269), [-0.06585,   inf] (269), [-0.06585,   inf] (269), [-0.06585,   inf] (269), [-0.06584,   inf] (269), [-0.06584,   inf] (269), [-0.06584,   inf] (269), [-0.06584,   inf] (269), [-0.06584,   inf] (269), [-0.06584,   inf] (269), [-0.06584,   inf] (269), [-0.06584,   inf] (269), [-0.06584,   inf] (269), [-0.06584,   inf] (269), 
length of domains: 67359
Total time: 2.0266	 pickout: 0.2309	 decision: 0.2506	 get_bound: 0.9884	 add_domain: 0.5566
Current lb:-0.06584525108337402
282176 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 314.4728515148163

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 42] [4, 17] [4, 17] [1, 138] [4, 17] [4, 17] [4, 17] [4, 17] [4, 17] [4, 17] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 57.60739517211914 with beta sum per layer: [58.7196044921875, 360.83831787109375, 355.7435607910156, 531.4075927734375, 504.4639587402344]
alpha/beta optimization time: 0.4062795639038086
This batch time : update_bounds func: 0.9867	 prepare: 0.3413	 bound: 0.4068	 transfer: 0.0219	 finalize: 0.2104
Accumulated time: update_bounds func: 161.3023	 prepare: 48.0831	 bound: 60.1676	 transfer: 0.0219	 finalize: 47.4885
batch bounding time:  0.9889698028564453
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (271), [-0.06585,   inf] (271), [-0.06585,   inf] (271), [-0.06585,   inf] (271), [-0.06585,   inf] (271), [-0.06585,   inf] (271), [-0.06585,   inf] (271), [-0.06585,   inf] (271), [-0.06584,   inf] (271), [-0.06584,   inf] (271), [-0.06584,   inf] (271), [-0.06584,   inf] (271), [-0.06584,   inf] (271), [-0.06584,   inf] (271), [-0.06584,   inf] (271), [-0.06584,   inf] (271), [-0.06584,   inf] (271), [-0.06584,   inf] (271), [-0.06584,   inf] (271), [-0.06584,   inf] (271), 
length of domains: 67774
Total time: 2.0771	 pickout: 0.2296	 decision: 0.2534	 get_bound: 0.9926	 add_domain: 0.6016
Current lb:-0.06584525108337402
284224 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 316.6101064682007

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 16] [3, 16] [3, 16] [3, 16] [3, 16] [3, 16] [3, 16] [3, 16] [3, 16] [3, 16] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 50.04084014892578 with beta sum per layer: [61.73358917236328, 304.38116455078125, 360.1567687988281, 672.6788330078125, 344.25640869140625]
alpha/beta optimization time: 0.4068124294281006
This batch time : update_bounds func: 3.5490	 prepare: 0.3462	 bound: 0.4073	 transfer: 0.0231	 finalize: 2.7659
Accumulated time: update_bounds func: 164.8513	 prepare: 48.4293	 bound: 60.5749	 transfer: 0.0231	 finalize: 50.2544
batch bounding time:  3.551259994506836
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (273), [-0.06585,   inf] (273), [-0.06585,   inf] (273), [-0.06585,   inf] (273), [-0.06585,   inf] (273), [-0.06585,   inf] (273), [-0.06585,   inf] (273), [-0.06585,   inf] (273), [-0.06584,   inf] (273), [-0.06584,   inf] (273), [-0.06584,   inf] (273), [-0.06584,   inf] (273), [-0.06584,   inf] (273), [-0.06584,   inf] (273), [-0.06584,   inf] (273), [-0.06584,   inf] (273), [-0.06584,   inf] (273), [-0.06584,   inf] (273), [-0.06584,   inf] (273), [-0.06584,   inf] (273), 
length of domains: 68103
Total time: 4.6012	 pickout: 0.2294	 decision: 0.2482	 get_bound: 3.5549	 add_domain: 0.5687
Current lb:-0.06584525108337402
286272 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 321.2741415500641

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 50] [2, 50] [2, 50] [2, 50] [2, 50] [2, 50] [2, 50] [2, 50] [2, 50] [2, 50] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 41.786109924316406 with beta sum per layer: [55.0938720703125, 307.30780029296875, 405.7352294921875, 594.9476318359375, 408.7633056640625]
alpha/beta optimization time: 0.41257643699645996
This batch time : update_bounds func: 0.9997	 prepare: 0.3487	 bound: 0.4131	 transfer: 0.0224	 finalize: 0.2089
Accumulated time: update_bounds func: 165.8510	 prepare: 48.7781	 bound: 60.9880	 transfer: 0.0224	 finalize: 50.4633
batch bounding time:  1.0020151138305664
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (275), [-0.06585,   inf] (275), [-0.06585,   inf] (275), [-0.06585,   inf] (275), [-0.06585,   inf] (275), [-0.06585,   inf] (275), [-0.06585,   inf] (275), [-0.06585,   inf] (275), [-0.06584,   inf] (275), [-0.06584,   inf] (275), [-0.06584,   inf] (275), [-0.06584,   inf] (275), [-0.06584,   inf] (275), [-0.06584,   inf] (275), [-0.06584,   inf] (275), [-0.06584,   inf] (275), [-0.06584,   inf] (275), [-0.06584,   inf] (275), [-0.06584,   inf] (275), [-0.06584,   inf] (275), 
length of domains: 68349
Total time: 2.0333	 pickout: 0.2278	 decision: 0.2519	 get_bound: 1.0058	 add_domain: 0.5478
Current lb:-0.06584525108337402
288320 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 323.3776361942291

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 195] [1, 195] [1, 195] [1, 195] [1, 195] [1, 195] [1, 195] [1, 195] [1, 195] [1, 195] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 42.32450866699219 with beta sum per layer: [69.02269744873047, 379.04364013671875, 407.53619384765625, 700.905517578125, 315.15911865234375]
alpha/beta optimization time: 0.406994104385376
This batch time : update_bounds func: 0.9984	 prepare: 0.3530	 bound: 0.4075	 transfer: 0.0232	 finalize: 0.2078
Accumulated time: update_bounds func: 166.8494	 prepare: 49.1310	 bound: 61.3955	 transfer: 0.0232	 finalize: 50.6711
batch bounding time:  1.0007295608520508
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (277), [-0.06585,   inf] (277), [-0.06585,   inf] (277), [-0.06585,   inf] (277), [-0.06585,   inf] (277), [-0.06585,   inf] (277), [-0.06585,   inf] (277), [-0.06585,   inf] (277), [-0.06584,   inf] (277), [-0.06584,   inf] (277), [-0.06584,   inf] (277), [-0.06584,   inf] (277), [-0.06584,   inf] (277), [-0.06584,   inf] (277), [-0.06584,   inf] (277), [-0.06584,   inf] (277), [-0.06584,   inf] (277), [-0.06584,   inf] (277), [-0.06584,   inf] (277), [-0.06584,   inf] (277), 
length of domains: 68670
Total time: 2.0841	 pickout: 0.2378	 decision: 0.2509	 get_bound: 1.0045	 add_domain: 0.5909
Current lb:-0.06584525108337402
290368 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 325.53687477111816

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 83] [3, 83] [3, 83] [3, 83] [3, 83] [3, 83] [3, 83] [3, 83] [3, 83] [3, 83] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 34.10757064819336 with beta sum per layer: [69.69915771484375, 327.49700927734375, 293.988037109375, 779.2413940429688, 341.592041015625]
alpha/beta optimization time: 0.4118773937225342
This batch time : update_bounds func: 1.0063	 prepare: 0.3568	 bound: 0.4124	 transfer: 0.0231	 finalize: 0.2075
Accumulated time: update_bounds func: 167.8557	 prepare: 49.4879	 bound: 61.8079	 transfer: 0.0231	 finalize: 50.8786
batch bounding time:  1.0087471008300781
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (279), [-0.06585,   inf] (279), [-0.06585,   inf] (279), [-0.06585,   inf] (279), [-0.06585,   inf] (279), [-0.06585,   inf] (279), [-0.06585,   inf] (279), [-0.06585,   inf] (279), [-0.06584,   inf] (279), [-0.06584,   inf] (279), [-0.06584,   inf] (279), [-0.06584,   inf] (279), [-0.06584,   inf] (279), [-0.06584,   inf] (279), [-0.06584,   inf] (279), [-0.06584,   inf] (279), [-0.06584,   inf] (279), [-0.06584,   inf] (279), [-0.06584,   inf] (279), [-0.06584,   inf] (279), 
length of domains: 68833
Total time: 2.0049	 pickout: 0.2285	 decision: 0.2485	 get_bound: 1.0126	 add_domain: 0.5153
Current lb:-0.06584525108337402
292416 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 327.60649943351746

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 58] [4, 58] [4, 58] [4, 58] [4, 58] [4, 58] [4, 58] [4, 58] [4, 58] [4, 58] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 39.58741760253906 with beta sum per layer: [76.10980987548828, 291.32147216796875, 335.0396728515625, 638.1431884765625, 393.3347473144531]
alpha/beta optimization time: 0.40839695930480957
This batch time : update_bounds func: 1.0001	 prepare: 0.3549	 bound: 0.4089	 transfer: 0.0224	 finalize: 0.2077
Accumulated time: update_bounds func: 168.8558	 prepare: 49.8427	 bound: 62.2168	 transfer: 0.0224	 finalize: 51.0863
batch bounding time:  1.0024542808532715
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (281), [-0.06585,   inf] (281), [-0.06585,   inf] (281), [-0.06585,   inf] (281), [-0.06585,   inf] (281), [-0.06585,   inf] (281), [-0.06585,   inf] (281), [-0.06585,   inf] (281), [-0.06584,   inf] (281), [-0.06584,   inf] (281), [-0.06584,   inf] (281), [-0.06584,   inf] (281), [-0.06584,   inf] (281), [-0.06584,   inf] (281), [-0.06584,   inf] (281), [-0.06584,   inf] (281), [-0.06584,   inf] (281), [-0.06584,   inf] (281), [-0.06584,   inf] (281), [-0.06584,   inf] (281), 
length of domains: 69059
Total time: 2.0238	 pickout: 0.2271	 decision: 0.2494	 get_bound: 1.0062	 add_domain: 0.5412
Current lb:-0.06584525108337402
294464 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 329.69914078712463

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 114] [2, 114] [2, 114] [2, 114] [2, 114] [2, 114] [2, 114] [2, 114] [2, 114] [2, 114] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 35.93394470214844 with beta sum per layer: [99.63937377929688, 305.3110656738281, 351.18524169921875, 563.1683349609375, 466.05072021484375]
alpha/beta optimization time: 0.40837693214416504
This batch time : update_bounds func: 1.0141	 prepare: 0.3659	 bound: 0.4089	 transfer: 0.0230	 finalize: 0.2096
Accumulated time: update_bounds func: 169.8699	 prepare: 50.2087	 bound: 62.6257	 transfer: 0.0230	 finalize: 51.2959
batch bounding time:  1.0164299011230469
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (283), [-0.06585,   inf] (283), [-0.06585,   inf] (283), [-0.06585,   inf] (283), [-0.06585,   inf] (283), [-0.06585,   inf] (283), [-0.06585,   inf] (283), [-0.06585,   inf] (283), [-0.06584,   inf] (283), [-0.06584,   inf] (283), [-0.06584,   inf] (283), [-0.06584,   inf] (283), [-0.06584,   inf] (283), [-0.06584,   inf] (283), [-0.06584,   inf] (283), [-0.06584,   inf] (283), [-0.06584,   inf] (283), [-0.06584,   inf] (283), [-0.06584,   inf] (283), [-0.06584,   inf] (283), 
length of domains: 69280
Total time: 2.0379	 pickout: 0.2286	 decision: 0.2499	 get_bound: 1.0202	 add_domain: 0.5392
Current lb:-0.06584525108337402
296512 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 331.79844188690186

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 118] [4, 118] [4, 118] [4, 118] [4, 118] [4, 118] [4, 118] [4, 118] [4, 118] [4, 118] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 36.53777313232422 with beta sum per layer: [78.06700134277344, 334.24444580078125, 304.91790771484375, 486.561767578125, 565.433837890625]
alpha/beta optimization time: 0.4031064510345459
This batch time : update_bounds func: 0.9896	 prepare: 0.3473	 bound: 0.4036	 transfer: 0.0231	 finalize: 0.2091
Accumulated time: update_bounds func: 170.8594	 prepare: 50.5560	 bound: 63.0293	 transfer: 0.0231	 finalize: 51.5050
batch bounding time:  0.991828441619873
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (285), [-0.06585,   inf] (285), [-0.06585,   inf] (285), [-0.06585,   inf] (285), [-0.06585,   inf] (285), [-0.06585,   inf] (285), [-0.06585,   inf] (285), [-0.06585,   inf] (285), [-0.06584,   inf] (285), [-0.06584,   inf] (285), [-0.06584,   inf] (285), [-0.06584,   inf] (285), [-0.06584,   inf] (285), [-0.06584,   inf] (285), [-0.06584,   inf] (285), [-0.06584,   inf] (285), [-0.06584,   inf] (285), [-0.06584,   inf] (285), [-0.06584,   inf] (285), [-0.06584,   inf] (285), 
length of domains: 69460
Total time: 4.6803	 pickout: 0.2287	 decision: 2.9344	 get_bound: 0.9955	 add_domain: 0.5216
Current lb:-0.06584525108337402
298560 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 336.54002022743225

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 47] [4, 54] [4, 54] [4, 54] [4, 54] [4, 54] [4, 54] [4, 54] [0, 47] [4, 54] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 40.498939514160156 with beta sum per layer: [114.19049072265625, 304.9508056640625, 284.6172790527344, 425.8982238769531, 606.7315063476562]
alpha/beta optimization time: 0.4038400650024414
This batch time : update_bounds func: 1.0146	 prepare: 0.3739	 bound: 0.4044	 transfer: 0.0230	 finalize: 0.2066
Accumulated time: update_bounds func: 171.8741	 prepare: 50.9299	 bound: 63.4337	 transfer: 0.0230	 finalize: 51.7116
batch bounding time:  1.0169181823730469
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (287), [-0.06585,   inf] (287), [-0.06585,   inf] (287), [-0.06585,   inf] (287), [-0.06585,   inf] (287), [-0.06585,   inf] (287), [-0.06585,   inf] (287), [-0.06585,   inf] (287), [-0.06584,   inf] (287), [-0.06584,   inf] (287), [-0.06584,   inf] (287), [-0.06584,   inf] (287), [-0.06584,   inf] (287), [-0.06584,   inf] (287), [-0.06584,   inf] (287), [-0.06584,   inf] (287), [-0.06584,   inf] (287), [-0.06584,   inf] (287), [-0.06584,   inf] (287), [-0.06584,   inf] (287), 
length of domains: 69756
Total time: 2.0811	 pickout: 0.2297	 decision: 0.2558	 get_bound: 1.0206	 add_domain: 0.5749
Current lb:-0.06584525108337402
300608 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 338.680388212204

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 54] [4, 60] [4, 60] [4, 60] [4, 60] [4, 60] [4, 60] [4, 60] [4, 54] [4, 60] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 51.14033889770508 with beta sum per layer: [78.65022277832031, 385.30499267578125, 349.99432373046875, 444.58453369140625, 623.0612182617188]
alpha/beta optimization time: 0.40457606315612793
This batch time : update_bounds func: 0.9909	 prepare: 0.3468	 bound: 0.4051	 transfer: 0.0231	 finalize: 0.2099
Accumulated time: update_bounds func: 172.8649	 prepare: 51.2767	 bound: 63.8388	 transfer: 0.0231	 finalize: 51.9215
batch bounding time:  0.9931299686431885
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (289), [-0.06585,   inf] (289), [-0.06585,   inf] (289), [-0.06585,   inf] (289), [-0.06585,   inf] (289), [-0.06585,   inf] (289), [-0.06585,   inf] (289), [-0.06585,   inf] (289), [-0.06584,   inf] (289), [-0.06584,   inf] (289), [-0.06584,   inf] (289), [-0.06584,   inf] (289), [-0.06584,   inf] (289), [-0.06584,   inf] (289), [-0.06584,   inf] (289), [-0.06584,   inf] (289), [-0.06584,   inf] (289), [-0.06584,   inf] (289), [-0.06584,   inf] (289), [-0.06584,   inf] (289), 
length of domains: 70195
Total time: 2.1117	 pickout: 0.2281	 decision: 0.2496	 get_bound: 0.9968	 add_domain: 0.6373
Current lb:-0.06584525108337402
302656 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 340.8493115901947

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 60] [0, 47] [0, 47] [0, 47] [0, 47] [0, 47] [0, 47] [0, 47] [4, 60] [0, 47] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 40.46278381347656 with beta sum per layer: [123.6220474243164, 325.05682373046875, 422.6943359375, 386.65728759765625, 527.9987182617188]
alpha/beta optimization time: 0.40262818336486816
This batch time : update_bounds func: 0.9869	 prepare: 0.3456	 bound: 0.4031	 transfer: 0.0220	 finalize: 0.2099
Accumulated time: update_bounds func: 173.8518	 prepare: 51.6223	 bound: 64.2419	 transfer: 0.0220	 finalize: 52.1314
batch bounding time:  0.9893724918365479
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (291), [-0.06585,   inf] (291), [-0.06585,   inf] (291), [-0.06585,   inf] (291), [-0.06585,   inf] (291), [-0.06585,   inf] (291), [-0.06585,   inf] (291), [-0.06585,   inf] (291), [-0.06584,   inf] (291), [-0.06584,   inf] (291), [-0.06584,   inf] (291), [-0.06584,   inf] (291), [-0.06584,   inf] (291), [-0.06584,   inf] (291), [-0.06584,   inf] (291), [-0.06584,   inf] (291), [-0.06584,   inf] (291), [-0.06584,   inf] (291), [-0.06584,   inf] (291), [-0.06584,   inf] (291), 
length of domains: 70565
Total time: 2.0811	 pickout: 0.2263	 decision: 0.2485	 get_bound: 0.9933	 add_domain: 0.6131
Current lb:-0.06584525108337402
304704 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 342.9875679016113

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 53] [2, 53] [2, 53] [2, 53] [2, 53] [2, 53] [2, 53] [2, 53] [2, 53] [2, 53] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 35.94506072998047 with beta sum per layer: [145.35748291015625, 317.94647216796875, 525.6470947265625, 429.7470703125, 438.74627685546875]
alpha/beta optimization time: 0.40071725845336914
This batch time : update_bounds func: 0.9829	 prepare: 0.3451	 bound: 0.4012	 transfer: 0.0232	 finalize: 0.2075
Accumulated time: update_bounds func: 174.8348	 prepare: 51.9674	 bound: 64.6431	 transfer: 0.0232	 finalize: 52.3389
batch bounding time:  0.9851663112640381
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (293), [-0.06585,   inf] (293), [-0.06585,   inf] (293), [-0.06585,   inf] (293), [-0.06585,   inf] (293), [-0.06585,   inf] (293), [-0.06585,   inf] (293), [-0.06585,   inf] (293), [-0.06584,   inf] (293), [-0.06584,   inf] (293), [-0.06584,   inf] (293), [-0.06584,   inf] (293), [-0.06584,   inf] (293), [-0.06584,   inf] (293), [-0.06584,   inf] (293), [-0.06584,   inf] (293), [-0.06584,   inf] (293), [-0.06584,   inf] (293), [-0.06584,   inf] (293), [-0.06584,   inf] (293), 
length of domains: 70841
Total time: 2.0338	 pickout: 0.2225	 decision: 0.2472	 get_bound: 0.9889	 add_domain: 0.5752
Current lb:-0.06584525108337402
306752 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 345.0862548351288

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 192] [3, 192] [3, 192] [3, 192] [3, 192] [3, 192] [3, 192] [3, 192] [3, 192] [3, 192] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 40.161537170410156 with beta sum per layer: [99.60981750488281, 315.18438720703125, 397.834228515625, 475.466796875, 472.43701171875]
alpha/beta optimization time: 0.4003598690032959
This batch time : update_bounds func: 3.6410	 prepare: 0.3412	 bound: 0.4009	 transfer: 0.0233	 finalize: 2.8696
Accumulated time: update_bounds func: 178.4758	 prepare: 52.3086	 bound: 65.0439	 transfer: 0.0233	 finalize: 55.2085
batch bounding time:  3.643648147583008
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (295), [-0.06585,   inf] (295), [-0.06585,   inf] (295), [-0.06585,   inf] (295), [-0.06585,   inf] (295), [-0.06585,   inf] (295), [-0.06585,   inf] (295), [-0.06585,   inf] (295), [-0.06584,   inf] (295), [-0.06584,   inf] (295), [-0.06584,   inf] (295), [-0.06584,   inf] (295), [-0.06584,   inf] (295), [-0.06584,   inf] (295), [-0.06584,   inf] (295), [-0.06584,   inf] (295), [-0.06584,   inf] (295), [-0.06584,   inf] (295), [-0.06584,   inf] (295), [-0.06584,   inf] (295), 
length of domains: 71020
Total time: 4.6519	 pickout: 0.2259	 decision: 0.2459	 get_bound: 3.6475	 add_domain: 0.5325
Current lb:-0.06584525108337402
308800 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 349.8032822608948

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 15] [4, 15] [4, 15] [4, 15] [4, 15] [4, 15] [4, 15] [4, 15] [4, 15] [4, 15] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 30.396699905395508 with beta sum per layer: [155.55490112304688, 311.30450439453125, 368.4428405761719, 443.176025390625, 441.2939453125]
alpha/beta optimization time: 0.4074058532714844
This batch time : update_bounds func: 1.0163	 prepare: 0.3727	 bound: 0.4079	 transfer: 0.0232	 finalize: 0.2060
Accumulated time: update_bounds func: 179.4921	 prepare: 52.6812	 bound: 65.4519	 transfer: 0.0232	 finalize: 55.4145
batch bounding time:  1.0186727046966553
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (297), [-0.06585,   inf] (297), [-0.06585,   inf] (297), [-0.06585,   inf] (297), [-0.06585,   inf] (297), [-0.06585,   inf] (297), [-0.06585,   inf] (297), [-0.06585,   inf] (297), [-0.06584,   inf] (297), [-0.06584,   inf] (297), [-0.06584,   inf] (297), [-0.06584,   inf] (297), [-0.06584,   inf] (297), [-0.06584,   inf] (297), [-0.06584,   inf] (297), [-0.06584,   inf] (297), [-0.06584,   inf] (297), [-0.06584,   inf] (297), [-0.06584,   inf] (297), [-0.06584,   inf] (297), 
length of domains: 71116
Total time: 2.0115	 pickout: 0.2379	 decision: 0.2510	 get_bound: 1.0225	 add_domain: 0.5002
Current lb:-0.06584525108337402
310848 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 351.8824505805969

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 120] [2, 120] [2, 120] [2, 120] [2, 120] [2, 120] [2, 120] [2, 120] [2, 120] [2, 120] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 31.6796932220459 with beta sum per layer: [125.89055633544922, 371.7364807128906, 396.0553894042969, 493.16583251953125, 451.5924072265625]
alpha/beta optimization time: 0.4089691638946533
This batch time : update_bounds func: 0.9960	 prepare: 0.3515	 bound: 0.4095	 transfer: 0.0231	 finalize: 0.2053
Accumulated time: update_bounds func: 180.4881	 prepare: 53.0328	 bound: 65.8614	 transfer: 0.0231	 finalize: 55.6198
batch bounding time:  0.9984185695648193
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (299), [-0.06585,   inf] (299), [-0.06585,   inf] (299), [-0.06585,   inf] (299), [-0.06585,   inf] (299), [-0.06585,   inf] (299), [-0.06585,   inf] (299), [-0.06585,   inf] (299), [-0.06584,   inf] (299), [-0.06584,   inf] (299), [-0.06584,   inf] (299), [-0.06584,   inf] (299), [-0.06584,   inf] (299), [-0.06584,   inf] (299), [-0.06584,   inf] (299), [-0.06584,   inf] (299), [-0.06584,   inf] (299), [-0.06584,   inf] (299), [-0.06584,   inf] (299), [-0.06584,   inf] (299), 
length of domains: 71210
Total time: 1.9956	 pickout: 0.2318	 decision: 0.2589	 get_bound: 1.0021	 add_domain: 0.5028
Current lb:-0.06584525108337402
312896 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 353.94616174697876

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 58] [0, 58] [0, 58] [0, 58] [0, 58] [0, 58] [0, 58] [0, 58] [0, 58] [0, 58] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 26.669445037841797 with beta sum per layer: [150.3025360107422, 325.9933776855469, 428.0830993652344, 466.3558044433594, 443.5898132324219]
alpha/beta optimization time: 0.406402587890625
This batch time : update_bounds func: 0.9959	 prepare: 0.3513	 bound: 0.4069	 transfer: 0.0222	 finalize: 0.2090
Accumulated time: update_bounds func: 181.4839	 prepare: 53.3841	 bound: 66.2683	 transfer: 0.0222	 finalize: 55.8289
batch bounding time:  0.9980792999267578
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (301), [-0.06585,   inf] (301), [-0.06585,   inf] (301), [-0.06585,   inf] (301), [-0.06585,   inf] (301), [-0.06585,   inf] (301), [-0.06585,   inf] (301), [-0.06585,   inf] (301), [-0.06584,   inf] (301), [-0.06584,   inf] (301), [-0.06584,   inf] (301), [-0.06584,   inf] (301), [-0.06584,   inf] (301), [-0.06584,   inf] (301), [-0.06584,   inf] (301), [-0.06584,   inf] (301), [-0.06584,   inf] (301), [-0.06584,   inf] (301), [-0.06584,   inf] (301), [-0.06584,   inf] (301), 
length of domains: 71361
Total time: 2.0270	 pickout: 0.2349	 decision: 0.2587	 get_bound: 1.0017	 add_domain: 0.5318
Current lb:-0.06584525108337402
314944 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 356.04202485084534

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 58] [3, 58] [3, 58] [3, 58] [3, 58] [3, 58] [3, 58] [3, 58] [3, 58] [3, 58] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 32.0501823425293 with beta sum per layer: [139.18019104003906, 319.128173828125, 310.28546142578125, 658.042724609375, 477.24249267578125]
alpha/beta optimization time: 0.40065479278564453
This batch time : update_bounds func: 0.9805	 prepare: 0.3447	 bound: 0.4012	 transfer: 0.0219	 finalize: 0.2063
Accumulated time: update_bounds func: 182.4645	 prepare: 53.7288	 bound: 66.6694	 transfer: 0.0219	 finalize: 56.0352
batch bounding time:  0.982757568359375
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (303), [-0.06585,   inf] (303), [-0.06585,   inf] (303), [-0.06585,   inf] (303), [-0.06585,   inf] (303), [-0.06585,   inf] (303), [-0.06585,   inf] (303), [-0.06585,   inf] (303), [-0.06584,   inf] (303), [-0.06584,   inf] (303), [-0.06584,   inf] (303), [-0.06584,   inf] (303), [-0.06584,   inf] (303), [-0.06584,   inf] (303), [-0.06584,   inf] (303), [-0.06584,   inf] (303), [-0.06584,   inf] (303), [-0.06584,   inf] (303), [-0.06584,   inf] (303), [-0.06584,   inf] (303), 
length of domains: 71436
Total time: 1.9706	 pickout: 0.2291	 decision: 0.2506	 get_bound: 0.9864	 add_domain: 0.5045
Current lb:-0.06584525108337402
316992 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 358.0798804759979

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 109] [4, 109] [4, 109] [4, 109] [4, 109] [4, 109] [4, 109] [4, 109] [4, 109] [4, 109] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 44.63935852050781 with beta sum per layer: [107.40583801269531, 310.2958984375, 347.75946044921875, 539.884765625, 437.142578125]
alpha/beta optimization time: 0.41240382194519043
This batch time : update_bounds func: 1.0166	 prepare: 0.3640	 bound: 0.4130	 transfer: 0.0232	 finalize: 0.2102
Accumulated time: update_bounds func: 183.4811	 prepare: 54.0928	 bound: 67.0824	 transfer: 0.0232	 finalize: 56.2455
batch bounding time:  1.0191857814788818
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (305), [-0.06585,   inf] (305), [-0.06585,   inf] (305), [-0.06585,   inf] (305), [-0.06585,   inf] (305), [-0.06585,   inf] (305), [-0.06585,   inf] (305), [-0.06585,   inf] (305), [-0.06584,   inf] (305), [-0.06584,   inf] (305), [-0.06584,   inf] (305), [-0.06584,   inf] (305), [-0.06584,   inf] (305), [-0.06584,   inf] (305), [-0.06584,   inf] (305), [-0.06584,   inf] (305), [-0.06584,   inf] (305), [-0.06584,   inf] (305), [-0.06584,   inf] (305), [-0.06584,   inf] (305), 
length of domains: 71808
Total time: 2.1431	 pickout: 0.2299	 decision: 0.2467	 get_bound: 1.0230	 add_domain: 0.6434
Current lb:-0.06584525108337402
319040 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 360.29049944877625

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 107] [1, 107] [1, 107] [1, 107] [1, 107] [1, 107] [1, 107] [1, 107] [1, 107] [1, 107] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 38.5849723815918 with beta sum per layer: [81.51760864257812, 419.6311950683594, 517.992431640625, 661.543701171875, 311.4542236328125]
alpha/beta optimization time: 0.3997964859008789
This batch time : update_bounds func: 3.6605	 prepare: 0.3656	 bound: 0.4003	 transfer: 0.0222	 finalize: 0.2047
Accumulated time: update_bounds func: 187.1415	 prepare: 54.4583	 bound: 67.4827	 transfer: 0.0222	 finalize: 56.4502
batch bounding time:  3.662663698196411
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (307), [-0.06585,   inf] (307), [-0.06585,   inf] (307), [-0.06585,   inf] (307), [-0.06585,   inf] (307), [-0.06585,   inf] (307), [-0.06585,   inf] (307), [-0.06585,   inf] (307), [-0.06584,   inf] (307), [-0.06584,   inf] (307), [-0.06584,   inf] (307), [-0.06584,   inf] (307), [-0.06584,   inf] (307), [-0.06584,   inf] (307), [-0.06584,   inf] (307), [-0.06584,   inf] (307), [-0.06584,   inf] (307), [-0.06584,   inf] (307), [-0.06584,   inf] (307), [-0.06584,   inf] (307), 
length of domains: 72128
Total time: 4.7906	 pickout: 0.2371	 decision: 0.2575	 get_bound: 3.6663	 add_domain: 0.6297
Current lb:-0.06584525108337402
321088 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 365.14452362060547

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 112] [2, 112] [2, 112] [2, 112] [2, 112] [2, 112] [2, 112] [2, 112] [2, 112] [2, 112] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 40.79142379760742 with beta sum per layer: [86.0816421508789, 445.595703125, 519.1693115234375, 654.1632080078125, 311.5618591308594]
alpha/beta optimization time: 0.40585827827453613
This batch time : update_bounds func: 1.0089	 prepare: 0.3655	 bound: 0.4064	 transfer: 0.0231	 finalize: 0.2077
Accumulated time: update_bounds func: 188.1505	 prepare: 54.8238	 bound: 67.8891	 transfer: 0.0231	 finalize: 56.6579
batch bounding time:  1.0112543106079102
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (309), [-0.06585,   inf] (309), [-0.06585,   inf] (309), [-0.06585,   inf] (309), [-0.06585,   inf] (309), [-0.06585,   inf] (309), [-0.06585,   inf] (309), [-0.06585,   inf] (309), [-0.06584,   inf] (309), [-0.06584,   inf] (309), [-0.06584,   inf] (309), [-0.06584,   inf] (309), [-0.06584,   inf] (309), [-0.06584,   inf] (309), [-0.06584,   inf] (309), [-0.06584,   inf] (309), [-0.06584,   inf] (309), [-0.06584,   inf] (309), [-0.06584,   inf] (309), [-0.06584,   inf] (309), 
length of domains: 72396
Total time: 2.1029	 pickout: 0.2368	 decision: 0.2456	 get_bound: 1.0148	 add_domain: 0.6056
Current lb:-0.06584525108337402
323136 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 367.3099603652954

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 122] [2, 122] [2, 122] [2, 122] [2, 122] [2, 122] [2, 122] [2, 122] [2, 122] [2, 122] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 41.63283920288086 with beta sum per layer: [67.2105712890625, 454.3981018066406, 631.8065795898438, 511.872802734375, 313.53277587890625]
alpha/beta optimization time: 0.4049091339111328
This batch time : update_bounds func: 0.9930	 prepare: 0.3534	 bound: 0.4054	 transfer: 0.0232	 finalize: 0.2041
Accumulated time: update_bounds func: 189.1435	 prepare: 55.1773	 bound: 68.2945	 transfer: 0.0232	 finalize: 56.8620
batch bounding time:  0.9953582286834717
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (311), [-0.06585,   inf] (311), [-0.06585,   inf] (311), [-0.06585,   inf] (311), [-0.06585,   inf] (311), [-0.06585,   inf] (311), [-0.06585,   inf] (311), [-0.06585,   inf] (311), [-0.06584,   inf] (311), [-0.06584,   inf] (311), [-0.06584,   inf] (311), [-0.06584,   inf] (311), [-0.06584,   inf] (311), [-0.06584,   inf] (311), [-0.06584,   inf] (311), [-0.06584,   inf] (311), [-0.06584,   inf] (311), [-0.06584,   inf] (311), [-0.06584,   inf] (311), [-0.06584,   inf] (311), 
length of domains: 72792
Total time: 2.1504	 pickout: 0.2313	 decision: 0.2514	 get_bound: 0.9989	 add_domain: 0.6689
Current lb:-0.06584525108337402
325184 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 369.5199122428894

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 14] [2, 14] [2, 14] [2, 14] [2, 14] [2, 14] [2, 14] [4, 59] [2, 14] [2, 14] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 24.261367797851562 with beta sum per layer: [52.406272888183594, 390.2537841796875, 564.87939453125, 428.56982421875, 414.7416687011719]
alpha/beta optimization time: 0.4010293483734131
This batch time : update_bounds func: 0.9814	 prepare: 0.3455	 bound: 0.4016	 transfer: 0.0230	 finalize: 0.2047
Accumulated time: update_bounds func: 190.1249	 prepare: 55.5228	 bound: 68.6961	 transfer: 0.0230	 finalize: 57.0667
batch bounding time:  0.9836127758026123
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (313), [-0.06585,   inf] (313), [-0.06585,   inf] (313), [-0.06585,   inf] (313), [-0.06585,   inf] (313), [-0.06585,   inf] (313), [-0.06585,   inf] (313), [-0.06585,   inf] (313), [-0.06584,   inf] (313), [-0.06584,   inf] (313), [-0.06584,   inf] (313), [-0.06584,   inf] (313), [-0.06584,   inf] (313), [-0.06584,   inf] (313), [-0.06584,   inf] (313), [-0.06584,   inf] (313), [-0.06584,   inf] (313), [-0.06584,   inf] (313), [-0.06584,   inf] (313), [-0.06584,   inf] (313), 
length of domains: 73169
Total time: 2.1253	 pickout: 0.2302	 decision: 0.2473	 get_bound: 0.9871	 add_domain: 0.6607
Current lb:-0.06584525108337402
327232 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 371.7106750011444

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 59] [4, 59] [4, 59] [4, 59] [4, 59] [4, 59] [4, 59] [2, 14] [4, 59] [4, 59] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 34.169742584228516 with beta sum per layer: [51.03731155395508, 394.087158203125, 442.75885009765625, 492.5013427734375, 550.9000244140625]
alpha/beta optimization time: 0.3984415531158447
This batch time : update_bounds func: 0.9905	 prepare: 0.3559	 bound: 0.3989	 transfer: 0.0232	 finalize: 0.2062
Accumulated time: update_bounds func: 191.1155	 prepare: 55.8787	 bound: 69.0950	 transfer: 0.0232	 finalize: 57.2729
batch bounding time:  0.992725133895874
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (315), [-0.06585,   inf] (315), [-0.06585,   inf] (315), [-0.06585,   inf] (315), [-0.06585,   inf] (315), [-0.06585,   inf] (315), [-0.06585,   inf] (315), [-0.06585,   inf] (315), [-0.06584,   inf] (315), [-0.06584,   inf] (315), [-0.06584,   inf] (315), [-0.06584,   inf] (315), [-0.06584,   inf] (315), [-0.06584,   inf] (315), [-0.06584,   inf] (315), [-0.06584,   inf] (315), [-0.06584,   inf] (315), [-0.06584,   inf] (315), [-0.06584,   inf] (315), [-0.06584,   inf] (315), 
length of domains: 73539
Total time: 2.1342	 pickout: 0.2289	 decision: 0.2470	 get_bound: 0.9963	 add_domain: 0.6620
Current lb:-0.06584525108337402
329280 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 373.9044666290283

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 77] [3, 44] [3, 44] [1, 77] [1, 77] [1, 77] [3, 44] [1, 77] [1, 77] [1, 77] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 55.33379364013672 with beta sum per layer: [46.105979919433594, 375.4072265625, 450.954345703125, 558.8512573242188, 593.802001953125]
alpha/beta optimization time: 0.39860081672668457
This batch time : update_bounds func: 0.9861	 prepare: 0.3540	 bound: 0.3991	 transfer: 0.0231	 finalize: 0.2039
Accumulated time: update_bounds func: 192.1016	 prepare: 56.2327	 bound: 69.4941	 transfer: 0.0231	 finalize: 57.4768
batch bounding time:  0.9883241653442383
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (317), [-0.06585,   inf] (317), [-0.06585,   inf] (317), [-0.06585,   inf] (317), [-0.06585,   inf] (317), [-0.06585,   inf] (317), [-0.06585,   inf] (317), [-0.06585,   inf] (317), [-0.06585,   inf] (317), [-0.06584,   inf] (317), [-0.06584,   inf] (317), [-0.06584,   inf] (317), [-0.06584,   inf] (317), [-0.06584,   inf] (317), [-0.06584,   inf] (317), [-0.06584,   inf] (317), [-0.06584,   inf] (317), [-0.06584,   inf] (317), [-0.06584,   inf] (317), [-0.06584,   inf] (317), 
length of domains: 73975
Total time: 2.1613	 pickout: 0.2292	 decision: 0.2447	 get_bound: 0.9919	 add_domain: 0.6955
Current lb:-0.06584525108337402
331328 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 376.1233093738556

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 44] [1, 138] [1, 77] [3, 44] [3, 44] [3, 44] [1, 77] [2, 72] [3, 44] [3, 44] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 57.24327087402344 with beta sum per layer: [50.88319778442383, 380.0316162109375, 493.7176513671875, 638.6630859375, 612.03955078125]
alpha/beta optimization time: 0.404188871383667
This batch time : update_bounds func: 0.9804	 prepare: 0.3414	 bound: 0.4047	 transfer: 0.0231	 finalize: 0.2048
Accumulated time: update_bounds func: 193.0819	 prepare: 56.5742	 bound: 69.8988	 transfer: 0.0231	 finalize: 57.6815
batch bounding time:  0.982661247253418
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (319), [-0.06585,   inf] (319), [-0.06585,   inf] (319), [-0.06585,   inf] (319), [-0.06585,   inf] (319), [-0.06585,   inf] (319), [-0.06585,   inf] (319), [-0.06584,   inf] (319), [-0.06584,   inf] (319), [-0.06584,   inf] (319), [-0.06584,   inf] (319), [-0.06584,   inf] (319), [-0.06584,   inf] (319), [-0.06584,   inf] (319), [-0.06584,   inf] (319), [-0.06584,   inf] (319), [-0.06584,   inf] (319), [-0.06584,   inf] (319), [-0.06584,   inf] (319), [-0.06584,   inf] (319), 
length of domains: 74431
Total time: 4.9266	 pickout: 0.2215	 decision: 3.0074	 get_bound: 0.9863	 add_domain: 0.7113
Current lb:-0.06584525108337402
333376 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 381.1222324371338

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 63] [4, 63] [4, 63] [2, 72] [4, 63] [1, 138] [1, 138] [4, 63] [1, 138] [4, 63] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 57.00630187988281 with beta sum per layer: [49.23560333251953, 396.4048767089844, 585.4981689453125, 685.1289672851562, 631.7096557617188]
alpha/beta optimization time: 0.4019618034362793
This batch time : update_bounds func: 0.9778	 prepare: 0.3426	 bound: 0.4025	 transfer: 0.0220	 finalize: 0.2043
Accumulated time: update_bounds func: 194.0598	 prepare: 56.9168	 bound: 70.3013	 transfer: 0.0220	 finalize: 57.8859
batch bounding time:  0.9801816940307617
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (321), [-0.06585,   inf] (321), [-0.06585,   inf] (321), [-0.06585,   inf] (321), [-0.06584,   inf] (321), [-0.06584,   inf] (321), [-0.06584,   inf] (321), [-0.06584,   inf] (321), [-0.06584,   inf] (321), [-0.06584,   inf] (321), [-0.06584,   inf] (321), [-0.06584,   inf] (321), [-0.06584,   inf] (321), [-0.06584,   inf] (321), [-0.06584,   inf] (321), [-0.06584,   inf] (321), [-0.06584,   inf] (321), [-0.06584,   inf] (321), [-0.06584,   inf] (321), [-0.06584,   inf] (321), 
length of domains: 74898
Total time: 2.2116	 pickout: 0.2262	 decision: 0.2658	 get_bound: 0.9839	 add_domain: 0.7357
Current lb:-0.06584525108337402
335424 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 383.39293122291565

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 152] [4, 152] [4, 152] [4, 152] [4, 152] [4, 152] [4, 152] [4, 152] [4, 152] [4, 152] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 55.99296188354492 with beta sum per layer: [57.35184860229492, 388.93927001953125, 573.8997802734375, 627.0631103515625, 598.3345947265625]
alpha/beta optimization time: 0.39902591705322266
This batch time : update_bounds func: 0.9706	 prepare: 0.3393	 bound: 0.3995	 transfer: 0.0231	 finalize: 0.2021
Accumulated time: update_bounds func: 195.0304	 prepare: 57.2561	 bound: 70.7008	 transfer: 0.0231	 finalize: 58.0880
batch bounding time:  0.9732980728149414
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (323), [-0.06585,   inf] (323), [-0.06585,   inf] (323), [-0.06585,   inf] (323), [-0.06584,   inf] (323), [-0.06584,   inf] (323), [-0.06584,   inf] (323), [-0.06584,   inf] (323), [-0.06584,   inf] (323), [-0.06584,   inf] (323), [-0.06584,   inf] (323), [-0.06584,   inf] (323), [-0.06584,   inf] (323), [-0.06584,   inf] (323), [-0.06584,   inf] (323), [-0.06584,   inf] (323), [-0.06584,   inf] (323), [-0.06584,   inf] (323), [-0.06584,   inf] (323), [-0.06584,   inf] (323), 
length of domains: 75328
Total time: 2.1890	 pickout: 0.2332	 decision: 0.2720	 get_bound: 0.9773	 add_domain: 0.7065
Current lb:-0.06584525108337402
337472 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 385.6436460018158

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 42] [1, 52] [2, 72] [2, 72] [0, 42] [2, 72] [2, 72] [0, 42] [1, 52] [1, 52] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 70.87123107910156 with beta sum per layer: [57.00598907470703, 391.2146911621094, 522.067626953125, 653.5774536132812, 666.93212890625]
alpha/beta optimization time: 0.39899754524230957
This batch time : update_bounds func: 0.9653	 prepare: 0.3331	 bound: 0.3995	 transfer: 0.0221	 finalize: 0.2041
Accumulated time: update_bounds func: 195.9957	 prepare: 57.5892	 bound: 71.1003	 transfer: 0.0221	 finalize: 58.2920
batch bounding time:  0.9677078723907471
Current worst splitting domains [lb, ub] (depth):
[-0.06585,   inf] (325), [-0.06584,   inf] (325), [-0.06584,   inf] (325), [-0.06584,   inf] (325), [-0.06584,   inf] (325), [-0.06584,   inf] (325), [-0.06584,   inf] (325), [-0.06583,   inf] (325), [-0.06583,   inf] (325), [-0.06583,   inf] (325), [-0.06583,   inf] (325), [-0.06583,   inf] (325), [-0.06583,   inf] (325), [-0.06583,   inf] (325), [-0.06583,   inf] (325), [-0.06583,   inf] (325), [-0.06583,   inf] (325), [-0.06583,   inf] (325), [-0.06582,   inf] (325), [-0.06582,   inf] (325), 
length of domains: 75960
Total time: 2.2971	 pickout: 0.2309	 decision: 0.2817	 get_bound: 0.9734	 add_domain: 0.8110
Current lb:-0.06584525108337402
339520 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 388.0005557537079

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 138] [1, 138] [0, 42] [2, 72] [0, 42] [0, 42] [2, 85] [1, 52] [0, 42] [0, 42] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 69.47732543945312 with beta sum per layer: [57.42084503173828, 401.516845703125, 504.20489501953125, 606.7723388671875, 732.755859375]
alpha/beta optimization time: 0.39982151985168457
This batch time : update_bounds func: 0.9919	 prepare: 0.3495	 bound: 0.4003	 transfer: 0.0231	 finalize: 0.2129
Accumulated time: update_bounds func: 196.9876	 prepare: 57.9387	 bound: 71.5006	 transfer: 0.0231	 finalize: 58.5049
batch bounding time:  0.9941151142120361
Current worst splitting domains [lb, ub] (depth):
[-0.06583,   inf] (327), [-0.06583,   inf] (327), [-0.06583,   inf] (327), [-0.06583,   inf] (327), [-0.06583,   inf] (327), [-0.06583,   inf] (327), [-0.06583,   inf] (327), [-0.06582,   inf] (327), [-0.06582,   inf] (327), [-0.06582,   inf] (327), [-0.06581,   inf] (327), [-0.06581,   inf] (327), [-0.06581,   inf] (327), [-0.06580,   inf] (327), [-0.06579,   inf] (327), [-0.06579,   inf] (327), [-0.06579,   inf] (327), [-0.06577,   inf] (327), [-0.06574,   inf] (327), [-0.06574,   inf] (327), 
length of domains: 76501
Total time: 2.2937	 pickout: 0.2304	 decision: 0.2832	 get_bound: 0.9980	 add_domain: 0.7821
Current lb:-0.06583213806152344
341568 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 390.35209584236145

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 42] [0, 42] [1, 52] [0, 42] [2, 85] [0, 42] [0, 42] [1, 138] [2, 73] [2, 73] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 58.35700607299805 with beta sum per layer: [68.62269592285156, 498.6259460449219, 601.3804321289062, 640.7644653320312, 602.129150390625]
alpha/beta optimization time: 0.3962984085083008
This batch time : update_bounds func: 3.9598	 prepare: 0.3394	 bound: 0.3968	 transfer: 0.0221	 finalize: 3.1948
Accumulated time: update_bounds func: 200.9474	 prepare: 58.2780	 bound: 71.8974	 transfer: 0.0221	 finalize: 61.6997
batch bounding time:  3.962627410888672
Current worst splitting domains [lb, ub] (depth):
[-0.06583,   inf] (329), [-0.06583,   inf] (329), [-0.06582,   inf] (329), [-0.06582,   inf] (329), [-0.06581,   inf] (329), [-0.06581,   inf] (329), [-0.06579,   inf] (329), [-0.06579,   inf] (329), [-0.06579,   inf] (329), [-0.06575,   inf] (329), [-0.06574,   inf] (329), [-0.06571,   inf] (329), [-0.06571,   inf] (329), [-0.06570,   inf] (329), [-0.06570,   inf] (329), [-0.06570,   inf] (329), [-0.06570,   inf] (329), [-0.06569,   inf] (329), [-0.06569,   inf] (329), [-0.06569,   inf] (329), 
length of domains: 76908
Total time: 5.2025	 pickout: 0.2319	 decision: 0.2992	 get_bound: 3.9667	 add_domain: 0.7047
Current lb:-0.06583058834075928
343616 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 395.619754076004

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 138] [0, 42] [1, 52] [0, 42] [2, 187] [0, 42] [1, 138] [2, 73] [2, 85] [1, 166] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 47.4000244140625 with beta sum per layer: [73.64396667480469, 570.3382568359375, 592.8453979492188, 578.0759887695312, 425.63671875]
alpha/beta optimization time: 0.4011044502258301
This batch time : update_bounds func: 0.9700	 prepare: 0.3389	 bound: 0.4016	 transfer: 0.0232	 finalize: 0.2000
Accumulated time: update_bounds func: 201.9174	 prepare: 58.6169	 bound: 72.2990	 transfer: 0.0232	 finalize: 61.8997
batch bounding time:  0.9723548889160156
Current worst splitting domains [lb, ub] (depth):
[-0.06582,   inf] (331), [-0.06581,   inf] (331), [-0.06581,   inf] (331), [-0.06579,   inf] (331), [-0.06579,   inf] (331), [-0.06574,   inf] (331), [-0.06573,   inf] (331), [-0.06570,   inf] (331), [-0.06569,   inf] (331), [-0.06569,   inf] (331), [-0.06569,   inf] (331), [-0.06569,   inf] (331), [-0.06568,   inf] (331), [-0.06568,   inf] (331), [-0.06566,   inf] (331), [-0.06565,   inf] (331), [-0.06561,   inf] (331), [-0.06549,   inf] (331), [-0.06548,   inf] (331), [-0.06548,   inf] (331), 
length of domains: 77259
Total time: 2.1870	 pickout: 0.2243	 decision: 0.3098	 get_bound: 0.9760	 add_domain: 0.6768
Current lb:-0.06581652164459229
345664 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 397.8665165901184

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 138] [0, 42] [2, 194] [2, 187] [0, 42] [0, 42] [0, 42] [2, 187] [0, 42] [1, 138] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 58.992916107177734 with beta sum per layer: [78.01349639892578, 598.529052734375, 674.485595703125, 648.5228271484375, 384.2828369140625]
alpha/beta optimization time: 0.3983042240142822
This batch time : update_bounds func: 0.9679	 prepare: 0.3374	 bound: 0.3988	 transfer: 0.0230	 finalize: 0.2025
Accumulated time: update_bounds func: 202.8853	 prepare: 58.9543	 bound: 72.6978	 transfer: 0.0230	 finalize: 62.1022
batch bounding time:  0.970205545425415
Current worst splitting domains [lb, ub] (depth):
[-0.06581,   inf] (333), [-0.06579,   inf] (333), [-0.06570,   inf] (333), [-0.06569,   inf] (333), [-0.06568,   inf] (333), [-0.06566,   inf] (333), [-0.06563,   inf] (333), [-0.06561,   inf] (333), [-0.06561,   inf] (333), [-0.06548,   inf] (333), [-0.06548,   inf] (333), [-0.06548,   inf] (333), [-0.06548,   inf] (333), [-0.06548,   inf] (333), [-0.06548,   inf] (333), [-0.06548,   inf] (333), [-0.06548,   inf] (333), [-0.06547,   inf] (333), [-0.06547,   inf] (333), [-0.06547,   inf] (333), 
length of domains: 77712
Total time: 2.2714	 pickout: 0.2255	 decision: 0.3424	 get_bound: 0.9739	 add_domain: 0.7296
Current lb:-0.0658092200756073
347712 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 400.20253825187683

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 42] [2, 194] [0, 42] [1, 138] [2, 85] [0, 42] [0, 42] [2, 187] [2, 85] [0, 42] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 55.19915771484375 with beta sum per layer: [87.61898803710938, 560.9808959960938, 667.26416015625, 614.5938110351562, 403.5949401855469]
alpha/beta optimization time: 0.39638662338256836
This batch time : update_bounds func: 0.9634	 prepare: 0.3368	 bound: 0.3969	 transfer: 0.0232	 finalize: 0.2000
Accumulated time: update_bounds func: 203.8487	 prepare: 59.2911	 bound: 73.0947	 transfer: 0.0232	 finalize: 62.3023
batch bounding time:  0.9656276702880859
Current worst splitting domains [lb, ub] (depth):
[-0.06579,   inf] (335), [-0.06563,   inf] (335), [-0.06561,   inf] (335), [-0.06556,   inf] (335), [-0.06552,   inf] (335), [-0.06549,   inf] (335), [-0.06548,   inf] (335), [-0.06548,   inf] (335), [-0.06548,   inf] (335), [-0.06548,   inf] (335), [-0.06547,   inf] (335), [-0.06547,   inf] (335), [-0.06547,   inf] (335), [-0.06547,   inf] (335), [-0.06546,   inf] (335), [-0.06536,   inf] (335), [-0.06527,   inf] (335), [-0.06513,   inf] (335), [-0.06510,   inf] (335), [-0.06508,   inf] (335), 
length of domains: 78108
Total time: 2.2533	 pickout: 0.2296	 decision: 0.3508	 get_bound: 0.9693	 add_domain: 0.7036
Current lb:-0.06579208374023438
349760 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 402.5163686275482

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  0
all nodes are split!!
Global ub: inf, batch ub: inf
Image 465 label 3 verification end, final lower bound -0.06579208374023438, upper bound inf, time: 406.1341724395752
465 -0.06579208374023438
Result: image 465 verification failure (with branch and bound).
Wall time: 652.8190610408783

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 0): []
verification failure idx (total 1): [465]
final verified acc: 0.0%[1]
verifier is called on 1 examples.
total verified: 0
mean time [cnt:1] (excluding attack success): 652.7040526866913
