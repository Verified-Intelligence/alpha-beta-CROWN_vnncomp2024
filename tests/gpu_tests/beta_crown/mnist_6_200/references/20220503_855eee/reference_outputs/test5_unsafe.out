Building native CUDA modules...
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/torch/utils/cpp_extension.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
CUDA modules have been built.
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  mode: verified-acc
  complete_verifier: bab-refine
  enable_incomplete_verification: true
  get_crown_verified_acc: false
model:
  path: mnist_6_200_nat.pth
  name: mnist_6_200
data:
  start: 199
  end: 200
  num_outputs: 10
  mean: [0.0]
  std: [1.0]
  pkl_path: null
  dataset: MNIST_ERAN_UN
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  norm: .inf
  epsilon: 0.015
solver:
  no_float64_last_iter: false
  no_amp: false
  early_stop_patience: 10
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
  beta-crown:
    batch_size: 1024
    min_batch_size_ratio: 0.1
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
    solver_pkg: gurobi
  mip:
    parallel_solvers: 16
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
bab:
  max_domains: 200000
  decision_thresh: 0
  timeout: 900
  get_upper_bound: false
  dfs_percent: 0.0
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr_decay: 1
    iteration: 500
    lr_beta: 0.01
    number_cuts: 50
    add_implied_cuts: false
    add_input_cuts: false
    _tmp_cuts: null
    _eran_cuts: null
    skip_bab: false
    max_num: 1000000000
    incomplete: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: max
    input_split:
      enable: false
      use_alpha_patience: 20
      attack_patience: 80
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_timeout: 30.0
    mip_start_iteration: 5
    max_dive_domains: -1
    num_dive_constraints: 50
    dive_rate: 0.2
    adv_dive: false
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  use_auto_attack: false
  use_diversed_pgd: false
  enable_mip_attack: false
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon May  2 23:03:15 2022 on diablo.cs.ucla.edu
Sequential(
  (0): Flatten()
  (1): Linear(in_features=784, out_features=200, bias=True)
  (2): ReLU()
  (3): Linear(in_features=200, out_features=200, bias=True)
  (4): ReLU()
  (5): Linear(in_features=200, out_features=200, bias=True)
  (6): ReLU()
  (7): Linear(in_features=200, out_features=200, bias=True)
  (8): ReLU()
  (9): Linear(in_features=200, out_features=200, bias=True)
  (10): ReLU()
  (11): Linear(in_features=200, out_features=10, bias=True)
)
############################
Sampled data loaded. No normalization used!
Shape: torch.Size([1000, 1, 28, 28]) torch.Size([1000]) torch.Size([1000])
X range: tensor(1.) tensor(0.) tensor(0.1223)
Note runnerup label is empty here!
############################
epsilon after preprocessing: tensor([[[[0.0150]]]]), data_max = tensor([[[[1.]]]]), data_min = tensor([[[[0.]]]])
Task length: 1
saving results to Verified_ret_[mnist_6_200]_start=199_end=200_iter=20_b=1024_timeout=900_branching=kfsb-max-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip.npy

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0 img ID: 199 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
predicted label 2, correct label 2, image norm 148.9686279296875, logits tensor([-2.2822, -0.0930,  5.9459,  3.8994, -2.5546, -2.1217, -2.1716,  2.3568,
         0.9355, -1.2078], device='cuda:0', grad_fn=<SelectBackward>)
Model prediction is: tensor([[-2.2822, -0.0930,  5.9459,  3.8994, -2.5546, -2.1217, -2.1716,  2.3568,
          0.9355, -1.2078]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
initial CROWN bounds: tensor([[-1.4875, -4.5137, -8.7272, -1.9358, -3.6779, -0.4973, -6.3013, -6.1962,
         -4.8338]], device='cuda:0') None
best_l after optimization: 18.23979949951172 with beta sum per layer: []
alpha/beta optimization time: 8.131165266036987
initial alpha-CROWN bounds: tensor([[ 0.5606, -2.4437, -6.0469, -0.0726, -1.4113,  1.1106, -4.1156, -3.6193,
         -2.2016]], device='cuda:0', grad_fn=<AsStridedBackward>)
worst class: tensor(-6.0469, device='cuda:0', grad_fn=<MinBackward1>)
Start solving intermediate bounds with MIP...
alpha-CROWN optimizable variables initialized.
Academic license - for non-commercial use only - expires 2023-03-23
Using license file /home/zhouxingshi/gurobi.lic
mip_multi_proc: 16, mip_threads: 1,total threads used: 16, mip_perneuron_refine_timeout: 15
[total time budget for MIP: 712.8900312423707]

Linear(in_features=784, out_features=200, bias=True) 0 2 torch.Size([200])
Linear(in_features=200, out_features=200, bias=True) 1 4 torch.Size([200])
sorted candidates ['lay4_173', 'lay4_50', 'lay4_82', 'lay4_40', 'lay4_15', 'lay4_112', 'lay4_37', 'lay4_2', 'lay4_14', 'lay4_109', 'lay4_125', 'lay4_132', 'lay4_47', 'lay4_192', 'lay4_178', 'lay4_29', 'lay4_7', 'lay4_73', 'lay4_160', 'lay4_78', 'lay4_183', 'lay4_120', 'lay4_6', 'lay4_8', 'lay4_150', 'lay4_95', 'lay4_9', 'lay4_157', 'lay4_94', 'lay4_62', 'lay4_61', 'lay4_92', 'lay4_199', 'lay4_147', 'lay4_72', 'lay4_48', 'lay4_129', 'lay4_76', 'lay4_25', 'lay4_128', 'lay4_123', 'lay4_135', 'lay4_146', 'lay4_96'] filter: 1.0
/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/utils.py:579: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(eps_temp).reshape(1, -1, 1, 1)
Solving MIP for lay4_125, [-0.7554391026496887,0.10784581303596497]=>[-0.626054877061923,0.003140196462576823] (2,-1; 2,-1), time: 1.1090s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_82, [-0.5639065504074097,0.3146212697029114]=>[-0.40114453045772097,0.26083291301596234] (2,-1; 2,-1), time: 1.1156s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_2, [-0.6618744730949402,0.16623874008655548]=>[-0.5746035353031085,0.057908430588275606] (2,-1; 2,-1), time: 1.1181s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_109, [-0.24741072952747345,0.45193421840667725]=>[-0.1510157240832808,0.37699962826264743] (2,-1; 2,-1), time: 1.2041s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_173, [-0.5409368276596069,0.38717466592788696]=>[-0.3722428106602873,0.3279109858548309] (2,-1; 2,-1), time: 1.2665s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_40, [-0.31013333797454834,0.5457890033721924]=>[-0.2330248957945793,0.4207780759197318] (2,-1; 2,-1), time: 1.4006s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_132, [-0.4780332148075104,0.2817067503929138]=>[-0.329003178256573,0.23750915811913145] (2,-1; 2,-1), time: 1.4398s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_160, [-0.7164592146873474,0.002726137638092041]=>[-0.7164592146873474,-1e-05] (-1,-1; 15,-1), time: 0.3328s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_14, [-0.1245139092206955,0.5999994874000549]=>[-0.04175303439023928,0.5076102215157794] (2,-1; 2,-1), time: 1.4613s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_50, [-0.32423025369644165,0.5100337266921997]=>[-0.20231505404604355,0.447072586515587] (2,-1; 2,-1), time: 1.5256s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_192, [-0.2952492833137512,0.718616247177124]=>[-0.15111675734950855,0.5877728663961433] (2,-1; 2,-1), time: 1.5874s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_112, [-0.49669304490089417,0.34139835834503174]=>[-0.33932608046325624,0.2899272530705359] (2,-1; 2,-1), time: 1.8284s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_47, [-0.35948315262794495,0.39023399353027344]=>[-0.2554113476497013,0.28324701733791346] (2,-1; 2,-1), time: 1.8653s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_15, [-0.19214288890361786,0.7049602270126343]=>[-0.005033930458046704,0.6584585590477476] (2,-1; 2,-1), time: 1.8837s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_37, [-0.20119024813175201,0.4409624934196472]=>[-0.09389469775241012,0.3576998997785301] (2,-1; 2,-1), time: 1.9196s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_6, [-0.7585126161575317,0.0598318874835968]=>[-0.7585126161575317,-1e-05] (-1,-1; 15,-1), time: 0.5009s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_178, [-0.5621764659881592,0.17271298170089722]=>[-0.4626424722086735,0.037575407367358336] (2,-1; 2,-1), time: 2.0076s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_150, [-0.009175552986562252,0.8132741451263428]=>[1e-05,0.8132741451263428] (15,-1; -1,-1), time: 0.5446s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_29, [-0.4695689082145691,0.2404119074344635]=>[-0.35870237642879993,0.13649380792263352] (2,-1; 2,-1), time: 2.0959s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_95, [-0.0971410870552063,0.6407703161239624]=>[1e-05,0.6407703161239624] (15,-1; -1,-1), time: 0.6640s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_78, [-0.2107393592596054,0.7869402170181274]=>[-0.08931511759975008,0.6532014984807808] (2,-1; 2,-1), time: 1.2221s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_199, [-0.06060469150543213,0.6964855790138245]=>[1e-05,0.6964855790138245] (15,-1; -1,-1), time: 0.4281s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_92, [-0.0710437148809433,0.7213423252105713]=>[1e-05,0.7213423252105713] (15,-1; -1,-1), time: 0.5093s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_7, [-0.2879859209060669,0.4204721450805664]=>[-0.19089753607753301,0.3269935629155393] (2,-1; 2,-1), time: 1.4717s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_48, [-0.7693661451339722,0.008753985166549683]=>[-0.7693661451339722,-1e-05] (-1,-1; 15,-1), time: 0.3987s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_73, [-0.5003886222839355,0.21451112627983093]=>[-0.3782920005288241,0.17053091937822867] (2,-1; 2,-1), time: 1.5043s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_61, [-0.3427629768848419,0.7924027442932129]=>[-0.24125961284322628,0.6452560352157151] (2,-1; 2,-1), time: 0.9858s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_76, [-0.06418698281049728,0.7906360626220703]=>[1e-05,0.7906360626220703] (15,-1; -1,-1), time: 0.4987s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_25, [-0.03141285479068756,0.7082180976867676]=>[1e-05,0.7082180976867676] (15,-1; -1,-1), time: 0.5291s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_123, [-0.007588865235447884,0.8023363947868347]=>[1e-05,0.8023363947868347] (15,-1; -1,-1), time: 0.4303s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_8, [-0.43758463859558105,0.2763310670852661]=>[-0.2937963663370855,0.213443572109972] (2,-1; 2,-1), time: 1.6132s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_94, [-0.23432670533657074,0.4710065424442291]=>[-0.12616914498544188,0.3747595887866362] (2,-1; 2,-1), time: 1.2581s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_9, [-0.2013886570930481,0.6555506587028503]=>[-0.08986181971163396,0.5467261747033094] (2,-1; 2,-1), time: 1.6226s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_120, [-0.6012441515922546,0.09887105226516724]=>[-0.44729075768403126,0.056527889469420056] (2,-1; 2,-1), time: 1.8813s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_62, [-0.47702932357788086,0.3562295436859131]=>[-0.378505681851494,0.2572704069784563] (2,-1; 2,-1), time: 1.4204s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_183, [-0.48722320795059204,0.1082407534122467]=>[-0.3624004529640038,0.01026482967874881] (2,-1; 2,-1), time: 2.0444s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_157, [-0.5045678615570068,0.24353083968162537]=>[-0.3706816788648318,0.16338596912033734] (2,-1; 2,-1), time: 1.7674s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_147, [-0.13317683339118958,0.4876354932785034]=>[-0.05917509479611404,0.37617506752514696] (2,-1; 2,-1), time: 1.6229s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_129, [-0.11869148910045624,0.42920351028442383]=>[-0.05369755397136053,0.3885567077248281] (2,-1; 2,-1), time: 1.2792s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_128, [-0.1998896598815918,0.42118459939956665]=>[-0.07689119293523414,0.3700996452657509] (2,-1; 2,-1), time: 1.2840s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_72, [-0.3645373284816742,0.40766650438308716]=>[-0.24238626085742065,0.29267692887306823] (2,-1; 2,-1), time: 1.7847s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_135, [-0.13897588849067688,0.3686060607433319]=>[-0.059167618853408065,0.28372671329874105] (2,-1; 2,-1), time: 1.3753s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_96, [-0.48690205812454224,0.15461033582687378]=>[-0.34856833887795535,0.12651495654278583] (2,-1; 2,-1), time: 1.5740s, #vars: 1231, #constrs: 469, improved: True
Solving MIP for lay4_146, [-0.11459871381521225,0.6032922267913818]=>[-0.020391770195272333,0.4581326114178204] (2,-1; 2,-1), time: 1.7008s, #vars: 1231, #constrs: 469, improved: True
MIP improved 44 nodes out of 44 unstable nodes, lb improved 4.34018611907959, ub improved 3.0370876789093018, time 5.3544
maximum relu layer improved by MIP so far 1 last_relu_layer_refined: True
Linear(in_features=200, out_features=200, bias=True) 2 6 torch.Size([200])
sorted candidates ['lay6_173', 'lay6_29', 'lay6_21', 'lay6_162', 'lay6_168', 'lay6_56', 'lay6_15', 'lay6_140', 'lay6_94', 'lay6_48', 'lay6_152', 'lay6_143', 'lay6_124', 'lay6_23', 'lay6_101', 'lay6_70', 'lay6_75', 'lay6_125', 'lay6_37', 'lay6_60', 'lay6_78', 'lay6_64', 'lay6_93', 'lay6_2', 'lay6_129', 'lay6_160', 'lay6_35', 'lay6_13', 'lay6_171', 'lay6_69', 'lay6_190', 'lay6_191', 'lay6_136', 'lay6_144', 'lay6_111', 'lay6_131', 'lay6_53', 'lay6_126', 'lay6_132', 'lay6_26', 'lay6_103', 'lay6_148', 'lay6_9', 'lay6_91', 'lay6_38', 'lay6_146', 'lay6_39', 'lay6_117', 'lay6_74', 'lay6_115', 'lay6_102', 'lay6_118', 'lay6_18', 'lay6_130', 'lay6_73', 'lay6_174', 'lay6_159', 'lay6_197', 'lay6_54', 'lay6_194', 'lay6_12', 'lay6_59', 'lay6_199', 'lay6_165', 'lay6_169', 'lay6_172', 'lay6_138', 'lay6_55', 'lay6_150', 'lay6_72', 'lay6_186', 'lay6_157', 'lay6_50'] filter: 1.0
Solving MIP for lay6_70, [-0.028237193822860718,1.0703039169311523]=>[1e-05,1.0703039169311523] (15,-1; -1,-1), time: 0.2715s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_173, [-1.3623325824737549,0.019409894943237305]=>[-1.3623325824737549,-1e-05] (-1,-1; 15,-1), time: 0.3048s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_124, [-0.06715473532676697,1.4868848323822021]=>[1e-05,1.4868848323822021] (15,-1; -1,-1), time: 0.3043s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_101, [-0.08002731204032898,0.9785274267196655]=>[1e-05,0.9785274267196655] (15,-1; -1,-1), time: 0.3028s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_15, [-0.890674889087677,0.12104365229606628]=>[-0.890674889087677,-1e-05] (-1,-1; 15,-1), time: 0.5087s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_140, [-0.14753073453903198,0.6358767151832581]=>[1e-05,0.6358767151832581] (15,-1; -1,-1), time: 0.5475s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_152, [-0.7306386232376099,0.07484331727027893]=>[-0.7306386232376099,-1e-05] (-1,-1; 15,-1), time: 0.5449s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_168, [-0.19238677620887756,0.767544150352478]=>[1e-05,0.767544150352478] (15,-1; -1,-1), time: 1.0447s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_78, [-0.9034802317619324,0.10407304763793945]=>[-0.9034802317619324,-1e-05] (-1,-1; 15,-1), time: 0.6107s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_75, [-0.96007239818573,0.19156014919281006]=>[-0.96007239818573,-1e-05] (-1,-1; 15,-1), time: 3.2925s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_125, [-0.7596900463104248,0.1445644497871399]=>[-0.7596900463104248,-1e-05] (-1,-1; 15,-1), time: 3.2873s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_48, [-0.19033963978290558,0.6571844816207886]=>[1e-05,0.6571844816207886] (15,-1; -1,-1), time: 3.8118s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_160, [-0.06639912724494934,0.8132020235061646]=>[1e-05,0.8132020235061646] (15,-1; -1,-1), time: 0.2489s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_93, [-0.6831488609313965,0.1506180465221405]=>[-0.6831488609313965,-0.0023754408970508988] (-1,-1; 2,-1), time: 3.5325s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_35, [-0.7171381115913391,0.13438057899475098]=>[-0.7171381115913391,-1e-05] (-1,-1; 15,-1), time: 0.7058s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_171, [-0.05167199671268463,0.6053510904312134]=>[1e-05,0.6053510904312134] (15,-1; -1,-1), time: 0.5348s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_13, [-0.62830650806427,0.1894766390323639]=>[-0.62830650806427,-1e-05] (-1,-1; 15,-1), time: 3.4220s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_69, [-0.7222959399223328,0.17509064078330994]=>[-0.7222959399223328,-1e-05] (-1,-1; 15,-1), time: 3.5288s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_136, [-0.06378590315580368,0.8732072114944458]=>[1e-05,0.8732072114944458] (15,-1; -1,-1), time: 0.4371s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_56, [-0.434022456407547,0.4472765624523163]=>[-0.24034305821996074,0.2307841951175753] (2,-1; 2,-1), time: 7.8255s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_29, [-0.4385984241962433,0.6281147003173828]=>[-0.09808620461774266,0.47914200734433093] (2,-1; 2,-1), time: 8.0673s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_23, [-0.5871878862380981,1.24737548828125]=>[-0.17778304383569107,0.8942696792351614] (2,-1; 2,-1), time: 8.3255s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_64, [-0.3852090537548065,0.5340235829353333]=>[-0.20975529846630867,0.31259068195351425] (2,-1; 2,-1), time: 8.3074s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_2, [-0.7603536248207092,0.45990872383117676]=>[-0.5242638371054212,0.2032229196254164] (2,-1; 2,-1), time: 7.8649s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_132, [-0.7422170042991638,0.03788019344210625]=>[-0.7422170042991638,-1e-05] (-1,-1; 15,-1), time: 0.2340s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_103, [-1.1202993392944336,0.027593597769737244]=>[-1.1202993392944336,-1e-05] (-1,-1; 15,-1), time: 0.2206s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_129, [-0.45046764612197876,0.3876776099205017]=>[-0.28444114709717194,0.22002381959353234] (2,-1; 2,-1), time: 8.3647s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_143, [-0.3939093351364136,0.49738064408302307]=>[-0.09517796661716367,0.34881175871758097] (2,-1; 2,-1), time: 9.7924s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_162, [-0.9318593740463257,0.41069433093070984]=>[-0.5934479624603985,0.1363738255316114] (2,-1; 2,-1), time: 9.8620s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_37, [-0.5241283774375916,0.24985313415527344]=>[-0.343600385533084,0.06839081972953572] (2,-1; 2,-1), time: 9.6750s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_148, [-0.1653892993927002,0.8696614503860474]=>[1e-05,0.8696614503860474] (15,-1; -1,-1), time: 0.8325s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_39, [-0.6829074621200562,0.06704673171043396]=>[-0.6829074621200562,-1e-05] (-1,-1; 15,-1), time: 0.2334s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_117, [-0.8840343356132507,0.05119291692972183]=>[-0.8840343356132507,-1e-05] (-1,-1; 15,-1), time: 0.2338s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_60, [-0.43773430585861206,0.37238818407058716]=>[-0.17576750100593783,0.22123339546620382] (2,-1; 2,-1), time: 10.3433s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_91, [-0.6017056703567505,0.12657324969768524]=>[-0.6017056703567505,-1e-05] (-1,-1; 15,-1), time: 1.4357s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_102, [-0.9695647358894348,0.045033931732177734]=>[-0.9695647358894348,-1e-05] (-1,-1; 15,-1), time: 0.2219s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_94, [-0.673225998878479,0.3505608141422272]=>[-0.3793224384572503,0.09292748350744429] (2,-1; 2,-1), time: 11.6527s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_190, [-0.28175851702690125,0.75188148021698]=>[-0.050753125040854205,0.5090064704127957] (2,-1; 2,-1), time: 7.4329s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_126, [-0.23652026057243347,1.1497976779937744]=>[1e-05,1.1497976779937744] (15,-1; -1,-1), time: 3.5668s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_131, [-0.2657598853111267,0.7100407481193542]=>[1e-05,0.7100407481193542] (15,-1; -1,-1), time: 4.4659s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_9, [-0.1543285846710205,0.6140693426132202]=>[1e-05,0.6140693426132202] (15,-1; -1,-1), time: 2.8116s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_159, [-0.8807568550109863,0.04415449500083923]=>[-0.8807568550109863,-1e-05] (-1,-1; 15,-1), time: 0.2175s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_21, [-0.3068302571773529,0.3561621904373169]=>[-0.054984075701258475,0.23290715728911754] (2,-1; 2,-1), time: 13.4017s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_53, [-0.32690203189849854,0.42840901017189026]=>[-0.14704857529537732,0.25825911046757616] (2,-1; 2,-1), time: 6.1744s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_54, [-0.17738333344459534,0.8809366822242737]=>[1e-05,0.8809366822242737] (15,-1; -1,-1), time: 0.8469s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_191, [-0.9219374656677246,0.1957734376192093]=>[-0.612439336398515,0.05082160153474105] (2,-1; 2,-1), time: 10.0212s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_144, [-0.5050715208053589,0.35124170780181885]=>[-0.27277112147517996,0.22463133170834265] (2,-1; 2,-1), time: 7.4341s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_12, [-0.1256345510482788,0.6343193054199219]=>[1e-05,0.6343193054199219] (15,-1; -1,-1), time: 1.1663s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_26, [-0.6577795743942261,0.29713937640190125]=>[-0.3851685734187497,0.12598304318956252] (2,-1; 2,-1), time: 6.6568s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_165, [-0.08984588086605072,0.7725214958190918]=>[1e-05,0.7725214958190918] (15,-1; -1,-1), time: 0.5616s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_38, [-0.7316105365753174,0.2737463116645813]=>[-0.5414457854472255,0.09125690633999699] (2,-1; 2,-1), time: 6.6757s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_138, [-0.11020858585834503,0.6851550340652466]=>[1e-05,0.6851550340652466] (15,-1; -1,-1), time: 0.5172s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_111, [-0.645879328250885,0.3705030083656311]=>[-0.36190791909357306,0.12545674978943622] (2,-1; 2,-1), time: 9.6772s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_146, [-0.5676049590110779,0.30130282044410706]=>[-0.362886938907925,0.058600652602600056] (2,-1; 2,-1), time: 9.1672s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_130, [-0.5204657316207886,0.9348349571228027]=>[-0.23931839186320697,0.6710520897096254] (2,-1; 2,-1), time: 7.5609s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_186, [-0.0851961076259613,0.6733288168907166]=>[1e-05,0.6733288168907166] (15,-1; -1,-1), time: 0.2158s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_118, [-0.20386356115341187,0.6553595662117004]=>[-0.017174490980816397,0.46342493005203955] (2,-1; 2,-1), time: 8.1311s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_72, [-0.1120070219039917,0.7277711033821106]=>[1e-05,0.7277711033821106] (15,-1; -1,-1), time: 0.6412s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_74, [-0.5309507846832275,0.3740087151527405]=>[-0.3054319139718634,0.19754157240916279] (2,-1; 2,-1), time: 9.2492s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_50, [-0.9352402687072754,0.13728965818881989]=>[-0.9352402687072754,-1e-05] (-1,-1; 15,-1), time: 0.4091s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_157, [-0.17851656675338745,0.9865168333053589]=>[1e-05,0.9865168333053589] (15,-1; -1,-1), time: 0.8161s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_150, [-0.6141341924667358,0.1493469625711441]=>[-0.6141341924667358,-1e-05] (-1,-1; 15,-1), time: 3.5610s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_197, [-0.4981467127799988,0.2938113212585449]=>[-0.2762765258742423,0.14152922522591196] (2,-1; 2,-1), time: 8.6053s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_73, [-0.32126492261886597,0.7307471036911011]=>[-0.07317596148031019,0.6005688540904235] (2,-1; 2,-1), time: 9.7819s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_174, [-0.7191833257675171,0.34278929233551025]=>[-0.4070207511142972,0.1189850163686724] (2,-1; 2,-1), time: 9.6742s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_199, [-0.3548642098903656,0.6886327266693115]=>[-0.15119284441500153,0.4281045485981996] (2,-1; 2,-1), time: 7.9261s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_18, [-0.44719043374061584,0.3660418391227722]=>[-0.19296107877948798,0.1409948925064211] (2,-1; 2,-1), time: 11.7499s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_55, [-0.31350019574165344,0.9845231771469116]=>[-0.04466329719467976,0.7424710627432392] (2,-1; 2,-1), time: 6.8846s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_169, [-0.20438626408576965,0.6229168772697449]=>[-0.02538232226638944,0.39380597569106907] (2,-1; 2,-1), time: 9.4140s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_59, [-0.37577760219573975,0.5654170513153076]=>[-0.06202468668316989,0.4217250733929489] (2,-1; 2,-1), time: 10.9548s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_115, [-0.5110013484954834,0.3443217873573303]=>[-0.21300952849723345,0.17596167026342463] (2,-1; 2,-1), time: 16.3663s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_172, [-0.30004703998565674,0.6746489405632019]=>[-0.033258628462150934,0.5097330886432241] (2,-1; 2,-1), time: 12.1040s, #vars: 1499, #constrs: 771, improved: True
Solving MIP for lay6_194, [-0.6001683473587036,0.23365314304828644]=>[-0.32285786120050475,0.02637655000942847] (2,-1; 2,-1), time: 18.1411s, #vars: 1499, #constrs: 771, improved: True
Run alpha-CROWN after refining layer 4 and relu idx 1
0 /21 torch.Size([1, 200])
1 /23 torch.Size([1, 200])
best_l after optimization: -7.726408004760742 with beta sum per layer: []
alpha/beta optimization time: 7.948076963424683
alpha-CROWN with intermediate bounds by MIP: tensor([[ 3.2662,  0.4929, -3.5712,  2.8349,  1.6455,  3.7684, -1.3041, -0.3831,
          0.9769]], device='cuda:0', grad_fn=<AsStridedBackward>) None
MIP improved 73 nodes out of 73 unstable nodes, lb improved 11.176260948181152, ub improved 8.79987907409668, time 33.1799
maximum relu layer improved by MIP so far 2
Linear(in_features=200, out_features=200, bias=True) 3 8 torch.Size([200])
sorted candidates ['lay8_76', 'lay8_58', 'lay8_155', 'lay8_46', 'lay8_66', 'lay8_141', 'lay8_70', 'lay8_90', 'lay8_21', 'lay8_142', 'lay8_136', 'lay8_192', 'lay8_162', 'lay8_175', 'lay8_55', 'lay8_25', 'lay8_10', 'lay8_195', 'lay8_26', 'lay8_183', 'lay8_30', 'lay8_23', 'lay8_133', 'lay8_78', 'lay8_4', 'lay8_22', 'lay8_33', 'lay8_18', 'lay8_75', 'lay8_12', 'lay8_118', 'lay8_38', 'lay8_180', 'lay8_57', 'lay8_131', 'lay8_160', 'lay8_165', 'lay8_59', 'lay8_116', 'lay8_29', 'lay8_48', 'lay8_80', 'lay8_127', 'lay8_146', 'lay8_199', 'lay8_45', 'lay8_86', 'lay8_106', 'lay8_117', 'lay8_145', 'lay8_9', 'lay8_16', 'lay8_1', 'lay8_193', 'lay8_63', 'lay8_148', 'lay8_129', 'lay8_50', 'lay8_83', 'lay8_31', 'lay8_93', 'lay8_144', 'lay8_87', 'lay8_149', 'lay8_152', 'lay8_157', 'lay8_188', 'lay8_92', 'lay8_159', 'lay8_67', 'lay8_44', 'lay8_107', 'lay8_97', 'lay8_185', 'lay8_190', 'lay8_161', 'lay8_24', 'lay8_5', 'lay8_81', 'lay8_181', 'lay8_19', 'lay8_15', 'lay8_173', 'lay8_39', 'lay8_139', 'lay8_96', 'lay8_151', 'lay8_172', 'lay8_77', 'lay8_64', 'lay8_56', 'lay8_41', 'lay8_0', 'lay8_121', 'lay8_60', 'lay8_164', 'lay8_11', 'lay8_17', 'lay8_124', 'lay8_110', 'lay8_143', 'lay8_179', 'lay8_122', 'lay8_37', 'lay8_105', 'lay8_177', 'lay8_51', 'lay8_28', 'lay8_168', 'lay8_169'] filter: 1.0
Solving MIP for lay8_25, [-0.9313310980796814,0.21384543180465698]=>[-0.9313310980796814,-1e-05] (-1,-1; 15,-1), time: 0.3640s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_162, [-1.4973344802856445,0.28267449140548706]=>[-1.4973344802856445,-1e-05] (-1,-1; 15,-1), time: 0.4583s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_142, [-0.8897922039031982,0.3242165446281433]=>[-0.8897922039031982,-1e-05] (-1,-1; 15,-1), time: 0.7636s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_195, [-1.2490524053573608,0.1290295124053955]=>[-1.2490524053573608,-1e-05] (-1,-1; 15,-1), time: 0.3386s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_192, [-0.7273954749107361,0.28549209237098694]=>[-0.7273954749107361,-1e-05] (-1,-1; 15,-1), time: 1.2298s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_30, [-0.29680323600769043,0.845039427280426]=>[1e-05,0.845039427280426] (15,-1; -1,-1), time: 0.3985s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_58, [-1.172010898590088,0.3478180170059204]=>[-1.172010898590088,-1e-05] (-1,-1; 15,-1), time: 5.3147s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_133, [-1.063383936882019,0.20691482722759247]=>[-1.063383936882019,-1e-05] (-1,-1; 15,-1), time: 0.4755s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_175, [-1.076988697052002,0.33540457487106323]=>[-1.076988697052002,-1e-05] (-1,-1; 15,-1), time: 5.9189s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_70, [-0.3439004719257355,0.774105966091156]=>[1e-05,0.774105966091156] (15,-1; -1,-1), time: 6.0163s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_136, [-0.844043493270874,0.39193350076675415]=>[-0.844043493270874,-1e-05] (-1,-1; 15,-1), time: 6.6669s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_4, [-1.328711986541748,0.337266743183136]=>[-1.328711986541748,-1e-05] (-1,-1; 15,-1), time: 1.0277s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_18, [-1.1786190271377563,0.22736507654190063]=>[-1.1786190271377563,-1e-05] (-1,-1; 15,-1), time: 0.3787s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_141, [-0.47087329626083374,1.0231949090957642]=>[1e-05,1.0231949090957642] (15,-1; -1,-1), time: 7.9018s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_75, [-0.899870753288269,0.26527291536331177]=>[-0.899870753288269,-1e-05] (-1,-1; 15,-1), time: 0.7398s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_118, [-0.9653273224830627,0.16080117225646973]=>[-0.9653273224830627,-1e-05] (-1,-1; 15,-1), time: 0.4672s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_46, [-1.0578075647354126,0.404254674911499]=>[-1.0578075647354126,-1e-05] (-1,-1; 15,-1), time: 8.7729s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_38, [-1.2095881700515747,0.1557755470275879]=>[-1.2095881700515747,-1e-05] (-1,-1; 15,-1), time: 0.5285s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_57, [-1.3304157257080078,0.24199730157852173]=>[-1.3304157257080078,-1e-05] (-1,-1; 15,-1), time: 0.4847s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_131, [-0.40323853492736816,1.2077648639678955]=>[1e-05,1.2077648639678955] (15,-1; -1,-1), time: 5.1197s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_160, [-0.9726195931434631,0.2581423819065094]=>[-0.9726195931434631,-1e-05] (-1,-1; 15,-1), time: 0.7683s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_165, [-0.9444141387939453,0.21407806873321533]=>[-0.9444141387939453,-1e-05] (-1,-1; 15,-1), time: 0.6722s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_55, [-0.7770127058029175,0.7986282706260681]=>[-0.33564903889544495,0.3928538492601401] (9,-1; 2,-1), time: 21.2530s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_155, [-1.4193980693817139,0.44884270429611206]=>[-0.8567556814749813,0.07549896442852136] (2,-1; 9,-1), time: 21.3860s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_29, [-1.1720523834228516,0.1971389651298523]=>[-1.1720523834228516,-1e-05] (-1,-1; 15,-1), time: 0.4021s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_116, [-1.1396849155426025,0.30587059259414673]=>[-1.1396849155426025,-1e-05] (-1,-1; 15,-1), time: 0.6820s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_26, [-0.868392825126648,0.41333889961242676]=>[-0.47427507019830956,0.10289525475427473] (2,-1; 9,-1), time: 21.3056s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_127, [-1.6205143928527832,0.0934998020529747]=>[-1.6205143928527832,-1e-05] (-1,-1; 15,-1), time: 0.4547s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_76, [-0.56300950050354,1.1440380811691284]=>[-0.04351085413746879,0.7717697560026776] (9,-1; 2,-1), time: 22.7299s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_66, [-1.3340705633163452,0.6085835099220276]=>[-0.857898682020014,0.07522257255945931] (9,-1; 2,-1), time: 22.9497s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_21, [-0.6775820255279541,0.6617636680603027]=>[-0.266747887175606,0.3172924481844553] (9,-1; 2,-1), time: 23.5232s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_146, [-1.128223180770874,0.37607133388519287]=>[-1.128223180770874,-1e-05] (-1,-1; 15,-1), time: 1.6857s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_86, [-0.26248547434806824,1.8299793004989624]=>[1e-05,1.8299793004989624] (15,-1; -1,-1), time: 0.7112s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_106, [-1.1572129726409912,0.04087364673614502]=>[-1.1572129726409912,-1e-05] (-1,-1; 15,-1), time: 0.4208s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_145, [-0.8745441436767578,0.2430397868156433]=>[-0.8745441436767578,-1e-05] (-1,-1; 15,-1), time: 0.7239s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_9, [-1.074897289276123,0.13117587566375732]=>[-1.074897289276123,-1e-05] (-1,-1; 15,-1), time: 0.4558s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_90, [-0.6386076211929321,0.7356484532356262]=>[-0.21670635904364044,0.3536099643495402] (2,-1; 9,-1), time: 26.0417s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_1, [-0.9988251328468323,0.16957896947860718]=>[-0.9988251328468323,-1e-05] (-1,-1; 15,-1), time: 0.4645s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_16, [-1.110256314277649,0.2406010627746582]=>[-1.110256314277649,-1e-05] (-1,-1; 15,-1), time: 0.7710s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_63, [-1.2979505062103271,0.06412434577941895]=>[-1.2979505062103271,-1e-05] (-1,-1; 15,-1), time: 0.4175s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_33, [-0.788632869720459,0.8170996904373169]=>[-0.30091567507163963,0.39726901520219415] (9,-1; 2,-1), time: 20.4559s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_23, [-0.46814095973968506,0.8338146805763245]=>[-0.050201109390267055,0.41224432599002586] (9,-1; 2,-1), time: 25.7335s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_148, [-0.8503034710884094,0.20800019800662994]=>[-0.8503034710884094,-1e-05] (-1,-1; 15,-1), time: 0.6232s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_22, [-0.7917613387107849,0.4777965247631073]=>[-0.408852907654253,0.08349937429451551] (9,-1; 2,-1), time: 21.6992s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_129, [-1.3312060832977295,0.3296613097190857]=>[-1.3312060832977295,-1e-05] (-1,-1; 15,-1), time: 0.6136s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_50, [-0.18255677819252014,1.15632164478302]=>[1e-05,1.15632164478302] (15,-1; -1,-1), time: 0.3973s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_31, [-1.0464836359024048,0.18509632349014282]=>[-1.0464836359024048,-1e-05] (-1,-1; 15,-1), time: 0.3679s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_183, [-1.0084507465362549,0.5521670579910278]=>[-0.5885280157310637,0.022184415245076493] (9,-1; 2,-1), time: 27.3814s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_83, [-1.203874945640564,0.33230066299438477]=>[-1.203874945640564,-1e-05] (-1,-1; 15,-1), time: 0.6483s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_87, [-1.1512304544448853,0.10859891772270203]=>[-1.1512304544448853,-1e-05] (-1,-1; 15,-1), time: 0.4385s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_149, [-1.1054661273956299,0.09674996137619019]=>[-1.1054661273956299,-1e-05] (-1,-1; 15,-1), time: 0.3959s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_188, [-1.2423466444015503,0.24946096539497375]=>[-1.2423466444015503,-1e-05] (-1,-1; 15,-1), time: 0.6330s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_157, [-0.8491747975349426,0.31625667214393616]=>[-0.8491747975349426,-1e-05] (-1,-1; 15,-1), time: 0.8794s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_92, [-1.0303382873535156,0.08006548881530762]=>[-1.0303382873535156,-1e-05] (-1,-1; 15,-1), time: 0.3823s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_67, [-1.1016204357147217,0.019713841378688812]=>[-1.1016204357147217,-1e-05] (-1,-1; 15,-1), time: 0.4384s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_10, [-0.7922506332397461,0.41135358810424805]=>[-0.4048972323813975,0.03661824748849408] (9,-1; 9,-1), time: 30.0107s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_78, [-0.3751852512359619,0.7993656396865845]=>[-0.003976573204513967,0.4701551043085178] (2,-1; 9,-1), time: 24.9201s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_107, [-0.8080971240997314,0.1553369164466858]=>[-0.8080971240997314,-1e-05] (-1,-1; 15,-1), time: 0.4050s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_185, [-0.8708573579788208,0.09883686900138855]=>[-0.8708573579788208,-1e-05] (-1,-1; 15,-1), time: 0.3654s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_97, [-1.0017530918121338,0.21521472930908203]=>[-1.0017530918121338,-1e-05] (-1,-1; 15,-1), time: 0.4791s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_190, [-0.17848382890224457,0.9024103879928589]=>[1e-05,0.9024103879928589] (15,-1; -1,-1), time: 0.3786s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_161, [-0.16439945995807648,1.1832642555236816]=>[1e-05,1.1832642555236816] (15,-1; -1,-1), time: 0.3821s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_24, [-1.419564962387085,0.016655702143907547]=>[-1.419564962387085,-1e-05] (-1,-1; 15,-1), time: 0.3523s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_81, [-1.1260278224945068,0.015868186950683594]=>[-1.1260278224945068,-1e-05] (-1,-1; 15,-1), time: 0.3665s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_193, [-0.5459588766098022,1.6894023418426514]=>[1e-05,1.6894023418426514] (15,-1; -1,-1), time: 7.3681s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_19, [-1.375070333480835,0.2766017019748688]=>[-1.375070333480835,-1e-05] (-1,-1; 15,-1), time: 0.4058s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_159, [-1.0835673809051514,0.3475985825061798]=>[-1.0835673809051514,-1e-05] (-1,-1; 15,-1), time: 5.2432s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_152, [-0.9367460012435913,0.3278205990791321]=>[-0.9367460012435913,-1e-05] (-1,-1; 15,-1), time: 6.7635s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_173, [-0.03210175037384033,1.1786437034606934]=>[1e-05,1.1786437034606934] (15,-1; -1,-1), time: 0.4062s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_139, [-1.0255135297775269,0.1542556881904602]=>[-1.0255135297775269,-1e-05] (-1,-1; 15,-1), time: 0.4687s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_39, [-0.9137948155403137,0.26733338832855225]=>[-0.9137948155403137,-1e-05] (-1,-1; 15,-1), time: 0.5992s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_96, [-0.07429146766662598,1.3920964002609253]=>[1e-05,1.3920964002609253] (15,-1; -1,-1), time: 0.3879s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_59, [-0.8701816201210022,0.6437530517578125]=>[-0.5193652995717183,0.10993941646433361] (2,-1; 9,-1), time: 21.3793s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_12, [-0.6784958839416504,0.5781189203262329]=>[-0.24316964410559053,0.19215889457022153] (9,-1; 9,-1), time: 30.0230s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_77, [-0.056596964597702026,1.1440420150756836]=>[1e-05,1.1440420150756836] (15,-1; -1,-1), time: 0.4553s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_64, [-0.21735253930091858,0.9489368200302124]=>[1e-05,0.9489368200302124] (15,-1; -1,-1), time: 0.3967s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_56, [-1.1423336267471313,0.00701927300542593]=>[-1.1423336267471313,-1e-05] (-1,-1; 15,-1), time: 0.4126s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_41, [-1.138350248336792,0.05747336149215698]=>[-1.138350248336792,-1e-05] (-1,-1; 15,-1), time: 0.3517s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_180, [-0.5583760142326355,0.5529400706291199]=>[-0.1780360969358427,0.2295641291289172] (9,-1; 9,-1), time: 30.1936s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_121, [-0.06025061011314392,1.7539751529693604]=>[1e-05,1.7539751529693604] (15,-1; -1,-1), time: 0.4244s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_60, [-1.4086254835128784,0.007086396217346191]=>[-1.4086254835128784,-1e-05] (-1,-1; 15,-1), time: 0.4119s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_181, [-1.022957682609558,0.3991573452949524]=>[-1.022957682609558,-1e-05] (-1,-1; 15,-1), time: 7.8948s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_11, [-0.9080313444137573,0.23741696774959564]=>[-0.9080313444137573,-1e-05] (-1,-1; 15,-1), time: 0.9117s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_17, [-0.3779667615890503,0.9381401538848877]=>[1e-05,0.9381401538848877] (15,-1; -1,-1), time: 0.6666s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_15, [-0.3610251247882843,0.8365663290023804]=>[1e-05,0.8365663290023804] (15,-1; -1,-1), time: 8.4074s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_45, [-0.7425123453140259,1.2056691646575928]=>[-0.20417557992657623,0.6813043695221647] (9,-1; 2,-1), time: 22.9288s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_179, [-1.1003224849700928,0.0043306476436555386]=>[-1.1003224849700928,-1e-05] (-1,-1; 15,-1), time: 0.3726s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_80, [-0.6881453990936279,1.1188873052597046]=>[-0.19080722075210432,0.6376924851291825] (9,-1; 2,-1), time: 28.0141s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_144, [-0.9897940158843994,0.5336614847183228]=>[-0.5100881149617336,0.11503070151595202] (2,-1; 9,-1), time: 22.2598s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_105, [-0.11341243982315063,1.257153868675232]=>[1e-05,1.257153868675232] (15,-1; -1,-1), time: 0.3507s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_48, [-0.4479706585407257,0.7032981514930725]=>[-0.08638222364433505,0.3193442421997057] (9,-1; 9,-1), time: 30.2527s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_199, [-0.7509975433349609,0.5765116214752197]=>[-0.358370963929988,0.19816249973475486] (9,-1; 9,-1), time: 30.0537s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_143, [-0.4082309901714325,0.9182475805282593]=>[1e-05,0.9182475805282593] (15,-1; -1,-1), time: 10.4364s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_28, [-0.000747978687286377,1.59181547164917]=>[1e-05,1.59181547164917] (15,-1; -1,-1), time: 0.3786s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_117, [-0.7504896521568298,0.43605464696884155]=>[-0.3678627273116405,0.11902336324750093] (9,-1; 9,-1), time: 30.0140s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_5, [-0.9034667611122131,0.38812243938446045]=>[-0.491319604845707,0.03515136155767398] (9,-1; 2,-1), time: 23.3308s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_172, [-1.037612795829773,0.35546526312828064]=>[-0.5980357594992288,0.0015779522529848567] (9,-1; 2,-1), time: 22.0489s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_93, [-0.7151739597320557,0.3886893689632416]=>[-0.3404023725994781,0.05098497743765488] (9,-1; 9,-1), time: 30.4147s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_168, [-0.3548986315727234,1.1209537982940674]=>[1e-05,1.1209537982940674] (15,-1; -1,-1), time: 5.6169s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_164, [-0.7905386090278625,0.6945816874504089]=>[-0.37355013780155055,0.35988808614576406] (9,-1; 2,-1), time: 19.8078s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_151, [-0.9584944248199463,0.9834954738616943]=>[-0.4958313218534013,0.44145944367438994] (2,-1; 9,-1), time: 23.5567s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_44, [-0.6750906705856323,0.32825762033462524]=>[-0.3345857844096806,0.03228176368035174] (9,-1; 9,-1), time: 30.2553s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_110, [-0.645150363445282,0.9636895656585693]=>[-0.09495493477985048,0.6211203479405666] (2,-1; 2,-1), time: 19.5125s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_0, [-0.8786801695823669,0.6205796003341675]=>[-0.5461439510578161,0.09935896731487204] (9,-1; 2,-1), time: 22.3358s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_124, [-0.6462392807006836,0.4974985122680664]=>[-0.23026307633062154,0.17092945989063316] (9,-1; 9,-1), time: 30.0456s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_122, [-0.9166884422302246,0.5033131241798401]=>[-0.47812444761243345,0.029343964354300058] (9,-1; 2,-1), time: 26.1228s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_177, [-0.8580449819564819,0.48225393891334534]=>[-0.3760329416647214,0.14250162291014445] (9,-1; 2,-1), time: 22.3171s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_51, [-0.4899595379829407,0.6315072178840637]=>[-0.09833511268796308,0.3274491249542136] (9,-1; 2,-1), time: 24.3047s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_37, [-0.609489917755127,0.5690419673919678]=>[-0.2514845209429491,0.17939661699246348] (9,-1; 9,-1), time: 30.0134s, #vars: 1767, #constrs: 1073, improved: True
Solving MIP for lay8_169, [-0.7547659873962402,0.5741223096847534]=>[-0.3418672711932664,0.2488529854690219] (9,-1; 9,-1), time: 30.0230s, #vars: 1767, #constrs: 1073, improved: True
Run alpha-CROWN after refining layer 6 and relu idx 2
0 /21 torch.Size([1, 200])
1 /23 torch.Size([1, 200])
2 /25 torch.Size([1, 200])
best_l after optimization: -23.80412483215332 with beta sum per layer: []
alpha/beta optimization time: 7.7832653522491455
alpha-CROWN with intermediate bounds by MIP: tensor([[ 4.8855,  2.4374, -1.8946,  4.7012,  3.4782,  5.1850,  0.6405,  1.3949,
          2.9760]], device='cuda:0', grad_fn=<AsStridedBackward>) None
MIP improved 110 nodes out of 110 unstable nodes, lb improved 20.246524810791016, ub improved 25.337034225463867, time 83.9604
maximum relu layer improved by MIP so far 3
Linear(in_features=200, out_features=200, bias=True) 4 10 torch.Size([200])
sorted candidates ['lay10_11', 'lay10_142', 'lay10_94', 'lay10_198', 'lay10_90', 'lay10_33', 'lay10_30', 'lay10_135', 'lay10_138', 'lay10_192', 'lay10_157', 'lay10_137', 'lay10_149', 'lay10_91', 'lay10_115', 'lay10_49', 'lay10_31', 'lay10_130', 'lay10_109', 'lay10_189', 'lay10_140', 'lay10_187', 'lay10_80', 'lay10_164', 'lay10_3', 'lay10_180', 'lay10_159', 'lay10_42', 'lay10_141', 'lay10_107', 'lay10_125', 'lay10_131', 'lay10_188', 'lay10_153', 'lay10_87', 'lay10_59', 'lay10_117', 'lay10_167', 'lay10_152', 'lay10_143', 'lay10_81', 'lay10_89', 'lay10_6', 'lay10_127', 'lay10_195', 'lay10_175', 'lay10_86', 'lay10_17', 'lay10_83', 'lay10_196', 'lay10_98', 'lay10_151', 'lay10_161', 'lay10_82', 'lay10_129', 'lay10_60', 'lay10_168', 'lay10_165', 'lay10_179', 'lay10_123', 'lay10_47', 'lay10_88', 'lay10_172', 'lay10_84', 'lay10_186', 'lay10_139', 'lay10_25', 'lay10_1', 'lay10_116', 'lay10_199', 'lay10_15', 'lay10_110', 'lay10_174', 'lay10_96', 'lay10_70', 'lay10_66', 'lay10_73', 'lay10_54', 'lay10_23', 'lay10_148', 'lay10_103', 'lay10_64', 'lay10_113', 'lay10_170', 'lay10_78', 'lay10_68', 'lay10_14', 'lay10_19', 'lay10_134', 'lay10_97', 'lay10_93', 'lay10_36', 'lay10_111', 'lay10_58', 'lay10_155', 'lay10_32', 'lay10_50', 'lay10_173', 'lay10_40', 'lay10_177', 'lay10_182', 'lay10_74', 'lay10_18', 'lay10_62', 'lay10_39', 'lay10_181', 'lay10_183', 'lay10_72', 'lay10_75', 'lay10_100', 'lay10_169', 'lay10_150', 'lay10_26', 'lay10_104', 'lay10_101', 'lay10_197', 'lay10_51', 'lay10_193', 'lay10_121', 'lay10_2', 'lay10_63', 'lay10_12', 'lay10_146', 'lay10_29', 'lay10_41', 'lay10_191', 'lay10_77', 'lay10_158', 'lay10_184', 'lay10_65', 'lay10_194', 'lay10_35', 'lay10_22', 'lay10_4', 'lay10_20', 'lay10_13', 'lay10_24', 'lay10_106', 'lay10_128', 'lay10_176', 'lay10_147', 'lay10_7', 'lay10_85', 'lay10_9', 'lay10_5', 'lay10_102', 'lay10_37', 'lay10_46', 'lay10_118', 'lay10_67', 'lay10_92', 'lay10_27', 'lay10_99', 'lay10_132', 'lay10_45', 'lay10_71', 'lay10_52', 'lay10_69', 'lay10_133', 'lay10_160', 'lay10_0', 'lay10_185', 'lay10_43', 'lay10_8', 'lay10_166', 'lay10_38', 'lay10_178', 'lay10_162', 'lay10_122', 'lay10_190', 'lay10_21', 'lay10_79', 'lay10_112', 'lay10_136', 'lay10_16', 'lay10_10', 'lay10_34', 'lay10_108', 'lay10_48', 'lay10_120', 'lay10_44'] filter: 1.0
Solving MIP for lay10_11, [-2.5106101036071777,0.5894607305526733]=>[-2.5106101036071777,-1e-05] (-1,-1; 15,-1), time: 0.4054s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_198, [-1.5811723470687866,0.4537813067436218]=>[-1.5811723470687866,-1e-05] (-1,-1; 15,-1), time: 0.4148s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_90, [-0.6051560044288635,1.8224300146102905]=>[1e-05,1.8224300146102905] (15,-1; -1,-1), time: 0.4247s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_115, [-1.5909006595611572,0.4981818199157715]=>[-1.5909006595611572,-1e-05] (-1,-1; 15,-1), time: 0.4344s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_157, [-1.70993971824646,0.5399654507637024]=>[-1.70993971824646,-1e-05] (-1,-1; 15,-1), time: 0.4355s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_30, [-0.5643693208694458,1.6239569187164307]=>[1e-05,1.6239569187164307] (15,-1; -1,-1), time: 0.4538s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_135, [-2.8979239463806152,0.21378576755523682]=>[-2.8979239463806152,-1e-05] (-1,-1; 15,-1), time: 0.4560s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_33, [-2.1375441551208496,0.2764316201210022]=>[-2.1375441551208496,-1e-05] (-1,-1; 15,-1), time: 0.4615s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_192, [-2.1926870346069336,0.5112789869308472]=>[-2.1926870346069336,-1e-05] (-1,-1; 15,-1), time: 0.4807s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_91, [-0.8272407650947571,1.7108862400054932]=>[1e-05,1.7108862400054932] (15,-1; -1,-1), time: 0.4812s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_49, [-1.5830670595169067,0.6886714100837708]=>[-1.5830670595169067,-1e-05] (-1,-1; 15,-1), time: 0.4878s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_137, [-2.1104135513305664,0.551787257194519]=>[-2.1104135513305664,-1e-05] (-1,-1; 15,-1), time: 0.5111s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_31, [-0.7326828241348267,1.3829898834228516]=>[1e-05,1.3829898834228516] (15,-1; -1,-1), time: 0.4063s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_189, [-2.4511311054229736,0.49378859996795654]=>[-2.4511311054229736,-1e-05] (-1,-1; 15,-1), time: 0.4265s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_109, [-2.293259382247925,0.6568658351898193]=>[-2.293259382247925,-1e-05] (-1,-1; 15,-1), time: 0.4472s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_140, [-1.8406177759170532,0.4459322690963745]=>[-1.8406177759170532,-1e-05] (-1,-1; 15,-1), time: 0.4655s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_164, [-1.9276659488677979,0.8220360279083252]=>[-1.9276659488677979,-1e-05] (-1,-1; 15,-1), time: 0.4722s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_80, [-1.7538782358169556,0.39559805393218994]=>[-1.7538782358169556,-1e-05] (-1,-1; 15,-1), time: 0.4796s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_187, [-0.4169873595237732,2.4058899879455566]=>[1e-05,2.4058899879455566] (15,-1; -1,-1), time: 0.4986s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_180, [-1.6572824716567993,0.444505512714386]=>[-1.6572824716567993,-1e-05] (-1,-1; 15,-1), time: 0.4856s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_159, [-0.2909057140350342,2.3828585147857666]=>[1e-05,2.3828585147857666] (15,-1; -1,-1), time: 0.4813s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_3, [-1.8480596542358398,0.21198540925979614]=>[-1.8480596542358398,-1e-05] (-1,-1; 15,-1), time: 0.5477s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_42, [-2.181905508041382,0.2954059839248657]=>[-2.181905508041382,-1e-05] (-1,-1; 15,-1), time: 0.5369s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_131, [-1.8987752199172974,0.31034767627716064]=>[-1.8987752199172974,-1e-05] (-1,-1; 15,-1), time: 0.5052s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_87, [-1.812053918838501,0.3767382502555847]=>[-1.812053918838501,-1e-05] (-1,-1; 15,-1), time: 0.4955s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_167, [-0.5761684775352478,2.486616611480713]=>[1e-05,2.486616611480713] (15,-1; -1,-1), time: 0.5181s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_143, [-1.761406421661377,0.45689237117767334]=>[-1.761406421661377,-1e-05] (-1,-1; 15,-1), time: 0.4613s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_125, [-1.5197737216949463,0.7662443518638611]=>[-1.5197737216949463,-1e-05] (-1,-1; 15,-1), time: 1.3392s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_117, [-2.194131374359131,0.8325433731079102]=>[-2.194131374359131,-1e-05] (-1,-1; 15,-1), time: 1.2710s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_6, [-1.3786066770553589,0.6200001239776611]=>[-1.3786066770553589,-1e-05] (-1,-1; 15,-1), time: 12.5876s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_175, [-0.7601403594017029,2.0821948051452637]=>[1e-05,2.0821948051452637] (15,-1; -1,-1), time: 0.4800s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_86, [-1.4404470920562744,0.7395764589309692]=>[-1.4404470920562744,-1e-05] (-1,-1; 15,-1), time: 7.6630s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_17, [-1.5594991445541382,0.7490836977958679]=>[-1.5594991445541382,-1e-05] (-1,-1; 15,-1), time: 0.4766s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_83, [-1.5182957649230957,0.5381390452384949]=>[-1.5182957649230957,-1e-05] (-1,-1; 15,-1), time: 0.5460s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_142, [-0.9456040859222412,1.2236456871032715]=>[-0.10983288982047708,0.35836800119597967] (9,-1; 9,-1), time: 30.0204s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_149, [-0.8761354684829712,1.0918611288070679]=>[-0.035397314811269315,0.45970524114699357] (9,-1; 9,-1), time: 30.0374s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_138, [-1.5500074625015259,0.9397872686386108]=>[-0.5620909129312487,0.14014343591371994] (9,-1; 9,-1), time: 30.3013s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_94, [-1.6132206916809082,1.0039423704147339]=>[-0.7326118136554297,0.06689616451355705] (9,-1; 9,-1), time: 30.3477s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_98, [-1.8954769372940063,0.38837307691574097]=>[-1.8954769372940063,-1e-05] (-1,-1; 15,-1), time: 0.4777s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_130, [-0.896641731262207,1.0932714939117432]=>[-0.014368195331035376,0.43115566982445297] (9,-1; 9,-1), time: 30.2178s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_82, [-1.9654184579849243,0.8309589624404907]=>[-1.9654184579849243,-1e-05] (-1,-1; 15,-1), time: 0.3598s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_161, [-1.4822360277175903,0.6027872562408447]=>[-1.4822360277175903,-1e-05] (-1,-1; 15,-1), time: 0.4523s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_141, [-1.5811489820480347,0.8146122694015503]=>[-0.5154934682716217,0.12246876380220725] (9,-1; 9,-1), time: 30.0556s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_129, [-1.598873257637024,0.4084259271621704]=>[-1.598873257637024,-1e-05] (-1,-1; 15,-1), time: 0.4535s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_60, [-2.032526969909668,0.07618612051010132]=>[-2.032526969909668,-1e-05] (-1,-1; 15,-1), time: 0.3527s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_153, [-1.574499487876892,1.3595936298370361]=>[-0.6596157460320982,0.45600453367431315] (9,-1; 9,-1), time: 30.2236s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_107, [-1.2329741716384888,0.7658571004867554]=>[-0.46066973880571305,0.05555568798822866] (9,-1; 9,-1), time: 30.3478s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_59, [-1.5016376972198486,1.8987650871276855]=>[-0.521098857734764,0.7499160707812857] (9,-1; 9,-1), time: 30.3278s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_152, [-1.1459964513778687,1.268066644668579]=>[-0.22071919387006295,0.4410795937257741] (9,-1; 9,-1), time: 30.5426s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_188, [-1.2747293710708618,2.0059759616851807]=>[-0.16867836199608877,0.9668764821012854] (9,-1; 9,-1), time: 30.8262s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_89, [-1.5289849042892456,0.9920812249183655]=>[-0.46044492535778364,0.1771108318324862] (9,-1; 9,-1), time: 30.2567s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_84, [-1.9827147722244263,0.25032734870910645]=>[-1.9827147722244263,-1e-05] (-1,-1; 15,-1), time: 0.5136s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_81, [-1.1396435499191284,0.8988463878631592]=>[-0.2757363930715857,0.14339886329306942] (9,-1; 9,-1), time: 30.5076s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_186, [-0.6590654850006104,2.085378885269165]=>[1e-05,2.085378885269165] (15,-1; -1,-1), time: 0.4751s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_179, [-1.7137956619262695,0.4901160001754761]=>[-1.7137956619262695,-1e-05] (-1,-1; 15,-1), time: 1.3295s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_25, [-1.7746026515960693,0.4803464710712433]=>[-1.7746026515960693,-1e-05] (-1,-1; 15,-1), time: 0.4419s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_1, [-1.9132567644119263,0.41429319977760315]=>[-1.9132567644119263,-1e-05] (-1,-1; 15,-1), time: 0.4503s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_195, [-0.9091605544090271,1.4008581638336182]=>[-0.08687661219444824,0.5769456522921027] (9,-1; 9,-1), time: 30.1301s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_116, [-1.6986578702926636,0.5490841269493103]=>[-1.6986578702926636,-1e-05] (-1,-1; 15,-1), time: 0.4219s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_127, [-1.216391682624817,0.8386800289154053]=>[-0.37250892395064,0.12624008488370111] (9,-1; 9,-1), time: 30.2996s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_199, [-2.02903413772583,0.13374918699264526]=>[-2.02903413772583,-1e-05] (-1,-1; 15,-1), time: 0.4351s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_15, [-2.0884652137756348,0.11700471490621567]=>[-2.0884652137756348,-1e-05] (-1,-1; 15,-1), time: 0.3739s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_70, [-2.034893035888672,0.42039597034454346]=>[-2.034893035888672,-1e-05] (-1,-1; 15,-1), time: 0.4896s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_54, [-1.9492989778518677,0.3618229925632477]=>[-1.9492989778518677,-1e-05] (-1,-1; 15,-1), time: 0.3568s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_66, [-0.6641730070114136,2.1814749240875244]=>[1e-05,2.1814749240875244] (15,-1; -1,-1), time: 0.4212s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_73, [-2.016387701034546,0.28207412362098694]=>[-2.016387701034546,-1e-05] (-1,-1; 15,-1), time: 0.4517s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_148, [-1.6394336223602295,0.23382800817489624]=>[-1.6394336223602295,-1e-05] (-1,-1; 15,-1), time: 0.3484s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_103, [-1.9545986652374268,0.2038595974445343]=>[-1.9545986652374268,-1e-05] (-1,-1; 15,-1), time: 0.4977s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_113, [-1.644705891609192,0.4778713583946228]=>[-1.644705891609192,-1e-05] (-1,-1; 15,-1), time: 0.4116s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_78, [-0.9495983123779297,1.3973232507705688]=>[1e-05,1.3973232507705688] (15,-1; -1,-1), time: 0.3635s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_96, [-0.8152939081192017,1.3114044666290283]=>[1e-05,1.3114044666290283] (15,-1; -1,-1), time: 1.7633s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_170, [-1.1834121942520142,2.45694899559021]=>[1e-05,2.45694899559021] (15,-1; -1,-1), time: 0.9270s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_68, [-1.8655942678451538,0.17224419116973877]=>[-1.8655942678451538,-1e-05] (-1,-1; 15,-1), time: 0.3806s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_14, [-1.5568045377731323,0.5207920074462891]=>[-1.5568045377731323,-1e-05] (-1,-1; 15,-1), time: 0.4393s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_97, [-0.6462106704711914,2.21412992477417]=>[1e-05,2.21412992477417] (15,-1; -1,-1), time: 0.5153s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_19, [-0.8834801912307739,1.5521448850631714]=>[1e-05,1.5521448850631714] (15,-1; -1,-1), time: 1.0060s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_93, [-2.256525754928589,0.11420684307813644]=>[-2.256525754928589,-1e-05] (-1,-1; 15,-1), time: 0.4342s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_36, [-2.121283531188965,0.4726191759109497]=>[-2.121283531188965,-1e-05] (-1,-1; 15,-1), time: 0.4074s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_111, [-1.5745400190353394,0.3932000994682312]=>[-1.5745400190353394,-1e-05] (-1,-1; 15,-1), time: 0.4949s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_58, [-1.9340600967407227,0.27205759286880493]=>[-1.9340600967407227,-1e-05] (-1,-1; 15,-1), time: 0.4358s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_155, [-0.7745149731636047,1.5695956945419312]=>[1e-05,1.5695956945419312] (15,-1; -1,-1), time: 0.4345s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_32, [-1.9550247192382812,0.3685746490955353]=>[-1.9550247192382812,-1e-05] (-1,-1; 15,-1), time: 0.4549s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_151, [-1.5008434057235718,0.7192034125328064]=>[-1.5008434057235718,-1e-05] (-1,-1; 15,-1), time: 7.3159s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_173, [-2.758043050765991,0.648727297782898]=>[-2.758043050765991,-1e-05] (-1,-1; 15,-1), time: 8.7651s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_50, [-1.0296746492385864,2.19734263420105]=>[1e-05,2.19734263420105] (15,-1; -1,-1), time: 10.4183s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_196, [-1.308068871498108,1.0205663442611694]=>[-0.27111983719914917,0.3166028222952424] (9,-1; 9,-1), time: 30.0163s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_74, [-0.19707664847373962,2.1878256797790527]=>[1e-05,2.1878256797790527] (15,-1; -1,-1), time: 0.5143s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_168, [-1.1947603225708008,0.8638574481010437]=>[-0.4534189931371976,0.04740222253193415] (9,-1; 9,-1), time: 30.1601s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_165, [-0.8516393303871155,1.6491587162017822]=>[-0.015405673378043157,0.7443829599011995] (9,-1; 9,-1), time: 30.4297s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_62, [-1.991750717163086,0.04478578642010689]=>[-1.991750717163086,-1e-05] (-1,-1; 15,-1), time: 0.4101s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_123, [-1.0409133434295654,1.062801480293274]=>[-0.19035486471307864,0.31117880864781916] (9,-1; 9,-1), time: 30.3802s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_47, [-1.62302565574646,0.9224936366081238]=>[-0.7219717170237469,0.03499075664590111] (9,-1; 9,-1), time: 30.4956s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_88, [-1.230027437210083,0.6804742217063904]=>[-0.32702748674521437,0.029491826587525267] (9,-1; 9,-1), time: 30.3566s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_183, [-2.0650887489318848,0.073320671916008]=>[-2.0650887489318848,-1e-05] (-1,-1; 15,-1), time: 0.3804s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_172, [-1.298876166343689,1.1232309341430664]=>[-0.2069699996519287,0.2877282994130186] (9,-1; 9,-1), time: 30.5740s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_139, [-1.3922996520996094,1.0230752229690552]=>[-0.3017017424791772,0.315197615615798] (9,-1; 9,-1), time: 30.0763s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_72, [-2.1525797843933105,0.4202183187007904]=>[-2.1525797843933105,-1e-05] (-1,-1; 15,-1), time: 0.3692s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_75, [-0.5294467210769653,2.759719133377075]=>[1e-05,2.759719133377075] (15,-1; -1,-1), time: 0.3737s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_100, [-2.0394299030303955,0.4262840151786804]=>[-2.0394299030303955,-1e-05] (-1,-1; 15,-1), time: 0.4036s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_174, [-1.0128264427185059,1.2210317850112915]=>[-0.06610571224471046,0.4671453054757012] (9,-1; 9,-1), time: 30.1942s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_110, [-1.2971676588058472,0.6788749098777771]=>[-0.35572009072254823,0.1349123482763747] (9,-1; 9,-1), time: 30.2468s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_101, [-0.5823937654495239,1.6465023756027222]=>[1e-05,1.6465023756027222] (15,-1; -1,-1), time: 0.4392s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_26, [-1.4959864616394043,0.8513416647911072]=>[-1.4959864616394043,-1e-05] (-1,-1; 15,-1), time: 1.0098s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_23, [-1.1677770614624023,0.647287130355835]=>[-0.30067483166581027,0.07841332663856886] (9,-1; 9,-1), time: 30.0639s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_51, [-2.1194305419921875,0.17977379262447357]=>[-2.1194305419921875,-1e-05] (-1,-1; 15,-1), time: 0.4563s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_64, [-0.9602311849594116,1.7305697202682495]=>[-0.12384732237357404,0.8300662524602114] (9,-1; 9,-1), time: 30.1493s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_12, [-0.8685114979743958,1.370261788368225]=>[1e-05,1.370261788368225] (15,-1; -1,-1), time: 0.8192s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_134, [-0.7661833763122559,1.1513193845748901]=>[-0.012564735237496887,0.4719823353012207] (9,-1; 9,-1), time: 30.3893s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_40, [-0.9298689961433411,1.1639081239700317]=>[-0.07057808827487597,0.4813251803957568] (9,-1; 9,-1), time: 30.0883s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_41, [-2.5409955978393555,0.1454879641532898]=>[-2.5409955978393555,-1e-05] (-1,-1; 15,-1), time: 0.3880s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_191, [-0.08629598468542099,2.4540951251983643]=>[1e-05,2.4540951251983643] (15,-1; -1,-1), time: 0.3783s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_169, [-1.2256442308425903,0.5063610076904297]=>[-1.2256442308425903,-1e-05] (-1,-1; 15,-1), time: 8.7389s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_158, [-1.8533979654312134,0.3850436210632324]=>[-1.8533979654312134,-1e-05] (-1,-1; 15,-1), time: 0.4928s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_184, [-2.373464345932007,0.061025772243738174]=>[-2.373464345932007,-1e-05] (-1,-1; 15,-1), time: 0.4897s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_65, [-1.4493155479431152,0.40048789978027344]=>[-1.4493155479431152,-1e-05] (-1,-1; 15,-1), time: 0.4647s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_194, [-2.204033613204956,0.366412490606308]=>[-2.204033613204956,-1e-05] (-1,-1; 15,-1), time: 0.4595s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_63, [-2.1315743923187256,0.7220710515975952]=>[-2.1315743923187256,-1e-05] (-1,-1; 15,-1), time: 9.9085s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_35, [-1.7307085990905762,0.3704426884651184]=>[-1.7307085990905762,-1e-05] (-1,-1; 15,-1), time: 0.4095s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_22, [-1.6403751373291016,0.4924163222312927]=>[-1.6403751373291016,-1e-05] (-1,-1; 15,-1), time: 0.4060s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_4, [-2.266958475112915,0.02694912627339363]=>[-2.266958475112915,-1e-05] (-1,-1; 15,-1), time: 0.4667s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_20, [-0.22441262006759644,2.0545685291290283]=>[1e-05,2.0545685291290283] (15,-1; -1,-1), time: 0.5173s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_13, [-1.6309515237808228,0.37774449586868286]=>[-1.6309515237808228,-1e-05] (-1,-1; 15,-1), time: 0.4794s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_24, [-1.5805625915527344,0.6085573434829712]=>[-1.5805625915527344,-1e-05] (-1,-1; 15,-1), time: 0.4423s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_128, [-1.9628841876983643,0.08147160708904266]=>[-1.9628841876983643,-1e-05] (-1,-1; 15,-1), time: 0.4229s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_176, [-0.45000797510147095,2.3267993927001953]=>[1e-05,2.3267993927001953] (15,-1; -1,-1), time: 0.5256s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_147, [-2.1260411739349365,0.08610853552818298]=>[-2.1260411739349365,-1e-05] (-1,-1; 15,-1), time: 0.4831s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_177, [-1.2803411483764648,1.404078722000122]=>[-0.3675764918140434,0.49268424392023646] (9,-1; 9,-1), time: 30.3656s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_7, [-2.385324239730835,0.31352394819259644]=>[-2.385324239730835,-1e-05] (-1,-1; 15,-1), time: 0.4360s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_85, [-0.6782645583152771,1.5868403911590576]=>[1e-05,1.5868403911590576] (15,-1; -1,-1), time: 0.4427s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_9, [-0.32205861806869507,1.8947384357452393]=>[1e-05,1.8947384357452393] (15,-1; -1,-1), time: 0.4522s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_5, [-0.17574644088745117,2.305941581726074]=>[1e-05,2.305941581726074] (15,-1; -1,-1), time: 0.5099s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_182, [-1.4195867776870728,0.821233332157135]=>[-0.4634248922241588,0.11073945502540845] (9,-1; 9,-1), time: 30.0108s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_102, [-0.20523309707641602,2.475283622741699]=>[1e-05,2.475283622741699] (15,-1; -1,-1), time: 0.4280s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_37, [-2.762073516845703,0.013286471366882324]=>[-2.762073516845703,-1e-05] (-1,-1; 15,-1), time: 0.5164s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_118, [-2.189197540283203,0.1106218695640564]=>[-2.189197540283203,-1e-05] (-1,-1; 15,-1), time: 0.4133s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_92, [-1.8243112564086914,0.5013564825057983]=>[-1.8243112564086914,-1e-05] (-1,-1; 15,-1), time: 0.3994s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_67, [-2.1155622005462646,0.771599531173706]=>[-2.1155622005462646,-1e-05] (-1,-1; 15,-1), time: 0.7420s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_27, [-1.5961239337921143,0.5899529457092285]=>[-1.5961239337921143,-1e-05] (-1,-1; 15,-1), time: 0.3947s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_18, [-1.6507363319396973,1.1727436780929565]=>[-0.5087563996055489,0.2997747963149414] (9,-1; 9,-1), time: 30.2896s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_45, [-1.9682363271713257,0.5447266101837158]=>[-1.9682363271713257,-1e-05] (-1,-1; 15,-1), time: 0.5113s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_39, [-1.0747512578964233,0.9101583957672119]=>[-0.23654256728137107,0.14906725306148932] (9,-1; 9,-1), time: 30.0409s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_181, [-1.3483970165252686,1.1487617492675781]=>[-0.2722056674598961,0.41875419346766635] (9,-1; 9,-1), time: 30.1504s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_2, [-1.084474802017212,1.4194802045822144]=>[-0.01498784278861098,0.6555421963760457] (9,-1; 2,-1), time: 28.7394s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_150, [-0.882727861404419,1.3515441417694092]=>[-0.011779617069577322,0.5383790204186312] (9,-1; 9,-1), time: 30.2133s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_104, [-1.426351547241211,0.6070969700813293]=>[-0.5827962746542594,0.028563406933626197] (9,-1; 9,-1), time: 30.2234s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_133, [-0.45798125863075256,1.9345062971115112]=>[1e-05,1.9345062971115112] (15,-1; -1,-1), time: 0.4249s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_0, [-2.138648509979248,0.33572256565093994]=>[-2.138648509979248,-1e-05] (-1,-1; 15,-1), time: 0.3582s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_185, [-1.8922145366668701,0.47921231389045715]=>[-1.8922145366668701,-1e-05] (-1,-1; 15,-1), time: 0.4512s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_193, [-1.1131218671798706,1.530379295349121]=>[-0.12920187402604813,0.593787819081393] (9,-1; 9,-1), time: 30.0375s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_121, [-1.106860876083374,0.9191932082176208]=>[-0.22768275732501622,0.2186010125317335] (9,-1; 9,-1), time: 30.0177s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_197, [-1.459967851638794,1.0651140213012695]=>[-0.4995977355766078,0.13591691055391183] (9,-1; 9,-1), time: 30.4238s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_8, [-2.2958149909973145,0.21417485177516937]=>[-2.2958149909973145,-1e-05] (-1,-1; 15,-1), time: 0.4248s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_166, [-2.3750052452087402,0.15976262092590332]=>[-2.3750052452087402,-1e-05] (-1,-1; 15,-1), time: 0.4095s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_38, [-1.4971312284469604,0.43854445219039917]=>[-1.4971312284469604,-1e-05] (-1,-1; 15,-1), time: 0.3731s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_178, [-0.8436752557754517,1.3340567350387573]=>[1e-05,1.3340567350387573] (15,-1; -1,-1), time: 0.4490s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_162, [-2.329099655151367,0.047364041209220886]=>[-2.329099655151367,-1e-05] (-1,-1; 15,-1), time: 0.4609s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_190, [-0.3427649736404419,2.8647031784057617]=>[1e-05,2.8647031784057617] (15,-1; -1,-1), time: 0.3862s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_79, [-2.068258762359619,0.37016749382019043]=>[-2.068258762359619,-1e-05] (-1,-1; 15,-1), time: 0.4194s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_112, [-1.9259989261627197,0.3808668553829193]=>[-1.9259989261627197,-1e-05] (-1,-1; 15,-1), time: 0.4020s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_136, [-0.0625440776348114,2.3163647651672363]=>[1e-05,2.3163647651672363] (15,-1; -1,-1), time: 0.4437s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_146, [-1.0865862369537354,1.573655605316162]=>[-0.041450287918184954,0.6889742725443972] (9,-1; 9,-1), time: 30.4102s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_16, [-1.7044837474822998,0.7359132766723633]=>[-1.7044837474822998,-1e-05] (-1,-1; 15,-1), time: 0.3803s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_108, [-1.6041555404663086,0.5136054158210754]=>[-1.6041555404663086,-1e-05] (-1,-1; 15,-1), time: 0.3792s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_10, [-2.0736002922058105,0.5267727971076965]=>[-2.0736002922058105,-1e-05] (-1,-1; 15,-1), time: 0.5151s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_160, [-1.9951874017715454,0.6462734937667847]=>[-1.9951874017715454,-1e-05] (-1,-1; 15,-1), time: 2.9231s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_29, [-1.1876554489135742,1.361885905265808]=>[-0.2052394772024786,0.5863869626824624] (9,-1; 9,-1), time: 30.3470s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_48, [-1.920449137687683,0.002312363125383854]=>[-1.920449137687683,-1e-05] (-1,-1; 15,-1), time: 0.3753s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_120, [-2.062293767929077,0.1327652931213379]=>[-2.062293767929077,-1e-05] (-1,-1; 15,-1), time: 0.5095s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_69, [-1.7198529243469238,0.7281355857849121]=>[-1.7198529243469238,-1e-05] (-1,-1; 15,-1), time: 6.4841s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_77, [-1.8335704803466797,1.4151215553283691]=>[-0.5209058072639552,0.42869884635878197] (9,-1; 9,-1), time: 30.2185s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_43, [-2.2598938941955566,0.8289517760276794]=>[-2.2598938941955566,-1e-05] (-1,-1; 15,-1), time: 8.0938s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_122, [-0.9292103052139282,1.3744170665740967]=>[1e-05,1.3744170665740967] (15,-1; -1,-1), time: 8.5994s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_106, [-1.338470458984375,0.9791570901870728]=>[-0.2905271269278314,0.2204373081720467] (9,-1; 9,-1), time: 30.4588s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_46, [-1.0142464637756348,1.2153230905532837]=>[-0.1246584775519711,0.4391931521766988] (9,-1; 9,-1), time: 30.5159s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_99, [-1.1168699264526367,1.2406361103057861]=>[-0.13525889382584444,0.4601804849094259] (9,-1; 9,-1), time: 30.2667s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_132, [-0.8912858366966248,1.2260193824768066]=>[-0.021752954391722194,0.3569288908992139] (9,-1; 9,-1), time: 30.4746s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_71, [-1.4293378591537476,0.9637940526008606]=>[-0.4943168157648672,0.10260516139911806] (9,-1; 9,-1), time: 30.3119s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_52, [-1.5120353698730469,0.6385749578475952]=>[-0.29950600565825636,0.16869629606197994] (9,-1; 9,-1), time: 30.1514s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_21, [-1.2398794889450073,0.9412199258804321]=>[-0.25183213914382907,0.19731325449927845] (9,-1; 9,-1), time: 30.6860s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_34, [-1.2918834686279297,0.8627264499664307]=>[-0.3342369943256954,0.3022794007072256] (9,-1; 9,-1), time: 30.6774s, #vars: 2039, #constrs: 1381, improved: True
Solving MIP for lay10_44, [-1.082405924797058,1.085932970046997]=>[-0.3074957682629437,0.29391812489612956] (9,-1; 9,-1), time: 30.4183s, #vars: 2039, #constrs: 1381, improved: True
Run alpha-CROWN after refining layer 8 and relu idx 3
0 /21 torch.Size([1, 200])
1 /23 torch.Size([1, 200])
2 /25 torch.Size([1, 200])
3 /27 torch.Size([1, 200])
best_l after optimization: -30.961421966552734 with beta sum per layer: []
alpha/beta optimization time: 7.374706745147705
alpha-CROWN with intermediate bounds by MIP: tensor([[ 5.7209,  3.3615, -1.2354,  5.6431,  4.2877,  5.7957,  1.5203,  2.0494,
          3.8183]], device='cuda:0', grad_fn=<AsStridedBackward>) None
MIP improved 181 nodes out of 181 unstable nodes, lb improved 68.31167602539062, ub improved 80.5732650756836, time 126.1625
maximum relu layer improved by MIP so far 4
Linear(in_features=200, out_features=10, bias=True) 5 12 torch.Size([10])
MIP finished with 253.04846858978271s
Run final alpha-CROWN after MIP solving on layer 12 and relu idx 5
0 /21 torch.Size([1, 200])
1 /23 torch.Size([1, 200])
2 /25 torch.Size([1, 200])
3 /27 torch.Size([1, 200])
4 /29 torch.Size([1, 200])
best_l after optimization: -32.55141067504883 with beta sum per layer: []
alpha/beta optimization time: 5.56870436668396
alpha-CROWN with intermediate bounds improved by MIP: tensor([[ 5.8496,  3.5679, -1.0178,  5.7947,  4.4677,  5.8737,  1.7206,  2.2642,
          4.0308]], device='cuda:0', grad_fn=<AsStridedBackward>) None
refined global lb: tensor([[ 5.8496,  3.5679,  0.0000, -1.0178,  5.7947,  4.4677,  5.8737,  1.7206,
          2.2642,  4.0308]], device='cuda:0') min: tensor(-1.0178, device='cuda:0')
time threshold left for bab: 632.4599561691284
##### [0:199] Tested against 3 ######
Model prediction is: tensor([[-2.2822, -0.0930,  5.9459,  3.8994, -2.5546, -2.1217, -2.1716,  2.3568,
          0.9355, -1.2078]], device='cuda:0')
alpha-CROWN optimizable variables initialized.
setting alpha for layer /22 start_node /23
setting alpha for layer /22 start_node /25
setting alpha for layer /22 start_node /27
setting alpha for layer /22 start_node /29
not setting layer /22 start_node /31 because shape mismatch (torch.Size([2, 1, 1, 200]) != torch.Size([2, 9, 1, 200]))
setting alpha for layer /24 start_node /25
setting alpha for layer /24 start_node /27
setting alpha for layer /24 start_node /29
not setting layer /24 start_node /31 because shape mismatch (torch.Size([2, 1, 1, 200]) != torch.Size([2, 9, 1, 200]))
setting alpha for layer /26 start_node /27
setting alpha for layer /26 start_node /29
not setting layer /26 start_node /31 because shape mismatch (torch.Size([2, 1, 1, 200]) != torch.Size([2, 9, 1, 200]))
setting alpha for layer /28 start_node /29
not setting layer /28 start_node /31 because shape mismatch (torch.Size([2, 1, 1, 200]) != torch.Size([2, 9, 1, 200]))
not setting layer /30 start_node /31 because shape mismatch (torch.Size([2, 1, 1, 200]) != torch.Size([2, 9, 1, 200]))
0 /21 torch.Size([1, 200])
1 /23 torch.Size([1, 200])
2 /25 torch.Size([1, 200])
3 /27 torch.Size([1, 200])
4 /29 torch.Size([1, 200])
best_l after optimization: 1.017799973487854 with beta sum per layer: []
alpha/beta optimization time: 1.7371294498443604
alpha-CROWN with fixed intermediate bounds: tensor([[-1.0178]], device='cuda:0', grad_fn=<AsStridedBackward>) None
-1.017799973487854
layer 0 size torch.Size([200]) unstable 23
layer 1 size torch.Size([200]) unstable 34
layer 2 size torch.Size([200]) unstable 34
layer 3 size torch.Size([200]) unstable 36
layer 4 size torch.Size([200]) unstable 52
-----------------
# of unstable neurons: 179
-----------------

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1, 200]) pre split depth:  6
batch:  torch.Size([1, 200]) post split depth:  6
splitting decisions: 
split level 0: [3, 45] 
split level 1: [0, 29] 
split level 2: [0, 53] 
split level 3: [0, 148] 
split level 4: [4, 153] 
split level 5: [0, 199] 
regular batch size: 2*32, diving batch size 1*0
best_l after optimization: -4.121577262878418 with beta sum per layer: [33.605140686035156, 0.0, 0.0, 4.197902202606201, 9.532638549804688]
alpha/beta optimization time: 0.3607349395751953
This batch time : update_bounds func: 0.3769	 prepare: 0.0076	 bound: 0.3612	 transfer: 0.0012	 finalize: 0.0067
Accumulated time: update_bounds func: 0.3769	 prepare: 0.0076	 bound: 0.3612	 transfer: 0.0012	 finalize: 0.0067
batch bounding time:  0.37728404998779297
Current worst splitting domains [lb, ub] (depth):
[-0.78809,   inf] (7), [-0.68197,   inf] (7), [-0.57601,   inf] (7), [-0.47024,   inf] (7), [-0.42205,   inf] (7), [-0.30278,   inf] (7), [-0.28551,   inf] (7), [-0.22004,   inf] (7), [-0.21356,   inf] (7), [-0.18510,   inf] (7), [-0.14418,   inf] (7), [-0.09908,   inf] (7), [-0.09127,   inf] (7), [-0.06598,   inf] (7), [-0.03757,   inf] (7), 
length of domains: 15
Total time: 0.4421	 pickout: 0.0013	 decision: 0.0515	 get_bound: 0.3881	 add_domain: 0.0011
Current lb:-0.7880949378013611
64 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 2.6377811431884766

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([15, 200]) pre split depth:  2
batch:  torch.Size([15, 200]) post split depth:  2
splitting decisions: 
split level 0: [2, 23] [2, 23] [2, 23] [2, 23] [2, 23] [2, 23] [2, 23] [2, 23] [2, 23] [2, 23] 
split level 1: [2, 130] [2, 130] [2, 130] [2, 130] [2, 130] [2, 130] [0, 190] [2, 130] [0, 190] [2, 130] 
regular batch size: 2*30, diving batch size 1*0
best_l after optimization: -8.038064002990723 with beta sum per layer: [62.670040130615234, 0.0, 4.478219985961914, 0.0, 19.567331314086914]
alpha/beta optimization time: 0.36267590522766113
This batch time : update_bounds func: 0.3804	 prepare: 0.0096	 bound: 0.3631	 transfer: 0.0012	 finalize: 0.0064
Accumulated time: update_bounds func: 0.7573	 prepare: 0.0171	 bound: 0.7243	 transfer: 0.0012	 finalize: 0.0131
batch bounding time:  0.3806145191192627
Current worst splitting domains [lb, ub] (depth):
[-0.78809,   inf] (10), [-0.67715,   inf] (10), [-0.55573,   inf] (10), [-0.43823,   inf] (10), [-0.35148,   inf] (10), [-0.19649,   inf] (10), [-0.10113,   inf] (10), [-0.03548,   inf] (10), [-0.02915,   inf] (10), 
length of domains: 9
Total time: 0.4207	 pickout: 0.0036	 decision: 0.0302	 get_bound: 0.3862	 add_domain: 0.0006
Current lb:-0.7880949378013611
124 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.059161901473999

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([9, 200]) pre split depth:  3
batch:  torch.Size([9, 200]) post split depth:  3
splitting decisions: 
split level 0: [1, 40] [1, 40] [0, 190] [0, 190] [0, 190] [0, 190] [0, 190] [0, 190] [4, 188] 
split level 1: [0, 190] [0, 190] [1, 40] [1, 40] [1, 40] [1, 40] [1, 40] [1, 173] [0, 190] 
split level 2: [1, 173] [1, 173] [1, 173] [1, 173] [1, 173] [1, 173] [1, 173] [1, 40] [1, 173] 
regular batch size: 2*36, diving batch size 1*0
best_l after optimization: 2.246777057647705 with beta sum per layer: [104.51068115234375, 23.22625732421875, 6.302959442138672, 0.0, 0.0]
alpha/beta optimization time: 0.37419700622558594
This batch time : update_bounds func: 0.3951	 prepare: 0.0118	 bound: 0.3746	 transfer: 0.0012	 finalize: 0.0072
Accumulated time: update_bounds func: 1.1525	 prepare: 0.0290	 bound: 1.0989	 transfer: 0.0012	 finalize: 0.0203
batch bounding time:  0.3954603672027588
Current worst splitting domains [lb, ub] (depth):
[-0.64151,   inf] (14), [-0.53464,   inf] (14), [-0.52748,   inf] (14), [-0.52568,   inf] (14), [-0.43630,   inf] (14), [-0.42348,   inf] (14), [-0.42039,   inf] (14), [-0.39256,   inf] (14), [-0.38951,   inf] (14), [-0.35628,   inf] (14), [-0.33292,   inf] (14), [-0.30509,   inf] (14), [-0.29029,   inf] (14), [-0.28331,   inf] (14), [-0.26095,   inf] (14), [-0.25884,   inf] (14), [-0.25721,   inf] (14), [-0.25458,   inf] (14), [-0.20571,   inf] (14), [-0.19218,   inf] (14), 
length of domains: 34
Total time: 0.4404	 pickout: 0.0027	 decision: 0.0295	 get_bound: 0.4058	 add_domain: 0.0024
Current lb:-0.6415097713470459
196 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.50046443939209

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([34, 200]) pre split depth:  1
batch:  torch.Size([34, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 188] [4, 188] [4, 188] [4, 188] [4, 188] [4, 188] [4, 188] [4, 188] [4, 188] [4, 188] 
regular batch size: 2*34, diving batch size 1*0
best_l after optimization: 0.9143103361129761 with beta sum per layer: [84.87449645996094, 46.02747344970703, 0.0, 0.0, 4.17207145690918]
alpha/beta optimization time: 0.35735201835632324
This batch time : update_bounds func: 0.3772	 prepare: 0.0115	 bound: 0.3578	 transfer: 0.0009	 finalize: 0.0068
Accumulated time: update_bounds func: 1.5296	 prepare: 0.0405	 bound: 1.4567	 transfer: 0.0009	 finalize: 0.0270
batch bounding time:  0.3773534297943115
Current worst splitting domains [lb, ub] (depth):
[-0.63915,   inf] (16), [-0.52747,   inf] (16), [-0.52149,   inf] (16), [-0.51737,   inf] (16), [-0.42446,   inf] (16), [-0.41182,   inf] (16), [-0.40987,   inf] (16), [-0.37799,   inf] (16), [-0.31803,   inf] (16), [-0.29655,   inf] (16), [-0.28931,   inf] (16), [-0.27690,   inf] (16), [-0.24023,   inf] (16), [-0.23848,   inf] (16), [-0.19199,   inf] (16), [-0.18649,   inf] (16), [-0.18355,   inf] (16), [-0.17226,   inf] (16), [-0.16943,   inf] (16), [-0.16488,   inf] (16), 
length of domains: 29
Total time: 0.4193	 pickout: 0.0073	 decision: 0.0325	 get_bound: 0.3775	 add_domain: 0.0020
Current lb:-0.6391513347625732
264 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 3.920727252960205

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([29, 200]) pre split depth:  1
batch:  torch.Size([29, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 188] [0, 188] [0, 188] [0, 188] [0, 188] [0, 188] [0, 188] [0, 188] [0, 188] [0, 188] 
regular batch size: 2*29, diving batch size 1*0
best_l after optimization: 3.369248628616333 with beta sum per layer: [80.35189819335938, 48.06449508666992, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.3591458797454834
This batch time : update_bounds func: 0.3769	 prepare: 0.0101	 bound: 0.3596	 transfer: 0.0011	 finalize: 0.0059
Accumulated time: update_bounds func: 1.9065	 prepare: 0.0507	 bound: 1.8163	 transfer: 0.0011	 finalize: 0.0329
batch bounding time:  0.37715816497802734
Current worst splitting domains [lb, ub] (depth):
[-0.59908,   inf] (18), [-0.48529,   inf] (18), [-0.48505,   inf] (18), [-0.48016,   inf] (18), [-0.38981,   inf] (18), [-0.37836,   inf] (18), [-0.36739,   inf] (18), [-0.33483,   inf] (18), [-0.28305,   inf] (18), [-0.25458,   inf] (18), [-0.21654,   inf] (18), [-0.21495,   inf] (18), [-0.19321,   inf] (18), [-0.19050,   inf] (18), [-0.14927,   inf] (18), [-0.13790,   inf] (18), [-0.12808,   inf] (18), [-0.10941,   inf] (18), [-0.10483,   inf] (18), [-0.09930,   inf] (18), 
length of domains: 29
Total time: 0.4175	 pickout: 0.0060	 decision: 0.0318	 get_bound: 0.3773	 add_domain: 0.0023
Current lb:-0.5990821719169617
322 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.339215278625488

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([29, 200]) pre split depth:  1
batch:  torch.Size([29, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 159] [0, 159] [0, 45] [0, 159] [0, 45] [0, 45] [0, 159] [0, 159] [0, 45] [0, 45] 
regular batch size: 2*29, diving batch size 1*0
best_l after optimization: 2.088836193084717 with beta sum per layer: [73.75814819335938, 55.275428771972656, 0.0, 0.0, 0.0]
alpha/beta optimization time: 0.36757421493530273
This batch time : update_bounds func: 0.3858	 prepare: 0.0103	 bound: 0.3680	 transfer: 0.0010	 finalize: 0.0063
Accumulated time: update_bounds func: 2.2924	 prepare: 0.0610	 bound: 2.1843	 transfer: 0.0010	 finalize: 0.0392
batch bounding time:  0.3860290050506592
Current worst splitting domains [lb, ub] (depth):
[-0.59474,   inf] (20), [-0.47830,   inf] (20), [-0.47431,   inf] (20), [-0.45674,   inf] (20), [-0.35930,   inf] (20), [-0.35909,   inf] (20), [-0.34756,   inf] (20), [-0.32694,   inf] (20), [-0.25087,   inf] (20), [-0.22318,   inf] (20), [-0.18315,   inf] (20), [-0.17960,   inf] (20), [-0.15202,   inf] (20), [-0.15175,   inf] (20), [-0.11592,   inf] (20), [-0.09256,   inf] (20), [-0.09237,   inf] (20), [-0.08833,   inf] (20), [-0.06348,   inf] (20), [-0.03931,   inf] (20), 
length of domains: 25
Total time: 0.4263	 pickout: 0.0063	 decision: 0.0315	 get_bound: 0.3861	 add_domain: 0.0025
Current lb:-0.594737708568573
380 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 4.766417503356934

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([25, 200]) pre split depth:  2
batch:  torch.Size([25, 200]) post split depth:  2
splitting decisions: 
split level 0: [0, 45] [0, 45] [0, 45] [1, 50] [0, 45] [1, 50] [1, 50] [0, 45] [1, 50] [1, 50] 
split level 1: [1, 50] [1, 50] [1, 50] [1, 94] [1, 50] [1, 94] [1, 94] [1, 50] [1, 94] [1, 94] 
regular batch size: 2*50, diving batch size 1*0
best_l after optimization: 1.7835259437561035 with beta sum per layer: [105.75135803222656, 140.19412231445312, 0.0, 2.2174220085144043, 0.0]
alpha/beta optimization time: 0.4043126106262207
This batch time : update_bounds func: 0.4415	 prepare: 0.0209	 bound: 0.4048	 transfer: 0.0014	 finalize: 0.0139
Accumulated time: update_bounds func: 2.7339	 prepare: 0.0820	 bound: 2.5891	 transfer: 0.0014	 finalize: 0.0531
batch bounding time:  0.4418215751647949
Current worst splitting domains [lb, ub] (depth):
[-0.53099,   inf] (23), [-0.41302,   inf] (23), [-0.41062,   inf] (23), [-0.39004,   inf] (23), [-0.36621,   inf] (23), [-0.29432,   inf] (23), [-0.28943,   inf] (23), [-0.28260,   inf] (23), [-0.27106,   inf] (23), [-0.26028,   inf] (23), [-0.24621,   inf] (23), [-0.24210,   inf] (23), [-0.19311,   inf] (23), [-0.17964,   inf] (23), [-0.16233,   inf] (23), [-0.15297,   inf] (23), [-0.15218,   inf] (23), [-0.12400,   inf] (23), [-0.11355,   inf] (23), [-0.11353,   inf] (23), 
length of domains: 35
Total time: 0.4972	 pickout: 0.0055	 decision: 0.0346	 get_bound: 0.4540	 add_domain: 0.0031
Current lb:-0.5309906005859375
480 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.2649126052856445

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([35, 200]) pre split depth:  1
batch:  torch.Size([35, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 169] [3, 169] [3, 169] [3, 169] [3, 169] [3, 169] [3, 169] [3, 169] [0, 159] [1, 94] 
regular batch size: 2*35, diving batch size 1*0
best_l after optimization: 5.034578800201416 with beta sum per layer: [58.03681182861328, 95.88319396972656, 0.0, 12.714886665344238, 0.0]
alpha/beta optimization time: 0.4246678352355957
This batch time : update_bounds func: 0.4549	 prepare: 0.0187	 bound: 0.4252	 transfer: 0.0012	 finalize: 0.0097
Accumulated time: update_bounds func: 3.1888	 prepare: 0.1007	 bound: 3.0144	 transfer: 0.0012	 finalize: 0.0628
batch bounding time:  0.4551849365234375
Current worst splitting domains [lb, ub] (depth):
[-0.50969,   inf] (25), [-0.39546,   inf] (25), [-0.38805,   inf] (25), [-0.38634,   inf] (25), [-0.36934,   inf] (25), [-0.29659,   inf] (25), [-0.28603,   inf] (25), [-0.28188,   inf] (25), [-0.26635,   inf] (25), [-0.26343,   inf] (25), [-0.26070,   inf] (25), [-0.24674,   inf] (25), [-0.23755,   inf] (25), [-0.23590,   inf] (25), [-0.17953,   inf] (25), [-0.17262,   inf] (25), [-0.16047,   inf] (25), [-0.15498,   inf] (25), [-0.15296,   inf] (25), [-0.15111,   inf] (25), 
length of domains: 41
Total time: 0.5097	 pickout: 0.0106	 decision: 0.0402	 get_bound: 0.4553	 add_domain: 0.0036
Current lb:-0.509688138961792
550 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 5.775713920593262

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([41, 200]) pre split depth:  1
batch:  torch.Size([41, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 94] [1, 72] [1, 94] [1, 94] [1, 132] [1, 94] [1, 72] [1, 72] [1, 94] [3, 37] 
regular batch size: 2*41, diving batch size 1*0
best_l after optimization: 6.126564025878906 with beta sum per layer: [58.485347747802734, 118.34526062011719, 0.0, 35.896522521972656, 0.0]
alpha/beta optimization time: 0.41903257369995117
This batch time : update_bounds func: 0.4545	 prepare: 0.0214	 bound: 0.4197	 transfer: 0.0012	 finalize: 0.0119
Accumulated time: update_bounds func: 3.6433	 prepare: 0.1221	 bound: 3.4340	 transfer: 0.0012	 finalize: 0.0747
batch bounding time:  0.4546785354614258
Current worst splitting domains [lb, ub] (depth):
[-0.48912,   inf] (27), [-0.36576,   inf] (27), [-0.36557,   inf] (27), [-0.36157,   inf] (27), [-0.32937,   inf] (27), [-0.31253,   inf] (27), [-0.27844,   inf] (27), [-0.25862,   inf] (27), [-0.25400,   inf] (27), [-0.25331,   inf] (27), [-0.24389,   inf] (27), [-0.23934,   inf] (27), [-0.22217,   inf] (27), [-0.21657,   inf] (27), [-0.21531,   inf] (27), [-0.21362,   inf] (27), [-0.19508,   inf] (27), [-0.18303,   inf] (27), [-0.17684,   inf] (27), [-0.17010,   inf] (27), 
length of domains: 50
Total time: 0.5129	 pickout: 0.0121	 decision: 0.0416	 get_bound: 0.4548	 add_domain: 0.0045
Current lb:-0.48911958932876587
632 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.289708614349365

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([50, 200]) pre split depth:  1
batch:  torch.Size([50, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 132] [1, 132] [1, 132] [4, 29] [4, 29] [4, 29] [1, 132] [1, 132] [4, 29] [4, 29] 
regular batch size: 2*50, diving batch size 1*0
best_l after optimization: 4.480965614318848 with beta sum per layer: [67.46865844726562, 128.70571899414062, 0.0, 51.912315368652344, 5.726912975311279]
alpha/beta optimization time: 0.37691473960876465
This batch time : update_bounds func: 0.4144	 prepare: 0.0251	 bound: 0.3775	 transfer: 0.0014	 finalize: 0.0102
Accumulated time: update_bounds func: 4.0577	 prepare: 0.1472	 bound: 3.8115	 transfer: 0.0014	 finalize: 0.0849
batch bounding time:  0.4148385524749756
Current worst splitting domains [lb, ub] (depth):
[-0.45839,   inf] (29), [-0.38320,   inf] (29), [-0.35726,   inf] (29), [-0.33529,   inf] (29), [-0.33151,   inf] (29), [-0.32537,   inf] (29), [-0.30775,   inf] (29), [-0.28045,   inf] (29), [-0.25037,   inf] (29), [-0.24893,   inf] (29), [-0.24588,   inf] (29), [-0.23482,   inf] (29), [-0.22090,   inf] (29), [-0.21712,   inf] (29), [-0.21019,   inf] (29), [-0.20772,   inf] (29), [-0.20259,   inf] (29), [-0.20141,   inf] (29), [-0.18899,   inf] (29), [-0.18175,   inf] (29), 
length of domains: 52
Total time: 0.4794	 pickout: 0.0144	 decision: 0.0449	 get_bound: 0.4150	 add_domain: 0.0051
Current lb:-0.4583928883075714
732 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 6.770884275436401

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([52, 200]) pre split depth:  1
batch:  torch.Size([52, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 29] [4, 29] [1, 94] [4, 29] [4, 29] [1, 72] [1, 72] [4, 29] [1, 94] [1, 94] 
regular batch size: 2*52, diving batch size 1*0
best_l after optimization: 4.493027210235596 with beta sum per layer: [67.43555450439453, 144.71087646484375, 1.1849018335342407, 46.040626525878906, 6.60158634185791]
alpha/beta optimization time: 0.35691356658935547
This batch time : update_bounds func: 0.3867	 prepare: 0.0179	 bound: 0.3573	 transfer: 0.0013	 finalize: 0.0099
Accumulated time: update_bounds func: 4.4444	 prepare: 0.1651	 bound: 4.1689	 transfer: 0.0013	 finalize: 0.0948
batch bounding time:  0.3868982791900635
Current worst splitting domains [lb, ub] (depth):
[-0.45541,   inf] (31), [-0.35758,   inf] (31), [-0.33644,   inf] (31), [-0.33185,   inf] (31), [-0.32804,   inf] (31), [-0.30965,   inf] (31), [-0.29384,   inf] (31), [-0.26689,   inf] (31), [-0.22998,   inf] (31), [-0.22924,   inf] (31), [-0.21552,   inf] (31), [-0.21257,   inf] (31), [-0.20627,   inf] (31), [-0.20406,   inf] (31), [-0.19911,   inf] (31), [-0.19694,   inf] (31), [-0.19541,   inf] (31), [-0.18502,   inf] (31), [-0.17990,   inf] (31), [-0.17626,   inf] (31), 
length of domains: 56
Total time: 0.4393	 pickout: 0.0107	 decision: 0.0365	 get_bound: 0.3871	 add_domain: 0.0051
Current lb:-0.45541417598724365
836 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.2116734981536865

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([56, 200]) pre split depth:  1
batch:  torch.Size([56, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 72] [1, 72] [4, 177] [1, 72] [1, 72] [2, 74] [2, 74] [1, 72] [4, 177] [1, 132] 
regular batch size: 2*56, diving batch size 1*0
best_l after optimization: 6.27934455871582 with beta sum per layer: [69.40730285644531, 165.821533203125, 5.49587345123291, 44.5567512512207, 3.146279811859131]
alpha/beta optimization time: 0.36434412002563477
This batch time : update_bounds func: 0.3958	 prepare: 0.0188	 bound: 0.3648	 transfer: 0.0013	 finalize: 0.0107
Accumulated time: update_bounds func: 4.8402	 prepare: 0.1839	 bound: 4.5337	 transfer: 0.0013	 finalize: 0.1054
batch bounding time:  0.3961501121520996
Current worst splitting domains [lb, ub] (depth):
[-0.44194,   inf] (33), [-0.34330,   inf] (33), [-0.32783,   inf] (33), [-0.31765,   inf] (33), [-0.30859,   inf] (33), [-0.29371,   inf] (33), [-0.27867,   inf] (33), [-0.26663,   inf] (33), [-0.24674,   inf] (33), [-0.22100,   inf] (33), [-0.20640,   inf] (33), [-0.20183,   inf] (33), [-0.19877,   inf] (33), [-0.19796,   inf] (33), [-0.19224,   inf] (33), [-0.18649,   inf] (33), [-0.18235,   inf] (33), [-0.17890,   inf] (33), [-0.17681,   inf] (33), [-0.17415,   inf] (33), 
length of domains: 66
Total time: 0.4503	 pickout: 0.0111	 decision: 0.0367	 get_bound: 0.3963	 add_domain: 0.0062
Current lb:-0.4419390559196472
948 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 7.663863182067871

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([66, 200]) pre split depth:  1
batch:  torch.Size([66, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 74] [2, 74] [1, 132] [2, 74] [3, 37] [4, 177] [4, 177] [2, 74] [3, 37] [3, 37] 
regular batch size: 2*66, diving batch size 1*0
best_l after optimization: 5.202239036560059 with beta sum per layer: [79.07087707519531, 188.88629150390625, 19.55951690673828, 56.35809326171875, 5.6727166175842285]
alpha/beta optimization time: 0.362750768661499
This batch time : update_bounds func: 0.3996	 prepare: 0.0222	 bound: 0.3632	 transfer: 0.0012	 finalize: 0.0126
Accumulated time: update_bounds func: 5.2397	 prepare: 0.2061	 bound: 4.8968	 transfer: 0.0012	 finalize: 0.1180
batch bounding time:  0.3998417854309082
Current worst splitting domains [lb, ub] (depth):
[-0.42608,   inf] (35), [-0.32724,   inf] (35), [-0.30517,   inf] (35), [-0.30068,   inf] (35), [-0.28735,   inf] (35), [-0.28638,   inf] (35), [-0.28581,   inf] (35), [-0.27096,   inf] (35), [-0.22316,   inf] (35), [-0.22217,   inf] (35), [-0.19948,   inf] (35), [-0.19924,   inf] (35), [-0.19713,   inf] (35), [-0.18170,   inf] (35), [-0.18059,   inf] (35), [-0.17483,   inf] (35), [-0.17363,   inf] (35), [-0.17169,   inf] (35), [-0.16544,   inf] (35), [-0.16460,   inf] (35), 
length of domains: 70
Total time: 0.4591	 pickout: 0.0131	 decision: 0.0393	 get_bound: 0.4001	 add_domain: 0.0066
Current lb:-0.4260772466659546
1080 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.12479829788208

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([70, 200]) pre split depth:  1
batch:  torch.Size([70, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 177] [4, 177] [2, 64] [4, 177] [4, 177] [3, 37] [4, 177] [3, 37] [4, 177] [2, 64] 
regular batch size: 2*70, diving batch size 1*0
best_l after optimization: 3.575101852416992 with beta sum per layer: [74.06385803222656, 192.37222290039062, 36.66303253173828, 76.9197998046875, 10.551342964172363]
alpha/beta optimization time: 0.35497498512268066
This batch time : update_bounds func: 0.3927	 prepare: 0.0226	 bound: 0.3554	 transfer: 0.0011	 finalize: 0.0133
Accumulated time: update_bounds func: 5.6325	 prepare: 0.2287	 bound: 5.2522	 transfer: 0.0011	 finalize: 0.1313
batch bounding time:  0.3929781913757324
Current worst splitting domains [lb, ub] (depth):
[-0.42041,   inf] (37), [-0.31998,   inf] (37), [-0.29805,   inf] (37), [-0.29363,   inf] (37), [-0.28031,   inf] (37), [-0.26217,   inf] (37), [-0.24543,   inf] (37), [-0.22979,   inf] (37), [-0.21505,   inf] (37), [-0.19801,   inf] (37), [-0.19037,   inf] (37), [-0.18966,   inf] (37), [-0.18921,   inf] (37), [-0.18403,   inf] (37), [-0.17305,   inf] (37), [-0.17189,   inf] (37), [-0.16393,   inf] (37), [-0.15797,   inf] (37), [-0.15503,   inf] (37), [-0.15102,   inf] (37), 
length of domains: 64
Total time: 0.4548	 pickout: 0.0135	 decision: 0.0405	 get_bound: 0.3933	 add_domain: 0.0075
Current lb:-0.4204055070877075
1220 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 8.581581830978394

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([64, 200]) pre split depth:  1
batch:  torch.Size([64, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 37] [3, 37] [2, 74] [3, 37] [2, 64] [2, 64] [2, 64] [0, 195] [2, 64] [0, 195] 
regular batch size: 2*64, diving batch size 1*0
best_l after optimization: 5.438704490661621 with beta sum per layer: [61.53849792480469, 162.06857299804688, 41.70953369140625, 94.30675506591797, 7.098941802978516]
alpha/beta optimization time: 0.35665369033813477
This batch time : update_bounds func: 0.4746	 prepare: 0.0211	 bound: 0.3571	 transfer: 0.0011	 finalize: 0.0949
Accumulated time: update_bounds func: 6.1070	 prepare: 0.2498	 bound: 5.6093	 transfer: 0.0011	 finalize: 0.2263
batch bounding time:  0.4749112129211426
Current worst splitting domains [lb, ub] (depth):
[-0.40029,   inf] (39), [-0.30987,   inf] (39), [-0.29442,   inf] (39), [-0.28882,   inf] (39), [-0.27253,   inf] (39), [-0.27190,   inf] (39), [-0.25601,   inf] (39), [-0.23969,   inf] (39), [-0.23417,   inf] (39), [-0.20664,   inf] (39), [-0.19436,   inf] (39), [-0.18898,   inf] (39), [-0.17882,   inf] (39), [-0.17800,   inf] (39), [-0.17777,   inf] (39), [-0.16244,   inf] (39), [-0.15470,   inf] (39), [-0.14860,   inf] (39), [-0.14706,   inf] (39), [-0.14611,   inf] (39), 
length of domains: 71
Total time: 0.5323	 pickout: 0.0125	 decision: 0.0378	 get_bound: 0.4751	 add_domain: 0.0069
Current lb:-0.4002886414527893
1348 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.115736722946167

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([71, 200]) pre split depth:  1
batch:  torch.Size([71, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 64] [2, 174] [2, 64] [3, 37] [2, 64] [2, 74] [0, 159] [4, 138] [2, 174] [2, 74] 
regular batch size: 2*71, diving batch size 1*0
best_l after optimization: 4.671562671661377 with beta sum per layer: [77.2652587890625, 141.21292114257812, 59.19532775878906, 121.70115661621094, 6.960848331451416]
alpha/beta optimization time: 0.3559079170227051
This batch time : update_bounds func: 0.3935	 prepare: 0.0230	 bound: 0.3563	 transfer: 0.0011	 finalize: 0.0127
Accumulated time: update_bounds func: 6.5005	 prepare: 0.2728	 bound: 5.9656	 transfer: 0.0011	 finalize: 0.2389
batch bounding time:  0.39376282691955566
Current worst splitting domains [lb, ub] (depth):
[-0.39490,   inf] (41), [-0.28985,   inf] (41), [-0.26925,   inf] (41), [-0.26604,   inf] (41), [-0.25451,   inf] (41), [-0.25356,   inf] (41), [-0.25103,   inf] (41), [-0.21994,   inf] (41), [-0.19591,   inf] (41), [-0.18714,   inf] (41), [-0.17632,   inf] (41), [-0.17295,   inf] (41), [-0.17153,   inf] (41), [-0.15825,   inf] (41), [-0.15735,   inf] (41), [-0.15545,   inf] (41), [-0.15370,   inf] (41), [-0.14683,   inf] (41), [-0.14075,   inf] (41), [-0.13958,   inf] (41), 
length of domains: 73
Total time: 0.4550	 pickout: 0.0139	 decision: 0.0397	 get_bound: 0.3940	 add_domain: 0.0073
Current lb:-0.39489519596099854
1490 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 9.572555541992188

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([73, 200]) pre split depth:  1
batch:  torch.Size([73, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 138] [4, 138] [4, 138] [4, 138] [4, 138] [4, 138] [4, 138] [1, 157] [4, 138] [4, 138] 
regular batch size: 2*73, diving batch size 1*0
best_l after optimization: 7.569535255432129 with beta sum per layer: [66.51179504394531, 137.21029663085938, 58.97345733642578, 133.6527557373047, 32.11077880859375]
alpha/beta optimization time: 0.36798548698425293
This batch time : update_bounds func: 0.4091	 prepare: 0.0242	 bound: 0.3684	 transfer: 0.0013	 finalize: 0.0146
Accumulated time: update_bounds func: 6.9096	 prepare: 0.2971	 bound: 6.3341	 transfer: 0.0013	 finalize: 0.2536
batch bounding time:  0.4094393253326416
Current worst splitting domains [lb, ub] (depth):
[-0.37547,   inf] (43), [-0.32909,   inf] (43), [-0.26962,   inf] (43), [-0.25328,   inf] (43), [-0.24342,   inf] (43), [-0.23537,   inf] (43), [-0.23010,   inf] (43), [-0.22721,   inf] (43), [-0.21261,   inf] (43), [-0.20921,   inf] (43), [-0.20654,   inf] (43), [-0.19040,   inf] (43), [-0.18802,   inf] (43), [-0.18736,   inf] (43), [-0.18723,   inf] (43), [-0.17750,   inf] (43), [-0.16459,   inf] (43), [-0.15988,   inf] (43), [-0.15317,   inf] (43), [-0.14603,   inf] (43), 
length of domains: 94
Total time: 0.4741	 pickout: 0.0139	 decision: 0.0406	 get_bound: 0.4097	 add_domain: 0.0099
Current lb:-0.375465989112854
1636 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.048903465270996

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([94, 200]) pre split depth:  1
batch:  torch.Size([94, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 157] [3, 144] [1, 157] [3, 23] [1, 157] [0, 195] [1, 157] [3, 144] [2, 190] [3, 144] 
regular batch size: 2*94, diving batch size 1*0
best_l after optimization: 5.392194747924805 with beta sum per layer: [84.98387908935547, 174.1378936767578, 50.6771125793457, 190.81878662109375, 56.46601867675781]
alpha/beta optimization time: 0.3622441291809082
This batch time : update_bounds func: 0.4128	 prepare: 0.0302	 bound: 0.3627	 transfer: 0.0017	 finalize: 0.0173
Accumulated time: update_bounds func: 7.3224	 prepare: 0.3273	 bound: 6.6968	 transfer: 0.0017	 finalize: 0.2708
batch bounding time:  0.41315603256225586
Current worst splitting domains [lb, ub] (depth):
[-0.35563,   inf] (45), [-0.31380,   inf] (45), [-0.30395,   inf] (45), [-0.25063,   inf] (45), [-0.24533,   inf] (45), [-0.22776,   inf] (45), [-0.22277,   inf] (45), [-0.22227,   inf] (45), [-0.22072,   inf] (45), [-0.21408,   inf] (45), [-0.21241,   inf] (45), [-0.20101,   inf] (45), [-0.20001,   inf] (45), [-0.19603,   inf] (45), [-0.18812,   inf] (45), [-0.17482,   inf] (45), [-0.17396,   inf] (45), [-0.17384,   inf] (45), [-0.17011,   inf] (45), [-0.16556,   inf] (45), 
length of domains: 108
Total time: 0.4882	 pickout: 0.0183	 decision: 0.0441	 get_bound: 0.4135	 add_domain: 0.0123
Current lb:-0.35563236474990845
1824 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 10.539838552474976

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([108, 200]) pre split depth:  1
batch:  torch.Size([108, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 191] [4, 18] [2, 191] [4, 18] [2, 191] [2, 174] [1, 157] [2, 18] [2, 191] [4, 18] 
regular batch size: 2*108, diving batch size 1*0
best_l after optimization: 4.512001991271973 with beta sum per layer: [84.78840637207031, 218.63522338867188, 58.6745719909668, 195.2020721435547, 71.54147338867188]
alpha/beta optimization time: 0.3724536895751953
This batch time : update_bounds func: 0.4301	 prepare: 0.0350	 bound: 0.3729	 transfer: 0.0018	 finalize: 0.0198
Accumulated time: update_bounds func: 7.7525	 prepare: 0.3623	 bound: 7.0697	 transfer: 0.0018	 finalize: 0.2907
batch bounding time:  0.4305150508880615
Current worst splitting domains [lb, ub] (depth):
[-0.33955,   inf] (47), [-0.30873,   inf] (47), [-0.28638,   inf] (47), [-0.24744,   inf] (47), [-0.24431,   inf] (47), [-0.22964,   inf] (47), [-0.20864,   inf] (47), [-0.20546,   inf] (47), [-0.19975,   inf] (47), [-0.19967,   inf] (47), [-0.19708,   inf] (47), [-0.19586,   inf] (47), [-0.19284,   inf] (47), [-0.19126,   inf] (47), [-0.19038,   inf] (47), [-0.18436,   inf] (47), [-0.17603,   inf] (47), [-0.17280,   inf] (47), [-0.16853,   inf] (47), [-0.16695,   inf] (47), 
length of domains: 128
Total time: 0.5138	 pickout: 0.0208	 decision: 0.0468	 get_bound: 0.4309	 add_domain: 0.0152
Current lb:-0.33955323696136475
2040 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.057450771331787

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([128, 200]) pre split depth:  1
batch:  torch.Size([128, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 18] [3, 23] [0, 195] [0, 195] [3, 80] [4, 18] [3, 23] [4, 18] [1, 29] [2, 18] 
regular batch size: 2*128, diving batch size 1*0
best_l after optimization: 4.812901020050049 with beta sum per layer: [95.40510559082031, 273.4561767578125, 90.56240844726562, 211.19741821289062, 72.6964340209961]
alpha/beta optimization time: 0.3720414638519287
This batch time : update_bounds func: 0.4423	 prepare: 0.0430	 bound: 0.3725	 transfer: 0.0020	 finalize: 0.0240
Accumulated time: update_bounds func: 8.1948	 prepare: 0.4053	 bound: 7.4422	 transfer: 0.0020	 finalize: 0.3147
batch bounding time:  0.44272422790527344
Current worst splitting domains [lb, ub] (depth):
[-0.33381,   inf] (49), [-0.30580,   inf] (49), [-0.27362,   inf] (49), [-0.24034,   inf] (49), [-0.22309,   inf] (49), [-0.20586,   inf] (49), [-0.20270,   inf] (49), [-0.19894,   inf] (49), [-0.18935,   inf] (49), [-0.18746,   inf] (49), [-0.18279,   inf] (49), [-0.18205,   inf] (49), [-0.17602,   inf] (49), [-0.17487,   inf] (49), [-0.16558,   inf] (49), [-0.16552,   inf] (49), [-0.16349,   inf] (49), [-0.15794,   inf] (49), [-0.15343,   inf] (49), [-0.15271,   inf] (49), 
length of domains: 140
Total time: 0.5366	 pickout: 0.0257	 decision: 0.0518	 get_bound: 0.4431	 add_domain: 0.0158
Current lb:-0.33380886912345886
2296 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 11.598530769348145

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([140, 200]) pre split depth:  1
batch:  torch.Size([140, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 18] [1, 157] [4, 18] [1, 157] [2, 18] [1, 157] [1, 29] [2, 18] [2, 18] [1, 157] 
regular batch size: 2*140, diving batch size 1*0
best_l after optimization: 4.496831893920898 with beta sum per layer: [102.68482971191406, 313.13580322265625, 110.1419677734375, 232.07171630859375, 75.121337890625]
alpha/beta optimization time: 0.45026326179504395
This batch time : update_bounds func: 0.5226	 prepare: 0.0432	 bound: 0.4507	 transfer: 0.0019	 finalize: 0.0261
Accumulated time: update_bounds func: 8.7174	 prepare: 0.4485	 bound: 7.8929	 transfer: 0.0019	 finalize: 0.3408
batch bounding time:  0.5229597091674805
Current worst splitting domains [lb, ub] (depth):
[-0.30758,   inf] (51), [-0.30618,   inf] (51), [-0.28857,   inf] (51), [-0.26573,   inf] (51), [-0.23611,   inf] (51), [-0.23125,   inf] (51), [-0.20039,   inf] (51), [-0.19451,   inf] (51), [-0.19219,   inf] (51), [-0.18884,   inf] (51), [-0.17676,   inf] (51), [-0.17181,   inf] (51), [-0.17149,   inf] (51), [-0.16900,   inf] (51), [-0.16811,   inf] (51), [-0.16800,   inf] (51), [-0.16743,   inf] (51), [-0.16616,   inf] (51), [-0.15650,   inf] (51), [-0.15640,   inf] (51), 
length of domains: 136
Total time: 0.6209	 pickout: 0.0287	 decision: 0.0531	 get_bound: 0.5234	 add_domain: 0.0157
Current lb:-0.3075766861438751
2576 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.22351360321045

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([136, 200]) pre split depth:  1
batch:  torch.Size([136, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 23] [3, 23] [3, 177] [2, 18] [0, 195] [3, 90] [3, 23] [3, 144] [3, 23] [3, 80] 
regular batch size: 2*136, diving batch size 1*0
best_l after optimization: 5.273623466491699 with beta sum per layer: [85.3643798828125, 350.54766845703125, 114.22259521484375, 180.79881286621094, 75.34982299804688]
alpha/beta optimization time: 0.3669121265411377
This batch time : update_bounds func: 0.4379	 prepare: 0.0429	 bound: 0.3674	 transfer: 0.0016	 finalize: 0.0253
Accumulated time: update_bounds func: 9.1552	 prepare: 0.4915	 bound: 8.2603	 transfer: 0.0016	 finalize: 0.3661
batch bounding time:  0.43833446502685547
Current worst splitting domains [lb, ub] (depth):
[-0.30405,   inf] (53), [-0.30311,   inf] (53), [-0.28177,   inf] (53), [-0.24303,   inf] (53), [-0.22676,   inf] (53), [-0.21793,   inf] (53), [-0.21223,   inf] (53), [-0.20508,   inf] (53), [-0.19712,   inf] (53), [-0.18786,   inf] (53), [-0.18633,   inf] (53), [-0.18217,   inf] (53), [-0.16828,   inf] (53), [-0.16827,   inf] (53), [-0.16756,   inf] (53), [-0.16419,   inf] (53), [-0.16303,   inf] (53), [-0.16021,   inf] (53), [-0.15252,   inf] (53), [-0.14685,   inf] (53), 
length of domains: 148
Total time: 0.5348	 pickout: 0.0257	 decision: 0.0521	 get_bound: 0.4388	 add_domain: 0.0183
Current lb:-0.304049015045166
2848 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 12.762652397155762

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([148, 200]) pre split depth:  1
batch:  torch.Size([148, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 80] [3, 80] [2, 18] [3, 23] [3, 23] [3, 177] [2, 26] [2, 26] [3, 80] [3, 80] 
regular batch size: 2*148, diving batch size 1*0
best_l after optimization: 4.105854511260986 with beta sum per layer: [81.07594299316406, 362.3075866699219, 134.3951873779297, 198.64564514160156, 82.63835144042969]
alpha/beta optimization time: 0.37369346618652344
This batch time : update_bounds func: 0.4509	 prepare: 0.0467	 bound: 0.3742	 transfer: 0.0018	 finalize: 0.0276
Accumulated time: update_bounds func: 9.6062	 prepare: 0.5382	 bound: 8.6344	 transfer: 0.0018	 finalize: 0.3938
batch bounding time:  0.45139527320861816
Current worst splitting domains [lb, ub] (depth):
[-0.30145,   inf] (55), [-0.30064,   inf] (55), [-0.24949,   inf] (55), [-0.24537,   inf] (55), [-0.23973,   inf] (55), [-0.22301,   inf] (55), [-0.21019,   inf] (55), [-0.20748,   inf] (55), [-0.19953,   inf] (55), [-0.19442,   inf] (55), [-0.18540,   inf] (55), [-0.17938,   inf] (55), [-0.16840,   inf] (55), [-0.16465,   inf] (55), [-0.16435,   inf] (55), [-0.16167,   inf] (55), [-0.15641,   inf] (55), [-0.15617,   inf] (55), [-0.14955,   inf] (55), [-0.14815,   inf] (55), 
length of domains: 151
Total time: 0.5822	 pickout: 0.0291	 decision: 0.0820	 get_bound: 0.4519	 add_domain: 0.0193
Current lb:-0.3014497756958008
3144 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.349786758422852

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([151, 200]) pre split depth:  1
batch:  torch.Size([151, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 174] [2, 174] [3, 80] [3, 80] [3, 80] [3, 80] [2, 18] [2, 115] [3, 144] [2, 174] 
regular batch size: 2*151, diving batch size 1*0
best_l after optimization: 5.349334716796875 with beta sum per layer: [79.46576690673828, 365.7774353027344, 144.59451293945312, 211.00856018066406, 94.25410461425781]
alpha/beta optimization time: 0.35729098320007324
This batch time : update_bounds func: 0.4434	 prepare: 0.0523	 bound: 0.3578	 transfer: 0.0029	 finalize: 0.0295
Accumulated time: update_bounds func: 10.0495	 prepare: 0.5905	 bound: 8.9922	 transfer: 0.0029	 finalize: 0.4232
batch bounding time:  0.4437751770019531
Current worst splitting domains [lb, ub] (depth):
[-0.29150,   inf] (57), [-0.29064,   inf] (57), [-0.24704,   inf] (57), [-0.24322,   inf] (57), [-0.23642,   inf] (57), [-0.22031,   inf] (57), [-0.19240,   inf] (57), [-0.18843,   inf] (57), [-0.18750,   inf] (57), [-0.18607,   inf] (57), [-0.18362,   inf] (57), [-0.17596,   inf] (57), [-0.17380,   inf] (57), [-0.17112,   inf] (57), [-0.16771,   inf] (57), [-0.16214,   inf] (57), [-0.15526,   inf] (57), [-0.15507,   inf] (57), [-0.15342,   inf] (57), [-0.15127,   inf] (57), 
length of domains: 167
Total time: 0.5531	 pickout: 0.0298	 decision: 0.0573	 get_bound: 0.4443	 add_domain: 0.0217
Current lb:-0.29150086641311646
3446 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 13.908041954040527

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([167, 200]) pre split depth:  1
batch:  torch.Size([167, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 144] [3, 144] [1, 29] [2, 174] [2, 174] [2, 174] [3, 144] [4, 52] [3, 144] [1, 29] 
regular batch size: 2*167, diving batch size 1*0
best_l after optimization: 6.676547527313232 with beta sum per layer: [81.94888305664062, 385.49139404296875, 189.59811401367188, 249.21749877929688, 104.25450134277344]
alpha/beta optimization time: 0.36032748222351074
This batch time : update_bounds func: 0.4484	 prepare: 0.0521	 bound: 0.3608	 transfer: 0.0032	 finalize: 0.0316
Accumulated time: update_bounds func: 10.4979	 prepare: 0.6426	 bound: 9.3530	 transfer: 0.0032	 finalize: 0.4548
batch bounding time:  0.44887328147888184
Current worst splitting domains [lb, ub] (depth):
[-0.28112,   inf] (59), [-0.27994,   inf] (59), [-0.23510,   inf] (59), [-0.23247,   inf] (59), [-0.22827,   inf] (59), [-0.21154,   inf] (59), [-0.19272,   inf] (59), [-0.18677,   inf] (59), [-0.18061,   inf] (59), [-0.18042,   inf] (59), [-0.18013,   inf] (59), [-0.17838,   inf] (59), [-0.17520,   inf] (59), [-0.16893,   inf] (59), [-0.16558,   inf] (59), [-0.16067,   inf] (59), [-0.15906,   inf] (59), [-0.14500,   inf] (59), [-0.14435,   inf] (59), [-0.14430,   inf] (59), 
length of domains: 175
Total time: 0.6173	 pickout: 0.0336	 decision: 0.1124	 get_bound: 0.4494	 add_domain: 0.0219
Current lb:-0.2811216711997986
3780 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 14.530292510986328

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([175, 200]) pre split depth:  1
batch:  torch.Size([175, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 29] [1, 29] [1, 29] [2, 174] [1, 29] [3, 144] [1, 29] [2, 174] [1, 125] [2, 18] 
regular batch size: 2*175, diving batch size 1*0
best_l after optimization: 8.304460525512695 with beta sum per layer: [81.05734252929688, 395.6513671875, 182.73455810546875, 278.29498291015625, 125.37501525878906]
alpha/beta optimization time: 0.35684657096862793
This batch time : update_bounds func: 0.4476	 prepare: 0.0539	 bound: 0.3573	 transfer: 0.0026	 finalize: 0.0329
Accumulated time: update_bounds func: 10.9455	 prepare: 0.6966	 bound: 9.7102	 transfer: 0.0026	 finalize: 0.4878
batch bounding time:  0.4480423927307129
Current worst splitting domains [lb, ub] (depth):
[-0.26660,   inf] (61), [-0.26253,   inf] (61), [-0.22892,   inf] (61), [-0.22403,   inf] (61), [-0.22381,   inf] (61), [-0.22080,   inf] (61), [-0.21123,   inf] (61), [-0.20045,   inf] (61), [-0.18506,   inf] (61), [-0.17376,   inf] (61), [-0.17042,   inf] (61), [-0.16935,   inf] (61), [-0.16576,   inf] (61), [-0.16537,   inf] (61), [-0.16503,   inf] (61), [-0.16143,   inf] (61), [-0.16115,   inf] (61), [-0.16080,   inf] (61), [-0.15975,   inf] (61), [-0.15823,   inf] (61), 
length of domains: 196
Total time: 0.5694	 pickout: 0.0335	 decision: 0.0623	 get_bound: 0.4486	 add_domain: 0.0250
Current lb:-0.26660019159317017
4130 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.105827331542969

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([196, 200]) pre split depth:  1
batch:  torch.Size([196, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 52] [3, 90] [4, 52] [4, 52] [4, 52] [1, 82] [1, 82] [1, 29] [4, 52] [4, 52] 
regular batch size: 2*196, diving batch size 1*0
best_l after optimization: 10.750781059265137 with beta sum per layer: [83.76406860351562, 455.3633117675781, 173.64273071289062, 307.5811767578125, 160.92340087890625]
alpha/beta optimization time: 0.3627431392669678
This batch time : update_bounds func: 0.4670	 prepare: 0.0622	 bound: 0.3632	 transfer: 0.0033	 finalize: 0.0373
Accumulated time: update_bounds func: 11.4125	 prepare: 0.7588	 bound: 10.0734	 transfer: 0.0033	 finalize: 0.5251
batch bounding time:  0.4674971103668213
Current worst splitting domains [lb, ub] (depth):
[-0.25879,   inf] (63), [-0.24313,   inf] (63), [-0.23643,   inf] (63), [-0.21707,   inf] (63), [-0.21684,   inf] (63), [-0.21654,   inf] (63), [-0.20532,   inf] (63), [-0.20232,   inf] (63), [-0.18832,   inf] (63), [-0.17520,   inf] (63), [-0.17387,   inf] (63), [-0.16658,   inf] (63), [-0.16039,   inf] (63), [-0.15778,   inf] (63), [-0.15738,   inf] (63), [-0.15560,   inf] (63), [-0.15479,   inf] (63), [-0.15332,   inf] (63), [-0.15062,   inf] (63), [-0.15047,   inf] (63), 
length of domains: 222
Total time: 0.6028	 pickout: 0.0386	 decision: 0.0662	 get_bound: 0.4681	 add_domain: 0.0298
Current lb:-0.25879448652267456
4522 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 15.716599464416504

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([222, 200]) pre split depth:  1
batch:  torch.Size([222, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 90] [1, 82] [0, 195] [3, 90] [4, 46] [4, 46] [3, 90] [3, 144] [3, 90] [1, 82] 
regular batch size: 2*222, diving batch size 1*0
best_l after optimization: 11.41307544708252 with beta sum per layer: [93.77626037597656, 506.2749938964844, 172.52081298828125, 314.5483093261719, 219.73828125]
alpha/beta optimization time: 0.43386101722717285
This batch time : update_bounds func: 0.5528	 prepare: 0.0698	 bound: 0.4343	 transfer: 0.0044	 finalize: 0.0432
Accumulated time: update_bounds func: 11.9652	 prepare: 0.8285	 bound: 10.5078	 transfer: 0.0044	 finalize: 0.5683
batch bounding time:  0.5533642768859863
Current worst splitting domains [lb, ub] (depth):
[-0.23816,   inf] (65), [-0.23442,   inf] (65), [-0.23439,   inf] (65), [-0.22904,   inf] (65), [-0.20563,   inf] (65), [-0.20558,   inf] (65), [-0.19758,   inf] (65), [-0.19096,   inf] (65), [-0.19045,   inf] (65), [-0.18637,   inf] (65), [-0.18630,   inf] (65), [-0.18587,   inf] (65), [-0.17026,   inf] (65), [-0.16993,   inf] (65), [-0.16291,   inf] (65), [-0.15554,   inf] (65), [-0.15181,   inf] (65), [-0.15036,   inf] (65), [-0.14665,   inf] (65), [-0.14605,   inf] (65), 
length of domains: 261
Total time: 0.7707	 pickout: 0.0449	 decision: 0.1355	 get_bound: 0.5541	 add_domain: 0.0363
Current lb:-0.23816341161727905
4966 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 16.495216131210327

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([261, 200]) pre split depth:  1
batch:  torch.Size([261, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 195] [4, 52] [0, 195] [4, 52] [3, 183] [2, 143] [3, 177] [3, 90] [0, 195] [4, 52] 
regular batch size: 2*261, diving batch size 1*0
best_l after optimization: 11.17973804473877 with beta sum per layer: [111.61204528808594, 575.9554443359375, 169.06158447265625, 381.9395751953125, 296.423828125]
alpha/beta optimization time: 0.38527417182922363
This batch time : update_bounds func: 0.5291	 prepare: 0.0895	 bound: 0.3860	 transfer: 0.0037	 finalize: 0.0487
Accumulated time: update_bounds func: 12.4943	 prepare: 0.9180	 bound: 10.8938	 transfer: 0.0037	 finalize: 0.6170
batch bounding time:  0.5296585559844971
Current worst splitting domains [lb, ub] (depth):
[-0.23172,   inf] (67), [-0.22713,   inf] (67), [-0.22531,   inf] (67), [-0.21928,   inf] (67), [-0.20060,   inf] (67), [-0.19446,   inf] (67), [-0.19240,   inf] (67), [-0.18915,   inf] (67), [-0.18058,   inf] (67), [-0.18038,   inf] (67), [-0.17674,   inf] (67), [-0.17634,   inf] (67), [-0.17302,   inf] (67), [-0.16058,   inf] (67), [-0.16016,   inf] (67), [-0.15730,   inf] (67), [-0.15511,   inf] (67), [-0.15436,   inf] (67), [-0.15320,   inf] (67), [-0.15134,   inf] (67), 
length of domains: 288
Total time: 0.7140	 pickout: 0.0681	 decision: 0.0756	 get_bound: 0.5304	 add_domain: 0.0399
Current lb:-0.23172202706336975
5488 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.217833995819092

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([288, 200]) pre split depth:  1
batch:  torch.Size([288, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 177] [2, 53] [3, 177] [1, 82] [3, 183] [2, 190] [4, 46] [2, 143] [0, 195] [1, 82] 
regular batch size: 2*288, diving batch size 1*0
best_l after optimization: 10.148200988769531 with beta sum per layer: [115.47994995117188, 620.3458251953125, 173.7985382080078, 452.9127197265625, 351.5168762207031]
alpha/beta optimization time: 0.36759424209594727
This batch time : update_bounds func: 0.5159	 prepare: 0.0887	 bound: 0.3680	 transfer: 0.0040	 finalize: 0.0538
Accumulated time: update_bounds func: 13.0102	 prepare: 1.0067	 bound: 11.2618	 transfer: 0.0040	 finalize: 0.6708
batch bounding time:  0.5165038108825684
Current worst splitting domains [lb, ub] (depth):
[-0.22670,   inf] (69), [-0.22153,   inf] (69), [-0.22039,   inf] (69), [-0.21056,   inf] (69), [-0.19187,   inf] (69), [-0.18966,   inf] (69), [-0.18066,   inf] (69), [-0.18018,   inf] (69), [-0.17934,   inf] (69), [-0.17324,   inf] (69), [-0.17179,   inf] (69), [-0.17148,   inf] (69), [-0.16546,   inf] (69), [-0.16514,   inf] (69), [-0.16336,   inf] (69), [-0.15533,   inf] (69), [-0.15386,   inf] (69), [-0.14647,   inf] (69), [-0.14636,   inf] (69), [-0.14387,   inf] (69), 
length of domains: 309
Total time: 0.7402	 pickout: 0.0554	 decision: 0.1237	 get_bound: 0.5174	 add_domain: 0.0437
Current lb:-0.22670257091522217
6064 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 17.967199325561523

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([309, 200]) pre split depth:  1
batch:  torch.Size([309, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 190] [3, 177] [2, 190] [2, 53] [4, 40] [2, 190] [2, 190] [4, 40] [3, 66] [1, 125] 
regular batch size: 2*309, diving batch size 1*0
best_l after optimization: 8.345789909362793 with beta sum per layer: [95.30745697021484, 695.5770263671875, 170.95559692382812, 497.8677673339844, 396.3480224609375]
alpha/beta optimization time: 0.3670918941497803
This batch time : update_bounds func: 0.5343	 prepare: 0.0950	 bound: 0.3676	 transfer: 0.0075	 finalize: 0.0627
Accumulated time: update_bounds func: 13.5445	 prepare: 1.1018	 bound: 11.6294	 transfer: 0.0075	 finalize: 0.7335
batch bounding time:  0.5350184440612793
Current worst splitting domains [lb, ub] (depth):
[-0.22401,   inf] (71), [-0.21787,   inf] (71), [-0.21641,   inf] (71), [-0.20334,   inf] (71), [-0.18753,   inf] (71), [-0.18690,   inf] (71), [-0.17793,   inf] (71), [-0.17563,   inf] (71), [-0.17261,   inf] (71), [-0.16942,   inf] (71), [-0.16495,   inf] (71), [-0.16472,   inf] (71), [-0.16369,   inf] (71), [-0.16077,   inf] (71), [-0.15648,   inf] (71), [-0.15300,   inf] (71), [-0.15176,   inf] (71), [-0.14800,   inf] (71), [-0.14360,   inf] (71), [-0.14053,   inf] (71), 
length of domains: 318
Total time: 0.7266	 pickout: 0.0598	 decision: 0.0840	 get_bound: 0.5360	 add_domain: 0.0468
Current lb:-0.22400933504104614
6682 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 18.7045419216156

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([318, 200]) pre split depth:  1
batch:  torch.Size([318, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 40] [4, 40] [2, 190] [4, 46] [3, 66] [4, 40] [4, 40] [0, 195] [4, 46] [4, 40] 
regular batch size: 2*318, diving batch size 1*0
best_l after optimization: 8.768217086791992 with beta sum per layer: [73.71841430664062, 694.3245239257812, 202.2616729736328, 567.6326293945312, 449.2914733886719]
alpha/beta optimization time: 0.36763691902160645
This batch time : update_bounds func: 0.5363	 prepare: 0.0989	 bound: 0.3681	 transfer: 0.0079	 finalize: 0.0601
Accumulated time: update_bounds func: 14.0808	 prepare: 1.2006	 bound: 11.9974	 transfer: 0.0079	 finalize: 0.7936
batch bounding time:  0.536963701248169
Current worst splitting domains [lb, ub] (depth):
[-0.22047,   inf] (73), [-0.21424,   inf] (73), [-0.21391,   inf] (73), [-0.19219,   inf] (73), [-0.18231,   inf] (73), [-0.17900,   inf] (73), [-0.17452,   inf] (73), [-0.17196,   inf] (73), [-0.17004,   inf] (73), [-0.16973,   inf] (73), [-0.16481,   inf] (73), [-0.16106,   inf] (73), [-0.15901,   inf] (73), [-0.15810,   inf] (73), [-0.15454,   inf] (73), [-0.15207,   inf] (73), [-0.14934,   inf] (73), [-0.14753,   inf] (73), [-0.14616,   inf] (73), [-0.14327,   inf] (73), 
length of domains: 345
Total time: 0.7908	 pickout: 0.0620	 decision: 0.1400	 get_bound: 0.5379	 add_domain: 0.0509
Current lb:-0.22046613693237305
7318 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 19.50619626045227

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([345, 200]) pre split depth:  1
batch:  torch.Size([345, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 82] [0, 195] [1, 125] [2, 129] [3, 90] [2, 191] [1, 82] [0, 195] [3, 177] [3, 90] 
regular batch size: 2*345, diving batch size 1*0
best_l after optimization: 8.521383285522461 with beta sum per layer: [64.24002075195312, 769.7236328125, 244.87164306640625, 676.3973388671875, 513.8878784179688]
alpha/beta optimization time: 0.3661315441131592
This batch time : update_bounds func: 0.5925	 prepare: 0.1060	 bound: 0.3666	 transfer: 0.0043	 finalize: 0.1140
Accumulated time: update_bounds func: 14.6733	 prepare: 1.3066	 bound: 12.3641	 transfer: 0.0043	 finalize: 0.9076
batch bounding time:  0.5932812690734863
Current worst splitting domains [lb, ub] (depth):
[-0.21406,   inf] (75), [-0.21346,   inf] (75), [-0.20867,   inf] (75), [-0.18786,   inf] (75), [-0.17246,   inf] (75), [-0.17115,   inf] (75), [-0.16803,   inf] (75), [-0.16721,   inf] (75), [-0.16287,   inf] (75), [-0.15987,   inf] (75), [-0.15942,   inf] (75), [-0.15711,   inf] (75), [-0.15496,   inf] (75), [-0.15439,   inf] (75), [-0.15011,   inf] (75), [-0.14821,   inf] (75), [-0.14551,   inf] (75), [-0.14075,   inf] (75), [-0.14006,   inf] (75), [-0.13974,   inf] (75), 
length of domains: 365
Total time: 0.8079	 pickout: 0.0676	 decision: 0.0922	 get_bound: 0.5943	 add_domain: 0.0537
Current lb:-0.21405738592147827
8008 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 20.32574772834778

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([365, 200]) pre split depth:  1
batch:  torch.Size([365, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 46] [4, 46] [4, 46] [3, 177] [2, 191] [3, 90] [2, 129] [3, 90] [3, 21] [2, 191] 
regular batch size: 2*365, diving batch size 1*0
best_l after optimization: 11.377494812011719 with beta sum per layer: [61.907527923583984, 824.9371948242188, 250.98782348632812, 743.2711181640625, 515.49462890625]
alpha/beta optimization time: 0.37012600898742676
This batch time : update_bounds func: 0.5581	 prepare: 0.1128	 bound: 0.3706	 transfer: 0.0038	 finalize: 0.0690
Accumulated time: update_bounds func: 15.2314	 prepare: 1.4194	 bound: 12.7347	 transfer: 0.0038	 finalize: 0.9766
batch bounding time:  0.5588643550872803
Current worst splitting domains [lb, ub] (depth):
[-0.20267,   inf] (77), [-0.20205,   inf] (77), [-0.19743,   inf] (77), [-0.18907,   inf] (77), [-0.18594,   inf] (77), [-0.18349,   inf] (77), [-0.17635,   inf] (77), [-0.16486,   inf] (77), [-0.16409,   inf] (77), [-0.16012,   inf] (77), [-0.15755,   inf] (77), [-0.15271,   inf] (77), [-0.15141,   inf] (77), [-0.15133,   inf] (77), [-0.14961,   inf] (77), [-0.14881,   inf] (77), [-0.14560,   inf] (77), [-0.14438,   inf] (77), [-0.14432,   inf] (77), [-0.14346,   inf] (77), 
length of domains: 405
Total time: 0.7866	 pickout: 0.0705	 decision: 0.0960	 get_bound: 0.5600	 add_domain: 0.0601
Current lb:-0.20266687870025635
8738 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 21.124595642089844

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([405, 200]) pre split depth:  1
batch:  torch.Size([405, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 22] [4, 40] [3, 22] [3, 21] [3, 21] [2, 190] [3, 21] [0, 195] [3, 66] [0, 195] 
regular batch size: 2*405, diving batch size 1*0
best_l after optimization: 9.326066970825195 with beta sum per layer: [56.3414421081543, 894.074462890625, 274.326904296875, 906.569580078125, 592.2747192382812]
alpha/beta optimization time: 0.3730769157409668
This batch time : update_bounds func: 0.5801	 prepare: 0.1237	 bound: 0.3735	 transfer: 0.0049	 finalize: 0.0759
Accumulated time: update_bounds func: 15.8114	 prepare: 1.5431	 bound: 13.1082	 transfer: 0.0049	 finalize: 1.0524
batch bounding time:  0.580885648727417
Current worst splitting domains [lb, ub] (depth):
[-0.19838,   inf] (79), [-0.19434,   inf] (79), [-0.18891,   inf] (79), [-0.18108,   inf] (79), [-0.17615,   inf] (79), [-0.17369,   inf] (79), [-0.16312,   inf] (79), [-0.15937,   inf] (79), [-0.15545,   inf] (79), [-0.15469,   inf] (79), [-0.15366,   inf] (79), [-0.14902,   inf] (79), [-0.14869,   inf] (79), [-0.14675,   inf] (79), [-0.14601,   inf] (79), [-0.14391,   inf] (79), [-0.14294,   inf] (79), [-0.14162,   inf] (79), [-0.14081,   inf] (79), [-0.13976,   inf] (79), 
length of domains: 428
Total time: 0.8747	 pickout: 0.0781	 decision: 0.1484	 get_bound: 0.5821	 add_domain: 0.0660
Current lb:-0.19837594032287598
9548 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 22.01386594772339

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([428, 200]) pre split depth:  1
batch:  torch.Size([428, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 22] [2, 129] [2, 129] [3, 66] [3, 66] [2, 26] [3, 66] [3, 22] [2, 143] [0, 195] 
regular batch size: 2*428, diving batch size 1*0
best_l after optimization: 10.778331756591797 with beta sum per layer: [56.92207336425781, 919.7279663085938, 298.05133056640625, 959.77099609375, 637.741455078125]
alpha/beta optimization time: 0.3676135540008545
This batch time : update_bounds func: 0.5863	 prepare: 0.1304	 bound: 0.3681	 transfer: 0.0055	 finalize: 0.0805
Accumulated time: update_bounds func: 16.3978	 prepare: 1.6735	 bound: 13.4763	 transfer: 0.0055	 finalize: 1.1330
batch bounding time:  0.5872189998626709
Current worst splitting domains [lb, ub] (depth):
[-0.19112,   inf] (81), [-0.18998,   inf] (81), [-0.18548,   inf] (81), [-0.17066,   inf] (81), [-0.16981,   inf] (81), [-0.16894,   inf] (81), [-0.16391,   inf] (81), [-0.15529,   inf] (81), [-0.15083,   inf] (81), [-0.15059,   inf] (81), [-0.15043,   inf] (81), [-0.14736,   inf] (81), [-0.14297,   inf] (81), [-0.14201,   inf] (81), [-0.13999,   inf] (81), [-0.13826,   inf] (81), [-0.13822,   inf] (81), [-0.13786,   inf] (81), [-0.13701,   inf] (81), [-0.13611,   inf] (81), 
length of domains: 451
Total time: 0.8970	 pickout: 0.0842	 decision: 0.1542	 get_bound: 0.5885	 add_domain: 0.0701
Current lb:-0.19111508131027222
10404 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 22.92604899406433

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([451, 200]) pre split depth:  1
batch:  torch.Size([451, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 66] [2, 129] [3, 66] [4, 40] [3, 59] [4, 40] [1, 125] [3, 59] [3, 66] [4, 107] 
regular batch size: 2*451, diving batch size 1*0
best_l after optimization: 11.642295837402344 with beta sum per layer: [47.3106689453125, 940.3223266601562, 317.2799987792969, 1006.2178344726562, 641.8308715820312]
alpha/beta optimization time: 0.3697826862335205
This batch time : update_bounds func: 0.6468	 prepare: 0.1391	 bound: 0.3703	 transfer: 0.0061	 finalize: 0.1293
Accumulated time: update_bounds func: 17.0446	 prepare: 1.8126	 bound: 13.8465	 transfer: 0.0061	 finalize: 1.2623
batch bounding time:  0.6478450298309326
Current worst splitting domains [lb, ub] (depth):
[-0.18634,   inf] (83), [-0.18423,   inf] (83), [-0.17674,   inf] (83), [-0.16947,   inf] (83), [-0.16685,   inf] (83), [-0.16479,   inf] (83), [-0.16468,   inf] (83), [-0.16335,   inf] (83), [-0.16245,   inf] (83), [-0.14694,   inf] (83), [-0.14607,   inf] (83), [-0.14559,   inf] (83), [-0.14385,   inf] (83), [-0.14028,   inf] (83), [-0.13822,   inf] (83), [-0.13765,   inf] (83), [-0.13505,   inf] (83), [-0.13466,   inf] (83), [-0.13366,   inf] (83), [-0.13244,   inf] (83), 
length of domains: 494
Total time: 0.9288	 pickout: 0.0880	 decision: 0.1131	 get_bound: 0.6494	 add_domain: 0.0784
Current lb:-0.18633711338043213
11306 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 23.870784997940063

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([494, 200]) pre split depth:  1
batch:  torch.Size([494, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 66] [3, 21] [3, 21] [1, 125] [3, 22] [1, 96] [3, 66] [1, 47] [3, 183] [2, 115] 
regular batch size: 2*494, diving batch size 1*0
best_l after optimization: 13.648987770080566 with beta sum per layer: [44.22704315185547, 940.078125, 349.3568115234375, 1142.31103515625, 741.7307739257812]
alpha/beta optimization time: 0.3686044216156006
This batch time : update_bounds func: 0.6681	 prepare: 0.1494	 bound: 0.3691	 transfer: 0.0062	 finalize: 0.1411
Accumulated time: update_bounds func: 17.7126	 prepare: 1.9620	 bound: 14.2156	 transfer: 0.0062	 finalize: 1.4033
batch bounding time:  0.669058084487915
Current worst splitting domains [lb, ub] (depth):
[-0.17876,   inf] (85), [-0.17660,   inf] (85), [-0.17146,   inf] (85), [-0.16895,   inf] (85), [-0.16666,   inf] (85), [-0.15880,   inf] (85), [-0.15541,   inf] (85), [-0.15470,   inf] (85), [-0.15293,   inf] (85), [-0.14962,   inf] (85), [-0.14208,   inf] (85), [-0.13924,   inf] (85), [-0.13858,   inf] (85), [-0.13791,   inf] (85), [-0.13787,   inf] (85), [-0.13571,   inf] (85), [-0.13461,   inf] (85), [-0.13162,   inf] (85), [-0.13109,   inf] (85), [-0.13100,   inf] (85), 
length of domains: 546
Total time: 0.9765	 pickout: 0.0967	 decision: 0.1214	 get_bound: 0.6705	 add_domain: 0.0878
Current lb:-0.1787620186805725
12294 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 24.864694833755493

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([546, 200]) pre split depth:  1
batch:  torch.Size([546, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 81] [2, 26] [4, 81] [4, 39] [1, 96] [2, 26] [2, 197] [3, 59] [4, 39] [2, 143] 
regular batch size: 2*546, diving batch size 1*0
best_l after optimization: 12.219197273254395 with beta sum per layer: [40.86553955078125, 1049.6497802734375, 409.6925354003906, 1280.4664306640625, 851.6593627929688]
alpha/beta optimization time: 0.3682878017425537
This batch time : update_bounds func: 0.7227	 prepare: 0.1743	 bound: 0.3688	 transfer: 0.0093	 finalize: 0.1675
Accumulated time: update_bounds func: 18.4353	 prepare: 2.1363	 bound: 14.5844	 transfer: 0.0093	 finalize: 1.5708
batch bounding time:  0.7237281799316406
Current worst splitting domains [lb, ub] (depth):
[-0.17477,   inf] (87), [-0.17363,   inf] (87), [-0.16721,   inf] (87), [-0.16331,   inf] (87), [-0.15600,   inf] (87), [-0.15218,   inf] (87), [-0.14715,   inf] (87), [-0.14711,   inf] (87), [-0.14497,   inf] (87), [-0.14431,   inf] (87), [-0.13388,   inf] (87), [-0.13332,   inf] (87), [-0.13281,   inf] (87), [-0.13279,   inf] (87), [-0.13111,   inf] (87), [-0.13048,   inf] (87), [-0.13014,   inf] (87), [-0.12893,   inf] (87), [-0.12839,   inf] (87), [-0.12730,   inf] (87), 
length of domains: 598
Total time: 1.0618	 pickout: 0.1057	 decision: 0.1315	 get_bound: 0.7254	 add_domain: 0.0992
Current lb:-0.1747688502073288
13386 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 25.947377681732178

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([598, 200]) pre split depth:  1
batch:  torch.Size([598, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 53] [3, 21] [2, 53] [3, 183] [3, 183] [2, 197] [1, 125] [3, 183] [2, 26] [1, 96] 
regular batch size: 2*598, diving batch size 1*0
best_l after optimization: 10.87890625 with beta sum per layer: [39.334251403808594, 1104.900634765625, 475.4559326171875, 1410.7371826171875, 988.1209716796875]
alpha/beta optimization time: 0.37712621688842773
This batch time : update_bounds func: 0.7363	 prepare: 0.1832	 bound: 0.3776	 transfer: 0.0101	 finalize: 0.1625
Accumulated time: update_bounds func: 19.1716	 prepare: 2.3195	 bound: 14.9620	 transfer: 0.0101	 finalize: 1.7333
batch bounding time:  0.7375009059906006
Current worst splitting domains [lb, ub] (depth):
[-0.17236,   inf] (89), [-0.16841,   inf] (89), [-0.16452,   inf] (89), [-0.15442,   inf] (89), [-0.14944,   inf] (89), [-0.14741,   inf] (89), [-0.14668,   inf] (89), [-0.14248,   inf] (89), [-0.14162,   inf] (89), [-0.13795,   inf] (89), [-0.13701,   inf] (89), [-0.13447,   inf] (89), [-0.12968,   inf] (89), [-0.12949,   inf] (89), [-0.12863,   inf] (89), [-0.12802,   inf] (89), [-0.12571,   inf] (89), [-0.12218,   inf] (89), [-0.12138,   inf] (89), [-0.12023,   inf] (89), 
length of domains: 612
Total time: 1.1022	 pickout: 0.1176	 decision: 0.1430	 get_bound: 0.7393	 add_domain: 0.1023
Current lb:-0.17235565185546875
14582 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 27.07151436805725

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([612, 200]) pre split depth:  1
batch:  torch.Size([612, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 39] [4, 39] [4, 107] [3, 21] [1, 96] [3, 21] [4, 39] [2, 115] [1, 135] [4, 39] 
regular batch size: 2*612, diving batch size 1*0
best_l after optimization: 12.215176582336426 with beta sum per layer: [30.385963439941406, 1097.61767578125, 528.413330078125, 1447.7802734375, 1031.2657470703125]
alpha/beta optimization time: 0.3786122798919678
This batch time : update_bounds func: 0.6921	 prepare: 0.1885	 bound: 0.3791	 transfer: 0.0077	 finalize: 0.1137
Accumulated time: update_bounds func: 19.8637	 prepare: 2.5080	 bound: 15.3411	 transfer: 0.0077	 finalize: 1.8470
batch bounding time:  0.6932976245880127
Current worst splitting domains [lb, ub] (depth):
[-0.16633,   inf] (91), [-0.16201,   inf] (91), [-0.15772,   inf] (91), [-0.14883,   inf] (91), [-0.14195,   inf] (91), [-0.14064,   inf] (91), [-0.13910,   inf] (91), [-0.13772,   inf] (91), [-0.13464,   inf] (91), [-0.13404,   inf] (91), [-0.12999,   inf] (91), [-0.12695,   inf] (91), [-0.12660,   inf] (91), [-0.12448,   inf] (91), [-0.12438,   inf] (91), [-0.12345,   inf] (91), [-0.12267,   inf] (91), [-0.11977,   inf] (91), [-0.11894,   inf] (91), [-0.11864,   inf] (91), 
length of domains: 611
Total time: 1.1133	 pickout: 0.1200	 decision: 0.1934	 get_bound: 0.6952	 add_domain: 0.1047
Current lb:-0.1663340926170349
15806 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 28.2080500125885

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([611, 200]) pre split depth:  1
batch:  torch.Size([611, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 107] [3, 183] [4, 146] [4, 81] [4, 81] [3, 183] [1, 73] [4, 81] [4, 39] [3, 21] 
regular batch size: 2*611, diving batch size 1*0
best_l after optimization: 13.15710735321045 with beta sum per layer: [21.676115036010742, 1088.320068359375, 534.1220703125, 1426.35400390625, 1038.084228515625]
alpha/beta optimization time: 0.3765842914581299
This batch time : update_bounds func: 0.6853	 prepare: 0.1859	 bound: 0.3770	 transfer: 0.0050	 finalize: 0.1144
Accumulated time: update_bounds func: 20.5491	 prepare: 2.6939	 bound: 15.7181	 transfer: 0.0050	 finalize: 1.9614
batch bounding time:  0.6865036487579346
Current worst splitting domains [lb, ub] (depth):
[-0.15956,   inf] (93), [-0.15331,   inf] (93), [-0.15178,   inf] (93), [-0.14438,   inf] (93), [-0.13985,   inf] (93), [-0.13769,   inf] (93), [-0.13211,   inf] (93), [-0.13186,   inf] (93), [-0.13155,   inf] (93), [-0.12886,   inf] (93), [-0.12811,   inf] (93), [-0.12385,   inf] (93), [-0.12172,   inf] (93), [-0.12086,   inf] (93), [-0.11977,   inf] (93), [-0.11938,   inf] (93), [-0.11809,   inf] (93), [-0.11421,   inf] (93), [-0.11320,   inf] (93), [-0.11163,   inf] (93), 
length of domains: 643
Total time: 1.1158	 pickout: 0.1200	 decision: 0.1967	 get_bound: 0.6883	 add_domain: 0.1108
Current lb:-0.15955597162246704
17028 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 29.346402883529663

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([643, 200]) pre split depth:  1
batch:  torch.Size([643, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 146] [4, 81] [2, 21] [4, 107] [1, 96] [4, 39] [1, 73] [3, 21] [2, 169] [1, 135] 
regular batch size: 2*643, diving batch size 1*0
best_l after optimization: 11.12732982635498 with beta sum per layer: [17.181665420532227, 1188.843505859375, 606.0684814453125, 1466.210205078125, 1107.7403564453125]
alpha/beta optimization time: 0.3725883960723877
This batch time : update_bounds func: 0.7017	 prepare: 0.1984	 bound: 0.3731	 transfer: 0.0054	 finalize: 0.1213
Accumulated time: update_bounds func: 21.2508	 prepare: 2.8924	 bound: 16.0912	 transfer: 0.0054	 finalize: 2.0827
batch bounding time:  0.7028825283050537
Current worst splitting domains [lb, ub] (depth):
[-0.15357,   inf] (95), [-0.14916,   inf] (95), [-0.14627,   inf] (95), [-0.13765,   inf] (95), [-0.13167,   inf] (95), [-0.12843,   inf] (95), [-0.12632,   inf] (95), [-0.12554,   inf] (95), [-0.12446,   inf] (95), [-0.12369,   inf] (95), [-0.11935,   inf] (95), [-0.11783,   inf] (95), [-0.11738,   inf] (95), [-0.11672,   inf] (95), [-0.11344,   inf] (95), [-0.11309,   inf] (95), [-0.11263,   inf] (95), [-0.11067,   inf] (95), [-0.10956,   inf] (95), [-0.10652,   inf] (95), 
length of domains: 653
Total time: 1.2060	 pickout: 0.1263	 decision: 0.1984	 get_bound: 0.7049	 add_domain: 0.1764
Current lb:-0.1535722017288208
18314 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 30.575952529907227

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([653, 200]) pre split depth:  1
batch:  torch.Size([653, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 21] [1, 96] [4, 110] [4, 146] [2, 38] [4, 107] [4, 81] [4, 107] [4, 81] [4, 81] 
regular batch size: 2*653, diving batch size 1*0
best_l after optimization: 10.626082420349121 with beta sum per layer: [9.169941902160645, 1164.24609375, 639.3427124023438, 1465.8514404296875, 1238.7685546875]
alpha/beta optimization time: 0.37403225898742676
This batch time : update_bounds func: 0.7608	 prepare: 0.2000	 bound: 0.3745	 transfer: 0.0060	 finalize: 0.1773
Accumulated time: update_bounds func: 22.0116	 prepare: 3.0924	 bound: 16.4657	 transfer: 0.0060	 finalize: 2.2601
batch bounding time:  0.7620689868927002
Current worst splitting domains [lb, ub] (depth):
[-0.14860,   inf] (97), [-0.14181,   inf] (97), [-0.14116,   inf] (97), [-0.13150,   inf] (97), [-0.12838,   inf] (97), [-0.12181,   inf] (97), [-0.12174,   inf] (97), [-0.11980,   inf] (97), [-0.11927,   inf] (97), [-0.11907,   inf] (97), [-0.11806,   inf] (97), [-0.11402,   inf] (97), [-0.11140,   inf] (97), [-0.11128,   inf] (97), [-0.11092,   inf] (97), [-0.10844,   inf] (97), [-0.10814,   inf] (97), [-0.10480,   inf] (97), [-0.10425,   inf] (97), [-0.10256,   inf] (97), 
length of domains: 660
Total time: 1.1630	 pickout: 0.1288	 decision: 0.1514	 get_bound: 0.7640	 add_domain: 0.1187
Current lb:-0.1486005187034607
19620 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 31.76372718811035

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([660, 200]) pre split depth:  1
batch:  torch.Size([660, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 110] [4, 94] [4, 107] [4, 110] [4, 107] [4, 107] [4, 146] [4, 107] [4, 107] [2, 21] 
regular batch size: 2*660, diving batch size 1*0
best_l after optimization: 8.890640258789062 with beta sum per layer: [3.259932518005371, 1078.549560546875, 674.810546875, 1513.1220703125, 1400.4068603515625]
alpha/beta optimization time: 0.3736701011657715
This batch time : update_bounds func: 0.7597	 prepare: 0.2019	 bound: 0.3741	 transfer: 0.0054	 finalize: 0.1748
Accumulated time: update_bounds func: 22.7713	 prepare: 3.2943	 bound: 16.8398	 transfer: 0.0054	 finalize: 2.4349
batch bounding time:  0.7610068321228027
Current worst splitting domains [lb, ub] (depth):
[-0.14418,   inf] (99), [-0.13551,   inf] (99), [-0.13444,   inf] (99), [-0.12714,   inf] (99), [-0.12193,   inf] (99), [-0.11548,   inf] (99), [-0.11523,   inf] (99), [-0.11306,   inf] (99), [-0.11279,   inf] (99), [-0.11249,   inf] (99), [-0.10979,   inf] (99), [-0.10919,   inf] (99), [-0.10587,   inf] (99), [-0.10451,   inf] (99), [-0.10359,   inf] (99), [-0.10191,   inf] (99), [-0.09945,   inf] (99), [-0.09885,   inf] (99), [-0.09666,   inf] (99), [-0.09627,   inf] (99), 
length of domains: 658
Total time: 1.1680	 pickout: 0.1312	 decision: 0.1549	 get_bound: 0.7630	 add_domain: 0.1189
Current lb:-0.14418497681617737
20940 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 32.95635008811951

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([658, 200]) pre split depth:  1
batch:  torch.Size([658, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 94] [2, 169] [4, 146] [4, 94] [4, 146] [2, 21] [1, 135] [4, 146] [2, 169] [4, 146] 
regular batch size: 2*658, diving batch size 1*0
best_l after optimization: 3.734071731567383 with beta sum per layer: [0.9493062496185303, 1001.976318359375, 674.2750244140625, 1477.88671875, 1595.0733642578125]
alpha/beta optimization time: 0.3732917308807373
This batch time : update_bounds func: 0.7050	 prepare: 0.1993	 bound: 0.3737	 transfer: 0.0048	 finalize: 0.1241
Accumulated time: update_bounds func: 23.4763	 prepare: 3.4935	 bound: 17.2136	 transfer: 0.0048	 finalize: 2.5590
batch bounding time:  0.7064688205718994
Current worst splitting domains [lb, ub] (depth):
[-0.13790,   inf] (101), [-0.13319,   inf] (101), [-0.12801,   inf] (101), [-0.12093,   inf] (101), [-0.11574,   inf] (101), [-0.11073,   inf] (101), [-0.10987,   inf] (101), [-0.10777,   inf] (101), [-0.10683,   inf] (101), [-0.10656,   inf] (101), [-0.10646,   inf] (101), [-0.10376,   inf] (101), [-0.10330,   inf] (101), [-0.10261,   inf] (101), [-0.09673,   inf] (101), [-0.09569,   inf] (101), [-0.09384,   inf] (101), [-0.09304,   inf] (101), [-0.09196,   inf] (101), [-0.09110,   inf] (101), 
length of domains: 603
Total time: 1.1538	 pickout: 0.1311	 decision: 0.2031	 get_bound: 0.7087	 add_domain: 0.1109
Current lb:-0.13790243864059448
22256 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 34.135772705078125

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([603, 200]) pre split depth:  1
batch:  torch.Size([603, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 59] [3, 59] [2, 38] [3, 59] [4, 110] [4, 146] [2, 197] [2, 197] [2, 169] [3, 183] 
regular batch size: 2*603, diving batch size 1*0
best_l after optimization: 1.7278127670288086 with beta sum per layer: [0.9493062496185303, 868.0675659179688, 615.6341552734375, 1342.7540283203125, 1510.9066162109375]
alpha/beta optimization time: 0.375150203704834
This batch time : update_bounds func: 0.6800	 prepare: 0.1833	 bound: 0.3756	 transfer: 0.0041	 finalize: 0.1140
Accumulated time: update_bounds func: 24.1563	 prepare: 3.6768	 bound: 17.5892	 transfer: 0.0041	 finalize: 2.6730
batch bounding time:  0.681098222732544
Current worst splitting domains [lb, ub] (depth):
[-0.13320,   inf] (103), [-0.12855,   inf] (103), [-0.12172,   inf] (103), [-0.11584,   inf] (103), [-0.11137,   inf] (103), [-0.11041,   inf] (103), [-0.10472,   inf] (103), [-0.10450,   inf] (103), [-0.10440,   inf] (103), [-0.10283,   inf] (103), [-0.10180,   inf] (103), [-0.10051,   inf] (103), [-0.09922,   inf] (103), [-0.09836,   inf] (103), [-0.09765,   inf] (103), [-0.09189,   inf] (103), [-0.08838,   inf] (103), [-0.08763,   inf] (103), [-0.08740,   inf] (103), [-0.08662,   inf] (103), 
length of domains: 504
Total time: 1.0865	 pickout: 0.1198	 decision: 0.1917	 get_bound: 0.6829	 add_domain: 0.0921
Current lb:-0.13319632411003113
23462 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 35.24583625793457

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([504, 200]) pre split depth:  1
batch:  torch.Size([504, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 169] [3, 183] [4, 110] [1, 96] [4, 94] [1, 82] [4, 110] [4, 146] [2, 38] [4, 110] 
regular batch size: 2*504, diving batch size 1*0
best_l after optimization: 3.120344877243042 with beta sum per layer: [0.3295440375804901, 715.9639892578125, 491.3612060546875, 1052.6929931640625, 1212.170166015625]
alpha/beta optimization time: 0.36780476570129395
This batch time : update_bounds func: 0.6342	 prepare: 0.1535	 bound: 0.3683	 transfer: 0.0073	 finalize: 0.1030
Accumulated time: update_bounds func: 24.7905	 prepare: 3.8303	 bound: 17.9575	 transfer: 0.0073	 finalize: 2.7760
batch bounding time:  0.6352577209472656
Current worst splitting domains [lb, ub] (depth):
[-0.13111,   inf] (105), [-0.11977,   inf] (105), [-0.11831,   inf] (105), [-0.11716,   inf] (105), [-0.10614,   inf] (105), [-0.10526,   inf] (105), [-0.09994,   inf] (105), [-0.09866,   inf] (105), [-0.09805,   inf] (105), [-0.09760,   inf] (105), [-0.09526,   inf] (105), [-0.09478,   inf] (105), [-0.09430,   inf] (105), [-0.09413,   inf] (105), [-0.09350,   inf] (105), [-0.08820,   inf] (105), [-0.08813,   inf] (105), [-0.08583,   inf] (105), [-0.08516,   inf] (105), [-0.08463,   inf] (105), 
length of domains: 466
Total time: 0.9919	 pickout: 0.0991	 decision: 0.1669	 get_bound: 0.6369	 add_domain: 0.0890
Current lb:-0.13111236691474915
24470 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 36.258158445358276

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([466, 200]) pre split depth:  1
batch:  torch.Size([466, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 73] [4, 39] [2, 143] [4, 94] [2, 21] [3, 59] [4, 94] [4, 94] [4, 110] [1, 82] 
regular batch size: 2*466, diving batch size 1*0
best_l after optimization: 3.419574737548828 with beta sum per layer: [0.23732657730579376, 652.115966796875, 469.5725402832031, 964.9772338867188, 1090.6923828125]
alpha/beta optimization time: 0.36185240745544434
This batch time : update_bounds func: 0.6104	 prepare: 0.1503	 bound: 0.3623	 transfer: 0.0060	 finalize: 0.0876
Accumulated time: update_bounds func: 25.4009	 prepare: 3.9806	 bound: 18.3198	 transfer: 0.0060	 finalize: 2.8636
batch bounding time:  0.6113638877868652
Current worst splitting domains [lb, ub] (depth):
[-0.12902,   inf] (107), [-0.11371,   inf] (107), [-0.11364,   inf] (107), [-0.11119,   inf] (107), [-0.10173,   inf] (107), [-0.10022,   inf] (107), [-0.09479,   inf] (107), [-0.09386,   inf] (107), [-0.09385,   inf] (107), [-0.09266,   inf] (107), [-0.09221,   inf] (107), [-0.09207,   inf] (107), [-0.08965,   inf] (107), [-0.08815,   inf] (107), [-0.08718,   inf] (107), [-0.08419,   inf] (107), [-0.08237,   inf] (107), [-0.08104,   inf] (107), [-0.08053,   inf] (107), [-0.08004,   inf] (107), 
length of domains: 436
Total time: 0.9786	 pickout: 0.0924	 decision: 0.1915	 get_bound: 0.6128	 add_domain: 0.0820
Current lb:-0.12902146577835083
25402 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 37.25591683387756

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([436, 200]) pre split depth:  1
batch:  torch.Size([436, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 183] [1, 96] [1, 96] [3, 59] [1, 73] [1, 96] [1, 73] [3, 59] [4, 94] [4, 110] 
regular batch size: 2*436, diving batch size 1*0
best_l after optimization: 3.332528829574585 with beta sum per layer: [0.9493061304092407, 595.927978515625, 416.2574157714844, 879.9539794921875, 998.4503173828125]
alpha/beta optimization time: 0.36068081855773926
This batch time : update_bounds func: 0.5819	 prepare: 0.1336	 bound: 0.3611	 transfer: 0.0032	 finalize: 0.0820
Accumulated time: update_bounds func: 25.9828	 prepare: 4.1142	 bound: 18.6810	 transfer: 0.0032	 finalize: 2.9456
batch bounding time:  0.5828251838684082
Current worst splitting domains [lb, ub] (depth):
[-0.12011,   inf] (109), [-0.11815,   inf] (109), [-0.10870,   inf] (109), [-0.10648,   inf] (109), [-0.10377,   inf] (109), [-0.09894,   inf] (109), [-0.09456,   inf] (109), [-0.09330,   inf] (109), [-0.08970,   inf] (109), [-0.08876,   inf] (109), [-0.08870,   inf] (109), [-0.08788,   inf] (109), [-0.08757,   inf] (109), [-0.08754,   inf] (109), [-0.08479,   inf] (109), [-0.08438,   inf] (109), [-0.08381,   inf] (109), [-0.08358,   inf] (109), [-0.08319,   inf] (109), [-0.08003,   inf] (109), 
length of domains: 405
Total time: 0.9053	 pickout: 0.0871	 decision: 0.1567	 get_bound: 0.5841	 add_domain: 0.0773
Current lb:-0.12011498212814331
26274 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 38.17775511741638

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([405, 200]) pre split depth:  1
batch:  torch.Size([405, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 96] [2, 143] [4, 196] [2, 197] [4, 39] [2, 169] [2, 197] [2, 115] [1, 96] [0, 146] 
regular batch size: 2*405, diving batch size 1*0
best_l after optimization: 3.629025459289551 with beta sum per layer: [1.4376931190490723, 524.6342163085938, 372.6787109375, 783.4493408203125, 905.97021484375]
alpha/beta optimization time: 0.3610382080078125
This batch time : update_bounds func: 0.6132	 prepare: 0.1260	 bound: 0.3616	 transfer: 0.0031	 finalize: 0.0761
Accumulated time: update_bounds func: 26.5960	 prepare: 4.2402	 bound: 19.0425	 transfer: 0.0031	 finalize: 3.0217
batch bounding time:  0.6140167713165283
Current worst splitting domains [lb, ub] (depth):
[-0.11349,   inf] (111), [-0.11334,   inf] (111), [-0.10585,   inf] (111), [-0.10239,   inf] (111), [-0.09777,   inf] (111), [-0.09686,   inf] (111), [-0.09354,   inf] (111), [-0.09060,   inf] (111), [-0.08848,   inf] (111), [-0.08769,   inf] (111), [-0.08551,   inf] (111), [-0.08518,   inf] (111), [-0.08496,   inf] (111), [-0.08222,   inf] (111), [-0.08212,   inf] (111), [-0.08181,   inf] (111), [-0.08139,   inf] (111), [-0.08007,   inf] (111), [-0.07879,   inf] (111), [-0.07697,   inf] (111), 
length of domains: 398
Total time: 0.8778	 pickout: 0.0797	 decision: 0.1059	 get_bound: 0.6153	 add_domain: 0.0770
Current lb:-0.11348694562911987
27084 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 39.07040286064148

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([398, 200]) pre split depth:  1
batch:  torch.Size([398, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 96] [4, 196] [2, 197] [4, 196] [2, 38] [1, 135] [0, 146] [4, 196] [2, 197] [2, 197] 
regular batch size: 2*398, diving batch size 1*0
best_l after optimization: 1.9423391819000244 with beta sum per layer: [0.8717465996742249, 493.5821228027344, 384.5086669921875, 731.6483154296875, 892.20703125]
alpha/beta optimization time: 0.36199116706848145
This batch time : update_bounds func: 0.6143	 prepare: 0.1220	 bound: 0.3624	 transfer: 0.0029	 finalize: 0.1253
Accumulated time: update_bounds func: 27.2103	 prepare: 4.3621	 bound: 19.4050	 transfer: 0.0029	 finalize: 3.1470
batch bounding time:  0.6151881217956543
Current worst splitting domains [lb, ub] (depth):
[-0.11047,   inf] (113), [-0.10245,   inf] (113), [-0.10221,   inf] (113), [-0.09954,   inf] (113), [-0.09277,   inf] (113), [-0.09178,   inf] (113), [-0.08790,   inf] (113), [-0.08633,   inf] (113), [-0.08561,   inf] (113), [-0.08474,   inf] (113), [-0.08268,   inf] (113), [-0.08247,   inf] (113), [-0.08170,   inf] (113), [-0.08011,   inf] (113), [-0.07888,   inf] (113), [-0.07709,   inf] (113), [-0.07706,   inf] (113), [-0.07614,   inf] (113), [-0.07554,   inf] (113), [-0.07409,   inf] (113), 
length of domains: 373
Total time: 0.8711	 pickout: 0.0794	 decision: 0.1025	 get_bound: 0.6165	 add_domain: 0.0728
Current lb:-0.1104736328125
27880 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 39.956268548965454

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([373, 200]) pre split depth:  1
batch:  torch.Size([373, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 197] [2, 115] [2, 38] [3, 0] [2, 197] [0, 146] [3, 0] [4, 127] [1, 96] [4, 196] 
regular batch size: 2*373, diving batch size 1*0
best_l after optimization: 1.014733076095581 with beta sum per layer: [1.8272299766540527, 438.820068359375, 365.89288330078125, 698.3011474609375, 806.0213623046875]
alpha/beta optimization time: 0.36121201515197754
This batch time : update_bounds func: 0.5503	 prepare: 0.1141	 bound: 0.3617	 transfer: 0.0028	 finalize: 0.0701
Accumulated time: update_bounds func: 27.7606	 prepare: 4.4763	 bound: 19.7666	 transfer: 0.0028	 finalize: 3.2170
batch bounding time:  0.5510754585266113
Current worst splitting domains [lb, ub] (depth):
[-0.10666,   inf] (115), [-0.09721,   inf] (115), [-0.09640,   inf] (115), [-0.09608,   inf] (115), [-0.09598,   inf] (115), [-0.08814,   inf] (115), [-0.08530,   inf] (115), [-0.08411,   inf] (115), [-0.08393,   inf] (115), [-0.08356,   inf] (115), [-0.08274,   inf] (115), [-0.08166,   inf] (115), [-0.08072,   inf] (115), [-0.07699,   inf] (115), [-0.07690,   inf] (115), [-0.07688,   inf] (115), [-0.07663,   inf] (115), [-0.07439,   inf] (115), [-0.07349,   inf] (115), [-0.07329,   inf] (115), 
length of domains: 357
Total time: 0.7935	 pickout: 0.0729	 decision: 0.0968	 get_bound: 0.5522	 add_domain: 0.0715
Current lb:-0.10666012763977051
28626 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 40.76378536224365

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([357, 200]) pre split depth:  1
batch:  torch.Size([357, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 115] [2, 143] [2, 169] [2, 115] [2, 143] [1, 47] [1, 14] [1, 96] [4, 196] [1, 82] 
regular batch size: 2*357, diving batch size 1*0
best_l after optimization: 1.3837507963180542 with beta sum per layer: [2.618283271789551, 409.713134765625, 361.06524658203125, 617.4719848632812, 702.1949462890625]
alpha/beta optimization time: 0.37533092498779297
This batch time : update_bounds func: 0.5585	 prepare: 0.1108	 bound: 0.3758	 transfer: 0.0027	 finalize: 0.0674
Accumulated time: update_bounds func: 28.3191	 prepare: 4.5871	 bound: 20.1424	 transfer: 0.0027	 finalize: 3.2845
batch bounding time:  0.5592293739318848
Current worst splitting domains [lb, ub] (depth):
[-0.10102,   inf] (117), [-0.10039,   inf] (117), [-0.09523,   inf] (117), [-0.09497,   inf] (117), [-0.09408,   inf] (117), [-0.09032,   inf] (117), [-0.08926,   inf] (117), [-0.08201,   inf] (117), [-0.08150,   inf] (117), [-0.08137,   inf] (117), [-0.08065,   inf] (117), [-0.07712,   inf] (117), [-0.07633,   inf] (117), [-0.07624,   inf] (117), [-0.07477,   inf] (117), [-0.07438,   inf] (117), [-0.07184,   inf] (117), [-0.07138,   inf] (117), [-0.07113,   inf] (117), [-0.07024,   inf] (117), 
length of domains: 359
Total time: 0.8389	 pickout: 0.0691	 decision: 0.1385	 get_bound: 0.5603	 add_domain: 0.0709
Current lb:-0.10102203488349915
29340 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 41.61514735221863

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([359, 200]) pre split depth:  1
batch:  torch.Size([359, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 143] [2, 143] [2, 26] [1, 73] [2, 26] [2, 197] [0, 146] [2, 169] [3, 12] [3, 0] 
regular batch size: 2*359, diving batch size 1*0
best_l after optimization: 3.466226577758789 with beta sum per layer: [3.7020456790924072, 404.1309509277344, 394.1141357421875, 577.4569091796875, 638.2925415039062]
alpha/beta optimization time: 0.3640553951263428
This batch time : update_bounds func: 0.6198	 prepare: 0.1148	 bound: 0.3645	 transfer: 0.0036	 finalize: 0.1353
Accumulated time: update_bounds func: 28.9389	 prepare: 4.7019	 bound: 20.5070	 transfer: 0.0036	 finalize: 3.4198
batch bounding time:  0.6206483840942383
Current worst splitting domains [lb, ub] (depth):
[-0.09914,   inf] (119), [-0.09826,   inf] (119), [-0.09455,   inf] (119), [-0.09336,   inf] (119), [-0.09315,   inf] (119), [-0.08700,   inf] (119), [-0.08472,   inf] (119), [-0.08035,   inf] (119), [-0.07907,   inf] (119), [-0.07858,   inf] (119), [-0.07856,   inf] (119), [-0.07812,   inf] (119), [-0.07507,   inf] (119), [-0.07225,   inf] (119), [-0.07161,   inf] (119), [-0.07023,   inf] (119), [-0.06940,   inf] (119), [-0.06785,   inf] (119), [-0.06724,   inf] (119), [-0.06718,   inf] (119), 
length of domains: 399
Total time: 0.8788	 pickout: 0.0758	 decision: 0.0990	 get_bound: 0.6218	 add_domain: 0.0822
Current lb:-0.09913569688796997
30058 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 42.508320808410645

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([399, 200]) pre split depth:  1
batch:  torch.Size([399, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 26] [2, 26] [0, 146] [2, 38] [1, 82] [4, 196] [2, 197] [2, 21] [2, 162] [3, 12] 
regular batch size: 2*399, diving batch size 1*0
best_l after optimization: 2.9164845943450928 with beta sum per layer: [5.101289749145508, 460.2659912109375, 444.82733154296875, 626.318359375, 682.0119018554688]
alpha/beta optimization time: 0.3679227828979492
This batch time : update_bounds func: 0.5717	 prepare: 0.1233	 bound: 0.3684	 transfer: 0.0029	 finalize: 0.0752
Accumulated time: update_bounds func: 29.5106	 prepare: 4.8252	 bound: 20.8754	 transfer: 0.0029	 finalize: 3.4950
batch bounding time:  0.5725710391998291
Current worst splitting domains [lb, ub] (depth):
[-0.09835,   inf] (121), [-0.09754,   inf] (121), [-0.09256,   inf] (121), [-0.09065,   inf] (121), [-0.09053,   inf] (121), [-0.08406,   inf] (121), [-0.08171,   inf] (121), [-0.07810,   inf] (121), [-0.07515,   inf] (121), [-0.07513,   inf] (121), [-0.07512,   inf] (121), [-0.07511,   inf] (121), [-0.07378,   inf] (121), [-0.07067,   inf] (121), [-0.06969,   inf] (121), [-0.06915,   inf] (121), [-0.06868,   inf] (121), [-0.06756,   inf] (121), [-0.06515,   inf] (121), [-0.06492,   inf] (121), 
length of domains: 431
Total time: 0.8432	 pickout: 0.0776	 decision: 0.1032	 get_bound: 0.5738	 add_domain: 0.0886
Current lb:-0.0983489453792572
30856 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 43.36586880683899

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([431, 200]) pre split depth:  1
batch:  torch.Size([431, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 38] [2, 38] [2, 38] [2, 21] [3, 0] [3, 0] [4, 196] [4, 127] [4, 142] [0, 146] 
regular batch size: 2*431, diving batch size 1*0
best_l after optimization: 1.9580559730529785 with beta sum per layer: [3.6966805458068848, 480.6896667480469, 490.24432373046875, 626.0067138671875, 764.1287841796875]
alpha/beta optimization time: 0.36282777786254883
This batch time : update_bounds func: 0.5846	 prepare: 0.1338	 bound: 0.3633	 transfer: 0.0034	 finalize: 0.0822
Accumulated time: update_bounds func: 30.0952	 prepare: 4.9589	 bound: 21.2386	 transfer: 0.0034	 finalize: 3.5772
batch bounding time:  0.5855112075805664
Current worst splitting domains [lb, ub] (depth):
[-0.09493,   inf] (123), [-0.09435,   inf] (123), [-0.08940,   inf] (123), [-0.08828,   inf] (123), [-0.08720,   inf] (123), [-0.08061,   inf] (123), [-0.07979,   inf] (123), [-0.07878,   inf] (123), [-0.07750,   inf] (123), [-0.07622,   inf] (123), [-0.07601,   inf] (123), [-0.07404,   inf] (123), [-0.07377,   inf] (123), [-0.07353,   inf] (123), [-0.07334,   inf] (123), [-0.07301,   inf] (123), [-0.07113,   inf] (123), [-0.07028,   inf] (123), [-0.06865,   inf] (123), [-0.06751,   inf] (123), 
length of domains: 450
Total time: 0.9233	 pickout: 0.0854	 decision: 0.1530	 get_bound: 0.5869	 add_domain: 0.0980
Current lb:-0.09492606669664383
31718 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 44.31039547920227

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([450, 200]) pre split depth:  1
batch:  torch.Size([450, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 0] [3, 0] [1, 14] [4, 127] [1, 14] [0, 146] [4, 127] [3, 0] [1, 135] [1, 135] 
regular batch size: 2*450, diving batch size 1*0
best_l after optimization: 4.031491756439209 with beta sum per layer: [2.939690351486206, 470.7471923828125, 515.085693359375, 698.5032958984375, 800.6895751953125]
alpha/beta optimization time: 0.3648240566253662
This batch time : update_bounds func: 0.6001	 prepare: 0.1405	 bound: 0.3653	 transfer: 0.0075	 finalize: 0.0847
Accumulated time: update_bounds func: 30.6954	 prepare: 5.0994	 bound: 21.6040	 transfer: 0.0075	 finalize: 3.6619
batch bounding time:  0.6010293960571289
Current worst splitting domains [lb, ub] (depth):
[-0.09121,   inf] (125), [-0.09071,   inf] (125), [-0.08713,   inf] (125), [-0.08614,   inf] (125), [-0.08562,   inf] (125), [-0.08508,   inf] (125), [-0.08110,   inf] (125), [-0.07749,   inf] (125), [-0.07484,   inf] (125), [-0.07427,   inf] (125), [-0.07399,   inf] (125), [-0.07379,   inf] (125), [-0.07316,   inf] (125), [-0.07275,   inf] (125), [-0.07249,   inf] (125), [-0.07050,   inf] (125), [-0.07010,   inf] (125), [-0.06945,   inf] (125), [-0.06651,   inf] (125), [-0.06608,   inf] (125), 
length of domains: 491
Total time: 0.9698	 pickout: 0.0928	 decision: 0.1709	 get_bound: 0.6024	 add_domain: 0.1036
Current lb:-0.09121048450469971
32618 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 45.29894256591797

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([491, 200]) pre split depth:  1
batch:  torch.Size([491, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 5] [3, 5] [3, 0] [3, 5] [1, 135] [3, 5] [1, 135] [0, 146] [1, 47] [2, 162] 
regular batch size: 2*491, diving batch size 1*0
best_l after optimization: 3.0107333660125732 with beta sum per layer: [4.56791877746582, 508.81927490234375, 580.0394287109375, 802.93701171875, 777.582763671875]
alpha/beta optimization time: 0.3692951202392578
This batch time : update_bounds func: 0.6323	 prepare: 0.1529	 bound: 0.3698	 transfer: 0.0071	 finalize: 0.1000
Accumulated time: update_bounds func: 31.3277	 prepare: 5.2523	 bound: 21.9737	 transfer: 0.0071	 finalize: 3.7619
batch bounding time:  0.6333284378051758
Current worst splitting domains [lb, ub] (depth):
[-0.08938,   inf] (127), [-0.08889,   inf] (127), [-0.08441,   inf] (127), [-0.08407,   inf] (127), [-0.08326,   inf] (127), [-0.08300,   inf] (127), [-0.07561,   inf] (127), [-0.07548,   inf] (127), [-0.07053,   inf] (127), [-0.07050,   inf] (127), [-0.07046,   inf] (127), [-0.07022,   inf] (127), [-0.07007,   inf] (127), [-0.06949,   inf] (127), [-0.06938,   inf] (127), [-0.06855,   inf] (127), [-0.06841,   inf] (127), [-0.06805,   inf] (127), [-0.06790,   inf] (127), [-0.06748,   inf] (127), 
length of domains: 500
Total time: 1.0113	 pickout: 0.0952	 decision: 0.1719	 get_bound: 0.6349	 add_domain: 0.1093
Current lb:-0.08937898278236389
33600 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 46.329612016677856

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 200]) pre split depth:  1
batch:  torch.Size([500, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 127] [1, 135] [2, 162] [4, 127] [4, 127] [3, 5] [3, 5] [4, 127] [4, 142] [4, 142] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: 5.704640865325928 with beta sum per layer: [3.974884033203125, 518.9786376953125, 610.2906494140625, 825.7757568359375, 707.4900512695312]
alpha/beta optimization time: 0.36431360244750977
This batch time : update_bounds func: 0.6241	 prepare: 0.1560	 bound: 0.3648	 transfer: 0.0069	 finalize: 0.0942
Accumulated time: update_bounds func: 31.9517	 prepare: 5.4083	 bound: 22.3386	 transfer: 0.0069	 finalize: 3.8561
batch bounding time:  0.6250576972961426
Current worst splitting domains [lb, ub] (depth):
[-0.08767,   inf] (129), [-0.08724,   inf] (129), [-0.08197,   inf] (129), [-0.08119,   inf] (129), [-0.08106,   inf] (129), [-0.07605,   inf] (129), [-0.07362,   inf] (129), [-0.07311,   inf] (129), [-0.06996,   inf] (129), [-0.06915,   inf] (129), [-0.06913,   inf] (129), [-0.06906,   inf] (129), [-0.06904,   inf] (129), [-0.06799,   inf] (129), [-0.06655,   inf] (129), [-0.06645,   inf] (129), [-0.06642,   inf] (129), [-0.06627,   inf] (129), [-0.06598,   inf] (129), [-0.06543,   inf] (129), 
length of domains: 578
Total time: 1.0382	 pickout: 0.1007	 decision: 0.1854	 get_bound: 0.6266	 add_domain: 0.1254
Current lb:-0.08766782283782959
34600 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 47.38629221916199

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([578, 200]) pre split depth:  1
batch:  torch.Size([578, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 146] [4, 142] [3, 5] [4, 142] [4, 127] [4, 142] [1, 47] [0, 146] [1, 135] [4, 141] 
regular batch size: 2*578, diving batch size 1*0
best_l after optimization: 5.442712306976318 with beta sum per layer: [6.435391426086426, 576.1862182617188, 720.0601806640625, 937.6426391601562, 843.0836181640625]
alpha/beta optimization time: 0.36626625061035156
This batch time : update_bounds func: 0.6610	 prepare: 0.1790	 bound: 0.3667	 transfer: 0.0046	 finalize: 0.1078
Accumulated time: update_bounds func: 32.6128	 prepare: 5.5873	 bound: 22.7053	 transfer: 0.0046	 finalize: 3.9639
batch bounding time:  0.6621499061584473
Current worst splitting domains [lb, ub] (depth):
[-0.08585,   inf] (131), [-0.08459,   inf] (131), [-0.08019,   inf] (131), [-0.07985,   inf] (131), [-0.07871,   inf] (131), [-0.07473,   inf] (131), [-0.06784,   inf] (131), [-0.06781,   inf] (131), [-0.06774,   inf] (131), [-0.06773,   inf] (131), [-0.06686,   inf] (131), [-0.06587,   inf] (131), [-0.06558,   inf] (131), [-0.06510,   inf] (131), [-0.06501,   inf] (131), [-0.06435,   inf] (131), [-0.06368,   inf] (131), [-0.06352,   inf] (131), [-0.06341,   inf] (131), [-0.06337,   inf] (131), 
length of domains: 658
Total time: 1.1145	 pickout: 0.1147	 decision: 0.1852	 get_bound: 0.6639	 add_domain: 0.1507
Current lb:-0.08585315942764282
35756 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 48.52911019325256

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([658, 200]) pre split depth:  1
batch:  torch.Size([658, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 150] [4, 127] [1, 47] [4, 172] [4, 142] [1, 47] [4, 150] [4, 150] [4, 150] [4, 150] 
regular batch size: 2*658, diving batch size 1*0
best_l after optimization: 2.3889341354370117 with beta sum per layer: [2.145455837249756, 646.772216796875, 862.8536376953125, 1036.8250732421875, 1031.79296875]
alpha/beta optimization time: 0.3725473880767822
This batch time : update_bounds func: 0.7124	 prepare: 0.2030	 bound: 0.3730	 transfer: 0.0088	 finalize: 0.1240
Accumulated time: update_bounds func: 33.3251	 prepare: 5.7903	 bound: 23.0783	 transfer: 0.0088	 finalize: 4.0879
batch bounding time:  0.7136881351470947
Current worst splitting domains [lb, ub] (depth):
[-0.08544,   inf] (133), [-0.08252,   inf] (133), [-0.07796,   inf] (133), [-0.07791,   inf] (133), [-0.07731,   inf] (133), [-0.07515,   inf] (133), [-0.06744,   inf] (133), [-0.06743,   inf] (133), [-0.06736,   inf] (133), [-0.06735,   inf] (133), [-0.06508,   inf] (133), [-0.06497,   inf] (133), [-0.06239,   inf] (133), [-0.06223,   inf] (133), [-0.06073,   inf] (133), [-0.06009,   inf] (133), [-0.05999,   inf] (133), [-0.05879,   inf] (133), [-0.05856,   inf] (133), [-0.05848,   inf] (133), 
length of domains: 696
Total time: 1.2921	 pickout: 0.1345	 decision: 0.2174	 get_bound: 0.7158	 add_domain: 0.2245
Current lb:-0.08544483780860901
37072 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 49.84771752357483

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([696, 200]) pre split depth:  1
batch:  torch.Size([696, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 195] [1, 14] [4, 150] [4, 150] [4, 172] [4, 142] [1, 135] [1, 135] [4, 195] [4, 195] 
regular batch size: 2*696, diving batch size 1*0
best_l after optimization: -1.8894063234329224 with beta sum per layer: [4.5655927658081055, 673.3861083984375, 912.0299072265625, 1065.752197265625, 1090.912109375]
alpha/beta optimization time: 0.3701193332672119
This batch time : update_bounds func: 0.7853	 prepare: 0.2154	 bound: 0.3706	 transfer: 0.0064	 finalize: 0.1897
Accumulated time: update_bounds func: 34.1104	 prepare: 6.0057	 bound: 23.4489	 transfer: 0.0064	 finalize: 4.2776
batch bounding time:  0.7865941524505615
Current worst splitting domains [lb, ub] (depth):
[-0.08463,   inf] (135), [-0.08107,   inf] (135), [-0.07758,   inf] (135), [-0.07752,   inf] (135), [-0.07550,   inf] (135), [-0.07430,   inf] (135), [-0.07354,   inf] (135), [-0.06659,   inf] (135), [-0.06658,   inf] (135), [-0.06658,   inf] (135), [-0.06656,   inf] (135), [-0.06388,   inf] (135), [-0.06326,   inf] (135), [-0.06306,   inf] (135), [-0.05831,   inf] (135), [-0.05765,   inf] (135), [-0.05709,   inf] (135), [-0.05677,   inf] (135), [-0.05672,   inf] (135), [-0.05656,   inf] (135), 
length of domains: 706
Total time: 1.2452	 pickout: 0.1373	 decision: 0.1593	 get_bound: 0.7887	 add_domain: 0.1599
Current lb:-0.08463296294212341
38464 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 51.12047338485718

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([706, 200]) pre split depth:  1
batch:  torch.Size([706, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 172] [4, 172] [4, 195] [0, 146] [4, 150] [3, 199] [4, 172] [0, 146] [1, 135] [1, 135] 
regular batch size: 2*706, diving batch size 1*0
best_l after optimization: -0.7224739789962769 with beta sum per layer: [3.098330020904541, 657.5306396484375, 921.856201171875, 1071.5467529296875, 1086.843994140625]
alpha/beta optimization time: 0.372267484664917
This batch time : update_bounds func: 0.7838	 prepare: 0.2178	 bound: 0.3728	 transfer: 0.0073	 finalize: 0.1325
Accumulated time: update_bounds func: 34.8943	 prepare: 6.2235	 bound: 23.8217	 transfer: 0.0073	 finalize: 4.4101
batch bounding time:  0.7853193283081055
Current worst splitting domains [lb, ub] (depth):
[-0.08277,   inf] (137), [-0.08248,   inf] (137), [-0.07919,   inf] (137), [-0.07897,   inf] (137), [-0.07678,   inf] (137), [-0.07646,   inf] (137), [-0.07509,   inf] (137), [-0.07284,   inf] (137), [-0.07144,   inf] (137), [-0.07104,   inf] (137), [-0.06595,   inf] (137), [-0.06591,   inf] (137), [-0.06448,   inf] (137), [-0.06363,   inf] (137), [-0.06195,   inf] (137), [-0.06176,   inf] (137), [-0.06140,   inf] (137), [-0.06139,   inf] (137), [-0.05746,   inf] (137), [-0.05712,   inf] (137), 
length of domains: 722
Total time: 1.2581	 pickout: 0.1393	 decision: 0.1661	 get_bound: 0.7876	 add_domain: 0.1650
Current lb:-0.08276930451393127
39876 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 52.406471967697144

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([722, 200]) pre split depth:  1
batch:  torch.Size([722, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 135] [1, 15] [4, 142] [4, 142] [1, 47] [1, 47] [4, 195] [4, 141] [4, 150] [4, 150] 
regular batch size: 2*722, diving batch size 1*0
best_l after optimization: -2.9194421768188477 with beta sum per layer: [4.697305202484131, 656.3825073242188, 940.6585693359375, 1113.446533203125, 1122.028564453125]
alpha/beta optimization time: 0.36894679069519043
This batch time : update_bounds func: 0.7461	 prepare: 0.2222	 bound: 0.3694	 transfer: 0.0118	 finalize: 0.1393
Accumulated time: update_bounds func: 35.6404	 prepare: 6.4457	 bound: 24.1911	 transfer: 0.0118	 finalize: 4.5494
batch bounding time:  0.7474753856658936
Current worst splitting domains [lb, ub] (depth):
[-0.08218,   inf] (139), [-0.08217,   inf] (139), [-0.07785,   inf] (139), [-0.07761,   inf] (139), [-0.07434,   inf] (139), [-0.07339,   inf] (139), [-0.07228,   inf] (139), [-0.07162,   inf] (139), [-0.07068,   inf] (139), [-0.07027,   inf] (139), [-0.06575,   inf] (139), [-0.06550,   inf] (139), [-0.06284,   inf] (139), [-0.06196,   inf] (139), [-0.06147,   inf] (139), [-0.06115,   inf] (139), [-0.06071,   inf] (139), [-0.06025,   inf] (139), [-0.06022,   inf] (139), [-0.05957,   inf] (139), 
length of domains: 674
Total time: 1.3599	 pickout: 0.1573	 decision: 0.2298	 get_bound: 0.7497	 add_domain: 0.2231
Current lb:-0.08217954635620117
41320 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 53.7966034412384

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([674, 200]) pre split depth:  1
batch:  torch.Size([674, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 135] [1, 15] [4, 141] [4, 141] [4, 141] [0, 146] [4, 195] [4, 150] [4, 195] [4, 195] 
regular batch size: 2*674, diving batch size 1*0
best_l after optimization: -5.736085414886475 with beta sum per layer: [4.496770858764648, 612.862548828125, 891.47119140625, 1015.94091796875, 982.2984619140625]
alpha/beta optimization time: 0.36799097061157227
This batch time : update_bounds func: 0.7675	 prepare: 0.2088	 bound: 0.3685	 transfer: 0.0063	 finalize: 0.1807
Accumulated time: update_bounds func: 36.4078	 prepare: 6.6545	 bound: 24.5596	 transfer: 0.0063	 finalize: 4.7301
batch bounding time:  0.7688002586364746
Current worst splitting domains [lb, ub] (depth):
[-0.08188,   inf] (141), [-0.08165,   inf] (141), [-0.07673,   inf] (141), [-0.07650,   inf] (141), [-0.07319,   inf] (141), [-0.07155,   inf] (141), [-0.07123,   inf] (141), [-0.07106,   inf] (141), [-0.06971,   inf] (141), [-0.06926,   inf] (141), [-0.06559,   inf] (141), [-0.06534,   inf] (141), [-0.06356,   inf] (141), [-0.06244,   inf] (141), [-0.06223,   inf] (141), [-0.06071,   inf] (141), [-0.06031,   inf] (141), [-0.05884,   inf] (141), [-0.05868,   inf] (141), [-0.05829,   inf] (141), 
length of domains: 658
Total time: 1.2160	 pickout: 0.1346	 decision: 0.1566	 get_bound: 0.7710	 add_domain: 0.1538
Current lb:-0.08187813311815262
42668 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 55.03940558433533

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([658, 200]) pre split depth:  1
batch:  torch.Size([658, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 146] [0, 146] [4, 150] [4, 150] [3, 199] [4, 141] [4, 195] [4, 141] [4, 141] [4, 141] 
regular batch size: 2*658, diving batch size 1*0
best_l after optimization: -3.5128302574157715 with beta sum per layer: [3.3043131828308105, 597.4288940429688, 882.673095703125, 925.3062744140625, 958.2630615234375]
alpha/beta optimization time: 0.3859403133392334
This batch time : update_bounds func: 0.7702	 prepare: 0.2020	 bound: 0.3864	 transfer: 0.0054	 finalize: 0.1244
Accumulated time: update_bounds func: 37.1780	 prepare: 6.8565	 bound: 24.9460	 transfer: 0.0054	 finalize: 4.8545
batch bounding time:  0.7713937759399414
Current worst splitting domains [lb, ub] (depth):
[-0.08139,   inf] (143), [-0.08117,   inf] (143), [-0.07629,   inf] (143), [-0.07607,   inf] (143), [-0.07202,   inf] (143), [-0.07043,   inf] (143), [-0.06974,   inf] (143), [-0.06946,   inf] (143), [-0.06829,   inf] (143), [-0.06792,   inf] (143), [-0.06517,   inf] (143), [-0.06517,   inf] (143), [-0.06067,   inf] (143), [-0.06045,   inf] (143), [-0.05921,   inf] (143), [-0.05878,   inf] (143), [-0.05830,   inf] (143), [-0.05821,   inf] (143), [-0.05813,   inf] (143), [-0.05784,   inf] (143), 
length of domains: 673
Total time: 1.2150	 pickout: 0.1287	 decision: 0.1524	 get_bound: 0.7734	 add_domain: 0.1605
Current lb:-0.0813894271850586
43984 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 56.28040051460266

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([673, 200]) pre split depth:  1
batch:  torch.Size([673, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 141] [4, 130] [3, 199] [4, 195] [1, 15] [1, 15] [1, 15] [1, 15] [1, 15] [1, 15] 
regular batch size: 2*673, diving batch size 1*0
best_l after optimization: -4.270998954772949 with beta sum per layer: [4.074893951416016, 616.8040161132812, 878.7224731445312, 919.750732421875, 990.205322265625]
alpha/beta optimization time: 0.38613295555114746
This batch time : update_bounds func: 0.7293	 prepare: 0.2082	 bound: 0.3866	 transfer: 0.0044	 finalize: 0.1269
Accumulated time: update_bounds func: 37.9073	 prepare: 7.0647	 bound: 25.3326	 transfer: 0.0044	 finalize: 4.9814
batch bounding time:  0.7306809425354004
Current worst splitting domains [lb, ub] (depth):
[-0.08071,   inf] (145), [-0.08026,   inf] (145), [-0.07524,   inf] (145), [-0.07520,   inf] (145), [-0.07176,   inf] (145), [-0.06934,   inf] (145), [-0.06907,   inf] (145), [-0.06868,   inf] (145), [-0.06798,   inf] (145), [-0.06753,   inf] (145), [-0.06537,   inf] (145), [-0.06297,   inf] (145), [-0.06289,   inf] (145), [-0.05845,   inf] (145), [-0.05772,   inf] (145), [-0.05759,   inf] (145), [-0.05686,   inf] (145), [-0.05651,   inf] (145), [-0.05626,   inf] (145), [-0.05617,   inf] (145), 
length of domains: 661
Total time: 1.2289	 pickout: 0.1326	 decision: 0.2060	 get_bound: 0.7328	 add_domain: 0.1575
Current lb:-0.0807090699672699
45330 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 57.53578495979309

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([661, 200]) pre split depth:  1
batch:  torch.Size([661, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 141] [4, 130] [3, 199] [1, 15] [4, 130] [2, 172] [3, 199] [4, 130] [3, 199] [4, 130] 
regular batch size: 2*661, diving batch size 1*0
best_l after optimization: -6.642406940460205 with beta sum per layer: [4.728104114532471, 620.9061279296875, 858.9282836914062, 857.514404296875, 1034.190185546875]
alpha/beta optimization time: 0.37368297576904297
This batch time : update_bounds func: 0.7714	 prepare: 0.2059	 bound: 0.3742	 transfer: 0.0042	 finalize: 0.1839
Accumulated time: update_bounds func: 38.6787	 prepare: 7.2706	 bound: 25.7067	 transfer: 0.0042	 finalize: 5.1654
batch bounding time:  0.7729520797729492
Current worst splitting domains [lb, ub] (depth):
[-0.07982,   inf] (147), [-0.07966,   inf] (147), [-0.07490,   inf] (147), [-0.07424,   inf] (147), [-0.07135,   inf] (147), [-0.06787,   inf] (147), [-0.06759,   inf] (147), [-0.06730,   inf] (147), [-0.06704,   inf] (147), [-0.06675,   inf] (147), [-0.06430,   inf] (147), [-0.06236,   inf] (147), [-0.06109,   inf] (147), [-0.05772,   inf] (147), [-0.05655,   inf] (147), [-0.05638,   inf] (147), [-0.05631,   inf] (147), [-0.05547,   inf] (147), [-0.05542,   inf] (147), [-0.05519,   inf] (147), 
length of domains: 624
Total time: 1.2600	 pickout: 0.1294	 decision: 0.2028	 get_bound: 0.7753	 add_domain: 0.1525
Current lb:-0.07981991767883301
46652 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 58.82230615615845

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([624, 200]) pre split depth:  1
batch:  torch.Size([624, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 199] [1, 125] [4, 195] [1, 15] [2, 172] [3, 199] [4, 130] [3, 48] [3, 199] [4, 130] 
regular batch size: 2*624, diving batch size 1*0
best_l after optimization: -5.540102481842041 with beta sum per layer: [2.8532426357269287, 586.4825439453125, 787.0567626953125, 808.8743896484375, 1005.93359375]
alpha/beta optimization time: 0.3643643856048584
This batch time : update_bounds func: 0.7394	 prepare: 0.1919	 bound: 0.3648	 transfer: 0.0041	 finalize: 0.1757
Accumulated time: update_bounds func: 39.4181	 prepare: 7.4625	 bound: 26.0715	 transfer: 0.0041	 finalize: 5.3411
batch bounding time:  0.7405750751495361
Current worst splitting domains [lb, ub] (depth):
[-0.07932,   inf] (149), [-0.07868,   inf] (149), [-0.07411,   inf] (149), [-0.07391,   inf] (149), [-0.07026,   inf] (149), [-0.06688,   inf] (149), [-0.06666,   inf] (149), [-0.06633,   inf] (149), [-0.06603,   inf] (149), [-0.06196,   inf] (149), [-0.06181,   inf] (149), [-0.06057,   inf] (149), [-0.06054,   inf] (149), [-0.05793,   inf] (149), [-0.05602,   inf] (149), [-0.05542,   inf] (149), [-0.05532,   inf] (149), [-0.05491,   inf] (149), [-0.05475,   inf] (149), [-0.05459,   inf] (149), 
length of domains: 600
Total time: 1.1594	 pickout: 0.1236	 decision: 0.1468	 get_bound: 0.7425	 add_domain: 0.1464
Current lb:-0.07931509613990784
47900 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 60.00725603103638

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([600, 200]) pre split depth:  1
batch:  torch.Size([600, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 199] [1, 125] [2, 162] [4, 130] [4, 152] [2, 162] [1, 125] [2, 162] [1, 125] [0, 146] 
regular batch size: 2*600, diving batch size 1*0
best_l after optimization: -4.3384809494018555 with beta sum per layer: [5.451530456542969, 575.8526611328125, 751.40478515625, 761.9305419921875, 1013.1466064453125]
alpha/beta optimization time: 0.3658161163330078
This batch time : update_bounds func: 0.7221	 prepare: 0.1856	 bound: 0.3663	 transfer: 0.0043	 finalize: 0.1626
Accumulated time: update_bounds func: 40.1402	 prepare: 7.6481	 bound: 26.4378	 transfer: 0.0043	 finalize: 5.5037
batch bounding time:  0.7232813835144043
Current worst splitting domains [lb, ub] (depth):
[-0.07832,   inf] (151), [-0.07824,   inf] (151), [-0.07350,   inf] (151), [-0.07350,   inf] (151), [-0.06985,   inf] (151), [-0.06631,   inf] (151), [-0.06600,   inf] (151), [-0.06579,   inf] (151), [-0.06572,   inf] (151), [-0.06174,   inf] (151), [-0.06018,   inf] (151), [-0.05981,   inf] (151), [-0.05671,   inf] (151), [-0.05561,   inf] (151), [-0.05541,   inf] (151), [-0.05530,   inf] (151), [-0.05456,   inf] (151), [-0.05452,   inf] (151), [-0.05397,   inf] (151), [-0.05377,   inf] (151), 
length of domains: 584
Total time: 1.1319	 pickout: 0.1188	 decision: 0.1429	 get_bound: 0.7252	 add_domain: 0.1450
Current lb:-0.07832398265600204
49100 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 61.163702964782715

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([584, 200]) pre split depth:  1
batch:  torch.Size([584, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 14] [4, 2] [4, 130] [4, 152] [4, 2] [4, 2] [1, 125] [4, 2] [1, 125] [2, 146] 
regular batch size: 2*584, diving batch size 1*0
best_l after optimization: -4.867093086242676 with beta sum per layer: [8.040924072265625, 558.3576049804688, 743.4934692382812, 697.5986328125, 1056.30517578125]
alpha/beta optimization time: 0.36324620246887207
This batch time : update_bounds func: 0.6592	 prepare: 0.1787	 bound: 0.3637	 transfer: 0.0038	 finalize: 0.1100
Accumulated time: update_bounds func: 40.7993	 prepare: 7.8268	 bound: 26.8015	 transfer: 0.0038	 finalize: 5.6138
batch bounding time:  0.6602940559387207
Current worst splitting domains [lb, ub] (depth):
[-0.07822,   inf] (153), [-0.07809,   inf] (153), [-0.07309,   inf] (153), [-0.07303,   inf] (153), [-0.06983,   inf] (153), [-0.06786,   inf] (153), [-0.06620,   inf] (153), [-0.06578,   inf] (153), [-0.06578,   inf] (153), [-0.06550,   inf] (153), [-0.06021,   inf] (153), [-0.06016,   inf] (153), [-0.05937,   inf] (153), [-0.05518,   inf] (153), [-0.05504,   inf] (153), [-0.05448,   inf] (153), [-0.05340,   inf] (153), [-0.05326,   inf] (153), [-0.05200,   inf] (153), [-0.05183,   inf] (153), 
length of domains: 548
Total time: 1.1041	 pickout: 0.1158	 decision: 0.1897	 get_bound: 0.6621	 add_domain: 0.1365
Current lb:-0.07821515202522278
50268 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 62.292359590530396

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([548, 200]) pre split depth:  1
batch:  torch.Size([548, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 162] [4, 2] [4, 152] [1, 125] [4, 134] [1, 47] [4, 152] [4, 152] [4, 2] [4, 2] 
regular batch size: 2*548, diving batch size 1*0
best_l after optimization: -5.8488335609436035 with beta sum per layer: [9.838908195495605, 534.7764892578125, 716.763671875, 627.248046875, 1013.808349609375]
alpha/beta optimization time: 0.36263108253479004
This batch time : update_bounds func: 0.6433	 prepare: 0.1694	 bound: 0.3631	 transfer: 0.0036	 finalize: 0.1047
Accumulated time: update_bounds func: 41.4426	 prepare: 7.9962	 bound: 27.1646	 transfer: 0.0036	 finalize: 5.7185
batch bounding time:  0.6443991661071777
Current worst splitting domains [lb, ub] (depth):
[-0.07806,   inf] (155), [-0.07772,   inf] (155), [-0.07277,   inf] (155), [-0.07263,   inf] (155), [-0.06971,   inf] (155), [-0.06755,   inf] (155), [-0.06578,   inf] (155), [-0.06575,   inf] (155), [-0.06548,   inf] (155), [-0.06537,   inf] (155), [-0.06004,   inf] (155), [-0.05991,   inf] (155), [-0.05536,   inf] (155), [-0.05516,   inf] (155), [-0.05491,   inf] (155), [-0.05480,   inf] (155), [-0.05408,   inf] (155), [-0.05308,   inf] (155), [-0.05280,   inf] (155), [-0.05197,   inf] (155), 
length of domains: 522
Total time: 1.0718	 pickout: 0.1107	 decision: 0.1837	 get_bound: 0.6461	 add_domain: 0.1313
Current lb:-0.07806345820426941
51364 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 63.38660907745361

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([522, 200]) pre split depth:  1
batch:  torch.Size([522, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 162] [1, 14] [4, 2] [1, 125] [1, 125] [3, 48] [4, 134] [4, 134] [4, 134] [4, 134] 
regular batch size: 2*522, diving batch size 1*0
best_l after optimization: -6.938116550445557 with beta sum per layer: [7.2195611000061035, 485.6649169921875, 700.4932861328125, 562.435791015625, 1025.845703125]
alpha/beta optimization time: 0.3647181987762451
This batch time : update_bounds func: 0.6408	 prepare: 0.1599	 bound: 0.3652	 transfer: 0.0076	 finalize: 0.1056
Accumulated time: update_bounds func: 42.0834	 prepare: 8.1561	 bound: 27.5298	 transfer: 0.0076	 finalize: 5.8241
batch bounding time:  0.6418368816375732
Current worst splitting domains [lb, ub] (depth):
[-0.07754,   inf] (157), [-0.07745,   inf] (157), [-0.07276,   inf] (157), [-0.07235,   inf] (157), [-0.06961,   inf] (157), [-0.06566,   inf] (157), [-0.06564,   inf] (157), [-0.06536,   inf] (157), [-0.06525,   inf] (157), [-0.06236,   inf] (157), [-0.05992,   inf] (157), [-0.05985,   inf] (157), [-0.05457,   inf] (157), [-0.05447,   inf] (157), [-0.05375,   inf] (157), [-0.05353,   inf] (157), [-0.05301,   inf] (157), [-0.05230,   inf] (157), [-0.05184,   inf] (157), [-0.04978,   inf] (157), 
length of domains: 488
Total time: 1.0461	 pickout: 0.1026	 decision: 0.1734	 get_bound: 0.6434	 add_domain: 0.1267
Current lb:-0.07754220813512802
52408 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 64.45509457588196

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([488, 200]) pre split depth:  1
batch:  torch.Size([488, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 134] [4, 134] [2, 172] [4, 2] [1, 37] [2, 162] [4, 152] [4, 152] [2, 172] [1, 47] 
regular batch size: 2*488, diving batch size 1*0
best_l after optimization: -2.7189862728118896 with beta sum per layer: [10.03335189819336, 477.2406005859375, 674.2623901367188, 491.14508056640625, 1003.379150390625]
alpha/beta optimization time: 0.36220526695251465
This batch time : update_bounds func: 0.6188	 prepare: 0.1546	 bound: 0.3627	 transfer: 0.0060	 finalize: 0.0931
Accumulated time: update_bounds func: 42.7022	 prepare: 8.3107	 bound: 27.8925	 transfer: 0.0060	 finalize: 5.9171
batch bounding time:  0.6197583675384521
Current worst splitting domains [lb, ub] (depth):
[-0.07742,   inf] (159), [-0.07733,   inf] (159), [-0.07258,   inf] (159), [-0.07233,   inf] (159), [-0.06654,   inf] (159), [-0.06628,   inf] (159), [-0.06523,   inf] (159), [-0.06522,   inf] (159), [-0.06506,   inf] (159), [-0.06494,   inf] (159), [-0.05972,   inf] (159), [-0.05918,   inf] (159), [-0.05446,   inf] (159), [-0.05439,   inf] (159), [-0.05324,   inf] (159), [-0.05305,   inf] (159), [-0.05289,   inf] (159), [-0.05227,   inf] (159), [-0.04963,   inf] (159), [-0.04938,   inf] (159), 
length of domains: 477
Total time: 1.0113	 pickout: 0.0975	 decision: 0.1698	 get_bound: 0.6213	 add_domain: 0.1228
Current lb:-0.07742142677307129
53384 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 65.48616051673889

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([477, 200]) pre split depth:  1
batch:  torch.Size([477, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 152] [4, 152] [4, 134] [4, 134] [2, 146] [2, 146] [1, 109] [1, 109] [1, 109] [1, 109] 
regular batch size: 2*477, diving batch size 1*0
best_l after optimization: -4.382392883300781 with beta sum per layer: [21.885093688964844, 493.8148193359375, 711.096435546875, 461.4889831542969, 1005.3099975585938]
alpha/beta optimization time: 0.3598215579986572
This batch time : update_bounds func: 0.6030	 prepare: 0.1468	 bound: 0.3603	 transfer: 0.0035	 finalize: 0.0903
Accumulated time: update_bounds func: 43.3052	 prepare: 8.4575	 bound: 28.2528	 transfer: 0.0035	 finalize: 6.0075
batch bounding time:  0.6039278507232666
Current worst splitting domains [lb, ub] (depth):
[-0.07699,   inf] (161), [-0.07689,   inf] (161), [-0.07245,   inf] (161), [-0.07221,   inf] (161), [-0.06719,   inf] (161), [-0.06617,   inf] (161), [-0.06585,   inf] (161), [-0.06504,   inf] (161), [-0.06360,   inf] (161), [-0.06359,   inf] (161), [-0.06263,   inf] (161), [-0.06184,   inf] (161), [-0.05938,   inf] (161), [-0.05844,   inf] (161), [-0.05376,   inf] (161), [-0.05356,   inf] (161), [-0.05302,   inf] (161), [-0.05189,   inf] (161), [-0.05145,   inf] (161), [-0.04902,   inf] (161), 
length of domains: 413
Total time: 0.9869	 pickout: 0.0945	 decision: 0.1794	 get_bound: 0.6054	 add_domain: 0.1076
Current lb:-0.07699465751647949
54338 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 66.49304294586182

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([413, 200]) pre split depth:  1
batch:  torch.Size([413, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 47] [1, 47] [2, 162] [1, 47] [1, 47] [0, 24] [0, 24] [1, 47] [1, 8] [1, 8] 
regular batch size: 2*413, diving batch size 1*0
best_l after optimization: -4.471163749694824 with beta sum per layer: [19.308244705200195, 437.7088623046875, 604.66845703125, 429.3844299316406, 848.1314697265625]
alpha/beta optimization time: 0.36683058738708496
This batch time : update_bounds func: 0.6294	 prepare: 0.1284	 bound: 0.3673	 transfer: 0.0030	 finalize: 0.1287
Accumulated time: update_bounds func: 43.9346	 prepare: 8.5859	 bound: 28.6201	 transfer: 0.0030	 finalize: 6.1362
batch bounding time:  0.6303195953369141
Current worst splitting domains [lb, ub] (depth):
[-0.07657,   inf] (163), [-0.07646,   inf] (163), [-0.07209,   inf] (163), [-0.06767,   inf] (163), [-0.06581,   inf] (163), [-0.06537,   inf] (163), [-0.06103,   inf] (163), [-0.06024,   inf] (163), [-0.06018,   inf] (163), [-0.05878,   inf] (163), [-0.05849,   inf] (163), [-0.05622,   inf] (163), [-0.05619,   inf] (163), [-0.05602,   inf] (163), [-0.05591,   inf] (163), [-0.05578,   inf] (163), [-0.05512,   inf] (163), [-0.05376,   inf] (163), [-0.05197,   inf] (163), [-0.05176,   inf] (163), 
length of domains: 361
Total time: 0.9145	 pickout: 0.0819	 decision: 0.1061	 get_bound: 0.6316	 add_domain: 0.0949
Current lb:-0.0765654668211937
55164 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 67.42439365386963

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([361, 200]) pre split depth:  1
batch:  torch.Size([361, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 24] [0, 24] [1, 47] [1, 109] [4, 59] [4, 59] [1, 135] [0, 94] [0, 94] [2, 56] 
regular batch size: 2*361, diving batch size 1*0
best_l after optimization: -5.4709906578063965 with beta sum per layer: [30.111568450927734, 418.5587463378906, 518.538330078125, 404.51904296875, 724.6287841796875]
alpha/beta optimization time: 0.35776424407958984
This batch time : update_bounds func: 0.5427	 prepare: 0.1116	 bound: 0.3582	 transfer: 0.0027	 finalize: 0.0685
Accumulated time: update_bounds func: 44.4773	 prepare: 8.6975	 bound: 28.9783	 transfer: 0.0027	 finalize: 6.2047
batch bounding time:  0.5434937477111816
Current worst splitting domains [lb, ub] (depth):
[-0.07626,   inf] (165), [-0.07615,   inf] (165), [-0.06696,   inf] (165), [-0.06528,   inf] (165), [-0.06495,   inf] (165), [-0.05875,   inf] (165), [-0.05872,   inf] (165), [-0.05697,   inf] (165), [-0.05622,   inf] (165), [-0.05616,   inf] (165), [-0.05610,   inf] (165), [-0.05511,   inf] (165), [-0.05459,   inf] (165), [-0.05444,   inf] (165), [-0.05376,   inf] (165), [-0.05341,   inf] (165), [-0.05184,   inf] (165), [-0.05134,   inf] (165), [-0.04998,   inf] (165), [-0.04884,   inf] (165), 
length of domains: 328
Total time: 0.7969	 pickout: 0.0714	 decision: 0.0947	 get_bound: 0.5446	 add_domain: 0.0862
Current lb:-0.07626333087682724
55886 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 68.23537588119507

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([328, 200]) pre split depth:  1
batch:  torch.Size([328, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 59] [4, 59] [1, 109] [0, 99] [0, 99] [1, 8] [1, 7] [3, 10] [0, 80] [0, 80] 
regular batch size: 2*328, diving batch size 1*0
best_l after optimization: -5.514041423797607 with beta sum per layer: [24.447467803955078, 396.9361572265625, 520.8648681640625, 369.205322265625, 649.6375122070312]
alpha/beta optimization time: 0.3570072650909424
This batch time : update_bounds func: 0.5254	 prepare: 0.1010	 bound: 0.3574	 transfer: 0.0025	 finalize: 0.0629
Accumulated time: update_bounds func: 45.0027	 prepare: 8.7985	 bound: 29.3358	 transfer: 0.0025	 finalize: 6.2676
batch bounding time:  0.5261242389678955
Current worst splitting domains [lb, ub] (depth):
[-0.07596,   inf] (167), [-0.07585,   inf] (167), [-0.06477,   inf] (167), [-0.06441,   inf] (167), [-0.05804,   inf] (167), [-0.05740,   inf] (167), [-0.05667,   inf] (167), [-0.05620,   inf] (167), [-0.05612,   inf] (167), [-0.05511,   inf] (167), [-0.05436,   inf] (167), [-0.05432,   inf] (167), [-0.05427,   inf] (167), [-0.05419,   inf] (167), [-0.05376,   inf] (167), [-0.05037,   inf] (167), [-0.04973,   inf] (167), [-0.04903,   inf] (167), [-0.04865,   inf] (167), [-0.04865,   inf] (167), 
length of domains: 292
Total time: 0.8008	 pickout: 0.0638	 decision: 0.1322	 get_bound: 0.5271	 add_domain: 0.0777
Current lb:-0.07596119493246078
56542 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 69.05032777786255

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([292, 200]) pre split depth:  1
batch:  torch.Size([292, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 99] [0, 99] [2, 60] [1, 7] [1, 8] [1, 7] [0, 24] [4, 59] [4, 59] [3, 164] 
regular batch size: 2*292, diving batch size 1*0
best_l after optimization: -4.755871295928955 with beta sum per layer: [27.13327407836914, 377.2611083984375, 485.313232421875, 346.8651123046875, 540.1885986328125]
alpha/beta optimization time: 0.35915207862854004
This batch time : update_bounds func: 0.5557	 prepare: 0.0912	 bound: 0.3596	 transfer: 0.0023	 finalize: 0.1014
Accumulated time: update_bounds func: 45.5585	 prepare: 8.8897	 bound: 29.6954	 transfer: 0.0023	 finalize: 6.3690
batch bounding time:  0.5564131736755371
Current worst splitting domains [lb, ub] (depth):
[-0.07569,   inf] (169), [-0.07557,   inf] (169), [-0.06422,   inf] (169), [-0.06280,   inf] (169), [-0.06078,   inf] (169), [-0.05667,   inf] (169), [-0.05661,   inf] (169), [-0.05619,   inf] (169), [-0.05612,   inf] (169), [-0.05574,   inf] (169), [-0.05545,   inf] (169), [-0.05485,   inf] (169), [-0.05426,   inf] (169), [-0.05426,   inf] (169), [-0.05425,   inf] (169), [-0.05410,   inf] (169), [-0.05376,   inf] (169), [-0.04971,   inf] (169), [-0.04846,   inf] (169), [-0.04754,   inf] (169), 
length of domains: 263
Total time: 0.7710	 pickout: 0.0583	 decision: 0.0848	 get_bound: 0.5573	 add_domain: 0.0706
Current lb:-0.0756867527961731
57126 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 69.83357763290405

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([263, 200]) pre split depth:  1
batch:  torch.Size([263, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 146] [1, 146] [2, 60] [1, 7] [1, 47] [4, 59] [1, 78] [0, 99] [1, 112] [0, 24] 
regular batch size: 2*263, diving batch size 1*0
best_l after optimization: -3.5433456897735596 with beta sum per layer: [25.016929626464844, 370.6639404296875, 436.6533203125, 325.354736328125, 472.4907531738281]
alpha/beta optimization time: 0.35657191276550293
This batch time : update_bounds func: 0.4913	 prepare: 0.0812	 bound: 0.3570	 transfer: 0.0022	 finalize: 0.0498
Accumulated time: update_bounds func: 46.0498	 prepare: 8.9709	 bound: 30.0524	 transfer: 0.0022	 finalize: 6.4188
batch bounding time:  0.49195384979248047
Current worst splitting domains [lb, ub] (depth):
[-0.07541,   inf] (171), [-0.07530,   inf] (171), [-0.06313,   inf] (171), [-0.06280,   inf] (171), [-0.06131,   inf] (171), [-0.05667,   inf] (171), [-0.05647,   inf] (171), [-0.05619,   inf] (171), [-0.05526,   inf] (171), [-0.05516,   inf] (171), [-0.05483,   inf] (171), [-0.05448,   inf] (171), [-0.05441,   inf] (171), [-0.05423,   inf] (171), [-0.05422,   inf] (171), [-0.05410,   inf] (171), [-0.05376,   inf] (171), [-0.05238,   inf] (171), [-0.04949,   inf] (171), [-0.04849,   inf] (171), 
length of domains: 268
Total time: 0.6955	 pickout: 0.0519	 decision: 0.0774	 get_bound: 0.4928	 add_domain: 0.0735
Current lb:-0.07541252672672272
57652 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 70.54249715805054

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([268, 200]) pre split depth:  1
batch:  torch.Size([268, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 123] [4, 123] [4, 123] [4, 123] [1, 47] [1, 146] [0, 146] [4, 123] [0, 173] [1, 178] 
regular batch size: 2*268, diving batch size 1*0
best_l after optimization: -3.3555967807769775 with beta sum per layer: [29.36272430419922, 379.47076416015625, 462.85150146484375, 347.9845275878906, 458.380126953125]
alpha/beta optimization time: 0.3597218990325928
This batch time : update_bounds func: 0.5420	 prepare: 0.0837	 bound: 0.3602	 transfer: 0.0022	 finalize: 0.0946
Accumulated time: update_bounds func: 46.5918	 prepare: 9.0546	 bound: 30.4125	 transfer: 0.0022	 finalize: 6.5133
batch bounding time:  0.5426476001739502
Current worst splitting domains [lb, ub] (depth):
[-0.07517,   inf] (173), [-0.07504,   inf] (173), [-0.06313,   inf] (173), [-0.06280,   inf] (173), [-0.06256,   inf] (173), [-0.06039,   inf] (173), [-0.05792,   inf] (173), [-0.05667,   inf] (173), [-0.05619,   inf] (173), [-0.05481,   inf] (173), [-0.05468,   inf] (173), [-0.05433,   inf] (173), [-0.05422,   inf] (173), [-0.05420,   inf] (173), [-0.05418,   inf] (173), [-0.05416,   inf] (173), [-0.05410,   inf] (173), [-0.05376,   inf] (173), [-0.05175,   inf] (173), [-0.05038,   inf] (173), 
length of domains: 275
Total time: 0.7472	 pickout: 0.0519	 decision: 0.0771	 get_bound: 0.5435	 add_domain: 0.0747
Current lb:-0.07516822963953018
58188 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 71.30038571357727

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([275, 200]) pre split depth:  1
batch:  torch.Size([275, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 155] [3, 155] [3, 155] [3, 155] [3, 48] [2, 172] [0, 146] [3, 155] [3, 155] [3, 33] 
regular batch size: 2*275, diving batch size 1*0
best_l after optimization: -7.918936729431152 with beta sum per layer: [29.953060150146484, 375.16314697265625, 493.3148498535156, 361.13568115234375, 475.022705078125]
alpha/beta optimization time: 0.3579275608062744
This batch time : update_bounds func: 0.5002	 prepare: 0.0862	 bound: 0.3584	 transfer: 0.0023	 finalize: 0.0519
Accumulated time: update_bounds func: 47.0920	 prepare: 9.1408	 bound: 30.7709	 transfer: 0.0023	 finalize: 6.5652
batch bounding time:  0.5008513927459717
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (175), [-0.07497,   inf] (175), [-0.06313,   inf] (175), [-0.06280,   inf] (175), [-0.05676,   inf] (175), [-0.05667,   inf] (175), [-0.05619,   inf] (175), [-0.05451,   inf] (175), [-0.05433,   inf] (175), [-0.05420,   inf] (175), [-0.05409,   inf] (175), [-0.05376,   inf] (175), [-0.05349,   inf] (175), [-0.05230,   inf] (175), [-0.05201,   inf] (175), [-0.05155,   inf] (175), [-0.05084,   inf] (175), [-0.05057,   inf] (175), [-0.05015,   inf] (175), [-0.04975,   inf] (175), 
length of domains: 283
Total time: 0.7142	 pickout: 0.0543	 decision: 0.0797	 get_bound: 0.5017	 add_domain: 0.0784
Current lb:-0.0751020684838295
58738 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 72.02513074874878

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([283, 200]) pre split depth:  1
batch:  torch.Size([283, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 56] [0, 56] [0, 56] [0, 56] [3, 48] [4, 123] [1, 146] [0, 24] [4, 123] [3, 155] 
regular batch size: 2*283, diving batch size 1*0
best_l after optimization: -6.60117769241333 with beta sum per layer: [34.146183013916016, 400.6791687011719, 521.3952026367188, 376.51983642578125, 498.57159423828125]
alpha/beta optimization time: 0.35909605026245117
This batch time : update_bounds func: 0.5467	 prepare: 0.0878	 bound: 0.3595	 transfer: 0.0023	 finalize: 0.0959
Accumulated time: update_bounds func: 47.6387	 prepare: 9.2286	 bound: 31.1304	 transfer: 0.0023	 finalize: 6.6611
batch bounding time:  0.547360897064209
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (177), [-0.07497,   inf] (177), [-0.06313,   inf] (177), [-0.06280,   inf] (177), [-0.05667,   inf] (177), [-0.05619,   inf] (177), [-0.05448,   inf] (177), [-0.05433,   inf] (177), [-0.05420,   inf] (177), [-0.05404,   inf] (177), [-0.05376,   inf] (177), [-0.05345,   inf] (177), [-0.05280,   inf] (177), [-0.05173,   inf] (177), [-0.05145,   inf] (177), [-0.05048,   inf] (177), [-0.04999,   inf] (177), [-0.04960,   inf] (177), [-0.04935,   inf] (177), [-0.04861,   inf] (177), 
length of domains: 299
Total time: 0.7683	 pickout: 0.0555	 decision: 0.0807	 get_bound: 0.5483	 add_domain: 0.0839
Current lb:-0.0751020684838295
59304 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 72.80469346046448

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([299, 200]) pre split depth:  1
batch:  torch.Size([299, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 64] [4, 64] [1, 146] [1, 146] [0, 99] [0, 56] [4, 59] [1, 9] [4, 64] [4, 64] 
regular batch size: 2*299, diving batch size 1*0
best_l after optimization: -3.8639955520629883 with beta sum per layer: [31.50531005859375, 422.70843505859375, 554.640380859375, 397.161865234375, 562.6075439453125]
alpha/beta optimization time: 0.3583228588104248
This batch time : update_bounds func: 0.5121	 prepare: 0.0930	 bound: 0.3587	 transfer: 0.0023	 finalize: 0.0568
Accumulated time: update_bounds func: 48.1508	 prepare: 9.3216	 bound: 31.4892	 transfer: 0.0023	 finalize: 6.7179
batch bounding time:  0.5127773284912109
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (179), [-0.07497,   inf] (179), [-0.06525,   inf] (179), [-0.06510,   inf] (179), [-0.06313,   inf] (179), [-0.06280,   inf] (179), [-0.05667,   inf] (179), [-0.05619,   inf] (179), [-0.05439,   inf] (179), [-0.05420,   inf] (179), [-0.05401,   inf] (179), [-0.05380,   inf] (179), [-0.05376,   inf] (179), [-0.05260,   inf] (179), [-0.05153,   inf] (179), [-0.05145,   inf] (179), [-0.05108,   inf] (179), [-0.05064,   inf] (179), [-0.04973,   inf] (179), [-0.04939,   inf] (179), 
length of domains: 323
Total time: 0.7462	 pickout: 0.0579	 decision: 0.0841	 get_bound: 0.5137	 add_domain: 0.0906
Current lb:-0.0751020684838295
59902 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 73.56240153312683

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([323, 200]) pre split depth:  1
batch:  torch.Size([323, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 59] [2, 59] [2, 172] [2, 172] [4, 64] [4, 64] [4, 64] [4, 64] [0, 99] [1, 146] 
regular batch size: 2*323, diving batch size 1*0
best_l after optimization: -3.219985008239746 with beta sum per layer: [37.219940185546875, 466.85791015625, 616.0284423828125, 426.88897705078125, 610.8504638671875]
alpha/beta optimization time: 0.3597748279571533
This batch time : update_bounds func: 0.5276	 prepare: 0.1028	 bound: 0.3602	 transfer: 0.0024	 finalize: 0.0603
Accumulated time: update_bounds func: 48.6784	 prepare: 9.4244	 bound: 31.8494	 transfer: 0.0024	 finalize: 6.7783
batch bounding time:  0.5283224582672119
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (181), [-0.07497,   inf] (181), [-0.06437,   inf] (181), [-0.06313,   inf] (181), [-0.06282,   inf] (181), [-0.06280,   inf] (181), [-0.05667,   inf] (181), [-0.05645,   inf] (181), [-0.05619,   inf] (181), [-0.05492,   inf] (181), [-0.05431,   inf] (181), [-0.05420,   inf] (181), [-0.05401,   inf] (181), [-0.05380,   inf] (181), [-0.05376,   inf] (181), [-0.05250,   inf] (181), [-0.05145,   inf] (181), [-0.05051,   inf] (181), [-0.05038,   inf] (181), [-0.05026,   inf] (181), 
length of domains: 354
Total time: 0.8255	 pickout: 0.0632	 decision: 0.1324	 get_bound: 0.5293	 add_domain: 0.1006
Current lb:-0.0751020684838295
60548 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 74.40022015571594

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([354, 200]) pre split depth:  1
batch:  torch.Size([354, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 161] [0, 161] [3, 48] [2, 59] [1, 109] [2, 59] [1, 78] [0, 146] [2, 59] [0, 146] 
regular batch size: 2*354, diving batch size 1*0
best_l after optimization: -4.219498157501221 with beta sum per layer: [43.905540466308594, 502.56561279296875, 659.4180297851562, 446.6271057128906, 692.913330078125]
alpha/beta optimization time: 0.35791921615600586
This batch time : update_bounds func: 0.5862	 prepare: 0.1093	 bound: 0.3584	 transfer: 0.0026	 finalize: 0.1143
Accumulated time: update_bounds func: 49.2646	 prepare: 9.5337	 bound: 32.2077	 transfer: 0.0026	 finalize: 6.8925
batch bounding time:  0.587195634841919
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (183), [-0.07497,   inf] (183), [-0.06313,   inf] (183), [-0.06280,   inf] (183), [-0.05851,   inf] (183), [-0.05746,   inf] (183), [-0.05667,   inf] (183), [-0.05619,   inf] (183), [-0.05604,   inf] (183), [-0.05571,   inf] (183), [-0.05431,   inf] (183), [-0.05420,   inf] (183), [-0.05401,   inf] (183), [-0.05380,   inf] (183), [-0.05376,   inf] (183), [-0.05237,   inf] (183), [-0.05145,   inf] (183), [-0.05107,   inf] (183), [-0.05092,   inf] (183), [-0.05072,   inf] (183), 
length of domains: 392
Total time: 0.8662	 pickout: 0.0680	 decision: 0.0943	 get_bound: 0.5884	 add_domain: 0.1154
Current lb:-0.0751020684838295
61256 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 75.28491568565369

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([392, 200]) pre split depth:  1
batch:  torch.Size([392, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 9] [1, 9] [1, 8] [1, 8] [0, 146] [1, 47] [1, 7] [1, 78] [3, 48] [1, 109] 
regular batch size: 2*392, diving batch size 1*0
best_l after optimization: -5.384371757507324 with beta sum per layer: [51.434322357177734, 547.993408203125, 782.20654296875, 479.75335693359375, 785.3158569335938]
alpha/beta optimization time: 0.37804532051086426
This batch time : update_bounds func: 0.5824	 prepare: 0.1222	 bound: 0.3785	 transfer: 0.0057	 finalize: 0.0740
Accumulated time: update_bounds func: 49.8470	 prepare: 9.6559	 bound: 32.5863	 transfer: 0.0057	 finalize: 6.9666
batch bounding time:  0.5831973552703857
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (185), [-0.07497,   inf] (185), [-0.06313,   inf] (185), [-0.06280,   inf] (185), [-0.05951,   inf] (185), [-0.05796,   inf] (185), [-0.05667,   inf] (185), [-0.05619,   inf] (185), [-0.05458,   inf] (185), [-0.05431,   inf] (185), [-0.05420,   inf] (185), [-0.05401,   inf] (185), [-0.05380,   inf] (185), [-0.05376,   inf] (185), [-0.05237,   inf] (185), [-0.05145,   inf] (185), [-0.05062,   inf] (185), [-0.04973,   inf] (185), [-0.04973,   inf] (185), [-0.04939,   inf] (185), 
length of domains: 442
Total time: 0.8951	 pickout: 0.0802	 decision: 0.1023	 get_bound: 0.5844	 add_domain: 0.1282
Current lb:-0.0751020684838295
62040 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 76.19537281990051

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([442, 200]) pre split depth:  1
batch:  torch.Size([442, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 89] [0, 89] [2, 118] [2, 118] [2, 118] [0, 146] [0, 56] [0, 161] [1, 47] [0, 56] 
regular batch size: 2*442, diving batch size 1*0
best_l after optimization: -7.299907207489014 with beta sum per layer: [60.819942474365234, 631.0593872070312, 890.6410522460938, 525.7431640625, 917.78076171875]
alpha/beta optimization time: 0.3791840076446533
This batch time : update_bounds func: 0.6073	 prepare: 0.1376	 bound: 0.3796	 transfer: 0.0050	 finalize: 0.0830
Accumulated time: update_bounds func: 50.4542	 prepare: 9.7935	 bound: 32.9659	 transfer: 0.0050	 finalize: 7.0496
batch bounding time:  0.6081726551055908
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (187), [-0.07497,   inf] (187), [-0.06313,   inf] (187), [-0.06280,   inf] (187), [-0.05940,   inf] (187), [-0.05733,   inf] (187), [-0.05667,   inf] (187), [-0.05619,   inf] (187), [-0.05431,   inf] (187), [-0.05420,   inf] (187), [-0.05401,   inf] (187), [-0.05380,   inf] (187), [-0.05376,   inf] (187), [-0.05237,   inf] (187), [-0.05145,   inf] (187), [-0.04973,   inf] (187), [-0.04973,   inf] (187), [-0.04939,   inf] (187), [-0.04870,   inf] (187), [-0.04861,   inf] (187), 
length of domains: 483
Total time: 1.0045	 pickout: 0.0857	 decision: 0.1676	 get_bound: 0.6096	 add_domain: 0.1417
Current lb:-0.0751020684838295
62924 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 77.21738648414612

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([483, 200]) pre split depth:  1
batch:  torch.Size([483, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 0] [0, 0] [0, 161] [2, 2] [0, 161] [0, 161] [2, 162] [1, 147] [3, 155] [0, 161] 
regular batch size: 2*483, diving batch size 1*0
best_l after optimization: -8.879768371582031 with beta sum per layer: [77.90977478027344, 710.2583618164062, 999.8703002929688, 548.958740234375, 1027.316650390625]
alpha/beta optimization time: 0.36422133445739746
This batch time : update_bounds func: 0.6138	 prepare: 0.1494	 bound: 0.3647	 transfer: 0.0061	 finalize: 0.0913
Accumulated time: update_bounds func: 51.0680	 prepare: 9.9429	 bound: 33.3306	 transfer: 0.0061	 finalize: 7.1408
batch bounding time:  0.6148226261138916
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (189), [-0.07497,   inf] (189), [-0.06313,   inf] (189), [-0.06280,   inf] (189), [-0.05940,   inf] (189), [-0.05732,   inf] (189), [-0.05667,   inf] (189), [-0.05619,   inf] (189), [-0.05431,   inf] (189), [-0.05420,   inf] (189), [-0.05401,   inf] (189), [-0.05380,   inf] (189), [-0.05376,   inf] (189), [-0.05237,   inf] (189), [-0.05145,   inf] (189), [-0.04973,   inf] (189), [-0.04973,   inf] (189), [-0.04939,   inf] (189), [-0.04861,   inf] (189), [-0.04834,   inf] (189), 
length of domains: 500
Total time: 1.0242	 pickout: 0.0940	 decision: 0.1660	 get_bound: 0.6163	 add_domain: 0.1479
Current lb:-0.0751020684838295
63890 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 78.26142764091492

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([500, 200]) pre split depth:  1
batch:  torch.Size([500, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 99] [4, 99] [2, 2] [0, 161] [2, 2] [2, 118] [1, 147] [4, 99] [4, 64] [1, 147] 
regular batch size: 2*500, diving batch size 1*0
best_l after optimization: -5.853974342346191 with beta sum per layer: [70.45264434814453, 745.2590942382812, 1028.9342041015625, 548.5916748046875, 1135.94921875]
alpha/beta optimization time: 0.3604094982147217
This batch time : update_bounds func: 0.6180	 prepare: 0.1541	 bound: 0.3609	 transfer: 0.0062	 finalize: 0.0945
Accumulated time: update_bounds func: 51.6861	 prepare: 10.0971	 bound: 33.6915	 transfer: 0.0062	 finalize: 7.2353
batch bounding time:  0.6190752983093262
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (191), [-0.07497,   inf] (191), [-0.06313,   inf] (191), [-0.06280,   inf] (191), [-0.05940,   inf] (191), [-0.05732,   inf] (191), [-0.05667,   inf] (191), [-0.05619,   inf] (191), [-0.05431,   inf] (191), [-0.05420,   inf] (191), [-0.05401,   inf] (191), [-0.05380,   inf] (191), [-0.05376,   inf] (191), [-0.05237,   inf] (191), [-0.05145,   inf] (191), [-0.04973,   inf] (191), [-0.04973,   inf] (191), [-0.04939,   inf] (191), [-0.04861,   inf] (191), [-0.04834,   inf] (191), 
length of domains: 524
Total time: 1.0478	 pickout: 0.0983	 decision: 0.1729	 get_bound: 0.6206	 add_domain: 0.1560
Current lb:-0.0751020684838295
64890 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 79.32989597320557

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([524, 200]) pre split depth:  1
batch:  torch.Size([524, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 118] [2, 118] [0, 89] [0, 89] [0, 89] [2, 2] [3, 78] [2, 118] [1, 9] [4, 99] 
regular batch size: 2*524, diving batch size 1*0
best_l after optimization: -8.874883651733398 with beta sum per layer: [81.14876556396484, 774.0499267578125, 1094.15966796875, 570.1942138671875, 1217.314697265625]
alpha/beta optimization time: 0.3628861904144287
This batch time : update_bounds func: 0.6311	 prepare: 0.1624	 bound: 0.3633	 transfer: 0.0045	 finalize: 0.0984
Accumulated time: update_bounds func: 52.3172	 prepare: 10.2594	 bound: 34.0548	 transfer: 0.0045	 finalize: 7.3337
batch bounding time:  0.6321356296539307
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (193), [-0.07497,   inf] (193), [-0.06313,   inf] (193), [-0.06280,   inf] (193), [-0.05940,   inf] (193), [-0.05732,   inf] (193), [-0.05667,   inf] (193), [-0.05619,   inf] (193), [-0.05431,   inf] (193), [-0.05420,   inf] (193), [-0.05401,   inf] (193), [-0.05380,   inf] (193), [-0.05376,   inf] (193), [-0.05237,   inf] (193), [-0.05145,   inf] (193), [-0.04973,   inf] (193), [-0.04973,   inf] (193), [-0.04939,   inf] (193), [-0.04861,   inf] (193), [-0.04834,   inf] (193), 
length of domains: 543
Total time: 1.0750	 pickout: 0.1027	 decision: 0.1753	 get_bound: 0.6338	 add_domain: 0.1633
Current lb:-0.0751020684838295
65938 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 80.42747116088867

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([543, 200]) pre split depth:  1
batch:  torch.Size([543, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 147] [1, 147] [4, 99] [4, 99] [2, 162] [0, 89] [0, 89] [0, 89] [2, 59] [2, 118] 
regular batch size: 2*543, diving batch size 1*0
best_l after optimization: -9.346480369567871 with beta sum per layer: [87.53305053710938, 801.5620727539062, 1081.9649658203125, 577.51171875, 1301.19970703125]
alpha/beta optimization time: 0.36127662658691406
This batch time : update_bounds func: 0.6429	 prepare: 0.1713	 bound: 0.3617	 transfer: 0.0047	 finalize: 0.1028
Accumulated time: update_bounds func: 52.9601	 prepare: 10.4308	 bound: 34.4165	 transfer: 0.0047	 finalize: 7.4365
batch bounding time:  0.6439552307128906
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (195), [-0.07497,   inf] (195), [-0.06313,   inf] (195), [-0.06280,   inf] (195), [-0.05940,   inf] (195), [-0.05732,   inf] (195), [-0.05667,   inf] (195), [-0.05619,   inf] (195), [-0.05431,   inf] (195), [-0.05420,   inf] (195), [-0.05401,   inf] (195), [-0.05380,   inf] (195), [-0.05376,   inf] (195), [-0.05237,   inf] (195), [-0.05145,   inf] (195), [-0.04973,   inf] (195), [-0.04973,   inf] (195), [-0.04966,   inf] (195), [-0.04939,   inf] (195), [-0.04861,   inf] (195), 
length of domains: 564
Total time: 1.1032	 pickout: 0.1075	 decision: 0.1798	 get_bound: 0.6456	 add_domain: 0.1703
Current lb:-0.0751020684838295
67024 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 81.55269455909729

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([564, 200]) pre split depth:  1
batch:  torch.Size([564, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 7] [1, 7] [0, 0] [0, 0] [4, 99] [4, 99] [0, 161] [0, 0] [0, 161] [0, 89] 
regular batch size: 2*564, diving batch size 1*0
best_l after optimization: -10.79959774017334 with beta sum per layer: [92.9557113647461, 831.61865234375, 1122.416015625, 605.4950561523438, 1403.4117431640625]
alpha/beta optimization time: 0.36261630058288574
This batch time : update_bounds func: 0.6555	 prepare: 0.1769	 bound: 0.3631	 transfer: 0.0053	 finalize: 0.1075
Accumulated time: update_bounds func: 53.6156	 prepare: 10.6076	 bound: 34.7796	 transfer: 0.0053	 finalize: 7.5441
batch bounding time:  0.6566262245178223
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (197), [-0.07497,   inf] (197), [-0.06313,   inf] (197), [-0.06280,   inf] (197), [-0.05940,   inf] (197), [-0.05732,   inf] (197), [-0.05667,   inf] (197), [-0.05619,   inf] (197), [-0.05431,   inf] (197), [-0.05420,   inf] (197), [-0.05401,   inf] (197), [-0.05380,   inf] (197), [-0.05376,   inf] (197), [-0.05237,   inf] (197), [-0.05145,   inf] (197), [-0.04973,   inf] (197), [-0.04973,   inf] (197), [-0.04948,   inf] (197), [-0.04939,   inf] (197), [-0.04861,   inf] (197), 
length of domains: 576
Total time: 1.1281	 pickout: 0.1107	 decision: 0.1833	 get_bound: 0.6584	 add_domain: 0.1758
Current lb:-0.0751020684838295
68152 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 82.70517301559448

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([576, 200]) pre split depth:  1
batch:  torch.Size([576, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 78] [1, 78] [1, 147] [2, 162] [0, 0] [2, 162] [4, 99] [0, 152] [0, 89] [0, 0] 
regular batch size: 2*576, diving batch size 1*0
best_l after optimization: -10.118322372436523 with beta sum per layer: [90.48892211914062, 855.4813232421875, 1157.531494140625, 614.9251708984375, 1459.567626953125]
alpha/beta optimization time: 0.36464715003967285
This batch time : update_bounds func: 0.6615	 prepare: 0.1794	 bound: 0.3651	 transfer: 0.0054	 finalize: 0.1088
Accumulated time: update_bounds func: 54.2771	 prepare: 10.7871	 bound: 35.1447	 transfer: 0.0054	 finalize: 7.6529
batch bounding time:  0.6626029014587402
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (199), [-0.07497,   inf] (199), [-0.06313,   inf] (199), [-0.06280,   inf] (199), [-0.05940,   inf] (199), [-0.05732,   inf] (199), [-0.05667,   inf] (199), [-0.05619,   inf] (199), [-0.05431,   inf] (199), [-0.05420,   inf] (199), [-0.05401,   inf] (199), [-0.05380,   inf] (199), [-0.05376,   inf] (199), [-0.05237,   inf] (199), [-0.05145,   inf] (199), [-0.04973,   inf] (199), [-0.04973,   inf] (199), [-0.04948,   inf] (199), [-0.04939,   inf] (199), [-0.04861,   inf] (199), 
length of domains: 607
Total time: 1.1514	 pickout: 0.1145	 decision: 0.1861	 get_bound: 0.6644	 add_domain: 0.1864
Current lb:-0.0751020684838295
69304 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 83.8812484741211

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([607, 200]) pre split depth:  1
batch:  torch.Size([607, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 152] [0, 152] [2, 162] [1, 147] [1, 147] [1, 147] [0, 0] [2, 199] [0, 0] [0, 152] 
regular batch size: 2*607, diving batch size 1*0
best_l after optimization: -10.757780075073242 with beta sum per layer: [106.36492156982422, 886.8072509765625, 1206.12353515625, 661.0503540039062, 1523.245361328125]
alpha/beta optimization time: 0.3653388023376465
This batch time : update_bounds func: 0.6760	 prepare: 0.1885	 bound: 0.3659	 transfer: 0.0046	 finalize: 0.1141
Accumulated time: update_bounds func: 54.9531	 prepare: 10.9756	 bound: 35.5106	 transfer: 0.0046	 finalize: 7.7670
batch bounding time:  0.6772825717926025
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (201), [-0.07497,   inf] (201), [-0.06313,   inf] (201), [-0.06280,   inf] (201), [-0.05940,   inf] (201), [-0.05732,   inf] (201), [-0.05667,   inf] (201), [-0.05619,   inf] (201), [-0.05431,   inf] (201), [-0.05420,   inf] (201), [-0.05401,   inf] (201), [-0.05380,   inf] (201), [-0.05376,   inf] (201), [-0.05237,   inf] (201), [-0.05145,   inf] (201), [-0.04973,   inf] (201), [-0.04973,   inf] (201), [-0.04948,   inf] (201), [-0.04939,   inf] (201), [-0.04861,   inf] (201), 
length of domains: 651
Total time: 1.2580	 pickout: 0.1213	 decision: 0.1923	 get_bound: 0.6792	 add_domain: 0.2651
Current lb:-0.0751020684838295
70518 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 85.16306829452515

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([651, 200]) pre split depth:  1
batch:  torch.Size([651, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 199] [2, 199] [0, 152] [0, 152] [0, 152] [0, 0] [3, 51] [4, 193] [2, 118] [2, 199] 
regular batch size: 2*651, diving batch size 1*0
best_l after optimization: -10.810737609863281 with beta sum per layer: [107.22189331054688, 967.3034057617188, 1332.084228515625, 698.7191772460938, 1644.319091796875]
alpha/beta optimization time: 0.365980863571167
This batch time : update_bounds func: 0.7611	 prepare: 0.2028	 bound: 0.3664	 transfer: 0.0055	 finalize: 0.1817
Accumulated time: update_bounds func: 55.7143	 prepare: 11.1784	 bound: 35.8770	 transfer: 0.0055	 finalize: 7.9487
batch bounding time:  0.7624921798706055
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (203), [-0.07497,   inf] (203), [-0.06313,   inf] (203), [-0.06280,   inf] (203), [-0.05940,   inf] (203), [-0.05732,   inf] (203), [-0.05667,   inf] (203), [-0.05619,   inf] (203), [-0.05431,   inf] (203), [-0.05420,   inf] (203), [-0.05401,   inf] (203), [-0.05380,   inf] (203), [-0.05376,   inf] (203), [-0.05237,   inf] (203), [-0.05145,   inf] (203), [-0.04973,   inf] (203), [-0.04973,   inf] (203), [-0.04948,   inf] (203), [-0.04939,   inf] (203), [-0.04861,   inf] (203), 
length of domains: 698
Total time: 1.2652	 pickout: 0.1274	 decision: 0.1508	 get_bound: 0.7647	 add_domain: 0.2224
Current lb:-0.0751020684838295
71820 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 86.45637321472168

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([698, 200]) pre split depth:  1
batch:  torch.Size([698, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 193] [4, 193] [1, 9] [4, 193] [4, 193] [0, 152] [2, 2] [4, 181] [4, 99] [4, 193] 
regular batch size: 2*698, diving batch size 1*0
best_l after optimization: -13.474159240722656 with beta sum per layer: [126.61021423339844, 1015.1651611328125, 1395.8056640625, 765.3958129882812, 1818.7086181640625]
alpha/beta optimization time: 0.398029088973999
This batch time : update_bounds func: 0.8135	 prepare: 0.2185	 bound: 0.3985	 transfer: 0.0089	 finalize: 0.1842
Accumulated time: update_bounds func: 56.5278	 prepare: 11.3969	 bound: 36.2755	 transfer: 0.0089	 finalize: 8.1329
batch bounding time:  0.8149325847625732
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (205), [-0.07497,   inf] (205), [-0.06313,   inf] (205), [-0.06280,   inf] (205), [-0.05940,   inf] (205), [-0.05732,   inf] (205), [-0.05667,   inf] (205), [-0.05619,   inf] (205), [-0.05431,   inf] (205), [-0.05420,   inf] (205), [-0.05401,   inf] (205), [-0.05380,   inf] (205), [-0.05376,   inf] (205), [-0.05237,   inf] (205), [-0.05145,   inf] (205), [-0.04973,   inf] (205), [-0.04973,   inf] (205), [-0.04948,   inf] (205), [-0.04939,   inf] (205), [-0.04861,   inf] (205), 
length of domains: 733
Total time: 1.3505	 pickout: 0.1384	 decision: 0.1598	 get_bound: 0.8172	 add_domain: 0.2351
Current lb:-0.0751020684838295
73216 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 87.84579038619995

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([733, 200]) pre split depth:  1
batch:  torch.Size([733, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 181] [4, 181] [4, 193] [4, 181] [4, 181] [4, 193] [0, 152] [2, 73] [2, 73] [4, 181] 
regular batch size: 2*733, diving batch size 1*0
best_l after optimization: -13.222734451293945 with beta sum per layer: [133.0958709716797, 1107.7818603515625, 1420.19921875, 823.535400390625, 1846.466064453125]
alpha/beta optimization time: 0.371204137802124
This batch time : update_bounds func: 0.7520	 prepare: 0.2287	 bound: 0.3717	 transfer: 0.0100	 finalize: 0.1383
Accumulated time: update_bounds func: 57.2798	 prepare: 11.6256	 bound: 36.6472	 transfer: 0.0100	 finalize: 8.2712
batch bounding time:  0.753342866897583
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (207), [-0.07497,   inf] (207), [-0.06313,   inf] (207), [-0.06280,   inf] (207), [-0.05940,   inf] (207), [-0.05732,   inf] (207), [-0.05667,   inf] (207), [-0.05619,   inf] (207), [-0.05431,   inf] (207), [-0.05420,   inf] (207), [-0.05401,   inf] (207), [-0.05380,   inf] (207), [-0.05376,   inf] (207), [-0.05237,   inf] (207), [-0.05145,   inf] (207), [-0.04973,   inf] (207), [-0.04973,   inf] (207), [-0.04948,   inf] (207), [-0.04939,   inf] (207), [-0.04861,   inf] (207), 
length of domains: 760
Total time: 1.4410	 pickout: 0.1498	 decision: 0.2234	 get_bound: 0.7556	 add_domain: 0.3122
Current lb:-0.0751020684838295
74682 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 89.31902766227722

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([760, 200]) pre split depth:  1
batch:  torch.Size([760, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 73] [2, 73] [4, 181] [1, 9] [3, 55] [4, 181] [2, 29] [3, 55] [3, 55] [2, 73] 
regular batch size: 2*760, diving batch size 1*0
best_l after optimization: -16.239849090576172 with beta sum per layer: [137.89675903320312, 1148.78857421875, 1446.185546875, 888.0325927734375, 1928.3204345703125]
alpha/beta optimization time: 0.37825775146484375
This batch time : update_bounds func: 0.8592	 prepare: 0.2397	 bound: 0.3787	 transfer: 0.0108	 finalize: 0.2261
Accumulated time: update_bounds func: 58.1389	 prepare: 11.8653	 bound: 37.0259	 transfer: 0.0108	 finalize: 8.4974
batch bounding time:  0.8606445789337158
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (209), [-0.07497,   inf] (209), [-0.06313,   inf] (209), [-0.06280,   inf] (209), [-0.05940,   inf] (209), [-0.05732,   inf] (209), [-0.05667,   inf] (209), [-0.05619,   inf] (209), [-0.05431,   inf] (209), [-0.05420,   inf] (209), [-0.05401,   inf] (209), [-0.05380,   inf] (209), [-0.05376,   inf] (209), [-0.05237,   inf] (209), [-0.05145,   inf] (209), [-0.04973,   inf] (209), [-0.04973,   inf] (209), [-0.04948,   inf] (209), [-0.04939,   inf] (209), [-0.04861,   inf] (209), 
length of domains: 786
Total time: 1.4418	 pickout: 0.1490	 decision: 0.1720	 get_bound: 0.8630	 add_domain: 0.2578
Current lb:-0.0751020684838295
76202 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 90.79586386680603

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([786, 200]) pre split depth:  1
batch:  torch.Size([786, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 55] [3, 55] [3, 55] [3, 55] [3, 110] [3, 55] [1, 128] [3, 110] [3, 48] [3, 55] 
regular batch size: 2*786, diving batch size 1*0
best_l after optimization: -16.590606689453125 with beta sum per layer: [150.73731994628906, 1175.6278076171875, 1505.736572265625, 936.1324462890625, 1912.993896484375]
alpha/beta optimization time: 0.38561153411865234
This batch time : update_bounds func: 0.7915	 prepare: 0.2431	 bound: 0.3861	 transfer: 0.0107	 finalize: 0.1480
Accumulated time: update_bounds func: 58.9304	 prepare: 12.1084	 bound: 37.4120	 transfer: 0.0107	 finalize: 8.6453
batch bounding time:  0.7930576801300049
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (211), [-0.07497,   inf] (211), [-0.06313,   inf] (211), [-0.06280,   inf] (211), [-0.05940,   inf] (211), [-0.05732,   inf] (211), [-0.05667,   inf] (211), [-0.05619,   inf] (211), [-0.05431,   inf] (211), [-0.05420,   inf] (211), [-0.05401,   inf] (211), [-0.05380,   inf] (211), [-0.05376,   inf] (211), [-0.05237,   inf] (211), [-0.05145,   inf] (211), [-0.04973,   inf] (211), [-0.04973,   inf] (211), [-0.04948,   inf] (211), [-0.04939,   inf] (211), [-0.04861,   inf] (211), 
length of domains: 836
Total time: 1.5328	 pickout: 0.1574	 decision: 0.2418	 get_bound: 0.7955	 add_domain: 0.3381
Current lb:-0.0751020684838295
77774 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 92.36247205734253

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([836, 200]) pre split depth:  1
batch:  torch.Size([836, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 110] [3, 110] [3, 110] [3, 110] [1, 9] [1, 9] [2, 73] [0, 173] [1, 192] [3, 110] 
regular batch size: 2*836, diving batch size 1*0
best_l after optimization: -18.635639190673828 with beta sum per layer: [161.1533203125, 1269.2672119140625, 1611.3896484375, 1010.829833984375, 2002.5123291015625]
alpha/beta optimization time: 0.38262367248535156
This batch time : update_bounds func: 0.8659	 prepare: 0.2590	 bound: 0.3831	 transfer: 0.0078	 finalize: 0.2119
Accumulated time: update_bounds func: 59.7963	 prepare: 12.3674	 bound: 37.7951	 transfer: 0.0078	 finalize: 8.8572
batch bounding time:  0.8674931526184082
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (213), [-0.07497,   inf] (213), [-0.06313,   inf] (213), [-0.06280,   inf] (213), [-0.05940,   inf] (213), [-0.05732,   inf] (213), [-0.05667,   inf] (213), [-0.05619,   inf] (213), [-0.05431,   inf] (213), [-0.05420,   inf] (213), [-0.05401,   inf] (213), [-0.05380,   inf] (213), [-0.05376,   inf] (213), [-0.05237,   inf] (213), [-0.05145,   inf] (213), [-0.04973,   inf] (213), [-0.04973,   inf] (213), [-0.04948,   inf] (213), [-0.04939,   inf] (213), [-0.04861,   inf] (213), 
length of domains: 869
Total time: 1.5087	 pickout: 0.1660	 decision: 0.1864	 get_bound: 0.8701	 add_domain: 0.2862
Current lb:-0.0751020684838295
79446 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 93.9085624217987

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([869, 200]) pre split depth:  1
batch:  torch.Size([869, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 8] [1, 8] [1, 192] [1, 192] [1, 192] [3, 110] [4, 193] [0, 107] [1, 128] [0, 173] 
regular batch size: 2*869, diving batch size 1*0
best_l after optimization: -19.07063865661621 with beta sum per layer: [176.2586669921875, 1331.701171875, 1671.8885498046875, 1084.180908203125, 2027.6060791015625]
alpha/beta optimization time: 0.3777129650115967
This batch time : update_bounds func: 0.8953	 prepare: 0.2775	 bound: 0.3782	 transfer: 0.0073	 finalize: 0.2284
Accumulated time: update_bounds func: 60.6916	 prepare: 12.6448	 bound: 38.1733	 transfer: 0.0073	 finalize: 9.0856
batch bounding time:  0.8969204425811768
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (215), [-0.07497,   inf] (215), [-0.07445,   inf] (215), [-0.07434,   inf] (215), [-0.06313,   inf] (215), [-0.06280,   inf] (215), [-0.05940,   inf] (215), [-0.05732,   inf] (215), [-0.05667,   inf] (215), [-0.05619,   inf] (215), [-0.05431,   inf] (215), [-0.05420,   inf] (215), [-0.05401,   inf] (215), [-0.05380,   inf] (215), [-0.05376,   inf] (215), [-0.05237,   inf] (215), [-0.05145,   inf] (215), [-0.04973,   inf] (215), [-0.04973,   inf] (215), [-0.04948,   inf] (215), 
length of domains: 918
Total time: 1.6275	 pickout: 0.1735	 decision: 0.2487	 get_bound: 0.8997	 add_domain: 0.3056
Current lb:-0.0751020684838295
81184 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 95.5737030506134

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([918, 200]) pre split depth:  1
batch:  torch.Size([918, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 107] [0, 107] [0, 107] [0, 107] [2, 199] [2, 199] [0, 107] [0, 107] [4, 181] [4, 165] 
regular batch size: 2*918, diving batch size 1*0
best_l after optimization: -19.041423797607422 with beta sum per layer: [187.47714233398438, 1390.939697265625, 1695.91015625, 1190.716796875, 2132.383056640625]
alpha/beta optimization time: 0.38231635093688965
This batch time : update_bounds func: 0.9396	 prepare: 0.2870	 bound: 0.3828	 transfer: 0.0136	 finalize: 0.2511
Accumulated time: update_bounds func: 61.6312	 prepare: 12.9318	 bound: 38.5561	 transfer: 0.0136	 finalize: 9.3367
batch bounding time:  0.9416308403015137
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (217), [-0.07497,   inf] (217), [-0.07445,   inf] (217), [-0.07434,   inf] (217), [-0.06313,   inf] (217), [-0.06280,   inf] (217), [-0.05940,   inf] (217), [-0.05732,   inf] (217), [-0.05667,   inf] (217), [-0.05619,   inf] (217), [-0.05431,   inf] (217), [-0.05420,   inf] (217), [-0.05401,   inf] (217), [-0.05380,   inf] (217), [-0.05376,   inf] (217), [-0.05237,   inf] (217), [-0.05145,   inf] (217), [-0.04973,   inf] (217), [-0.04973,   inf] (217), [-0.04948,   inf] (217), 
length of domains: 954
Total time: 1.7441	 pickout: 0.1999	 decision: 0.2795	 get_bound: 0.9447	 add_domain: 0.3199
Current lb:-0.0751020684838295
83020 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 97.35774993896484

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([954, 200]) pre split depth:  1
batch:  torch.Size([954, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 165] [4, 165] [0, 173] [0, 173] [0, 107] [0, 107] [2, 199] [1, 192] [2, 59] [3, 151] 
regular batch size: 2*954, diving batch size 1*0
best_l after optimization: -22.09433364868164 with beta sum per layer: [199.17807006835938, 1431.8603515625, 1775.22119140625, 1237.103515625, 2218.83984375]
alpha/beta optimization time: 0.38458895683288574
This batch time : update_bounds func: 0.8794	 prepare: 0.2977	 bound: 0.3851	 transfer: 0.0109	 finalize: 0.1806
Accumulated time: update_bounds func: 62.5107	 prepare: 13.2295	 bound: 38.9412	 transfer: 0.0109	 finalize: 9.5174
batch bounding time:  0.8812220096588135
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (219), [-0.07497,   inf] (219), [-0.07445,   inf] (219), [-0.07434,   inf] (219), [-0.06313,   inf] (219), [-0.06280,   inf] (219), [-0.05940,   inf] (219), [-0.05732,   inf] (219), [-0.05667,   inf] (219), [-0.05619,   inf] (219), [-0.05431,   inf] (219), [-0.05420,   inf] (219), [-0.05401,   inf] (219), [-0.05380,   inf] (219), [-0.05376,   inf] (219), [-0.05319,   inf] (219), [-0.05237,   inf] (219), [-0.05145,   inf] (219), [-0.04973,   inf] (219), [-0.04973,   inf] (219), 
length of domains: 998
Total time: 1.7558	 pickout: 0.1920	 decision: 0.2696	 get_bound: 0.8841	 add_domain: 0.4100
Current lb:-0.0751020684838295
84928 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 99.15430569648743

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([998, 200]) pre split depth:  1
batch:  torch.Size([998, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 128] [1, 128] [4, 165] [4, 165] [4, 165] [4, 165] [4, 165] [0, 173] [3, 199] [4, 132] 
regular batch size: 2*998, diving batch size 1*0
best_l after optimization: -26.454832077026367 with beta sum per layer: [194.78945922851562, 1525.02392578125, 1826.44482421875, 1306.9449462890625, 2295.1884765625]
alpha/beta optimization time: 0.3863241672515869
This batch time : update_bounds func: 0.9554	 prepare: 0.3119	 bound: 0.3868	 transfer: 0.0081	 finalize: 0.1881
Accumulated time: update_bounds func: 63.4661	 prepare: 13.5415	 bound: 39.3280	 transfer: 0.0081	 finalize: 9.7055
batch bounding time:  0.957261323928833
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (221), [-0.07497,   inf] (221), [-0.07445,   inf] (221), [-0.07434,   inf] (221), [-0.06313,   inf] (221), [-0.06280,   inf] (221), [-0.05940,   inf] (221), [-0.05732,   inf] (221), [-0.05667,   inf] (221), [-0.05619,   inf] (221), [-0.05431,   inf] (221), [-0.05420,   inf] (221), [-0.05401,   inf] (221), [-0.05380,   inf] (221), [-0.05376,   inf] (221), [-0.05308,   inf] (221), [-0.05237,   inf] (221), [-0.05145,   inf] (221), [-0.04973,   inf] (221), [-0.04973,   inf] (221), 
length of domains: 1036
Total time: 1.8144	 pickout: 0.2025	 decision: 0.2190	 get_bound: 0.9605	 add_domain: 0.4324
Current lb:-0.0751020684838295
86924 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 101.01195430755615

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 173] [0, 173] [1, 128] [1, 128] [1, 78] [0, 80] [1, 109] [2, 199] [0, 80] [3, 78] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -26.193893432617188 with beta sum per layer: [226.48269653320312, 1561.55908203125, 1857.254638671875, 1293.7459716796875, 2390.06884765625]
alpha/beta optimization time: 0.38477659225463867
This batch time : update_bounds func: 0.9759	 prepare: 0.3189	 bound: 0.3853	 transfer: 0.0100	 finalize: 0.1939
Accumulated time: update_bounds func: 64.4420	 prepare: 13.8604	 bound: 39.7132	 transfer: 0.0100	 finalize: 9.8994
batch bounding time:  0.9778003692626953
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (223), [-0.07497,   inf] (223), [-0.07445,   inf] (223), [-0.07434,   inf] (223), [-0.06313,   inf] (223), [-0.06280,   inf] (223), [-0.06201,   inf] (223), [-0.05940,   inf] (223), [-0.05732,   inf] (223), [-0.05667,   inf] (223), [-0.05619,   inf] (223), [-0.05431,   inf] (223), [-0.05420,   inf] (223), [-0.05401,   inf] (223), [-0.05380,   inf] (223), [-0.05380,   inf] (223), [-0.05376,   inf] (223), [-0.05308,   inf] (223), [-0.05237,   inf] (223), [-0.05145,   inf] (223), 
length of domains: 1087
Total time: 1.8611	 pickout: 0.2049	 decision: 0.2263	 get_bound: 0.9810	 add_domain: 0.4489
Current lb:-0.0751020684838295
88972 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 102.92890071868896

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 192] [1, 192] [1, 192] [1, 192] [1, 109] [1, 78] [1, 78] [1, 14] [4, 165] [4, 165] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -29.190357208251953 with beta sum per layer: [219.0728759765625, 1513.012451171875, 1871.268798828125, 1299.812255859375, 2339.5166015625]
alpha/beta optimization time: 0.38752102851867676
This batch time : update_bounds func: 1.0044	 prepare: 0.3202	 bound: 0.3880	 transfer: 0.0241	 finalize: 0.1963
Accumulated time: update_bounds func: 65.4464	 prepare: 14.1806	 bound: 40.1012	 transfer: 0.0241	 finalize: 10.0957
batch bounding time:  1.006274700164795
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (225), [-0.07497,   inf] (225), [-0.07445,   inf] (225), [-0.07434,   inf] (225), [-0.06313,   inf] (225), [-0.06280,   inf] (225), [-0.06199,   inf] (225), [-0.05940,   inf] (225), [-0.05732,   inf] (225), [-0.05667,   inf] (225), [-0.05619,   inf] (225), [-0.05431,   inf] (225), [-0.05420,   inf] (225), [-0.05401,   inf] (225), [-0.05380,   inf] (225), [-0.05376,   inf] (225), [-0.05308,   inf] (225), [-0.05237,   inf] (225), [-0.05149,   inf] (225), [-0.05145,   inf] (225), 
length of domains: 1134
Total time: 1.9093	 pickout: 0.2213	 decision: 0.2299	 get_bound: 1.0094	 add_domain: 0.4487
Current lb:-0.0751020684838295
91020 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 104.88262891769409

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 151] [3, 151] [3, 151] [3, 151] [0, 80] [1, 109] [1, 109] [1, 78] [1, 109] [1, 9] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -25.416786193847656 with beta sum per layer: [209.15652465820312, 1487.8734130859375, 1854.4599609375, 1296.136962890625, 2367.783447265625]
alpha/beta optimization time: 0.39957427978515625
This batch time : update_bounds func: 0.9978	 prepare: 0.3151	 bound: 0.4001	 transfer: 0.0239	 finalize: 0.1924
Accumulated time: update_bounds func: 66.4442	 prepare: 14.4958	 bound: 40.5013	 transfer: 0.0239	 finalize: 10.2881
batch bounding time:  0.999762773513794
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (227), [-0.07497,   inf] (227), [-0.07445,   inf] (227), [-0.07434,   inf] (227), [-0.06313,   inf] (227), [-0.06280,   inf] (227), [-0.06212,   inf] (227), [-0.06199,   inf] (227), [-0.05940,   inf] (227), [-0.05732,   inf] (227), [-0.05667,   inf] (227), [-0.05619,   inf] (227), [-0.05431,   inf] (227), [-0.05420,   inf] (227), [-0.05401,   inf] (227), [-0.05380,   inf] (227), [-0.05376,   inf] (227), [-0.05308,   inf] (227), [-0.05237,   inf] (227), [-0.05145,   inf] (227), 
length of domains: 1180
Total time: 1.8864	 pickout: 0.2065	 decision: 0.2236	 get_bound: 1.0029	 add_domain: 0.4533
Current lb:-0.0751020684838295
93068 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 106.81378841400146

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 132] [4, 132] [4, 132] [4, 132] [3, 151] [1, 14] [3, 151] [1, 14] [3, 151] [1, 78] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -24.246978759765625 with beta sum per layer: [199.5938720703125, 1472.8369140625, 1846.318359375, 1344.550537109375, 2376.84423828125]
alpha/beta optimization time: 0.38028836250305176
This batch time : update_bounds func: 0.9810	 prepare: 0.3163	 bound: 0.3807	 transfer: 0.0239	 finalize: 0.1937
Accumulated time: update_bounds func: 67.4252	 prepare: 14.8121	 bound: 40.8821	 transfer: 0.0239	 finalize: 10.4818
batch bounding time:  0.9829916954040527
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (229), [-0.07497,   inf] (229), [-0.07445,   inf] (229), [-0.07434,   inf] (229), [-0.06313,   inf] (229), [-0.06280,   inf] (229), [-0.06207,   inf] (229), [-0.06199,   inf] (229), [-0.05940,   inf] (229), [-0.05732,   inf] (229), [-0.05667,   inf] (229), [-0.05619,   inf] (229), [-0.05431,   inf] (229), [-0.05420,   inf] (229), [-0.05401,   inf] (229), [-0.05380,   inf] (229), [-0.05376,   inf] (229), [-0.05308,   inf] (229), [-0.05300,   inf] (229), [-0.05237,   inf] (229), 
length of domains: 1232
Total time: 1.8770	 pickout: 0.2071	 decision: 0.2222	 get_bound: 0.9863	 add_domain: 0.4613
Current lb:-0.0751020684838295
95116 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 108.7359447479248

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 80] [0, 80] [3, 78] [3, 78] [4, 132] [3, 151] [1, 14] [3, 151] [4, 132] [1, 14] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -27.003915786743164 with beta sum per layer: [220.65765380859375, 1388.8194580078125, 1868.70263671875, 1351.0693359375, 2362.1435546875]
alpha/beta optimization time: 0.3849325180053711
This batch time : update_bounds func: 1.0620	 prepare: 0.4498	 bound: 0.3854	 transfer: 0.0238	 finalize: 0.1967
Accumulated time: update_bounds func: 68.4871	 prepare: 15.2619	 bound: 41.2675	 transfer: 0.0238	 finalize: 10.6784
batch bounding time:  1.0638914108276367
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (231), [-0.07497,   inf] (231), [-0.07445,   inf] (231), [-0.07436,   inf] (231), [-0.07434,   inf] (231), [-0.07424,   inf] (231), [-0.06313,   inf] (231), [-0.06280,   inf] (231), [-0.06207,   inf] (231), [-0.06199,   inf] (231), [-0.05940,   inf] (231), [-0.05732,   inf] (231), [-0.05667,   inf] (231), [-0.05619,   inf] (231), [-0.05431,   inf] (231), [-0.05420,   inf] (231), [-0.05401,   inf] (231), [-0.05380,   inf] (231), [-0.05376,   inf] (231), [-0.05308,   inf] (231), 
length of domains: 1280
Total time: 2.0935	 pickout: 0.2080	 decision: 0.3230	 get_bound: 1.0671	 add_domain: 0.4954
Current lb:-0.0751020684838295
97164 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 110.87549829483032

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 78] [3, 78] [3, 164] [3, 78] [3, 164] [3, 78] [2, 73] [4, 132] [4, 132] [4, 132] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -24.268709182739258 with beta sum per layer: [214.3254852294922, 1372.542236328125, 1845.889892578125, 1344.1546630859375, 2349.236083984375]
alpha/beta optimization time: 0.3809084892272949
This batch time : update_bounds func: 0.9317	 prepare: 0.3199	 bound: 0.3814	 transfer: 0.0240	 finalize: 0.2008
Accumulated time: update_bounds func: 69.4189	 prepare: 15.5818	 bound: 41.6489	 transfer: 0.0240	 finalize: 10.8793
batch bounding time:  0.9336228370666504
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (233), [-0.07497,   inf] (233), [-0.07445,   inf] (233), [-0.07436,   inf] (233), [-0.07434,   inf] (233), [-0.07424,   inf] (233), [-0.06313,   inf] (233), [-0.06280,   inf] (233), [-0.06207,   inf] (233), [-0.06199,   inf] (233), [-0.05940,   inf] (233), [-0.05784,   inf] (233), [-0.05732,   inf] (233), [-0.05667,   inf] (233), [-0.05619,   inf] (233), [-0.05431,   inf] (233), [-0.05420,   inf] (233), [-0.05401,   inf] (233), [-0.05380,   inf] (233), [-0.05376,   inf] (233), 
length of domains: 1331
Total time: 1.9241	 pickout: 0.2203	 decision: 0.2990	 get_bound: 0.9368	 add_domain: 0.4680
Current lb:-0.0751020684838295
99212 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 112.844313621521

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 164] [3, 164] [2, 111] [3, 164] [2, 111] [3, 164] [1, 14] [2, 73] [2, 73] [2, 73] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -24.920085906982422 with beta sum per layer: [222.22474670410156, 1376.1868896484375, 1858.97607421875, 1336.607421875, 2287.60791015625]
alpha/beta optimization time: 0.3807332515716553
This batch time : update_bounds func: 0.9236	 prepare: 0.3169	 bound: 0.3812	 transfer: 0.0239	 finalize: 0.1961
Accumulated time: update_bounds func: 70.3425	 prepare: 15.8987	 bound: 42.0301	 transfer: 0.0239	 finalize: 11.0754
batch bounding time:  0.925635814666748
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (235), [-0.07497,   inf] (235), [-0.07445,   inf] (235), [-0.07436,   inf] (235), [-0.07434,   inf] (235), [-0.07424,   inf] (235), [-0.06313,   inf] (235), [-0.06280,   inf] (235), [-0.06207,   inf] (235), [-0.06199,   inf] (235), [-0.05940,   inf] (235), [-0.05783,   inf] (235), [-0.05732,   inf] (235), [-0.05667,   inf] (235), [-0.05619,   inf] (235), [-0.05431,   inf] (235), [-0.05420,   inf] (235), [-0.05401,   inf] (235), [-0.05380,   inf] (235), [-0.05376,   inf] (235), 
length of domains: 1369
Total time: 1.8925	 pickout: 0.2053	 decision: 0.2931	 get_bound: 0.9290	 add_domain: 0.4651
Current lb:-0.0751020684838295
101260 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 114.78300356864929

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 111] [2, 111] [4, 89] [2, 111] [4, 89] [2, 111] [1, 128] [1, 128] [1, 128] [1, 128] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -24.521333694458008 with beta sum per layer: [221.34754943847656, 1372.567626953125, 1889.103515625, 1311.7918701171875, 2251.96630859375]
alpha/beta optimization time: 0.3801538944244385
This batch time : update_bounds func: 0.9252	 prepare: 0.3183	 bound: 0.3806	 transfer: 0.0238	 finalize: 0.1969
Accumulated time: update_bounds func: 71.2677	 prepare: 16.2170	 bound: 42.4107	 transfer: 0.0238	 finalize: 11.2722
batch bounding time:  0.927253007888794
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (237), [-0.07497,   inf] (237), [-0.07445,   inf] (237), [-0.07436,   inf] (237), [-0.07434,   inf] (237), [-0.07424,   inf] (237), [-0.06313,   inf] (237), [-0.06280,   inf] (237), [-0.06207,   inf] (237), [-0.06199,   inf] (237), [-0.05940,   inf] (237), [-0.05779,   inf] (237), [-0.05732,   inf] (237), [-0.05667,   inf] (237), [-0.05619,   inf] (237), [-0.05431,   inf] (237), [-0.05420,   inf] (237), [-0.05401,   inf] (237), [-0.05380,   inf] (237), [-0.05376,   inf] (237), 
length of domains: 1426
Total time: 1.9147	 pickout: 0.2048	 decision: 0.2973	 get_bound: 0.9306	 add_domain: 0.4820
Current lb:-0.0751020684838295
103308 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 116.75889444351196

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 89] [4, 89] [0, 80] [4, 89] [0, 80] [4, 89] [3, 78] [3, 78] [3, 78] [3, 78] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -23.89629364013672 with beta sum per layer: [230.13304138183594, 1293.771240234375, 1916.37841796875, 1315.47998046875, 2236.5263671875]
alpha/beta optimization time: 0.41814756393432617
This batch time : update_bounds func: 0.9808	 prepare: 0.3223	 bound: 0.4187	 transfer: 0.0268	 finalize: 0.2074
Accumulated time: update_bounds func: 72.2484	 prepare: 16.5393	 bound: 42.8294	 transfer: 0.0268	 finalize: 11.4796
batch bounding time:  0.9830303192138672
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (239), [-0.07497,   inf] (239), [-0.07445,   inf] (239), [-0.07436,   inf] (239), [-0.07434,   inf] (239), [-0.07424,   inf] (239), [-0.07195,   inf] (239), [-0.07187,   inf] (239), [-0.06313,   inf] (239), [-0.06280,   inf] (239), [-0.06207,   inf] (239), [-0.06199,   inf] (239), [-0.05940,   inf] (239), [-0.05779,   inf] (239), [-0.05732,   inf] (239), [-0.05667,   inf] (239), [-0.05619,   inf] (239), [-0.05431,   inf] (239), [-0.05420,   inf] (239), [-0.05401,   inf] (239), 
length of domains: 1492
Total time: 2.0700	 pickout: 0.2231	 decision: 0.3149	 get_bound: 0.9864	 add_domain: 0.5457
Current lb:-0.0751020684838295
105356 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 118.87917828559875

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 197] [3, 33] [4, 197] [4, 197] [3, 33] [3, 33] [4, 197] [3, 33] [3, 164] [3, 164] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -25.501554489135742 with beta sum per layer: [239.33164978027344, 1262.32177734375, 1906.895263671875, 1309.56640625, 2182.4248046875]
alpha/beta optimization time: 0.44398021697998047
This batch time : update_bounds func: 1.0997	 prepare: 0.3281	 bound: 0.4445	 transfer: 0.0248	 finalize: 0.2967
Accumulated time: update_bounds func: 73.3482	 prepare: 16.8674	 bound: 43.2739	 transfer: 0.0248	 finalize: 11.7763
batch bounding time:  1.1027112007141113
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (241), [-0.07497,   inf] (241), [-0.07445,   inf] (241), [-0.07436,   inf] (241), [-0.07434,   inf] (241), [-0.07424,   inf] (241), [-0.07194,   inf] (241), [-0.07186,   inf] (241), [-0.06313,   inf] (241), [-0.06280,   inf] (241), [-0.06207,   inf] (241), [-0.06199,   inf] (241), [-0.05940,   inf] (241), [-0.05779,   inf] (241), [-0.05732,   inf] (241), [-0.05667,   inf] (241), [-0.05619,   inf] (241), [-0.05557,   inf] (241), [-0.05431,   inf] (241), [-0.05420,   inf] (241), 
length of domains: 1559
Total time: 2.2064	 pickout: 0.2127	 decision: 0.3164	 get_bound: 1.1076	 add_domain: 0.5697
Current lb:-0.0751020684838295
107404 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 121.15011525154114

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 33] [4, 197] [3, 33] [3, 33] [4, 197] [4, 197] [3, 33] [4, 197] [4, 89] [4, 89] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -21.29121208190918 with beta sum per layer: [244.592529296875, 1256.00439453125, 1891.10205078125, 1294.253173828125, 2135.689697265625]
alpha/beta optimization time: 0.44848108291625977
This batch time : update_bounds func: 1.2608	 prepare: 0.4903	 bound: 0.4492	 transfer: 0.0242	 finalize: 0.2914
Accumulated time: update_bounds func: 74.6090	 prepare: 17.3577	 bound: 43.7231	 transfer: 0.0242	 finalize: 12.0678
batch bounding time:  1.2630410194396973
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (243), [-0.07497,   inf] (243), [-0.07445,   inf] (243), [-0.07436,   inf] (243), [-0.07434,   inf] (243), [-0.07424,   inf] (243), [-0.07194,   inf] (243), [-0.07186,   inf] (243), [-0.06313,   inf] (243), [-0.06280,   inf] (243), [-0.06207,   inf] (243), [-0.06199,   inf] (243), [-0.05940,   inf] (243), [-0.05779,   inf] (243), [-0.05732,   inf] (243), [-0.05667,   inf] (243), [-0.05619,   inf] (243), [-0.05554,   inf] (243), [-0.05431,   inf] (243), [-0.05420,   inf] (243), 
length of domains: 1620
Total time: 2.5237	 pickout: 0.3202	 decision: 0.3924	 get_bound: 1.2668	 add_domain: 0.5442
Current lb:-0.0751020684838295
109452 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 123.73225522041321

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 56] [2, 56] [2, 56] [2, 56] [2, 56] [2, 56] [2, 56] [2, 56] [0, 173] [4, 197] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -21.077648162841797 with beta sum per layer: [243.86709594726562, 1245.305419921875, 1901.1282958984375, 1285.1541748046875, 2131.82470703125]
alpha/beta optimization time: 0.4473092555999756
This batch time : update_bounds func: 1.2547	 prepare: 0.4868	 bound: 0.4479	 transfer: 0.0237	 finalize: 0.2905
Accumulated time: update_bounds func: 75.8637	 prepare: 17.8445	 bound: 44.1710	 transfer: 0.0237	 finalize: 12.3583
batch bounding time:  1.2569613456726074
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (245), [-0.07497,   inf] (245), [-0.07445,   inf] (245), [-0.07436,   inf] (245), [-0.07434,   inf] (245), [-0.07424,   inf] (245), [-0.07194,   inf] (245), [-0.07186,   inf] (245), [-0.06313,   inf] (245), [-0.06280,   inf] (245), [-0.06207,   inf] (245), [-0.06199,   inf] (245), [-0.05940,   inf] (245), [-0.05779,   inf] (245), [-0.05732,   inf] (245), [-0.05667,   inf] (245), [-0.05619,   inf] (245), [-0.05554,   inf] (245), [-0.05431,   inf] (245), [-0.05420,   inf] (245), 
length of domains: 1679
Total time: 2.5624	 pickout: 0.3172	 decision: 0.3874	 get_bound: 1.2608	 add_domain: 0.5970
Current lb:-0.0751020684838295
111500 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 126.36094069480896

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 2] [2, 2] [2, 2] [2, 2] [2, 2] [2, 2] [0, 17] [0, 17] [4, 197] [3, 33] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -21.870826721191406 with beta sum per layer: [241.2003936767578, 1204.69921875, 1937.067138671875, 1276.189453125, 2187.029296875]
alpha/beta optimization time: 0.39015793800354004
This batch time : update_bounds func: 0.9723	 prepare: 0.3348	 bound: 0.3907	 transfer: 0.0256	 finalize: 0.2155
Accumulated time: update_bounds func: 76.8361	 prepare: 18.1793	 bound: 44.5617	 transfer: 0.0256	 finalize: 12.5738
batch bounding time:  0.9745175838470459
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (247), [-0.07497,   inf] (247), [-0.07445,   inf] (247), [-0.07436,   inf] (247), [-0.07434,   inf] (247), [-0.07424,   inf] (247), [-0.07194,   inf] (247), [-0.07186,   inf] (247), [-0.06313,   inf] (247), [-0.06280,   inf] (247), [-0.06207,   inf] (247), [-0.06199,   inf] (247), [-0.05940,   inf] (247), [-0.05779,   inf] (247), [-0.05732,   inf] (247), [-0.05667,   inf] (247), [-0.05619,   inf] (247), [-0.05431,   inf] (247), [-0.05420,   inf] (247), [-0.05401,   inf] (247), 
length of domains: 1750
Total time: 2.0995	 pickout: 0.2254	 decision: 0.3600	 get_bound: 0.9779	 add_domain: 0.5362
Current lb:-0.0751020684838295
113548 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 128.5085220336914

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 77] [4, 77] [4, 77] [4, 77] [4, 77] [4, 77] [2, 2] [2, 2] [3, 33] [2, 56] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -20.067487716674805 with beta sum per layer: [236.25668334960938, 1179.369140625, 1935.782958984375, 1286.86181640625, 2149.48974609375]
alpha/beta optimization time: 0.3838968276977539
This batch time : update_bounds func: 0.9598	 prepare: 0.3367	 bound: 0.3844	 transfer: 0.0235	 finalize: 0.2094
Accumulated time: update_bounds func: 77.7959	 prepare: 18.5160	 bound: 44.9461	 transfer: 0.0235	 finalize: 12.7833
batch bounding time:  0.9620208740234375
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (249), [-0.07497,   inf] (249), [-0.07445,   inf] (249), [-0.07436,   inf] (249), [-0.07434,   inf] (249), [-0.07424,   inf] (249), [-0.07194,   inf] (249), [-0.07186,   inf] (249), [-0.06313,   inf] (249), [-0.06280,   inf] (249), [-0.06207,   inf] (249), [-0.06199,   inf] (249), [-0.05940,   inf] (249), [-0.05779,   inf] (249), [-0.05732,   inf] (249), [-0.05667,   inf] (249), [-0.05619,   inf] (249), [-0.05431,   inf] (249), [-0.05420,   inf] (249), [-0.05401,   inf] (249), 
length of domains: 1811
Total time: 2.0220	 pickout: 0.2099	 decision: 0.3206	 get_bound: 0.9656	 add_domain: 0.5259
Current lb:-0.0751020684838295
115596 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 130.57933282852173

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 51] [4, 149] [0, 17] [3, 51] [0, 17] [4, 149] [4, 77] [4, 77] [2, 56] [0, 173] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -18.52756690979004 with beta sum per layer: [244.62269592285156, 1184.8662109375, 1911.0040283203125, 1279.88916015625, 2169.473876953125]
alpha/beta optimization time: 0.3847661018371582
This batch time : update_bounds func: 0.9591	 prepare: 0.3298	 bound: 0.3853	 transfer: 0.0226	 finalize: 0.2160
Accumulated time: update_bounds func: 78.7550	 prepare: 18.8458	 bound: 45.3314	 transfer: 0.0226	 finalize: 12.9992
batch bounding time:  0.9611935615539551
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (251), [-0.07497,   inf] (251), [-0.07445,   inf] (251), [-0.07436,   inf] (251), [-0.07434,   inf] (251), [-0.07424,   inf] (251), [-0.07194,   inf] (251), [-0.07186,   inf] (251), [-0.06313,   inf] (251), [-0.06280,   inf] (251), [-0.06207,   inf] (251), [-0.06199,   inf] (251), [-0.05940,   inf] (251), [-0.05779,   inf] (251), [-0.05732,   inf] (251), [-0.05667,   inf] (251), [-0.05619,   inf] (251), [-0.05431,   inf] (251), [-0.05420,   inf] (251), [-0.05401,   inf] (251), 
length of domains: 1908
Total time: 2.0296	 pickout: 0.2072	 decision: 0.3125	 get_bound: 0.9647	 add_domain: 0.5452
Current lb:-0.0751020684838295
117644 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 132.6554458141327

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 149] [2, 144] [3, 51] [4, 149] [4, 149] [2, 144] [3, 51] [4, 149] [4, 77] [4, 77] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -15.883573532104492 with beta sum per layer: [243.01150512695312, 1161.111328125, 1909.6094970703125, 1321.927978515625, 2117.55517578125]
alpha/beta optimization time: 0.3893613815307617
This batch time : update_bounds func: 0.9371	 prepare: 0.3217	 bound: 0.3898	 transfer: 0.0224	 finalize: 0.1980
Accumulated time: update_bounds func: 79.6921	 prepare: 19.1675	 bound: 45.7212	 transfer: 0.0224	 finalize: 13.1972
batch bounding time:  0.9390490055084229
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (253), [-0.07497,   inf] (253), [-0.07445,   inf] (253), [-0.07436,   inf] (253), [-0.07434,   inf] (253), [-0.07424,   inf] (253), [-0.07194,   inf] (253), [-0.07186,   inf] (253), [-0.06313,   inf] (253), [-0.06280,   inf] (253), [-0.06207,   inf] (253), [-0.06199,   inf] (253), [-0.05940,   inf] (253), [-0.05779,   inf] (253), [-0.05732,   inf] (253), [-0.05667,   inf] (253), [-0.05619,   inf] (253), [-0.05431,   inf] (253), [-0.05420,   inf] (253), [-0.05401,   inf] (253), 
length of domains: 2020
Total time: 2.0189	 pickout: 0.2215	 decision: 0.3220	 get_bound: 0.9423	 add_domain: 0.5332
Current lb:-0.0751020684838295
119692 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 134.72316312789917

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 144] [3, 51] [4, 149] [2, 144] [2, 144] [3, 51] [4, 149] [2, 144] [3, 51] [3, 51] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -13.298473358154297 with beta sum per layer: [259.7559814453125, 1118.68310546875, 1871.4482421875, 1354.472412109375, 2053.2412109375]
alpha/beta optimization time: 0.38085484504699707
This batch time : update_bounds func: 1.0302	 prepare: 0.3196	 bound: 0.3813	 transfer: 0.0227	 finalize: 0.3015
Accumulated time: update_bounds func: 80.7223	 prepare: 19.4871	 bound: 46.1025	 transfer: 0.0227	 finalize: 13.4987
batch bounding time:  1.0326428413391113
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (255), [-0.07497,   inf] (255), [-0.07445,   inf] (255), [-0.07436,   inf] (255), [-0.07434,   inf] (255), [-0.07424,   inf] (255), [-0.07194,   inf] (255), [-0.07186,   inf] (255), [-0.06313,   inf] (255), [-0.06280,   inf] (255), [-0.06207,   inf] (255), [-0.06199,   inf] (255), [-0.05940,   inf] (255), [-0.05779,   inf] (255), [-0.05732,   inf] (255), [-0.05667,   inf] (255), [-0.05619,   inf] (255), [-0.05431,   inf] (255), [-0.05420,   inf] (255), [-0.05401,   inf] (255), 
length of domains: 2142
Total time: 1.9960	 pickout: 0.2068	 decision: 0.3149	 get_bound: 1.0363	 add_domain: 0.4381
Current lb:-0.0751020684838295
121740 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 136.76809906959534

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 29] [2, 29] [2, 144] [2, 29] [3, 51] [2, 29] [2, 144] [3, 51] [4, 149] [4, 149] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -13.999083518981934 with beta sum per layer: [251.76368713378906, 1092.6976318359375, 1913.531494140625, 1399.624267578125, 1980.6693115234375]
alpha/beta optimization time: 0.3807053565979004
This batch time : update_bounds func: 1.0411	 prepare: 0.3236	 bound: 0.3812	 transfer: 0.0225	 finalize: 0.3081
Accumulated time: update_bounds func: 81.7634	 prepare: 19.8106	 bound: 46.4837	 transfer: 0.0225	 finalize: 13.8068
batch bounding time:  1.043524980545044
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (257), [-0.07497,   inf] (257), [-0.07445,   inf] (257), [-0.07436,   inf] (257), [-0.07434,   inf] (257), [-0.07424,   inf] (257), [-0.07194,   inf] (257), [-0.07186,   inf] (257), [-0.06313,   inf] (257), [-0.06280,   inf] (257), [-0.06207,   inf] (257), [-0.06199,   inf] (257), [-0.05940,   inf] (257), [-0.05779,   inf] (257), [-0.05732,   inf] (257), [-0.05667,   inf] (257), [-0.05619,   inf] (257), [-0.05431,   inf] (257), [-0.05420,   inf] (257), [-0.05401,   inf] (257), 
length of domains: 2262
Total time: 2.0176	 pickout: 0.2089	 decision: 0.3175	 get_bound: 1.0471	 add_domain: 0.4441
Current lb:-0.0751020684838295
123788 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 138.83699011802673

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 17] [0, 17] [2, 29] [0, 17] [2, 29] [0, 17] [2, 29] [2, 29] [0, 17] [0, 17] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -12.715926170349121 with beta sum per layer: [259.42938232421875, 1061.660400390625, 1877.575439453125, 1438.73876953125, 1944.5699462890625]
alpha/beta optimization time: 0.38323378562927246
This batch time : update_bounds func: 1.0768	 prepare: 0.3249	 bound: 0.3837	 transfer: 0.0234	 finalize: 0.3390
Accumulated time: update_bounds func: 82.8403	 prepare: 20.1356	 bound: 46.8674	 transfer: 0.0234	 finalize: 14.1458
batch bounding time:  1.0793664455413818
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (259), [-0.07497,   inf] (259), [-0.07445,   inf] (259), [-0.07436,   inf] (259), [-0.07434,   inf] (259), [-0.07424,   inf] (259), [-0.07194,   inf] (259), [-0.07186,   inf] (259), [-0.06313,   inf] (259), [-0.06280,   inf] (259), [-0.06207,   inf] (259), [-0.06199,   inf] (259), [-0.05940,   inf] (259), [-0.05779,   inf] (259), [-0.05732,   inf] (259), [-0.05667,   inf] (259), [-0.05619,   inf] (259), [-0.05431,   inf] (259), [-0.05420,   inf] (259), [-0.05401,   inf] (259), 
length of domains: 2373
Total time: 2.0738	 pickout: 0.2085	 decision: 0.3364	 get_bound: 1.0832	 add_domain: 0.4457
Current lb:-0.0751020684838295
125836 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 140.96270751953125

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 129] [1, 129] [1, 129] [1, 129] [1, 129] [1, 129] [1, 129] [1, 129] [2, 94] [2, 94] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -10.038558006286621 with beta sum per layer: [236.934814453125, 1025.605224609375, 1920.76708984375, 1428.179931640625, 1944.432861328125]
alpha/beta optimization time: 0.3822181224822998
This batch time : update_bounds func: 1.0468	 prepare: 0.3227	 bound: 0.3827	 transfer: 0.0226	 finalize: 0.3134
Accumulated time: update_bounds func: 83.8870	 prepare: 20.4583	 bound: 47.2501	 transfer: 0.0226	 finalize: 14.4591
batch bounding time:  1.0490429401397705
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (261), [-0.07497,   inf] (261), [-0.07445,   inf] (261), [-0.07436,   inf] (261), [-0.07434,   inf] (261), [-0.07424,   inf] (261), [-0.07194,   inf] (261), [-0.07186,   inf] (261), [-0.06313,   inf] (261), [-0.06280,   inf] (261), [-0.06207,   inf] (261), [-0.06199,   inf] (261), [-0.05940,   inf] (261), [-0.05779,   inf] (261), [-0.05732,   inf] (261), [-0.05667,   inf] (261), [-0.05619,   inf] (261), [-0.05431,   inf] (261), [-0.05420,   inf] (261), [-0.05401,   inf] (261), 
length of domains: 2506
Total time: 2.0493	 pickout: 0.2099	 decision: 0.3319	 get_bound: 1.0526	 add_domain: 0.4550
Current lb:-0.0751020684838295
127884 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 143.06076955795288

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 106] [4, 106] [4, 106] [4, 106] [4, 106] [4, 106] [4, 106] [4, 106] [1, 129] [1, 129] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -9.1560640335083 with beta sum per layer: [228.66461181640625, 1055.7208251953125, 1857.158935546875, 1414.177001953125, 1988.8857421875]
alpha/beta optimization time: 0.38274264335632324
This batch time : update_bounds func: 1.0625	 prepare: 0.3365	 bound: 0.3832	 transfer: 0.0227	 finalize: 0.3146
Accumulated time: update_bounds func: 84.9495	 prepare: 20.7948	 bound: 47.6333	 transfer: 0.0227	 finalize: 14.7738
batch bounding time:  1.0647735595703125
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (263), [-0.07497,   inf] (263), [-0.07445,   inf] (263), [-0.07436,   inf] (263), [-0.07434,   inf] (263), [-0.07424,   inf] (263), [-0.07194,   inf] (263), [-0.07186,   inf] (263), [-0.06313,   inf] (263), [-0.06280,   inf] (263), [-0.06207,   inf] (263), [-0.06199,   inf] (263), [-0.05940,   inf] (263), [-0.05779,   inf] (263), [-0.05732,   inf] (263), [-0.05667,   inf] (263), [-0.05619,   inf] (263), [-0.05431,   inf] (263), [-0.05420,   inf] (263), [-0.05401,   inf] (263), 
length of domains: 2629
Total time: 2.0654	 pickout: 0.2132	 decision: 0.3295	 get_bound: 1.0683	 add_domain: 0.4544
Current lb:-0.0751020684838295
129932 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 145.18701457977295

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 61] [1, 61] [1, 61] [1, 61] [1, 61] [1, 61] [1, 61] [1, 61] [4, 106] [4, 106] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -6.041732311248779 with beta sum per layer: [230.18003845214844, 1053.294921875, 1840.705078125, 1418.781005859375, 2013.9466552734375]
alpha/beta optimization time: 0.3810842037200928
This batch time : update_bounds func: 1.0751	 prepare: 0.3255	 bound: 0.3816	 transfer: 0.0223	 finalize: 0.3399
Accumulated time: update_bounds func: 86.0247	 prepare: 21.1203	 bound: 48.0148	 transfer: 0.0223	 finalize: 15.1137
batch bounding time:  1.0774002075195312
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (265), [-0.07497,   inf] (265), [-0.07445,   inf] (265), [-0.07436,   inf] (265), [-0.07434,   inf] (265), [-0.07424,   inf] (265), [-0.07194,   inf] (265), [-0.07186,   inf] (265), [-0.06313,   inf] (265), [-0.06280,   inf] (265), [-0.06207,   inf] (265), [-0.06199,   inf] (265), [-0.05940,   inf] (265), [-0.05779,   inf] (265), [-0.05732,   inf] (265), [-0.05667,   inf] (265), [-0.05619,   inf] (265), [-0.05430,   inf] (265), [-0.05420,   inf] (265), [-0.05418,   inf] (265), 
length of domains: 2772
Total time: 2.0988	 pickout: 0.2096	 decision: 0.3422	 get_bound: 1.0810	 add_domain: 0.4659
Current lb:-0.0751020684838295
131980 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 147.3383448123932

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 120] [1, 120] [1, 120] [1, 120] [1, 120] [1, 120] [1, 120] [1, 120] [2, 37] [2, 37] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -4.524825572967529 with beta sum per layer: [228.78860473632812, 1015.3203125, 1849.33056640625, 1409.59765625, 2041.53564453125]
alpha/beta optimization time: 0.3809621334075928
This batch time : update_bounds func: 1.0689	 prepare: 0.3236	 bound: 0.3814	 transfer: 0.0222	 finalize: 0.3360
Accumulated time: update_bounds func: 87.0936	 prepare: 21.4438	 bound: 48.3963	 transfer: 0.0222	 finalize: 15.4497
batch bounding time:  1.0711395740509033
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (267), [-0.07497,   inf] (267), [-0.07445,   inf] (267), [-0.07436,   inf] (267), [-0.07434,   inf] (267), [-0.07424,   inf] (267), [-0.07194,   inf] (267), [-0.07186,   inf] (267), [-0.06313,   inf] (267), [-0.06313,   inf] (267), [-0.06280,   inf] (267), [-0.06279,   inf] (267), [-0.06207,   inf] (267), [-0.06207,   inf] (267), [-0.06199,   inf] (267), [-0.06199,   inf] (267), [-0.05939,   inf] (267), [-0.05938,   inf] (267), [-0.05779,   inf] (267), [-0.05779,   inf] (267), 
length of domains: 2943
Total time: 2.1302	 pickout: 0.2214	 decision: 0.3547	 get_bound: 1.0746	 add_domain: 0.4795
Current lb:-0.0751020684838295
134028 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 149.5177080631256

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 94] [2, 94] [2, 94] [2, 94] [2, 94] [2, 94] [2, 94] [2, 94] [4, 121] [4, 121] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -6.785690784454346 with beta sum per layer: [213.69320678710938, 992.7577514648438, 1887.081787109375, 1369.881103515625, 2049.45849609375]
alpha/beta optimization time: 0.38193655014038086
This batch time : update_bounds func: 1.0744	 prepare: 0.3251	 bound: 0.3824	 transfer: 0.0222	 finalize: 0.3390
Accumulated time: update_bounds func: 88.1680	 prepare: 21.7689	 bound: 48.7787	 transfer: 0.0222	 finalize: 15.7886
batch bounding time:  1.0767195224761963
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (269), [-0.07497,   inf] (269), [-0.07445,   inf] (269), [-0.07436,   inf] (269), [-0.07434,   inf] (269), [-0.07424,   inf] (269), [-0.07194,   inf] (269), [-0.07186,   inf] (269), [-0.06313,   inf] (269), [-0.06313,   inf] (269), [-0.06280,   inf] (269), [-0.06279,   inf] (269), [-0.06207,   inf] (269), [-0.06207,   inf] (269), [-0.06199,   inf] (269), [-0.06199,   inf] (269), [-0.05939,   inf] (269), [-0.05938,   inf] (269), [-0.05779,   inf] (269), [-0.05778,   inf] (269), 
length of domains: 3096
Total time: 2.1177	 pickout: 0.2131	 decision: 0.3508	 get_bound: 1.0804	 add_domain: 0.4735
Current lb:-0.0751020684838295
136076 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 151.68842363357544

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 37] [2, 37] [2, 37] [2, 37] [2, 37] [2, 37] [2, 37] [2, 37] [2, 29] [2, 29] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -2.2772552967071533 with beta sum per layer: [225.004150390625, 1003.2708129882812, 1912.974609375, 1334.305908203125, 2019.8779296875]
alpha/beta optimization time: 0.3829026222229004
This batch time : update_bounds func: 1.0763	 prepare: 0.3229	 bound: 0.3834	 transfer: 0.0225	 finalize: 0.3420
Accumulated time: update_bounds func: 89.2443	 prepare: 22.0918	 bound: 49.1621	 transfer: 0.0225	 finalize: 16.1306
batch bounding time:  1.078747272491455
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (271), [-0.07497,   inf] (271), [-0.07445,   inf] (271), [-0.07436,   inf] (271), [-0.07434,   inf] (271), [-0.07424,   inf] (271), [-0.07194,   inf] (271), [-0.07186,   inf] (271), [-0.07153,   inf] (271), [-0.07130,   inf] (271), [-0.07080,   inf] (271), [-0.07065,   inf] (271), [-0.06956,   inf] (271), [-0.06943,   inf] (271), [-0.06840,   inf] (271), [-0.06829,   inf] (271), [-0.06313,   inf] (271), [-0.06313,   inf] (271), [-0.06280,   inf] (271), [-0.06279,   inf] (271), 
length of domains: 3290
Total time: 2.1415	 pickout: 0.2100	 decision: 0.3535	 get_bound: 1.0823	 add_domain: 0.4957
Current lb:-0.0751020684838295
138124 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 153.88201475143433

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 121] [4, 121] [4, 121] [4, 121] [4, 121] [4, 121] [4, 121] [4, 121] [1, 37] [3, 48] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 4.824715614318848 with beta sum per layer: [221.24327087402344, 1053.082763671875, 1893.1910400390625, 1213.1544189453125, 1974.229736328125]
alpha/beta optimization time: 0.3822810649871826
This batch time : update_bounds func: 1.0774	 prepare: 0.3335	 bound: 0.3828	 transfer: 0.0221	 finalize: 0.2094
Accumulated time: update_bounds func: 90.3217	 prepare: 22.4254	 bound: 49.5448	 transfer: 0.0221	 finalize: 16.3400
batch bounding time:  1.0795364379882812
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (273), [-0.07497,   inf] (273), [-0.07445,   inf] (273), [-0.07436,   inf] (273), [-0.07434,   inf] (273), [-0.07424,   inf] (273), [-0.07194,   inf] (273), [-0.07186,   inf] (273), [-0.07148,   inf] (273), [-0.07148,   inf] (273), [-0.07078,   inf] (273), [-0.07077,   inf] (273), [-0.07062,   inf] (273), [-0.07062,   inf] (273), [-0.06913,   inf] (273), [-0.06901,   inf] (273), [-0.06826,   inf] (273), [-0.06818,   inf] (273), [-0.06816,   inf] (273), [-0.06792,   inf] (273), 
length of domains: 3522
Total time: 2.2048	 pickout: 0.2097	 decision: 0.2320	 get_bound: 1.0830	 add_domain: 0.6802
Current lb:-0.0751020684838295
140172 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 156.13539671897888

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 139] [4, 139] [4, 139] [4, 139] [4, 139] [4, 139] [4, 139] [4, 139] [4, 121] [4, 121] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 6.285976409912109 with beta sum per layer: [229.6470184326172, 1085.186767578125, 1861.5711669921875, 1186.219482421875, 1908.66943359375]
alpha/beta optimization time: 0.38213276863098145
This batch time : update_bounds func: 1.0872	 prepare: 0.3269	 bound: 0.3826	 transfer: 0.0223	 finalize: 0.3502
Accumulated time: update_bounds func: 91.4089	 prepare: 22.7523	 bound: 49.9274	 transfer: 0.0223	 finalize: 16.6902
batch bounding time:  1.0892155170440674
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (275), [-0.07497,   inf] (275), [-0.07445,   inf] (275), [-0.07436,   inf] (275), [-0.07434,   inf] (275), [-0.07424,   inf] (275), [-0.07194,   inf] (275), [-0.07186,   inf] (275), [-0.07148,   inf] (275), [-0.07148,   inf] (275), [-0.07078,   inf] (275), [-0.07077,   inf] (275), [-0.06913,   inf] (275), [-0.06900,   inf] (275), [-0.06826,   inf] (275), [-0.06816,   inf] (275), [-0.06789,   inf] (275), [-0.06783,   inf] (275), [-0.06776,   inf] (275), [-0.06746,   inf] (275), 
length of domains: 3747
Total time: 2.0554	 pickout: 0.2140	 decision: 0.2292	 get_bound: 1.0926	 add_domain: 0.5197
Current lb:-0.0751020684838295
142220 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 158.24295949935913

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 109] [1, 109] [1, 109] [1, 109] [1, 109] [1, 109] [1, 109] [1, 109] [4, 139] [4, 139] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 9.518174171447754 with beta sum per layer: [237.50408935546875, 1143.1114501953125, 1914.27783203125, 1094.990966796875, 1882.6300048828125]
alpha/beta optimization time: 0.3994181156158447
This batch time : update_bounds func: 1.1853	 prepare: 0.3427	 bound: 0.4000	 transfer: 0.0251	 finalize: 0.4117
Accumulated time: update_bounds func: 92.5941	 prepare: 23.0950	 bound: 50.3274	 transfer: 0.0251	 finalize: 17.1019
batch bounding time:  1.1873340606689453
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (277), [-0.07497,   inf] (277), [-0.07445,   inf] (277), [-0.07436,   inf] (277), [-0.07434,   inf] (277), [-0.07424,   inf] (277), [-0.07194,   inf] (277), [-0.07186,   inf] (277), [-0.07148,   inf] (277), [-0.07148,   inf] (277), [-0.07078,   inf] (277), [-0.07077,   inf] (277), [-0.06913,   inf] (277), [-0.06900,   inf] (277), [-0.06825,   inf] (277), [-0.06816,   inf] (277), [-0.06789,   inf] (277), [-0.06782,   inf] (277), [-0.06782,   inf] (277), [-0.06776,   inf] (277), 
length of domains: 4032
Total time: 2.3446	 pickout: 0.2215	 decision: 0.3826	 get_bound: 1.1907	 add_domain: 0.5497
Current lb:-0.0751020684838295
144268 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 160.64227986335754

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 112] [1, 112] [1, 112] [1, 112] [1, 112] [1, 112] [1, 112] [1, 112] [1, 109] [1, 109] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 9.972922325134277 with beta sum per layer: [252.27316284179688, 1152.731689453125, 1963.0526123046875, 1061.476318359375, 1838.4354248046875]
alpha/beta optimization time: 0.383561372756958
This batch time : update_bounds func: 1.1368	 prepare: 0.3265	 bound: 0.3840	 transfer: 0.0221	 finalize: 0.3981
Accumulated time: update_bounds func: 93.7310	 prepare: 23.4214	 bound: 50.7115	 transfer: 0.0221	 finalize: 17.5000
batch bounding time:  1.139350175857544
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (279), [-0.07497,   inf] (279), [-0.07445,   inf] (279), [-0.07436,   inf] (279), [-0.07434,   inf] (279), [-0.07424,   inf] (279), [-0.07194,   inf] (279), [-0.07186,   inf] (279), [-0.07148,   inf] (279), [-0.07148,   inf] (279), [-0.07078,   inf] (279), [-0.07077,   inf] (279), [-0.06913,   inf] (279), [-0.06900,   inf] (279), [-0.06825,   inf] (279), [-0.06816,   inf] (279), [-0.06789,   inf] (279), [-0.06782,   inf] (279), [-0.06782,   inf] (279), [-0.06776,   inf] (279), 
length of domains: 4330
Total time: 2.3321	 pickout: 0.2124	 decision: 0.4106	 get_bound: 1.1431	 add_domain: 0.5660
Current lb:-0.0751020684838295
146316 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 163.03869771957397

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 122] [3, 122] [3, 122] [3, 122] [3, 122] [3, 122] [3, 122] [3, 122] [1, 112] [1, 112] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5.121988773345947 with beta sum per layer: [250.4594268798828, 1139.9141845703125, 1941.2822265625, 1084.8623046875, 1774.481201171875]
alpha/beta optimization time: 0.38367724418640137
This batch time : update_bounds func: 1.1348	 prepare: 0.3292	 bound: 0.3842	 transfer: 0.0233	 finalize: 0.3921
Accumulated time: update_bounds func: 94.8658	 prepare: 23.7506	 bound: 51.0957	 transfer: 0.0233	 finalize: 17.8921
batch bounding time:  1.1370229721069336
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (281), [-0.07497,   inf] (281), [-0.07445,   inf] (281), [-0.07436,   inf] (281), [-0.07434,   inf] (281), [-0.07424,   inf] (281), [-0.07194,   inf] (281), [-0.07186,   inf] (281), [-0.07148,   inf] (281), [-0.07148,   inf] (281), [-0.07078,   inf] (281), [-0.07077,   inf] (281), [-0.06913,   inf] (281), [-0.06900,   inf] (281), [-0.06825,   inf] (281), [-0.06816,   inf] (281), [-0.06789,   inf] (281), [-0.06782,   inf] (281), [-0.06782,   inf] (281), [-0.06776,   inf] (281), 
length of domains: 4585
Total time: 2.1473	 pickout: 0.2273	 decision: 0.2389	 get_bound: 1.1405	 add_domain: 0.5406
Current lb:-0.0751020684838295
148364 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 165.2485489845276

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 94] [0, 94] [1, 37] [0, 94] [1, 37] [0, 94] [1, 37] [1, 37] [0, 94] [0, 94] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 4.045598030090332 with beta sum per layer: [262.99951171875, 1168.09130859375, 1989.30322265625, 1105.3443603515625, 1727.982421875]
alpha/beta optimization time: 0.38602399826049805
This batch time : update_bounds func: 1.1726	 prepare: 0.3311	 bound: 0.3865	 transfer: 0.0232	 finalize: 0.4258
Accumulated time: update_bounds func: 96.0383	 prepare: 24.0818	 bound: 51.4822	 transfer: 0.0232	 finalize: 18.3180
batch bounding time:  1.1746604442596436
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (283), [-0.07497,   inf] (283), [-0.07445,   inf] (283), [-0.07436,   inf] (283), [-0.07434,   inf] (283), [-0.07424,   inf] (283), [-0.07233,   inf] (283), [-0.07226,   inf] (283), [-0.07194,   inf] (283), [-0.07186,   inf] (283), [-0.07148,   inf] (283), [-0.07148,   inf] (283), [-0.07085,   inf] (283), [-0.07078,   inf] (283), [-0.07077,   inf] (283), [-0.07077,   inf] (283), [-0.06913,   inf] (283), [-0.06900,   inf] (283), [-0.06825,   inf] (283), [-0.06816,   inf] (283), 
length of domains: 4815
Total time: 2.3422	 pickout: 0.2177	 decision: 0.4092	 get_bound: 1.1781	 add_domain: 0.5372
Current lb:-0.0751020684838295
150412 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 167.64225363731384

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 37] [1, 37] [3, 12] [1, 37] [3, 12] [1, 37] [0, 94] [0, 94] [3, 12] [3, 12] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 3.8478360176086426 with beta sum per layer: [283.86993408203125, 1138.016357421875, 1966.26953125, 1119.3013916015625, 1730.0587158203125]
alpha/beta optimization time: 0.3957250118255615
This batch time : update_bounds func: 0.9637	 prepare: 0.3307	 bound: 0.3962	 transfer: 0.0232	 finalize: 0.2081
Accumulated time: update_bounds func: 97.0020	 prepare: 24.4124	 bound: 51.8784	 transfer: 0.0232	 finalize: 18.5261
batch bounding time:  0.9657912254333496
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (285), [-0.07497,   inf] (285), [-0.07471,   inf] (285), [-0.07458,   inf] (285), [-0.07445,   inf] (285), [-0.07436,   inf] (285), [-0.07434,   inf] (285), [-0.07424,   inf] (285), [-0.07374,   inf] (285), [-0.07360,   inf] (285), [-0.07232,   inf] (285), [-0.07222,   inf] (285), [-0.07194,   inf] (285), [-0.07186,   inf] (285), [-0.07148,   inf] (285), [-0.07148,   inf] (285), [-0.07082,   inf] (285), [-0.07078,   inf] (285), [-0.07077,   inf] (285), [-0.07077,   inf] (285), 
length of domains: 5018
Total time: 2.4059	 pickout: 0.2179	 decision: 0.4822	 get_bound: 0.9693	 add_domain: 0.7364
Current lb:-0.0751020684838295
152460 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 170.10149335861206

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 12] [3, 12] [3, 12] [3, 12] [1, 62] [3, 12] [1, 62] [3, 12] [3, 12] [3, 12] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 4.766767501831055 with beta sum per layer: [273.55328369140625, 1215.453857421875, 1975.021728515625, 1099.832763671875, 1670.4385986328125]
alpha/beta optimization time: 0.40551280975341797
This batch time : update_bounds func: 1.1637	 prepare: 0.3299	 bound: 0.4060	 transfer: 0.0223	 finalize: 0.3997
Accumulated time: update_bounds func: 98.1658	 prepare: 24.7423	 bound: 52.2844	 transfer: 0.0223	 finalize: 18.9258
batch bounding time:  1.165848970413208
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (287), [-0.07497,   inf] (287), [-0.07471,   inf] (287), [-0.07458,   inf] (287), [-0.07445,   inf] (287), [-0.07436,   inf] (287), [-0.07434,   inf] (287), [-0.07424,   inf] (287), [-0.07370,   inf] (287), [-0.07357,   inf] (287), [-0.07232,   inf] (287), [-0.07222,   inf] (287), [-0.07194,   inf] (287), [-0.07186,   inf] (287), [-0.07148,   inf] (287), [-0.07148,   inf] (287), [-0.07082,   inf] (287), [-0.07078,   inf] (287), [-0.07077,   inf] (287), [-0.07077,   inf] (287), 
length of domains: 5224
Total time: 2.1527	 pickout: 0.2143	 decision: 0.2364	 get_bound: 1.1695	 add_domain: 0.5326
Current lb:-0.0751020684838295
154508 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 172.31224489212036

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 62] [1, 62] [1, 62] [1, 62] [0, 94] [1, 62] [0, 94] [1, 62] [1, 62] [1, 62] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -1.8606370687484741 with beta sum per layer: [276.45916748046875, 1120.54541015625, 1921.50537109375, 1145.648193359375, 1694.763671875]
alpha/beta optimization time: 0.384993314743042
This batch time : update_bounds func: 0.9976	 prepare: 0.3575	 bound: 0.3855	 transfer: 0.0234	 finalize: 0.2251
Accumulated time: update_bounds func: 99.1633	 prepare: 25.0998	 bound: 52.6699	 transfer: 0.0234	 finalize: 19.1509
batch bounding time:  0.9997670650482178
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (289), [-0.07497,   inf] (289), [-0.07471,   inf] (289), [-0.07458,   inf] (289), [-0.07445,   inf] (289), [-0.07436,   inf] (289), [-0.07434,   inf] (289), [-0.07424,   inf] (289), [-0.07370,   inf] (289), [-0.07357,   inf] (289), [-0.07232,   inf] (289), [-0.07222,   inf] (289), [-0.07194,   inf] (289), [-0.07186,   inf] (289), [-0.07148,   inf] (289), [-0.07148,   inf] (289), [-0.07082,   inf] (289), [-0.07078,   inf] (289), [-0.07077,   inf] (289), [-0.07077,   inf] (289), 
length of domains: 5353
Total time: 2.1780	 pickout: 0.2273	 decision: 0.4357	 get_bound: 1.0035	 add_domain: 0.5115
Current lb:-0.0751020684838295
156556 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 174.5458493232727

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 124] [3, 26] [3, 124] [3, 26] [3, 124] [3, 124] [3, 26] [3, 26] [3, 124] [3, 26] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -3.002786159515381 with beta sum per layer: [249.98330688476562, 1103.694091796875, 1926.9449462890625, 1132.6964111328125, 1730.216064453125]
alpha/beta optimization time: 0.3858332633972168
This batch time : update_bounds func: 1.2217	 prepare: 0.3415	 bound: 0.3863	 transfer: 0.0256	 finalize: 0.4625
Accumulated time: update_bounds func: 100.3850	 prepare: 25.4413	 bound: 53.0562	 transfer: 0.0256	 finalize: 19.6134
batch bounding time:  1.2240545749664307
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (291), [-0.07497,   inf] (291), [-0.07471,   inf] (291), [-0.07458,   inf] (291), [-0.07445,   inf] (291), [-0.07436,   inf] (291), [-0.07434,   inf] (291), [-0.07424,   inf] (291), [-0.07370,   inf] (291), [-0.07357,   inf] (291), [-0.07232,   inf] (291), [-0.07222,   inf] (291), [-0.07194,   inf] (291), [-0.07186,   inf] (291), [-0.07148,   inf] (291), [-0.07148,   inf] (291), [-0.07082,   inf] (291), [-0.07078,   inf] (291), [-0.07077,   inf] (291), [-0.07077,   inf] (291), 
length of domains: 5503
Total time: 2.4222	 pickout: 0.2203	 decision: 0.4590	 get_bound: 1.2278	 add_domain: 0.5151
Current lb:-0.0751020684838295
158604 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 177.02200078964233

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 26] [3, 124] [3, 26] [3, 124] [3, 26] [3, 26] [3, 124] [3, 124] [3, 26] [3, 124] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -8.201091766357422 with beta sum per layer: [253.28619384765625, 1083.5948486328125, 1963.728271484375, 1059.879638671875, 1776.11572265625]
alpha/beta optimization time: 0.3819756507873535
This batch time : update_bounds func: 1.1536	 prepare: 0.3379	 bound: 0.3824	 transfer: 0.0222	 finalize: 0.2076
Accumulated time: update_bounds func: 101.5386	 prepare: 25.7792	 bound: 53.4386	 transfer: 0.0222	 finalize: 19.8211
batch bounding time:  1.1558167934417725
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (293), [-0.07497,   inf] (293), [-0.07471,   inf] (293), [-0.07458,   inf] (293), [-0.07445,   inf] (293), [-0.07436,   inf] (293), [-0.07434,   inf] (293), [-0.07424,   inf] (293), [-0.07370,   inf] (293), [-0.07357,   inf] (293), [-0.07232,   inf] (293), [-0.07222,   inf] (293), [-0.07194,   inf] (293), [-0.07186,   inf] (293), [-0.07148,   inf] (293), [-0.07148,   inf] (293), [-0.07082,   inf] (293), [-0.07078,   inf] (293), [-0.07077,   inf] (293), [-0.07077,   inf] (293), 
length of domains: 5630
Total time: 2.1134	 pickout: 0.2102	 decision: 0.2380	 get_bound: 1.1595	 add_domain: 0.5056
Current lb:-0.0751020684838295
160652 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 179.19949913024902

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 182] [4, 182] [4, 182] [4, 182] [4, 182] [4, 182] [4, 182] [4, 182] [4, 182] [4, 182] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -8.057108879089355 with beta sum per layer: [246.15737915039062, 1069.0963134765625, 1974.1348876953125, 935.05419921875, 1876.4578857421875]
alpha/beta optimization time: 0.38640403747558594
This batch time : update_bounds func: 1.1724	 prepare: 0.3274	 bound: 0.3869	 transfer: 0.0222	 finalize: 0.4305
Accumulated time: update_bounds func: 102.7110	 prepare: 26.1066	 bound: 53.8255	 transfer: 0.0222	 finalize: 20.2516
batch bounding time:  1.1749467849731445
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (295), [-0.07497,   inf] (295), [-0.07471,   inf] (295), [-0.07458,   inf] (295), [-0.07445,   inf] (295), [-0.07436,   inf] (295), [-0.07434,   inf] (295), [-0.07424,   inf] (295), [-0.07370,   inf] (295), [-0.07357,   inf] (295), [-0.07232,   inf] (295), [-0.07222,   inf] (295), [-0.07194,   inf] (295), [-0.07186,   inf] (295), [-0.07148,   inf] (295), [-0.07148,   inf] (295), [-0.07082,   inf] (295), [-0.07078,   inf] (295), [-0.07077,   inf] (295), [-0.07077,   inf] (295), 
length of domains: 5769
Total time: 2.3371	 pickout: 0.2122	 decision: 0.4299	 get_bound: 1.1794	 add_domain: 0.5156
Current lb:-0.0751020684838295
162700 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 181.5982654094696

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 71] [4, 71] [4, 71] [4, 71] [4, 71] [4, 71] [4, 71] [4, 71] [4, 71] [4, 71] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -9.423869132995605 with beta sum per layer: [239.03033447265625, 1023.050048828125, 1999.6708984375, 908.5677490234375, 1924.997802734375]
alpha/beta optimization time: 0.3851747512817383
This batch time : update_bounds func: 1.1862	 prepare: 0.3402	 bound: 0.3857	 transfer: 0.0232	 finalize: 0.4310
Accumulated time: update_bounds func: 103.8971	 prepare: 26.4468	 bound: 54.2112	 transfer: 0.0232	 finalize: 20.6826
batch bounding time:  1.1891496181488037
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (297), [-0.07497,   inf] (297), [-0.07471,   inf] (297), [-0.07458,   inf] (297), [-0.07445,   inf] (297), [-0.07436,   inf] (297), [-0.07434,   inf] (297), [-0.07424,   inf] (297), [-0.07370,   inf] (297), [-0.07357,   inf] (297), [-0.07232,   inf] (297), [-0.07222,   inf] (297), [-0.07194,   inf] (297), [-0.07186,   inf] (297), [-0.07148,   inf] (297), [-0.07148,   inf] (297), [-0.07082,   inf] (297), [-0.07078,   inf] (297), [-0.07077,   inf] (297), [-0.07077,   inf] (297), 
length of domains: 5893
Total time: 2.2011	 pickout: 0.2332	 decision: 0.2492	 get_bound: 1.1929	 add_domain: 0.5258
Current lb:-0.0751020684838295
164748 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 183.86369276046753

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 168] [4, 168] [4, 168] [4, 168] [4, 168] [4, 168] [4, 168] [4, 168] [4, 168] [4, 168] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -5.613513946533203 with beta sum per layer: [242.90875244140625, 1033.4384765625, 1988.4833984375, 900.8975830078125, 2007.788818359375]
alpha/beta optimization time: 0.43939876556396484
This batch time : update_bounds func: 1.1029	 prepare: 0.3331	 bound: 0.4399	 transfer: 0.0235	 finalize: 0.3002
Accumulated time: update_bounds func: 105.0001	 prepare: 26.7799	 bound: 54.6511	 transfer: 0.0235	 finalize: 20.9828
batch bounding time:  1.1055543422698975
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (299), [-0.07497,   inf] (299), [-0.07471,   inf] (299), [-0.07458,   inf] (299), [-0.07445,   inf] (299), [-0.07436,   inf] (299), [-0.07434,   inf] (299), [-0.07424,   inf] (299), [-0.07370,   inf] (299), [-0.07357,   inf] (299), [-0.07232,   inf] (299), [-0.07222,   inf] (299), [-0.07194,   inf] (299), [-0.07186,   inf] (299), [-0.07148,   inf] (299), [-0.07148,   inf] (299), [-0.07082,   inf] (299), [-0.07078,   inf] (299), [-0.07077,   inf] (299), [-0.07077,   inf] (299), 
length of domains: 5994
Total time: 2.6059	 pickout: 0.2287	 decision: 0.4663	 get_bound: 1.1112	 add_domain: 0.7998
Current lb:-0.0751020684838295
166796 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 186.5298044681549

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 21] [4, 21] [4, 21] [4, 21] [4, 21] [4, 21] [4, 21] [4, 21] [4, 21] [4, 21] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -3.9830265045166016 with beta sum per layer: [236.79347229003906, 1024.1549072265625, 1986.9716796875, 912.4212646484375, 2066.115234375]
alpha/beta optimization time: 0.4267578125
This batch time : update_bounds func: 1.4131	 prepare: 0.5098	 bound: 0.4273	 transfer: 0.0232	 finalize: 0.4466
Accumulated time: update_bounds func: 106.4131	 prepare: 27.2897	 bound: 55.0784	 transfer: 0.0232	 finalize: 21.4294
batch bounding time:  1.4152271747589111
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (301), [-0.07497,   inf] (301), [-0.07471,   inf] (301), [-0.07458,   inf] (301), [-0.07445,   inf] (301), [-0.07436,   inf] (301), [-0.07434,   inf] (301), [-0.07424,   inf] (301), [-0.07370,   inf] (301), [-0.07357,   inf] (301), [-0.07232,   inf] (301), [-0.07222,   inf] (301), [-0.07194,   inf] (301), [-0.07186,   inf] (301), [-0.07148,   inf] (301), [-0.07148,   inf] (301), [-0.07082,   inf] (301), [-0.07078,   inf] (301), [-0.07077,   inf] (301), [-0.07077,   inf] (301), 
length of domains: 6086
Total time: 2.5298	 pickout: 0.3050	 decision: 0.2992	 get_bound: 1.4186	 add_domain: 0.5070
Current lb:-0.0751020684838295
168844 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 189.12339329719543

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 47] [4, 47] [4, 47] [4, 47] [4, 47] [4, 47] [4, 47] [4, 47] [4, 47] [4, 47] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -7.411494731903076 with beta sum per layer: [246.20115661621094, 1021.2490234375, 2039.91552734375, 903.2581787109375, 2095.11083984375]
alpha/beta optimization time: 0.3889760971069336
This batch time : update_bounds func: 1.2263	 prepare: 0.3457	 bound: 0.3895	 transfer: 0.0234	 finalize: 0.4615
Accumulated time: update_bounds func: 107.6394	 prepare: 27.6354	 bound: 55.4679	 transfer: 0.0234	 finalize: 21.8909
batch bounding time:  1.2286279201507568
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (303), [-0.07497,   inf] (303), [-0.07471,   inf] (303), [-0.07458,   inf] (303), [-0.07445,   inf] (303), [-0.07436,   inf] (303), [-0.07434,   inf] (303), [-0.07424,   inf] (303), [-0.07370,   inf] (303), [-0.07357,   inf] (303), [-0.07232,   inf] (303), [-0.07222,   inf] (303), [-0.07194,   inf] (303), [-0.07186,   inf] (303), [-0.07148,   inf] (303), [-0.07148,   inf] (303), [-0.07082,   inf] (303), [-0.07078,   inf] (303), [-0.07077,   inf] (303), [-0.07077,   inf] (303), 
length of domains: 6166
Total time: 2.1927	 pickout: 0.2175	 decision: 0.2398	 get_bound: 1.2323	 add_domain: 0.5031
Current lb:-0.0751020684838295
170892 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 191.37277007102966

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 23] [4, 23] [4, 23] [4, 23] [4, 23] [4, 23] [4, 23] [4, 23] [4, 23] [4, 23] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -4.621911525726318 with beta sum per layer: [232.72947692871094, 991.593994140625, 2059.17626953125, 914.6993408203125, 2065.71875]
alpha/beta optimization time: 0.3861258029937744
This batch time : update_bounds func: 0.9531	 prepare: 0.3308	 bound: 0.3866	 transfer: 0.0222	 finalize: 0.2079
Accumulated time: update_bounds func: 108.5925	 prepare: 27.9661	 bound: 55.8545	 transfer: 0.0222	 finalize: 22.0989
batch bounding time:  0.9552223682403564
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (305), [-0.07497,   inf] (305), [-0.07471,   inf] (305), [-0.07458,   inf] (305), [-0.07445,   inf] (305), [-0.07436,   inf] (305), [-0.07434,   inf] (305), [-0.07424,   inf] (305), [-0.07370,   inf] (305), [-0.07357,   inf] (305), [-0.07232,   inf] (305), [-0.07222,   inf] (305), [-0.07194,   inf] (305), [-0.07186,   inf] (305), [-0.07148,   inf] (305), [-0.07148,   inf] (305), [-0.07082,   inf] (305), [-0.07078,   inf] (305), [-0.07077,   inf] (305), [-0.07077,   inf] (305), 
length of domains: 6243
Total time: 2.1631	 pickout: 0.2162	 decision: 0.4829	 get_bound: 0.9587	 add_domain: 0.5052
Current lb:-0.0751020684838295
172940 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 193.59598541259766

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 60] [2, 60] [2, 60] [2, 60] [2, 60] [2, 60] [2, 60] [2, 60] [2, 60] [2, 60] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5.440948009490967 with beta sum per layer: [227.72018432617188, 1003.7232666015625, 2200.55859375, 879.7686767578125, 1949.670166015625]
alpha/beta optimization time: 0.38806915283203125
This batch time : update_bounds func: 1.2002	 prepare: 0.3306	 bound: 0.3886	 transfer: 0.0232	 finalize: 0.4519
Accumulated time: update_bounds func: 109.7927	 prepare: 28.2967	 bound: 56.2430	 transfer: 0.0232	 finalize: 22.5508
batch bounding time:  1.2026011943817139
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (307), [-0.07497,   inf] (307), [-0.07471,   inf] (307), [-0.07458,   inf] (307), [-0.07445,   inf] (307), [-0.07436,   inf] (307), [-0.07434,   inf] (307), [-0.07424,   inf] (307), [-0.07370,   inf] (307), [-0.07357,   inf] (307), [-0.07232,   inf] (307), [-0.07222,   inf] (307), [-0.07194,   inf] (307), [-0.07186,   inf] (307), [-0.07148,   inf] (307), [-0.07148,   inf] (307), [-0.07082,   inf] (307), [-0.07078,   inf] (307), [-0.07077,   inf] (307), [-0.07077,   inf] (307), 
length of domains: 6448
Total time: 2.4531	 pickout: 0.2130	 decision: 0.4685	 get_bound: 1.2064	 add_domain: 0.5651
Current lb:-0.0751020684838295
174988 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 196.1058373451233

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 55] [2, 146] [2, 55] [2, 146] [2, 55] [2, 55] [2, 146] [2, 146] [2, 55] [2, 146] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 4.87192964553833 with beta sum per layer: [266.62060546875, 1012.2421264648438, 2462.71142578125, 764.0735473632812, 1701.656005859375]
alpha/beta optimization time: 0.3863637447357178
This batch time : update_bounds func: 1.2137	 prepare: 0.3385	 bound: 0.3869	 transfer: 0.0222	 finalize: 0.4605
Accumulated time: update_bounds func: 111.0064	 prepare: 28.6352	 bound: 56.6299	 transfer: 0.0222	 finalize: 23.0113
batch bounding time:  1.2158372402191162
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (309), [-0.07497,   inf] (309), [-0.07471,   inf] (309), [-0.07458,   inf] (309), [-0.07445,   inf] (309), [-0.07436,   inf] (309), [-0.07434,   inf] (309), [-0.07424,   inf] (309), [-0.07370,   inf] (309), [-0.07357,   inf] (309), [-0.07232,   inf] (309), [-0.07222,   inf] (309), [-0.07194,   inf] (309), [-0.07186,   inf] (309), [-0.07148,   inf] (309), [-0.07148,   inf] (309), [-0.07082,   inf] (309), [-0.07078,   inf] (309), [-0.07077,   inf] (309), [-0.07077,   inf] (309), 
length of domains: 6655
Total time: 2.2445	 pickout: 0.2211	 decision: 0.2347	 get_bound: 1.2193	 add_domain: 0.5694
Current lb:-0.0751020684838295
177036 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 198.4136519432068

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 146] [2, 55] [2, 146] [2, 55] [2, 146] [2, 146] [2, 55] [2, 55] [2, 146] [2, 55] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 1.3111847639083862 with beta sum per layer: [240.72128295898438, 1013.9234008789062, 2702.1552734375, 666.05419921875, 1619.64013671875]
alpha/beta optimization time: 0.3832426071166992
This batch time : update_bounds func: 0.9658	 prepare: 0.3356	 bound: 0.3837	 transfer: 0.0231	 finalize: 0.2171
Accumulated time: update_bounds func: 111.9722	 prepare: 28.9708	 bound: 57.0136	 transfer: 0.0231	 finalize: 23.2284
batch bounding time:  0.9680619239807129
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (311), [-0.07497,   inf] (311), [-0.07471,   inf] (311), [-0.07458,   inf] (311), [-0.07445,   inf] (311), [-0.07436,   inf] (311), [-0.07434,   inf] (311), [-0.07424,   inf] (311), [-0.07370,   inf] (311), [-0.07357,   inf] (311), [-0.07232,   inf] (311), [-0.07222,   inf] (311), [-0.07194,   inf] (311), [-0.07186,   inf] (311), [-0.07148,   inf] (311), [-0.07148,   inf] (311), [-0.07082,   inf] (311), [-0.07078,   inf] (311), [-0.07077,   inf] (311), [-0.07077,   inf] (311), 
length of domains: 6817
Total time: 2.2198	 pickout: 0.2152	 decision: 0.4785	 get_bound: 0.9715	 add_domain: 0.5546
Current lb:-0.0751020684838295
179084 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 200.6991844177246

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 117] [3, 117] [3, 117] [3, 117] [3, 117] [3, 117] [3, 117] [3, 117] [3, 117] [3, 117] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -0.4482120871543884 with beta sum per layer: [231.2811279296875, 992.9906005859375, 2803.9833984375, 716.9959716796875, 1543.60107421875]
alpha/beta optimization time: 0.3863086700439453
This batch time : update_bounds func: 0.9810	 prepare: 0.3470	 bound: 0.3868	 transfer: 0.0228	 finalize: 0.2183
Accumulated time: update_bounds func: 112.9531	 prepare: 29.3178	 bound: 57.4004	 transfer: 0.0228	 finalize: 23.4467
batch bounding time:  0.9831287860870361
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (313), [-0.07497,   inf] (313), [-0.07471,   inf] (313), [-0.07458,   inf] (313), [-0.07445,   inf] (313), [-0.07436,   inf] (313), [-0.07434,   inf] (313), [-0.07424,   inf] (313), [-0.07370,   inf] (313), [-0.07357,   inf] (313), [-0.07232,   inf] (313), [-0.07222,   inf] (313), [-0.07194,   inf] (313), [-0.07186,   inf] (313), [-0.07148,   inf] (313), [-0.07148,   inf] (313), [-0.07082,   inf] (313), [-0.07078,   inf] (313), [-0.07077,   inf] (313), [-0.07077,   inf] (313), 
length of domains: 6948
Total time: 2.5405	 pickout: 0.2151	 decision: 0.4905	 get_bound: 0.9868	 add_domain: 0.8482
Current lb:-0.0751020684838295
181132 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 203.3042595386505

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 178] [1, 178] [1, 178] [1, 178] [1, 178] [1, 178] [1, 178] [1, 178] [1, 178] [1, 178] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -7.198683738708496 with beta sum per layer: [228.52896118164062, 1021.7030639648438, 2697.52197265625, 767.431884765625, 1548.91357421875]
alpha/beta optimization time: 0.3837141990661621
This batch time : update_bounds func: 1.2370	 prepare: 0.3305	 bound: 0.3842	 transfer: 0.0231	 finalize: 0.4932
Accumulated time: update_bounds func: 114.1901	 prepare: 29.6484	 bound: 57.7846	 transfer: 0.0231	 finalize: 23.9400
batch bounding time:  1.2395966053009033
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (315), [-0.07497,   inf] (315), [-0.07471,   inf] (315), [-0.07458,   inf] (315), [-0.07445,   inf] (315), [-0.07436,   inf] (315), [-0.07434,   inf] (315), [-0.07424,   inf] (315), [-0.07370,   inf] (315), [-0.07357,   inf] (315), [-0.07232,   inf] (315), [-0.07222,   inf] (315), [-0.07194,   inf] (315), [-0.07186,   inf] (315), [-0.07148,   inf] (315), [-0.07148,   inf] (315), [-0.07082,   inf] (315), [-0.07078,   inf] (315), [-0.07077,   inf] (315), [-0.07077,   inf] (315), 
length of domains: 7032
Total time: 2.2153	 pickout: 0.2146	 decision: 0.2366	 get_bound: 1.2434	 add_domain: 0.5206
Current lb:-0.0751020684838295
183180 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 205.5839397907257

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 10] [3, 10] [3, 10] [3, 10] [3, 10] [3, 10] [3, 10] [3, 10] [3, 10] [3, 10] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -5.829384803771973 with beta sum per layer: [236.52670288085938, 975.2600708007812, 2614.27978515625, 785.7891845703125, 1652.808349609375]
alpha/beta optimization time: 0.38222360610961914
This batch time : update_bounds func: 1.2213	 prepare: 0.3275	 bound: 0.3827	 transfer: 0.0223	 finalize: 0.4826
Accumulated time: update_bounds func: 115.4114	 prepare: 29.9758	 bound: 58.1673	 transfer: 0.0223	 finalize: 24.4225
batch bounding time:  1.223649263381958
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (317), [-0.07497,   inf] (317), [-0.07471,   inf] (317), [-0.07458,   inf] (317), [-0.07445,   inf] (317), [-0.07436,   inf] (317), [-0.07434,   inf] (317), [-0.07424,   inf] (317), [-0.07370,   inf] (317), [-0.07357,   inf] (317), [-0.07232,   inf] (317), [-0.07222,   inf] (317), [-0.07194,   inf] (317), [-0.07186,   inf] (317), [-0.07148,   inf] (317), [-0.07148,   inf] (317), [-0.07082,   inf] (317), [-0.07078,   inf] (317), [-0.07077,   inf] (317), [-0.07077,   inf] (317), 
length of domains: 7129
Total time: 2.2094	 pickout: 0.2170	 decision: 0.2356	 get_bound: 1.2273	 add_domain: 0.5294
Current lb:-0.0751020684838295
185228 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 207.8587110042572

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 44] [4, 44] [4, 44] [4, 44] [4, 44] [4, 44] [4, 44] [4, 44] [4, 44] [4, 44] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 8.585432052612305 with beta sum per layer: [231.66209411621094, 974.5361938476562, 2611.142578125, 804.7363891601562, 1709.263671875]
alpha/beta optimization time: 0.3826470375061035
This batch time : update_bounds func: 1.2178	 prepare: 0.3281	 bound: 0.3831	 transfer: 0.0232	 finalize: 0.4770
Accumulated time: update_bounds func: 116.6292	 prepare: 30.3040	 bound: 58.5505	 transfer: 0.0232	 finalize: 24.8995
batch bounding time:  1.2201964855194092
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (319), [-0.07497,   inf] (319), [-0.07471,   inf] (319), [-0.07458,   inf] (319), [-0.07445,   inf] (319), [-0.07436,   inf] (319), [-0.07434,   inf] (319), [-0.07424,   inf] (319), [-0.07370,   inf] (319), [-0.07357,   inf] (319), [-0.07232,   inf] (319), [-0.07222,   inf] (319), [-0.07194,   inf] (319), [-0.07186,   inf] (319), [-0.07148,   inf] (319), [-0.07148,   inf] (319), [-0.07082,   inf] (319), [-0.07078,   inf] (319), [-0.07077,   inf] (319), [-0.07077,   inf] (319), 
length of domains: 7247
Total time: 2.2241	 pickout: 0.2164	 decision: 0.2373	 get_bound: 1.2239	 add_domain: 0.5465
Current lb:-0.0751020684838295
187276 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 210.14802241325378

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 44] [3, 44] [3, 44] [3, 44] [3, 44] [3, 44] [3, 44] [3, 44] [3, 44] [3, 44] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 13.668292999267578 with beta sum per layer: [228.07518005371094, 1004.653076171875, 2652.652099609375, 903.8994750976562, 1607.6923828125]
alpha/beta optimization time: 0.3893239498138428
This batch time : update_bounds func: 0.9607	 prepare: 0.3318	 bound: 0.3898	 transfer: 0.0232	 finalize: 0.2100
Accumulated time: update_bounds func: 117.5899	 prepare: 30.6357	 bound: 58.9403	 transfer: 0.0232	 finalize: 25.1095
batch bounding time:  0.9629771709442139
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (321), [-0.07497,   inf] (321), [-0.07471,   inf] (321), [-0.07458,   inf] (321), [-0.07445,   inf] (321), [-0.07436,   inf] (321), [-0.07434,   inf] (321), [-0.07424,   inf] (321), [-0.07370,   inf] (321), [-0.07357,   inf] (321), [-0.07232,   inf] (321), [-0.07222,   inf] (321), [-0.07194,   inf] (321), [-0.07186,   inf] (321), [-0.07148,   inf] (321), [-0.07148,   inf] (321), [-0.07082,   inf] (321), [-0.07078,   inf] (321), [-0.07077,   inf] (321), [-0.07077,   inf] (321), 
length of domains: 7367
Total time: 2.2327	 pickout: 0.2157	 decision: 0.5005	 get_bound: 0.9666	 add_domain: 0.5499
Current lb:-0.0751020684838295
189324 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 212.45607233047485

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 48] [3, 93] [3, 48] [3, 93] [3, 48] [3, 48] [3, 93] [3, 93] [3, 48] [3, 93] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 7.941258430480957 with beta sum per layer: [228.82614135742188, 1010.255615234375, 2640.8115234375, 924.783203125, 1557.010986328125]
alpha/beta optimization time: 0.3908083438873291
This batch time : update_bounds func: 0.9700	 prepare: 0.3326	 bound: 0.3913	 transfer: 0.0240	 finalize: 0.2160
Accumulated time: update_bounds func: 118.5600	 prepare: 30.9683	 bound: 59.3316	 transfer: 0.0240	 finalize: 25.3256
batch bounding time:  0.9724171161651611
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (323), [-0.07497,   inf] (323), [-0.07471,   inf] (323), [-0.07458,   inf] (323), [-0.07445,   inf] (323), [-0.07436,   inf] (323), [-0.07434,   inf] (323), [-0.07424,   inf] (323), [-0.07370,   inf] (323), [-0.07357,   inf] (323), [-0.07232,   inf] (323), [-0.07222,   inf] (323), [-0.07194,   inf] (323), [-0.07186,   inf] (323), [-0.07148,   inf] (323), [-0.07148,   inf] (323), [-0.07082,   inf] (323), [-0.07078,   inf] (323), [-0.07077,   inf] (323), [-0.07077,   inf] (323), 
length of domains: 7464
Total time: 2.2415	 pickout: 0.2165	 decision: 0.5093	 get_bound: 0.9762	 add_domain: 0.5395
Current lb:-0.0751020684838295
191372 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 214.76344513893127

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 93] [1, 2] [3, 93] [1, 2] [3, 93] [3, 93] [1, 2] [1, 2] [3, 93] [1, 2] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: 5.162349224090576 with beta sum per layer: [225.77005004882812, 1024.6375732421875, 2604.155517578125, 943.6083984375, 1529.39599609375]
alpha/beta optimization time: 0.3905794620513916
This batch time : update_bounds func: 1.2656	 prepare: 0.3310	 bound: 0.3911	 transfer: 0.0241	 finalize: 0.5131
Accumulated time: update_bounds func: 119.8256	 prepare: 31.2993	 bound: 59.7226	 transfer: 0.0241	 finalize: 25.8387
batch bounding time:  1.2682929039001465
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (325), [-0.07497,   inf] (325), [-0.07471,   inf] (325), [-0.07458,   inf] (325), [-0.07445,   inf] (325), [-0.07436,   inf] (325), [-0.07434,   inf] (325), [-0.07424,   inf] (325), [-0.07370,   inf] (325), [-0.07357,   inf] (325), [-0.07232,   inf] (325), [-0.07222,   inf] (325), [-0.07194,   inf] (325), [-0.07186,   inf] (325), [-0.07148,   inf] (325), [-0.07148,   inf] (325), [-0.07082,   inf] (325), [-0.07078,   inf] (325), [-0.07077,   inf] (325), [-0.07077,   inf] (325), 
length of domains: 7574
Total time: 2.5417	 pickout: 0.2185	 decision: 0.5048	 get_bound: 1.2722	 add_domain: 0.5462
Current lb:-0.0751020684838295
193420 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 217.36758685112

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 2] [3, 76] [1, 2] [3, 76] [1, 2] [1, 2] [3, 76] [3, 76] [1, 2] [3, 76] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -13.921801567077637 with beta sum per layer: [220.16761779785156, 1052.936279296875, 2631.800537109375, 833.040283203125, 1573.36669921875]
alpha/beta optimization time: 0.38835787773132324
This batch time : update_bounds func: 1.2625	 prepare: 0.3302	 bound: 0.3888	 transfer: 0.0231	 finalize: 0.5137
Accumulated time: update_bounds func: 121.0881	 prepare: 31.6295	 bound: 60.1115	 transfer: 0.0231	 finalize: 26.3524
batch bounding time:  1.2648370265960693
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (327), [-0.07497,   inf] (327), [-0.07471,   inf] (327), [-0.07458,   inf] (327), [-0.07445,   inf] (327), [-0.07436,   inf] (327), [-0.07434,   inf] (327), [-0.07424,   inf] (327), [-0.07370,   inf] (327), [-0.07357,   inf] (327), [-0.07232,   inf] (327), [-0.07222,   inf] (327), [-0.07194,   inf] (327), [-0.07186,   inf] (327), [-0.07148,   inf] (327), [-0.07148,   inf] (327), [-0.07082,   inf] (327), [-0.07078,   inf] (327), [-0.07077,   inf] (327), [-0.07077,   inf] (327), 
length of domains: 7690
Total time: 2.2814	 pickout: 0.2217	 decision: 0.2354	 get_bound: 1.2686	 add_domain: 0.5557
Current lb:-0.0751020684838295
195468 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 219.7083740234375

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 76] [3, 180] [3, 76] [3, 180] [3, 76] [3, 76] [3, 180] [3, 180] [3, 76] [3, 180] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -14.946577072143555 with beta sum per layer: [228.92044067382812, 1025.8740234375, 2599.7421875, 818.5249633789062, 1652.3330078125]
alpha/beta optimization time: 0.39317917823791504
This batch time : update_bounds func: 1.3156	 prepare: 0.3462	 bound: 0.3937	 transfer: 0.0241	 finalize: 0.5455
Accumulated time: update_bounds func: 122.4036	 prepare: 31.9757	 bound: 60.5051	 transfer: 0.0241	 finalize: 26.8979
batch bounding time:  1.3182120323181152
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (329), [-0.07497,   inf] (329), [-0.07471,   inf] (329), [-0.07458,   inf] (329), [-0.07445,   inf] (329), [-0.07436,   inf] (329), [-0.07434,   inf] (329), [-0.07424,   inf] (329), [-0.07370,   inf] (329), [-0.07357,   inf] (329), [-0.07232,   inf] (329), [-0.07222,   inf] (329), [-0.07194,   inf] (329), [-0.07186,   inf] (329), [-0.07148,   inf] (329), [-0.07148,   inf] (329), [-0.07082,   inf] (329), [-0.07078,   inf] (329), [-0.07077,   inf] (329), [-0.07077,   inf] (329), 
length of domains: 7771
Total time: 2.3653	 pickout: 0.2511	 decision: 0.2438	 get_bound: 1.3222	 add_domain: 0.5482
Current lb:-0.0751020684838295
197516 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 222.13685870170593

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 88] [4, 88] [4, 88] [4, 88] [4, 88] [4, 88] [4, 88] [4, 88] [4, 88] [4, 88] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -14.96398639678955 with beta sum per layer: [231.39120483398438, 1035.6055908203125, 2602.616455078125, 683.076904296875, 1760.00537109375]
alpha/beta optimization time: 0.3869640827178955
This batch time : update_bounds func: 1.2504	 prepare: 0.3330	 bound: 0.3874	 transfer: 0.0231	 finalize: 0.5001
Accumulated time: update_bounds func: 123.6540	 prepare: 32.3087	 bound: 60.8926	 transfer: 0.0231	 finalize: 27.3980
batch bounding time:  1.2528443336486816
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (331), [-0.07497,   inf] (331), [-0.07471,   inf] (331), [-0.07458,   inf] (331), [-0.07445,   inf] (331), [-0.07436,   inf] (331), [-0.07434,   inf] (331), [-0.07424,   inf] (331), [-0.07370,   inf] (331), [-0.07357,   inf] (331), [-0.07232,   inf] (331), [-0.07222,   inf] (331), [-0.07194,   inf] (331), [-0.07186,   inf] (331), [-0.07148,   inf] (331), [-0.07148,   inf] (331), [-0.07082,   inf] (331), [-0.07078,   inf] (331), [-0.07077,   inf] (331), [-0.07077,   inf] (331), 
length of domains: 7818
Total time: 2.2548	 pickout: 0.2236	 decision: 0.2447	 get_bound: 1.2566	 add_domain: 0.5300
Current lb:-0.0751020684838295
199564 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 224.45803141593933

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 180] [1, 183] [3, 180] [1, 183] [3, 180] [3, 180] [1, 183] [1, 183] [3, 180] [1, 183] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -16.953649520874023 with beta sum per layer: [223.97378540039062, 1050.6375732421875, 2633.984375, 653.4347534179688, 1733.9002685546875]
alpha/beta optimization time: 0.386000394821167
This batch time : update_bounds func: 1.2456	 prepare: 0.3366	 bound: 0.3865	 transfer: 0.0233	 finalize: 0.2107
Accumulated time: update_bounds func: 124.8996	 prepare: 32.6453	 bound: 61.2791	 transfer: 0.0233	 finalize: 27.6087
batch bounding time:  1.2479710578918457
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (333), [-0.07497,   inf] (333), [-0.07471,   inf] (333), [-0.07458,   inf] (333), [-0.07445,   inf] (333), [-0.07436,   inf] (333), [-0.07434,   inf] (333), [-0.07424,   inf] (333), [-0.07370,   inf] (333), [-0.07357,   inf] (333), [-0.07232,   inf] (333), [-0.07222,   inf] (333), [-0.07194,   inf] (333), [-0.07186,   inf] (333), [-0.07148,   inf] (333), [-0.07148,   inf] (333), [-0.07082,   inf] (333), [-0.07078,   inf] (333), [-0.07077,   inf] (333), [-0.07077,   inf] (333), 
length of domains: 7878
Total time: 2.2512	 pickout: 0.2203	 decision: 0.2393	 get_bound: 1.2517	 add_domain: 0.5399
Current lb:-0.0751020684838295
201612 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 226.77732014656067

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [1, 183] [4, 34] [1, 183] [4, 34] [1, 183] [1, 183] [4, 34] [4, 34] [1, 183] [4, 34] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -27.06946563720703 with beta sum per layer: [225.5637664794922, 1063.732421875, 2616.565673828125, 611.96142578125, 1758.103515625]
alpha/beta optimization time: 0.3850712776184082
This batch time : update_bounds func: 0.9638	 prepare: 0.3365	 bound: 0.3856	 transfer: 0.0231	 finalize: 0.2125
Accumulated time: update_bounds func: 125.8634	 prepare: 32.9818	 bound: 61.6646	 transfer: 0.0231	 finalize: 27.8212
batch bounding time:  0.9662723541259766
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (335), [-0.07497,   inf] (335), [-0.07471,   inf] (335), [-0.07458,   inf] (335), [-0.07445,   inf] (335), [-0.07436,   inf] (335), [-0.07434,   inf] (335), [-0.07424,   inf] (335), [-0.07370,   inf] (335), [-0.07357,   inf] (335), [-0.07232,   inf] (335), [-0.07222,   inf] (335), [-0.07194,   inf] (335), [-0.07186,   inf] (335), [-0.07148,   inf] (335), [-0.07148,   inf] (335), [-0.07082,   inf] (335), [-0.07078,   inf] (335), [-0.07077,   inf] (335), [-0.07077,   inf] (335), 
length of domains: 7934
Total time: 2.2735	 pickout: 0.2187	 decision: 0.5450	 get_bound: 0.9700	 add_domain: 0.5399
Current lb:-0.0751020684838295
203660 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 229.11564946174622

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 34] [4, 104] [4, 34] [4, 104] [4, 34] [4, 34] [4, 104] [4, 104] [4, 34] [4, 104] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -27.193870544433594 with beta sum per layer: [226.98883056640625, 1073.84521484375, 2697.236083984375, 584.0350952148438, 1738.935791015625]
alpha/beta optimization time: 0.3839411735534668
This batch time : update_bounds func: 0.9623	 prepare: 0.3351	 bound: 0.3844	 transfer: 0.0231	 finalize: 0.2132
Accumulated time: update_bounds func: 126.8257	 prepare: 33.3169	 bound: 62.0490	 transfer: 0.0231	 finalize: 28.0344
batch bounding time:  0.9645297527313232
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (337), [-0.07497,   inf] (337), [-0.07471,   inf] (337), [-0.07458,   inf] (337), [-0.07445,   inf] (337), [-0.07436,   inf] (337), [-0.07434,   inf] (337), [-0.07424,   inf] (337), [-0.07370,   inf] (337), [-0.07357,   inf] (337), [-0.07232,   inf] (337), [-0.07222,   inf] (337), [-0.07194,   inf] (337), [-0.07186,   inf] (337), [-0.07148,   inf] (337), [-0.07148,   inf] (337), [-0.07082,   inf] (337), [-0.07078,   inf] (337), [-0.07077,   inf] (337), [-0.07077,   inf] (337), 
length of domains: 7983
Total time: 2.2711	 pickout: 0.2245	 decision: 0.5383	 get_bound: 0.9681	 add_domain: 0.5401
Current lb:-0.0751020684838295
205708 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 231.45148587226868

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 104] [2, 194] [4, 104] [2, 194] [4, 104] [4, 104] [2, 194] [2, 194] [4, 104] [2, 194] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -19.144737243652344 with beta sum per layer: [231.4337158203125, 1074.26025390625, 2764.25732421875, 603.5624389648438, 1722.5166015625]
alpha/beta optimization time: 0.38632869720458984
This batch time : update_bounds func: 0.9599	 prepare: 0.3323	 bound: 0.3868	 transfer: 0.0223	 finalize: 0.2124
Accumulated time: update_bounds func: 127.7856	 prepare: 33.6492	 bound: 62.4358	 transfer: 0.0223	 finalize: 28.2468
batch bounding time:  0.9624407291412354
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (339), [-0.07497,   inf] (339), [-0.07471,   inf] (339), [-0.07458,   inf] (339), [-0.07445,   inf] (339), [-0.07436,   inf] (339), [-0.07434,   inf] (339), [-0.07424,   inf] (339), [-0.07370,   inf] (339), [-0.07357,   inf] (339), [-0.07232,   inf] (339), [-0.07222,   inf] (339), [-0.07194,   inf] (339), [-0.07186,   inf] (339), [-0.07148,   inf] (339), [-0.07148,   inf] (339), [-0.07082,   inf] (339), [-0.07078,   inf] (339), [-0.07077,   inf] (339), [-0.07077,   inf] (339), 
length of domains: 8062
Total time: 2.6258	 pickout: 0.2226	 decision: 0.5405	 get_bound: 0.9663	 add_domain: 0.8965
Current lb:-0.0751020684838295
207756 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 234.14006876945496

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 194] [4, 174] [2, 194] [4, 174] [2, 194] [2, 194] [4, 174] [4, 174] [2, 194] [4, 174] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -15.114506721496582 with beta sum per layer: [246.41201782226562, 1096.695556640625, 2708.052734375, 595.4381103515625, 1803.99853515625]
alpha/beta optimization time: 0.3864705562591553
This batch time : update_bounds func: 0.9576	 prepare: 0.3288	 bound: 0.3870	 transfer: 0.0237	 finalize: 0.2120
Accumulated time: update_bounds func: 128.7432	 prepare: 33.9780	 bound: 62.8228	 transfer: 0.0237	 finalize: 28.4588
batch bounding time:  0.9599392414093018
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (341), [-0.07497,   inf] (341), [-0.07471,   inf] (341), [-0.07458,   inf] (341), [-0.07445,   inf] (341), [-0.07436,   inf] (341), [-0.07434,   inf] (341), [-0.07424,   inf] (341), [-0.07370,   inf] (341), [-0.07357,   inf] (341), [-0.07232,   inf] (341), [-0.07222,   inf] (341), [-0.07194,   inf] (341), [-0.07186,   inf] (341), [-0.07148,   inf] (341), [-0.07148,   inf] (341), [-0.07082,   inf] (341), [-0.07078,   inf] (341), [-0.07077,   inf] (341), [-0.07077,   inf] (341), 
length of domains: 8140
Total time: 2.3696	 pickout: 0.2208	 decision: 0.2713	 get_bound: 0.9636	 add_domain: 0.9140
Current lb:-0.0751020684838295
209804 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 236.5777072906494

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [4, 174] [2, 172] [4, 174] [2, 172] [4, 174] [4, 174] [3, 48] [3, 48] [4, 174] [2, 172] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -13.261117935180664 with beta sum per layer: [264.322998046875, 1094.49365234375, 2703.37841796875, 652.521240234375, 1813.82470703125]
alpha/beta optimization time: 0.3889434337615967
This batch time : update_bounds func: 0.9747	 prepare: 0.3465	 bound: 0.3895	 transfer: 0.0222	 finalize: 0.2100
Accumulated time: update_bounds func: 129.7179	 prepare: 34.3245	 bound: 63.2123	 transfer: 0.0222	 finalize: 28.6689
batch bounding time:  0.9772987365722656
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (343), [-0.07493,   inf] (343), [-0.07471,   inf] (343), [-0.07454,   inf] (343), [-0.07445,   inf] (343), [-0.07436,   inf] (343), [-0.07370,   inf] (343), [-0.07353,   inf] (343), [-0.07232,   inf] (343), [-0.07218,   inf] (343), [-0.07194,   inf] (343), [-0.07182,   inf] (343), [-0.07148,   inf] (343), [-0.07148,   inf] (343), [-0.07099,   inf] (343), [-0.07082,   inf] (343), [-0.07078,   inf] (343), [-0.07071,   inf] (343), [-0.07060,   inf] (343), [-0.06907,   inf] (343), 
length of domains: 8199
Total time: 2.4281	 pickout: 0.2191	 decision: 0.3160	 get_bound: 0.9812	 add_domain: 0.9119
Current lb:-0.0751020684838295
211852 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 239.07337880134583

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [3, 172] [3, 48] [2, 172] [3, 48] [0, 156] [3, 172] [0, 156] [0, 156] [2, 172] [3, 48] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -16.40209197998047 with beta sum per layer: [306.4217834472656, 1100.116943359375, 2721.343505859375, 679.6343994140625, 1794.229248046875]
alpha/beta optimization time: 0.3932673931121826
This batch time : update_bounds func: 0.9570	 prepare: 0.3281	 bound: 0.3937	 transfer: 0.0232	 finalize: 0.2056
Accumulated time: update_bounds func: 130.6748	 prepare: 34.6526	 bound: 63.6060	 transfer: 0.0232	 finalize: 28.8745
batch bounding time:  0.9591763019561768
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (345), [-0.07465,   inf] (345), [-0.07445,   inf] (345), [-0.07436,   inf] (345), [-0.07370,   inf] (345), [-0.07353,   inf] (345), [-0.07226,   inf] (345), [-0.07194,   inf] (345), [-0.07148,   inf] (345), [-0.07148,   inf] (345), [-0.07121,   inf] (345), [-0.07099,   inf] (345), [-0.07087,   inf] (345), [-0.07082,   inf] (345), [-0.07078,   inf] (345), [-0.07071,   inf] (345), [-0.07058,   inf] (345), [-0.06998,   inf] (345), [-0.06976,   inf] (345), [-0.06892,   inf] (345), 
length of domains: 8267
Total time: 2.4439	 pickout: 0.2188	 decision: 0.3579	 get_bound: 0.9629	 add_domain: 0.9043
Current lb:-0.0751020684838295
213900 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 241.57997274398804

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [0, 156] [0, 156] [2, 172] [0, 156] [2, 172] [3, 48] [0, 156] [2, 172] [1, 183] [2, 172] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -20.818750381469727 with beta sum per layer: [328.5638732910156, 1122.3800048828125, 2753.267578125, 736.2708740234375, 1741.4127197265625]
alpha/beta optimization time: 0.3860611915588379
This batch time : update_bounds func: 0.9549	 prepare: 0.3319	 bound: 0.3865	 transfer: 0.0232	 finalize: 0.2067
Accumulated time: update_bounds func: 131.6297	 prepare: 34.9845	 bound: 63.9926	 transfer: 0.0232	 finalize: 29.0812
batch bounding time:  0.957165002822876
Current worst splitting domains [lb, ub] (depth):
[-0.07510,   inf] (347), [-0.07465,   inf] (347), [-0.07439,   inf] (347), [-0.07436,   inf] (347), [-0.07364,   inf] (347), [-0.07226,   inf] (347), [-0.07188,   inf] (347), [-0.07148,   inf] (347), [-0.07142,   inf] (347), [-0.07121,   inf] (347), [-0.07099,   inf] (347), [-0.07086,   inf] (347), [-0.07082,   inf] (347), [-0.07078,   inf] (347), [-0.07071,   inf] (347), [-0.07057,   inf] (347), [-0.07031,   inf] (347), [-0.06998,   inf] (347), [-0.06976,   inf] (347), [-0.06891,   inf] (347), 
length of domains: 8351
Total time: 2.5361	 pickout: 0.2219	 decision: 0.4257	 get_bound: 0.9607	 add_domain: 0.9277
Current lb:-0.0751020684838295
215948 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 244.19821572303772

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  1
splitting decisions: 
split level 0: [2, 172] [3, 172] [3, 172] [2, 172] [3, 172] [3, 172] [0, 156] [2, 172] [0, 156] [0, 156] 
regular batch size: 2*1024, diving batch size 1*0
best_l after optimization: -21.5820255279541 with beta sum per layer: [336.9700622558594, 1121.52197265625, 2739.7578125, 751.4046630859375, 1752.989013671875]
alpha/beta optimization time: 0.387836217880249
This batch time : update_bounds func: 0.9587	 prepare: 0.3321	 bound: 0.3883	 transfer: 0.0231	 finalize: 0.2086
Accumulated time: update_bounds func: 132.5883	 prepare: 35.3166	 bound: 64.3809	 transfer: 0.0231	 finalize: 29.2898
batch bounding time:  0.9608969688415527
Current worst splitting domains [lb, ub] (depth):
[-0.07504,   inf] (349), [-0.07465,   inf] (349), [-0.07439,   inf] (349), [-0.07430,   inf] (349), [-0.07364,   inf] (349), [-0.07225,   inf] (349), [-0.07188,   inf] (349), [-0.07142,   inf] (349), [-0.07142,   inf] (349), [-0.07121,   inf] (349), [-0.07099,   inf] (349), [-0.07086,   inf] (349), [-0.07076,   inf] (349), [-0.07072,   inf] (349), [-0.07071,   inf] (349), [-0.07056,   inf] (349), [-0.07027,   inf] (349), [-0.06998,   inf] (349), [-0.06976,   inf] (349), [-0.06891,   inf] (349), 
length of domains: 8408
Total time: 2.6428	 pickout: 0.2451	 decision: 0.4627	 get_bound: 0.9646	 add_domain: 0.9704
Current lb:-0.0750431939959526
217996 neurons visited
0 diving domains visited
Global ub: inf, batch ub: inf
Cumulative time: 246.9058358669281

remaining dive domains: 0/-1, dive_rate:0.0
batch:  torch.Size([1024, 200]) pre split depth:  1
batch:  torch.Size([1024, 200]) post split depth:  0
all nodes are split!!
Global ub: inf, batch ub: inf
Image 199 label 3 verification end, final lower bound -0.0750431939959526, upper bound inf, time: 247.997216463089
199 -0.0750431939959526
Result: image 199 verification failure (with branch and bound).
Wall time: 515.5988607406616

number of correctly classified examples: 1
incorrectly classified idx (total 0): []
attack success idx (total 0): []
verification success idx (total 0): []
verification failure idx (total 1): [199]
final verified acc: 0.0%[1]
verifier is called on 1 examples.
total verified: 0
mean time [cnt:1] (excluding attack success): 515.5372688770294
