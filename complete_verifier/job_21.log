/home/zhouxingshi/miniconda3/envs/torch2.0/lib/python3.10/site-packages/torchvision/transforms/_functional_pil.py:242: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.
  interpolation: int = Image.BILINEAR,
/home/zhouxingshi/miniconda3/envs/torch2.0/lib/python3.10/site-packages/torchvision/transforms/_functional_pil.py:286: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.
  interpolation: int = Image.NEAREST,
/home/zhouxingshi/miniconda3/envs/torch2.0/lib/python3.10/site-packages/torchvision/transforms/_functional_pil.py:319: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.
  interpolation: int = Image.BICUBIC,
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: matrix
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  sparse_alpha: false
  sparse_interm: false
  save_adv_example: false
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: false
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: /home/zhouxingshi/nfs/experiments/vnncomp/0708/ml4acopf/master/job_0021_0022.pkl
  root_path: ../../vnncomp2023_benchmarks/benchmarks/ml4acopf
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "default_optimizer")'
  no_batchdim_buffers: true
model:
  name: null
  path: null
  onnx_path: null
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: default_onnx_and_vnnlib_loader
  onnx_optimization_flags: [remove_matmul_inplace]
  onnx_vnnlib_joint_optimization_flags: none
  check_optmized: false
  flatten_final_output: false
data:
  start: 21
  end: 22
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: null
  vnnlib_path_prefix: ''
solver:
  batch_size: 512
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.0
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.5
    iteration: 40
    share_alphas: false
    lr_decay: 0.99
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    include_output_constraint: false
    disable_optimization: [sin, cos]
  beta-crown:
    lr_alpha: 0.5
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 10
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
    alpha_masks: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: false
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 360
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: false
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
    _tmp_cuts: null
    fixed_cuts: false
    add_implied_cuts: false
    add_input_cuts: false
  branching:
    method: nonlinear
    candidates: 3
    reduceop: min
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    sort_domain_interval: 1
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sb_coeff_thresh: 0.001
    nonlinear_split:
      method: shortcut
      branching_point_method: middle
      num_branches: 2
      branching_point_refinement: false
      filter: true
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      faster: true
      loose_tanh_threshold: null
      batch_size: 51200
      shortlist_size: 500
    new_input_split:
      enable: false
      batch_size: 2
      rounds: 1
      init_alpha_batch_size: 8192
      full_alpha: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      ibp_enhancement: false
      alpha_enhancement: null
      alpha_enhancement_batch: 2048
      qp_enhancement: null
      catch_assertion: false
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 30.0
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 100
  pgd_batch_size: 100000000
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: default_adv_saver
  early_stop_condition: default_early_stop_condition
  adv_example_finalizer: default_adv_example_finalizer
  pgd_loss: default_pgd_loss
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0001
  attack_func: attack_with_general_specs
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
debug:
  rhs_offset: null
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0

Experiments at Sat Jul  8 12:02:35 2023 on nova.cs.ucla.edu
customized start/end sample from instance 21 to 22 in instances.csv
Internal results will be saved to /home/zhouxingshi/nfs/experiments/vnncomp/0708/ml4acopf/master/job_0021_0022.pkl.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 21 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx onnx/300_ieee_ml4acopf.onnx
Using vnnlib vnnlib/300_ieee_prop2.vnnlib
Precompiled vnnlib file found at ../../vnncomp2023_benchmarks/benchmarks/ml4acopf/vnnlib/300_ieee_prop2.vnnlib.compiled
Loading onnx ../../vnncomp2023_benchmarks/benchmarks/ml4acopf/onnx/300_ieee_ml4acopf.onnx wih quirks {}
Onnx optimization with flag: ['remove_matmul_inplace']
Found existed optimized onnx model at ../../vnncomp2023_benchmarks/benchmarks/ml4acopf/onnx/300_ieee_ml4acopf.onnx.optimized
Automatic inference of operator: cos
Automatic inference of operator: sin
Automatic inference of operator: neg
/home/zhouxingshi/onnx2pytorch/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(

**************************
Model might not be converted correctly. Please check onnx conversion carefully.
Output by pytorch: [[ 0.          0.          0.         ... -0.00017691 -0.00050684
  -0.00118516]]
Output by onnx: [[ 0.          0.          0.         ... -0.00017691 -0.00050678
  -0.00118504]]
Max error: tensor(0.00292969)
**************************

Attack parameters: initialization=uniform, steps=100, restarts=100, alpha=0.2547740936279297, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ 0.00000000,  0.00000000,  0.00000000,  ..., -0.00012999,
         -0.00026011, -0.00088488]], device='cuda:0')
  0%|                                                                                                                 | 0/1 [00:00<?, ?it/s]pgd early stop
  0%|                                                                                                                 | 0/1 [00:00<?, ?it/s]
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 0.00000000,  0.00000000,  0.00000000,  ...,  0.00100958,
          -0.00023638,  0.00017704]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[-110.26781464]]], device='cuda:0')
number of violation:  1
Attack finished in 1.2713 seconds.
PGD attack succeeded!
Result: unsafe-pgd in 3.0628 seconds
############# Summary #############
Final verified acc: 0.0% (total 1 examples)
Problem instances count: 1 , total verified (safe/unsat): 0 , total falsified (unsafe/sat): 1 , timeout: 0
mean time for ALL instances (total 1):3.0627786011110834, max time: 3.0628092288970947
mean time for verified UNSAFE instances (total 1): 3.0628092288970947, max time: 3.0628092288970947
unsafe-pgd (total 1), index: [0]
